%%{{{ [vim] 
% vim:foldmarker=%{{{,%}}}
% vim:foldmethod=marker
% vim:foldcolumn=7
%%}}}
%% fmcmain.tex
%% author: Thanos Tsouanas <thanos@tsouanas.org>
%% Copyright (c) 2016--2020 Thanos Tsouanas
%% All rights reserved.

%%{{{ chapter: Introductions 
\chapter Introduções.
%%%{{{ meta 
\label Introductions
%%%}}}

%%{{{ intro 
\chapintro
Sim, plural:
neste capítulo intoduzo todas as noções e idéias básicas com
a profundidade mínima---e logo com umas mentiras
também, e logo com uns erros---para começar aprofundar
nos próximos capítulos.
Se encontrar alguma notação, algum termo, símbolo, processo, etc.,
que tu não reconhece, continue lendo;
o importante é entender bem as idéias básicas.
E os detalhes?  Depois.
%%}}}

%%{{{ Propositions_vs_objects 
\section Proposições \vs objetos.
%%%{{{ meta 
\label Propositions_vs_objects
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Olhando para matemática de longe podemos enxergar dois tipos principais:
\emph{proposições} e \emph{objetos}
(também \emph{indivíduos}).\foot
Para o leitor que já sabe o que é um \dterm{sintagma nominal}
em lingüística, as expressões que denotam objetos são exatamente
os sintagmas nomináis.
\toof
O primeiro e mais elementar desafio do meu leitor seria entender
essas duas noções, no ponto que nunca confundiria uma por outra.

%%}}}

%%{{{ eg: object_phrase_examples 
\example Objetos.
%%%{{{ meta 
\label object_phrase_examples
%%%}}}

Uns exemplos de frases que denotam objetos:
\elist:
\li: Brasil
\li: a mãe do Bart
\li: $(1 + 1)^3$
\li: Évariste Galois
\li: 8
\li: Matemática
\endelist
Não faz sentido supor nenhuma delas, nem duvidar, nem tentar demonstrar,
nem nada disso.  Não têm verbo!  Imagine alguém dizer:
\quote
\wq{Eu acho que $(1+1)^3$.}
\endquote
Tu acha que $(1+1)^3$ o que?!

%%}}}

%%{{{ eg: proposition_phrase_examples 
\example Proposições.
%%%{{{ meta 
\label proposition_phrase_examples
%%%}}}

Uns exemplos de frases que denotam proposições:
\elist:
\li: Brasil é um país na Europa.
\li: A mãe do Bart fala português.
\li: $(1 + 1)^3 = 3^2-1$
\li: Galois morreu baleado.
\li: $8 \leq 12$
\li: Matemática estuda cavalos.
\endelist
Cada uma dessas frases, tem um verbo, e afirma algo completo.
Não importa a vericidade dessas proposições, o importante aqui é
entender que essas frases realmente são proposições.
Faz sentido afirmá-las, questioná-las, demonstrá-la, refutá-las, etc.

%%}}}

%%{{{ warning: expressions_that_denote_prop_not_always_do_so 
\warning Expressões que denotam proposições.
%%%{{{ meta 
\label expressions_that_denote_prop_not_always_do_so
%%%}}}

Umas expressões matemáticas que normalmente denotam proposições
podem assumir um papel diferente dependendo do contexto.
Por exemplo \symq{$x=y$} normalmente denota a proposição
``$x$ é igual ao $y$'', mas se o contexto já tem seu verbo
principal, por exemplo:
\math
\textwq{No outro lado, {\xlthole} é primo e logo \dots}
\endmath
Aqui pelo contexto precisamos algo que denota um objeto:
não faria sentido afirmar que uma proposição é primo.
Nesse caso a expressão \symq{$x=y$} pode ser lida como
qualquer uma das:
\mathcol
x = y & :\quad\text{``\aR{$x$, que é igual a $y$,}''} \\
x = y & :\quad\text{``\aB{$x$ é igual ao $y$, e $y$}''}.
\endmathcol
Por exemplo:
\math
\textwq{No outro lado, $2^n + 1 = 5$ é primo e logo \dots}
\endmath
pode ser lido respectivamente como qualquer uma das:
\math
\textwq{No outro lado, \aR{$2^n + 1$, que é igual a $5$,} é primo e logo \dots} \\
\textwq{No outro lado, \aB{$2^n + 1$ é igual a $5$, e $5$} é primo e logo \dots}.
\endmath
A mesma coisa aplica em outras notações que vamos encontrar depois,
por exemplo \symq{$x \in A$}, \symq{$A \subset B$}, e \symq{$f : A \to B$}.

%%}}}

\endsection
%%}}}

%%{{{ Equality_vs_equivalence 
\section Igualdade \vs equivalência.
%%%{{{ meta 
\label Equality_vs_equivalence
%%%}}}

%%{{{ equal or equivalente 
\note Igual ou equivalente?.
%%%{{{ meta 
\indexes
    * sse
    ;;
%%%}}}

Usamos os símbolos \symq{$=$} e \symq{$\iffsymbol$} para afirmar uma relação especifica entre as
coisas que aparecem nos dois lados deles.
Só que os \emph{tipos} de coisas são diferentes para cada símbolo.
O \symq{$=$} fica entre \emph{objetos},
o \symq{$\iffsymbol$} entre \emph{proposições}.
\eop
Usamos \symq{$=$} para dizer que os objetos nos seus lados
são \emph{iguais}, ou seja, as coisas escritas nos seus dois lados,
denotam o mesmo objeto.
Por exemplo \sq{$1+5$} denota um número e \sq{$3$}
também denota um número, e escrevendo
$$
1 + 5 = 3
$$
estamos afirmando---erroneamente nesse caso---que as duas
expressões denotam o mesmo número.
Se tivesse escrito \sq{$1 + 5 = 3 + 3$} teria sido uma afirmação correta.
Pronunciamos o \sq{$A = B$} como \utter{$A$ é igual ao $B$}.
\eop
Usamos \symq{$\iffsymbol$} para dizer que as proposições nos seus lados são
\emph{logicamente equivalentes}, ou seja, são ambas verdadeiras ou ambas falsas.
Escrevemos então
$$
\text{$p$ é primo e $p>2$}
\iff
\text{$p$ é um primo ímpar}
$$
e nesse caso essa é uma afirmação correta.
Note que não sabemos dizer qual é o caso aqui: são ambas verdadeiras, ou ambas falsas?
Não sabemos que número é denotado por a variável $p$, mesmo assim as afirmações
são equivalentes.
Pronunciamos o \sq{$A \iff B$} como \utter{$A$ é equivalente a $B$}
ou \utter{$A$ se e somente se $B$}, usando a abreviação \dterm{sse}
para a frase \wq{se e somente se}.
\eop
Entendemos o \symq{$\impliessymbol$} como uma abreviação de
\wq{implica} e o \symq{$\impliedbysymbol$} como uma abreviação de
\wq{é implicado por}.
Podemos ler as expressões seguintes assim também:
$$
\xalignat2
A \implies B   & :\quad\textwq{se $A$ então $B$} &
A \iff B       & :\quad\textwq{$A$ se e somente se $B$}.
\endxalignat
$$

%%}}}

%%{{{ x: which_is_if_and_which_is_only_if 
\exercise.
%%%{{{ meta 
\label which_is_if_and_which_is_only_if
%%%}}}

Já que \symq{$\iffsymbol$} corresponde à frase \wq{se e somente se},
faz sentido pensar que uma das setinhas envolvidas
(\symq{$\impliessymbol$} e \symq{$\impliedbysymbol$})
corresponde na frase \wq{se} e a outra na \wq{somente se}.
Qual é qual?

\solution
$$
\align
A \implies   B & :\quad\text{$A$ somente se $B$}\\
A \impliedby B & :\quad\text{$A$ se $B$}
\endalign
$$

%%}}}

%%{{{ x: which_is_nec_and_which_is_suf 
\exercise.
%%%{{{ meta 
\label which_is_nec_and_which_is_suf
%%%}}}

Mesma pergunta, agora lendo o \symq{$\iffsymbol$}
como \wq{é suficiente e necessário para}.
Uma direção corresponde ao \wq{suficiente} outra ao \wq{necessário}.
Qual é qual?

\solution
$$
\align
A \implies   B & :\quad\text{$A$ é necessário para $B$}\\
A \impliedby B & :\quad\text{$A$ é suficiente para $B$}.
\endalign
$$

%%}}}

%%{{{ relevance logics
\note Lógicas de relevância.
%%%{{{ meta 
\label relevance_logics
\defines
    * lógica!de relevância
    ;;
%%%}}}

Note que seguindo nossa interpretação de implicação e equivalência nos permite
corretamente afirmar implicações e equivalências entre
proposições que não tem nada a ver uma com outra.
Por exemplo, seria correto afirmar:
\tlist:
\li: $0 = 1$ se e somente se existe número natural maior que todos os outros.
\li: $1 + 1 = 2 \iff \text{Creta é uma ilha grega}$.
\li: Se Brasil é um país na Europa, então 4 é um número par.
\li: Se $4$ é um número par, então Grécia é um país na Europa.
\endtlist
Felizmente, afirmações desse tipo raramente aparecem em matemática.
Lógicas que tomam cuidado para proibir
implicações entre proposições irrelevantes são chamadas
\dterm{lógicas de relevância} (por motivos óbvios) mas não
vamos estudá-las aqui.

%%}}}

\endsection
%%}}}

%%{{{ Type_errors 
\section Type erros.
%%%{{{ meta 
\label Type_errors
%%%}}}

%%{{{ What is it? 
\note O que é?.
%%%{{{ meta 
\defines
    * mal-tipado
    * type error
    ;;
%%%}}}

Um \dterm{type error} ocorre quando usamos uma expressão cujo tipo é
incompatível com o tipo esperado pelo contexto.
Esse tipo de erro é muito comum quando começamos aprender matemática
e infelizmente é completamente destruidor: com um type error nosso texto
\emph{nem compila}, nem chega a dizer algo para ter chances de ser avaliado
para sua corretude.
Um texto com type errors não chega a ter significado nenhum.
Chamamos de \dterm{mal-tipada} uma expressão que contem type errors.

%%}}}

%%{{{ Type errors 
\note O type error mais grave.
%%%{{{ meta 
%%%}}}

Claramente o type error mais gritante seria confundir objeto com proposição ou
vice versa, pois como discutimos (\reftag[Propositions_vs_objects])
são os grupos mais distantes.

%%}}}

%%{{{ eg: biggest_type_error_eg 
\example.
%%%{{{ meta 
\label biggest_type_error_eg
%%%}}}

Todas as frases seguintes têm o type error mais grave:
confusão entre proposição e objeto:
\tlist:
\li (1):shithead $(x+y)^2 \iff x^2 + 2xy + y^2$.
\li (2):shittum $x(a-(b+c)) = xa - x(b + c) \implies xa - xb - xc$.
\li (3): Concluimos que $(A \subset B) = (B \subset A)$.
\li (4): Suponha $n$.  Vamos demonstrar que $n+1$.
\endtlist
(1) Temos uma suposta equivalência entre dois objetos.
O \sq{$\iffsymbol$} tava esperando ver (receber) proposições
nos seus lados, mas recebeu objetos.
(2) No lado esquerdo da implicação temos uma proposição,
(isso tá OK), mas no seu lado direito aparece um objeto.
Não faz sentido implicar um objeto:
\dialogue
\say Se chuver amanhã, então Maria.
\say \dots então Maria o quê?!
\enddialogue
(3) Aqui aparece igualdade entre duas proposições em vez de objetos.
(4) Como assim supor um objeto?  E como assim demonstrar um objeto?
Supomos proposições, e demonstramos suposições.  O que significa
supor Alex?  O que significa demonstrar o $5$?

%%}}}

%%{{{ x: biggest_type_error_exercise 
\exercise.
%%%{{{ meta 
\label biggest_type_error_exercise
%%%}}}

Mude cada uma das frases do~\ref[biggest_type_error_eg]
para resolver o type error.
Não se preocupe com a \emph{vericidade}.

\solution
\tlist:
\li (1): $(x+y)^2 = x^2 + 2xy + y^2$.
\li (2): $x(a-(b+c)) = xa - x(b + c) = xa - xb - xc$.
\li (3): Concluimos que $(A \subset B) \iff (B \subset A)$.
\li (4): Suponha que $n$ é lindo.  Vamos demonstrar que $n+1$ é feio.
\endtlist

%%}}}

%%{{{ Refining_further 
\note Refinando mais.
%%%{{{ meta 
\label Refining_further
%%%}}}

Podemos subdividir os objetos em tipos também, por exemplo:
números, pessoas, conjuntos de pessoas, palavras, cidades, funcções, programas, etc.
Sobre proposições, vamos fazer algo parecido nos capítulos~\reftag[Languages]
e~\reftag[Proofs]: conjunções, disjunções, implicações, negações, etc.

%%}}}

\endsection
%%}}}

%%{{{ Definitions 
\section Definições.
%%%{{{ meta 
\label Definitions
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tanto em matemática quanto fora de matemática, para facilitar nosso pensamento
e a comunicação com outras pessoas introduzimos novos termos, e novas notações
de certos conceitos, assim evitando a necessidade de descrever em todo detalhe
a mesma idéia repetidamente.

%%}}}

%%{{{ From mind to paper 
\note De mente para papel.
%%%{{{ meta 
%%%}}}

O processo de definir algo começa na nossa cabeça, onde
identificamos---ou pelo menos, achamos que identificamos---um conceito
que consideramos interessante e que merece seu próprio nome, sua própria
notação, etc.
Depois disso começa o processo de \emph{traduzir} nossa idéia, do mundo
mental para uma linguagem, freqüentemente sendo uma linguagem natural
pouco enriquecida com notação, termos, convenções, etc., para atender
as necessidades de matemática.
Também precisamos de \emph{escolher um nome bonito} para nossa definição,
uma notação conveniente e útil.

%%}}}

%%{{{ defiff_defeq (definition vs proposition) 
\note Definição \vs proposição.
%%%{{{ meta 
\label defiff_defeq
\defines
    * ~A \defiff ~B -- $A$ tá sendo definida para ser equivalente a $B$
    * ~A \defeq  ~B -- $A$ tá sendo definido para ser igual a $B$
    ;;
%%%}}}

Para enfatisar que estamos definindo algo, e não afirmando uma equivalência
ou uma igualdade, decoramos o símbolo correspondente por um \symq{$\deftag$}:
usamos \sq{$A \defiff B$} para \emph{definir a proposição} $A$ para significar
a mesma coisa com a proposição $B$;
usamos \sq{$A \defeq B$} para \emph{definir o objeto} $A$ como um novo nome
do objeto $B$.
Olhe nisso:
$$
\xalignat2
&\tubrace {\tobrace A {(prop)} \defiff \tobrace B {\phantom(prop\phantom)}} {definição} &
&\tubrace {\tobrace A {prop}   \iff    \tobrace B {prop}} {afirmação}.
\endxalignat
$$
Na \sq{$A \defiff B$} estamos \emph{definindo algo:} a expressão $A$, que vai acabar
tendo o significado da proposição $B$, logo apos dessa definição.
Ou seja, na esquerda do \symq{$\defiffsymbol$} temos uma \dterm{futura-proposição},
na sua direita temos uma proposição mesmo.
Na \sq{$A \iff B$}, estamos \emph{afirmando algo:}
que as proposições $A,B$ são equivalentes.
Necessariamente então ambas já têm significados conhecidos.
Similarmente sobre as
$$
\xalignat2
&\tubrace {\tobrace A {(obj)} \defeq \tobrace B {obj}} {definição} &
&\tubrace {\tobrace A {obj}   =      \tobrace B {obj}} {afirmação}:
\endxalignat
$$
a primeira é uma definição, a segunda a afirmação que $A,B$ são iguais.

%%}}}

%%{{{ eg: with_and_without_def 
\example.
%%%{{{ meta 
%%%}}}

Qual a diferença entre as duas expressões?:
$$
\align
\text{$n$ é ímpar} &\defiff \text{$n = 2k + 1$ para algum inteiro $k$}\\
\text{$n$ é ímpar} &\iff    \text{$n = 2k + 1$ para algum inteiro $k$}
\endalign
$$

\solution.
A primeira linha \emph{é uma definição}.
Estamos \emph{definindo} o que significa \wq{ser ímpar},
dizendo como traduzir a afirmação \wq{$n$ é ímpar} para uma
outra afirmação que supostamente entendemos.
A segunda linha \emph{é uma afirmação}:
afirma que as duas proposições nos seus lados são equivalentes.
Ou seja, é algo que pode ser demonstrado ou refutado.
E para usar o \symq{$\iffsymbol$} com certeza seus dois lados precisam ser
proposições bem-definidas.

%%}}}

%%{{{ remark: conventions_with_defs 
\remark Convenções.
%%%{{{ meta 
\label conventions_with_defs
%%%}}}

Essa ênfase com o \symq{$\deftag$} não é obrigatória, e muitas vezes
o contexto é suficiente para deixar claro que se trata de definição
e não de afirmação.
Note que por convenção a coisa sendo definida vai no lado esquerdo
do símbolo que decoramos com esse \symq{$\deftag$} e a sua definição
fica no lado direito.
Então mesmo que nos símbolos \symq{$=$} e \symq{$\iffsymbol$} podemos
trocar seus lados, nos \symq{$\defeq$} e \symq{$\defiffsymbol$} não!

%%}}}

%%{{{ examples_and_nonexamples 
\note Exemplos e nãœxemplos.
%%%{{{ meta 
\label examples_and_nonexamples
\defines
    * exemplo
    * nãœxemplo
    ;;
%%%}}}

Talvez já temos vários \dterm{exemplos} de objetos que satisfazem nossa
definição, ou nem sabemos se existem tais objetos!  Observe então que
para definir algo não é necessário---e com certeza nem suficiente!---mostrar
exemplos de objetos.
Mesmo assim, quando escrevemos um texto matemático e queremos ajudar nosso
leitor confirmar seu entendimento da nossa definição, podemos dar uns
exemplos e/ou uns \dterm{nãœxemplos} (ou seja, objetos que \emph{não}
satisfazem nossa definição).
Mas é importante entender que a natureza deles nunca é essencial
para a definição, e que \emph{eles não fazem parte da definição}.
É apenas uma ferramenta pedagógica.

%%}}}

%%{{{ eg: examples_and_nonexamples_example
\example.
%%%{{{ meta 
\label examples_and_nonexamples_example
%%%}}}

As afirmações seguintes são todas corretas:
\tlist:
\li: $41$ é um exemplo de: número ímpar\foot
sim, acabei de usar a palavra exemplo para
dar um exemplo para ajudar entender o que
significa exemplo
\toof
\li: $18$ é um exemplo de: múltiplo de $3$
\li: $16$ é um nãœxemplo de: múltiplo de $3$
\li: $16$ é um nãœxemplo de: número ímpar
\endtlist
Mas não contam como definição do que significa ser ímpar,
ou ser múltiplo de $3$.

%%}}}

%%{{{ beware: nonexample_vs_counterexample 
\beware nãœxemplo \vs contraexemplo.
%%%{{{ meta 
\label nonexample_vs_counterexample
\defines
    * contraexemplo
    ;;
%%%}}}

Não confunda as palavras \wq{nãœxemplo} e \wq{contraexemplo}.
Um \dterm{nãœxemplo} é algo que \emph{não} satisfaz uma definição,
que não tem uma propriedade, etc.
No outro lado, quando usamos o termo \dterm{contraexemplo}?
Apenas quando estamos tentando \emph{refutar} uma afirmação da forma
\wq{todos os tais $x$ têm tal propriedade}.
Qualquer tal objeto $x$ que não possui essa propriedade
conta como contraexemplo dessa afirmação.
Isso vai ficar mais claro na~\ref[Examples_and_counterexamples]
do~\ref[Proofs] (onde estudamos demonstrações).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Dando uma definição de algum termo, notação, etc., precisamos deixar claro
o que exatamente eles denotam.
Considere como exemplo a noção de \emph{primos gêmeos} que aparece em
teoria dos números:

%%}}}

%%{{{ eg: eg_def_of_twin_primes 
\example.
%%%{{{ meta 
\label eg_def_of_twin_primes
%%%}}}

Considere a definição:
\quote
\wq{Dois números $p,q$ são \dterm{primos gêmeos} sse
$p,q$ são primos e $\abs{p-q} = 2$.}
\endquote
Dados então dois números $a,b$, sabemos o que a afirmação
``$a,b$ são primos gêmeos''
significa:
$$
\text{$a,b$ são primos e $\abs{p-q} = 2$}.
$$

%%}}}

%%{{{ context_of_a_definition 
\note Contexto.
%%%{{{ meta 
\label context_of_a_definition
%%%}}}

Para definir qualquer coisa precisamos primeiramente deixar claro o
\dterm{contexto}.  No~\ref[eg_def_of_twin_primes] o contexto é:
$$
\align
p &\eqtype \text{número} \\
q &\eqtype \text{número}.
\intertext{No outro lado, se a definição fosse <<dois números primos $p,q$ são \dterm{primos gêmeos} sse $\abs{p-q} = 2$>> o contexto seria pouco diferente:}
p &\eqtype \text{número primo} \\
q &\eqtype \text{número primo}.
\endalign
$$

%%}}}

%%{{{ what_is_tijolo 
\note O que é tijolo?.
%%%{{{ meta 
\label what_is_tijolo
%%%}}}

No meu primeiro semestre como professor no Brasil, em algum momento---%
não lembro porquê---um aluno na sua explicação usou a palavra ``tijolo''.
O problema é, que eu nunca tinha encontrado essa palavra antes; então
perguntei ao meu aluno:
\spoken
\wq{O que é tijolo?}
\endspoken
Neste momento o aluno sentiu um desafio:
como você explica o que é um tijolo para um gringo?\foot
O aluno não falava inglês---nem grego!---e logo a gente não tinha
uma linguagem ``fallback'' para usá-la e tirar minha dúvida.
\toof
Ele precisou dar uma \emph{definição} dessa palavra.
A resposta dele foi
\spoken
\wq{Tijolo é tijolo, ué!}
\endspoken
\dots E isso não me ajudou muito.

%%}}}

%%{{{ Circular definition 
\note Definições circulares.
%%%{{{ meta 
\indexes
    * tijolo    see: tijolo
    ;;
\defines
    * definição circular
    ;;
%%%}}}

A resposta do aluno acima é um exemplo duma \dterm{definição circular}.
$$
\tikzpicture
\node (word) at (0,0) {tijolo};
\draw[-Latex] (word.-45) arc (-150:150:6mm);
\endtikzpicture
$$
Tenho então uma questão pra ti:
\spoken
\wq{O que é um conjunto?}
\endspoken
Uma resposta razoável neste momento seria a seguinte:
\spoken
\wq{Um conjunto é uma colecção de objetos.}
\endspoken
E, se eu sei o que significa ``colecção'' eu vou entender
o que é um conjunto e vou ficar feliz; mas caso contrário, eu vou perguntar:
\spoken
\wq{E o que é uma colecção?}
\endspoken
Provavelmente aquele aluno que me ensinou o que é ``tijolo'' ia responder:
\spoken
\wq{Uma colecção é um conjunto de objetos.}
\endspoken
Aqui o problema é o mesmo com o ``tijolo'', só que um tiquinho menos óbvio,
pois o cíclo aqui pelo menos tem duas setinhas:
$$
\tikzpicture
\node[inner sep=2pt, outer sep=2pt] (word1) at (-1,0) {conjunto};
\node[inner sep=2pt, outer sep=2pt] (word2) at (1,0)  {colecção};
\draw (word1) edge[out=315,in=225,-Latex] (word2);
\draw (word2) edge[out=135,in=45, -Latex] (word1);
\endtikzpicture
$$
Pensando numa forma computacional, entendemos essa definição como um
programa cuja execução caiu num \emph{loop infinito}.
Como ele nunca termina, nos nunca sabemos se um objeto satisfaz
ou não essa definição.

%}}}

%%{{{ teaser: recursive_definitions_teaser 
\teaser Definições recursivas.
%%%{{{ meta 
\label recursive_definitions_teaser
%%%}}}

Alguém pode pensar que o problema com as definições circulares é que a palavra
que estamos definindo apareceu na sua própria definição.
Isso \emph{não} é o caso!
Numa \dterm{definição recursiva} a palavra que queremos definir parece aparacer
dentro da sua própria definição, e mesmo assim, não estamos caindo num loop infinito,
e realmente conseguimos definir o que queremos.
Mas bora deixar esse assunto para depois, quando com pouco mais experiência
vamos trabalhar com recursão.

%%}}}

%%{{{ Errors in definitions 
\note Erros em definições.
%%%{{{ meta 
%%%}}}

Pode ser que para algum erro uma suposta definição acaba não definindo
nada pois seu texto não conseguiu descrever nenhum conceito.
Ou, pode ser que acabou definindo algo mesmo, só que esse algo não é
o que queriamos definir!

%%}}}

%%{{{ eg: wrong_def_par_that_does_not_compile 
\example definição errada que nem compila.
%%%{{{ meta 
\label wrong_def_par_that_compiles
%%%}}}

Considere a definição seguinte:
\quote
Definição.
Seja $n$ um inteiro.
Chamamos o $n$ de \dterm{par} se e somente se $n = 2k$.
\endquote
Essa definição \emph{nem compila}.
Por quê?

\solution.
O compilador reclamaria com a mensagem
\quote
Usou \symq{$k$} mas \symq{$k$} não está declarado aqui.
\endquote
Para esclarecer mais a situação, vamos testar se $6$ é um número par.
Temos
$$
\text{$6$ é par}
\intiff
\text{6 = 2k}.
$$
Ou seja, basta verificar se realmente $6 \askeq 2k$.
Mas nessa afirmação está sendo referido um objeto $k$ que nunca foi
declarado (nem definido).  \emph{Quem é esse $k$?}
Ninguém sabe, não faz sentido então afirmar nada que envolve $k$.

%%}}}

%%{{{ eg: wrong_def_par_that_compiles 
\example definição errada que compila.
%%%{{{ meta 
\label wrong_def_par_that_compiles
%%%}}}

Considere a definição seguinte:
\quote
Definição.  Seja $n$ um inteiro.  Chamamos o $n$ de \dterm{par} se e somente se
$n = 2k$ para qualquer inteiro $k$.
\endquote
Essa definição ``compila''.
Mas o conceito que foi definido não é o que o seu escritor tinha no coração dele.

%%}}}

%%{{{ x: check_wrong_def_par_that_compiles 
\exercise.
%%%{{{ meta 
\label check_wrong_def_par_that_compiles
%%%}}}

Por quê?
Qual o problema com a definição do~\ref[wrong_def_par_that_compiles]?
Como podemos consertar?

\solution
Essa definição não aceita objetos que deveria aceitar.
Por exemplo, o $2$ não é um número par segundo essa definição,
pois, lembrando:
$$
\text{$6$ é par} \intiff \text{para todo inteiro $k$, $6=2k$}.
$$
Para \emph{refutar} a afirmação que $6$ é par então, basta achar
um inteiro $k$ tal que $6 \neq 2k$.
Tome $k \asseq 1$ e observe que $6 \neq 2\ntimes 1$ e pronto,
o $6$ acabou sendo um número não par!
Para consertar a definição basta trocar o ``para todo''
por ``para algum''!

%%}}}

%%{{{ What is ``well-defined''? 
\note O que é ``bem-definido''?.
%%%{{{ meta 
%%%}}}

Essa frase deixa muita gente confusa em matemática.
Realmente fica estranho pedir para teu leitor demonstrar, por exemplo,
que um tal símbolo, notação, funcção, não foi bem-definida.
Como assim?
Se não foi bem-definida, como que estamos usando sua notação então?
A idéia nesse caso seria explicar exatamente o porquê que o compilador
reclamaria na sua definição.  Em geral, o erro fica na falta de determinicidade:
\emph{fingimos} que determinamos um certo objeto que nomeamos numa certa forma,
mas na verdade deixamos muita liberdade (ambigüidade) no nosso leitor,
pois vários objetos satisfazem essa condição, então nossa descripção \emph{não
determinou} um objeto.  No outro extremo, pode ser que nenhum objeto satisfaz
a condição, então é como se a gente tentou dar nome para algo que nem existe.

%%}}}

%%{{{ The importance of definitions 
\note A importância das definições.
%%%{{{ meta 
%%%}}}

Superficialmente alguém pode pensar que ``não existe definição errada''.
Ficando no pé da letra seria difícil convencer esse alguém que ele não
tem razão.  Mas muitas vezes dando as definições ``certas'' é o que te
permite demonstrar um teorema difícil que seria inatacável sem elas.
Uma definição deve ser escrita na maneira mais simples possível para entender e usar.
E deve capturar um conceito interessante.
Tendo as definições corretas, raciocinamos melhor,
e conseguimos formular nosso pensamento numa forma
curta e entendível.
Com prática, vamos conseguir identificar quando faria sentido definir
um termo novo, dar uma definição elegante e correta, e escolher
um nome bom, e se for útil uma notação conveniente também.

%%}}}

%%{{{ Comparison with programming 
\note Comparação com programação.
%%%{{{ meta 
\defines
    * entry point
    ;;
%%%}}}

Enquanto programando, para muitos programadores a parte mais
desafiadora (e divertida) é \emph{inventar os nomes corretos}\foot
Ou até \emph{descobrir os nomes escondidos},
dependendo do caso e do ponto de vista, para enfatisar!
\toof
para partes dos seus programas.
Em muitas linguagens existe um \dterm{entry point} para teu programa, onde a execução começa.
Por exemplo, em C isso seria o corpo da funcção $\code{main}$.
Seria bizarro (no mínimo) tentar escrever um inteiro programa apenas usando os primitivos da C dentro dessa funcção $\code{main}$.
Felizmente as linguagens oferecem ferraments de abstracção para o programador---umas bem mais que outras---e assim começamos definindo nossos próprios conceitos: funcções, variáveis, constantes, tipos, etc.

%%}}}

\endsection
%%}}}

%%{{{ Intension_vs_extension 
\section Intensão \vs extensão.
%%%{{{ meta 
\label Intension_vs_extension
%%%}}}

%%{{{ intenstion_vs_extension
\note.
%%%{{{ meta 
\defines
    * extensão
    * intensão
    ;;
%%%}}}

Muitas vezes é útil diferenciar entre a intensão e a extensão de expressões que denotam tanto objetos quanto proposições.
Considere a frase \emph{a mãe de Thanos}, que denota a minha mãe mesmo, \emph{Styliani}.
Agora vamos supor para esse exemplo que minha mãe é \emph{a reitora da UFRN}.
Temos três expressões que denotam o mesmo objeto: mainha.
Alguém diria que
$$
{\mathit{a mãe de Thanos}}
\;=\;
{\mathit{a reitora da UFRN}}
\;=\;
{\mathit{Styliani}}.
$$
Realmente a \dterm{extensão} dessas três frase é a mesma.
Mas a \dterm{intensão} é diferente: é outra coisa ser a mãe de Thanos,
outra coisa ser a reitora da UFRN, e outra coisa ser a Styliani.
Para enfatisar que não faz sentido tratar as três frases como \emph{iguais},
considere as frases seguintes:
\quote
\wq{Eu não sabia que a mãe de Thanos é a reitora da UFRN.}\CR
\wq{A mãe de Thanos é Styliani, mas não sei quem é a reitora da UFRN.}
\endquote
Agora, supondo que realmente são iguais essas frases, tente trocar
uma por outra e tu vai descobrir que o significado muda bastante;
uns exemplos:
\quote
\wq{Eu não sabia que Styliani é a mãe de Thanos.}\CR
\wq{Eu não sabia que a mãe de Thanos é a mãe de Thanos.}\CR
\wq{A reitora da UFRN é Styliani, mas não sei quem é a mãe de Thanos.}
\endquote
As extensões são iguais pois todas essas frases denotam o mesmo objeto, mas as intensões não.
Nesse exemplo usei um objeto (Styliani) para explicar a diferença entre igualdade intensional e extensional.
A mesma idéia aplica entre \emph{equivalência} intensional e extensional.
Considere a equivalência entre as proposições que cada uma afirma algo sobre um número $x$:
$$
\text{$x$ é primo e par}
\iff
\text{uma molécula de água tem $x$ átomos de hidrogênio}
\iff
\text{$x = 2$}
$$
Sim, as proposições são equivalentes extensionalmente:
ambas são verdade ou ambas são falsas.
Mas a intensão de cada proposição é bem diferente.
Considere dado um número $x$.
Para decidir se a primeira é verdade precisamos saber
o que significa número primo, o que significa número par,
e também saber responder sobre nosso $x$ se satisfaz ambas
essas definições.
Para a segunda, precisamos saber pouca coisa de química:
$\mathrm H_2\mathrm O$ é a molécula da água.
Finalmente para a terceira não precisamos nenhum conhecimento
(além de reconhecer a constante \symq{$2$} como um nome do número dois),
pois afirma diretamente que $x$ é o número $2$.

%%}}}

%%{{{ notation: intensional_notation 
\notation.
%%%{{{ meta 
\label intensional_notation
\defines
    * ~A = ~B         -- igualdade extensional
    * ~A \iff ~B      -- equivalência extensional
    * ~A \inteq ~B    -- igualdade intensional
    * ~A \intiff ~B   -- equivalência intensional
    ;;
%%%}}}

Em matemática os símbolos \symq{$=$} e \symq{$\iffsymbol$}
são usados na maneira extensional:
\symq{$A = B$} significa que $A$ e $B$ denotam o mesmo objeto;
\symq{$A \iff B$} significa que as proposições $A,B$ são logicamente equivalentes.
Para diferenciar entre intensional e extensional,
adicionamos mais uma linha nos símbolos correspondentes:
usamos \symq{$\inteq$} para igualdade intensional
e \symq{$\intiffsymbol$} para equivalência intensional.

%%}}}

%%{{{ definition_and_intension 
\remark Definição e intensão.
%%%{{{ meta 
\label definition_and_intension
%%%}}}

A partir duma definição
$$
A \defiff B
$$
as expressões $A$ e $B$ não são apenas extensionalmente (logicamente) equivalentes,
mas intensionalmente também: definimos o $A$ para ter o próprio significado (intensão) de $B$.
Então depois da definição acima claro que temos
$$
A \iff B
$$
mas, ainda mais, temos
$$
A \intiff B.
$$
Parece então que em vez de \symq{$\defiffsymbol$} deveriamos decorar
o \symq{$\intiffsymbol$} com o \symq{\deftag}
mas não precisamos fazer isso pois já o fato que é uma definição implica que as expressoes nos
dois lados vão ter até a mesma intensão!\foot
Assim não vamos precisar de escrever \symq{$\defintiffsymbol$}.
\toof
Mesma coisa sobre o \symq{$\defeq$}.

%%}}}

%%{{{ x: intensional_implies_extensional 
\exercise.
%%%{{{ meta 
\label intensional_implies_extensional
%%%}}}

Verdade ou falso?:
\tlist:
\li (i):  se $A \inteq B$ então $A = B$;
\li (ii): se $A \intiff B$ então $A \iff B$.
\endtlist
Observe que para cada uma dessas afirmações fazer sentido
os $A,B$ denotam objetos na primeira, mas proposições na segunda.

%%}}}

%%{{{ x: intensional_vs_extensional_quiz 
\exercise.
%%%{{{ meta 
\label intensional_vs_extensional
\pdefs
    \pdef phrases ####1####2{$\left\{\aligned &####1 \\ &####2 \endaligned\right.$}
    ;;
%%%}}}

Para cada um par de expressões escolhe a melhor opção dos:
$$
\intiffsymbol, \quad
\iffsymbol, \quad
{\inteq}, \quad
{=}.
$$
Observe que as versões intensionais são mais fortes que as extensionais,
então quando aplica a versão intensional, precisa escolhé-la.
\elist 1:listoula
\cdhere
\li:six
\phrases
    {2 \ntimes 3}
    {6}
\li:twothree
\phrases
    {2 \ntimes 3}
    {3 \ntimes 2}
\li:love
\phrases
    {\text{$x$ ama $y$}}
    {\text{$y$ é amado por $x$}}
\li:even
\phrases
    {\text{$n$ é par}}
    {\text{existe $k \in \ints$ tal que $n = 2k$}}
\li:matheus
\phrases
    {\text{Matheus mora na capital do RN}}
    {\text{Matheus mora na maior cidade do RN}}
\li:athens
\phrases
    {\text{a capital da Grécia}}
    {\text{Aténas}}
\li:sarcofago
\phrases
    {\text{o vocalista da banda Sarcófago é professor da UFMG}}
    {\text{Wagner Moura é professor da maior universidade de MG}}
\li:aristoteles
\phrases
    {\text{Aristoteles foi professor de Alexandre o Grande}}
    {\text{Aristoteles ensinou Alexandre o Grande}}
\li:cheese
\phrases
    {\text{A terra é plana}}
    {\text{A lua é feita de queijo}}
\li:zeros
\phrases
    {x^2 + y^2 \leq 0}
    {x = y = 0}
\li:squares
\phrases
    {x^2 + y^2 \leq 0}
    {0 \geq x \ntimes x + y \ntimes y}
\li:manysquares
\phrases
    {(x^2 + y^2)^2}
    {(x\ntimes x + y^2)(x^2 + y \ntimes y)}
\endelist

\solution
\refcd intensional_vs_extensional
Temos:
\tlist:
\li: \symq{$\intiffsymbol$} para os pares:
     \refnear[love], \refnear[even], \refnear[aristoteles], \refnear[squares];
\li: \symq{$\iffsymbol$} para os pares:
     \refnear[matheus], \refnear[sarcofago], \refnear[cheese], \refnear[zeros];
\li: \symq{${\inteq}$} para o par
     \refnear[manysquares];
\li: \symq{${=}$} para os pares:
     \refnear[six], \refnear[twothree], \refnear[athens].
\endtlist
Aqui considerei que elevar um número ao 2 \emph{significa} multiplicar
o número por ele mesmo.
Caso que considerou exponenciação como operação primitiva e não definida
em termos da multiplicação, seria correto mudar as~\refnear[squares]
e~\refnear[manysquares] de intensional para extensional.

%%}}}

\endsection

%%}}}

%%{{{ Variables 
\section Variáveis.
%%%{{{ meta 
\label Variables
%%%}}}

%%{{{ intro 
\secintro
Vamos estudar variáveis e seus usos depois
(especialmente no~\ref[Lambda_calculus], mas também nos
\reftag[Functional_programming], \reftag[Logic_programming],
\reftag[Mathematical_logic], \dots).
Por enquanto precisas só entender o básico.
Esta secção, é esse básico.
%%}}}

%%{{{ from_pronouns_to_variables 
\note De pronomes para variáveis.
%%%{{{ meta 
\label from_pronouns_to_variables
\defines
    * variável
    ;;
%%%}}}

Considere as proposições:
\tlist:
\li (i):   \wq{Existe número tal que ele é múltiplo de todos os números.}
\li (ii):  \wq{Para todo país, existe cidade tal que ela fica perto da fronteira dele.}
\li (iii): \wq{Para toda pessoa, existe pessoa tal que ela a ama.}
\endtlist
aqui usamos os pronomes \sq{ele}, \sq{ela}, \sq{a},
para referir a algum objeto que foi ``introduzido''
a partir dos \wq{existe} e \wq{para todo}.
Na segunda frase graças à coincidência que temos em português onde
a palavra \sq{país} é masculina, e a \sq{cidade} feminina, não
existe confusão: \sq{ele} refere ao país, e \sq{ela} refere à cidade.
No outro lado, na última frase não é claro a que as
palavras \sq{ela} e \sq{a} referem.
Usando variáveis escrevemos as primeiras duas assim:
\tlist:
\li (i):   \wq{Existe número $n$ tal que $n$ é múltiplo de todos os números.}
\li (ii):  \wq{Para todo país $p$, existe cidade $c$ tal que $c$ fica perto da fronteira de $p$.}
\endtlist
Agora olha na terceira frase.
Temos duas razoáveis maneiras de interpretá-la, dependendo de
a que cada pronome refere:
\tlist:
\li (iii)${}_1$: \wq{Para toda pessoa $x$, existe pessoa $y$ tal que $x$ ama $y$.}
\li (iii)${}_2$: \wq{Para toda pessoa $x$, existe pessoa $y$ tal que $y$ ama $x$.}
\endtlist
Observe que os significiados são bem diferentes:
\tlist:
\li (iii)${}_1$: \wq{Toda pessoa ama.}
\li (iii)${}_2$: \wq{Toda pessoa é amada.}
\endtlist
Ou seja, a frase (iii) não tem um significado bem determinado e sendo ambígua não podemos usá-la.

%%}}}

%%{{{ variable_instance 
\note Instância de variável.
%%%{{{ meta 
\label variable_instance
\defines
    * variável!instância
    ;;
%%%}}}

Numa frase que envolve variáveis é muito importante poder separar
(e falar sobre) cada \dterm{instância} de variável na frase.
Na frase seguinte por exemplo, temos $4$~instâncias da variável
$p$ e $2$~da variável $q$.
$$
\textwq{$\undertag p 1$ é primo e para todo primo $\undertag p 2$ tal que $\undertag p 3$ divide $\undertag q 1$, $\undertag p 4^2$ divides $\undertag q 2$}
$$
Sublinhei e rotulei todas.
Mesmo sem isso, alguém poderia falar da
\wq{terceira instância da variável $p$} e entenderiamos qual seria.

%%}}}

%%{{{ x: typecheck_warmup 
\exercise typecheck warmup.
%%%{{{ meta 
\label typecheck_warmup
%%%}}}

Considere as expressões:
% TODO: fix reflabs
\elist a:
\eachitem expression
\li: $(x + y)^2 = x^2 + 2xy$;
\li:motherof a mãe de $p$;
\li: $2^n + 1$;
\li: $p$ é irmão de $q$;
\li: a capital do país $p$;
\li: $a$ mora em Atenas.
\endelist
Para cada uma decida se ela denota objeto ou proposição.

\solution
\context tt
\x $(x + y)^2 = x^2 + 2xy$ : proposição ; \\
\x a mãe de $p$            : objeto     ; \\
\x $2^n + 1$               : objeto     ; \\
\x $p$ é irmão de $q$      : proposição ; \\
\x a capital do país $p$   : objeto     ; \\
\x $a$ mora em Atenas      : proposição ; \\
\endcontext

%%}}}

%%{{{ variables_free_and_bound 
\note Variáveis livres e ligadas.
%%%{{{ meta 
\label variables_free_and_bound
\indexes
    * capturada    see: variável
    * dummy    see: variável ligada
    ;;
\defines
    * variável!ligada
    * variável!livre
    ;;
%%%}}}

Cada uma das expressões da~\ref[typecheck_warmup] refere a pelo
menos uma coisa por meio de variáveis, e logo seu significado é dependente
(dessas variáveis).
Essas \emph{instâncias de variáveis} chamamos de \dterm{livres}.
Sobre as expressões que denotam proposições:
não sabemos o que cada uma afirma sem saber quais são
os objetos denotados por essas variáveis;
similarmente sobre as expressões que denotam objetos:
não sabemos qual objeto é denotado sem saber quais são
os objetos denotados por essas variáveis.
Agora considere as expressões:
\elist 1:
\li: existe $k \in \ints$ tal que $13 = 2k + 1$;
\li: existem números $x,y$ tais que $(x + y)^2 = x^2 + 2xy$;
\li: aquela funcção que dada um número $x$ retorna o $x+1$;
\li: o conjunto de todos livros $b$ tais que existe palavra $w$ no $b$ com tantas letras quantas as letras do título de $b$;
\li: para toda pessoa $p$, a pessoa $w$ não gosta de $p$.
\endelist
Aqui as instâncias das variáveis são todas \dterm{ligadas},
exceto na última frase onde ambas as instâncias da variável $p$
são ligadas, mas (a única instância de) $q$ é livre.\foot
Na literatura aparece como sinônimo de variável ligada
o termo \dterm{dummy} (boba) também.
\toof

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Precisamos entender \emph{muito bem} essa idéia de variáveis
ligadas e livres, mas antes de continuar com isso\dots

%%}}}

%%{{{ x: typecheck spinoff exercise 
\exercise.
%%%{{{ meta 
%%%}}}

Para cada uma das cinco expressões do~\reftag[variables_free_and_bound]:
objeto ou proposição?

\solution
(1) proposição;
(2) proposição;
(3) objeto;
(4) objeto;
(5) proposição.

%%}}}

%%{{{ advice: how_to_tell_if_variable_is_free 
\advice.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free
%%%}}}

Para saber se uma variável \sq{$x$} aparece livre numa expressão,
tente enunciar umao mesmo significado da expressão sem pronunciar
\utter{x}.
Se conseguir, a variável é ligada.
Por exemplo, a frase (5) do~\reftag[variables_free_and_bound]
afirma que \wq{$w$ não gosta de ninguém}.

%%}}}

%%{{{ x: how_to_tell_if_variable_is_free_exercise_1 
\exercise.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free_exercise_1
%%%}}}

Enuncie cada uma das (1)--(4)
% TODO: fix reflabs
do~\reftag[variables_free_and_bound]
sem pronunciar nenhuma das variáveis ligadas que aparecem.

\solution
(1) existe número inteiro tal que seu dobro mais um é igual ao $13$;
(2) existem dois números inteiros tais que sua soma quadrada é igual à soma
do quadrado do primeiro e do dobro do produto do primeiro com o segundo;
$(x + y)^2 = x^2 + 2xy$;
(3) aquela funcção que dada um número retorna a soma desse número com o $1$;
(4) o conjunto de todos livros em quais aparece palavra com tantas letras quantas as letras do título do próprio livro.
\eop
(Se enunciou a (1) com a simples \wq{$13$ é ímpar} tá tudo OK; vamos voltar
a discutir questões de paridade (par, ímpar, etc.) no~\ref[Proofs].)

%%}}}

%%{{{ x: how_to_tell_if_variable_is_free_exercise_2 
\exercise.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free_exercise_2
%%%}}}

Mesma coisa sobre as frases seguintes:
\elist 1:
\li: existem pessoas $p,q$ tais que $p$ ama $q$ e $q$ ama $p$;
\li: existe pessoa $p$ tal que $p$ ama $q$ e $q$ ama $p$;
\li: $x+y = z$;
\li: existe número $x$ tal que $x+y = z$;
\li: existem números $x,z$ tais que $x+y = z$;
\li: para todo número $y$, existe número $x$ tal que $x+y=z$;
\li: para quaisquer números $y,z$, existe número $x$ tal que $x+y=z$.
\endelist

\solution
\elist 1:
\li: existem pessoas que se amam mutalmente;
\li: existe pessoa que ama e é amada pela pessoa $q$;
\li: $x + y = z$;
\li: existe número tal que sua soma com $x$ é igual ao $z$;
\li: existem números tais que somando $y$ num deles resulta no outro;
\li: para qualquer número, existe número tal que a soma com o primeiro é igual ao $z$;
\li: para quaisquer dois números, existe número cuja soma com o primeiro é igual ao segundo.
\endelist

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver agora a mesma idéia no contexto de programação:

%%}}}

%%{{{ eg: freeboundvars_c 
\example.
%%%{{{ meta 
\label freeboundvars_c
%%%}}}

Considere o código seguinte:
\sourcecode freeboundvars.c;
A $\code{i}$ da primeira linha é livre, e nas suas outras instâncias ligada;
a $\code{w}$ é livre em todo canto.

%%}}}

%%{{{ remark: variable_vs_instance_abuse 
\remark.
%%%{{{ meta 
\label variable_vs_instance_abuse
%%%}}}

Quando não existe possibilidade de confundir,
falamos apenas de \wq{variável} em vez de \wq{tal instância de variável}.
Assim, mesmo que ser livre ou ligada não é uma propriedade de variáveis
mas de instâncias de variáveis, nos permitimos o abuso de usar frases
como \wq{$x$ é ligada}, etc.

%%}}}

%%{{{ beware: variable_both_bound_and_free 
\beware.
%%%{{{ meta 
\label variable_both_bound_and_free
%%%}}}

Numa frase, a mesma variável pode ter instâncias livres e ligadas também!
Olha por exemplo a frase do~\ref[variable_instance].
A primeira instância da $p$ é livre, mas todas as outras são ligadas!

%%}}}

%%{{{ variable_assignment 
\note Atribuição e substituição.
%%%{{{ meta 
\label variable_assignment
\pdefs
    \pdef Amanda {\mathrm{Amanda}}
    \pdef Larry  {\mathrm{Larry}}
    ;;
%%%}}}

Quando queremos \dterm{substituir} uma variável por um
outro termo, ou \dterm{atribuir} um valor a uma variável,
para evitar o uso do símbolo da igualdade
\symq{$=$} e escrever frases como \wq{para $n=1$ temos\dots}
usamos o símbolo \symq{$\asseq$}: \wq{para $n\asseq 1$ temos\dots}.
A idéia é que a expressão na esquerda é para assumir o valor
determinado pela direita.
Escrevemos, por exemplo:
\tlist:
\li: A proposição (5) do~\reftag[variables_free_and_bound] com $q \asseq \Larry$ é a proposição que a Larry não gosta de ninguém.
\li: \emph{Usando} a (5) do~\reftag[variables_free_and_bound] para $p \asseq \Amanda$ \emph{inferimos} que a pessoa $q$ não gosta de Amanda.
\endtlist
Naturalmente, usamos o \symq{$\eqass$} nas raras vezes que
queremos inverter os papeis da esquerda e da direita.
Caso que a variável que estamos substituindo é uma variavel
proposiçional (ou seja, serve para denotar proposições
e não objetos) usamos os \symq{$\assiff$} e \symq{$\iffass$}.

%%}}}

%%{{{ variable_renaming 
\note Renomeamento.
%%%{{{ meta 
\label variable_renaming
%%%}}}

Considere o texto seguinte:
$$
\textwq{Existe número $x$ tal que $x^2 = k$.}
$$
A variável \symq{$x$} \emph{sendo ligada} pode ser renomeada
por outra, por exemplo, a \symq{$n$}, sem mudar o significado
da proposição:
$$
\textwq{Existe número $n$ tal que $n^2 = k$.}
$$
No outro lado, não podemos renomear a \symq{$k$},
pois ela é livre, e logo o singificado da proposição
mudaria, pois em vez de ser uma afirmação sobre
um certo objeto $k$, viraria uma afirmação sobre
outra coisa.
O processo de (re)nomear variáveis tem certos perigos,
então precisamos tomar cuidado.
Vamos analizar:

%%}}}

%%{{{ variable_capturing_and_shadowing 
\note Capturamento e sombreamento de variável.
%%%{{{ meta 
\label variable_capturing_and_shadowing
\defines
    * variável!capturada
    * variável!fresca
    * variável!sombreamento
    ;;
%%%}}}

Leia o texto seguinte:
\quote
\flwq{Seja $p$ a maior potência de $2$ que divide o $x$.\CR
Qualquer número que divide $p$, também divide $x$.}
\endquote
Aqui conseguimos evitar o uso de variável na segunda linha para referir
nesse número que divide o $d$.
Realmente ficou sem ambigüidade o texto, então realmente não necessitamos.
Mas se quisermos usar, podemos usar qualquer uma?
Não sempre!
Precisamos tomar cuidado.
Vamos tentar usar uma \dterm{variável fresca}, ou seja,
uma variável que não temos usado ainda:
\quote
\flwq{Seja $p$ a maior potência de $2$ que divide o $x$.\CR
Para todo número $d$, se $d$ divide $p$, então $d$ divide $x$.}
\endquote
Primeiramente confirme que \emph{nada mudou no significado} do texto.
Usamos a variável \symq{$d$} para referir ao divisor arbitrário de $p$.
Essa (usar uma variável fresca) seria a melhor e mais segura escolha aqui.
Mas, o que acontece se usar, por exemplo, a \symq{$x$}?
Vamos ver:
\quote
\flwq{Seja $p$ a maior potência de $2$ que divide o $x$.\CR
Para todo número $x$, se $d$ divide $x$, então $d$ divide $x$.}
\endquote
Acabou de acontecer sombreamento e capturamento.
Para explicar vou pintar as variáveis no texto anterior onde usamos \symq{$d$}:
\quote
\flwq{Seja $\aG p$ a maior potência de $2$ que divide o $\aR x$.\CR
Para todo número $\aB d$, se $\aB d$ divide $\aG p$, então $\aB d$ divide $\aR x$.}
\endquote
e no novo, onde usamos a \symq{$x$}:
\quote
\flwq{Seja $\aG p$ a maior potência de $2$ que divide o $\aR x$.\CR
Para todo número $\aB x$, se $\aB x$ divide $\aG p$, então $\aB x$ divide $\aB x$.}
\endquote
A partir da frase <<Para todo número $\aB x$>>,
o $\aR x$ da linha anterior não tem mais como ser referido
até o fim desse escopo, nesse caso até o ponto final da linha.
Aconteceu \dterm{sombreamento} (\dterm{shadowing}) da variável
$\aR x$ nesse escopo.
Dizemos também que a variável $\aR x$ da segunda linha da versão anterior,
foi \dterm{capturada} pela frase sublinhada, ou seja, virou azul.

%%}}}

%%{{{ eg: shadowing_c 
\example.
%%%{{{ meta 
\label shadowing_c
%%%}}}

Para os programadores, aqui um exemplo de código e uma análise relevante:
\sourcecode shadowing.c;
Nas linhas 12--14 aconteceu sombreamento da $\code{i}$ que foi declarada
na linha 2, por causa do $\code{for}$.
Esse $\code{for}$ capturou a $\code{i}$ que aparece na linha 13.
Ainda mais, a variável $\code{a}$ declarada na linha 1 foi sombreada
no escopo ta funcção $\code{foo}$ pois escolhemos usar o mesmo nome
para segunda parámetro da funcção $\code{foo}$, e logo qualquer
instância de $\code{a}$ no corpo da $\code{foo}$ refere ao segundo
argumento da funcção, e não à $\code{a}$ da linha 1.
Assim, dentro do corpo da funcção não temos mais como referir à $\code{a}$.

%%}}}

%%{{{ binders_and_their_bindings 
\note Ligadores de variáveis e suas ligações.
%%%{{{ meta 
\label binders_and_their_bindings
\defines
    * ligador!de variável
    ;;
%%%}}}

Já encontramos dois \dterm{ligadores (binders) de variáveis}:
\wq{existe {\thole} tal que \dots}
e
\wq{para todo {\thole}, \dots}.
Tem muito mais que esses dois, e provavelmente o leitor já enconctrou vários
em matemática, programação, ou na vida mesmo~(\ref[find_more_binders]).
Para entender melhor que onde aparecem variáveis ligadas não está sendo
afirmado algo sobre certos objetos denotados por essas variáveis, podemos
desenhar explicitamente as ligações.
É melhor pensar que uma proposição \emph{é} sua forma com ligações,
assim a desvinculando das escolhas de nome de variáveis insignificantes
que seu escritor favoreceu.
Espero que isso fica mais claro depois do exemplo seguinte:

%%}}}

%%{{{ eg: free_and_bound_variables_eg 
\example.
%%%{{{ meta 
\label free_and_bound_variables_eg
%%%}}}

Considere a proposição
$$
\text{\tenrm $n-d$ e $n+d$ são primos}. \tag{1}
$$
Sem sequer saber o que significa ser um número primo,
sabemos que essa proposição afirma que dois números (o $n-d$ e o $n+d$) possuem essa propriedade (misteriosa de ser primo).
Aparecem as variáveis \sq{$n$} e \sq{$d$}, e em todas as suas instâncias são livres.
Ou seja, a proposição (1) pode ser vista como uma afirmação sobre dois números $n$ e $d$.
Podemos \emph{quantificiar} uma ou ambas delas, por um dos quantificadores que discutimos:
$$
\text{\tenrm existe $d$ tal que $n-d$ e $n+d$ são primos}. \tag{2}
$$
Aqui todas as instâncias da $n$ são ligadas (com o ligador \wq{existe $n$ tal que \dots}).
Ou seja, a proposição (2) afirma algo sobre um certo número $d$.
Ela não fala nada sobre $n$.  Podemos pronunciá-la sem dizer \utter{n}:
\emph{\wq{Existe numero que tanto subtraindo ele de $n$, quanto somando ele com $n$, resulta em números primos.}}.
Mas não sem dizer \wq{n}.
Podemos desenhar as ligações da~(2) para esclarecer:
\Tikzi varbindings2;
Voltando na (1) podemos quantificar a outra variável:
$$
\text{\tenrm existe $n$ tal que $n-d$ e $n+d$ são primos}. \tag{3}
$$
Agora $d$ é livre e $n$ ligada, ou seja (3) afirma algo sobre um certo número $d$, e nada sobre nenhum $n$.
Podemos pronunciá-la sem dizer \utter{d}:
\utter{Existe numero que tanto subtraindo $d$ dele,
quanto somando $d$ nele, resulta em números primos.}.
Mas não sem dizer \utter{d}.
Deixo os desenhos de ligações pra ti (\ref[bindings_exercise]).
Observe que os significados das (2) e (3) são bem diferentes:
\tlist:
\li: Na (3) o $d$ é fixo (podemos pensar o $d$ como distância) e procuramos $n$ com essa propriedade.
Parece que fixamos nossos dedos numa distância $2d$ ($d$ pela esquerda e $d$ pela direita) e procuramos
achar se existe $n$ no meio tal que ambos os nossos dedos apontam para primos.
\li: Na (2) o $n$ é fixo (podemos pensar o $n$ como o centro da nossa busca) e ficamos estendendo mais e mais
os dedos (com distâncias iguais do centro) até encontrar (se encontrar) uma certa distância $d$ tal que
(novamente) ambos os nossos dedos apontam para primos.
\endtlist
Agora, volte na (2) e considere a proposição
$$
\text{\tenrm para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos}. \tag{4}
$$
que obtemos botando esse
\wq{\trueR{para todo $n$, se $n \geq N$ então}}
na frente da (2).
Aconteceu o seguinte:
\Tikzi varbindings4;
Essa então é uma afirmação sobre um certo número $N$.
Quantificando \sq{$N$} também, podemos chegar na:
$$
\text{\tenrm existe $N$ tal que para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos} \tag{5}
$$
Te deixo desenhar suas ligações (\ref[bindings_exercise]).

%%}}}

%%{{{ x: bindings_exercise 
\exercise.
%%%{{{ meta 
\label bindings_exercise
%%%}}}

Desenha as ligações da (3) e (5) do~\ref[free_and_bound_variables_eg].

\solution
A proposição (3) escrita com variáveis
$$
\text{\tenrm existe $n$ tal que $n-d$ e $n+d$ são primos} \tag{3}
$$
e agora com ligações:
\Tikzi varbindings3;
A proposição (5) escrita com variáveis:
$$
\text{\tenrm existe $N$ tal que para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos} \tag{5}
$$
e agora com ligações:
\Tikzi varbindings5;

%%}}}

%%{{{ x: find_more_binders 
\exercise.
%%%{{{ meta 
\label find_more_binders
%%%}}}

Já encontramos dois ligadores
\wq{existe {\thole} tal que \dots}
e
\wq{para todo {\thole}, \dots}.
Dê mais exemplos de ligadores que tu conhece:
de matemática, de programação, de vida\dots

%%}}}

%%{{{ x: renaming_trick_question 
\exercise.
%%%{{{ meta 
\label renaming_trick_question
%%%}}}

Na (3) do~\ref[free_and_bound_variables_eg]
podemos renomiar a variável\dots:
% TODO: fix reflabs
\tlist:
\li (i):    \sq{$n$} por \sq{$m$}?
\li (ii):   \sq{$n$} por \sq{$d$}?
\li (iii):  \sq{$d$} por \sq{$x$}?
\endtlist
Na (5) do~\ref[free_and_bound_variables_eg]
podemos renomiar a variável\dots:
% TODO: fix reflabs
\tlist:
\li (i):    \sq{$N$} por \sq{$n$}?
\li (ii):   \sq{$N$} por \sq{$d$}?
\li (iii):  \sq{$n$} por \sq{$N$}?
\li (iv):   \sq{$n$} por \sq{$d$}?
\li (v):    \sq{$d$} por \sq{$n$}?
\li (vi):   \sq{$d$} por \sq{$N$}?
\endtlist
Cuidado!

\solution
Na (3):
(i) sim, pois $m$ não aparece livre no escopo e assim não vai acontecer
capturamento de variável não-desejado;
(ii) não, pois não seria mais a mesma afirmação sobre o $d$;
(iii) não, pois não seria mais uma afirmação sobre o $d$, mas sobre o $x$.
\eop
Na (5):
(i) não, pois teriamos sombreamento do antigo \sq{$N$} e precisamos referi-lo;
(ii) sim---mesmo que fica esquisito!---pois o sombreamento acontece num escopo onde não precisamos referir mais o antigo \sq{$N$};
(iii) não, pois teriamos sombreamento do antigo \sq{$N$} e precisamos referi-lo;
(iv) não, pois teriamos sombreamento do antigo \sq{$n$} que tá sendo referido depois;
(v) não: mesmo problema com o (iv);
(vi) sim: mesma situação com o (ii).

%%}}}

%%{{{ beware: variables_do_not_vary 
\beware.
%%%{{{ meta 
\label variables_do_not_vary
%%%}}}

Em matemática---pelo incrível que parece---uma variável
não\dots varia!  Ela denota um objeto especifico
e pronto, não pode mudar depois duns minutos para denotar
algo diferente, nem mudar no mesmo escopo da mesma expressão
como acontece por exemplo com o que
chamamos de ``variáveis'' em programação imperativa.
Encontrando então a expressão \sq{$f(x) + x$}, não tem
como as duas instâncias de \symq{$x$} denotar objetos
diferentes.

%%}}}

%%{{{ used_but_unused_variables_phrases 
\note.
%%%{{{ meta 
\label used_but_unused_variables_phrases
%%%}}}

Antes de fechar nossa discução sobre variáveis tenho
uma última coisa para expôr.
Considere as frases:
% TODO: fix reflabs
\elist 1:
\li: todo inteiro $x$ divide ele mesmo;
\li: existe número $n$ tal que ele é primo e par;
\li: qualquer conjunto $A$ é determinado por seus membros;
\li: não existe país $P$ tal que a pessoa $p$ não viajou para esse país;
\li: para todo filme $f$ na lista $F$, existe pessoa $p$ nesse quarto tal que $p$ assistiu esse filme.
\endelist
E agora\dots

%%}}}

%%{{{ Q: what is the problem with those phrases? 
\question.
%%%{{{ meta 
%%%}}}

Qual o problema com elas?

%%}}}

\spoiler

%%{{{ used_but_unused_variables 
\beware variáveis inúteis.
%%%{{{ meta 
%%%}}}

Cada uma dessas frases usa pelo menos uma variável ligada
numa maneira completamente inútil: a frase introduza uma
variável para denotar algo, mas nunca usa essa variável
mesmo para referir a esse algo!  Acaba usando pronomes.
\emph{Nunca introduza uma variável se não pretende usá-la mesmo!}
Aqui as mesmas frases, essa vez sem as variáveis inúteis:
% TODO: fix reflabs
\elist 1:
\li: todo inteiro divide ele mesmo;
\li: existe número (tal que ele é) primo e par;
\li: qualquer conjunto é determinado por seus membros;
\li: não existe país tal que a pessoa $p$ não viajou para esse país;
\li: para todo filme na lista $F$, existe pessoa $p$ no quarto $q$ tal que $p$ assistiu esse filme.
\endelist
Observe que na última frase podemos nos livrar da variável \sq{$p$} também
já que ela é ligada.\foot
Assim:
\wq{alguém no quarto $q$ assistiu todos os filmes que estão na lista $F$}.
\toof
Mas pelo menos ela foi usada, e aqui o objetivo foi jogar
fora as variáveis que não foram usadas; e a \sq{$p$} foi usada sim.

%%}}}

\endsection
%%}}}

%%{{{ Types_of_numbers 
\section Tipos de números.
%%%{{{ meta 
\label Types_of_numbers
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos encontrar e estudar vários tipos de números:
naturais (\ref[Nat_rec_ind]), inteiros (\ref[The_integers]),
racionais (\ref[Galois_theory]), reais (\ref[The_reals]), \dots
Além disso, nos capítulos~\reftag[Cantors_paradise]
e~\reftag[Axiomatic_set_theory] vamos estudar bastante todos esses
tipos de números, e identificar certos reais que são ainda mais
selvagens do que os irracionais: os transcendentais.

%%}}}

%%{{{ from and to the reals 
\note De e para os reais.
%%%{{{ meta 
%%%}}}

Uma abordagem é começar considerado como conhecida ou dada
a noção dos números reais, freqüentemente identificados com
os pontos duma linha reta que extende infinitamente nas ambas
as direcções; um ponto dela chamamos de $0$, botamos na sua direita
mais um ponto chamado de $1$, e pensamos que a distancia entre
esses pontos é medida pelo número real $1$ mesmo,
ma outra direção temos o $-1$, etc., etc., e o leitor
provavelmente já ouviu dessa estoria muitas vezes na vida.\foot
Caso contrário vamos voltar a discutir isso numa
maneira melhor bem depois, nos capítulos~\reftag[The_reals]
e~\reftag[Axiomatic_set_theory].
\toof
Nada disso faz sentido formalmente falando, mas não estamos
falando formalmente nesse momento, e com certeza essa
imágem geométrica ajuda demais em elaborar uma intuição
sobre os reais.
Começando então com a reta dos reais como dada, podemos procurar
e definir um subconjunto dela para representar os racionais,
um subconjunto deles para os inteiros e um deles para os naturais.
Normalmente começamos definindo primeiro os naturais,
depois adicionamos para cada ponto o seu oposto chegando assim nos inteiros,
e depois formamos todas as fracções $m/n$ para quaisquer inteiros $m,n$ com $n\neq 0$
e pronto, temos o racionais também.
\eop
Podemos trabalhar também no sentido contrário (\ref[Axiomatic_set_theory]):
começar com os naturais, usá-los para \emph{construir} os inteiros,
usá-los para construir os racionais, e usá-los para construir os reais, etc.
Nesse contexto, \sq{construir} significa definir.

%%}}}

\endsection
%%}}}

%%{{{ Sets_functions_relations 
\section Conjuntos, funcções, relações.
%%%{{{ meta 
\label Sets_functions_relations
%%%}}}

%%{{{ intro 
\secintro
Rascunhamos aqui três tipos importantíssimos, só para ter uma idéia
do que se trata, pois vamos precisá-los desde já!
Mas cada um deles tem seu próprio capítulo dedicado ao seu estudo:
estudamos conjuntos no~\ref[Sets],
funcções no~\reftag[Functions],
e relações no~\reftag[Relations].
Agora, bora rascunhar!
%%}}}

%%{{{ sets_first_contact 
\note Conjuntos.
%%%{{{ meta 
\label sets_first_contact
\defines
    * conjunto!primeiro contato
    ;;
%%%}}}

Um \dterm{conjunto} é uma colecção de objetos que já conhecemos.
Denotamos um conjunto escrevendo seus membros entre ``chaves'',
separados por comas, por exemplo
$$
\set{1,2,3}
$$
denota o conjunto cujos membros são os números $1$, $2$, e $3$.
Conjuntos não têm seus membros numa certa ordem; e também não
faz sentido perguntar quantas vezes um objeto pertence àlgum conjunto:
$$
\set{1,2,3} = \set{3,1,2} = \set{1,1,3,2,2,1}.
$$
\emph{Dizemos que dois conjuntos são iguais sse
eles possuem exatamente os mesmos membros.}
Vamos também usar a notação
$$
\setstt x {$x$ é um múltiplo de $3$}
$$
para descrever o conjunto de todos os múltiplos de $3$
e---parabéns para nos---acabamos de definir um conjunto infinito
numa maneira tão curta e simples!
A gente leia o conjunto acima assim:
$$
\textwq{o conjunto de todos os $x$, tais que $x$ é um múltiplo de $3$}.
$$
Costumamos usar letras maiúsculas para denotar conjuntos,
mas não ficamos obsecados demais com essa costume.
Usamos a notação $x \in A$, para afirmar que $x$ é um dos membros
do conjunto $A$, e escrevemos $A \subset B$ para afirmar que
cada membro de $A$ é um membro de $B$ (nesse caso dizemos que
$A$ é um subconjunto de $B$).
Por exemplo, o conjunto de todos os brasileiros é um subconjunto
do conjunto de todos os humanos.
Usamos variações da notação em cima como por exemplo
$$
\setstt {n \in \nats} {$n$ e $n+2$ são números primos}
$$
denotando o conjunto de todos os naturais $n$ tais que
$n$ é primo e $n+2$ também.
\eop
Temos tudo que precisamos para começar até chegar no~\ref[Sets]
onde estudamos mesmo conjuntos e outros tipos de ``containers'',
notavelmente tuplas:

%%}}}

%%{{{ tuples_first_contact 
\note Tuplas.
%%%{{{ meta 
\label tuples_first_contact
\defines
    * tupla!primeiro contato
    ;;
%%%}}}

Quando temos uns objetos botados numa certa
ordem, temos uma \dterm{tupla}.
Denotamos a tupla dos objetos $x_1,\dotsc,x_n$ assim:
$$
\tup{x_1,\dotsc,x_n}
\qqqtext{ou}
\tupp{x_1,\dotsc,x_n}.
$$
Observe que temos
$$
\tup{1,2,3} \neq \tup{1,3,2}
$$
pois \emph{consideramos duas tuplas iguais
sse elas concordam em cada posição}.

%%}}}

%%{{{ functions_first_contact 
\note Funcções.
%%%{{{ meta 
\label functions_first_contact
\defines
    * funcção!primeiro contato
    ;;
%%%}}}

\dterm{Funcções} são objetos que dados objetos viram (ou \dterm{retornam}
outros objetos.
É comum usar as letras $f,g,h$, etc.~para denotar funcções, mas, novamente
isso não é uma regra inquebrável.
Escrevemos
$$
f : A \to B
$$
para dizer que $f$ é uma funcção que dada qualquer objeto de tipo $A$,
retorna algum objeto de tipo $B$.
Se $x\in A$, escrevemos \symq{$f(x)$} para o \dterm{valor}
ou \dterm{saida} da $f$ no $x$, e chamamos $x$ de \dterm{argumento}
ou \dterm{entrada} da $f$.
Observe que $f(x) \in B$.  O objeto $f(x)$ é determinado pelo $x\in A$,
ou seja, para qualquer $x \in A$, \emph{exatamente um}
objeto é denotado por $f(x)$.
Por exemplo, $\mother(x)$ pode denotar a mãe duma pessoa $x$.
Aqui entendemos que
$$
\align
\mother           &: \pers \to \pers
\intertext{onde $P$ denota o conjunto de pessoas.
No outro lado, seria errado pensar que}
\namedfun{sister} &: \pers \to \pers
\endalign
$$
também é uma funcção, pois para certos $x \in P$ o $\mathit{sister}(x)$
não seria determinado!

%%}}}

%%{{{ x: why_sister_is_not_a_function 
\exercise.
%%%{{{ meta 
\label why_sister_is_not_a_function
%%%}}}

Quais são esses $x\in P$ tais que $\mathit{sister}(x)$ não é determinado?
Cuidado: tem mais que uma categoria de $x$'s ``problemáticos''!

\solution
As pessoas que não tem nenhuma irmã, e também as pessoas que tem mais que uma!

%%}}}

%%{{{ arity_first_contact 
\note Aridade.
%%%{{{ meta 
\label arity_first_contact
\defines
    * arity!primeiro contato
    ;;
%%%}}}

Uma funcção pode precisar mais que um argumento:
a adição por exemplo precisa dois números para retornar seu valor.
A quantidade de argumentos que uma funcção $f$ precisa é chamada \dterm{aridade}
da $f$.
Não são apenas funcções que têm aridade, relações também têm:

%%}}}

%%{{{ relations_first_contact 
\note Relações.
%%%{{{ meta 
\label relations_first_contact
\defines
    * relação!primeiro contato
    ;;
%%%}}}

Funcções dadas objetos viram objetos.
\dterm{Relações} dadas objetos viram proposições.
Por exemplo
$$
\textwq{{\lthole} é a mãe de {\lthole}}
$$
é uma relação de aridade $2$, mas
$$
\gather
\textwq{Stella é a mãe de {\lthole}} \\
\textwq{{\lthole} é a mãe de Thanos}
\endgather
$$
são relações de aridade $1$.
Para relações de qualquer aridade emprestamos a notação de funcções
e escrevemos, por exemplo
$$
\align
\mathrm{MotherOf}(x,y)       & :\quad \textwq{$x$ é a mãe de $y$} \\
\mathrm{StellaIsMotherOf}(x) & :\quad \textwq{Stella é a mãe de $x$} \\
\mathrm{MotherOfThanos}(x)   & :\quad \textwq{$x$ é a mãe de Thanos}.
\endalign
$$

%%}}}

%%%{{{ notation: wherefix_notation 
\notation infix, prefix, postfix, mixfix.
%%%{{{ meta 
\label wherefix_notation
\defines
    * notação!infix
    * notação!prefix
    * notação!postfix
    * notação!mixfix
    ;;
\indexes
    * infix    see: notação
    * prefix   see: notação
    * postfix  see: notação
    * mixfix   see: notação
    ;;
%%%}}}

Especialmente para funcções e relações de aridade $2$ usamos
também notação \dterm{infix} em vez de \dterm{prefix}, ou seja,
escrevemos o símbolo da funcção ou relação \emph{entre}
os seus argumentos em vez de \emph{antes}.
Como exemplo considere as $+$, $=$, $\leq$, etc.:
\mathcols 4
&\text{em vez de escrever:} &&\mathord{+}(1,2)&&\mathord{=}(1+1,2) &&\mathord{\leq}(0,\mathord{+}(x,y)) \\
&\text{escrevemos:}         &&1+2             &&1+1=2              &&0 \leq x + y.
\endmathcols
Às vezes também usamos notação \dterm{postfix}: exemplo padrão aqui seria
a funcção fatorial que denotamos por um simples \symq{!} postfixo,
escrevendo, por exemplo, $3!$ em vez de $\mathord{!}(3)$.
Quando escrevemos partes da notação do operador e os argumentos intercalados
falamos de notação \dterm{mixfix}, por exemplo:
$\code{if}\thole\code{then}\thole\code{else}\thole$.

%%%}}}

%%{{{ warning: function_vs_relation_naming_convention 
\warning Convenção notacional.
%%%{{{ meta 
\label function_vs_relation_naming_convention
%%%}}}

Para enfatisar a diferença entre funcções e relações, tentarei
denotar funcções com nomes que começam com letra minúscula,
e relações com maiúscula:
usarei \symq{$\mother(x)$} para \emph{o objeto} (aqui pessoa)
\wq{mãe de $x$}, e \symq{$\Mother(x)$} para \emph{a proposição}
\wq{$x$ é uma mãe}.
Novamente, essa também é uma convenção que vou seguir, um costume,
e não uma regra inquebrável.

%%}}}

\endsection
%%}}}

%%{{{ Theorems_and_friends 
\section Teoremas e seus amigos.
%%%{{{ meta 
\label Theorems_and_friends
%%%}}}

%%{{{ theorem 
\note Teorema.
%%%{{{ meta 
\label theorem
\defines
    * theorem
    ;;
%%%}}}

Chamamos de \dterm{teorema} uma proposição que já foi demonstrada
por alguém.
Então: que tipo de coisa é um teorema?  É uma proposição.
E ainda mais, sabemos que essa proposição é verdade, pois já possui
uma demonstração.
Uma proposição $P$ que não conseguimos demonstrar ainda, talvez um belo dia
alguém vai demonstrar e assim vamos falar do teorema $P$, ou pode ser
que alguém refute, e logo sabemos que não se-trata dum teorema.
Mas por enquanto, não sabemos se $P$ é um teorema ou não.

%%}}}

%%{{{ lemma_corollary 
\note Lemma, teorema, corolário.
%%%{{{ meta 
\label lemma_corollary
\defines
    * corollary
    * lemma
    ;;
%%%}}}

Matematicamente falando então não existe diferença essencial entre lemma e teorema,
nem entre teorema e corolário;
mas cuidado no seu uso pois nosso objetivo em matemática é \emph{comunicar},
e chamando um teorema de lemma ou de corolário comunica algo diferente.
Pense que estamos tentando demonstrar uma proposição que consideramos importante,
e provavelmente não vai ser muito simples demonstrá-la.
Chamamos de \dterm{lemma} um teorema que demonstramos para usar em demonstrar
nosso teorema.  E assim que demonstrar nosso teorema, talvez para divulgá-lo
e falar da importância dele, consideramos varias proposições que são
conseqüências (faceis) do nosso teorema principal.
Esses são os \dterm{corolários} dele.
Para resumir: 

%%}}}

%%{{{ conjecture 
\note Conjectura.
%%%{{{ meta 
\label conjecture
\defines
    * conjectura
    ;;
%%%}}}

Uma proposição interessante que alguém afirmou e tentou demonstrar
sem conseguir, é uma \dterm{conjectura}.  Em qualquer momento
pode ser que alguém consegue demonstrar: nesse caso a proposição
vai ganhar o direito de ser chamada um teorema.
Similarmente, ipode ser que alguém consegue refutar:
nesse caso a proposição é mais uma conjectura, pois já sabemos
a resposta (negativa) sobre sua vericidade.
Já no~\reffull[The_integers] vamos conhecer umas conjecturas que têm
atrapalhado---ou, entretido---matemáticos para séculos.
O que talvez parece estranho---e eu espero pelo menos um pouco incrível
para meu leitor---é que existe mais uma possibilidade para
``resolver'' uma tal \dterm{questão em aberto}:
pode ser que alguém \emph{demonstra que não tem como demonstrá-la
nem como refutá-la!}
Mas é cedo demais para analizar mais isso; paciência; durante
esse texto vamos ver vários tais exemplos dessa situação e acabar
entendendo bem a situação.

%%}}}

\endsection
%%}}}

%%{{{ Proofs_first_encounter 
\section Demonstrações.
%%%{{{ meta 
\label Proofs_first_encounter
%%%}}}

%%{{{ What is a proof? 
\note O que é?.
%%%{{{ meta 
\defines
    * demonstração
    ;;
%%%}}}

Vamos começar com a idéia que uma \dterm{demonstração}
é uma argumentação ao favor duma proposição, convincente
e sem erros, escrita como um pedaço de texto, entendível
para uma pessoa que entende as noções matemáticas envolvidas.

%%}}}

%%{{{ proving_language_first_encounter 
\note Linguagem de demonstração.
%%%{{{ meta 
\label proving_language_first_encounter
\defines
    * linguagem!de demonstração
    ;;
%%%}}}

Normalmente a linguagem que usamos para escrever demonstrações
é uma linguagem natural, como grego, português, inglês, etc.,
\emph{enriquecida} saudavelmente por símbolos e notações
matemáticas.  Além disso, entendemos essa linguagem como
uma coisa mutável (especialmente aumentável), algo que
aproveitamos introduzindo novas notações, noções, convenções,
etc.
Infelizmente, especialmente quando começamos estudar
e \emph{fazer} matemática, não é uma idéia boa ter de
lidar com umas ambigüidades que as linguagens naturais carregam.
Vamos elaborar uma \emph{linguagem de demonstração},
bastante ``seca''---e sem a expressividade nem a beleza
que uma linguagem natural oferece---e tratá-la como se
fosse uma linguagem de programação.
Vamos diferenciar entre linhas de código e comentários,
e identificar certas palavras-chaves, explicar seus
efeitos, como, por que, e quando podemos usar.
Exatamente como na linguagem C por exemplo temos as
palavras $\code{while}$, $\code{return}$, $\code{float}$,
$\code{switch}$, $\code{else}$, etc., cada uma com seu
uso correto, sua sintaxe, sua semântica, etc.
A idéia é que uma demonstração escrita em linguagem natural,
corresponde ``por trás'' num texto feito por ``linhas de código''
escritas nessa linguagem de demonstração.
Demonstrações escritas na linguagem de demonstração
acabam sendo cansativas de ler, sem graça: parece que
um robô escreveu.
Nosso objetivo aqui é aprender como escrever numa linguagem
natural mesmo, mas entendendo em qualquer momento as
linhas de código por trás.
Elaboramos isso no~\ref[Proofs].

%%}}}

%%{{{ Programming vs. proving 
\note Programando \vs demonstrando.
%%%{{{ meta 
%%%}}}

Em muitos sentidos \emph{demonstrar} e \emph{programar}
são atividades parecidas---tanto que podemos até identificá-las!\foot
Isso não é um modo de falar, nem um exagero,
mas infelizmente vou ter que pedir para bastante paciência no teu lado,
pois vamos demorar até chegar a entender essa idéia.
\toof
Além disso vou fazer muitas metáforas usando noções de programação.
Caso que o leitor não tem nenhum contato com programação,
deveria começar (aprender) programar em paralelo---com certeza,
mas o que deveria ter dito aqui foi que o leitor sem experiência
de programação vai perder apenas certos exemplos, metáforas, e
referências, e nada essencial.  Esses exemplos são aqui para ajudar
o programador, não para prejudicar o não-programador.
No final das contas, o não-programador já se-prejudica sozinho na vida,
pela falta de\dots ``progranoção''!

%%}}}

%%{{{ Theses vs. hypotheses 
\note Teses \vs hipoteses.
%%%{{{ meta 
%%%}}}

``Tese'' vem da grega \emph{θέσις} e similarmente ``hipótese'' da
palavra \emph{ὑπόθεσις}.
\dterm{Tese} quis dizer \emph{posição},
nesse sentido também \emph{opinião}.
Tu tens uma tese sobre um assunto, e queres argumentar para defendê-la.
O prefixo ``ὑπο-'' (hipo-) denota uma idéia de ``a baixo de''.
O equivalente prefixo latino (e usado em português) é o ``sub-''.
\dterm{Hipoteses} então são \emph{su(b)posições}, ou seja,
afirmações ``a baixo'' da tese: as proposições em quais a tese depende.

%%}}}

\endsection
%%}}}

%%{{{ Axioms_and_primitive_notions 
\section Axiômas e noções primitivas.
%%%{{{ meta 
\label Axioms_and_primitive_notions
%%%}}}

%%{{{ an ``annoying'' child 
\note Uma criança ``chata''.
%%%{{{ meta 
%%%}}}

Imagine tentando convencer uma criança sobre alguma proposiação $P$:
\dialogue
\say $P$
\say por que $P$?
\say $P$ pois $Q$.
\say E por que $Q$?
\say $Q$ pois $R$.
\say E por que $R$?
\enddialogue
Quem conversou com uma criança sabe que não tem como ganhar nesse
jogo.  Não tem como justificar tudo: esse dialogo continuando
nessa forma nunca vai terminar.
A idéia é que nosso ``oponente'' ou ``inimigo'' (nesse exemplo a criança)
vai continuar duvidando qualquer uma das novas proposições que usamos
em nossa argumentação, \emph{até finalmente chegar em algo que concorda
aceitar}.  Talvez no exemplo da criança chegando numa afirmação do tipo
\wq{comer sorvete é bom} faria o dialogo terminar:
\dialogue
\say \dots pois comer sorvete é bom.
\say Ah sim, faz sentido.
\enddialogue

%%}}}


%%{{{ Euclidean geometry 
\note Um exemplo: geometria euclideana.
%%%{{{ meta 
\label euclidean_geometry_example
\defines
    * geometria!euclideana
    ;;
%%%}}}

{\Euclid}Euclides na Grécia antiga elaborou, investigou,
e estabeleceu o que chamamos de \dterm{geometria euclideana}.
Uma das mais importantes idéias que temos desde então é a percepção
que precisamos deixar claro quais são nossos axiomas, e trabalhar
para elaborar nossa teoria, investigando suas conseqüências: os teoremas.
Similarmente, separamos as noções primitivas que aceitamos sem definir
formalmente, e as usando continuamos em aumentar mais e mais nosso vocabulário.
As noções primitivas da geometria euclideana são os \dterm{pontos}
e as \dterm{linhas} (retas).
E também a relação entre pontos e linhas seguinte:
$$
\textwq{o ponto {\lthole} pertence à linha {\lthole}}.
$$
Não definimos o que significa ser um ponto; nem ser uma linha;
nem o que significa que um ponto pertence àlguma linha.
De fato, Euclides tentou dar uma intuição, uma descripção informal
sobre suas noções primitivas em vez de escrever algo do tipo
\quote
Essas aqui são noções primitivas, não me perguntem o que significam; aceitem.
\endquote
A partir dessas noções primitivas, podemos \emph{definir} conceitos interessantes.
Por exemplo, em vez de adicionar como primitiva a noção de linhas parallelas,
podemos realmente definir o que significa ser parallela, numa maneira que
a criançá chata do exemplo acima um belo momento cairia apenas em noções
primitivas e não teria como continuar com seus \wq{e o que é\dots?}.

%%}}}


%%{{{ x: define_parallel_line 
\exercise.
%%%{{{ meta 
\label define_parallel_line
%%%}}}

Defina o que significa \dterm{ser parallelas}.

\solution
Começamos assim:
\quote
Definição.
Sejam $a,b$ duas linhas.
Dizemos que $a,b$ são parallelas sse $a,b$ não se tocam.
\endquote
Não podemos parar com essa definição pois no lado direito usamos
uma frase que não significa nada (por enquanto): não definimos
o que significa que duas linhas ``se tocam''.
Basta então definir isso:
\quote
Definição.
Sejam $a,b$ duas linhas.
Dizemos que $a,b$ se tocam sse não existe ponto $p$ tal que
$p$ pertence à linha $a$ e $p$ pertence à linha $b$.
\endquote
Pronto, agora nada ficou ``solto'', acabou sendo reduzido para as noções primitivas de
ponto, linha, e o predicado primitivo de ``ponto pertence a linha''.

%%}}}

\endsection
%%}}}

%%{{{ More_errors 
\section Mais erros.
%%%{{{ meta 
\label More_errors
%%%}}}

%%{{{ logical_error 
\note De lógica.
%%%{{{ meta 
\label logical_error
\defines
    * falácia
    ;;
%%%}}}

Uma argumentação errada envolve concluir algo que não segue
necessariamente pelas premissas usadas:
talvez usamos incorretamente uma hipótese,
talvez reduzimos incorretamente nosso alvo para outro,
\dots
Assim, não conseguimos convencer uma pessoa que sabe
pensar sobre a validáde da nossa tese.
Em termos de programação, nosso programa
(i.e., nossa demostração) \emph{não compilou!}
Durante esse texto vamos encontrar e discutir várias \dterm{falácias},
ou seja, erros comuns em argumentação, mas não vamos focar agora em
criar e discutir uma lista de falácias aqui.
Logo no~\ref[Proofs] estudaremos qual é a maneira correta de
raciocinar e demontrar proposições e também discutimos umas
falácias comuns (\reftag[Fallacies]).
Mas só pra te dar uma idéia desde já, vamos ver um exemplo
duma argumentação.

%%}}}

%%{{{ eg: olive_tree 
\example.
%%%{{{ meta 
\label olive_tree
%%%}}}

Considere a inferência seguinte, que quer convencer alguém sobre
a tese que uma certa árvore é uma oliveira.
\quote
\flwq{Oliveiras têm azeitonas.\CR
Essa arvore tem azeitonas.\CR
Portanto, essa arvore é uma oliveira.}
\endquote
Aqui a partir das hipoteses nas duas primeiras linhas,
inferimos a tese (terceira).

%%}}}

%%{{{ Q: Is everything OK with this inference? 
\question.
%%%{{{ meta 
%%%}}}

Tá tudo OK com essa inferência?

%%}}}

\spoiler

%%{{{ A: Nope 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não, a inferência tá erradíssima, mesmo que sua conclusão---por sorte!---acontece
que é válida: o processo de inferi-la, não foi!
Compare com:
\quote
\flwq{Jogadores de basquetes são fortes.\CR
Esse homem é forte.\CR
Portanto, esse homem é jogador de basquete.}
\endquote
Observe que a estrutura da inferência é exatamente
\emph{a mesma} com a anterior.  Não parecida; mesma!
Outra maneira: substitua a palavra \sq{arvore}
pela palavra \sq{pizza} na argumentação original.

%%}}}

%%{{{ mathematical_error 
\note De matemática.
%%%{{{ meta 
\label mathematical_error
%%%}}}

Usando propriedades inválidas, erros em cálculos, etc.
Não tem muita coisa para discutir sobre esse tipo de erro:
ficar acordado ajuda avitá-los.

%%}}}

%%{{{ semantical_error 
\note De semântica.
%%%{{{ meta 
\label semantical_error
%%%}}}

Isso acontece quando o que escrevemos realmente quis dizer algo,
mas não é o que temos na nossa cabeça.
É quando um programador escreveu seu cógido e ele compilou ``com
sucesso'', mas o programa que foi criado não faz o que ele queria.
Isso acontece muito dando definições como discutimos
na~\ref[Definitions].

%%}}}

%%{{{ ethical_aesthetical_error 
\note De ética e de estética.
%%%{{{ meta 
\label ethical_aesthetical_errors
\defines
    * erro!de aestética
    * erro!de ética
    ;;
%%%}}}

\emph{Meio} brincando, quero analizar mais dois tipos de erros.
\dterm{Erro ético} é uma escolha de nóme ou notação desonesta,
que ajuda o leitor---ou até o escritor---errar.
\dterm{Erro de aestética} seria uma escolha de nóme ou notação que
quebra um padrão ou uma convenção estabelecida; algo que introduz uma
complexidade desnecessária.  Um bom programador dedica grande parte do
seu tempo na escolha de nomes para suas variáveis, suas funcções, etc.
Um nome bom deve ajudar em pensar, carregar informação correta sem ficar
pesado ou cansativo para usar, etc.
Com prática tu deves desenvolver um bom gosto nisso!

%%}}}

%%{{{ eg: ethical_aesthetical_errors 
\example.
%%%{{{ meta 
%%%}}}

Considere a frase:
\quote
\wq{Para quaisquer $a,x,y\in\ints$ se $a$ divide $x$ e $x$ divide $y$ então $a$ divide $y$.}
\endquote
A escolha de nomes dessas variáveis não faz sentido nenhum.  Queremos três nomes para os três inteiros que estão na mesma situação, moram no mesmo bairro, são parentes da mesma família.  Não faz sentido quebrar a norma alfabética pegando um nome do bairro dos $a,b,c,\dots$ e outros dois do bairro dos $x,y,z,\dots$.
Outra:
\quote
\wq{Seja $n$ um número real e seja $x$ o menor natural tal que $n \leq x$.}
\endquote
Aqui temos um natural e um real e escolhemos a letra `n' para o real.  Bizarro.

%%}}}

\endsection
%%}}}

%%{{{ Heart_level_and_slang 
\section Nível coração e palavras de rua.
%%%{{{ meta 
\label Heart_level_and_slang
%%%}}}

\TODO terminar.

%%{{{ intro 
\secintro
O maior objetivo deste texto é te ajudar elaborar
teu entendimento de matemática nos dois níveis.
Não faz sentido pensar que esses dois lados estão
combatendo um o outro.  Eles se ajudam e se completam,
e estão dando à matemática sua elegância e beleza
característica.
%%}}}

%%{{{ two_levels_of_understanding 
\note Dois níveis de entendimento.
%%%{{{ meta 
\label two_levels_of_understanding
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ heart_level 
\note Nível coração.
%%%{{{ meta 
\label heart_level
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ advice: slang_advice 
\advice palavras de rua.
%%%{{{ meta 
%%%}}}

Vamos dizer que acabamos de definir um objeto.
Então crie um apelido legal para esse objeto.
Sinta-se à vontade virar de melhor amigo até um bully.
Quais são as propriedades que ele tem?
O que \dterm{característico} sabemos dele?
É um conjunto?
Então\dots se fosse um time, qual seria o nome dele?
Se fosse uma banda, uma empresa, um vilarejo?
E esses membros que já temos mencionado nele,
como traduzem na nossa metáfora?
É uma funcção?
Talvez algo que termina em {-or(a)}?
É uma relação?
Então invente uma gíria significativa para
a ``situação'' descrita por ela.
Use tua imaginação, teu humor, inspira-se
de coisas que tu conhece bem e que tu gosta.
Quando puder, tente fazer isso em mais que uma maneira:
no teu bairro então o tal objeto ganhou esse apelido;
quais outros apelidos tu acha que ele tem em outros bairros?
\emph{Cada apelido, cada gíria, é mais uma ferramenta
valiosa para pensar; não subestime esse processo!}
E muitas vezes, uma metáfora boa num contexto, que nos ajudou
pensar e chegar numa idéia linda, pode acabar nos limitando em outro,
ou, até pior, nos ajudar errar, nos levar para caminhos inúteis, etc.

%%}}}

%%{{{ mechanic_level 
\note Lado mecânico.
%%%{{{ meta 
\label mechanic_level
%%%}}}

Aí chega o outro lado do entendimento que não vai nos permitir
ser enganados e levados por esses caminhos errados.
E, alem disso, nos momentos que nossas metáforas não nos ajudam,
ou que simplesmente não temos nenhuma maneira ``de rua'' para
descrever e pensar, ele pode nos dar o apóio para andar uns passos
no jogo, seguindo agora nossa intuição elaborada jogando o jogo
e conhecendo suas regras.

%%}}}

%%{{{ advice: game_advice 
\advice jogo formal.
%%%{{{ meta 
\label mechanic_advice
%%%}}}

No~\ref[Proofs] estudamos os principais conectivos de lógica
que mais usamos em matemática.  Lá enfatiso o ponto que
matemática pode ser vista como um jogo formal, com suas
regras e seu objetivo: o jogador joga escrevendo demonstrações
e definições, seguindo as regras do jogo.
Como tu vai ver, temos até um tabuleiro (de Dados/Alvos)
e cada ``movimento'' no jogo é uma linha, que altera
o estado desse tabuleiro.
Quando tu tá tentando escrever ou entender uma demonstração,
\emph{fique atualizando esse tabuleiro no teu rascunho,
com cada linha escrita ou lida!}

%%}}}

%%{{{ notation 
\notation.
%%%{{{ meta 
\defines
    * ~A \hearteq ~B   -- os $A,B$ são sinônimos no nível coração, com palavras de rua
    * ~A \heartiff ~B  -- as $A,B$ são sinônimas no nível coração, com palavras de rua
    ;;
%%%}}}

Para enfatisar que estou\dots ``caindo'', ``subindo'', ou ``entrando''
ao nível coração, decoro os símbolos correspondentes com um $\heart$.
Aqui uns exemplos imaginários para ilustrar:
$$
\xalignat2
r           &\hearteq \text{o árbito};           & f(x) \leadsto g(x)  &\heartimplies \text{$x$ é triste}; \\
G           &\hearteq \text{os goleiros};        & u < v               &\heartiff     \text{$u$ observa $v$}; \\
g(T)        &\hearteq \text{o goleiro do $T$};   & r = g(A)            &\heartiff     \text{o árbito é o goleiro do $A$}; \\
N(x)        &\hearteq \text{o bairro do $x$};    & N(x) = N(y)         &\heartiff     \text{$x,y$ são vizinhos}.
\endxalignat
$$

%%}}}

\endsection
%%}}}

%%{{{ Further reading 
\further.

Matemática elementar:
\cite[simmonsprecalculus] (para uma revisão rápida);
\cite[langbasicmath] (para uma (re)visão com mais detalhes).

Sobre geometria euclideana:
\cite[elements],
\cite[coxeterrevisited];
\cite[hartshorneeuclidbeyond].

Mais sobre falácias:
\cite[wiki:List_of_fallacies].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Languages 
\chapter Linguagens.
%%%{{{ meta 
\label Languages
%%%}}}

\TODO terminar merge e arrumar.

%%{{{ Numbers, numerals, digits 
\section Números, numerais, dígitos.
%%%{{{ meta 
%%%}}}

%%{{{ number_numeral_digit 
\note.
%%%{{{ meta 
\label number_numeral_digit
\indexes
    * algarismo    see: dígito
    ;;
\defines
    * dígito
    * numeral
    * número
    ;;
%%%}}}

Aceitamos por enquanto como dado o conceito dos números que usamos
para contar:
$$
0, 1, 2, 3, \dots, 247, 248, 249, \dots
$$
Usando então apenas um \emph{alfabeto} composto de dez símbolos
$$
\digit 0\ \ 
\digit 1\ \ 
\digit 2\ \ 
\digit 3\ \ 
\digit 4\ \ 
\digit 5\ \ 
\digit 6\ \ 
\digit 7\ \ 
\digit 8\ \ 
\digit 9
$$
e seguindo as regras bem-conhecidas do sistema decimal conseguimos
denotar qualquer um dos números, mesmo que tem uma infinidade deles!
\eop
Chamamos esses símbolos \dterm{dígitos} (ou \dterm{algarismos}),
e as palavras (ou ``strings'') que formamos justapondo esses dígitos
que representam os números, \dterm{numerais}.
Sem contexto, lendo o \sq{10} já temos uma ambigüidade:
é o numeral $\numeral {10}$ ou o número dez?
Para apreciar essa diferença ainda mais, note que o numeral $\numeral {10}$,
pode representar outro número em outro contexto.
Por exemplo, no sistema binário, o numeral $\numeral {10}$
representa o número dois.
E a ambigüidade pode ser ainda maior lendo ``1'':
é o numeral $\numeral {1}$; o número um; ou o dígito~$\digit 1$?
Quando o contexto é suficiente para entender, não precisamos mudar a fonte
como acabei de fazer aqui, nem escrever explicitamente o que é.
Note que existem numerais bem diferentes para denotar esses números:
o numeral (romano) {XII}
e o numeral (grego) {ιβ} denotam o mesmo número: doze.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Temos então umas pequenas linguágens que nos permitem descrever \emph{números}.
Não fatos sobre números.
Nem cálculos com números.
Números.
Quais números?
Todos os números \emph{naturais} (veja~\reftag[Types_of_numbers]),
cuja totalidade simbolizamos com $\nats$ e deixamos seu estudo para o \ref[Nat_rec_ind].

%%}}}

\endsection
%%}}}

%%{{{ Arithmetic expressions 
\section Expressões de aritmética.
%%%{{{ meta 
%%%}}}

%%{{{ arithmetic_expressions
\note Expressões sintácticas e sua semântica.
%%%{{{ meta 
\label arithmetic_expressions
\defines
    * expressão!aritmética
    ;;
\indexes
    * aritmética             seealso: expressão
    * aritmética             seealso: expressão
    ;;
%%%}}}

Aprendendo aritmética queremos expressar números numa maneira mais interessante
do que simplesmente usar os próprios nomes deles:
\sq{$2+5$}, por exemplo, é uma \dterm{expressão de aritmética}.
Podemos pensar que essas expressões acabam denotando números:
a expressão \sq{$2+5$} denota \emph{o número 7}.
Alternativamente podemos usá-las para denotar os próprios cálculos:
a expressão \sq{$2+5$} denota \emph{o cálculo de somar o 2 com o 5}.
E nesta paragrafo estou usando o \sq{$2+5$} para referir à propria
expressão sintáctica mesmo.
Mas em todos essas interpretações as expressões de aritmética denotam objetos
(números ou cálculos ou até elas mesmo) e ainda não temos como expressar
\emph{afirmações} sobre eles.  Resolveremos isso logo na \ref[FOLs].

%%}}}

%%{{{ denotational_semantics_first_mention 
\note Semântica denotacional.
%%%{{{ meta 
\label denotational_semantics_first_mention
\defines
    * semântica!denotacional
    ;;
\indexes
    * sintáxe
    * semântica
    ;;
%%%}}}

As expressões fazem parte da \dterm{sintaxe} duma linguagem (aqui, duma
linguagem de aritmética).
Uma \dterm{semântica denotacional} atribua um significado para esses objetos
sintácticos.  Já encontramos três exemplos acima: uma interpretou a expressão
como número, outra como cálculo, outra (trivial) como um string mesmo.
Vamos voltar a esse assunto varias vezes e até dedicar um capítulo inteiro
analizando essas idéias no contexto de linguagens de programação
(\ref[Denotational_semantics]).

%%}}}

\endsection
%%}}}

%%{{{ Derivation_trees 
\section Arvores de derivação.
%%%{{{ meta 
\label Derivation_trees
%%%}}}

%%{{{ Parsing 
\note Parsing.
%%%{{{ meta 
\label parsing
\defines
    * parsing
    * árvore!de derivação
    * árvore!sintáctica
    ;;
%%%}}}

Lendo uma expressão ``linear'' como a \sq{$1 + 5 \ntimes 2$}
nós a \dterm{parseamos} para revelar sua estrutura,
freqüentemente representada numa forma bidimensional,
como uma \dterm{árvore sintáctica}.
Temos então as árvores:
$$
1 + (5 \ntimes 2)
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$+$}
  child {node [circle,draw] (a) {$1$}}
  child {node [circle,draw] (b) {$\vphantom+\ntimes$}
    child {node [circle,draw] (b1) {$5$}}
    child {node [circle,draw] (b2) {$2$}}
  };
\endtikzpicture
\endgathered
\qqqquad
(1 + 5) \ntimes 2
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$\vphantom+\ntimes$}
  child {node [circle,draw] (a) {$+$}
    child {node [circle,draw] (a1) {$1$}}
    child {node [circle,draw] (a2) {$5$}}
  }
  child {node [circle,draw] (b) {$2$}};
\endtikzpicture
\endgathered
$$
Não vamos usar mais este tipo de árvore sintáctica nessas notas.

%%}}}

%%{{{ Derivation trees 
\note Arvores de derivação.
%%%{{{ meta 
\indexes
    * derivação    seealso: árvore
    ;;
\defines
    * árvore!de derivação
    ;;
%%%}}}

Em vez, vamos usar \dterm{árvores de derivação} como essas:
$$
\xalignat2
&
\PROOF {
\A {1}
          \A {5}       \A {2}
          \I2---------------- {$\ntimes$}
           {$(5 \ntimes 2)$}
\I2------------------------- {$+$}
      {$1 + (5 \ntimes 2)$}
}
&&
\PROOF {
\A {1}    \A {5}
\I2------------- {$+$}
   {$(1 + 5)$}            \A {2}
   \I2-------------------------- {$\ntimes$}
        {$(1 + 5) \ntimes 2$}
}
\endxalignat
$$
Sendo esse nosso primeiro contato com árvores sintácticas, vou explicar
em detalhe como as escrevemos.  Começamos então com a expressão (linear)
que queremos parsear:
$$
(1 + 5) \ntimes 2.
$$
Graças à sua parêntese, o ``operador principal'' (o mais ``externo'')
é o $\ntimes$\;.  Isso quer dizer que, no final das contas, essa expressão
representa uma multiplicação de duas coisas.
Exatamente por isso, reduzimos essa expressão em duas novas, escrevendo
uma linha em cima dela, onde temos agora dois lugares para botar essas
duas coisas.  No lado da linha, escrevemos sua ``justificativa''
$$
\PROOF {
\A {$\hole$}     \A {$\hole$}
\I2-------------------------- {$\holed \ntimes$}
     {$(1 + 5) \ntimes 2$}
}
$$
e nos dois buracos que aparecem botamos as expressões que estão
nos lados desse $\ntimes$:
$$
\PROOF {
\A {$\holed {(1 + 5)}$}    \A {$\holed {\vphantom(2}$}
\I2--------------------------------------------------- {$\ntimes$}
                    {$(1 + 5) \ntimes 2$}
}
$$
Agora \sq{$2$} já é uma expressão \dterm{atômica} (ou seja, inquebrável),
mas a \sq{$(1 + 5)$} não é; então repetimos o mesmo processo nela:
$$
\PROOF {
\A {$\holed 1$}    \A {$\holed 5$}
\I2------------------------------- {$\holed +$}
             {$(1 + 5)$}
                              \A {${\vphantom(2}$}
           \I2------------------------------------ {$\ntimes$}
                    {$(1 + 5) \ntimes 2$}
}
$$
Chegamos finalmente na árvore
$$
\PROOF {
\A {$1$}    \A {$5$}
\I2----------------- {$+$}
      {$(1 + 5)$}
                       \A {${\vphantom(2}$}
      \I2---------------------------------- {$\ntimes$}
               {$(1 + 5) \ntimes 2$}
}
$$
que mostra como a expressão aritmética \sq{$(1 + 5) \ntimes 2$}
que é a \dterm{raiz} (ou \dterm{root}) dessa árvore é composta por
os numeráis $1$, $5$, e $2$ que são as suas \dterm{folhas}
(ou \dterm{leaves}).

%%}}}

%%{{{ Q: What did we derive? 
\question.
%%%{{{ meta 
%%%}}}

Mas, como assim ``de derivação''?  O que derivamos?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Podemos visualizar a árvore acima como uma derivação (demonstração!)~da
afirmação \wq{\sq{$(1+5) \ntimes 2$} é uma expressão de aritmética} que
podemos simbolizar assim:
$$
(1 + 5) \ntimes 2 \is \type{ArExp}.
$$
Cada node da árvore (incluindo sua raiz e suas folhas) são
afirmações, mesmo se a parte de afirmar fica invisível (implícita).
Aqui todas as nodes têm a mesma parte invisível.
Aqui a mesma árvore com nada invisível:
$$
\PROOF {
\A {$1 \is \type{ArExp}$}    \A {$5 \is \type{ArExp}$}
\I2--------------------------------------------------- {$+$}
              {$(1 + 5) \is \type{ArExp}$}
                                              \A {${\vphantom(2 \is \type{ArExp}}$}
              \I2------------------------------------------------------------------ {$\ntimes$}
                             {$(1 + 5) \ntimes 2 \is \type{ArExp}$}
}
$$

%%}}}

\endsection
%%}}}

%%{{{ BNF_notation 
\section Gramáticas e a notação BNF.
%%%{{{ meta 
\label BNF_notation
\defines
    * gramática!BNF
    ;;
\indexes
    * Backus--Naur form    see: BNF
    * BNF    see: gramática
    ;;
%%%}}}

%%{{{ A first try 
\note Uma primeira tentativa.
%%%{{{ meta 
\label BNF_a_first_try
%%%}}}

Vamos começar diretamente com um exemplo de uso da
notação~\dterm{BNF}
(Backus{\Backus}--Naur{\Naur} form),
para descrever uma linguagem de expressões aritméticas, usando
a \dterm{gramática} seguinte:

%%}}}

%%{{{ grammar: ArEx_grammar_1 
\grammar ArEx (1).
%%%{{{ meta 
\label ArEx_grammar_1
%%%}}}

$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} + \bnf{ArEx})                  \tag{2}
\endalign
$$

%%}}}

%%{{{ Explanation 
\blah.
%%%{{{ meta 
%%%}}}

O que tudo isso significa?
A primeira linha, é uma regra dizendo:
uma expressão aritmética pode ser um dos
$0$, $1$, $2$, $3$, \dots.
A segunda linha é mais interessante: uma expressão aritmética pode começar
com o símbolo~\symq{(},
depois ter uma expressão aritmética,
depois o símbolo~\symq{+},
depois mais uma expressão aritmética,
e finalmente o símbolo~\symq{)}.
A idéia é que o que aparece com ângulos é algo que precisa ser substituido,
com uma das opções que aparecem no lado direito de alguma regra que começa com ele.
\eop
Começando com o $\bnf{ArEx}$ ficamos substituindo até não aparece mais nada em ângulos.
Et voilà: neste momento temos criado uma expressão aritmética.

%%}}}

%%{{{ eg: BNF_first_example 
\example.
%%%{{{ meta 
\label BNF_first_example
%%%}}}

Use as regras (1)--(2) da~\ref[ArEx_grammar_1] acima para criar
duas expressões aritmética.

\solution.
Começando usando a regra (2), temos:
$$
\align
\underline{\bnf{ArEx}}
&\leadstoby {(2)} (\bnf{ArEx} + \underline{\bnf{ArEx}})\\
&\leadstoby {(1)} (\underline{\bnf{ArEx}} + 3)\\
&\leadstoby {(2)} ((\underline{\bnf{ArEx}} + \bnf{ArEx}) + 3)\\
&\leadstoby {(1)} ((128 + \underline{\bnf{ArEx}}) + 3)\\
&\leadstoby {(1)} ((128 + 0) + 3)
\intertext{Começando usando a regra (1), temos:}
\underline{\bnf{ArEx}}
&\leadstoby {(1)} 17
\endalign
$$
Isto sendo nosso primeiro exemplo de uso de BNF,
em cada expressão que fica na parte esquerda dum \symq{$\leadsto$}
sublinhei o foco atual (o que escolhi para ser substituido nesse passo).
Em geral, não vamos fazer isso.

%%}}}

%%{{{ x: BNF_with_goal 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre como usar a~\ref[ArEx_grammar_1] para gerar a expressão aritmética
$((1 + (2 + 2)) + 3)$.

\solution
Uma solução é a seguinte:
$$
\align
\bnf{ArEx}
&\leadstoby {(2)} (\bnf{ArEx} + \bnf{ArEx})\\
&\leadstoby {(1)} (\bnf{ArEx} + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + \bnf{ArEx}) + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + 2)) + 3)
\endalign
$$

%%}}}

%%{{{ beware: bnf_not_variables_bnfeq_not_eq 
\beware.
%%%{{{ meta 
\label bnf_not_variables_bnfeq_not_eq
%%%}}}

Essa coisinha aí, a \sq{$(\bnf{ArEx} + \bnf{ArEx})$} que parece no
lado direito da \ref[ArEx_grammar_1] pode dar a impressão errada que
só podemos criar expressões de aritmética onde a soma é aplicada nos
mesmos termos, por exemplo, $(1+1)$, $(5+5)$, $((1+1)+(1+1))$, etc.
\emph{Não é o caso!}
Isso deve ser óbvio já pelo~\ref[BNF_first_example].
Não pense então nos \symq{$\bnf{Bla}$} como variáveis,
nem no \symq{$\bnfeq$} como igualdade.
Numa expressão como a \sq{$y = x + x$} o termo \sq{$x$} deve denotar
o mesmo objeto em ambas as suas instâncias.

%%}}}

%%{{{ Q: problems_of_first_BNF
\question.
%%%{{{ meta 
%%%}}}

Quais são uns defeitos dessa primeira tentativa?
O que podemos fazer para a melhorar?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Umas deficiências são:
\elist:
\li: A linguagem gerada por essa gramática não é suficiente para representar expressões que envolvem outras operações, como $-$, $\ntimes$, $\div$, etc.
\li: A regra (1) tem uma infinitade de casos (graças aos \symq{$\dotsb$}).
\li: As regras e os nomes escolhidos não refletem bem nossa idéia.
\endelist

%%}}}

%%{{{ x: solve_first_problem_of_ArEx 
\exercise.
%%%{{{ meta 
\label solve_first_problem_of_ArEx
%%%}}}

Apenas alterando a segunda regra da~\ref[ArEx_grammar_1], resolva a primeira deficiência.

\hint
Falta só adicionar 3 mais casos na segunda regra,
imitando para os outros operadores o caso do $+$.

\solution
Temos:
$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx}
&\bnfeq (\bnf{ArEx} + \bnf{ArEx})\tag{2}\\
&\bnfOR (\bnf{ArEx} - \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \ntimes \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \div \bnf{ArEx})
\endalign
$$

%%}}}

%%{{{ A second try 
\note Uma segunda tentativa.
%%%{{{ meta 
%%%}}}

A solução que encontramos no~\ref[solve_first_problem_of_ArEx]
não é a coisa mais elegante do mundo.
Tem muita repetição que podemos evitar, definindo uma nova regra em nossa gramática:

%%}}}

%%{{{ grammar: ArEx_grammar_2 
\grammar ArEx (2).
%%%{{{ meta 
\label ArEx_grammar_2
%%%}}}

$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})\tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bem melhor!
Mas ainda a gramática não refleta bem nossa idéia.
Podemos melhorá-la, com mais regras e com nomes melhores
que deixam mais claras nossas intenções:

%%}}}

%%{{{ grammar: ArEx_grammar_3 
\grammar ArEx (3).
%%%{{{ meta 
\label ArEx_grammar_3
%%%}}}

$$
\align
\bnf{ArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx}                 \tag{0}\\
\bnf{Num}   &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb  \tag{1}\\
\bnf{OpEx}  &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})         \tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div       \tag{3}
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Falta achar um jeito para remover esses \sq{$\dotsb$} ainda,
mas vamos deixar isso para depois (\ref[remove_dots_from_ArEx_grammar]).

%%}}}

%%{{{ beware: BNF_without_angle_brackets 
\beware.
%%%{{{ meta 
\label BNF_without_angle_brackets
%%%}}}

Como conseguimos separar o que é sintaxe da linguagem que estamos
definindo a partir duma gramática da sintaxe da \emph{metalingaugem}
que usamos para descrever essa gramática?
Por exeplo, na~(2) da~\ref[ArEx_grammar_3], na sua parte
direita,temos uma expressão cujo primeiro caracter é o \symq{$($}
e depois\dots continua com o caracter \symq{$\langle$}?
Claro que não, e parece que necessitamos esses ângulos na nossa
metalinguagem para tirar essa ambigüidade.
Mas muitas vezes não existe esse perigo, pois podemos inferir
se algo é para ser substituido ou se é sintaxe da linguagem-objeto
mesmo: \emph{caso que aparece no lado esquerdo de alguma das
regras da nossa gramática, é para ser substituido}.
Aqui um exemplo duma gramática escrita nesse jeito que define
uma linguagem importantíssima que vamos amar bastante,
logo no~\ref[Nat_rec_ind]:

%%}}}

%%{{{ Nat_grammar 
\grammar N, de \wq{Não vou dizer}.
%%%{{{ meta 
\label Nat_grammar
%%%}}}

$$
N \bnfeq \mathrm O \bnfor \mathrm S N
$$

%%}}}

%%{{{ x: generate_some_nats_from_grammar 
\exercise.
%%%{{{ meta 
\label generate_some_nats_from_grammar
%%%}}}

Quais são umas das palavras que podes gerar com a~\ref[Nat_grammar]?
Podes pensar de algum uso para essa linguagem?

\solution
\ref[Nat_rec_ind].

%%}}}

\endsection
%%}}}

%%{{{ Arithmetic_expressions_syntax_vs_semantics 
\section Expressões aritméticas: sintaxe \vs semântica.
%%%{{{ meta 
\label Arithmetic_expressions_syntax_vs_semantics
%%%}}}

%%{{{ precedence 
\note Precedência.
%%%{{{ meta 
\label precedence
\defines
    * precedência
    ;;
%%%}}}

Considere agora a expressão
$$
1 + 5 \ntimes 2
$$
que envolve os numerais $1$, $5$, e $2$,
e os símbolos de funcções $+$ (adição) e $\ntimes$ (multiplicação).
O que ela representa?
A multiplicação de $1+5$ com $2$, ou a adição de $1$ com $5\ntimes 2$?
A segunda opção, graças a uma convenção que temos%
---e que você provavelmente já encontrou na vida.
Digamos que a $\ntimes$ ``pega mais forte'' do que a $+$,
então precisamos ``aplicá-la'' primeiro.
Mais formalmente, a $\ntimes$ tem uma \dterm{precedência} mais alta que a da $+$.
Quando não temos convenções como essa, usamos parenteses para tirar a ambigüidade
e deixar claro como parsear uma expressão.
Então temos
$$
(1 + 5) \ntimes 2 \neq 1 + 5 \ntimes 2 = 1 + (5 \ntimes 2).
$$

%%}}}

%%{{{ syntactic_associativity 
\note Associatividade sintáctica.
%%%{{{ meta 
\defines
    * ~A \syneq ~B  -- igualdade sintáctica
    * associatividade!sintáctica
    * igualdade!semântica
    * igualdade!sintáctica
    ;;
%%%}}}

E a expressão
$$
1+5+2
$$
representa o quê?
Não seja tentado dizer \wq{tanto faz}, pois mesmo que as duas
razoáveis interpretações
$$
(1+5) + 2
\qqqqtext{e}
1 + (5+2)
$$
\emph{denotam valores} iguais, elas expressam algo diferente:
$$
\align
(1 + 5) + 2&: \quad\text{adicione o $1+5$ com o $2$};\\
1 + (5 + 2)&: \quad\text{adicione o $1$ com o $5+2$}.
\endalign
$$
Ou seja: a intensão é diferente, 
Então\dots
$$
(1 + 5) + 2 \askeq 1 + (5 + 2)
$$
Como \emph{expressões} (a \emph{sintaxe}) são diferentes;
como \emph{intensões} também;
como \emph{valores} (a \emph{semântica}) são iguais,
pois denotam o mesmo objeto: o número oito.
Como já discutimos (\reftag[Intension_vs_extension]) em matemática
ligamos sobre as denotações das expressões,
e logo escrevemos igualdades como
$$
(1 + 5) + 2 = 6 + 2 = 8 = 1 + 7 = 1 + (5 + 2).
$$
Lembre que o símbolo \symq{$=$} em geral denota
\dterm{igualdade semântica}:
$A=B$ significa que os dois lados, $A$ e $B$, denotam o mesmo objeto.
Querendo representar \dterm{igualdade sintáctica}, às vezes usamos
outros símbolos.  Vamos usar o \symq{$\syneq$} agora, de modo que:
$$
\align
1 + 2 = 3
&\qqqtext{mas}
1 + 2 \synneq 3;\\
(1 + 5) + 2 = 1 + (5 + 2)
&\qqqtext{mas}
(1 + 5) + 2 \synneq 1 + (5 + 2);
\quad\text{etc.}
\endalign
$$
Voltando à expressão \sq{$1 + 5 + 2$}, precisamos
\emph{declarar uma associatividade esquerda ou direita}.
Vamos concordar que \sq{$a + b + c$} representa a expressão
\sq{$((a + b) + c)$}, ou seja, atribuimos à $+$ uma
\dterm{associatividade esquerda}.
Mas $+$ não é uma operação associativa?
Sim, e isso impica que \emph{como valores},
$$
((a + b) + c) = (a + (b + c)).
$$
Essa associatividade é uma propriedade matemática
(algébrica) da operação $+$.  Umas operações binárias
possuem essa propriedade e as chamamos de \dterm{associativas}
(e.g.~adição, multiplicação) e outras não (e.g.~exponenciação).
No outro lado, a associatividade que \emph{declaramos} acima
não é uma propriedade da operação, não é uma proposição
para demonstrar ou refutar ou nada disso.
É sim uma definição sintáctica, e logo chamamos de
\dterm{associatividade sintáctica}.
Sem essa convenção \sq{$a + b + c$} não representaria
nenhuma expressão de aritmética!

%%}}}

%%{{{ x: syneq or semeq? 
\exercise.
%%%{{{ meta 
\label syneq_or_semeq
%%%}}}

Sejam $a,b,c$ números naturais.
Usando $=$ para igualdade semântica e $\syneq$ para igualdade
sintáctica, decida para cada uma das afirmações seguintes
se é verdadeira ou falsa:
% TODO: fix reflabs
\elist i:
\li: $a + b + c                \syneq  a + (b + c)$
\li: $a + b + c                \syneq  (a + b) + c$
\li: $a + b + c                =       a + (b + c)$
\li: $a + b + c                =       (a + b) + c$
\li: $2 \ntimes 0 + 3          =       0 + 3$
\li: $2 \ntimes 0 + 3          \syneq  0 + 3$
\li: $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \syneq  1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \syneq  2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          =       2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li: $1 + 2                    \syneq  2 + 1$
\endelist

\solution
Temos:
\elist i:
\li: $a + b + c                \synneq a + (b + c)$
\li: $a + b + c                \syneq  (a + b) + c$
\li: $a + b + c                =       a + (b + c)$
\li: $a + b + c                =       (a + b) + c$
\li: $2 \ntimes 0 + 3          =       0 + 3$
\li: $2 \ntimes 0 + 3          \synneq 0 + 3$
\li: $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \synneq 1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \synneq 2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \neq    2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li: $1 + 2                    \synneq 2 + 1$
\endelist

%%}}}

%%{{{ x: syntactic_implies_semantic 
\exercise.
%%%{{{ meta 
\label syntactic_implies_semantic
%%%}}}

Verdade ou falso?:
$$
A \syneq B \implies A = B
$$

%%}}}

\endsection
%%}}}

%%{{{ Language_vs_metalanguage 
\section Linguagem \vs metalinguagem.
%%%{{{ meta 
\label Language_vs_metalanguage
%%%}}}

%%{{{ metalanguage 
\note (Meta)linguagem.
%%%{{{ meta 
\label metalanguage
\defines
    * linguagem-objeto
    * metalinguagem
    ;;
%%%}}}

Já encontramos o conceito de linguagem como um objeto de estudo.
Logo vamos estudar bem mais linguagens, de lógica matemática,
estudar linguágens de programação, etc.
É preciso entender que enquanto estudando uma linguagem,
esse próprio estudo acontece também usando uma (outra) linguagem.
Aqui usamos por exemplo português,\foot
quase
\toof
demonstrando propriedades, dando definições,
afirmando relações, etc., de outras linguagens que estudamos,
como da aritmética, de lógica matemática, de programação, etc.
Para enfatizar essa diferença e para tirar certas ambigüidades,
chamamos \dterm{linguagem-objeto} a linguagem que estudamos,
e \dterm{metalinguagem} a linguagem que usamos para falar
sobre a linguagem-objeto.
Note que todos os símbolos \symq{$\iffsymbol$}, \symq{$\impliessymbol$},
e~\symq{$\impliedbysymbol$} fazem parte da \emph{metalinguagem},
e não é para confundir com os \symq{${\liff}$}, \symq{${\limplies}$},
e~\symq{${\limplied}$} que geralmente usamos como símbolos de
certas \emph{linguagens formais} de lógica.

%%}}}

%%{{{ metavariables 
\note (Meta)variável.
%%%{{{ meta 
\label metavariables
\defines
    * metavariável
    ;;
%%%}}}

Imagine que você trabalha como programador e teu chefe lhe pediu
fazer uma mudança no código de todos os teus programas escritos na linguagem de
programação C.
Ele disse:
\wq{Em todo programa teu $\Pi$, substitua cada variável $\alpha$
de tipo $\tau$ que aparece no código fonte por para
$\alpha\code{\_of\_}\tau$.}
\wq{Por exemplo,} ele continuou abrindo o programa no seu editor,
\wq{essa variável aqui $\code{i}$ que é de tipo $\code{int}$,
precisa ser renomeada para $\code{i\_of\_int}$;
e essa $\code{count}$ também para $\code{count\_of\_int}$;
e essa $\code{mean}$ de tipo $\code{float}$, para $\code{mean\_of\_float}$,
etc.}.
\eop
Nesse pedido---obviamente sem noção, algo muito comum em pedidos de chefes
de programadores---aparecem duas ``espécies'' de variáveis diferentes:
as $\Pi$, $\alpha$, e $\tau$ são variáveis de uma espécie;
as $\code{i}$, $\code{i\_of\_int}$,
$\code{count}$, $\code{count\_of\_int}$,
$\code{mean}$, e $\code{mean\_of\_float}$
de outra.
Chamamos as $\Pi$, $\alpha$, e $\tau$ de \dterm{metavariáveis},
pois elas pertencem à metalinguagem, e não à linguagem-objeto,
que nesse exemplo é a linguagem de programação C.
Observe que a metavariável $\Pi$ denota programas escritas na linguagem-objeto (C)
a metavariável $\alpha$ denota variáveis de C,
e a metavariável $\tau$ denota tipos da C.

%%}}}

\endsection
%%}}}

%%{{{ Abbreviations and syntactic sugar 
\section Abreviações e açúcar sintáctico.
%%%{{{ meta 
\label Abbreviations_and_syntactic_sugar
%%%}}}

%%{{{ x: ArEx_outer_parentheses_missing 
\exercise.
%%%{{{ meta 
\label ArEx_outer_parentheses_missing
%%%}}}

Tente gerar a expressão
$$
(1 + 5) \ntimes 2
$$
usando a~\ref[ArEx_grammar_2].

\solution
Não tem como!

%%}}}

%%{{{ abbreviations 
\note Abreviações.
%%%{{{ meta 
\label abbreviations
\defines
    * abreviação
    ;;
%%%}}}

Seguindo nossa~\ref[ArEx_grammar_2], cada vez que escrevemos um
operador binário começamos e terminamos com \symq{$($} e \symq{$)$}
respectivamente.
Logo, \sq{$1 + 2$} nem é uma expressão gerada por essa gramática!
Mas como é tedioso botar as parenteses mais externas,
temos a convenção de omiti-las.
Logo, consideramos a \sq{$1 + 2$} como uma \dterm{abreviação}
da expressão aritmética \sq{$(1 + 2)$}.
Então qual é o primeiro caráter da \sq{$1 + 2$}?
É sim o \symq{$($}, pois consideramos o $1+2$ apenas como um nome
que usamos na metalinguagem para denotar a expressão aritmética
\sq{$(1+2)$}, que pertence à linguagem-objeto.

%%}}}

%%{{{ beware: abbr_not_always_shorter 
\beware.
%%%{{{ meta 
\label abbr_not_always_shorter
%%%}}}

Não se iluda com a palavra ``abreviação'' que usamos aqui:
uma expressão pode ser mais curta do que uma das suas abreviações!
Nosso motivo não é preguiça de escrever;
mas sim ajudar nossos olhos humanos a parsear.

%%}}}

%%{{{ syntactic_sugar 
\note Açúcar sintáctico.
%%%{{{ meta 
\label syntactic_sugar
\defines
    * ~A \sugeq ~B   -- açúcar sintáctico de objeto
    * ~A \sugiff ~B  -- açúcar sintáctico de proposição
    * açúcar sintáctico
    ;;
%%%}}}

Querendo enriquecer uma linguagem com um novo conceito, uma nova operação,
etc., parece que precisamos aumentar sua sintaxe para adicionar certos
símbolos e formas para corresponder nessas novas idéias.
Mas isso não é sempre necessário.
Por exemplo, suponha que trabalhamos com a linguagem da~\ref[ArEx_grammar_3],
e queremos usá-la com sua interpretação canônica, onde suas expressões
aritméticas geradas denotam realmente as operações que conhecemos desde
pequenos.
Agora, queremos adicionar uma operação unária $S$, escrita na forma prefixa,
onde a idéia é que $Sn$ denota o sucessor de $n$ (o próximo inteiro):
$$
Sn \sugeq n + 1
$$
Nesse caso, em vez de realmente alterar a sintaxe da nossa linguagem,
podemos definir como \dterm{açúcar sintáctico} o uso de $S$ tal que,
para qualquer expressão aritmética $\alpha$, o $S\alpha$ denota a
expressão $(\alpha + 1)$.
Por exemplo, $S4$ é apenas uma abreviação para o $(4 + 1)$,
e $SS4$ só pode denotar o $((4 + 1) + 1)$.\foot
Percebeu que esse $\alpha$ aqui é uma metavariável?
\toof
Açúcar sintáctico é muito usado em linguagens de programação,
para agradar os programadores (que ganham assim um mecanismo
``doce'' para usar nos seus programas) sem mexer e complicar
a linguagem de verdade.
Para um exemplo mais perto da vida real, imagine que numa
linguagem orientada a objetos, certos objetos escutem às
mensagens \sq{$\code{.set(\mathit i,\mathit v)}$}
e \sq{$\code{.get(\mathit i)}$} a idéia sendo que utilizamos
a primeira método para atribuir o valor $v$ à posição $i$
e a segunda para solicitar em tal posição.
Mas ninguém merece escrever isso, e logo introduzimos:
$$
\alignat2
&\code{\mathit a[\,\mathit i\,] = \mathit v} &&\quad\sugeq\quad \code{\mathit a.set(\mathit i,\mathit v)} \\
&\code{\mathit a[\,\mathit i\,]}             &&\quad\sugeq\quad \code{\mathit a.get(\mathit i\/)}
\endalignat
$$
Observe que esse açúcar não é um simples \emph{search and replace}
do padrão \sq{$\code{\mathit a[\,\mathit i\,]}$},
pois seu sentido muda dependendo de se aparece no lado esquerdo duma
atribuição (primeira linha) ou não (segunda linha).

%%}}}

%%{{{ x: for_while_sugar 
\exercise.
%%%{{{ meta 
\label for_while_sugar
%%%}}}

Mostre como um $\code{while}$ loop pode ser implementado como
açúcar sintáctico numa linguagem que tem $\code{for}$ loops
mas não $\code{while}$ loops,
e vice versa.

%%}}}

%%{{{ x: recursion_loop_sugar 
\exercise.
%%%{{{ meta 
\label recursion_loop_sugar
%%%}}}

Mostre como um $\code{for}$ loop no estilo da linguagem C
pode ser implementado sem usar nenhum dos loops disponíveis
em C (for, while, do-while).

\hint
Recursão.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: decimal_numerals_BNF_problem
\problem.
%%%{{{ meta 
\label decimal_numerals_BNF_problem
%%%}}}

Usando BNF, defina uma gramática para a linguagem de todos os
numerais que representam os naturais no sistema decimal.
Embuta-la na gramática das expressões aritméticas
para eliminar os ``$\dotsb$''.

%%}}}

%%{{{ prob: remove_dots_from_ArEx_grammar 
\problem.
%%%{{{ meta 
\label remove_dots_from_ArEx_grammar
%%%}}}

Com base a~\ref[ArEx_grammar_3] defina uma gramática que gera a mesma linguagem,
sem usar ``$\dotsb$''.

\hint
Já resolveu o~\ref[decimal_numerals_BNF_problem]?

%%}}}

%%{{{ prob: ArEx_fact_grammar 
\problem.
%%%{{{ meta 
\label ArEx_with_factorial
%%%}}}

Aumente tua gramática do~\ref[remove_dots_from_ArEx_grammar] para
gerar expressões aritméticas que usam o operador unitário (e postfixo)
do factorial, que denotamos com $!$, escrevendo por exemplo
$8!$ para o factorial de $8$.
Note que não usamos parenteses para aplicar o factorial:
$$
((2 + 3!)! \ntimes 0!!)
$$

%%}}}

%%{{{ prob: ArEx_fact_vars_grammar 
\problem.
%%%{{{ meta 
\label ArEx_fact_vars_grammar
%%%}}}

Aumenta tua gramática do~\ref[ArEx_with_factorial] para
gerar expressões aritméticas que usam as variáveis
$$
x,y,z,
x',y',z',
x'',y'',z'',
x''',y''',z''',
\dotsc
$$

%%}}}

%%{{{ prob: polish_notation 
\problem Notação polonesa.
%%%{{{ meta 
\label polish_notation
\indexes
    * Polonesa!notação    seealso: Łukasiewicz
    ;;
\defines
    * Polonesa!notação
    ;;
\credits
    * Lukasiewicz : notação
    ;;
%%%}}}

Demonstre que não podemos simplesmente apagar as parenteses
da nossa gramática de $\bnf{ArEx}$ sem perder uma propriedade
importantíssima da nossa linguagem (qual?).
Experimente com a gramática
$$
\align
\bnf{PolArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx} \tag{0}\\
\bnf{Num}      &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{OpEx}     &\bnfeq \bnf{BinOp} \bnf{PolArEx} \bnf{PolArEx}\tag{2}\\
\bnf{BinOp}    &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$
Escreva uns dos seus termos.
Supondo que cada símbolo de $\bnf{Num}$ é apenas um símbolo
(por exemplo o \symq{$15$} é um símbolo atômico e não algo composto
dos \symq{$1$} e \symq{$5$}),
observe que com essa notação (chamada \dterm{notação Polonesa} ou
\dterm{notação Łukasiewicz}) não precisamos de parenteses!
Como escreverias nessa linguagem as expressões correspondentes às:
$$
1 + 2;
\qquad
3\ntimes(2 + 4) + 6;
\qquad
2 \ntimes 3 + 3 \ntimes (7 + 8\ntimes 2)\,?
$$

%%}}}

%%{{{ grammar: NatList_grammar 
\grammar.
%%%{{{ meta 
\label NatList_grammar
%%%}}}

$$
\align
\bnf{L} &\bnfeq [\,] \bnfor (\bnf{Nat} : \bnf{L})\\
\intertext{onde $\bnf{Nat}$ é o}
\bnf{Nat} &\bnfeq 0 \bnfor S\bnf{Nat}
\endalign
$$
da~\ref[Nat_grammar].

%%}}}

%%{{{ prob: NatList_grammar_problem 
\problem.
%%%{{{ meta 
\label NatList_grammar_problem
%%%}}}

Escreva umas expressões geradas por a~\ref[NatList_grammar]
e ache um possível uso da linguagem definida por ela.

%%}}}

\endproblems
%%}}}

%%{{{ A_propositional_language 
\section Uma linguagem proposicional.
%%%{{{ meta 
\label A_propositional_language
%%%}}}

%%{{{ atomic_vs_composite_prop 
\note Atômicas \vs compostas.
%%%{{{ meta 
\label atomic_vs_composite_prop
%%%}}}

Queremos desenvolver uma linguagem para escrever proposições do tipo que encontramos em matemática.
A idéia é que as proposições ou são \dterm{atómicas} (diretamente afirmando algo) ou \dterm{compostas} por outras sub-proposições que conectamos com os \dterm{conectivos lógicos}:

%%}}}

%%{{{ logical_connectives_prop 
\note Conectivos lógicos.
%%%{{{ meta 
\label logical_connectives_prop
%%%}}}

Considere os seguintes
$$
\xalignat2
\text{conjuncção}:    && (A \land B)       &\qqtext{significa} \textwq{$A$ e $B$} \\
\text{disjuncção}:    && (A \lor B)        &\qqtext{significa} \textwq{$A$ ou $B$} \\
\text{implicação}:    && (A \limplies B)   &\qqtext{significa} \textwq{se $A$ então $B$} \\
\text{equivalência}:  && (A \liff B)       &\qqtext{significa} \textwq{$A$ se e somente se $B$} \\
\text{negação}:       && \lnot A           &\qqtext{significa} \textwq{não $A$}.
\endxalignat
$$
onde os $A,B$ denotam proposições.
O que cada uma dessas cinco proposições significa mesmo, vamos deixar para depois.\foot
Também deixamos para depois a pergunta ainda mais interessante:
o que significa responder na pergunta \wq{O que significa $(A \lor B)$?}?
\toof
Considero que o leitor já tem uma idéia básica sobre o significado de cada uma
dessas frases, e também considero que provavelmente tem uns mal-entendidos também,
e logo não precisa se preocupar agora com seu significado.
Analizamos cada um deles logo no~\ref[Proofs] (e aprofundamos ainda mais nos
\reftag[Mathematical_logic], \reftag[Proof_theory], \reftag[Intuitionistic_logic]).
Agora quero discutir só a sintaxe: \emph{como definir uma linguagem cujo
objetivo é representar esse tipo de proposições}.

%%}}}

%%{{{ examples_of_propositions 
\note.
%%%{{{ meta 
%%%}}}

Considere as seguinte proposições:
% TODO: fix reflabs
\elist:
\li: Se $x < y$ e $y < z$ então $z < x$.
\li: $\sqrt 2$ é irracional.
\li: $5$ é primo
\li: $5$ é primo ou par
\li: $5$ é primo ou $8$ é primo
\li: O $5$ é um divisor dos $25$ e $26$.
\li: Se $p$ é primo então: $p$ divide $8$ se e somente se $p$ é par
\li: Eu não sei onde $p$ nasceu.
\endelist

%%}}}

%%{{{ Its syntax 
\note Sua sintaxe.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Givens 
\note Variáveis proposicionais.
%%%{{{ meta 
\indexes
    * metavariável
    * variável!proposicional
    * variável
    ;;
%%%}}}

Considere dado o conjunto dos símbolos
$$
\zolvars = \set{ \lsym p_0, \lsym p_1, \lsym p_2, \dotsc }
$$
chamados \dterm{variáveis proposicionais}.
Não importa quais são esses símbolos; o que ímporta é que temos
uma infinidade deles, e planejamos usá-los
para representar proposições atômicas.
Esses símbolos então são \emph{variáveis da linguagem-objeto}.
E vamos usar as \emph{metavariáveis} $p,q,r,\dots$ para representá-los.
(Lembre da~\ref[Language_vs_metalanguage]).
Observe que metavariáveis diferentes não necessariamente representam
variáveis diferentes, mesmo que muitas vezes isso é implícito pelo contexto.
Por exemplo, querendo traduzir a proposição
$$
\textwq{$5$ é primo ou par}
$$
podemos escolher atribuir os significados
$$
\rightbrace {
\aligned
\lsym p_0 & : \textwq{$5$ é primo} \\
\lsym p_1 & : \textwq{$5$ é par}
\endaligned
}
\qqtext{e logo usar}
\lsym p_0 \lor \lsym p_1
$$
mas também poderiamos ter escolhido
$$
\rightbrace {
\aligned
\lsym p_9 & : \textwq{$5$ é primo} \\
\lsym p_2 & : \textwq{$5$ é par}
\endaligned
}
\qqtext{e logo usar}
\lsym p_9 \lor \lsym p_2
$$
etc.
Mesmo quando as escolhas são poucas (como aqui),
\emph{preferimos usar metavariáveis} escrevendo
$$
\rightbrace {
\aligned
p & : \textwq{$5$ é primo} \\
q & : \textwq{$5$ é par}
\endaligned
}
\qqtext{e logo usar}
p \lor q
$$
pois \emph{não importa qual} dos símbolos escolhemos para a proposição \wq{$5$ é primo}
e qual para a \wq{$5$ é par}, o importante é que temos dois deles e conseguimos formar a expressão que queremos.

%%}}}

\TODO
Começar com duas definições erradas:
uma sem parens outra com conectivos apenas entre atômicas.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Finalmente chegamos na definição correta do que é uma fórmula:

%%}}}

%%{{{ df: propositional_formula 
\definition Fórmula.
%%%{{{ meta 
\label propositional_formula
\defines
    * fórmula!atômica
    * fórmula!proposicional
    ;;
%%%}}}

\tlist:
\li (A): Se $p$ é uma variável proposicional, então $p$ é uma fórmula.
\li (N): Se $F$ é uma fórmula, então $\lnot F$ é uma fórmula.
\li (B): Se $F,G$ são fórmulas, então:
         \tlist: \withtag --
         \li: $(F \limplies G)$ é uma fórmula;
         \li: $(F \lor G)$ é uma fórmula;
         \li: $(F \land G)$ é uma fórmula.
         \endtlist
\endtlist
Nada mais é uma fórmula.
Uma fórmula que consiste em apenas uma variável proposicional é chamada
\dterm{fórmula atômica}.

%%}}}

%%{{{ grammar: zolang_grammar 
\grammar.
%%%{{{ meta 
\label zolang_grammar
%%%}}}

Escrevemos
$$
\align
F &\bnfeq A \bnfor \lnot F \bnfor (F \limplies F) \bnfor (F \land F) \bnfor (F \lor F)\\
\intertext{onde $A$ denota as fórmulas atômicas da $\zolang$, ou seja as variáveis proposicionais:}
A &\bnfeq \lsym p_0 \bnfor \lsym p_1 \bnfor \lsym p_2 \bnfor \dotsb
\endalign
$$

%%}}}

%%{{{ x: metavar_vs_vats_in_propositional_formula 
\exercise.
%%%{{{ meta 
%%%}}}

No texto da \ref[propositional_formula], identifique todas as metavariáveis
e todas as variáveis (veja~\reftag[Language_vs_metalanguage], \reftag[metavariables]).


%%}}}

%%{{{ Sugar 
\note Açúcar.
%%%{{{ meta 
%%%}}}

Se $F,G$ são fórmulas, usamos as seguintes abreviações:
$$
\align
(F \liff G)     &\sugareq ((F \limplies G) \land (G \limplies F))\\
(F \limplied G) &\sugareq (G \limplies F)
\endalign
$$

%%}}}

%%{{{ x: second_character_of_limplied_abbr 
\exercise.
%%%{{{ meta 
\label second_character_of_limplied_abbr
%%%}}}

Qual é o segundo caráter da fórmula $(A \limplied B)$?

\hint
Lembre-se que aqui $A,B$ são apenas \emph{metavariáveis}
que denotam algumas fórmulas, sobre quais não sabemos nada mais
fora do fato que são fórmulas (bem formadas).

\solution
O primeiro caráter da fórmula $B$.

%%}}}

%%{{{ Parentheses 
\note Parenteses.
%%%{{{ meta 
%%%}}}

Nos permitimos ``esquecer'' as parenteses mais externas
duma fórmula.
$$
F \limplies G \abbreq (F \limplies G).
$$

%%}}}

%%{{{ Precedences 
\note Precedências.
%%%{{{ meta 
%%%}}}

Não vamos escolher nenhuma das $\land$, $\lor$ para considerá-la
mais forte, ou seja, \emph{nunca} vamos escrever algo do tipo
$$
F \lor G \land H.
$$
Por outro lado é comum considerar que elas têm precedência contra
a $\limplies$: com as
$$
F \limplies G \land H
\qqtext{e}
F \lor G \limplies H
$$
denotamos as fórmulas
$$
(F \limplies (G \land H))
\qqtext{e}
((F \lor G) \limplies H)
$$
respectivamente.
Mesmo assim, eu vou tentar botar essas parenteses quando considero
que ajudam na leitura da fórmula!

%%}}}

%%{{{ Associativities 
\note Associatividades.
%%%{{{ meta 
\indexes
    * associatividade!sintáctica
    ;;
%%%}}}

Atribuimos às $\land$ e $\lor$ uma associatividade à esquerda,
e a $\limplies$ uma associatividade à direita.
Pela semântica desejada a primeira escolha é arbitraria,
pois a conjuncção e a disjuncção são operações \emph{associativas}.
Mas a implicação não é.  Nossa escolha então importa!

%%}}}

%%{{{ Its semantics 
\note Sua semântica.
%%%{{{ meta 
%%%}}}

Definimos então a \emph{sintaxe} da nossa linguagem.
Mas por enquanto nenhuma das suas expressões válidas
tem significado!
A gente deixou claro o que é uma fórmula, mas não
o que ela \emph{denota}.
Neste capítulo não vamos definir formalmente alguma
\emph{semântica} para nossa linguagem.
Pelo contrário, usando exemplos e umas explicações
\emph{informais}, eu vou dar uma primeira idéia do que
todas essas fórmulas significam.
O importante é conseguir traduzir uma afirmação escrita
em portugues numa fórmula dessa linguagem, pois assim
ficará mais clara a \emph{estrutúra lógica} que tá
escondida atrás das palavras (e suas ambigüidades)
da linguagem natural.
Depois de bastante trabalho vamos voltar para a questão
de \emph{definir formalmente uma semântica}
para essa linguagem.
Essa tarefa vai nos preocupar nos capítulos
\reftag[Mathematical_logic], \reftag[Denotational_semantics],
\reftag[Intuitionistic_logic], \reftag[Proof_theory].
Por enquanto, deixe pra lá!

%%}}}

%%{{{ x: limplies_is_not_associative 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique com um exemplo que realmente, em geral
$$
A \limplies (B \limplies C)
\qqtext{não é equivalente a}
(A \limplies B) \limplies C.
$$

%%}}}

%%{{{ x: land_lor_need_parens 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique com exemplos que em geral
$$
\align
A \land (B \lor  C) &\qqtext{não é equivalente a} (A \land B) \lor  C \\
A \lor  (B \land C) &\qqtext{não é equivalente a} (A \lor  B) \land C.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ ZOL_limitations 
\section Limitações da linguagem de proposições.
%%%{{{ meta 
\label ZOL_limitations
%%%}}}

%%{{{ related propositions seem unrelated 
\note.
%%%{{{ meta 
%%%}}}

Considere a afirmação
\quote
Se Igor é brasileiro ele toca violão.
\endquote
Qual é a melhor maneira para traduzir essa afirmação na
nossa linguagem de lógica proposicional?
Estamos procurando então uma \emph{fórmula} da $\zolang$
que poderia representar essa afirmação.
Podemos usar a fórmula seguinte:
$$
(P_0 \limplies P_1)
$$
mas precisamos ainda declarar quais são as proposições
denotadas por as variáveis proposicionais que usamos ($P_0$ e $P_1$).
A escolha é óbvia:
$$
\align
P_0 &:\ \text{Igor é brasileiro}\\
P_1 &:\ \text{Igor toca violão}
\endalign
$$
Note aqui que $P_0$ não poderia ser ``ele toca violão'', pois
na afirmação original esse ``ele'' refere ao Igor, então seria
errado mudar isso para o indefinido e ambiguo ``ele''.
Tudo bem até agora, mas como vamos traduzir as frases:
% TODO: fix reflabs
\tlist:
\li (1): Se Thanos é brasileiro ele toca violão.
\li (2): Se Igor é brasileiro ele toca piano.
\li (3): Se Igor é grego ele toca violão.
\endtlist
Note que cada uma dessas proposições afirma algo muito parecido
com a original, e mesmo assim o melhor jeito que temos
para representar cada uma delas, é:
$$
\align
&(P_2 \limplies P_3)\\
&(P_0 \limplies P_4)\\
&(P_5 \limplies P_1)
\endalign
$$
O problema é que perdemos muita informação nessa traduação,
e olhando apenas para essas fórmulas não conseguimos ver
as conexões que alguém vê lendo as afirmações escritas na
lingua natural acima.

%%}}}

%%{{{ zolang_is_way_too_poor_for_some_propositions 
\note.
%%%{{{ meta 
%%%}}}

Até pior, vamos tentar traduzir a afirmação seguinte:
\quote
Todo brasileiro que fala grego toca piano.
\endquote

%%}}}

%%{{{ Q: what is the best way you can translate this to zolang? 
\question.
%%%{{{ meta 
%%%}}}

Qual é a melhor forma que você consegue traduzir essa proposição para a linguagem
$\zolang$?

%%}}}

\spoiler

%%{{{ a_wrong_translation_to_zolang 
\note.
%%%{{{ meta 
%%%}}}

Uma tentativa errada seria pensar numa fórmula como
$$
((B \land G) \limplies P)
$$
onde escolhendo as proposições denotadas por nossos
$B$, $G$, e $P$, acabamos falando algo sem sentido:
$$
\align
B &: \text{todo brasileiro}\\
G &: \text{alguém que fala grego}\\
P &: \text{ele toca piano}
\endalign
$$
ou algo parecido com isso.
Agora pare e resolva o exercício seguinte:

%%}}}

%%{{{ x: what_is_wrong_with_this_translation_to_zolang 
\exercise.
%%%{{{ meta 
%%%}}}

Qual o problema com essa tradução?

%%}}}

%%{{{ we accept the best is the worst 
\note.
%%%{{{ meta 
%%%}}}

Infelizmente temos que aceitar que a melhor tradução que conseguimos
é denotar a afirmação inteira por alguma variável proposicional.
Ou seja, pelos olhos da $\zolang$, essa é uma afirmação atômica.

%%}}}

%%{{{ x: zolang_limitation_examples 
\exercise.
%%%{{{ meta 
\label zolang_limitation_examples
%%%}}}

Para um exemplo ``mais matemático'', considere as proposições:
\elist:
\li: Para todo inteiro $n$, se $n$ é primo e $n>2$, então $n+2$ é primo.
\li: Existem $n > 2$ e inteiros positivos $a,b,c$, tais que $a^n + b^n = c^n$.
\li: Uma linguagem é regular se e somente se ela é reconhecida por um autômato finito.
\li: Um espaço topológico é normal se e somente se quaisquer dois conjuntos disjuntos e fechados podem ser separados por uma funcção contínua.
\li: Para todo $\alpha\neq0$ algébrico, $e^\alpha$ é transcendental.
\endelist
Qual é a melhor tradução de cada uma dessas na linguagem $\zolang$?

%%}}}

\endsection
%%}}}

%%{{{ FOLs 
\section Linguagens de predicados.
%%%{{{ meta 
\label FOLs 
%%%}}}

%%{{{ the alphabet 
\note O alfabeto.
%%%{{{ meta 
%%%}}}

Pelas limitações da linguagem da lógica proposicional que encontramos
já na~\reftag[ZOL_limitations] faz sentido adicionar pelo menos os dois
símbolos que correspondem nos quantificadores ``para todo'' e ``existe'',
além do resto dos símbolos que já temos:
$$
\lnot, \limplies, \land, \lor, \forall, \exists
$$
\eop
O que mais vamos precisar?
Com certeza precisamos uma nova infinidade de símbolos para \emph{variáveis}
$$
\lsym x_0, \lsym x_1, \lsym x_2, \dots
$$
Essas variáveis não tem nada a ver com as variáveis proposicionais,
pois elas não denotam proposições, mas objetos (indivíduos).
\eop
Que mais?
Faria sentido permitir símbolos de \emph{nomes} ou \emph{constantes}
para denotar certos indivíduos.  Por exemplo, estudando números,
$3$ e $\pi$ são constantes, símbolos que assim que determinar uma
linguagem, eles vão sempre denotar o mesmo objeto.
Observe que não faz sentido falar <<existe $3$ tal que\dots>>
nem <<para todo $3$ \dots>>.  Nossa sintaxe deve proibir essas
abominagens.\foot
Mesmo assim, isso já aconteceu na turma do meu amigo Fagner:
corrigindo provas de cálculo ele viu a frase ``$\forall 3 > 0$''.
Um aluno que, enquanto colando na prova, provavelmente pensou
que seu colega tinha errado no ``$\forall \epsilon > 0$'' escrevendo
o $3$ de cabeça pra baixo.
Depois dele, muitos mais alunos acabaram entregando essa prova com
``$\forall 3 > 0$''.  Ai ai\dots
\toof
Adicionamos então símbolos para constantes
$$
c,d,e,\dots
$$
\eop
Que mais?
Bem, se é para conseguir \emph{formular afirmações sobre objetos},
vamos precisar símbolos para \emph{predicados} que recebem argumentos.
E com eles vamos substituir os símbolos de variáveis proposicionais.
Já discutimos (\reftag[ZOL_limitations]) que uma das limitações que
queremos atender com essa nova linguagem é que afirmações bem parecidas
acabam sendo denotadas por fórmulas que não tem nada em comum:
nossa melhor tradução das afirmações \wq{$8$ é múltiplo de $2$}
e \wq{$10$ é múltiplo de $3$} é algo do tipo $\lsym p_0$ para uma e
$\lsym p_1$ para a outra.
Não serve.  Queremos conseguir usar algo do tipo $P(8,2)$ para uma
e $P(10,3)$ para a outra, onde o $P$ \emph{é o mesmo símbolo},
preservando assim a conexão entre as afirmações.
Jogamos fora então todos os símbolos de variáveis proposicionais
para usar símbolos de \emph{predicados}:
$$
P, Q, R, \dots
$$
e bora botar a virgula \symq{$,$} também para separar os argumentos.
\eop
Algo mais?
Sim, precisamos de uma última coisa.
Símbolos para denotar \emph{funcções}.
Eles nos permitem apontar para algum individual dados outros.
Por exemplo \wq{a mãe da Bárbara}; ou $\lsym x_0 + \sin(\pi)$
que seria \wq{a soma do $\lsym x_0$ com o seno do $\pi$}, etc.
Aqui a gente usaria símbolos como $\lsym{mother}$, $+$, $\ntimes$,
$\sin$, $\cos$, nos números.
Vamos adicionar então símbolos de \emph{funcções}
$$
f, g, h, \dots
$$
e pronto.
Então o alfabéto duma linguagem FOL parece assim:
$$
\def\symsnames##1##2{\tubrace{\;\vphantom {g_g} ##1\;} {##2}}
\symsnames {\lnot\ \limplies\ \land\ \lor\ \forall\ \exists\;} {lógica}\ 
\symsnames {(\ )\ ,\;} {puntuação}\ 
\symsnames {\lsym x_0\ \lsym x_1\ \lsym x_2\ \dots\;} {variáveis}\ 
\symsnames {c\ d\ e\ \dots\;} {constantes}\ 
\symsnames {f\ g\ h\ \dots\;} {funcções}\ 
\symsnames {P\ Q\ R\ \dots\;} {predicados}.
$$

%%}}}

%%{{{ givens_for_a_FOL 
\note Os dados para uma linguagem de FOL.
%%%{{{ meta 
%%%}}}

Um conjunto infinito de símbolos de variáveis
$$
\folvars  = \set{\lsym x_0, \lsym x_1, \lsym x_2, \lsym x_3, \dotsc}.
$$
Conjuntos de símbolos de constantes, de funcções, e de predicados:
$$
\folcons,\quad
\folfuns,\quad
\folpreds.
$$
Vamos separar os símbolos de funcções por \dterm{aridade},
ou seja, por a quantidade de argumentos que ele necessita ``consumir''.
Similarmente para os símbolos de predicados, escrevendo assim
$\folfuns_n$ e $\folpreds_n$, para o conjunto de símbolos de funcções
e de predicados de aridade $n$ respectivamente.

%%}}}

%%{{{ remark: nullary functions as constants 
\remark.
%%%{{{ meta 
%%%}}}

Podemos usar funcções de aridade $0$ como constantes,
e assim nem precisamos um conjunto especial para esses símbolos.
Mesmo assim, não vamos fazer isso aqui.
Questão de gosto.\foot
Mentira.
Tem uns detalhes inessenciais neste momento sobre essa escolha.
Vamos discutir isso no~\ref[Mathematical_logic].
\toof

%%}}}

%%{{{ remark: alternative approach with arity metafunction 
\remark.
%%%{{{ meta 
%%%}}}

Alternativamente, podemos deixar os símbolos de aridades
diferentes juntos e exigir uma funcção $\folarity$ que
atribua a cada deles sua aridade.
Por exemplo, numa FOL que usariamos para cálculo, faria
sentido ter símbolos $\lsym +,\lsym{cos},\lsym{<}$ entre outros, com aridades
$\folarity(\lsym{+}) = 2$, $\folarity(\lsym{cos}) = 1$,
$\folarity(\lsym{<}) = 2$, etc.
As duas abordagens são equivalentes:
$$
\align
f \in \folfuns_n  &\iff f \in \folfuns  \mland \folarity(f) = n\\
P \in \folpreds_n &\iff P \in \folpreds \mland \folarity(P) = n.
\endalign
$$
Vamos discutir mais sobre isso no~\ref[Mathematical_logic].

%%}}}

%%{{{ eg: FOL_example_number_theory 
\example.
%%%{{{ meta 
\label FOL_example_number_theory
%%%}}}

Para estudar teoria dos números alguém poderia escolher essa linguagem:
$$
\align
\folcons    &= \set{\lsym 0, \lsym 1, \lsym 2, \dots} \\
\folfuns_1  &= \set{{-}} \\
\folfuns_2  &= \set{{+}, {\cdot}, \lsym{gcd}} \\
\folpreds_1 &= \set{\lsym{Prime}, \lsym{Even}, \lsym{Odd}, \lsym{IsZero}} \\
\folpreds_2 &= \set{{=}, {<}, {\leq}, {\divides}}
\endalign
$$
Note que aqui o símbolo \symq{$-$} foi escolhido para ter aridade $1$.
O usuário dessa linguagem vai usá-lo para representar a operação
unária de negação de números, para formas termos como os:
$-1$, $-(1 + x)$, etc.

%%}}}

%%{{{ eg: FOL_example_people 
\example.
%%%{{{ meta 
\label FOL_example_people
%%%}}}

Para estudar pessoas e suas relações uma linguagem poderia ser:
$$
\align
\folcons    &= \set{\lsym{Thanos}, \lsym{Ramile}, \lsym{Eva}, \lsym{Sam}, \lsym{Maroui}, \lsym{Jebinos}} \\
\folfuns_1  &= \set{\lsym{mother}, \lsym{father}} \\
\folpreds_1 &= \set{\lsym{Male}, \lsym{Female}, \lsym{Adult}, \lsym{Mother}, \lsym{Father}, \lsym{Brazilian}, \lsym{Greek}} \\
\folpreds_2 &= \set{=, \lsym{Loves}, \lsym{SiblingOf}, \lsym{MotherOf}, \lsym{FatherOf}}
\endalign
$$
Qual a diferença entre os símbolos $\lsym{mother}$ e $\lsym{Mother}$?
Ambos são símbolos de aridade $1$, mas $\lsym{mother}$ é um símbolo de funcção
e $\lsym{Mother}$ é um símbolo de predicado.
O que isso quis dizer?
Suponha que $p$ é qualquer objeto do meu mundo (vamos pensar em pessoas).
A expressão $\lsym{mother}(p)$ vai acabar denotando um objeto do meu mundo
também.  A intenção do criador dessa linguagem provavelmente foi que
$\lsym{mother}(p)$ denota a mãe de $p$.
Similarmente, $\lsym{mother}(\lsym{mother}(p))$ denota a mãe da mãe
da pessoa $p$.  E por aí vai.
No outro lado, a expressão $\lsym{Mother}(p)$ não denota pessoa, mas
sim uma afirmação \emph{sobre} a pessoa $p$.  Adivinhando novamente
a intenção do criador, a proposição $\lsym{Mother}(p)$ afirma que
a pessoa $p$ \emph{é uma mãe}.
E o símbolo $\lsym{MotherOf}$?
Como ele tem aridade $2$, ele precisa de $2$ objetos, e assim
que recebé-los ele denota uma afirmação (pois é símbolo de \emph{predicado}).
Aqui a idéia é que $\lsym{MotherOf}(p,q)$ denota a afirmação
<<$p$ é a mãe de $q$>>.

%%}}}

%%{{{ eg: full_FOL_example 
\example.
%%%{{{ meta 
%%%}}}

Tomamos
$$
\xalignat2
\bigparen{\;\folcons =\;}\quad
\folfuns_0   &= \set{\lsym f^0_0, \lsym f^0_1, \lsym f^0_2, \lsym f^0_3, \dotsc} & \folpreds_0  &= \set{\lsym P^0_0, \lsym P^0_1, \lsym P^0_2, \lsym P^0_3, \dotsc}\\
\folfuns_1   &= \set{\lsym f^1_0, \lsym f^1_1, \lsym f^1_2, \lsym f^1_3, \dotsc} & \folpreds_1  &= \set{\lsym P^1_0, \lsym P^1_1, \lsym P^1_2, \lsym P^1_3, \dotsc}\\
\folfuns_2   &= \set{\lsym f^2_0, \lsym f^2_1, \lsym f^2_2, \lsym f^2_3, \dotsc} & \folpreds_2  &= \set{\lsym P^2_0, \lsym P^2_1, \lsym P^2_2, \lsym P^2_3, \dotsc}\\
             &\eqvdots                                                                   &              &\eqvdots                                                                  
\endxalignat
$$
onde temos denotado a aridade de cada símbolo como um ``exponente''.

%%}}}

%%{{{ Equality 
\remark Igualdade.
%%%{{{ meta 
%%%}}}

Note que podemos considerar o símbolo \symq{$=$} de
igualdade como símbolo da lógica, botando junto com os
$$
\lnot, \limplies, \land, \lor, \forall, \exists, =
$$
e nesse caso falamos que temos uma FOL \emph{com igualdade}.
Ou podemos considerar \symq{$=$} como mais um predicado,
cuja existência ou não na linguagem depende do usuário,
e---ainda mais importante---cuja \emph{interpretação}
também depende do usuário.
Nesse primeiro encontro com lógica e fórmulas, vamos considerar
que $=$ é um símbolo de predicado de aridade $2$, cujo significado
é sempre afirmar que seus $2$ argumentos \emph{denotam o mesmo objeto},
e que sempre faz parte do $\folpreds_2$.
Quando a gente voltar para estudar lógica matemática no
\ref[Mathematical_logic], vamos discutir mais sobre isso.
Por enquanto não importa!

%%}}}

%%{{{ Terms vs. formulae 
\note Terms \vs fórmulas.
%%%{{{ meta 
%%%}}}

Não vamos dar diretamente uma definição de quando uma expressão é uma fórmula.
Em vez disso, vamos primeiro definir o que são os \emph{termos} duma FOL.
A idéia é que o termos representam os objetos (indivíduos) do nosso universo.
Se estamos estudando pessoas, cada termo vai acabar apontando (denotando)
uma pessoa.  Estudando cálculo, os termos denotariam números reais, etc.
Um termo então é um caso especifico de fórmula?
Não!  Temos um ``type error'' se pensar assim!
Os termos denotam objetos.
As fórmulas denotam proposições (afirmações)
(possivelmente \emph{sobre} objetos).
Talvez uns exemplos ajudam.

%%}}}

%%{{{ eg: terms_vs_formulas_example 
\example.
%%%{{{ meta 
%%%}}}

Estudando cálculo, as expressões seguintes são termos:
$$
\xalignat7
 &0
&&\pi
&&x
&&-1
&&1/2
&&\sin(\pi/x)
&&x\sin(\pi/3) + y\cos(\pi^2)
\endxalignat
$$
Por outro lado, as expressões seguintes são fórmulas:
$$
\xalignat4
&
\gathered
{0 < 1} \land {x < 0} \\
{x^2 = 0} \limplies {x = 0}
\endgathered
&&
\gathered
\lnot\exists y (y^2 > 4) \\
x^2 + y^2 = 1
\endgathered
&&
\gathered
\forall x (0 \leq x^2 0) \\
\exists x \forall y (x + y = 0)
\endgathered
&&
\gathered
\forall y \exists y (x + y = 0) \\
\forall z \paren{{z = 0} \lor \forall w \lnot (w + z = w)}
\endgathered
\endxalignat
$$
Uns dos termos chamamos de atômicos e similarmente umas das fórmulas
chamamos de atômicas.  Tente agora (antes de ver a definição) adivinhar
quais desses termos são atômicos e quais dessas fórmulas são atômicas.

%%}}}

%%{{{ df: FOL_term 
\definition Termo.
%%%{{{ meta 
\label FOL_term
\defines
    * FOL!termo
    ;;
%%%}}}

\tlist:
\li: Se $c \in \folcons$ então $c$ é um termo.
\li: Se $f \in \folfuns_n$ e $t_1,\dotsc,t_n$ são termos, então $f(t_1,\dotsc,t_n)$ é um termo.
\li: Se $x \in \folvars$ então $x$ é um termo.
\endtlist
Nada mais é um termo.
Denotamos o conjunto de termos com $\folterms$.
Resumindo esquematicamente a definição, temos:
$$
\align
x \in \folvars &\implies x \in \folterms\\
c \in \folcons &\implies c \in \folterms\\
\rightbrace {
\aligned
f &\in \folfuns_n\\
t_1,\dotsc,t_n &\in \folterms
\endaligned
}
&\implies f(t_1,\dotsc,t_n) \in \folterms\\
\endalign
$$

%%}}}

%%{{{ df: FOL_atomic_formula 
\definition Fórmula atômica.
%%%{{{ meta 
\label FOL_atomic_formula
\defines
    * FOL!fórmula atômica
    ;;
%%%}}}

Se $P \in \folpreds_n$ e $t_1,\dotsc,t_n$ são termos,
então $P(t_1,\dotsc,t_n)$ é uma \dterm{fórmula atômica}.

%%}}}

%%{{{ df: FOL_formula 
\definition Fórmula.
%%%{{{ meta 
\label FOL_formula
\defines
    * FOL!fôrmula
    ;;
%%%}}}

\tlist:
\li (A): Se $A$ é uma fórmula atômica, então $A$ é uma fórmula.
\li (N): Se $F$ é uma fórmula, então $\lnot F$ é uma fórmula.
\li (B): Se $F,G$ são fórmulas, então:
         \tlist: \withtag --
         \li: $(F \limplies G)$ é uma fórmula;
         \li: $(F \lor G)$ é uma fórmula;
         \li: $(F \land G)$ é uma fórmula.
         \endtlist
\li (Q): Se $F$ é uma fórmula e $x$ é uma variável, então:
         \tlist: \withtag --
         \li: $\forall x F$ é uma fórmula;
         \li: $\exists x F$ é uma fórmula.
         \endtlist
\endtlist

%%}}}

%%{{{ Practical abuse of BNF for FOL 
\grammar FOL.
%%%{{{ meta 
\label FOL_grammar
%%%}}}

Seguindo uma práctica comum, escrevemos apenas
$$
\align
F &\bnfeq
\mathit{A}
\bnfor \lnot F
\bnfor (F \limplies F)
\bnfor (F \land F)
\bnfor (F \lor F)
\bnfor \forall v F
\bnfor \exists v F
\endalign
$$
onde $A$ denota fórmulas atômicas e $v$ denota qualquer variável da nossa FOL.

%%}}}

%%{{{ x: BNF_for_FOL 
\exercise.
%%%{{{ meta 
\label BNF_for_FOL
%%%}}}

Supondo que $\bnf{At}$ pode ser substituito por qualquer fórmula atômica duma FOL (e por nada mais),
defina umas gramáticas em BNF para gerar a linguagem das suas fórmulas bem formadas.

\solution
Aqui uma solução:
$$
\align
\bnf{F}     &\bnfeq \bnf{At} \bnfor \lnot \bnf{F} \bnfor (\bnf{F} \bnf{Bin} \bnf{F}) \bnfor \bnf{Q}\bnf{Var}\bnf{F}\\
\bnf{Bin}   &\bnfeq \lor \bnfor \land \bnfor \limplies\\
\bnf{Q}     &\bnfeq \forall \bnfor \exists\\
\bnf{Var}   &\bnfeq x_0 \bnfor x_1 \bnfor x_2 \bnfor \dotsb\\
\intertext{Como já encontramos, um fácil jeito para evitar os ``$\dotsb$'' seria usar:}
\bnf{Var}   &\bnfeq x \bnfor \bnf{Var}'
\endalign
$$

%%}}}

%%{{{ Q: What do we need in order to have a FOL language? 
\question.
%%%{{{ meta 
%%%}}}

O que precisamos especificar para ter uma linguagem FOL?

%%}}}

%%{{{ A: pick symbols and their arities 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Olhando cuidadosamente para a sua sintaxe, é claro que precisamos
deixar claro quais são os símbolos de variáveis, constantes,
funcções, e predicados, que vamos usar, e suas aridades para
os símbolos de funcções e predicados.

%%}}}

%%{{{ Its semantics 
\note Sua semântica.
%%%{{{ meta 
%%%}}}

Tanto como na lógica proposicional, não vamos nos preocupar
neste momento para definir formalmente uma semântica para
as linguagens de lógica da primeira ordem.
Para conseguir isso, precisamos ganhar muita experiência
com conjuntos (\ref[Sets]), funcções (\ref[Functions]),
e relações (\ref[Relations]), e uma certa
\emph{maturidade matemática} que vai chegando durante
nossos estudos.
Finalmente no~\ref[Mathematical_logic] vamos voltar
nessa questão.
Mesmo assim, precisamos dar pelo menos uma primeira idéia
da semântica da FOL, mesmo sem rigidez.

%%}}}

%%{{{ Interpretations 
\note Interpretações.
%%%{{{ meta 
\label Interpretations
\defines
    * interpretação
    ;;
%%%}}}

Dada uma linguagem de FOL, para suas fórmulas ganharem
significado, precisamos deixar claro:
\tlist:
\li: Qual é o \dterm{universo}, ou seja, todos os objetos
onde as variáveis (e constantes) tomam seus valores.
Todos os nossos termos vão acabar denotando objetos
desse universo.
\li: Para cada \emph{símbolo de funcção}, qual é a \emph{funcção mesmo}
que ele representa no universo escolhido.
\li: Para cada \emph{símbolo de predicado}, qual é a \emph{relação mesmo}
que ele representa no universo escolhido.
\endtlist
Assim que der tudo isso, digamos que temos uma \dterm{interpretação}
da linguagem.

%%}}}

%%{{{ Definition of truth 
\note Definição de verdade.
%%%{{{ meta 
%%%}}}

Mas o que significa que uma fórmula é verdadeira?
Tendo uma interpretação (\reftag[Interpretations])%
---ou seja, assim que especificar tudo isso---se numa fórmula
não aparecem variáveis livres, podemos investigar já sua veracidade,
testando a correspondente afirmação na interpretação.
Se aparecem variáveis livres, tendo uma atribuição de objetos
nelas também podemos decidir sua veracidade.
Essa curta explicação informal deve servir por enquanto,
junta com os exemplos abaixo.
No~\ref[Mathematical_logic] vamos ver tudo formalmente e com carinho.
Paciência.

%%}}}

%%{{{ eg: mother_of_all 
\example.
%%%{{{ meta 
\label mother_of_all
%%%}}}

Considere as fórmulas
\elist:
\li: $\forall x (P(x) \limplies Q(x))$;
\li: $\exists x \forall y R(x,y)$.
\li: $\forall y \exists x R(x,y)$.
\endelist
Escolhendo que o universo é feito por todas as pessoas
(tanto vivas quanto mortas) e que $P$ e $Q$ são os predicados de
``ser pai'' e ``ser homem'', a primeira fórmula vira-se verdade:
realmente cada pai é um homem.  Escolhendo interpretar o $R(u,v)$
como ``$u$ é a mãe de $v$'', a segunda frase se-traduza como
``existe pessoa que é mãe de todos'' (que é falso),
mas a terceira diz ``toda pessoa tem mãe'' (que é verdadeiro).

%%}}}

%%{{{ x: interpretting_formulas_exercise
\exercise.
%%%{{{ meta 
\label interpretting_formulas_exercise
%%%}}}

Para cada uma das fórmulas abaixo, quando possível,
ache uma interpretação que a satisfaz e uma que não.
\elist:
\li: $\forall x \forall y \paren{R(x,y) \land \lnot R(y,x)}$;
\li: $\forall x \forall z \exists y \paren{R(x,y) \land R(y,z)}$;
\li: $\exists x \exists y \exists z Q(f(x,y),z)$.
\endelist

%%}}}

%%{{{ Translations to and from FOL 
\note Traduzindo de e para FOL.
%%%{{{ meta 
\label FOL_translations
%%%}}}

\TODO.

%%}}}

\TODO Exemplos de matemática, pessoas, etc.

%%{{{ Non-limitations 
\note Não-limitações.
%%%{{{ meta 
%%%}}}

Numa primeira olhada a linguagem pode parecer limitada
para expressar umas afirmações que encontramos o tempo
todo em matemática:
$$
\gathered
\text{``existe único $x$ tal que \dots''} \\
\text{``para todo número primo $p$, \dots''} \\
\text{``existe $x\in A$ tal que \dots''} \\
\text{``para todo $x\in A$, \dots''} \\
\text{``existe único $x\in A$ tal que \dots''}
\endgathered
$$
etc.
Podemos expressar essas afirmações numa linguagem de FOL?
Se não, vamos precisar aumentar nossa linguagem
com novos quantificadores, mas felizmente isso
não é necessário.  Podemos realmente escrever
todas essas afirmações e logo basta só descrever
como, e definir mais \emph{acúcar sintáctico}.
Trabalhe nos exercícios seguintes para ver como.

%%}}}

%%{{{ x: forall_x_in_A_sugar 
\exercise.
%%%{{{ meta 
\label forall_x_in_A_sugar
%%%}}}

Ache uma fórmula de linguagem de FOL equivalente à
$\lforall {x \in A} {\phi(x)}$, onde $\phi(x)$ é
uma fórmula que envolve o $x$.  Podes supor que
tua linguagem tem o símbolo \symq{$\in$} nos seus predicados.

\hint
Só para ajudar, suponha que o universo é feito
por todas as pessoas da terra, e que $A$ é o conjunto
de todos os alunos.
E só para ficar mais concreto ainda, suponha
que a fórmula $\phi(x)$ quis dizer que
<<$x$ é uma pessoa legal>>.
O desafio é conseguir escrever a afirmação
$$
\text{<<todo aluno é legal>>}
$$
O problema é que minha linguagem me permite dizer
$$
\forall x {\lthole}
$$
ou seja
$$
\text{<<toda pessoa, \dots>>},
\qquad
\text{<<para toda pessoa $x$, $\psi(x)$>>},
$$
etc., mas não <<para todo aluno $x$, $\psi(x)$>>.
O que você precisa afirmar \emph{para toda pessoa $x$} mesmo,
tal que a afirmação inteira vai acabar sendo equivalente a
$$
\text{<<todo aluno é legal>>}?
$$

\hint
Tu tens que afirmar algo para toda pessoa $x$.
Em vez de afirmar que $x$ é legal, afirme uma implicação:
afirme que
$$
\text{se $x$ {\lthole}, então {\lthole}}.
$$

\solution
$$
\lforall {x \in A} {\phi(x)}
\iff
\forall x \paren{ x\in A \limplies \phi(x) }
$$

%%}}}

%%{{{ x: exists_x_in_A_sugar 
\exercise.
%%%{{{ meta 
\label exists_x_in_A_sugar
%%%}}}

Similarmente para a $\lexists {x \in A} {\phi(x)}$.

\hint
A idéia é parecida com o~\ref[forall_x_in_A_sugar],
mas cuidado, pois é fácil errar!

\hint
Se eu quiser afirmar que existe \emph{um aluno} $x$ tal que $\phi(x)$,
mas eu posso apenas afirmar que existe \emph{uma pessoa} $x$ tal que $\psi(x)$, como eu posso escolher esse $\psi(x)$ para conseguir dizer o que eu quero?
Observe que afirmando que existe aluno $x$ tal que $\phi(x)$,
é a mesma coisa de afirmar que existe pessoa $x$ tal que $\phi(x)$ e\dots
mais uma coisa!
Qual?

\solution
$$
\lexists {x \in A} {\phi(x)}
\iff
\lexists x {x\in A \land \phi(x)}
$$

%%}}}

%%{{{ x: unique_x_sugar 
\exercise.
%%%{{{ meta 
\label unique_x_sugar
%%%}}}

Similarmente para
$\lunique x {\phi(x)}$ e uma da $\lunique {x \in A} {\phi(x)}$.
Lemos o ``$\unique{}$'' como ``existe único''.

%%}}}

%%{{{ x: is_this_sugar_good_for_unique_1 
\exercise.
%%%{{{ meta 
\label is_this_sugar_good_for_unique_1
%%%}}}

$
\lunique x {\phi(x)}
\askiff
\pexists u \lforall y { \phi(y) \liff y = u }
$

%%}}}

%%{{{ x: is_this_sugar_good_for_unique_2 
\exercise.
%%%{{{ meta 
\label is_this_sugar_good_for_unique_2
%%%}}}

$
\lunique x {\phi(x)}
\askiff
\lexists x { \phi(x) \mland \lforall y { \phi(y) \limplies \phi(x) } }
$

%%}}}

%%{{{ x: square_of_odd_is_odd 
\exercise.
%%%{{{ meta 
\label square_of_odd_is_odd
%%%}}}

Considere a afirmação:
$$
\textwq{Todos os quadrados de ímpares são ímpares.}
$$
Usando a notação encontrada neste capítulo, escreva a afirmação em tal forma
que sua estrutura lógica é claramente exposta.
Considere o \wq{{\thole} é ímpar} como um predicado primitivo.

\hint
$\lforall {n \in \ints} {\dots?\dots}$.

\hint
$\lforall {n \in \ints} {\text{$n$ ímpar} \askiff \text{$n^2$ ímpar}}$.

\solution
$\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}$.

%%}}}

%%{{{ Its limitations 
\note Limitações.
%%%{{{ meta 
%%%}}}

Para a maioria das afirmações que encontramos em matemática normalmente
a FOL é suficiente.  Mesmo assim, ela tem suas limitações tanto
para expressar certas proposições matemáticas, quanto para certas afirmações
que encontramos com freqüência na nossa vida.
Mas vou deixar essas preocupações para os problemas.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: lang_Polish 
\problem.
%%%{{{ meta 
\label lang_Polish
%%%}}}

Defina linguagens: uma de logica proposicional e uma de
lógica de predicados que usam notação Polonesa
(\ref[polish_notation]).
Faça um bom trabalho, definindo açúcares sintácticos
e abreviações.
E sobre precedências e associatividades sintácticas?

%%}}}

%%{{{ limitation_of_fol_in_math 
\problem.
%%%{{{ meta 
\label limitation_of_fol_in_math
%%%}}}

Ache uma afirmação matemática que FOL não é capaz para traduzir bem.

%%}}}

%%{{{ modal_temporal_logics 
\problem.
%%%{{{ meta 
\label limitation_of_fol_not_in_math
%%%}}}

Pense em outras afirmações que aparecem freqüentemente na nossa fala
que FOL seria pobre para traduzir bem.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[velleman: Cap.~1];
\cite[velleman: Cap.~2];
\cite[corilascar1: Cap.~3];
\cite[bellmachover: Cap.~2--3].
\cite[corilascar1: Cap.~1];
\cite[bellmachover: Cap.~1].
\cite[alicebook: Cap.~4].
\cite[curryfoundations: Cap.~2].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Proofs 
\chapter Demonstrações.
%%%{{{ meta 
\label Proofs
%%%}}}

\TODO terminar e arrumar.

%%{{{ intro 
\chapintro
Neste capítulo estudamos varios tipos diferentes de proposições,
e para cada uma discutimos qual é a maneira correta de usá-la
para inferir algo novo, e também o que conta como argumentação
válida para demonstrá-la.
Para cada proposição precisamos saber:
\tlist:
\li: como atacá-la;
\li: como usá-la.
\endtlist
Aqui \emph{atacar} significa \emph{progressar em demonstrar},
e nesse contexto \emph{matar um teorema} é sinónimo de
\emph{demonstrar um teorema}.\foot
Vamos pegar emprestada muita da terminologia de \emph{jogos}
e de \emph{programação} para nos ajudar comunicar certas idéias.
\toof
(Lembra do túmulo \sq{$\qedsymbol$} de {\Halmos}Halmos?)
A partir dessas ``regras principais'' e talvez outros princípios de lógica
podemos derivar mais maneiras de usar ou de demonstrar proposições.
Para realmente aprender como demonstrar teoremas,
existe apenas um caminho: \emph{demonstrando}.
E vamos fazer isso no resto desse texto mesmo.
Nosso objectivo aqui \emph{não é} estudar profundamente estratégias
de demonstração num contexto abstrato, mas apenas introduzir umas
idéias e estabelecer uma terminologia e metodologia para nos ajudar
demonstrar teoremas e falar sobre demonstrações.
Durante esse capítulo vamos desenvolver uma
\emph{linguagem de demonstração} e usá-la como um ``backend'',
uma low-level linguagem em qual as nossas demonstrações
escritas numa linguagem mais humana ``compilam''.
%%}}}

\TODO diss truth tables.

%%{{{ Proofs, games, programs 
\section Demonstrações, jogos, programas.
%%%{{{ meta 
\label proofs_games_programs
%%%}}}

%%{{{ lorenzen dialogue games 
\note.
%%%{{{ meta 
%%%}}}

Existem várias maneiras de usar jogos para estudar provas.
Num dos mais comuns, é selecionada uma afirmação e dois jogadores
estão jogando um \emph{contra} o outro:
um acredita na afirmação e está tentando prová-la;
o outro não, e está tentando refutá-la.
Muitas variações disso existem e correspondem principalmente
em alterações da ``lógica por trás''.

%%}}}

%%{{{ one-player game 
\note.
%%%{{{ meta 
%%%}}}

Mas aqui vamos usar terminologia de jogos numa maneira
diferente, onde o jogo é jogado só por você mesmo,
como um jogo de Solitaire ou de Minesweeper.\foot
Podes visualizar esses jogos como jogos de 2 jogadores
onde teu oponente só joga uma vez (e joga primeiro) escolhendo
a ordem das cartas no caso de Solitaire ou onde botar as minas no
caso de Minesweeper.  Após disso, quem joga é apenas você.
\toof
Tu estás jogando com um ou mais alvos, onde cada alvo é uma afirmação
matemática que tu estás querendo matá-la (provar).
Para conseguir isso, tu tens na tua disposição:
certas \emph{armas}: os seus dados (hipoteses),
definições, teoremas, etc., e finalmente \emph{a própria lógica},
que é representada aqui por \emph{as próprias regras do jogo}.
O jogo é feito numa maneira que se não roubar
(ou seja, se seguir as regras),
então tua prova realmente estabelece a veracidade dos teus alvos.

%%}}}

%%{{{ where's the compiler? 
\note Cadê o compilador?.
%%%{{{ meta 
\label where_is_the_compiler
%%%}}}

Um dos maiores problemas em nossos primeiros contatos com
matemática \emph{de verdade}, é ``roubar sem querer''.
Em programação, o compilador assume bastante um papel de
regulador que não nos permite roubar.
O desafio em matemática é que, escrevendo uma prova estamos assumindo
o papel tanto do programador quanto do compilador.
No início isso pode aparecer uma carga muito pesada,
mas praticando acaba sendo algo natural.
No mesmo sentido, o programador iniciante ``briga'' com o compilador
o tempo todo, e com mais experiência ele assume (conscientemente ou não)
cada vez mais um papel de compilador mental também, e acaba brigando
cada vez menos com o compilador da sua máquina.

%%}}}

%%{{{ the game and its board 
\note O jogo e seu tabuleiro (REPL).
%%%{{{ meta 
\defines
    * proof!script
    * proof!state
    * estado!de demonstração
    * REPL!de demonstração
    * script!de demonstração
    ;;
\indexes
    * demonstração       seealso: proof
    * demonstração!REPL      see: REPL
    * demonstração!script    see: script
    * demonstração!estado    see: estado
    * state                  see: estado
    ;;
%%%}}}

Podemos pensar que o jogo acontece em duas partes.
A primeira parte é a \wq{\proofName}:
É aqui que o jogador (você) joga, onde cada movimento
é escrever uma frase mais nessa parte.
Chamamos essa parte também de \dterm{proof script}.
A segunda parte é a tabela de Dados/Alvos.
O enunciado do teorema que queres demonstrar cria o contexto da prova,
ou seja, ele está deixando claro quais são os \emph{dados},
e qual (ou quais) os \emph{alvos}.
Com cada movimento---ou seja, frase escrita na parte
\wq{\proofName})---a tabela
dos Dados/Alvos muda para refletir a situação atual
do jogo: o \dterm{estado} (ou \dterm{state}).
Novos dados podem ser adicionados, uns alvos podem
ser matados, outros nascidos.
O jogo termina quando não tem mais nenhum alvo vivo.
\eop
As partes do jogo e seu tabuleiro parecem assim então:
\repl
~ x: phantomed placeholder ;
\givens
~ x: phantomed placeholder ;
\goals
~ x: phantomed placeholder ;
\endrepl

%%}}}

%%{{{ eg: x odd => x^2 odd 
\example.
%%%{{{ meta 
%%%}}}

Nesse exemplo encontramos uma demonstração dum teorema sobre inteiros.
Neste momento apenas siga essa demonstração, movimento-por-movimento,
para entender a idéia desse jogo e nada mais.
A afirmação que queremos demonstrar é a seguinte:
$$
\textwq{Todos os quadrados de ímpares são ímpares.}
$$
Já que tu trabalhou no~\ref[square_of_odd_is_odd] (né?), entendes bem a forma do teu alvo:
$$
\lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}
$$
Bora começar jogar então!
\repls
\maxproof  : Suponha $x$ ímpar. ;
\maxgiven  : \ \ \lexists {k\in\ints} {x = 2k+1}  ;
\maxgoal   : \lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
\repl
\givens
\goals
~     : \lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
\endrepl
Começamos com nossa primeira linha:
\repl
~ a   : Seja $x$ inteiro. ;
\givens
~ a   : x \in \ints ;
\goals
~ a/  : \lforall {n \in \ints} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
~ a   : \text{$x$ ímpar} \implies \text{$x^2$ ímpar} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~ a   : Suponha $x$ ímpar. ;
\givens
~     : x \in \ints ;
~ a  t: $x$ ímpar ;
\goals
~ a/  : \text{$x$ ímpar} \implies \text{$x^2$ ímpar} ;
~ a  t: $x^2$ ímpar ;
\endrepl
\endrepls
Neste momento, olhamos para o tabuleiro de Dados/Alvos e anotamos, como rascunho,
o significado dumas dessas afirmações.
\repls
\maxproof : Seja $k\in\ints$ tal que $x = 2k+1$. ;
\maxgiven : \ \ \lexists {k\in\ints} {x = 2k+1}  ;
\maxgoal  : \ \ \lexists {a\in\ints} {x = 2a+1}  ;
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
\givens
~     : x \in \ints ;
~    t: $x$ ímpar ;
~    =: \lexists {k\in\ints} {x = 2k+1} ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a\in\ints} {x^2 = 2a + 1} ;
\endrepl
Poderiamos escrever uma
\emph{linha de comentário} na nossa demonstração,
mas por enquanto quero mostrar apenas as
\emph{linhas de código} mesmo.
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~ a   : Seja $k\in\ints$ tal que $x = 2k+1$. ;
\givens
~     : x \in \ints ;
~    t: $x$ ímpar ;
~ a   : k \in \ints ;
~ a   : x = 2k + 1 ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a\in\ints} {x^2 = 2a + 1} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~     : Seja $k\in\ints$ tal que $x = 2k+1$. ;
~ a   : Calculamos: ;
~,a  c: x^2 &= (2k+1)^2 \\
            &= 4k^2 + 4k + 1 \\
            &= 2(2k^2+2k) + 1 \\ ;
\givens
~     : x \in \ints ;
~    t: $x$ ímpar ;
~     : k \in \ints ;
~     : x = 2k + 1 ;
~ a   : x^2 = 2(2k^2 + 2k) + 1 ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a\in\ints} {x^2 = 2a + 1} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~     : Seja $k\in\ints$ tal que $x = 2k+1$. ;
~     : Calculamos: ;
~,   c: x^2 &= (2k+1)^2 \\
            &= 4k^2 + 4k + 1 \\
            &= 2(2k^2+2k) + 1 \\ ;
~ a   : Usando o inteiro $2k^2+2k$, ;
~,a s :   temos que $x^2$ é ímpar. \qed;
\givens
~     : x \in \ints ;
~    t: $x$ ímpar ;
~     : k \in \ints ;
~     : x = 2k + 1 ;
~     : x^2 = 2(2k^2 + 2k) + 1 ;
~ a  t: $x^2$ ímpar ;
\goals
~ a/ t: $x^2$ ímpar ;
~    =: \lexists {a\in\ints} {x^2 = 2a + 1} ;
\endrepl
\endrepls
Matamos todos os alvos---só tinha um---então podemos concluir que o que
queriamos demonstrar, foi demonstrado (ou seja: é um teorema mesmo).

%%}}}

%%{{{ remark: the text above is terrible 
\remark.
%%%{{{ meta 
%%%}}}

O texto que a prova acabou sendo é \emph{terrível}.
Parece escrito por um robô que não entende nada.
Não vamos escrever provas nesse jeito.
Em vez disso, o texto ``real e humano'' que corresponde
nessa prova seria algo do tipo:
\quotepar
Seja $x$ inteiro ímpar,
e logo seja $k\in\ints$ tal que $x = 2k + 1$.
Preciso mostrar que $x^2$ é ímpar também.
Calculamos:
$$
x^2 = (2k+1)^2 = 4k^2 + 4k + 1 = 2(2k^2+2k) + 1.
$$
Como $2k^2+2k\in\ints$, logo $x^2$ é ímpar.
\endquote
Mesmo assim, é importante entender o ``backend'' e esse
lado dinámico da prova, em termos da tabela ``Dados/Alvos''
e das mudanças que estão acontecendo nela.
Então quando tu vai escrever tuas próprias provas,
pelo menos no início, podes aproveitar um rascunho
para fazer teu ``bookkeeping'', escrevendo e apagando
coisas nele com cada frase que escreveu na tua prova.
Com mais experiência, esse processo vai virar automático
e subconsciente.

%%}}}

%%{{{ REPL 
\note REPL.
%%%{{{ meta 
\label REPL
\indexes
    * LISP
    * Python
    * programação
    ;;
\defines
    * REPL
    ;;
%%%}}}

Muitas linguagens de programação hoje em dia têm \dterm{REPL:}
Read--Eval--Print Loop.
Começou em LISP e é exatamente o que ele promete.
Um programa que:
(1) lê expressões (em geral escritas pelo usuário);
(2) calcula para achar o valor da expressão;
(3) imprime o valor
(4) loop para o (1).
Executando o programa \tool{python} por exemplo, abrimos
uma sessão com o REPL da linguagem Python, e brincamos
com o sistema.
Abrindo o REPL certas coisas já estão definidas e carregadas
na memória, e muitas vezes abrimos já especificando um
\dterm{script}, um arquivo que contem linhas de código
e que já defina várias coisas na nossa linguagem.
Podemos pensar que uma demonstração é parecida com uma
sessão num REPL, onde o script carregado é o enunciado
da demonstração, e cada linha que escrevemos na demonstração
corresponde numa linha que o programador escreveno REPL.
Uma diferença é que o demonstrador precisa assumir o
papel de tanto do escritor quanto do sistema, não vai
ver nada impresso, e nenhum cálculo vai ser feito
\emph{para} ele; tudo \emph{por} ele mesmo.
Consideramos então que os cálculos utilizados fazem
parte da demonstração, e precisamos justificar cada
passo deles.
\emph{Obviamente} certos passos deixamos sem
justificativa se as consideramos óbvias, mas vejá
também o~\ref[obvious_trivial_immediate].

%%}}}

%%{{{ code_vs_comment 
\note Linha de código \vs comentário.
%%%{{{ meta 
\label code_vs_comment
%%%}}}

Vamos continuar pouco ainda mais essa metafora relaconada a programação.
Lendo um texto de demonstração certas partes valem como linhas de
código e outras como comentários.
\dterm{Linhas de código} tem efeito no tabuleiro do jogo:
mudam algo nos alvos ou nos dados.
\dterm{Comentários} servem o mesmo propósito em programação: ajudar
o leitor (humano) do nosso código entender nossa idéia e seguir
nossos passos; não fazem parte da demonstração;
não oferecem nenhum progresso.
Com prática---e dependendo de quem é o teu alvo
(leitor)---tu vai ganhar uma noção de onde botar
um cometário, quão detalhado deveria ser, etc.\foot
Cuidado pois existe um máu hábito de decorar programas
com comentários demais, e o mesmo problema pode
acontecer com demonstrações.
Tanto em programação quanto em demonstração a dica
é a mesma sobre escrever comentários:
\emph{escreva um comentário apenas se sua falta
deixaria o leitor confuso}.
Seja lacônico.
\toof

%%}}}

%%{{{ keywords 
\note Keywords.
%%%{{{ meta 
%%%}}}

Cada linguagem de programação tem seus \dterm{reserved keywords}
que, quando usados corretamente formam expressões e outras
construções da linguagem para finalmente virar um programa.
Por exemplo uns keywords de C seriam os
$\code{if}$, $\code{while}$, $\code{int}$, $\code{void}$, $\code{switch}$, etc.
Observe que tem várias categorias sintacticamente corretas:
expressões, comandos, literais, etc., e a gramática da linguagem
não nos permite trocar uma frase duma categoria para uma frase de outra.
Uma frase da categoria \emph{declaração de variável}, por exemplo,
precisa começar com uma frase da categoria \emph{tipo}
(por exemplo \sq{$\code{int}$} seguida por uma frase da categoria \emph{variável}
(por exemplo \sq{$\code{x1}$}) e terminar com o \sq{$\code{;}$}.
Assim foi formada a declaração
$$
\code{int x1;}
$$
Lembra que falei que demonstrar e programar é a mesma coisa?
Bem; em demonstrações, é a mesma coisa!
Temos as categorias de frases, os keywords, e as regras que precisamos
seguir para escrever frases bem formadas, e também as regras de lógica
que precisamos respeitar, se é pra nosso côdigo ``compilar'' e servir
o seu propósito.
Exemplos de keywords são \emph{\symqq{seja}}, \emph{\symqq{ou}},
\emph{\symqq{suponha}}, \emph{\symqq{tal que}}, etc.

%%}}}

\endsection
%%}}}

%%{{{ Attacking the logical structure of a proposition 
\section Atacando a estrutura logical duma proposição.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Enquanto nosso alvo não é atômico, podemos atacá-lo numa maneira direita,
``batendo na lógica'' mesmo.
Similarmente, dados alvos não atômicos podemos usá-los na nossa
demonstração baseados na estrutura lógica deles.

%%}}}

%%{{{ x: how_to_use_and_how_to_attack_each_connective 
\exercise.
%%%{{{ meta 
\label how_to_use_and_how_to_attack_each_connective
%%%}}}

Até agora encontramos como usar os $\exists,\land$ e como atacar os $\forall,\exists,\limplies$.
Para cada um dos conectivos que ainda não achamos como usar ou atacar, pense em:
o que tu podes escrever na tua demonstração; o que efeito tem nos dados; e o que nos alvos.
$$
\vbox{\halign{
\hfil##\hfil            &\qquad ##\quad\hfil              & \qquad ## \hfil\cr
                        & {\bf Usar}                      & {\bf Atacar}\cr
\tablethickrule
$\sforall x \phi(x)$    & $?^{\phantom?}$                 & <<Seja $u$.>>\cr
                        &                                 & Novos dados: $u$\cr
                        &                                 & Novo alvo: $\phi(u)$\cr
\tablerule
$\sexists x \phi(x)$    & <<Seja $u$ tal que $\phi(u)$.>> & <<Demonstrarei $\phi(u)$.>> (eu escolho o $u$)\cr
                        & Novos dados: $u$, $\phi(u)$     & Efeito nos dados: --\cr
                        & Efeito nos alvos: --            & Novo alvo: $\phi(u)$\cr
\tablerule
$\phi \land \psi$       & --                              & ?\cr
                        & Novos dados: $\phi$, $\psi$     &  \cr
                        & Efeito nos alvos: --            &  \cr
\tablerule
$\phi \lor \psi$        & ?                               & ?\cr
                        &                                 &  \cr
                        &                                 &  \cr
\tablerule
$\phi \limplies \psi$   & ?                               & <<Suponha $\phi$.>>\cr
                        &                                 & Novo dado: $\phi$\cr
                        &                                 & Novo alvo: $\psi$\cr
\tablerule
$\lnot \phi$            & ?                               & ?\cr
}}
$$

%%}}}

\endsection
%%}}}

%{{{ Real_life_proof_examples 
\section Real-life exemplos: divisibilidade.
%%%{{{ meta 
\label Real_life_proof_examples
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para brincar com algo da ``vida real'', vamos definir
a relação de \emph{dividir} entre números e demonstrar
vários teoremas relacionados.

%%}}}

\TODO espalhar os teoreminhas no capítulo todo e botar mais.

%%{{{ definition of divides for now
\blah Definição.
%%%{{{ meta 
%%%}}}

Sejam $a,b\in\ints$.
Digamos que \dterm{o $a$ divide o $b$} (ou \dterm{o $b$ é divisível por $a$}), sse $b = ak$ para algum $k\in\ints$.
Nesse caso, escrevemos $a \divides b$.
Em símbolos:
$$
a \divides b \defiff \lexists {k\in\ints} {b = ak}.
$$
Os \dterm{divisores} do $a$ são todos os inteiros $d$ tais que $d \divides a$.
Naturalmente, usamos a notação $a\ndivides b$ quando $a$ não divide $b$.

%%}}}

%%{{{ eg: divides_and_ndivides_examples 
\example.
%%%{{{ meta 
\label divides_and_ndivides_examples
%%%}}}

$3 \divides 12$, porque $12 = 3 \ntimes 4$ e $4\in\ints$, mas
$8 \ndivides 12$, porque, nenhum inteiro $u$ satisfaz $12 = 8u$.
\mistake

%%}}}

%%{{{ x: wrong_use_of_because 
\exercise.
%%%{{{ meta 
\label wrong_use_of_because
%%%}}}

Qual o problema no~\ref[divides_and_ndivides_examples]?

\solution
A segunda ocorrência da palavra <<porque>> não faz sentido nenhum:
o que segue depois não é uma justificação da tese $8 \ndivides 12$,
mas sim apenas uma repetição da mesma afirmação.
Essencialmenteo que tá escrito nessa frase é:
\standout
\emph{o 8 não divide o 12 porque o 8 não divide o 12.}
\endstandout
Substituindo por um <<ou seja>>, a frase faz sentido, e serve
apenas como um \emph{comentário}, lembrando para o leitor a definição:
\standout
$8 \ndivides 12$, \emph{ou seja}, nenhum inteiro $u$ satisfaz $12 = 8u$.
\endstandout
Procure mais sobre isso no~\ref[proof_by_repeating_the_definition].

%%}}}

%%{{{ x: train_with_divides_properties 
\exercise Propriedades da divisibilidade.
%%%{{{ meta 
\label train_with_divides_properties
%%%}}}

Sejam $a,b,x,y,m\in\ints$.
Demonstre que:
\elist:
\li: $1 \divides a$
\li: $a \divides 0$
\li: $a \divides b \implies a \divides bx$
\li: $a \divides b \implies a \divides -b \mland -a \divides b$
\li: $a \divides b \mland a \divides c \implies a \divides b + c$
\li: $a \divides b \mland a \divides c \implies a \divides bx + cy$
\li: $a \divides b \mland b \neq 0 \implies \abs a \leq \abs b$
\li: se $m\neq0$ então: $a \divides b \!\iff\! ma \divides mb$.
\endelist

\hint
Aplique a definição do $\divides$.

%%}}}

%%{{{ x: divides_is_almost_a_partial_order_proof 
\exercise Mais propriedades da divisibilidade.
%%%{{{ meta 
\label divides_is_almost_a_partial_order_proof
%%%}}}

Para todos $a,b,c\in\ints$,
\mathcall
& a \divides a                                           \called {reflexividade} \\
& a \divides b \mland b \divides c \implies a \divides c \called {transitividade} \\
& a \divides b \mland b \divides a \implies \abs a = \abs b. \\
\intertext{Se $a,b\in\nats$, a terceira propriedade fica mais forte:}
& a \divides b \mland b \divides a \implies a = b.       \called {antissimetria} \\
\endmathcall

%%}}}

%%{{{ prop: wrong_property_of_product_dividing_common_multiple 
\proposition.
%%%{{{ meta 
\label wrong_property_of_product_dividing_common_multiple
%%%}}}

Sejam $a,b,m\in\ints$.  Se $a \divides m$ e $b \divides m$, então $ab \divides m$.

\wrongproof.
Como $a \divides m$, pela definição de $\divides$, existe $u\in\ints$ tal que
$a = mu$.  Similarmente, como $b \divides m$, existe $v\in\ints$ tal que
$b = mv$.  Multiplicando as duas equações por partes, temos
$$
ab = (mu)(mv) = m(umv),
$$
e como $umv\in\ints$, $ab \divides m$.

%%}}}

%%{{{ x: find the error and prove that it is false 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o erro na demonstração acima e \emph{demonstre} que a proposição é falsa!

\hint
Presta atenção na definição do $\divides$.

\hint
Procure um contraexemplo onde $a$ e $b$ tem um fator em comun.

\solution
O erro fica na aplicação da definição de $a \divides b$\thinspace:
ao invés de $\lexists {k\in\ints} {b = ak}$,
a prova usou $\lexists {k\in\ints} {a = bk}$.
\eop
Para ver que a proposição realmente é falsa, considere o contraexemplo seguinte:
$$
a = 6,\qquad
b = 15,\qquad
m = 30.
$$
Realmente temos
$6  \divides 30$ e 
$15 \divides 30$,
mas
$6\ntimes 15 = 90 \ndivides 30$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A falsa \ref[wrong_property_of_product_dividing_common_multiple]
tem uma ``versão correta'' que encontramos depois
(\ref[product_of_coprimes_divides_common_multiple]).

%%}}}

%%{{{ x: implications_with_divisibility_of_linear_combinations 
\exercise.
%%%{{{ meta 
\label implications_with_divisibility_of_linear_combinations
%%%}}}

Sejam $a,b,c\in\ints$.
Demonstre ou refute cada uma das afirmações:
$$
\alignat2
\text{(i)}   &\qquad& a \divides \phantom1b + c\phantom1                          &\implies a \divides b \mland a \divides c\\
\text{(ii)}  &\qquad& a \divides b + c \mland a \divides \phantom1b - c\phantom2  &\implies a \divides b                    \\
\text{(iii)} &\qquad& a \divides b + c \mland a \divides \phantom1b + 2c          &\implies a \divides b                    \\
\text{(iv)}  &\qquad& a \divides b + c \mland a \divides 2b + 2c                  &\implies a \divides b                    \\
\text{(v)}   &\qquad& a \divides b + c \mland a \divides 2b + 3c                  &\implies a \divides 3b + 2c\,.
\endalignat
$$

\solution
A (ii) é falsa: um contraexemplo seria o $a = 2$, $b = c = 1$.
Realmente, temos
$$
2 \divides 1 + 1 = 2 \mland 2 \divides 1 - 1 = 0,
\qqtext{mas}
2\ndivides 1.
$$
\eop
A (iii) é verdadeira:
$$
\rightbrace {
\aligned
        a \divides b + c \implies a \divides 2b + 2c\\
                                 a \divides \phantom1b + 2c
\endaligned
}
\implies
a \divides \mubrace{(2b + 2c) - (b + 2c)} {\dsize b}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Conjunction 
\section Conjuncção.
%%%{{{ meta 
\label Conjunction
%%%}}}

%%{{{ Understand 
\note Entender.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
%%%}}}

Escrevendo como regras---agora temos duas---de inferência
$$
\PROOFm {
\A {\phi\land\psi}
\I1--------------- {}
        {\phi}
}
\qqqquad
\PROOFm {
\A {\phi\land\psi}
\I1--------------- {}
        {\psi}
}
$$
Na prática, podes pensar que tendo como dado o $\phi\land\psi$ tu ganha os dados $\phi$ e $\psi$.

%%}}}

%%{{{ How do I attack it? 
\note Como eu ataco?.
%%%{{{ meta 
%%%}}}

Para convencer alguém que $\phi \land \psi$, precisamos convencê-lo que $\phi$, e também convencê-lo que $\psi$.
Ou seja, o alvo $\phi \land \psi$ é reduzível em dois alvos: o $\phi$ e o $\psi$.
$$
\PROOFm {
   \A {\phi}     \A {\psi}
\I2----------------------- {}
        {\phi\land\psi}
}
$$

%%}}}

\endsection
%%}}}

%%{{{ Implication 
\section Implicação.
%%%{{{ meta 
\label Implication
\defines
    * implicação
    ;;
%%%}}}

%%{{{ secintro: (Controversial) 
\secintro
Controversial.
%%}}}

%%{{{ implication_understand 
\note Entender.
%%%{{{ meta 
\label implication_understand
\defines
    * trivialmente
    ;;
%%%}}}

Pensando no que uma implicação realmente é, vamos visualizá-la como uma premissa:
$$
\textwq{Prometo que $B$ com a condição $A$.}
$$
E o que é prometido caso que a condição $A$ não for verdadeira?
\emph{Nada!}
É importante entender essa parte, e talvez essa piada conhecida ajuda:
\quotepar
Um filho tá gritando e seu pai vire e fala pra ele:
\emph{``se tu continuar gritando, eu vou bater em ti!''}
O filho, com medo, imediatemente fica calado, e logo após seu pai bate nele.
\endquote
A pergunta para pensar é: \emph{o pai mentiu?}
Em matemática entendemos a implicação numa forma que não culpa esse pai
de mentiroso.\foot
relaxe que tu podes culpar o pai para outras coisas se quiser
\toof
Entendemos a implicação
$$
\textwq{se $\namedhole A$ então $\namedhole B$}
$$
como uma promessa.
Aqui o pai não prometeu nada no caso que seu filho parasse de gritar!
Nesse exemplo bobo então, a afirmação do pai é verdadeira \dterm{trivialmente}
como a gente fala:
ou seja, como não aconteceu a \emph{premissa},
não tem como culpá-lo de mentiroso, e logo a implicação inteira é verdadeira.

%%}}}

%%{{{ modus_ponens : What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
\label modus_ponens
\defines
    * modus ponens
    ;;
%%%}}}

Tenho nos meus datos a implicação $\phi\limplies\psi$.
O que eu posso fazer agora, que não podia fazer antes?
Considerando só essa proposição, nada demais!
Sozinha parece inútil: pensando numa metafora de jogo com cartas,
para jogar essa carta e ganhar algo, preciso ter mais uma carta:
sua \dterm{premissa} $\phi$.
Jogando ambas juntas, ganhamos a $\psi$.
Podemos pensar então numa implicação $\phi\limplies\psi$
como uma fabrica do dado $\psi$, só que para \emph{funccionar},
ela precisa da proposição $\phi$.
Escrevendo como regra de inferência,
$$
\PROOFm {
   \A {\phi \limplies \psi}   \A {\phi}
\I2------------------------------------ {}
                  {\psi}
}
$$
O nome dessa regra é \dterm{modus ponens}.

%%}}}

%%{{{ How do I attack it? 
\note Como eu ataco?.
%%%{{{ meta 
%%%}}}

Para convencer teu inimigo sobre a vericidade duma implicação $\phi \implies \psi$
tu tens o direito de mandá-lo \emph{aceitar} a premissa $\phi$.
No final das contas, ele tá duvidando a proposição $\psi$,
\emph{dado a proposição $\phi$}.
Ou seja, para atacar uma implicação $\phi\limplies\psi$ escrevemos
\quote
Suponha $\phi$.
\endquote
Assim ganhamos nos nossos dados o $\phi$ e nosso alvo é $\psi$.

%%}}}

\endsection
%%}}}

%%{{{ Existential 
\section Existencial.
%%%{{{ meta 
\label Existential
%%%}}}

\endsection
%%}}}

%%{{{ Disjunction 
\section Disjuncção.
%%%{{{ meta 
%%%}}}

%%{{{ Understand 
\note Entender.
%%%{{{ meta 
%%%}}}

A disjunção $\phi\lor\psi$ representa uma informação ambígua, estritamente mais
fraca que qualquer uma das $\phi,\psi$: $\phi\lor\psi$ é a proposição que pelo
menos uma das $\phi,\psi$ é válida.

%%}}}

%%{{{ disjunctive_syllogism 
\note Silogismo disjuntivo.
%%%{{{ meta 
\label disjunctive_syllogism
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Negation 
\section Negação.
%%%{{{ meta 
%%%}}}

\TODO Botando negações pra dentro.

\TODO Negando fórmulas atômicas.

\endsection
%%}}}

%%{{{ Universal 
\section Universal.
%%%{{{ meta 
%%%}}}

%%{{{ Vacuously_true 
\note Por vacuidade.
%%%{{{ meta 
\label Vacuously_true
%%%}}}

\TODO Escrever.

%%}}}

\TODO arbitrário \vs aleatório.

\endsection
%%}}}

%%{{{ Examples_and_counterexamples 
\section Exemplos e contraexemplos.
%%%{{{ meta 
\label Examples_and_counterexamples
%%%}}}

\TODO elaborar e referir ao~\ref[nonexample_vs_counterexample].

%%{{{ eg: nonexample_vs_counterexample_example 
\example.
%%%{{{ meta 
\label nonexample_vs_counterexample_example
%%%}}}

As afirmações seguintes são corretas:
% TODO: fix reflabs
\tlist:
\li (i):   $21$ é um contraexemplo para a: todos os múltipos de $3$ são pares;
\li (ii):  $18$ é um contraexemplo para a: todos os múltipos de $3$ são ímpares;
\li (iii): $18$ é um contraexemplo para a: nenhum múltiplo de $3$ é par;
\li (iv):  $18$ não é um contraexemplo para a: todos os ímpares são multiplos de $3$;
\li (v):   $18$ não é um contraexemplo para a: todos os ímpares são múltiplos de $7$;
\li (vi):  $21$ não é um contraexemplo para a: todos os ímpares são múltiplos de $3$.
\endtlist
Vamos ver curtamente a razão de cada uma das últimas três:
nas (iv) e (v) o $18$ nem é ímpar então não tem chances de ser
contraexemplo de qualquer afirmação que todos os ímpares fazem algo;
na (vi) o $21$ é ímpar mas ele \emph{tem sim} a propriedade descrita, e logo
também não é um \emph{contra}exemplo.\foot
Para misturar nossa conversa com a discussão sobre exemplos e nãœxemplos
(\reftag[examples_and_nonexamples]):
acabei de listar aqui, em ordem:
três exemplos de contraexemplos e
três nãœxemplos de contraexemplos.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Logical equivalence 
\section Equivalência lógica.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Igualdade 
\section Igualdade.
%%%{{{ meta 
\label Equality
%%%}}}

%%{{{ Laws 
\law Leis da igualdade.
%%%{{{ meta 
\headerize
\label laws_of_eq
%%%}}}

Aceitamos como parte da nossa lógica que a igualdade é:
\dterm{reflexiva}, \dterm{simétrica}, e \dterm{transitiva}:
$$
\PROOFmr {
\I0---------------- {Refl}
   {\alpha = \alpha}
}
\qquad
\PROOFmr {
\A {\alpha = \beta}
\I1------------------ {Sym}
   {\beta = \alpha}
}
\qquad
\PROOFmr {
\A {\alpha = \beta}
\A                       {\beta = \gamma}
\I2---------------------------------------- {Trans}
           {\alpha = \gamma}
}
$$
Além disso, aceitamos a \dterm{lei de substituição:}
\emph{em qualquer fórmula ou qualquer termo podemos
substituir um subtermo por um igual
sem mudar o significado da fórmula ou termo}.

%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
%%%}}}

Ganhando como dado o $\alpha = \beta$, tu agora podes
substituir $\alpha$ por $\beta$ e vice versa em qualquer
contexto que eles aparecem!

%%}}}

%%{{{ How to attack? 
\note Como atacar?.
%%%{{{ meta 
%%%}}}

Simples: pega um lado, e calcule até chegar no outro!
Às vezes fica difícil enxergar um caminho direto de $\alpha$
pra $\beta$; nesse caso tente pegar um lado até chegar num ponto $\gamma$; depois pega o outro lado e se conseguir chegar no mesmo ponto $\gamma$, teu alvo já era!

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
\pdefs
    \pdef explodes {\leadsto}
    ;;
%%%}}}

%%{{{ prob: explodes 
\problem.
%%%{{{ meta 
\label explodes
\pdefs
    \pdef explodes {\doublemidrel}
    ;;
\defines
    * explode
    ;;
%%%}}}

Sejam $a,b\in\ints_{\geq 0}$.
Digamos que \dterm{o $a$ explode o $b$}, sse $b = a^n$ para algum $n\in \alert?$.
Nesse caso, escrevemos $a\explodes b$.
Dependendo do qual conjunto botamos no {\alert?} chegamos numa definição diferente:
$$
a\explodes b \defiff
\knuthcases {
\lexists {n\in\ints}          {b = a^n}   &(Definição D1) \cr
\lexists {n\in\ints_{\geq 0}} {b = a^n}   &(Definição D2) \cr
\lexists {n\in\ints_{> 0}}    {b = a^n}.  &(Definição D3)
}
$$
\eop\noi
Proposição P1:
para quaisquer $a,b,c\in\ints_{\geq 0}$,
se $a \explodes b$ e $b \explodes c$ então $a \explodes c$.
\eop\noi
Proposição P2:
para quaisquer $a,b\in\ints_{\geq 0}$,
se $a \explodes b$ então $a \divides b$.
\eop\noi
Proposição P3:
para quaisquer $a,b,c\in\ints_{\geq 0}$,
se $a \divides b$ e $b \explodes c$ então $a \divides c$.
\eop
Como cada proposição depende da definição de <<explode>> temos
em total 9 proposições.
Para cada uma delas, demonstre ou refute.

%%}}}

\endproblems
%%}}}

%%{{{ EFQ 
\section Ex falso quodlibet.
%%%{{{ meta 
\label EFQ
%%%}}}

%%{{{ discussion 
\note.
%%%{{{ meta 
%%%}}}

Em qualquer momento durante uma demonstração, o estado é a tabela de Dados/Alvos, e nosso objetivo é mostrar que se os dados são todos verdadeiros, então os alvos também devem ser.  Mas o que acontece se dentro dos nossos dados temos uma \dterm{inconsistência}, ou seja, nosso estado descreve uma situação impossível.  Nesse caso, ganhamos trivialmente o jogo, pois conseguimos mostrar a impossibilidade dos dados acontecerem, então não temos nada mais pra fazer: matamos assim qualquer alvo pois garantimos que a premissa (que os dados são verdadeiros) é falsa.
Na pratica isso significa que se em qualquer momento numa demonstração conseguimos como dado uma contradição ($\bottom$), já podemos parar vitoriosamente:
\emph{explodimos o mundo inteiro, e logo nosso alvo morreu também}.
Como regra, temos
$$
\PROOFm {
\A {\bottom}
\I1--------- {}
    {\phi}
}
$$
para qualquer $\phi$.

%%}}}

\endsection
%%}}}

%%{{{ LEM_spell 
\section Feitiço: LEM.
%%%{{{ meta 
\label LEM_spell
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Suponha que está tentando demonstrar uma afirmação.
Para matar esse monstro, em qualquer momento da tua prova,
você pode separar em casos, e mostrar como matá-lo
em cada um deles.
Quando decidir atacar nessa maneira precisa tomar certos cuidados.

%%}}}

%%{{{ our new goals 
\note Nossos novos alvos.
%%%{{{ meta 
\label case_split_clones_goal
%%%}}}

O alvo tá sendo clonado igualzíssimo para cada um dos casos.

%%}}}

%%{{{ remark: seems weird choice to case split 
\remark.
%%%{{{ meta 
%%%}}}

Mas, peraí.
A gente quer matar um monstro $G$.
Depois desse passo de separar em, sei lá, 4 casos,
agora nosso objectivo é matar 4 cópias desse monstro,
uma em cada caso.
Se fosse cada um desses novos monstros pelo menos
um pouquinho mais fraco, o motivo de separar em casos
faria sentido.  Mas, como eu acabei de dizer,
em cada caso temos que matar um clono de $G$.
Não uma versão diferente de $G$.  O mesmo $G$!

%%}}}

%%{{{ Q: why case split? 
\question.
%%%{{{ meta 
%%%}}}

Por que separar em casos então e multiplicar nossos alvos?

%%}}}

\spoiler

%%{{{ A: the monsters don't get weaker, but we get stronger 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não é que teus novos alvos são mais fracos---pois eles não são---mas
é você mesmo que fica mais forte em cada um deles.
Em cada caso, ganhas mais uma arma:
o dado que o próprio caso te oferece para matar esse mesmo alvo.

%%}}}

%%{{{ Don't forget a case 
\note Não deixar nenhum caso por fora.
%%%{{{ meta 
%%%}}}

Uma maneira de ter certeza que não esqueceu nada, é escolher uma
propriedade $A$ e separar nos dois casos complementares:
$A$ ou não $A$.
Para um exemplo de como errar, suponha que queremos demonstrar
que para todo inteiro $n$, o $n(n-1)$ é um múltiplo de $3$.
Consideramos dois casos:
\tlist:
\li: Caso $n = 3k$   para algum $k\in\ints$.
\li: Caso $n = 3k+1$ para algum $k\in\ints$.
\endtlist
Em cada um deles, é fácil demonstrar que realmente $n(n-1)$ é
um múltiplo de $3$.  Mas claramente temos um erro aqui,
pois, como um contraexemplo tome o inteiro $2$ e calcule:
$5(5-1) = 20$, e com certeza $20$ não é um múltiplo de $3$.
O problema é que em nossa separação em casos a gente não
considerou todas as possibilidades!
Esquecemos um terceiro caso:
\quote
Caso contrário.
\endquote
Como aprendemos no~\ref[The_integers],
a única possibilidade que deixamos,
esse ``caso contrário'' é equivalente ao:
\quote
Caso $n = 3k+2$  para algum $k\in\ints$.
\endquote
Uma separação em casos correta então seria considerar todos os:
\tlist:
\li: Caso $n = 3k$   para algum $k\in\ints$.
\li: Caso $n = 3k+1$ para algum $k\in\ints$.
\li: Caso $n = 3k+2$ para algum $k\in\ints$.
\endtlist
E com essa separação, felizmente, não podemos demonstrar
essa afirmação errada, pois no terceiro caso, não temos como
matar nosso alvo!

%%}}}

\endsection
%%}}}

%%{{{ RAA_spell 
\section Feitiço: RAA.
%%%{{{ meta 
\label RAA_spell
%%%}}}

\endsection
%%}}}

%%{{{ Contrapositive_spell 
\section Feitiço: Contrapositivo.
%%%{{{ meta 
\label Contrapositive_spell
%%%}}}

\endsection
%%}}}

%%{{{ NNE_spell 
\section Feitiço: NNE.
%%%{{{ meta 
\label NNE_spell
%%%}}}

\endsection
%%}}}

%%{{{ Disjunction_as_implication_spell 
\section Feitiço: Disjunção como implicação.
%%%{{{ meta 
\label Disjunction_as_implication_spell
%%%}}}

\endsection
%%}}}

%%{{{ Uniqueness proofs 
\section Provas de unicidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ More_jargon_and_slang 
\section Mais jargão e gírias.
%%%{{{ meta 
\label More_jargon_and_slang
%%%}}}

%%{{{ obvious_trivial_immediate 
\note Óbvio, trivial, imediato: é mesmo?.
%%%{{{ meta 
\label obvious_trivial_immediate
\defines
    * demonstração!por intimidação
    * trivial
    * óbvio
    ;;
%%%}}}

Muitas vezes matemáticos costumamos deixar certos passos sem
justificativas, ou até enfatisamos escrevendo palavras como
\wq{trivial}, \wq{imediato}, \wq{óbvio}, \wq{fácil}.
Muitas vezes essas palavras são usadas como sinônimos,
mas seus significados não são exatamente iguais.
\dterm{Trivial} é algo que não necessita pensar em nada,
e é só fazer o trabalho de corno óbvio para terminar.\foot
A palavra \dterm{trivial} também é usada para
demonstrações de implicações cuja premissa é falsa,
algo que vamos discutir na~\ref[Implication].
\toof
Note bem que isso significa que o escritor já sabe bem claramente
\emph{qual} é esse trabalho e com certeza
\emph{é capaz de fazê-lo até seu fim} caso que ele for desafiado.
\dterm{Óbvio} e \dterm{fácil} são palávrias notórias entre
matemáticos, como também a frase \wq{exercício para o leitor}.
Normalmente significa que os passos e/ou suas justificativas para
uma parte da demonstração devem ser óbvios (quais exatamente são)
para o leitor.
O uso honesto de ambas é muito conveniente, mas infelizmente elas
podem ser usadas também para criar uma
\dterm{demonstração por intimidação}, a idéia sendo que o leitor
não vai assumir que não consegue ver o passo ``fácil'' em questão,
e logo vai aceitar a demonstração.  \emph{Nunca faça isso!}
\dterm{Imediato} usamos dentro dum caso ou parte duma demonstração
cujo alvo é \emph{intensionalmente equivalente} a um dos dados,
ou quando não falta nada para verificar.\foot
A palavra \dterm{imediato} também é usada para
demonstrações por vacuidade.
\toof
Não fique obcecado com essas ``definições'' ou ``instruções''
sobre o uso dessas palavras; como falei: muitas vezes são
usadas sinonimamente.  Com experiência elaborarás uma noção
melhor de quando e como usá-las.

%%}}}

\endsection
%%}}}

%%{{{ Common errors and fallacies 
\section Erros comuns e falácias.
%%%{{{ meta 
\label Fallacies
\indexes
    * falácia
    ;;
%%%}}}

%%{{{ proof_by_repeating_the_definition 
\note Prova por repetição da definição.
%%%{{{ meta 
\label proof_by_repeating_the_definition
%%%}}}

Imagine que u tá querendo demonstrar que $2x + 8$ é ímpar, onde ímpar quis dizer
Para apreciar quão inútil 
Imagine um advogado defendendo um cara suspeito 
\quote
<<Meu cliente é inocente, porque ele não matou a vítima.>>
\endquote
Ninguém deveria considerar essa frase como um argumento convincente
e válido da inocência do acusado.
Nesse contexto, ``$x$ é inocente'' \emph{significa}
``$x$ não matou a vítima''.
É \emph{exatamente a mesma afirmação}, expressada com outras palavras.
Ou seja, traduzindo o argumento do advogado, percebemos que o que ele falou mesmo foi:
\quote
<<Meu cliente não matou a vítima, porque ele não matou a vítima.>>
\endquote
ou
\quote
<<Meu cliente é inocente, porque ele é inocente.>>
\endquote
dependendo de qual direção da tradução escolhemos aplicar.
Esse advogado não deveria ter muito sucesso no seu futuro assim!\foot
Infelizmente muitas pessoas caem por esse tipo de argumento
na vida real, onde políticos, pastores, e advogados como o não-tão-fictício
do meu exemplo, ``argumentam'' em maneiras erradas para convencer seus
ouvidores (que não estudaram matemática).
\toof

%%}}}

%%{{{ Forget one of the branches 
\note Esquecer um dos ramos.
%%%{{{ meta 
%%%}}}

Lembre-se o modus ponens:
$$
\PROOFm {
\A  {\phi \implies \psi}
\A                           {\phi}
\I2--------------------------------- {M.P.}
                 {\psi}
}
$$
Que nos permite inferir a proposição $\psi$,
pelas \emph{duas} proposições
\elist:
\li: $\phi \implies \psi$;
\li: $\phi$.
\endelist
É comum esquecer sobre uma das duas e mesmo assim tentar
inferir (a partir da outra) a mesma conclusão $\psi$.
Estudando matemática é mais freqüente esquecer a $\phi$;
na vida real qualquer uma das duas pode acabar sendo ``esquecida''.

%%}}}

%%{{{ Denying the antecedent 
\note Refutação do antecedente.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Let and prove vs. Prove that all 
\note Seja e demonstre \vs demonstre que todos.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ if_vs_since 
\note Se \vs como.
%%%{{{ meta 
\label if_vs_since
%%%}}}

Considere as frases seguintes:
$$
\gather
\text{<<Se $\namedhole A$, $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, $\namedhole B$.>>}
\endgather
$$
Observe que, em português, cada uma delas tem uma
palavra implícita logo após da virgula:
$$
\gather
\text{<<Se $\namedhole A$, ({\lthole}) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, ({\lthole}) $\namedhole B$.>>}
\endgather
$$
Quais são?
Na primeira frase a palavra implícita é a ``então'', e na segunda a ``logo'':
$$
\gather
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, (logo) $\namedhole B$.>>}
\endgather
$$
Numa lida superficial as duas frases podem aparecer parecidas.
Mas são bem, bem diferentes!

%%}}}

%%{{{ x: explain_the_difference_between_if_and_since 
\exercise.
%%%{{{ meta 
\label explain_the_difference_between_if_and_since
%%%}}}

Qual é a diferença entre as duas frases?

\solution
A frase
$$
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}
$$
é uma afirmação: que a proposição $A$ implica a proposição $B$.
Ou seja, não está afirmando que a proposição $A$ é verdade (nem que é falsa),
e também nada sobre a vericidade da $B$.
No outro lado, a frase
$$
\text{<<Como $\namedhole A$, (logo) $\namedhole B$.>>}
$$
é uma \emph{argumentação}.
Seu escritor já usa como fato conhecido que $A$ é verdade,
e além disso, ele tá afirmando que $B$ também é verdade por causa disso.
Em outras palavras, o escritor está \emph{inferindo} a $B$ a partir das
afirmações $A$ e $A \implies B$ que ele deixa como implícito que o
leitor aceita ambas.

%%}}}

%%{{{ warning: only_declare_variables 
\warning Declare apenas variáveis.
%%%{{{ meta 
\label only_declare_variables
%%%}}}

Não podemos ``sejar'' algo que envolve um termo.
Não faz sentido escrever
\quote
Seja $x+y$ natural.
\endquote
por exemplo.
Novamente: depois dum ``seja'' segue uma variável,
inclusive fresca para evitar sombreamento (\reftag[variable_capturing_and_shadowing]).
Voltando no exemplo da soma, não faria sentido escrever:
\quote
Sejam $x,y$ naturais.
Seja $x+y$ a soma dos $x$ e $y$.
\endquote
Não!
Já definimos a operação binária $+$ entre naturais, então
não podemos ``sejar'' a expressão \symq{$x+y$}.
Quando ``sejamos'' algo como um membro arbitrário dum conjunto
usamos apenas uma variável!  Nem constantes, nem termos que
involvem operações.  Imagine alguém escrevendo:
<<seja $3\in\ints$>>, ou <<seja $x^2 \in \reals$>>.
Não!  A operação $\dhole^2$ já é definida, e logo para
qualquer real $r$ o real $r^2$ já é definido!
Para dar um exemplo para quem programou em linguagem similar à C.
Tu escreverias essas declarações?
\sourcecode onlydeclarevars.c;
Espero que não!

%%}}}

\TODO complete and provide math and life examples.

\endsection
%%}}}

%%{{{ Wrong; now what? 
\section Deu errado; e agora?.
%%%{{{ meta 
%%%}}}

\TODO Erro na demonstração não é suficiente para dizer que o teorema é errado.

\TODO Conseqüência de teorema errado não é suficiente para concluir que
a conseqüência é errada também.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: change_order_of_like_quantifiers 
\problem.
%%%{{{ meta 
\label change_order_of_like_quantifiers
%%%}}}

Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre as equivalências:
$$
\forall x \sforall y \phi(x,y)
\askiff
\forall y \sforall x \phi(x,y).
$$
Podes demonstrar ou refutar a outra?

%%}}}

%%{{{ prob: change_order_of_unlike_quantifiers 
\problem.
%%%{{{ meta 
\label change_order_of_unlike_quantifiers 
%%%}}}

Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre \emph{uma} das duas direções da equivalência
$$
\forall x \sexists y \phi(x,y)
\askiff
\exists y \sforall x \phi(x,y).
$$
Podes demonstrar ou refutar a outra?

%%}}}

%%{{{ prob: sym_and_trans_derivable 
\problem.
%%%{{{ meta 
\label sym_and_trans_derivable
%%%}}}

Precisamos mesmo aceitar como axiomas todas as leis no \ref[laws_of_eq]?

\hint
Não.
Da pra aceitar apenas duas elas como axiomas e derivar as outras duas.
Quais?
Como?

\hint
Podemos derivar a simetria e a transitividade
a partir da reflexividade e da substituição (que aceitamos sim como
axiomas).
Como?

%%}}}

\endproblems
%%}}}

%%{{{ Back to Ancient Greece: irrationals 
\section De volta pra Grécia antiga: irracionais.
%%%{{{ meta 
%%%}}}

%%{{{ √2 is not rational 
\note O √2 não é racional.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ But √2 surely is a number 
\note Mas o √2 com certeza é um número.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Irrational numbers 
\note Números irracionais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ √3 is irrational 
\note O √3 é irracional.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ A lemma 
\note Um lemma.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ What happens with √4 and √5 
\note O que acontece com √4 e √5.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ A generalization theorem 
\note Um teorema de generalização.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ More irrational numbers 
\note Mais números irracionais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Algebraic and transcendental numbers 
\note Números algébricos e transcendentais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: transcendentality_of_one_of_epluspi_etimespi 
\problem.
%%%{{{ meta 
\label transcendentality_of_one_of_epluspi_etimespi
%%%}}}

Dado que ambos os $e,\pi$ são transcendentais,
mostre que pelo menos um dos $e+\pi$, $e\pi$ é transcendental.

\hint
Reductio ad absurdum.

\hint
Para chegar num absurdo, suponha que ambos os
$$
\xalignat2
S &= e + \pi &
P &= e\pi
\endxalignat
$$
são algébricos.
Se conseguir achar um polinómio com coeficientes algébricos
tal que $e,\pi$ são raizes dele então acabou!

\solution
Demonstramos usando reductio ad absurdum.
Suponha então que ambos são algébricos e
vamos chamá-los assim:
$$
\xalignat2
S &= e + \pi &
P &= e\pi.
\endxalignat
$$
Agora considere o polinômio
$$
f(x) = x^2 - Sx + P
$$
e observe que $e,\pi$ são raizes dele:
$$
\align
f(e)   &= e^2   - (e + \pi)e + e\pi   = 0 \\
f(\pi) &= \pi^2 - (e + \pi)\pi + e\pi = 0.
\endalign
$$
Chegamos assim na contradição que $e,\pi$
são algébricos, pois os coeficientes do $f$ são.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[nivenirrational].
\cite[velleman: Cap.~3].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Nat_rec_ind 
\chapter Naturais; recursão; indução.
%%%{{{ meta 
\label Nat_rec_ind
%%%}}}

\TODO finish merging.

%%{{{ intro: we define Nats, not the natural numbers 
\chapintro
Vou começar definindo formalmente os naturais.
Na verdade, não vou definir os próprios números naturais.
Não: os \emph{números} estão lá nas núvens do nosso coração.
Não vamos nos preocupar com a questão <<o que \emph{é} o número cinco?>>.
Vamos começar definindo uns \emph{numeráis}, que vou chamá-los de Nats,
e a gente vai estudá-los e ver o que podemos definir, calcular, e demonstrar
sobre eles.
%%}}}

%%{{{ The natural numbers formally 
\section Os números naturais formalmente.
%%%{{{ meta 
\label Nats_formally
%%%}}}

%%{{{ df: Nat 
\definition Nat.
%%%{{{ meta 
\label Nat
\defines
    * Nat
    ;;
%%%}}}

Definimos os \dterm{numerais $\Nat$} para representar os números naturais
com uma definição inductiva:
\tlist:
\li: $0$ é um $\Nat$;
\li: Se $n$ é um $\Nat$, então $Sn$ é um $\Nat$;
\endtlist
Nada mais é um $\Nat$.

%%}}}

%%{{{ With BNF 
\note Com gramática BNF.
%%%{{{ meta 
%%%}}}

Já fizemos isso na~\ref[Nat_grammar]:
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$

%%}}}

%%{{{ With rules of inference 
\note Com regras de inferência.
%%%{{{ meta 
%%%}}}

Uma maneira diferente de descrever a mesma idéia é com \dterm{regras de inferência}.
Essa abordagem combina bem com as árvores sintácticas:
escrevemos
$$
\PROOFm {
\I0-------------- {}
    {0 \is \Nat}
}
$$
e entendemos isso como
$$
\text{<<(do nada) posso concluir que $0$ é um $\Nat$>>}.
$$
Esse ``do nada'' aqui quis dizer ``sem nenhuma premissa''.
Vamos dar o nome \namedrule{Zero} para essa \emph{regra de inferência},
pois vamos precisar referir a ela depois.
Escrevemos seu nome no lado direito da linha de inferência.
Fica assim:
$$
\PROOFmr {
\I0-------------- {Zero}
    {0 \is \Nat}
}
$$
Olhando pra isso entendemos o seguinte:
a regra \namedrule{Zero}\ nos permite inferir que $0$ é um $\Nat$.

%%}}}

%%{{{ Q: how would you represent... 
\question.
%%%{{{ meta 
%%%}}}

Como tu representaria a segunda regra da~\ref[Nat] como uma regra
de inferência?

%%}}}

\spoiler

%%{{{ with inference rules 
\note Com regras de inferência.
%%%{{{ meta 
%%%}}}

$$
\xalignat2
&
\PROOFmr {
\I0----------- {Zero}
{0 \is \Nat}
}
&&
\PROOFmr {
\A  {n \is \Nat}
\I1-------------- {Succ}
   {Sn \is \Nat}
}
\endxalignat
$$

%%}}}

%%{{{ x: spot meta vs object on the definitions above 
\exercise.
%%%{{{ meta 
%%%}}}

Identifique variáveis \vs metavariáveis e símbolos da
linguagem-objeto \vs da metalinguagem nas definições acima.

%%}}}

%%{{{ eg: SSSS0 is a nat (inference tree) 
\example usando árvores.
%%%{{{ meta 
%%%}}}

Vamos inferir que $SSSS0$ é um $\Nat$ mesmo.

\solution.
Vamos construir sua árvore ``bottom-up''.
O desafio é inferir que
$$
SSSS0 \is \Nat
$$
e usando a regra \namedrule{Succ} podemos \emph{reduzir} esse problema para
$$
\PROOFmr {
\A  {SSS0 \is \Nat}
\I1------------------ {Succ}
    {SSSS0 \is \Nat}
}
$$
Essa árvore tem afirmações ``abertas'' então não terminamos ainda.
Usando a mesma regra reduzimos o $SSS0 \is \Nat$ para:
$$
\PROOFmr {
\A {SS0 \is \Nat}
\I1---------------- {Succ}
   {SSS0 \is \Nat}
\I1----------------- {Succ}
   {SSSS0 \is \Nat}
}
$$
e continuando nessa maneira, chegamos finalmente no
$0 \is \Nat$ que inferimos com a regra \namedrule{Zero},
fechando assim a única coisa que tava aberta:
$$
\PROOFmr {
\I0------------ {Zero}
   {0 \is \Nat}
\I1------------- {Succ}
   {S0 \is \Nat}
\I1-------------- {Succ}
   {SS0 \is \Nat}
\I1--------------- {Succ}
   {SSS0 \is \Nat}
\I1---------------- {Succ}
   {SSSS0 \is \Nat}
}
$$

%%}}}

%%{{{ x: read the tree bottom-up and top-down 
\exercise.
%%%{{{ meta 
%%%}}}

Leia essa árvore tanto de baixo pra cima, quanto de cima pra baixo!

%%}}}

%%{{{ eg: SSSS0 is a nat (grammar) 
\example usando a gramática.
%%%{{{ meta 
%%%}}}

Vamos inferir que $SSSS0 \is \Nat$ de novo, essa vez usando
a definição com a gramática.

\solution.
Temos:
$$
\align
\bnf{Nat}
&\leadsto S\bnf{Nat} \\
&\leadsto SS\bnf{Nat} \\
&\leadsto SSS\bnf{Nat} \\
&\leadsto SSSS\bnf{Nat} \\
&\leadsto SSSS0.
\endalign
$$

%%}}}

%%{{{ Using words 
\note Usando palavras.
%%%{{{ meta 
%%%}}}

Podemos inferir que $SSSS0 \is \Nat$ usando palavras tambem, ficando assim
mais perto da~\ref[Nat], mas para esse tipo de derivação fica bizarro:
\quote
<<Como $0$ é um Nat (pela primeira cláusula),
logo $S0$ é um Nat (pela segunda com $n\asseq 0$).
Logo $SS0$ é um Nat, de novo pela segunda cláusula, essa vez com $n\asseq S0$\dots>>
\endquote
E já cansei de escrever então vou parar aqui.
Espero que apreciamos a laconicidade e clareza das árvores
para esse tipo de inferência.

%%}}}

%%{{{ eg: 0,1,2,3 ; primes 
\example.
%%%{{{ meta 
%%%}}}

Aqui os numerais de $\Nat$ que correspondem nos primeiros
quatro números naturais:
$$
0,\quad
S0,\quad
SS0,\quad
SSS0.
$$
Escrevemos a seqüência de primos então assim:
$$
SS0,\quad
SSS0,\quad
SSSSS0,\quad
SSSSSSS0,\quad
SSSSSSSSSSS0,\quad\dots
$$
Ou seja, cada número natural $n$ corresponde numa seqüência
de $n$ cópias de $S$, seguidas por um $0$.

%%}}}

%%{{{ remark: unary numeral system 
\remark.
%%%{{{ meta 
%%%}}}

Esse sistema de numerais é praticamente um sistema unário.
A grande \emph{desvantagem} dele é que o tamanho dos numeráis cresce
analogamente com o tamanho de números.
Comparando com os sistemas mais comuns com bases $b > 1$ como o binário
ou o decimal, já parece deficiente nesse sentido.
Mas uma \emph{vantagem} para a gente nesse caso é sua simplicidade
na sua definição recursiva:
\emph{cada $\Nat$ ou é o zero, ou o sucessor de um $\Nat$}.
Todo esse capítulo é desenvolvido usando apenas essa definição.

%%}}}

%%{{{ canonic_nats 
\definition Os Nats canônicos.
%%%{{{ meta 
\label canonic_nats
\defines
    * canônico
    ;;
%%%}}}

Chamamos os termos da linguagem $\bnf{Nat}$ os Nats \dterm{canônicos:}
$$
0, S0, SS0, SSS0, SSSS0, \dotsc
$$

%%}}}

%%{{{ operator_vs_constructor 
\note Operador \vs construtor.
%%%{{{ meta 
\label operator_vs_constructor
\defines
    * construtor
    ;;
%%%}}}

Logo vamos definir operações nos Nats ($+$, $\ntimes$, etc.)
e vamos ter, por exemplo, que
$$
S(SS0 + (SSS0 \ntimes SS0)) \is \Nat
$$
também, mas obviamente faz sentido perguntar
\quote
<<Quanto é $S(SS0 + (SSS0 \ntimes SS0))$?>>
\endquote
e a resposta deve ser $SSSSSSSSS0$.
Mas não faz sentido perguntar
\quote
<<Quanto é $SS0$?>>
\endquote
Ou seja: esse $S$ (quem vem da palavra ``sucessor'') não representa
um operador que deve ser aplicado num argumento e que vai retornar um
resultado com valor.  Não!  Esse $S$ é o que chamamos de \dterm{construtor}
de valores, ou seja, o $SS0$ já é um valor próprio, um valor final,
um valor canônico: sem nada mais para ser calculado.
Por o mesmo motivo não faz sentido perguntar
\quote
<<Quanto é $2$?>>
\endquote
$2$ é $2$ ué.

%%}}}

%%{{{ property: Equality 
\property Igualdade.
%%%{{{ meta 
%%%}}}

Naturalmente consideramos todos os valores canônicos como distintos,
ou seja, para todos os $x,y\is\Nat$ temos:
$$
\align
& 0 \neq Sx \\
x \neq y &\implies Sx \neq Sy
\intertext{e a segunda é freqüentemente usada na forma da sua contrapositiva:}
Sx = Sy &\implies x = y
\endalign
$$
que nos permite ``cortar os $S$'s'' numa igualdade entre sucessores.

%%}}}

%%{{{ Syntactic sugar 
\note Açúcar sintáctico.
%%%{{{ meta 
%%%}}}

Eu vou usar os
$$
0, 1, 2, 3, \dotsc
$$
como outros nomes dos Nats
$$
0, S0, SS0, SSS0, \dotsc
$$
ou seja, como açúcar sintáctico.
Mas é importante entender que são apenas isso, um nóme alternativo
para os termos ``verdadeiros''; então quando eu peço para calcular,
por exemplo, o $3\ntimes 2$, tu precisas calcular mesmo o
$$
SSS0 \ntimes SS0.
$$
E espero que tu chegarás no resultado que eu chamaria de $6$,
ou seja, no $SSSSSS0$.

%%}}}

\endsection
%%}}}

%%{{{ Defining functions recursively 
\section Definindo funcções recursivamente.
%%%{{{ meta 
%%%}}}

%%{{{ df: nats_plus_recursive_def 
\definition Adição.
%%%{{{ meta 
%%%}}}

Definimos a operação $+$ no $\Nat$ pelas:
$$
\align
n + 0   &= n      \tag{a1}\\
n + S m &= S(n+m) \tag{a2}
\endalign
$$

%%}}}

%%{{{ eg: three_plus_two_formally 
\example.
%%%{{{ meta 
\label three_plus_two_formally
%%%}}}

Calcule a soma $SSS0 + SS0$.

\solution.
Temos a expressão
$$
SSS0 + SS0.
$$
Qual equação aplica?
Com certeza não podemos aplicar a primeira (na direção ``$\Rightarrow$''),
pois nossa expressão não tem a forma $n + 0$.
Por que não?  O primeiro termo na nossa expressão, o $SSS0$, não é um problema
pois ele pode ``casar'' com o $n$ do lado esquerdo da (a1).
Mas nosso segundo termo, o $SS0$,
não pode casar com o $0$, então a (a1) não é aplicável.
A segunda equação é sim, pois nossos termos podem casar assim
com as variáveis da (a2):
\compute
{\mubrace{SSS0}n} + {S\mubrace{S0}m} \\
\intertext{Tomando $n\asseq SSS0$ e $m\asseq S0$
substituimos nossa expressão por seu igual seguindo a (a2):}
{\mubrace{SSS0}n} + {S\mubrace{S0}m}
&= S\bigparen{ {\mubrace{SSS0}n} + {\mubrace{S0}m} }  \by {por (a2)} \\
\intertext{Depois um passo de cálculo então chegamos na expressão
$S(SSS0 + S0)$.
Como nenhuma equação tem a forma $S(\text{\thole}) = \text{\lthole}$,
olhamos ``dentro'' da nossa expressão para achar nas suas subexpressões
possíveis ``casamentos'' com nossas equações.
Focamos então na subexpressão sublinhada
$S(\underline{SSS0 + S0})$:
vamos tentar substituí-la por algo igual.
Novamente a primeira equação não é aplicavel
por causa do novo segundo termo ($S0$), mas a (a2) é:}
S\bigparen{{\mubrace{SSS0}n} + {S\mubrace{0}m}}\\
\intertext{Tomando agora $n\asseq SSS0$ e $m\asseq 0$ substituimos de novo
seguindo a (a2):}
S\tobrace{\bigparen{{\mubrace{SSS0}n} + {S\mubrace{0}m}}}{isso}
&= S\tobrace{S\bigparen{ {\mubrace{SSS0}n} + {\mubrace{0}m} }}{por isso}  \by {por (a2)} \\
\intertext{Agora focamos na subexpressão $SS(\underline{SSS0 + 0})$ e podemos finalmente
aplicar a primeira equação:}
SS\bigparen{{\mubrace{SSS0}n} + 0}\\
\intertext{então tomando $n\asseq SSS0$ substituimos}
SS\tobrace{\bigparen{{\mubrace{SSS0}n} + 0}}{isso}
&= SS\tobrace{ {\mubrace{SSS0}n} }{por isso}  \by {por (a1)} \\
\endcompute
Finalmente chegamos no resultado: no termo $SSSSS0$.
Nunca mais vamos escrever tudo isso com tanto detalhe!
Esse cálculo que acabamos de fazer, escrevemos curtamente nessa forma:
\compute
SSS0 + SS0
&= S(SSS0 + S0) \by {por (a2)} \\
&= SS(SSS0 + 0) \by {por (a2)} \\
&= SSSSS0       \by {por (a1)} \\
\endcompute
escrevendo apenas em cada linha o que foi usado.

%%}}}

%%{{{ When do I stop? 
\note Quando termino?.
%%%{{{ meta 
%%%}}}

Termino quando chegar num \emph{valor canônico}.
Quando eu peço calcular quanto é $SSS0 + SS0$ por exemplo,
a idéia é achar seu valor canônico, exatamente como acontece
quando pedimos para uma pessoa achar
\quote
<<Quanto é $2+3$?>>
\endquote
Uma resposta
\quote
<<$2+3=2+3$>>
\endquote
não seria aceitável---mesmo assim, é correta, não é?---pois
a pessoa que perguntamos não achou o valor canόnico (nesse caso $5$).

%%}}}

%%{{{ Is it always possible to terminate? 
\note Dá pra terminar sempre?.
%%%{{{ meta 
%%%}}}

Sempre tem como chegar num valor canônico?
Por enquanto não sabemos!
Realmente a $+$ na maneira que foi definida é uma operação
\dterm{total}, ou seja, sempre termina num valor canônico,
mas não é algo que deve se preocupar neste momento.
Estudamos muito esse assunto no~\ref[Theory_of_recursive_functions].

%%}}}

%%{{{ x: zero_plus_four_formally 
\exercise.
%%%{{{ meta 
\label zero_plus_four_formally
%%%}}}

Calcule a soma dos $0 + SSSS0$.

%%}}}

%%{{{ Evaluation strategy 
\note Estratégias de evaluação.
%%%{{{ meta 
\defines
    * estratégia!de evaluação
    ;;
%%%}}}

Vamos dizer que queremos calcular começando com uma expressão mais complexa,
como por exemplo a
$$
0 + \bigparen{0 + S\bigparen{(SS0 + 0) + 0}}.
$$
Como procedimos?
A expressão inteira não pode ser substituida pois nenhuma das (a1)--(a2) tem
essa forma, mas aparecem várias subexpressões em quais podemos \emph{focar}
para nosso próximo passo de cálculo:
$$
\align
0 + \underline{\bigparen{0 + S\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com (a2)}\\
0 + \bigparen{0 + S\underline{\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com (a1)}\\
0 + \bigparen{0 + S\bigparen{\underline{(SS0 + 0)} + 0}},&\quad\text{casando com (a1)}.
\endalign
$$
Podemos seguir uma \dterm{estratégia de evaluação} específica, por exemplo,
focando sempre na expressão que aparece primeira à esquerda; ou podemos
escolher cada vez onde focar aleatoriamente; etc.
No~\ref[three_plus_two_plus_one] tu vai ter que escolher onde focar
várias vezes.

%%}}}

%%{{{ x: three_plus_two_plus_one 
\exercise.
%%%{{{ meta 
\label three_plus_two_plus_one
%%%}}}

Calcule os valor das expressões $SSS0 + (SS0 + S0)$ e $(SSS0 + SS0) + S0$.

\solution
Um caminho para calcular a primeira é o seguinte:
\compute
SSS0 + \underline{(SS0 + S0)}
&= SSS0 + S\underline{(SS0 + 0)} \by {por (a2)} \\
&= \underline{SSS0 + SSS0}       \by {por (a1)} \\
&= S\underline{(SSS0 + SS0)}     \by {por (a2)} \\
&= SS\underline{(SSS0 + S0)}     \by {por (a2)} \\
&= SSS\underline{(SSS0 + 0)}     \by {por (a2)} \\
&= SSSSSS0                       \by {por (a1)} \\
\intertext{e um caminho para calcular a segunda é o:}
\underline{(SSS0 + SS0) + S0}
&= S(\underline{(SSS0 + SS0)} + 0)  \by {por (a2)} \\
&= S(S\underline{(SSS0 + S0)} + 0)  \by {por (a2)} \\
&= S\underline{(SS(SSS0 + 0) + 0)}  \by {por (a2)} \\
&= SSS\underline{(SSS0 + 0)}        \by {por (a1)} \\
&= SSSSSS0                          \by {por (a1)} \\
\endcompute

%%}}}

%%{{{ Where is the recursion and what don't we have a tijolo problem? 
\note Cadê a recursão e por quê não temos problema tipo tijolo?.
%%%{{{ meta 
%%%}}}

Estamos definindo a própria operação $+$, e na segunda linha
da sua definição aparece o $+$ tanto no lado esquerdo, quanto no lado direito.
Por isso chamamos a definição recursiva.
Se definimos $+$ em termos dele mesmo, por que não temos o problema
tipo \emph{tijolo} que discutimos no \ref[what_is_tijolo]?
(Chegou a hora que tinha prometido no~\reftag[recursive_definitions_teaser].)
Olhando com mais atenção, percebemos que não definimos o que significa
\emph{somar} em termos do que significa \emph{somar} mesmo;
mas definimos sim o que significa \emph{somar os números $n$ e $Sm$}
em termos do que significa \emph{somar os números $n$ e $m$}.
No lado direito, uma coisa nos argumentos da nossa operação está
diminuindo (os $S$'s do segundo argumento) assim evitando o loop
infinito, chegando finalmente na primeira equação \emph{depois duma
quantidade finita} de perguntas <<e o que é\dots?>>.

%%}}}

%%{{{ x: nats_double_def 
\exercise.
%%%{{{ meta 
\label nats_double_def
%%%}}}

Defina (recursivamente) a funcção $d : \Nat \to \Nat$ que dobra sua entrada.
Verifique que o dobro de três ($SSS0$) é seis ($SSSSSS0$).

\hint
Pensando fora do $\Nat$:
como podemos calcular o valor de $2(n+1)$, se sabemos como dobrar
qualquer número menor de $n+1$?

\hint
$2(n+1) = 2n + 2$.

\solution
Definimos:
$$
\align
d( 0 )  &= 0        \tag{D1}\\
d( Sn ) &= SSd(n).  \tag{D2}
\endalign
$$
Calculamos:
\compute
d( SSS0 )
&= SSd(SS0)    \by {por (D2)} \\
&= SSSSd(S0)   \by {por (D2)} \\
&= SSSSSSd(0)  \by {por (D2)} \\
&= SSSSSS0.    \by {por (D1)} \\
\endcompute

%%}}}

%%{{{ A worse programmer 
\note Um programador pior.
%%%{{{ meta 
%%%}}}

Alguém definiu a adição usando essas quatro equações:
$$
\align
0  + 0  &= 0  \\
Sn + 0  &= Sn \\
0  + Sm &= Sm \\
Sn + Sm &= S(Sn + m)
\endalign
$$
Ou seja, para cada argumento da operação, ele tratou os dois
casos principais separadamente, resultando assim em quatro
equações.
Mas, olhando nas primeiras duas, dá pra ver que ambás são
casos especiais da nossa primeira equação.
No final das contas, nas duas o que acontece é que o primeiro
argumento acaba sendo o resultado da soma, e é exatamente isso
que nossa primeira equação disse.
Nossa definição é bem melhor então, mais elegante e econômica.

%%}}}

%%{{{ x: nats_ntimes_recursive_def 
\exercise.
%%%{{{ meta 
\label nats_ntimes_recursive_def
%%%}}}

Defina a multiplicação no $\nats$.

\hint
Precisa de novo duas equações:
$$
\align
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
A primeira equação é fácil completar:
$$
\align
n \ntimes 0   &= 0
\intertext{talvez ajuda pensar numa outra equação mais simples:}
n \ntimes S0  &= \text{\lthole}
\endalign
$$
Depois?

\hint
Tu tens acesso na operação \symq{$+$} pois já definimos!

\hint
Provavelmente até agora tens:
$$
\align
n \ntimes 0    &= 0 \\
n \ntimes S0   &= n \\
n \ntimes SS0  &= n + n \\
n \ntimes SSS0 &= (n + n) + n \\
               &\eqvdots
\intertext{Observe que o ``valor'' (lado direito) de cada nova linha é o valor
da linha anterior ``$+n$''.  Mas temos um nome para o lado direito da linha
anterior: \emph{seu lado esquerdo!}
Isso deve ser suficiente para achar como escrever a segunda linha da definição:}
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
Na segunda equação, no seu lado direito, tu tens acesso no valor
$n \ntimes m$, pois é ``mais simples'' do que o $n \ntimes Sm$.
Isso é o poder da recursão: podes considerar o problema que tu
tá tentando resolver (definir a multplicação), como resolvido
para as ``entradas mais simples''.

\solution
$$
\align
n \ntimes 0  &= 0                 \tag{m1}\\
n \ntimes Sm &= (n\ntimes m) + n  \tag{m2}
\endalign
$$

%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule o $2(0+1)$.

%%}}}

%%{{{ x: two_times_three_and_three_times_two 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule os $2 \ntimes 3$ e $3 \ntimes 2$.

%%}}}

%%{{{ x: nats_exp_recursive_def 
\exercise.
%%%{{{ meta 
\label nats_exp_recursive_def
%%%}}}

Defina a exponenciação no $\nats$.

\solution
Definimos:
$$
\align
n \expop 0  &= S0 \\
n \expop Sm &= (n \expop m) \ntimes n.
\intertext{ou, se preferir usar a notação padrão para exponenciação e multiplicação:}
n^0    &= S0 \\
n^{Sm} &= n^m \ntimes n.
\intertext{Também pode ser definida assim:}
n^0    &= S0 \\
n^{Sm} &= n \ntimes n^m.
\endalign
$$
Depois vamos comparar essas duas definições.

%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule o $2^3$.

%%}}}

%%{{{ x: fibonacci_nats 
\exercise.
%%%{{{ meta 
\label fibonacci_nats
%%%}}}

Defina usando equações recursivas a \dterm{seqüência Fibonacci},
como uma funcção de $\Nat$ para $\Nat$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Proving properties of natural numbers without induction 
\section Provando propriedades de naturais sem indução.
%%%{{{ meta 
\label Proving_properties_of_nats_by_induction
%%%}}}

%%{{{ convention about quantifiers 
\note Convenção.
%%%{{{ meta 
%%%}}}

Nessa secção todos os quantificadores que aparecem ``nus'' em fórmulas
\emph{quantificam sobre os naturais}.  Por exemplo
$$
\forall x
\forall y
\exists z
\forall w
P(x,y,z,w)
$$
significa
$$
\pforall {x \in \nats}
\pforall {y \in \nats}
\pexists {z \in \nats}
\lforall {w \in \nats}
{P(x,y,z,w)}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos primeiramente \emph{definir} recursivamente as tres operações de adição,
multiplicação, e exponenciação:

%%}}}

%%{{{ df: natops_rec_defs 
\definition.
%%%{{{ meta 
\label natops_rec_defs
%%%}}}

Definimos as operações de adição, multiplicação, e exponenciação
recursivamente assim:
$$
\xxalignat3
&
\alignedat2
\text{(a1)}&\quad&  n + 0  &= n     \\
\text{(a2)}&&       n + Sm &= S(n+m)
\endalignedat
&&
\alignedat2
\text{(m1)}&\quad&  n \ntimes 0  &= 0   \\
\text{(m2)}&&       n \ntimes Sm &= (n \ntimes m) + n
\endalignedat
&&
\alignedat2
\text{(e1)}&\quad&  n \expop 0  &= S0   \\
\text{(e2)}&&       n \expop Sm &= (n \expop m) \ntimes n.
\endalignedat
\endxxalignat
$$
Observe que cada uma dessas equações tem um implícito
$\forall n$ ou $\forall n\forall m$ na frente dela.

%%}}}

%%{{{ conventions about precedence and associativity 
\note Convenções.
%%%{{{ meta 
%%%}}}

Seguindo a convenção comum, escrevemos o $x\expop y$ como $x^y$,
mas mesmo assim consideramos isso como um açúcar sintáctico para
a expressão $x \expop y$.  Entendemos então que no $x^y$ temos
uma aplicação duma operação binária (aplicada nos argumentos $x$ e $y$).
Vamos seguir também a convenção que a exponenciação
``pega mais forte'' que as outras duas operações,
e que multiplicação pega mais forte que a adição:
$a \ntimes b^c$ escrito sem parênteses quis dizer
$a \ntimes (b \expop c)$ e não $(a \ntimes b) \expop c$;
e $a + b\ntimes c$ quis dizer $a + (b\ntimes c)$.
Graças às associatividades das $+$ e $\ntimes$
(\ref[natadd_is_associative] e~\ref[natmult_is_associative])
podemos escrever $a + b + c$ e $a \ntimes b \ntimes c$,
mas para a exponenciação que não é associativa escolhemos
a associatividade-direita: $a^{b^c}$ é $a \expop (b \expop c)$
e não $(a \expop b) \expop c$.

%%}}}

%%{{{ + is associative 
\proposition.
%%%{{{ meta 
%%%}}}

A $+$ é associativa.

%%}}}

%%{{{ natadd_is_associative_failed_proof_attempt 
\note Tentativa de demonstração.
%%%{{{ meta 
\of natadd_is_associative
\label natadd_is_associative_failed_proof_attempt
%%%}}}

Vamos tentar demonstrar essa proposição.
Primeiramente, o que a afirmação significa?
A adição é essa operação $+$ que definimos na~\ref[natops_rec_defs].
Vamos tentar escrever essa afirmação numa maneira mais formal
para expor sua estrutura lógica:
$$
\forall n \forall m \forall k
\bigparen{ (n+m) + k = n + (m+k) }.
$$
Nosso alvo tem a forma
$$
\lforall {x\in\nats} {\phi(x)}
$$
olhando como
$$
\forall n
\mubrace
    {\aB{\forall m \forall k \bigparen{ (n+m) + k = n + (m+k) }}}
    {\aB{\phi_1(n)}}
$$
podemos atacá-la tomando um arbitrario membro de $\Nat$ e mostrando
que ele goza a propriedade $\phi$.
\eop
Seja $a \in \Nat$ então.
Agora precisamos mostrar que $\phi(a)$, ou seja nosso alvo é
$$
\forall m \forall k
\bigparen{ (n+m) + k = n + (m+k) }.
$$
Observe que nosso alvo é apenas uma afirmação sobre o natural $k$.
Beleza.
Mas nosso alvo tem a mesma forma,
$$
\mubrace
  {\forall m \mubrace
               {\aB{\forall k \bigparen{ (a+m) + k = a + (m+k) }}}
               {\aB{\phi_2(m)}}}
  {\phi_1(a)}
$$
então podemos atacar novamente
coma mesma idéia, ``sejando'' mais um natural.
\eop
Seja $m\in\Nat$.
Preciso demonstrar que
$$
\mubrace
  {\forall k \mubrace
               {\aB{(a+m) + k = a + (m+k)}}
               {\aB{\phi_3(k)}}}
  {\phi_2(m)}.
$$
Atacamos uma última vez com a mesma estratégia:
\eop
Seja $y\in\Nat$.
Agora precisamos demonstrar
$$
\mubrace
  {(a+m) + y = a + (m+y)}
  {\phi_3(y)}.
$$
E agora?
Como chegamos numa igualdade, precisamos verificar que seus dois lados
realmente denotam o mesmo valor.
Vamos calcular então.
Tomando o lado esquerdo, $(a+m)+y$, tantamos casá-lo com as equações
(a1)--(a2), mas ele não casa com nenhuma delas, então não tem como
simplificá-lo.\foot
Isso não é exatamente verdade, pois o lado direito
da (a1), sendo apenas uma variável, casa com qualquer coisa.
Mas escolhendo qualquer (sub)expressão da $(a+m)+y$, para casar
com $n$, não vamos ter progresso nenhum, pois vamos acabar
adicionando apenas uns ``$+0$'' até cansar, sem nenhuma
mudança na posição das parenteses que nos importam aqui.
\toof

%%}}}

%%{{{ Q: Seems like a dead end---or is it? 
\question.
%%%{{{ meta 
\label not_a_dead_end_without_induction
%%%}}}

Parece que chegamos num ``dead end''.
Tem como continuar?

%%}}}

\spoiler

%%{{{ A: case split 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Tem!
O problema foi que não sabemos nem sobre o $m$ nem sobre o $y$
se são da forma $0$ ou da forma $S\bnf{Nat}$ e por isso não conseguimos
aplicar nenhuma das (a1)--(a2).
Mas podemos \emph{separar em casos}.
Vamos escolher um desses Nats então, o $y$, e considerar:
\tlist:
\li: \case{Caso} $y$ é o $0$: \dots
\li: \case{Caso} $y$ é o successor de algum Nat: \dots
\endtlist
Lembre-se que cada vez que separamos em casos, nosso alvo
tá sendo \emph{copiado e colado} para cada um deles.

%%}}}

%%{{{ x: solve_the_zero_case_of_case_split_of_natadd_is_associative 
\exercise O primeiro caso.
%%%{{{ meta 
\label solve_the_zero_case_of_case_split_of_natadd_is_associative
%%%}}}

Demonstre que
$$
(a+m) + y = a + (m+y)
$$
no primeiro caso.

\hint
Pega um lado e calcule até chegar no outro;
ou se não conseguir chegar no outro lado,
trabalhe no outro lado separadamente até
chegar no mesmo.

\hint
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= \dots?
\endcompute

\hint
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= a + m       \by {pela~(a1)} \\
\intertext{Se travou aqui, sem problema:
trabalhe no outro lado até chegar em $a + m$:}
a + (m + y) &= \dots? \\
&\eqvdots\\
&= a + m
\endcompute

\solution
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= a + m       \by {pela~(a1)} \\
a + (m + y)
&= a + (m + 0) \by {hipótese do caso} \\
&= a + m       \by {pela~(a1)} \\
\endcompute

%%}}}

%%{{{ The second case 
\note O segundo caso.
%%%{{{ meta 
%%%}}}

Sabemos que $y$ é o sucessor de algum natural,
então vamos escolher um nome pra denotá-lo:
\emph{seja $y'$ natural tal que $y = Sy'$}\fact1.
Calculamos:
\compute
(a + m) + y
&= (a + m) + Sy'       \by {hipótese~\byfact1} \\
&= S\paren{(a+m) + y'} \by {(a2), com $n\asseq (a+m)$, $m\asseq y'$} \\
\intertext{e o outro lado}
a + (m + y)
&= a + (m + Sy')   \by {hipótese~\byfact1} \\
&= a + S(m + y')   \by {(a2) com $n\asseq m$, $m\asseq y'$} \\
&= S(a + (m + y')) \by {(a2) com $n\asseq a$, $m\asseq m+y'$} \\
\endcompute
E agora peguntamos
$$
S((a + m) + y')
\askeq
S(a + (m + y'))
$$
e para resolver isso basta ``cortar os $S$'s'' e demonstrar que
$$
(a+m) + y' = a + (m + y').
$$
\emph{E estamos onde estávamos!}
Só com $a,m,y'$ em vez de $a,m,y$.  E daí?
Podemos separar esse caso em dois subcasos:
\tlist:
\li: \case{Caso $y'=0$}: \dots
\li: \case{Caso $y'=Sy''$} para algum $y''\in\Nat$: \dots
\endtlist
O primeiro subcaso vamos conseguir matar, pois é igual ao
primeiro caso.  Mas a melhor coisa que conseguimos no segundo
caso seria chegar ate o alvo
$$
(a + m) + y'' \askeq a + (m+y'').
$$
E depois?  Considerar dois casos novamente?
Não importa quantas vezes repetir essa idéia, a gente
sempre cai conseguir matar apenas um dos sub-(sub-sub-\dots)-casos,
e chegar num
$$
(a + m) + y^{\prime\prime\cdots\prime}
\askeq
a + (m + y^{\prime\prime\cdots\prime}).
$$
Obviamente precisamos uma outra técnica para demonstrar esse teorema.

%%}}}

\endsection
%%}}}

%%{{{ Induction 
\section Indução.
%%%{{{ meta 
\label Induction
%%%}}}

%%{{{ principle: nats_principle_of_induction 
\principle Princípio da indução finita (PIF).
%%%{{{ meta 
\headerize
\label nats_principle_of_induction
\indexes
    * PIF                        seealso: indução
    * princípio!da indução finita    see: indução
    ;;
\defines
    * PIF
    * indução
    ;;
%%%}}}

Seja $\phi(\dhole)$ uma propriedade de naturais.
Se $\phi(0)$ e para todo $k\in\nats$
$\phi(k)$ implica $\phi(Sk)$,
então para todo $n\in\nats$, $\phi(n)$.

%%}}}

%%{{{ induction_scheme_rule 
\note Schema da indução.
%%%{{{ meta 
\label induction_scheme_rule 
\defines
    * indução!base
    * indução!passo indutivo
    * indução!hipótese indutiva
    ;;
\indexes
    * H.I.               see: hipótese indutiva
    * P.I.               see: passo indutivo
    * base               see: indução
    * passo indutivo     see: indução
    * hipótese indutivo  see: indução
    ;;
%%%}}}

Suponha que $\phi(x)$ é uma afirmação que depende num $x\in\nats$.
Em forma de regra de inferência, o princípio da indução é o seguinte:
$$
\PROOFmr {
     \A {\phi(0)}      \A {\lforall k {\phi(k) \implies \phi(Sk)}}
\I2---------------------------------------------------------------- {Ind$_\phi$}
                     {\lforall n {\phi(n)}}
}
$$
onde chamamos
a proposição $\phi(0)$
de \dterm{base}
e
a $\lforall k {\phi(k) \implies \phi(Sk)}$
de \dterm{passo indutivo}:
$$
\PROOFmr {
\A {\tobrace {\phi(0)} {\explanation{Base}}}   \A {\tobrace {\lforall k {\phi(k) \implies \phi(Sk)}} {\explanation{Passo indutivo}}}
\I2---------------------------------------------------------------- {Ind$_\phi$}
                     {\lforall n {\phi(n)}}
}
$$
Mas esses são apenas os apelidos que usamos freqüentemente; nada mais que isso.
Como vamos ver logo, a proposição $\phi(k)$ no esquema acima também tem um apelido:
\dterm{hipótese indutiva (H.I.)}.

%%}}}

%%{{{ induction_as_a_new_attack 
\note Novo ataque.
%%%{{{ meta 
\label induction_as_a_new_attack
%%%}}}

Para usar então a indução, precisamos ter algo dessa forma:
\repls
\maxproof  : \qquad Seja $k\in\nats$ tal que $\phi(k)$ (H.I.). ;
\maxgiven  : \qquad k \in \nats ;
\maxgoal   : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
\hidenum
\repl
\givens
\goals
~    : \lforall {n \in \ints} {\phi(n)} ;
\endrepl
\repl
~a   : Indução no $n$. ;
\givens
\goals
~a / : \lforall {n \in \nats} {\phi(n)} ;
~a   : \phi(0) ;
~a   : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Indução no $n$. ;
~a   : \proofpart{Base.} ;
\givens
\goals
~    : \phi(0) ;
~f   : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Indução no $n$. ;
~    : \proofpart{Base.} ;
~a   : \qquad $\vdots$ ;
~a   : \qquad (demonstração de $\phi(0)$) ;
\givens
~a   : \phi(0) ;
\goals
~a / : \phi(0) ;
~    : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Indução no $n$. ;
~    : \proofpart{Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~a   : \proofpart{Passo indutivo.} ;
\givens
~    : \phi(0) ;
\goals
~    : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Indução no $n$. ;
~    : \proofpart{Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~    : \proofpart{Passo indutivo.} ;
~a   : \qquad Seja $k\in\nats$ ;
\givens
~    : \phi(0) ;
~a   : k\in\nats ;
\goals
~a / : \lforall {k \in \nats} {\phi(k) \implies \phi(Sk)} ;
~a   : \phi(k) \implies \phi(Sk) ;
\endrepl
\repl
~    : Indução no $n$. ;
~    : \proofpart{Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~    : \proofpart{Passo indutivo.} ;
~    : \qquad Seja $k\in\nats$ \alert{tal que $\phi(k)$ (H.I.).} ;
\givens
~    : \phi(0) ;
~    : k\in\nats ;
~a   : \phi(k) ;
\goals
~a / : \phi(k) \implies \phi(Sk) ;
~a   : \phi(Sk) ;
\endrepl
\repl
~    : Indução no $n$. ;
~    : \proofpart{Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$). ;
~    : \proofpart{Passo indutivo.} ;
~    : \qquad Seja $k\in\nats$ tal que $\phi(k)$ (H.I.). ;
~a   : \qquad $\vdots$ ;
~a   : \qquad (demonstração de $\phi(Sk)$)\qed ;
\givens
~    : \phi(0) ;
~    : k\in\nats ;
~    : \phi(k) ;
~a   : \phi(Sk) ;
\goals
~a / : \phi(Sk) ;
\endrepl
\endrepls

%%}}}

%%{{{ remark: nothing special about induction once performed 
\remark.
%%%{{{ meta 
%%%}}}

Observe que no momento que escrevemos
\quote
<<Seja $k \in \nats$ tal que $\phi(k)$ (H.I.).>>
\endquote
no~\reftag[induction_as_a_new_attack]
não fizemos nada especial relacionado a indução!
Isso é o ``ataque padrão'' duma fórmula da forma
$$
\lforall {x \in A} {\phi(x) \implies \psi(x)}
$$
onde juntamos os passos de atacar o \symq{$\forall$} e o \symq{$\impliessymbol$}
numa frase só.
Em geral, podes considerar a indução como um ``feitiço'' que
quando usado transforma um alvo da forma
$$
\lforall {x \in \nats} {\phi(x)}
$$
para \emph{dois} novos alvos (com nomes chique):
$$
\align
\text{\proofpart{Base}:}\quad           & \phi(0) \\
\text{\proofpart{Passo indutivo}:}\quad & \lforall {k\in\nats} {\phi(k) \implies \phi(Sk)}
\endalign
$$
(exatamente como a regra do~\reftag[induction_scheme_rule]
disse, lida de baixo para cima).
Fora disso, \emph{não tem nada mais mágico} que acontece:
o feitiço já foi feito e seu efeito já aconteceu.
E depois?
Depois \emph{continuamos normalmente para matar esses dois alvos}.

%%}}}

%%{{{ remark: induction_on_a_variable? 
\remark Indução numa variável?.
%%%{{{ meta 
%%%}}}

No~\ref[induction_as_a_new_attack] escrevemos <<Indução no $n$>>.
Como assim ``no $n$''?  Quem é esse $n$?
Não tem $n$ no nosso escopo!
Sim, realmente não faz sentido no pé da letra essa frase,
mas ajudamos nosso leitor entender qual quantificador estamos atacando
do nosso alvo, caso que aparecem mais que um.
Talvez ficaria (pouco) mais correto escrever
<<Indução no $\forall n$.>>
(No final das contas, é o quantificador que estamos atacando.)
De qualquer forma, isso é apenas um ``modo de falar'', e presuponha
que nosso leitor tem acesso no nome da variável ligada que escolhemos
quando escrevemos nosso alvo.  (Muitas vezes isso faz parte do enunciado.)

%%}}}

\endsection
%%}}}

%%{{{ Proving properties with induction 
\section Demonstrando propriedades de naturais com indução.
%%%{{{ meta 
%%%}}}

%%{{{ thm: natadd_is_associative 
\theorem Associatividade da adição.
%%%{{{ meta 
\label natadd_is_associative
%%%}}}

A operação $+$ da~\ref[natops_rec_defs] é associativa:
$$
\forall n
\forall m
\forall k
\bigparen{ n + (m + k) = (n + m) + k }.
$$

\preproof.
Vamos demonstrar esse teorema duas vezes.
É importantíssimo entender a diferença e seguir todos os detalhes.
Antes de começar, lembre nossa tentativa~\reftag[natadd_is_associative_failed_proof_attempt] e como e onde exatamente a gente travou:
\repl \hidenum
~    : Seja $n$ natural. ;
~    : Seja $m$ natural. ;
~    : Seja $k$ natural. ;
~    : Separamos em casos: ;
~    : \proofpart{Caso $k=0$:} ;
~    : \quad(resolvido no~\ref[solve_the_zero_case_of_case_split_of_natadd_is_associative]) ;
~    : \proofpart{Caso $k=Sk'$ para algum $k' \is \Nat$:} ;
~    : \quad(caimos num caminho infinito aqui) ;
\givens
~    : n \is \Nat ;
~    : m \is \Nat ;
~    : k \is \Nat ;
\goals
~    : n + (m + k) = (n + m) + k ;
\endrepl
E como caimos num caminho de sempre separar em dois novos casos sem fim, percebemos que algo deu errado; queremos tentar nossa nova técnica, indução.
Neste momento na nossa prova, podemos atacar nosso alvo por indução?
Não!
Para atacar um alvo por indução ele precisa ter a forma
$$
\lforall {x \is \Nat} {\phi(x)}
$$
e nosso alvo não é um \symq{$\forall$} mas uma igualdade!
Vamos fazer uns ``undo'' então na nossa prova e voltar nesse momento:
\repl
~    : Seja $n$ natural. ;
~    : Seja $m$ natural. ;
~    : \strikeout{Seja $k$ natural.} ;
~    : \strikeout{Separamos em casos:} ;
\givens
~    : n \is \Nat ;
~    : m \is \Nat ;
\goals
~    : \sforall k \mubrace {n + (m + k) = (n + m) + k} {\phi(k)} ;
\endrepl
Agora sim!  Nosso alvo tem uma forma que casa com o padrão que precisamos para aplicar indução.
Bora ver essa demonstração primeiro então.

\proof Primeira demonstração.
Sejam $n, m$ naturais.
Vamos demonstrar por indução no $k$ que
$$
\forall k
\mubrace {n + (m + k) = (n + m) + k} {\phi(k)}.
$$
\proofpart {Base.}
Precisamos mostrar que
$$
n + (m + 0) = (n + m) + 0.
$$
Calculamos:
\compute
n + (m + 0)
&= n + m    \by {pela (a1) com $n \asseq m$} \\
(n + m) + 0
&= n + m    \by {pela (a1) com $n \asseq n + m$} \\
\endcompute
\proofpart {Passo indutivo.}
Precisamos mostrar que
$$
\forall t
\bigparen {
\mubrace {n + (m + t) = (n + m) + t} {\phi(t)}
\implies
\mubrace {n + (m + St) = (n + m) + St} {\phi(St)}
}
$$
Seja $w$ natural tal que
$$
n + (m + w) = (n + m) + w.  \tag{H.I.}
$$
Precisamos mostrar que
$$
n + (m + Sw) = (n + m) + Sw.  \tag{H.I.}
$$
Calculamos:
\compute
n + (m + Sw)
&= n + S(m + w)     \by {(a2): $n \asseq m$; $m \asseq w$} \\
&= S(n + (m + w))   \by {(a2): $n \asseq n$; $m \asseq m + w$} \\
(n + m) + Sw
&= S((n + m) + w)   \by {(a2): $n \asseq n + m$; $m \asseq w$} \\
\endcompute
Basta então mostrar que
$$
S(n + (m + w)) = S((n + m) + w)
$$
que realmente temos pela (H.I.).

%%}}}

%%{{{ We need to discuss what just happened. 
\blah.
%%%{{{ meta 
%%%}}}

Precisamos discutir o que aconteceu.
Agora bora ver uma demonstração que também usa indução, mas numa maneira bem diferente:
Queremos demonstrar a afirmação
$$
\forall n
\forall m
\sforall k
\psi(n,m,k)
$$
onde
$$
\psi(x,y,z) \abbriff x + (y + z) = (x + y) + z.
$$
Talvez parece que ela não está no formato $\sforall n \phi(n)$
e que não podemos atacá-la diretamente com indução.
Mas, na verdade, reescrevendo como
$$
\forall n
\mubrace {\forall m \sforall k \psi(n,m,k)} {\phi_1(n)}
$$
já percebemos que tem a forma certa.
E podemos trocar a órdem de quantificadores consecutivos
\emph{do mesmo tipo}, então o que queremos demonstrar é equivalente aos
$$
\xalignat3
\forall n & \mubrace {\forall m \sforall k \psi(n,m,k)} {\phi_1(n)}; &
\forall m & \mubrace {\forall n \sforall k \psi(n,m,k)} {\phi_2(m)}; &
\forall k & \mubrace {\forall n \sforall m \psi(n,m,k)} {\phi_3(k)};
\endxalignat
$$
etc.~(tem ainda mais três opções que não escrevi),
onde em cada caso o $\phi_i$ tem uma definição diferente,
mas o $\psi$ tem sempre a mesma.
Escolhemos demonstrar a
$$
\forall k \mubrace {\forall n \sforall m \psi(n,m,k)} {\phi(k)}.
$$
por indução.
Vamos ver o que vai acontecer.

%%}}}

%%{{{ proof: natadd_is_associative_second_proof 
\proof Segunda demonstração.
%%%{{{ meta 
\of natadd_is_associative
\headerize
\label natadd_is_associative_second_proof
%%%}}}

Por indução no $k$.
\crproofpart{Base.}
Precisamos demonstrar que
$$
\mubrace {\forall n \sforall m {n + (m + 0) = (n + m) + 0}} {\phi(0)}.
$$
Sejam $n,m$ naturais.
Calculamos os dois lados:
\compute
\underline{\paren{n+m} + 0} &= n + m \by {a1)} \\
n + \paren{\underline{m+0}} &= n + m \by {a1)} \\
\endcompute
Ou seja, a $\phi(0)$ realmente é verdade.
\crproofpart{Passo indutivo.}
Precisamos demonstrar a afirmação:
$$
\forall t \bracket{\phi(t) \implies \phi(St)},
$$
ou seja,
$$
\forall t
\bigbracket{
\paren{\forall n\forall m \bracket{ (n + m) + t  = n + (m + t) }}
\implies
\paren{\forall u\forall v \bracket{ (u + v) + St = u + (v + St)}}
}
$$
onde escolhi nomes diferentes nas variáveis quantificadas apenas para
enfatizar que são realmente diferentes!
Bora demonstrar isso então.
Seja $w$ natural tal que
$$
\forall n\forall m \bracket{ (n + m) + w = n + (m + w) }. \tag{H.I.}
$$
Preciso mostrar que:
$$
\forall u\forall v \bracket{ (u + v) + Sw = u + (v + Sw)}
$$
Sejam $u,v\in\nats$.
Calculamos:
\compute
\underline{(u + v) + Sw}
&= S(\underline{(u + v) + w})  \by {a2} \\
&= \underline{S(u + (v + w))}  \by {H.I., com $n := u$, $m := v$} \\
&= u + \underline{S(v + w)}    \by {(a2)$^{\leftarrow}$} \\
&= u + (v + Sw).               \by {(a2)$^{\leftarrow}$} \\
\endcompute
Isso termina nossa prova.

%%}}}

%%{{{ Q: How do we choose which forall to attack by induction? 
\question.
%%%{{{ meta 
%%%}}}

Acabamos de escolher para demonstrar por indução no $k$.
Por que $k$?
Faz diferença ou não?
Como escolherias qual dos $\forall$ seria o melhor para atacar por indução?

%%}}}

\spoiler

%%{{{ A: How to choose on which variable to induct 
\note Como escolher a variável da indução.
%%%{{{ meta 
%%%}}}

Como a definição da adição foi recursiva no segundo argumento
da funcção, vai nos ajudar se a indução é feita numa variável
que aparece mais como segundo argumento da adição do que como primeiro.
Aqui por exemplo, a $k$ aparece duas vezes como argumento da $+$,
e as duas vezes ela é o segundo argumento da $+$.  Perfeito.
O $n$ no outro lado aparece duas vezes como primeiro argumento,
e o $m$ uma como primeiro e uma como segundo.

%%}}}

%%{{{ thm: natadd_is_commutative 
\theorem Comutatividade da adição.
%%%{{{ meta 
\label natadd_is_commutative
%%%}}}

A operação $+$ da~\ref[natops_rec_defs] é comutativa:
$$
\forall n
\forall m
\bigparen{n + m = m + n}.
$$

\wrongproof.
Provamos a
$$
\forall n
\mubrace {\forall m \bigparen{n + m = m + n}} {\phi(n)}.
$$
\proofpart{Base.}
Queremos demonstrar o $\phi(0)$, ou seja, o seguinte:
$$
\forall m \mubrace {\bigparen{0 + m = m + 0}} {\psi(m)}.
$$
Vamos demonstrar por indução!
\leftindent
\proofpart{Sub-base.}
Trivial, pois o que queremos demonstrar é $0 + 0 = 0 + 0$ e os dois lados
são a mesma expressão.
\crproofpart{Sub-passo indutivo.}
Precisamos demonstrar que:
$$
\forall k \Bigbracket{\mubrace {0 + k = k + 0} {\psi(k)}
          \implies \mubrace {0 + Sk = Sk + 0} {\psi(Sk)}}.
$$
Seja $k\in\nats$ tal que
$$
0 + k = k + 0.   \tag{S.H.I.}
$$
Queremos mostrar que
$$
0 + Sk = Sk + 0.
$$
Calculamos:
\compute
0 + Sk
&= S(0 + k)  \by {(a2)} \\
&= S(k + 0)  \by {(S.H.I.)} \\
&= Sk        \by {(a1)} \\
&= Sk + 0.   \by {(a1)} \\
\endcompute
Isso termina nossa base.
\endleftindent
\proofpart{Passo indutivo.}
Queremos demonstrar:
$$
\forall k
\Bigbracket {
\mubrace {\forall m \paren{k + m = m + k}}
{\phi(k)}
\implies
\mubrace {\forall m \paren{Sk + m = m + Sk}}
{\phi(Sk)}
}.
$$
Seja $k\in\nats$ tal que
$$
\mubrace {\forall m \paren{k + m = m + k}} {\phi(k)} \tag{H.I.}
$$
então.
Basta demonstrar que
$$
\mubrace {\forall m \paren{Sk + m = m + Sk}} {\phi(Sk)}.
$$
Seja $m\in\nats$.
Calculamos:
\compute
Sk + m
&= S(k+m)   \by {(a2)} \\
&= S(m+k)   \by {(H.I.)} \\
&= m + Sk.  \by {(a2)} \\
\endcompute
Isso termina nossa prova.

%%}}}

%%{{{ x: natadd_is_commutative_find_the_error 
\exercise.
%%%{{{ meta 
\label natadd_is_commutative_find_the_error
%%%}}}

A prova do~\ref[natadd_is_commutative] tem um erro!
Ache o erro.

\hint
Está no passo indutivo.

\hint
Está no último cálculo.

\solution
O erro está na primeira equação do último cálculo:
\compute
Sk + m
&= S(k+m). \by {a2} \\
\endcompute
A \byfact{a2} não nos permite concluir isso; só o seguinte:
$$
k + Sm = S(k+m).
$$
Se soubessimos que $Sk + m = k + Sm$ seria fácil
terminar essa prova corretamente.
Essa propriedade parece razoável para afirmar:
$$
\forall x \forall y \bracket{ Sx + y = x + Sy }
$$
Bora demonstrar então!

%%}}}

%%{{{ lemma: succx_plus_y_eq_x_plus_succy
\lemma.
%%%{{{ meta 
\label succx_plus_y_eq_x_plus_succy
%%%}}}

A operação $+$ satisfaz:
$$
\forall a
\forall b
\bigparen{ Sa + b = a + Sb }.
$$

\proof.
Provamos por indução que
$$
\forall b
\mubrace {\forall a \bigparen{ Sa + b = a + Sb }} {\phi(b)}.
$$
\proofpart{Base.}
Precisamos demonstrar que
$$
\mubrace {\forall a \bigparen{ Sa + 0 = a + S0 }} {\phi(0)}.
$$
Calculamos:
\compute
Sa + 0 &= Sa        \by {a1} \\
a + S0 &= S(a + 0)  \by {a2} \\
       &= Sa.       \by {a1} \\
\endcompute
\proofpart{Passo indutivo.}
Queremos demonstrar:
$$
\forall k
\Bigbracket{
\mubrace
    {\forall a \bigparen{ Sa + k = a + Sk }}
    {\phi(k)}
\implies
\mubrace
    {\forall a \bigparen{ Sa + Sk = a + SSk }}
    {\phi(Sk)}
}.
$$
Seja $k\in\nats$ tal que
$$
\mubrace
    {\forall a \bigparen{ Sa + k = a + Sk }}
    {\phi(k)}.
\tag{H.I.}
$$
Basta mostrar que
$$
\mubrace
    {\forall a \bigparen{ Sa + Sk = a + SSk }}
    {\phi(Sk)}.
$$
Seja $a\in\nats$.
Calculamos
\compute
Sa + Sk
&= S(Sa + k)    \by {a2} \\
&= S(a + Sk)    \by {H.I.~com $a := a$} \\
&= a + SSk.     \by {a2} \\
\endcompute
Isso termina nossa prova, e logo substituindo a
justificativa~\wq{(a2)} na demonstração do~\ref[natadd_is_commutative] por
\wq{pelo~\ref[succx_plus_y_eq_x_plus_succy]} ganhamos também o direito de
substituir seu~\symq{\mistakesymbol} por um legítimo~\symq{\qedsymbol}:

%%}}}

\TODO Sketch da comutatividade da adição com indução dupla.

%%{{{ x: natmult_is_associative 
\exercise Associatividade da multiplicação.
%%%{{{ meta 
\label natmult_is_associative
%%%}}}

$
\forall n
\forall m
\forall k
\bigparen{(n \ntimes m) \ntimes k = n \ntimes (m \ntimes k)}.
$

\hint
Por indução no $k$.

\hint
Não seria bom ter uma distributividade?

\solution
Por indução no $k$.
\crproofpart{Base: $\forall n \forall m \bigparen{(n \ntimes m) \ntimes 0 = n \ntimes (m \ntimes 0)}$.}
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes 0
&= 0            \by {(m1)} \\
n \ntimes (m \ntimes 0)
&= n \ntimes 0  \by {(m1)} \\
&= 0.           \by {(m1)} \\
\endcompute
\proofpart{Passo indutivo.}
Seja $w$ natural tal que
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes w = n \ntimes (m \ntimes w)}. \tag{H.I.}
$$
Ou seja: ``$w$ na direita associa com todos''.
Queremos demonstrar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes Sw = n \ntimes (m \ntimes Sw)}.
$$
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes Sw
&= ((n \ntimes m) \ntimes w) + (n \ntimes m)    \by {(m2)} \\
n \ntimes (m \ntimes Sw)
&= n \ntimes ((m \ntimes w) + m)                \by {(m2)} \\
&= (n \ntimes (m \ntimes w)) + (n \ntimes m)    \by {(*)} \\
&= ((n \ntimes m) \ntimes w) + (n \ntimes m).   \by {(H.I.)} \\
\endcompute
Onde devemos para o (*) demonstrar como lemma a distributividade (esquerda) da $\ntimes$ sobre a $+$ (feito no~\ref[natmult_distributes_over_natadd]).

%%}}}

%%{{{ x: natmult_is_commutative 
\exercise Comutatividade da multiplicação.
%%%{{{ meta 
\label natmult_is_commutative
%%%}}}

$
\forall n
\forall m
\bigparen{n \ntimes m = m \ntimes n}.
$

\hint
Por indução em qualquer uma das $m,n$.

\hint
Demonstre a base da tua indução com uma sub-indução!

\hint
Teu passo indutivo vai precisar duma sub-indução também!
Alternativamente, tu podes demonstrar outras propriedades
que ajudaria ter (por exemplo distributividade) e usá-las
como lemmas nas tua prova.

\solution
Por indução no $m$.
\crproofpart{Base: $\forall n \paren{n \ntimes 0 = 0 \ntimes n}$.}
Vamos demonstrar por indução!
\leftindent
\proofpart{Sub-base: $0 \ntimes 0 = 0 \ntimes 0$.}
Trivial!
\crproofpart{Sub-passo indutivo.}
Seja $k\in\nats$ tal que
$$
k \ntimes 0 = 0 \ntimes k.  \tag{S.H.I.1}
$$
Ou seja, \emph{$k$ é um número que comuta com o $0$}.
Vamos demonstrar que $Sk \ntimes 0 = 0 \ntimes Sk$.
Calculamos:
\compute
Sk \ntimes 0  &= 0  \by {(m1)} \\
0 \ntimes Sk
&= 0 \ntimes k + 0  \by {(m2)} \\
&= 0 \ntimes k      \by {(a1)} \\
&= k \ntimes 0      \by {(S.H.I.1)} \\
&= 0.               \by {(m1)} \\
\endcompute
Isso prova nossa base.
\endleftindent
\proofpart{Passo indutivo.}
Seja $w\in\nats$ tal que
$$
\forall n \paren{n \ntimes w = w \ntimes n}. \tag{H.I.}
$$
Ou seja, \emph{$w$ é um número que comuta com todos}.
Queremos demonstrar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \paren{n \ntimes Sw = Sw \ntimes n}.
$$
Vamos demonstrar por mais uma indução!
\leftindent
\proofpart{Sub-base: $0 \ntimes Sw = Sw \ntimes 0$.}
Calculamos:
\compute
0 \ntimes Sw
&= 0 \ntimes w + 0 \by {(m2)} \\
&= 0 \ntimes w     \by {(a1)} \\
&= w \ntimes 0     \by {Base ($0$ comuta com todos) ou (H.I.) ($w$ comuta com todos)} \\
&= 0               \by {(m1)} \\
&= Sw \ntimes 0.   \by {(m1)} \\
\endcompute
\crproofpart{Sub-passo indutivo.}
Seja $p\in\nats$ tal que ele comuta com o $Sw$:
$$
p \ntimes Sw = Sw \ntimes p.    \tag{S.H.I.2}
$$
Vamos demonstrar que $Sp$ também comuta com o $Sw$:
$$
Sp \ntimes Sw = Sw \ntimes Sp.
$$
Calculamos:
\compute
Sp \ntimes Sw
&= Sp \ntimes w + Sp        \by {(m2)} \\
&= w \ntimes Sp + Sp        \by {(H.I.): $w$ comuta com todos} \\
&= (w \ntimes p + w) + Sp   \by {(m2)} \\
&= w \ntimes p + (w + Sp)   \by {associatividade da $+$} \\
&= w \ntimes p + S(w + p)   \by {(a2)} \\
&= w \ntimes p + S(p + w)   \by {comutatividade da $+$} \\
&= w \ntimes p + (p + Sw)   \by {(a2)} \\
Sw \ntimes Sp
&= Sw \ntimes p + Sw        \by {(m2)} \\
&= p \ntimes Sw + Sw        \by {(S.H.I.2): $p$ comuta com o $Sw$} \\
&= (p \ntimes w + p) + Sw   \by {(m2)} \\
&= p \ntimes w + (p + Sw)   \by {associatividade da $+$} \\
&= w \ntimes p + (p + Sw).  \by {(H.I.): $w$ comuta com todos} \\
\endcompute
\endleftindent

%%}}}

%%{{{ x: natmult_distributes_over_natadd 
\exercise Distributividade.
%%%{{{ meta 
\label natmult_distributes_over_natadd
%%%}}}

$
\forall x
\forall y
\forall z
\bigbracket{x \ntimes (y + z) = (x \ntimes y) + (x \ntimes z)}.
$

\hint
Indução no $z$.

\solution
Provamos a afirmação por indução no $z$.
\crproofpart{Base: $\forall x \forall y \bracket{x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0)}$}.
Sejam $x,y \in \nats$.
Queremos demonstrar que
$$
x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0).
$$
Calculamos:
\compute
x \ntimes (y + 0)
&= x \ntimes y                 \by {(a1)} \\
&= x \ntimes y + 0             \by {(a1)} \\
&= x \ntimes y + x \ntimes 0.  \by {(m1)} \\
\endcompute
\proofpart{Passo indutivo.}
Seja $k\in \nats$ tal que
$$
\forall x
\forall y
\bracket{x \ntimes (y + k) = (x \ntimes y) + (x \ntimes k)}. \tag{H.I.}
$$
Vamos demonstrar que
$$
\forall x
\forall y
\bracket{x \ntimes (y + Sk) = (x \ntimes y) + (x \ntimes Sk)}.
$$
Sejam $x,y\in\nats$.
Calculamos
\compute
x \ntimes (y + Sk)
&= x \ntimes S(y + k)                \by {(a1)} \\
&= \bigparen{x \ntimes (y + k)} + x  \by {(m2)} \\
&= (x \ntimes y + x \ntimes k) + x   \by {(H.I.) com $x\asseq x$, $y\asseq y$} \\
&= x \ntimes y + (x \ntimes k + x)   \by {associatividade de $+$} \\
&= x \ntimes y + x \ntimes Sk.       \by {(m2)} \\
\endcompute

%%}}}

%%{{{ thm: natmult_identity 
\theorem Identidade da multiplicação.
%%%{{{ meta 
\label natmult_identity
%%%}}}

$
\forall x
\bigparen{ x \ntimes S0 = x = S0 \ntimes x}.
$

\proof.
Seja $x\in \nats$.
Calculamos:
\compute
x \ntimes S0
&= (x \ntimes 0) + x    \by {(m2), $n\asseq x$, $m\asseq 0$} \\
&= 0 + x                \by {(m1)} \\
&= x + 0                \by {$+$ comut.~(\reftag[natadd_is_commutative])} \\
&= x.                   \by {(a1)} \\
\endcompute
Como já provamos a comutatividade da $\ntimes$, isso termina nossa prova.

%%}}}

\TODO easy equivalence of two ways to define exponenciation of~\ref[nats_exp_recursive_def].

\TODO still, there is reason to choose one over the other.

%%{{{ x: law_of_natexp_1 
\exercise Lei de exponenciação 1.
%%%{{{ meta 
\label law_of_natexp_1
%%%}}}

$
\forall x
\forall a
\forall b
\bigparen{x^{a + b} = (x^a) \ntimes (x^b)}.
$

\hint
Indução no $b$.

\hint
\proofpart{Base: $\forall x \forall a \bigbracket{x^{a+0} = x^a \ntimes x^0}$}:

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall x \forall a \bigbracket{x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Agora precisas demonstrar que
$$
\forall x \forall a \bigbracket{x^{a+Sk} = x^a \ntimes x^Sk}.
$$

\solution
Por indução no $b$.
\crproofpart{Base: $\forall x \forall a \bigbracket{x^{a+0} = x^a \ntimes x^0}$}.
Sejam $x,a\in\nats$.
Calculamos:
\compute
x^{a+0}
&= x^a              \by {(a1)} \\
&= x^a \ntimes S0   \by {$S0$ identidade (\reftag[natmult_identity])} \\
&= x^a \ntimes x^0. \by {(e1)} \\
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall x \forall a \bigbracket{x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Basta demonstrar que
$$
\forall x \forall a \bigbracket{x^{a+Sk} = x^a \ntimes x^{Sk}}.
$$
Sejam $x,a\in\nats$.
Queremos demonstrar $x^{a+Sk} = x^a \ntimes x^{Sk}$.
Calculamos:
\compute
x^{a + Sk}
&= x^{S(a + k)}                 \by {(a2)} \\
&= x^{a+k} \ntimes x            \by {(e2)} \\
&= (x^a\ntimes x^k) \ntimes x   \by {(H.I.)} \\
&= x^a\ntimes (x^k \ntimes x)   \by {assoc.~da~$\ntimes$~(\reftag[natmult_is_associative])} \\
&= x^a\ntimes x^{Sk}.             \by {(e2)} \\
\endcompute

%%}}}

%%{{{ x: law_of_natexp_2 
\exercise Lei de exponenciação 2.
%%%{{{ meta 
\label law_of_natexp_2
%%%}}}

$
\forall a
\forall b
\forall c
\bigparen{a^{b \ntimes c} = (a^b)^c}.
$

\hint
Indução no $c$.

\hint
\proofpart{Base: $\forall a \forall b \bigparen{ a^{b \ntimes 0} = (a^b)^0 }$.}

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Agora precisas demonstrar que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$

\solution
Por indução no $c$.
\crproofpart{Base: $\forall a \forall b \bigbracket{ a^{b \ntimes 0} = (a^b)^0 }$.}
Sejam $a,b\in\nats$.
Calculamos:
\compute
a^{b \ntimes 0}
&= a^0    \by {(m1)} \\
&= S0     \by {(e1)} \\
(a^b)^0
&= S0.    \by {(e1)} \\
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Queremos demonstrar que
$$
\forall a \forall b \bigbracket{ a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$
Sejam $a,b\in\nats$.
Basta mostrar que $a^{b \ntimes Sk} = (a^b)^{Sk}$.
Calculamos:
\compute
(a^b)^{Sk}
&= (a^b)^k \ntimes (a^b)        \by {(e2), $n\asseq a^b$, $m\asseq k$} \\
&= a^{b \ntimes k} \ntimes a^b  \by {(H.I.), $a\asseq a$, $b\asseq b$} \\
&= a^{(b \ntimes k) + b}        \by {\reftag[law_of_natexp_1], $x\asseq a$, $a\asseq b \ntimes k$, $b\asseq b$} \\
&= a^{b \ntimes Sk}.            \by {(m2), $n\asseq b$, $m\asseq k$} \\
\endcompute

%%}}}

%%{{{ x: law_of_natexp_3 
\exercise Lei de exponenciação 3.
%%%{{{ meta 
\label law_of_natexp_3
%%%}}}

$
\forall n
\bigparen{S0^n = S0}
$

\hint
Indução no $n$.

\hint
\proofpart{Base: $S0^0 \askeq S0$}:

\hint
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Agora precisas demonstrar que
$$
S0^{Sk} = S0.
$$

\solution
Por indução no $n$.
\crproofpart{Base: $S0^0 \askeq S0$.}
Imediato pela definição de $S0^0$.
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Basta demonstrar que
$$
S0^{Sk} = S0.
$$
Calculamos:
\compute
(S0)^{Sk}
&= S0 \ntimes S0^k              \by {(e2),   $n\asseq S0$, $m\asseq k$} \\
&= S0^k                         \by {$S0$ é identidade da $\ntimes$ (\ref[natmult_identity])} \\
&= S0.                          \by {(H.I.)} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Order in the naturals 
\section Ordem nos naturais.
%%%{{{ meta 
%%%}}}

%%{{{ df: natleq 
\definition.
%%%{{{ meta 
\label natleq
\defines
    * ordem!nos naturais
    ;;
%%%}}}

Definimos a relação de ordem $\leq$ nos naturais pela:
$$
n \leq m \defiff \lexists {k\in\nats} {n + k = m}.
$$

%%}}}

%%{{{ x: natleq_lemma 
\exercise.
%%%{{{ meta 
\label natleq_lemma
%%%}}}

Demonstre que
$$
\forall n \forall m \bigparen{ n \leq S m  \iff  n \leq m  \mlor  n = S m}
$$

\hint
Tente sem indução.

\solution
Sejam $n,m$ naturais.
\eop
\lrdir:
Suponha $n \leq S m$.
Logo seja $u$ tal que $n + u = Sm$.
Separamos em casos.
\case{Caso $u=0$.}
Logo $Sm = n+u = n+0 = n$ e temos o que queremos demonstrar.
\case{Caso $u=Su'$ para algum $u'$.}
Logo $Sm = n + Su' = S(n + u')$.
Agora, como $Sm = S(n + u')$, logo $m = n + u'$.
Ou seja, $n \leq m$.
\eop
\rldir:
Suponha $n \leq m$ ou $n = Sm$.
Vamos demonstrar que $n \leq Sm$.
Separamos em casos.
\case{Caso $n \leq m$}.
Logo seja $u$ tal que $n + u = m$.
Logo $S(n + u) = Sm$.
E pela (a1) temos $n + Su = Sm$, e logo $n \leq Sm$.
\case{Caso $n = Sm$}.
Nesse caso imediatamente $n + 0 = Sm$ (pois $n + 0 = n$ pela (a2))
e logo $n \leq Sm$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nos exercícios seguintes vamos demonstrar que $\leq$ é uma \dterm{ordem linear}, i.e.:

%%}}}

%%{{{ x: natleq_refl 
\exercise Reflexiva.
%%%{{{ meta 
\label natleq_refl
%%%}}}

A $\leq$ é \dterm{reflexiva}, i.e.,
$$
\forall x \bigparen{ x \leq x }.
$$

%%}}}

%%{{{ x: natleq_antisym 
\exercise Antissimétrica.
%%%{{{ meta 
\label natleq_antisym
%%%}}}

A $\leq$ é \dterm{antissimétrica}, i.e.,
$$
\forall x \forall y \bigparen{x \leq y  \mland  y \leq x  \implies  x = y}.
$$

%%}}}

%%{{{ x: natleq_trans 
\exercise Transitiva.
%%%{{{ meta 
\label natleq_trans
%%%}}}

A $\leq$ é \dterm{transitiva}, i.e.,
$$
\forall x \forall y \forall z \bigparen{x \leq y  \mland  y \leq z  \implies  x \leq z}.
$$

%%}}}

%%{{{ x: natleq_total 
\exercise Total.
%%%{{{ meta 
\label natleq_total
%%%}}}

A $\leq$ é \dterm{total}, i.e.,
$$
\forall x \forall y \bigparen{x \leq y  \mlor  y \leq x}.
$$

%%}}}

%%{{{ x: squares_smaller_than_powers_of_two_induction 
\exercise.
%%%{{{ meta 
\label squares_smaller_than_powers_of_two_induction
%%%}}}

Demonstre que para todo $n \geq 5$,
$$
n^2 < 2^n.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na verdade, $\leq$ é ainda mais legal: olha no~\ref[natleq_woset].

%%}}}

\endsection
%%}}}

%%{{{ Sums and products, formally 
\section Somatórios e produtórios formalmente.
%%%{{{ meta 
%%%}}}

\TODO Definições recursivas de somatórios e produtórios.

\TODO Generalizando operadores binários para $n$-ários.

%%{{{ eg: gauss_child 
\example.
%%%{{{ meta 
\label gauss_child
%%%}}}

Demonstre que para todo $n\in\nats$,
$$
2 \Sum_{i=1}^n i = n (n+1).
$$

\solution.
Por indução.
Primeiramente demonstramos a \proofpart{base:}
$$
2 \Sum_{i=1}^0 i \askeq 0 (0+1).
$$
Calculamos:
\math
2 \Sum_{i=1}^0 i
= 2 \ntimes 0
= 0
= 0 (0+1).
\endmath
\proofpart{Passo indutivo.}
Seja $k\in\nats$ tal que
$$
2 \Sum_{i=1}^k i = k (k+1).  \tag{H.I.}
$$
Calculamos:
\compute
2 \Sum_{i=1}^{k+1} i
&= 2((k+1) + \Sum_{i=1}^k i) \\
&= 2(k+1) + 2\Sum_{i=1}^k i \\
&= 2(k+1) + k(k+1) \by {pela H.I.} \\
&= (2+k)(k+1) \\
&= (k+1)(k+2).
\endcompute

%%}}}

%%{{{ x: sum_of_cubes_formula 
\exercise.
%%%{{{ meta 
\label sum_of_cubes_formula
%%%}}}

Demonstre que
$$
4 \paren{1 + 8 + 27 + \dotsb + n^3} = n^2 (n+1)^2
$$
para todo $n\in\nats$.

\hint
Lembre que o somatório vazio é $0$.

%%}}}

%%{{{ x: sum_of_negative_powers_of_two_formula 
\exercise.
%%%{{{ meta 
\label sum_of_negative_powers_of_two_formula
%%%}}}

Observando os valores de:
$$
\align
    1
    +
    \frac 1 2
    &= 2 - \frac 1 2\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    &= 2 - \frac 1 4\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    +
    \frac 1 8
    &= 2 - \frac 1 8,
\intertext{adivinhe uma fórmula geral para o somatório}
    1 + \frac 1 2 + \frac 1 4 + \cdots + \frac 1 {2^n} &= \text{?}
\endalign
$$
e demonstre que ela é válida para todo $n\in\nats$.

%%}}}

%%{{{ x: one_minus_sum_of_1_over_n_formula 
\exercise.
%%%{{{ meta 
\label one_minus_sum_of_1_over_n_formula
%%%}}}

Calculando os valores de:
$$
    \paren{1 - \frac 1 2},
   \qquad 
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3},
   \qquad
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4},
$$
adivinhe uma fórmula geral para o produtório
$$
\Prod_{i=2}^n\paren{ 1 - \frac 1 i}
=
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4}
\dotsb
    \paren{1 - \frac 1 n}
$$
e demonstre que ela é válida para todo inteiro $n \geq 2$.

%%}}}

%%{{{ x: sum_of_squares_formula 
\exercise.
%%%{{{ meta 
\label sum_of_squares_formula
%%%}}}

Demonstre que para todo $n \in\nats$,
$$
\Sum_{i=1}^n i^2
= \frac {n^3} 3 + \frac {n^2} 2 + \frac n 6.
$$

%%}}}

%%{{{ x: sum_of_cubes_and_gauss_formula 
\exercise.
%%%{{{ meta 
\label sum_of_cubes_and_gauss_formula
%%%}}}

Demonstre que para todo $n \in\nats$,
$$
\align
\Sum_{i=1}^n i^3 &= \paren{\Sum_{i=1}^n i}^2\\
\text{ou seja,}\qquad
1^3 + 2^3 + \dotsb + n^3 &= \paren{ 1 + 2 + 3 + \dotsb + n }^2.
\endalign
$$

%%}}}

%%{{{ x: sum_of_threes_and_fives 
\exercise.
%%%{{{ meta 
\label sum_of_threes_and_fives
%%%}}}

Qualquer número inteiro positivo $n \geq 8$ pode ser escrito
como somatório de $3$'s e $5$'s.

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

Seja
$$
\phi(n) \defiff 1 + 2 + \dotsb + n = \frac 1 8 \paren{2n + 1}^2.
$$
\tlist:
\li (i):
Demonstre que para todo $k\in\nats$, se $\phi(k)$ então $\phi(k+1)$.
\li (ii):
Critique a oração:
\emph{\wq{Logo, por indução, temos que para todo $n\in\nats$, $phi(n)$.}}.
\li (iii):
Mudando apenas o \sq{$=$} para \sq{$>$} ou \sq{$<$}, defina um outro
predicado $\psi(\dhole)$ tal que para todo $n\in\nats$, $\psi(n)$
(demonstre por indução).
\endtlist

%%}}}

%%{{{ x fibonacci 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n\in\nats$,
$$
\Sum_{i=0}^n F_i = F_{n+2} - 1,
$$
onde $F_n$ o $n$-ésimo número Fibonacci.

%%}}}

%%{{{ x fibonacci 2 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n\in\nats$,
$$
\Sum_{i=1}^n F_i^2 = F_n F_{n+1},
$$
onde $F_n$ o $n$-ésimo número Fibonacci.

%%}}}

%%{{{ x: n_over_succ_n_formula 
\exercise.
%%%{{{ meta 
\label n_over_succ_n_formula
%%%}}}

Demonstre que para todo inteiro $n \geq 1$.
$$
    \frac 1 {1 \cdot 2} +
    \frac 1 {2 \cdot 3} +
    \frac 1 {3 \cdot 4} + \cdots + 
    \frac 1 {n (n+1)}
    =
    \frac n {n+1}
$$

%%}}}

\endsection
%%}}}

%%{{{ Why accept the induction principle? 
\section Por que aceitar o princípio da indução?.
%%%{{{ meta 
%%%}}}

%%{{{ Intuition 
\note Intuição.
%%%{{{ meta 
%%%}}}

Por que provar $\phi(0)$ e $\lforall {k\in\nats} {\phi(k) \implies \phi(Sk}$
é suficiente para demonstrar o $\lforall {n\in\nats} {\phi(n)}$?
Estabelecendo esses dois alvos significa que ganhamos como regras de inferência
as seguintes:
$$
\xalignat2
&
\PROOFmr {
\I0------------ {IndZero$_\phi$}
    {\phi(0)}
}
&&
\PROOFmr {
\A  {\phi(n)}
\I1------------ {IndSucc$_\phi$}
    {\phi(Sn)}
}
\endxalignat
$$
onde $n$ é uma metavariável pegando valores em todos os naturais,
e onde eu escolhi esses rótulos talvez estranhos para nomear essas regras.
Vamos ver o que podemos demonstar graças essas duas regras agora:
com certeza temos o próprio $\phi(0)$ pela primeira que não tem
nenhuma premissa.
Mas, agora, usando a segunda com $n\asseq 0$ temos uma demonstração
do $\phi(S0)$:
$$
\PROOFmr {
\I0---------- {IndZero$_\phi$}
   {\phi(0)}
\I1----------- {IndStep$_\phi$}
   {\phi(S0)}
}
$$
Ou seja, ganhamos o $\phi(S0)$.
Então podemos usar a regra \namedrule{IndZero$_\phi$} agora com $n\asseq S0$
para ganhar o $\phi(SS0)$:
$$
\PROOFmr {
\I0---------- {IndZero$_\phi$}
   {\phi(0)}
\I1----------- {IndStep$_\phi$}
   {\phi(S0)}
\I1------------ {IndStep$_\phi$}
   {\phi(SS0)}
}
$$
E por aí vai!
Olhando para as duas regras 
$$
\xalignat2
&
\PROOFmr {
\I0------------ {IndZero$_\phi$}
   {\phi(0)}
}
&&
\PROOFmr {
\A {\phi(n)}
\I1------------ {IndSucc$_\phi$}
   {\phi(Sn)}
}
\intertext{observamos que são bem parecidas com as}
&
\PROOFmr {
\I0------------ {Zero}
   {0 \is \Nat}
}
&&
\PROOFmr {
\A  {n \is \Nat}
\I1-------------- {Succ}
   {Sn \is \Nat}
}
\endxalignat
$$
e logo dado qualquer natural $n$, o desafio de estabelecer que $n$ tem
a propriedade $\phi$, acaba sendo o mesmo com o ``desafio'' de estabelecer
que $n$ é um natural mesmo!
Em outras palavras, assim que demonstrar os dois alvos da indução para
matar o $\lforall {n\in\nats} {\phi(n)}$, temos:
$$
n \is \Nat \implies \phi(n).
$$
Ou seja: \emph{todos os naturais têm a propriedade $\phi$ mesmo}.

%%}}}

%%{{{ Does this blah-blah mean anything? 
\note Esse bla-bla presta mesmo?.
%%%{{{ meta 
%%%}}}

O leitor alerto justamente ficaria com dúvidas sobre o texto acima.
Realmente faz sentido essa descripção e essa intuição, mas todo esse
``bla-bla'' serve como uma prova mesmo do princípio da indução?
Serve não.  E por isso que o chamamos de \dterm{princípio}, ou seja
axioma!  Mas calma:
dependendo na fundação de matemática que trabalhamos,
o princípio pode virar teorema mesmo!  No~\ref[Axiomatic_set_theory]
por exemplo, vamos \emph{demonstrar mesmo} o princípio da indução
para os naturais.  Mas por enquanto não temos as ferramentas
nem a maduridade que precisamos para entender essas idéias;
então paciência.
O que podes mesmo fazer desde já é demonstrar a equivalência
desse princípio com um outro, que também é facilmente aceitável:
o princípio da boa ordem (\ref[WOP_iff_PFI]).

%%}}}

\endsection
%%}}}

%%{{{ Two sides of the same coin 
\section Dois lados da mesma moeda.
%%%{{{ meta 
%%%}}}

%%{{{ Inductive definition 
\note Definição inductiva.
%%%{{{ meta 
\label inductive_definitions
%%%}}}

Definimos o tipo Nat assim:
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$
Note que o Nat aparece no lado direito também;
e nesse sentido podemos dizer que essa foi uma definição recursiva.
Esse tipo de definição chamamos de \dterm{definição inductiva}.
Ele libera duas ferramentas poderosas:
definir operações e relações por recursão;
e demonstrar propriedades por indução.

%%}}}

%%{{{ inductive_vs_recursive_definitions 
\beware.
%%%{{{ meta 
\label inductive_vs_recursive_definitions
%%%}}}

Muitas vezes ``definição inductiva'' acaba sendo chamada ``definição recursiva''.
Vários autores, dependendo da área que estão trabalhando adoptam um uso ou
o outro, ou ambos, ou até diferenciando o que cada um significa.
Tradicionalmente o slogan seria:
\standout
<<define por recursão; demonstre por indução>>.
\endstandout

%%}}}

%%{{{ the_power_of_recursion 
\note O poder da recursão.
%%%{{{ meta 
\label the_power_of_recursion
%%%}}}

Estamos tentando \emph{definir algo por recursão},
por exemplo a operação de multiplicação
(\ref[nats_ntimes_recursive_def]).
Escrevemos já
$$
\align
n \ntimes 0  &= 0 \\
n \ntimes Sm &= \text{\lthole}
\endalign
$$
e estamos pensando em como completar nossa definição.
E a Recursão chega e nos oferece um presente:
\quote
<<Para definir o $n \ntimes Sm$, considere o valor do $n \ntimes m$ como dado,
de graça por mim; e veja se tu consegues definir o valor de $n \ntimes Sm$ com isso.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da recursão}.

%%}}}

%%{{{ the_power_of_induction 
\note O poder da indução.
%%%{{{ meta 
\label the_power_of_induction
%%%}}}

Estamos tentando \emph{demonstrar algo por indução}
por exemplo a associatividade da adição.
Já provamos a base (o $\phi(0)$), e queremos
demonstrar o $\phi(Sn)$.
E a Indução chega e nos oferece um presente:
\quote
<<Para demonstrar o $\phi(Sn)$, considere o $\phi(n)$ como dado, de graça por mim;
e veja se tu consegues demonstrar o $\phi(Sn)$ com isso agora.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da indução}.
Compare com nossa primeira tentativa de demonstrar a associatividade da adição
(sem indução) onde nossa única maneira de andar era separar em casos,
mas cada vez que conseguimos matar o ``caso 0'' o ``caso sucessor'' tava
sempre gerando mais dois casos: um novo ``caso 0'' e um novo ``caso sucessor''.
E nossos dados não eram suficientes para matar o ``caso sucessor''.

%%}}}

%%{{{ Where is recursion's principle? 
\note E a recursão?  Não tem princípio não?.
%%%{{{ meta 
%%%}}}

Se recursão é indução são dois lados da mesma moeda mesmo,
e já encontramos e enunciamos o princípio da indução;
a gente não deveria ter analogamente um princípio da recursão
também?
Temos sim, e vamos voltar a estudá-lo e demonstrá-lo depois,
pois precisamos mais ferramentas e maduridade
(\ref[Theory_of_recursive_functions] e~\ref[Axiomatic_set_theory]).

%%}}}

%%{{{ how_about_non_nats 
\note E os não-naturais?.
%%%{{{ meta 
\label how_about_non_nats
%%%}}}

Como falei no~\ref[inductive_definitions] o que nos permite
usar recursão e indução nos naturais é sua definição inductiva.
Ou seja, podemos usar essas ferramentas em qualquer tipo que
foi definido assim.  Nos problemas peço a você formalizar
o princípio da indução como um pequeno ``teaser'' da teoria
que voltaremos estudar mais na~\ref[Structural_recursion_and_induction].

%%}}}

\endsection
%%}}}

%%{{{ From low to high level 
\section De ``low level'' para ``high level''.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ninguém merece ficar escrevendo tudo sobre os naturais
nessa forma ``low level'' que temos usado neste capítulo.
Queremos escrever \symqq{$4$} em vez de \symqq{$SSSS0$}.
e \symqq{$n+1$} em vez de \symqq{$Sn$}.

%%}}}

\TODO finish this.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: tetration 
\problem.
%%%{{{ meta 
\label tetration
\defines
    * tetração
    ;;
%%%}}}

Definimos as operações binárias de adição, multiplicação, e exponenciação no $\Nat$.
Descubra um ``padrão'' nas definições dessas operações, e defina a próxima operação, \dterm{tetração}, nessa seqüência de operações.

%%}}}

%%{{{ prob: products_in_disguise 
\problem.
%%%{{{ meta 
\label products_in_disguise
%%%}}}

Seja $h : \nats\to\nats$.
Defina recursivamente as funcções $t : \nats \to \nats$ e $T : \nats^2 \to \nats$ que satisfazem:
$$
\align
t(n)   &= h(0)h(1)\dotsb h(n-1)     = \Prod\limits_{i=0}^{n-1} h(i);\\
T(m,n) &= h(m)h(m+1)\dotsb h(m+n-1) = \Prod\limits_{i=m}^{m+n-1} h(i).
\endalign
$$

\hint
Depois de definir confira tuas definições seguindo elas para calcular uns valores.
Por exemplo, $t(2)$ e $T(5,2)$ devem dar os resultados
$$
\xalignat2
t(2) &= h(0)h(1)
&
T(5,2) &= h(5)h(6).
\endxalignat
$$

\hint
Mesmo que a funcção $T$ tem aridade 2, escolhendo bem,
tu não precisarás escrever 4 equações, mas apenas 2.

\solution
Definimos
$$
\xalignat2
t      &\eqtype \nats\to\nats   &  T        &\eqtype \nats^2\to\reals\\
t(0)   &= 1                     &  T(m,0)   &= 1                     \\
t(n+1) &= h(n) \ntimes t(n)     &  T(m,k+1) &= h(m+k) \ntimes T(m,k).  
\endxalignat
$$
Tendo definido primeiro a $T$, podemos definir a $t$ assim:
$$
t(n) = T(0,n).
$$

%%}}}

%%{{{ prob: victors_mistake 
\problem.
%%%{{{ meta 
\label victors_mistake
%%%}}}

Tentando resolver o~\ref[products_in_disguise],
% STUDENT: Victor
um aluno definiu corretamente a $t$ e depois a usou
na sua definição de $T$, assim:
$$
T(m,n) = {t(m+n)}/{t(m)}.
$$
Qual o problema com essa definição?
(Suponha como conhecida uma definição recursiva da
operação $/$ de divisão inteira.)

\hint
Qual é o contradomínio da $h$?

\hint
$0\in\nats$.

\hint
O que acontece se $h(i) = 0$ para algum $i \in \nats$?

\solution
Se $h(i) = 0$ para algum $i \in \nats$,
o $t(j)=0$ para todo $j>i$.
Assim, a expressão
${t(m+n)}/{t(m)}$ não é definida para qualquer $m>i$.
Observe que a solução seria certa se
o contradomínio da $h$ fosse o $\nats\setminus\set0$.

%%}}}

%%{{{ prob: every_finite_set_of_reals_has_min_and_max 
\problem.
%%%{{{ meta 
\label every_finite_set_of_reals_has_min_and_max
%%%}}}

Cada conjunto finito e não vazio $A\subset\reals$ possui
elemento mínimo $\min A$ e máximo $\max A$.

\hint
Indução no número de elementos do $A$.

%%}}}

%%{{{ prob: triminos 
\problem Triminôs.
%%%{{{ meta 
\label triminos
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ prob: induction_iff_strong_induction 
\problem.
%%%{{{ meta 
\label induction_iff_strong_induction
\indexes
    * PIFF
    * PIF
    ;;
%%%}}}

$\text{PIF} \iff \text{PIFF}$.

%%}}}

%%{{{ prob: where_is_the_base_of_strong_induction 
\problem Cadê a base da indução forte?.
%%%{{{ meta 
\label where_is_the_base_of_strong_induction
%%%}}}

Seguindo o teorema acima, parece que não precisamos demonstrar uma ``base''
na indução forte.
Critique a seguinte afirmação:
\quote
Quando quero demonstrar um teorema da forma
$\lforall n {\phi(n)}$
usando indução, eu preciso demostrar uma(s) base(s)
$\phi(0), \phi(1), \dotsc, \phi(b)$
e depois demonstrar o $\phi(k+1)$,
dado apenas umas $b+1$ hipoteses:
$\phi(k), \phi(k-1), \dotsc, \phi(k-b)$.
No outro lado, usando indução forte eu preciso mostrar menos
coisas: não tenho que mostrar nenhuma base;
e, além disso, no meu esforço para demonstrar o $\phi(k+1)$,
eu não vou ter apenas umas poucas hipoteses, mas
todos os $\phi(i)$ para $i<k+1$.
Como os dois princípios são válidos no $\nats$,
eu vou sempre usar indução forte.
\endquote

\hint
Quantos $i\in\nats$ satisfazem $i < 0$?

%%}}}

%%{{{ prob: ackermann_function 
\problem.
%%%{{{ meta 
\label ackermann_function
%%%}}}

Considere a funcção recursiva $\alpha : \nats^2 \to \nats$ definida pelas equações:
$$
\align
\alpha(0,x)     &= x+1                      \tag{K1}\\
\alpha(n+1,0)   &= \alpha(n,1)              \tag{K2}\\
\alpha(n+1,x+1) &= \alpha(n,\alpha(n+1, x)) \tag{K3}  
\endalign
$$
\tlist:
\li (i):   Calcule o valor $\alpha(3,2)$, indicando para cada passo qual equação foi usada.
\li (ii):  Demonstre que para todo $x\in\nats$, $\alpha(1,x) = x + 2$.
\li (iii): Demonstre que para todo $x\in\nats$, $\alpha(2,x) = 2x + 3$.
\endtlist
A funcção $\alpha$ é conhecida como funcção de {\Ackermann}Ackermann,
e vamos encontrá-la novamente bem depois, no~\ref[Theory_of_recursive_functions].

%%}}}

%%{{{ prob: quot_rem_eq_prob 
\problem.
%%%{{{ meta 
\label quot_rem_eq_prob
%%%}}}

Considere as funcções $q$, $r$, e $t$ definidas recursivamente:
$$
\xalignat3
q       &\eqtype \nats \to \nats   & r      &\eqtype \nats \to \nats   &  t          &\eqtype \nats^2 \to \bools     \\
q(0)    &=       0\phantom{666}    & r(0)   &=       0\phantom{666}    &  t(0,   0)  &=       \True          \\
q(1)    &=       0\phantom{666}    & r(1)   &=       1\phantom{666}    &  t(0,  Sn)  &=       \False         \\
q(2)    &=       0\phantom{666}    & r(2)   &=       2\phantom{666}    &  t(Sm,  0)  &=       \False         \\
q(n+3)  &=       q(n) + 1          & r(n+3) &=       r(n)              &  t(Sm, Sn)  &=       t(m,n)             
\endxalignat
$$
O que cada funcção calcula?

\hint
Calcule os valores $q(11)$, $q(12)$, $r(11)$, e $r(12)$.

\solution
Temos:
\tlist:
\li: $q(n) = \floor{n / 3}$.
\li: O $r(n)$ é o resto da divisão do $n$ por $3$.
\li: A $t$ decida se suas entradas são iguais ou não.
\endtlist

%%}}}

%%{{{ prob: horses_and_birthdays 
\problem Cavalos e aniversários.
%%%{{{ meta 
\label horses_and_birthdays
%%%}}}

Vamos demonstrar o seguinte:
\quote
<<Para todo $n$ natural, em qualquer conjunto de $n$ pessoas, só tem pessoas com o mesmo dia de aniversário.>>
\endquote
\proofstylize{Suposta demonstração.}
\quote\it
<<Por indução no $n$.
\crproofpart{Base.}
Trivial: em qualquer conjunto de $0$ pessoas, só tem pessoas com o mesmo aniversário, pois não tem nenhuma pessoa e logo não tem como achar pessoas de aniversários diferentes.
\crproofpart{Passo indutivo.}
Seja $k$ natural tal que \emph{em qualquer conjunto de $k$ pessoas, só tem pessoas com o mesmo dia de aniversário}.
Seja $A$ conjunto de $k+1$ pessoas:
$$
A = \set{ p_0, p_1, \dotsc, p_{k-1}, p_k }.
$$
Considere os conjunto
$$
\align
A'  &= \set{ p_0, p_1, \dotsc, p_{k-1} } \\
A'' &= \set{      p_1, \dotsc, p_{k-1}, p_k }.
\endalign
$$
Ambos os $A', A''$ têm $k$ pessoas, e logo pela hipótese indutiva todos os membros de $A'$ têm o mesmo aniversário entre si; e também todos os membros de $A''$ têm o mesmo aniversário entre si.
Como a pessoa $p_1$ está no $A'$, todos os membros de $A'$ têm o mesmo aniversário com o $p_1$.
Mas a pessoa $p_1$ também etsá no $A''$, e logo todos os membros de $A''$ têm o mesmo aniversário com o $p_1$.
Ou seja:
todos os $p_0, p_1, \dotsc, p_{k-1}, p_k$ têm aniversario no mesmo dia.>>
\endquote
Numa maneira parecida podemos demonstrar várias afirmações doidas, como por exemplo a seguinte:
\quote
<<Para todo $n$ natural, em qualquer conjunto de $n$ cavalos, só tem cavalos da mesma cor.>>
\endquote
Obviamente o que ``demonstramos'' é errado, e logo na demonstração existe pelo menos um erro---%
caso contrário seria uma indicação que o princípio da indução não é válido!
Qual é?

%%}}}

\endproblems
%%}}}

%%{{{ When_one_base_is_not_enough 
\section Quando uma base não é suficiente.
%%%{{{ meta 
\label When_one_base_is_not_enough
%%%}}}

%%{{{ df: fibonacci 
\definition Os números Fibonacci.
%%%{{{ meta 
\label fibonacci
\defines
    * Fibonacci!números
    ;;
\credits
    * Fibonacci : números
    ;;
%%%}}}

Definimos os \dterm{números Fibonacci} recursivamente assim:
$$
\align
    F_0     &= 0 \\
    F_1     &= 1 \\
    F_{n+2} &= F_{n+1} + F_n.
\endalign
$$

%%}}}

\TODO Computando seus valores.

%%{{{ x: lucas 
\exercise Os números Lucas.
%%%{{{ meta 
\label lucas
\defines
    * Lucas!números
    ;;
\indexes
    * Lucas!números     seealso: Fibonacci
    ;;
\credits
    * Lucas!números
    ;;
%%%}}}

Os \dterm{números Lucas} são definidos similarmente:
$$
\align
L_0     &= 2\\
L_1     &= 1\\
L_{n+2} &= L_{n+1} + L_n.
\endalign
$$
Calcule o valor $L_{12}$.

%%}}}

%%{{{ prop: lucas_altdef_first_attempt 
\proposition.
%%%{{{ meta 
\label lucas_altdef_first_attempt
\indexes
    * Fibonacci
    ;;
%%%}}}

Para todo inteiro $n \geq 1$,
seja $\ell : \nats\setminus\set0\to\nats$ a funcção definida pela equação
$$
    \ell(n) = F_{n-1} + F_{n+1},
$$
onde $F_n$ é o $n$-ésimo número {\Fibonacci}Fibonacci (veja~\ref[fibonacci]).
Queremos mostrar que para todo $n \geq 1$, $L_n = \ell(n)$,
onde $L_n$ é o $n$-ésimo número {\Lucas}Lucas (veja~\ref[lucas]).

\wrongproof.
Nos vamos demonstrar por indução que \emph{para todo $n \geq 1$, $L_n = \ell(n)$}.
Vamos primeiramente verificar que para $n=1$, realmente temos $L_n = \ell(n)$:
\compute
\ell(1) &= F_0 + F_2      \by {def.~de $\ell(n)$} \\
        &= 0 + F_1 + F_0  \by {def.~de $F_n$} \\
        &= 0 + 1 + 0      \by {def.~de $F_n$} \\
        &= 1              \\
        &= L_1.           \by {def.~de $L_n$} \\
\intertext{Seja $k\in\nats$ com $k\geq 2$, tal que $L_{k-1} = \ell(k-1)$.
Realmente temos}
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$} \\
&= \ell(k-1) + \ell(k-2)                    \by {H.I.} \\
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell(n)$} \\
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $+$} \\
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$} \\
&= \ell(k).                                 \by {def.~de $\ell(n)$} \\
\endcompute
que termina nossa prova.

%%}}}

%%{{{ x: lucas_altdef_find_error 
\exercise.
%%%{{{ meta 
\label lucas_altdef_find_error
%%%}}}

Na prova acima roubamos.
Ache onde e explique como, e pense numa solução.

%%}}}

%%{{{ lucas_altdef_final 
\proposition.
%%%{{{ meta 
\label lucas_altdef_final
%%%}}}

Com a notação da~\ref[lucas_altdef_first_attempt],
para todo $n\geq 1$, $\ell(n) = L_n$.

\proof.
Nos vamos demonstrar por indução que \emph{para todo $n \geq 1$, $L_n = \ell(n)$}.
Vamos primeiramente verificar que para $n=1$ e $n=2$, realmente temos $L_n = \ell(n)$.
Para $n=1$:
\compute
\ell(1) &= F_0 + F_2      \by {def.~de $\ell(n)$} \\
        &= 0 + F_1 + F_0  \by {def.~de $F_n$} \\
        &= 0 + 1 + 0      \by {def.~de $F_n$} \\
        &= 1              \\
        &= L_1.           \by {def.~de $L_n$} \\
\endcompute
E para $n=2$:
$$
\xalignat2
\computed {
      L_2 &= L_1 + L_0  \by {def.~de $L_n$} \\
          &= 1 + 2      \by {def.~de $L_n$} \\
          &= 3          
}
&&
\computed {
\ell(2) &= F_1 + F_3          \by {def.~de $\ell(n)$} \\
        &= 1 + F_2 + F_1      \by {def.~de $F_n$} \\
        &= 1 + 1 + 1          \\
        &= 3.
}
&
\endxalignat
$$
Seja $k\in\nats$ com $k\geq 3$ tal que
$$
L_{k-1} = \ell(k-1)
\qquad
\text{e}
\qquad
L_{k-2} = \ell(k-2)
$$
(nossas \emph{duas} hipoteses indutivas).
Vamos demonstrar que $L_k = \ell(k)$.
Realmente temos
\compute
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$} \\
&= \ell(k-1) + \ell(k-2)                    \by {H.I.} \\
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell(n)$, $k\geq3$} \\
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $+$} \\
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$, $k\geq3$} \\
&= \ell(k),                                 \by {def.~de $\ell(n)$} \\
\endcompute
que termina nossa prova.

%%}}}

%%{{{ x: new_proof_of_sum_of_threes_and_fives_with_three_bases 
\exercise.
%%%{{{ meta 
\label new_proof_of_sum_of_threes_and_fives_with_three_bases
%%%}}}

Ache uma nova prova do~\ref[sum_of_threes_and_fives] por indução
com três bases.

\hint
$k = (k-3) + 3$.

\solution
Seja $k\geq 8 + 3 = 11$ tal que $k-1$, $k-2$, e $k-3$
podem ser escritos como somatórios de $3$'s e $5$'s (H.I.).
Temos
\compute
k &= (k-3) + 3      \\
  &= (3x + 5y) + 3  \quad\text{para alguns $x,y\in\nats$} \by {pela H.I.} \\
  &= 3(x+1) + 5y.
\endcompute
Como precisamos a veracidade da proposição para o valor $k-3$,
devemos mostrar as $3$ bases, para os inteiros $8$, $9$, e $10$:
$$
\alignat 2
8  &= 3 + 5     &&= 3\ntimes 1 + 5\ntimes 1\\
9  &= 3 + 3 + 3 &&= 3\ntimes 3 + 5\ntimes 0\\
10 &= 5 + 5     &&= 3\ntimes 0 + 5\ntimes 2.
\endalignat
$$

%%}}}

%%{{{ two_ways_to_organize_inductive_step 
\note Duas maneiras de organizar tua demonstração.
%%%{{{ meta 
\label two_ways_to_organize_inductive_step
%%%}}}

Ok, vamos supor que tu tá tentando demonstrar algo da forma
$$
\lforall {n \in \nats} {\phi(n)}
$$
por indução, e que tu decidiu usar duas bases
(obviamente a $\phi(0)$ e a $\phi(1)$).
Como seria teu passo indutivo?
Tem duas maneiras boas para proceder agora:
\crproofalt{Maneira 1:}
<<Seja $k\in\nats$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k-2)$\fact{H.I.2}.
Vou demonstrar que $\phi(k)$.>>
Nessa maneira, preciso tomar cuidado que nenhum inteiro menor que $k-2$ aparece
em algum canto errado, pois não sei nada sobre eles; até pior pode ser
que aparecem objetos que nem são definidos.
\crproofalt{Maneira 2:}
<<Seja $k\in\nats$ tal que $\phi(k)$\fact{H.I.1} e $\phi(k+1)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+2)$.>>
E agora preciso tomar o mesmo cuidado, só que agora com inteiros
menores que~$k$.
\eop
\emph{Ambas as maneiras são corretas} e bem escritas e bem entendíveis
e tudo mais---e dá pra variar também, não são
únicas~(\ref[third_way_to_organize_inductive_step]).
Qual vamos escolher?  Depende de gosto e às vezes do contexto também.
Na maioria das vezes eu vou favorecer a primeira:
meus olhos gostam da associação dos ``(H.I.$i$)'' com os $\phi(k-i)$.
Na mesma linha de pensar, na segunda maneira as hipoteses indutivas são as
$\phi(k)$ e $\phi(k+1)$, e o alvo seria o $\phi(k+2)$;
então a (H.I.2) parece mais com o alvo do que com a (H.I.1).
Ou seja: \emph{nos meus olhos}, os dados e o alvo ficam mais arrumados
na maneira 1.
Mas como falei: ambas corretas; questão de gosto; então consulte teus
próprios olhos.

%%}}}

%%{{{ x: third_way_to_organize_inductive_step 
\exercise.
%%%{{{ meta 
\label third_way_to_organize_inductive_step
%%%}}}

Qual seria a terceira ``óbvia'' maneira?
Com que inteiros tem que tomar cuidado se escolhê-la?

\solution
<<Seja $k\in\nats$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+1)$.>>
Nessa maneira, preciso tomar cuidado com inteiros menores de $k-1$.

%%}}}

\endsection
%%}}}

%%{{{ Many variables 
\section Muitas variáveis.
%%%{{{ meta 
%%%}}}

%TODO explain that it's just one more tool to attack theorems
%TODO XXX Maybe refer to a weaker result from "irrationality"?

%%{{{ lemma: odd_to_any_power_is_odd 
\lemma.
%%%{{{ meta 
\label odd_to_any_power_is_odd
%%%}}}

Para todo $n\in\nats$, e todo ímpar $k\in\ints$, $k^n$ é ímpar.

\proof.
Seja $k\in\ints$ ímpar, então $k=2a+1$ para um $a\in\ints$.\foot
Aqui consideramos a seguinte definição de ``ímpar'':
\emph{um inteiro $n$ é \dterm{ímpar} sse existe inteiro $k$ tal que $n = 2k+1$.}
\toof
Vamos demonstrar por indução que para todo $n\in\nats$, $k^n$ é ímpar.
Se $n=0$, imediatamente $k^0 = 1$ e é ímpar ($1 = 2\ntimes 0 + 1$).
Suponha que para algum $t\in\nats$, $k^t$ é ímpar, ou seja $k^t = 2b+1$ para um $b\in\ints$.
Falta demonstrar que $k^{t+1}$ também é ímpar.
Calculando,
\compute
k^{t+1}
&= k k^t               \by {definição de exponenciação} \\
&= (2a + 1) (2b + 1)   \by {hipoteses} \\
&= 4ab + 2a + 2b + 1   \\
&= 2(2ab + a + b) + 1.
\endcompute
Logo, como $2ab + a + b\in\ints$, $k^{t+1}$ é ímpar.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No \ref[odd_to_any_power_is_odd_oneliner] tu demonstrarás esse
lemma numa linha só!

%%}}}

\endsection
%%}}}

%%{{{ Strong induction 
\section O princípio da indução finita forte (PIFF).
%%%{{{ meta 
\label Strong_induction
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O seguinte princípio parece mais forte que o PIF.
Na verdade, nos naturais, os dois princípios são equivalentes:

%%}}}

%%{{{ thm: nats_principle_of_strong_induction
\theorem Princípio da indução finita forte (PIFF).
%%%{{{ meta 
\label nats_principle_of_strong_induction
\indexes
    * PIFF    seealso: indução
    * princípio!da indução finita forte    see: indução forte
    ;;
\defines
    * PIFF
    * indução!forte
    ;;
%%%}}}

Seja $P(n)$ uma propriedade de naturais.
Se para todo $k\in\nats$,
a hipótese que $P(i)$ é verdade para todo $i<k$
implica que $P(k)$ também é,
então $P(n)$ é verdade para todo $n\in\nats$.

%%}}}

%%{{{ note: PIFF in symbols 
\note.
%%%{{{ meta 
%%%}}}

Esquematicamente o PIFF:
$$
\lforall
    {k\in\nats}
    {\vphantom{\bigg(}\Big(\lforall {i < k} {P(i)}\Big) \limplies P(k)}
\implies
\lforall
    {n\in\nats}
    {P(n)}.
$$

%%}}}

\endsection
%%}}}

%%{{{ The well-ordering principle 
\section O princípio da boa ordem (PBO).
%%%{{{ meta 
\label The_wellordering_principle
%%%}}}

%%{{{ df: minimum_first_encounter 
\definition Membro mínimo.
%%%{{{ meta 
\label minimum_first_encounter
\defines
    * \min {~A}  -- mínimo do $A$
    * mínimo
    ;;
%%%}}}

Seja $A$ um conjunto ordenado.
Um membro $m\in A$ é chamado
\dterm{(membro) mínimo do $A$}
sse
$m$ é menor de todos os outros elementos do $A$.
Quando o conjunto $A$ possui mínimo,
escrevemos $\min A$ para denotá-lo:
$$
m = \min A
\defiff
m\in A \mland \lforall {a\in A} {m \leq a}.
$$
Note que necessariamente o mínimo dum conjunto $A$, se existe, pertence ao $A$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para justificar a definição do símbolo $\min A$, \emph{devemos}
demonstrar o seguinte:

%%}}}

%%{{{ x: uniqueness_of_minimum 
\exercise Unicidade de mínimo.
%%%{{{ meta 
\label uniqueness_of_minimum
%%%}}}

Um conjunto não pode ter mais que um mínimo.
Quais propriedades da $\leq$ precisamos?

\hint
Suponha que tem dois mínima diferentes
e aplicando a definição de ``mínimo''
e propriedades de $\leq$,
conclua que são iguais.

\hint
Pelas $m_1 \leq m_2$ e $m_2 \leq m_1$ concluimos que $m_1 = m_2$.

\solution
Sejam $m_1, m_2$ dois mínima dum conjunto $A$, ou seja, temos
$m_1, m_2 \in A$, e também
\mathcols 2
\lforall {a\in A} {m_1 \leq a} &
\lforall {a\in A} {m_2 \leq a}
\endmathcols
Usando a primeira com $a \asseq m_2$ e a segunda com $a \asseq m_1$ temos:
$$
m_1 \leq m_2 \mland
m_2 \leq m_1.
$$
Portanto, $m_1 = m_2$ (pela antisimetria da $\leq$).

%%}}}

%%{{{ x: ordered_singleton_set_has_minimum 
\exercise.
%%%{{{ meta 
\label ordered_singleton_set_has_minimum
%%%}}}

Seja $U$ um conjunto unitário ordenado.
Demonstre que ele tem mínimo.
Quais propriedades da $\leq$ tu precisas aqui?

\solution
Seja $m \in U$ o único membro do $U$.
Vamos confirmar que satisfaz a definição de mínimo.
Já temos que $m$ é um membro do $U$, então basta verificar que
$$
\lforall {u \in U} { m \leq u }.
$$
Seja $u \in U$ então.
Como $U$ unitário, temos $m = u$.
Portanto $m \leq u$ (pela reflexividade da $\leq$).

%%}}}

%%{{{ thm: nats_WOP 
\theorem Princípio da boa ordem (PBO).
%%%{{{ meta 
\label nats_WOP
\indexes
    * PBO    seealso: princípio da boa ordem
    ;;
\defines
    * PBO
    * princípio!da boa ordem
    ;;
%%%}}}

Cada subconjunto não vazio do $\nats$ possui mínimo.

\sketch.
Seja $P(n)$ a propriedade que cada subconjunto $A\subset\nats$
que possui membros menores ou iguais a $n$ tem mínimo.
Mostramos por indução que para todo $n$, $P(n)$.

%%}}}

%%{{{ x: why_standard_induction_on_size_does_not_work 
\exercise.
%%%{{{ meta 
\label why_standard_induction_on_size_does_not_work
%%%}}}

Podemos demonstrar o princípio da boa ordem usando
indução no tamanho do subconjunto $A$?

\solution
Não, isso nos levaria dum resultado apenas
para os subconjuntos finítos de $A$.
O princípio da boa ordem aplica para qualquer
subconjunto não vazio de $\nats$, até para os infinitos.

%%}}}

%%{{{ x: spot_the_wosets_1 
\exercise.
%%%{{{ meta 
\label spot_the_wosets_1
%%%}}}

Quais dos $\ints$, $\rats$, $\rats_{>0}$, $\rats_{\geq0}$, $\reals$,
satisfázem a propriedade de boa ordem?

%%}}}

%%{{{ x: spot_the_wosets_2 
\exercise.
%%%{{{ meta 
\label spot_the_wosets_2
%%%}}}

Seja $a\in\reals$.
Quais dos $\rats_{\geq a}$, $\reals_{\geq a}$,
e $\setst {2^{-n}} {n \in\nats, n \leq a}$
satisfázem a propriedade de boa ordem?

%%}}}

%%{{{ thm: no_int_between_0_and_1 
\theorem.
%%%{{{ meta 
\label no_int_between_0_and_1
%%%}}}

Não existe inteiro $k$ tal que\/ $0 < k < 1$.

\sketch.
Suponha que existe um tal inteiro $k$.
Então o conjunto $C = \setst {c\in\ints} {0 < c < 1}$
de todos os ``contraexemplos'' não é vazio.
Aplique o PBO para tomar seu menor elemento, e ache um outro contraexemplo,
ainda menor, chegando assim numa contradição.

%%}}}

%%{{{ x: no_int_between_0_and_1_by_induction 
\exercise.
%%%{{{ meta 
\label no_int_between_0_and_1_by_induction
%%%}}}

Demonstre o \ref[no_int_between_0_and_1] usando indução.

\hint
Nenhum inteiro negativo satisfaz $0 < m < 1$.
Então para demonstrar que nenhum inteiro fica estritamente entre $0$ e $1$, basta demonstrar
que todos os não-negativos $n$ satisfazem $n=0$ ou $n\geq 1$

\hint
Seja
$
P(n) \defiff \text{$n=0$ ou $n\geq1$}
$.

\hint
A base é trivial.

\hint
Para o passo indutivo, tomando um $k\in\nats$ tal que $P(k)$, separa tua prova
em dois casos, dependendo da razão que o $P(k)$ seja verdade.

%%}}}

%%{{{ x: if_ab_is_1_then_what 
\exercise.
%%%{{{ meta 
\label if_ab_is_1_then_what
%%%}}}

Sejam $a,b\in\ints$ com $ab=1$.
Demonstre que $a=\pm1$ e $b=\pm1$.

%%}}}

%%{{{ thm: nats_principle_of_induction_set_form 
\theorem Indução, forma com conjuntos.
%%%{{{ meta 
\label nats_principle_of_induction_set_form
\defines
    * indução!forma com conjuntos
    ;;
%%%}}}

Seja $A\subset\nats$ tal que $0\in A$ e para todo $n \in A$, $n+1\in A$.
Logo $A=\nats$.

\sketch.
Caso contrário, existeriam ``contraexemplos'', ou seja,
naturais que não pertencem ao $A$.
Aplique a PBO para escolher o menor tal contraexemplo,
e chega num absurdo.

%%}}}

%%{{{ x: shifted_WOP 
\exercise.
%%%{{{ meta 
\label shifted_WOP
%%%}}}

Demonstre que se um subconjunto $A$ de inteiros
tem membros maiores que um número fixo $n_0$,
então existe o $\min \setst {a\in A} {n_0 < a}$.

%%}}}

\endsection
%%}}}

%%{{{ Defining relations recursively 
\section Definindo relações recursivamente.
%%%{{{ meta 
%%%}}}

%%{{{ natleq_rec_def 
\definition Ordem.
%%%{{{ meta 
\label natleq_rec_def
%%%}}}

Com que temos já definido podemos definir recursivamente
uma \emph{relação} no $\nats$.  A relação de ordem $\preceq$:
$$
\align
0  \preceq m  &\iff \True      \tag{LE1}\\
Sn \preceq 0  &\iff \False     \tag{LE2}\\
Sn \preceq Sm &\iff n \preceq m   \tag{LE3}
\endalign
$$

%%}}}

%%{{{ eg: two_leq_four_but_four_notleq_two 
\example.
%%%{{{ meta 
\label two_leq_four_but_four_notleq_two
%%%}}}

Ache se $SS0 \preceq SSSS0$ e se $SSSS0 \preceq SS0$.

\solution.
Calculamos:
\compute
SS0 \preceq SSSS0
&\iff S0 \preceq SSS0  \by {por (LE3)} \\
&\iff 0  \preceq SS0   \by {por (LE3)} \\
&\iff \True         \by {por (LE1)} \\
\endcompute
ou seja, realmente $SS0 \preceq SSSS0$.
No outro lado, calculamos
\compute
SSSS0 \preceq SS0
&\iff SSS0 \preceq S0  \by {por (LE3)} \\
&\iff SS0  \preceq 0   \by {por (LE3)} \\
&\iff \False        \by {por (LE2)} \\
\endcompute
ou seja, $SSSS0 \not\preceq SS0$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos demonstrar que $\preceq$ é uma ordem linear,
demonstrando cada uma das propriedades como fizemos sobre a
$\leq$ nos exercícios
(\reftag[natleq_refl],
\reftag[natleq_antisym],
\reftag[natleq_trans],
\reftag[natleq_total])
mas uma maneira melhor que vai nos permitir ganhar
muitos mais resultados de graça é demonstrar que $\leq$
e $\preceq$ são na verdade a mesma relação.
Ou seja, as definições~\reftag[natleq]
e~\reftag[natleq_rec_def] são equivalentes.
Tu demonstrarás isso no~\ref[rec_and_nonrec_def_of_order_agree].

%%}}}

\endsection
%%}}}

%%{{{ Induction on such and such 
\section Indução em tal coisa.
%%%{{{ meta 
%%%}}}

%%{{{ intro 
\secintro
Até agora usamos indução para demonstrar proposições da forma
$$
\text{para todo natural $n$, $\phi(n)$}.
$$
Já encontramos como ``hackear o sistema'' escolhendo um apropriado
$\phi(\dhole)$, conseguindo assim demonstrar proposições que variaram
um pouco do padrão original.
Nesta secção vamos hackear pouco mais!
%%}}}

\TODO terminar e arrumar.

%%{{{ on the size of sets 
\note Todo conjunto finito.
%%%{{{ meta 
%%%}}}

Vamos supor que estamos tentando demostrar algo da forma
$$
\text{para todo conjunto $S$, $\phi(S)$}.
$$
Podemos usar indução?  Parece que estamos bem longe do padrão permitido,
essa mudança de <<todo natural>> para <<todo conjunto>> não vai ser tão
fácil de hackear como quando mudamos para conseguir um <<todo natural maior que $8$>>.
E se for realmente <<todo conjunto>> podemos esquecer a indução
que aprendemos; mas se for <<todo conjunto \emph{finito}>>?
$$
\text{para todo conjunto finito $S$, $\phi(S)$}.
$$

%%}}}

%%{{{ Q: how can we use induction now? 
\question.
%%%{{{ meta 
%%%}}}

Agora podemos usar indução sim, mas em que?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Indução \emph{no tamanho de $S$}.

%%}}}

%%{{{ df: finite_cardinality_recursively 
\definition Cardinalidade de conjunto recursivamente.
%%%{{{ meta 
\label finite_cardinality_recursively
%%%}}}

Definimos a cardinalidade $\card A$ dum conjunto finito $A$ pelas:
\mathcol
\card A = 0   & \iff A = \emptyset \\
\card A = Sn  & \iff
\pexists {a \in A}
\lexists {A' \subset A}
         { a \notin A'
           \mland \card {A'} = n
           \mland \mubrace {\lforall {x \in A} {\text{$x = a$ ou $x \in A'$}}}
                               {A \subset \set{a} \union A'}
         }
\endmathcol
Se existe $n \in \nats$ tal que $\card A = n$ dizemos que $A$ é \dterm{finito}.

%%}}}

%%{{{ Givens about numbers and order 
\note Dados sobre números e ordem.
%%%{{{ meta 
%%%}}}

Considere os números que tu conhece desde criança, e a ordem $\leq$
neles, onde consideramos dado que para
quaisquer números $x,y,z$, temos:
\mathcols 3
&x \leq x &
&x \leq y \mland y \leq z \implies x \leq z &
&x \leq y \mland y \leq x \implies x = y
\endmathcols
e também que quais quer dois números $x,y$ são comparáveis, ou seja, temos
$x \leq y$ ou $y \leq x$.
Finalmente, chamamos de \dterm{mínimo}
$$
m = \min A
\defiff
m \in A \mland \lforall {a \in A} {m \leq a}.
$$
Chamamos tal $m$ de \dterm{mínimo membro de $A$}.

%%}}}

%%{{{ lemma: finite_numbersets_have_min 
\lemma.
%%%{{{ meta 
\label finite_numbersets_have_min
%%%}}}

Qualquer conjunto finito de números $A$ possui mínimo ou é vazio.

\sketch.
Indução no tamanho do conjunto.
A base é trivial (quando um conjunto é vazio, ele é vazio).
Seja $k\in\nats$ tal que
$$
\text{todos os conjuntos de tamanho $k$ possuem mínimo ou são vazios.} \tag{HI}
$$
Considere um conjunto $A$ de tamanho $k+1$, ou seja,
$$
A = \set {a_1, \dotsc, a_k, a_{k+1}}.
$$
Pela hipótese indutiva sabemos que $\set{a_1,\dotsc,a_k}$ possui mínimo $m$
ou é vazio pois ele tem tamanho $k$.
Caso que ele é vazio, o $a_{k+1}$ é o menor membro do $A$.
Caso que possui mínimo $m$, o menor membro do $A$ é o menor dos $m$ e $a_{k+1}$.
$$
\pforall {n \in \nats}
         {\card A = n \implies \text{$A$ vazio ou $A$ possui mínimo}}.
$$

\proof.
Por indução no tamanho do conjunto $A$ demonstramos que
$$
\pforall {n \in \nats}
\lforall {\text{$A$ conjunto}}
         {\card A = n \implies \text{$A$ vazio ou $A$ possui mínimo}}.
$$
Observe que agora nossa indução virou <<indução original>>.
\proofpart{Base:}
demonstrar que \emph{se $\card A = 0$ então $A$ vazio ou $A$ possui mínimo}.
Suponha $\card A = 0$.
Logo temos que $A$ vazio e pronto.
\proofpart{Passo Indutivo.}
Seja $k \in \nats$ tal que
$$
         {\card H = k \implies \text{$H$ vazio ou $H$ possui mínimo}}.
         \tag{H.I.}
$$
Preciso demonstrar que
$$
\lforall {A \subset \nats}
         {\card A = Sk \implies \text{$A$ vazio ou $A$ possui mínimo}}.
$$
Seja $A \subset \nats$ tal que $\card A = Sk$.
Basta verificar que $A$ vazio ou $A$ possui mínimo.
Vou conseguir a segunda parte: vou demonstrar que $A$ possui mínimo.
Como $\card A = Sk$, temos:
$$
\pexists {a \in A}
\lexists {A' \subset A}
         { a \notin A'
           \mland \card {A'} = k
           \mland \lforall {x \in A} {\text{$x = a$ ou $x \in A'$}}
         }
$$
e logo sejam $m \in A$, $A' \subset A$, tais que
$$
\tubrace {m \notin A'} {(1a)}
\mland \tubrace {\card {A'} = k} {(1b)}
\mland \tubrace {\lforall {x \in A} {\text{$x = m$ ou $x \in A'$}}} {(1c)}.
\tag {1}
$$
Usamos a (HI) agora $H \asseq A'$, e já que $\card {A'} = k$ (pela (1b)) temos:
$$
\text{$A'$ vazio ou $A'$ possui mínimo}.
$$
Separamos em casos.
\case{Caso $A'$ vazio.}
Afirmo que $\min A = m$.
Basta verificar, ou seja, mostrar que $m$ é menor de qualquer membro de $A$.
Seja $x \in A$.
Pela escolha dos $m,A'$ ((1c) com $x \asseq x$) temos que $x = m$ ou $x \in A'$.
No primeiro subcaso temos imediatamente que $m \leq x$ e o segundo subcaso é
impossível pela hipótese do caso ($A'$ vazio).
\case{Caso $A'$ possui mínimo.}
Seja $m' = \min A'$ então.
Seja $m_*$ o menor dos $m,m'$.
Afirmo que $\min A = m_*$.
Basta verificar, ou seja, mostrar que $m_*$ é menor de qualquer membro de $A$.
Seja $x \in A$ então.
Novamente pela escolha dos $m,A'$ temos que $x = m$ ou $x \in A'$.
Tem cada subcaso vou demonstrar que $m_* \leq x$.
\case{Subcaso $x = m$.}
Imediato pois pela escolha de $m_* \leq m = x$.
\case{Subcaso $x \in A'$.}
Pela escolha dos $m_*$ e $m'$ respectivamente temos
$m_* \leq m' \leq x$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: natleq_woset 
\problem.
%%%{{{ meta 
\label natleq_woset
%%%}}}

Demonstre por indução que a $\leq$, definida na~\ref[natleq]
$$
n \leq m \defiff \lexists {k\in\nats} {n + k = m}.
$$
é uma bem-ordem, i.e.,
$$
\text{para todo $A \subset \nats$,\quad
se $A \neq \emptyset$ então $A$ tem elemento mínimo}.
$$
Dizemos que \dterm{mínimo membro de $A$} sse $m \in A$ e $\lforall {a \in A} {m \leq a}$.

\hint
Reductio ad absurdum.

\hint
Para chegar num absurdo suponha que existe $C \subset \nats$ não vazio
tal que $C$ não possui mínimo.
Vamos demonstrar que para todo $n\in\nats$, $C$ não possui membros $c \leq n$.
Isso é suficiente para garantir que $C$ é vazio.

\hint
Agora indução.

\hint
\case{Base: $C$ não possui membros $c \leq 0$.}
Imediato, pois o único natural $n \leq 0$ é o próprio $0$ que é o menor
membro do $\nats$.  Sabemos então que $0 \notin C$ pois caso contrário
o $C$ teria um mínimo.

\hint
\case{Passo Indutivo.}
Seja $k$ tal que $C$ não possui membros $c \leq k$.
Basta demonstrar que $C$ não possui membros $c \leq k+1$.

\solution
Usamos reductio ad absurdum.
Para chegar num absurdo suponha que existe $C \subset \nats$ não vazio
tal que $C$ não possui mínimo.
Vamos demonstrar que para todo $n\in\nats$, $C$ não possui membros $c \leq n$.
Isso é suficiente para garantir que $C$ é vazio.
\case{Base: $C$ não possui membros $c \leq 0$.}
Imediato, pois o único natural $n \leq 0$ é o próprio $0$ que é o menor
membro do $\nats$.  Sabemos então que $0 \notin C$ pois caso contrário
o $C$ teria um mínimo.
\case{Passo Indutivo.}
Seja $k$ tal que $C$ não possui membros $c \leq k$.
Basta demonstrar que $C$ não possui membros $c \leq k+1$.
Suponha então que $C$ possui $c_0 \leq k+1$.
Logo $c_0 < k+1$ ou $c_0 = k+1$.
O caso $c_0 < k+1$ é eliminado pela (HI).
No outro caso temos $k+1 \in C$.
% TODO: finish this

%%}}}

%%{{{ prob: finite_numbersets_have_min_quantifier_check 
\problem.
%%%{{{ meta 
\label finite_numbersets_have_min_quantifier_check
%%%}}}

Faria sentido trocar o \sq{$\pexists {a \in A}$} por \sq{$\pforall {a \in A}$}
na fim do \ref[finite_numbersets_have_min]?

%%}}}

%%{{{ prob: rec_and_nonrec_def_of_order_agree 
\problem.
%%%{{{ meta 
\label rec_and_nonrec_def_of_order_agree
%%%}}}

Na~\ref[natleq] definimos a ordem $\leq$ nos naturais.
Na~\ref[natleq_rec_def] definimos a relação $\preceq$ nos naturais.
Obviamente não podemos dar duas definições diferentes para a mesma coisa.
Demonstre que as duas definições sempre concordam:
$$
\text{para todo $n,m\in\nats$, \quad $n \leq m \iff n \preceq m$.}
$$

%%}}}

%%{{{ prob: structural_induction_teaser_prob 
\problem.
%%%{{{ meta 
\label structural_induction_teaser_prob
%%%}}}

Em qual outros (não-Nat) tipos de coisas tu pode enunciar um princípio
de indução?  Como definarias algo por recursão?
Tente demonstrar alguma propriedade simples sobre tua escolha.

\hint
Tente as fórmulas de lógica proposicional e de predicados (FOL) também.
Podes definir uma funcção que conta quantos $\lor$ aparecem na sua entrada?
Podes demonstrar que em cada fórmula bem formada a quantidade de \symq{$($}
e a quantidade de \symq{$)$} são iguais?

%%}}}

%%{{{ prob: concat_iterations_equivalent 
\problem.
%%%{{{ meta 
\label concat_iterations_equivalent
%%%}}}

Denotamos a operação de concatenação de strings por $\concat$.
Dois alunos definiram com as maneiras seguintes a ``exponenciação'':
$$
\xxalignat4
\text{(L1)} && \lexp s to 0 &= \epsilon                    & \rexp s to 0 &= \epsilon                   && \text{(R1)}\\
\text{(L2)} && \lexp s to n &= \lexp s to {n-1} \concat s  & \rexp s to n &= s \concat \rexp s to {n-1} && \text{(R2)}
\endxxalignat
$$
onde $\epsilon$ é o string vazio ``\,'', que é uma \dterm{identidade}
da concatenação, ou seja, que satisfaz:
$$
\lforall s {\epsilon \concat s = s = s \concat \epsilon}. \tag{E}
$$
Demonstre que as duas definições são equivalentes, ou seja,
que para todo string $s$ e todo $n \geq 0$, $\lexp s to n = \rexp s to n$.
Cuidado: a operação $\concat$ é associativa mas não comutativa:
\sq{oimundo} e \sq{mundooi} são palavras diferentes!

\hint
Tome um string arbitrário $s$, e demonstre por inducção
que \emph{para todo $n\in\nats$, $\lexp s to n = \rexp s to n$}.

\hint
Uma base não é suficiente:
demonstre para $n \asseq 0,1$.

\hint
Para teu passo indutivo, tu terás um $k\geq 2$ tal que
$\lexp s to {k-1} = \rexp s to {k-1}$\fact{HI1} e
$\lexp s to {k-2} = \rexp s to {k-2}$\fact{HI2}.
E com essas duas hipoteses indutivas basta demonstrar
$
\lexp s to k = \rexp s to k.
$

\solution
Seja $s$ string.
Vamos demonstrar por indução (com duas bases) que
\emph{para todo $n\in\nats$, $\lexp s to n = \rexp s to n$}.
Primeiramente verificamos que para $n \asseq 0$ e $n \asseq 1$,
realmente temos $\lexp s to n = \rexp s to n$.
\crproofpart{Base ($n \asseq 0$).}
Calculamos:
$$
\lexp s to 0 \eqlabel{L1} \epsilon \eqlabel{R1} \rexp s to 0.
$$
\crproofpart{Base ($n \asseq 1$).}
Calculamos:
$$
\computed {
\lexp s to 1 &= \lexp s to 0 \concat s \by {def.~$\lexp s to 1$} \\
             &= \epsilon     \concat s \by {def.~$\lexp s to 0$} \\
             &= s                      \by {E} \\
}
\qqqquad
\computed {
\rexp s to 1 &= s \concat \rexp s to 0  \by {def.~$\rexp s to 1$} \\
             &= s \concat \epsilon      \by {def.~$\rexp s to 0$} \\
             &= s.                      \by {E} \\
}
$$
Logo $\lexp s to 1 = \rexp s to 1$.
\crproofpart{Passo indutivo.}
Seja $k\geq 2$ tal que
$\lexp s to {k-1} = \rexp s to {k-1}$\fact{HI1} e
$\lexp s to {k-2} = \rexp s to {k-2}$\fact{HI2}.
Vou demonstrar que
$
\lexp s to k = \rexp s to k.
$
Calculamos:
\compute
\lexp s to k
&= \lexp s to {k-1} \concat s               \by {L1} \\
&= \rexp s to {k-1} \concat s               \by {HI1} \\
&= (s \concat \rexp s to {k-2}) \concat s   \by {R2} \\
&= (s \concat \lexp s to {k-2}) \concat s   \by {HI2} \\
&= s \concat (\lexp s to {k-2}  \concat s)  \by {Assoc.} \\
&= s \concat \lexp s to {k-1}               \by {L2} \\
&= s \concat \rexp s to {k-1}               \by {HI1} \\
&= \rexp s to k.                            \by {R2} \\
\endcompute

%%}}}

%%{{{ prob: even_or_odd_without_LEM 
\problem.
%%%{{{ meta 
\label even_or_odd_without_LEM
%%%}}}

Divulgando o LEM (\reftag[LEM_spell]) tentei vender
a idéia que seria essencial para demonstrar mais
proposições do que realmente é!
Com as definições de par e ímpar seguintes
\mathcol
\text{$n$ par}   &\defiff \lexists {k \in \ints} {n = 2k} \\
\text{$n$ ímpar} &\defiff \lexists {k \in \ints} {n = 2k+1}
\endmathcol
e sem usar nenhum dos feitiços do \ref[Proofs], demonstre a proposição:
{\proclaimstyle todo número natural é par ou ímpar.}

\hint
Indução!

%%}}}

\endproblems
%%}}}

%%{{{ Inductively_defined_types 
\section Tipos inductivamente definidos.
%%%{{{ meta 
\label Inductively_defined_types
%%%}}}

\TODO Lists.

\TODO Trees.

\TODO Bools.

\TODO Formulas.

\TODO Terminar.

\endsection
%%}}}

%%{{{ Structural_recursion_and_induction 
\section Recursão e indução estrutural.
%%%{{{ meta 
\label Structural_recursion_and_induction
%%%}}}

%%{{{ eg: bincon_count 
\example.
%%%{{{ meta 
\label bincon_count
%%%}}}

Defina uma funcção $f : \zolang \to \nats$ que calcula o número
de conectivos binários que aparecem na sua entrada.
Use-lá para calcular os conectivos binários da expressão
$$
\lnot(P_4 \limplies (P_9 \land \lnot P_9)).
$$

\solution.
Seguindo a definição de $\zolang$, cada um dos seus elementos
é formado por uma de certas regras.  Basta escrever então como
calcular o número desejado para cada um desses casos:
$$
\alignat2
f(p)                &= 0,          &\quad&\text{($p\in \mathrm{Pvar}$)} \tag{BC$_{P}$}\\
f(\lnot A)          &= f(A),            &&\text{($A\in \zolang$)}       \tag{BC$_{\lnot}$}\\
f((A \limplies B))  &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\limplies}$}\\
f((A \land B))      &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\land}$}\\
f((A \lor B))       &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\lor}$}\\
\intertext{Preguiçosamente, podemos condensar as três últimas equações em úma só, assim:}
f((A \heartop B)) &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$, e $\heartop \in \set{\limplies,\land,\lor}$)}
\endalignat
$$
Aplicando nossa funcção na fórmula dada calculamos:
\compute
f( \lnot(P_4 \limplies (P_9 \land \lnot P_9)) )
&= f( (P_4 \limplies (P_9 \land \lnot P_9)) )   \by {por BC$_{\lnot}$} \\
&= f( P_4 ) + 1 + f( (P_9 \land \lnot P_9) )    \by {por BC$_{\limplies}$} \\
&= 0 + 1 + f( (P_9 \land \lnot P_9) )           \by {por BC$_{P}$} \\
&= 0 + 1 + ( f( P_9 ) + 1 + f ( \lnot P_9 ) )   \by {por BC$_{\land}$} \\
&= 0 + 1 + ( 0 + 1 + f ( \lnot P_9 ) )          \by {por BC$_{P}$} \\
&= 0 + 1 + ( 0 + 1 + f ( P_9 ) )                \by {por BC$_{\lnot}$} \\
&= 0 + 1 + ( 0 + 1 + 0 )                        \by {por BC$_{P}$} \\
&= 2
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Recursão e indução vamos ficar usando o tempo todo.
Especialmente nos capítulos~\reftag[Theory_of_recursive_functions]
e~\reftag[Axiomatic_set_theory], vamos mergulhar na teoria desses
assuntos; mas sugiro paciência por enquanto,
e \emph{ganhar experiência trabalhando} com recursão e indução.

Sobre o princípio da boa ordem e indução,
dê uma olhada no~\cite[babybm: \S\S1.4--1.5].

Neste capítulo tivemos nosso primeiro contato com
\emph{programação funccional},
um assunto que vamos estudar no~\ref[Functional_programming].
Para o ansioso e animado-para-programar leitor recomendo brincar com uma
linguagem puramente funccional:
\tool{Haskell} (\cite[lyah], \cite[birdfphaskell], \cite[birdthinking],
\cite[huttonhaskell]) ou \tool{PureScript} (\cite[purescriptbook]).

Vale muito a pena investir em trabalhar com uma implementação
como o \tool{Coq} ou a \tool{Agda}.  Ambos podem ser vistos tanto como uma
linguagem de programação funccional, quanto como um \emph{proof assistant}.
Dois textos excelentes para inciantes que meu leitor é muito recomendado
começar desde já estudar são os \cite[piercesf1] (que usa Coq)
e o \cite[wadlerplfa] (que usa Agda).

Para aprofundar ainda mais em recursão e indução consulte os
\cite[aczelinductive] e \cite[ynminduction],
mas sugiro fazer isso bem depois, pois podem aparecer pesados
demais neste momento.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Enumerative_combinatorics 
\chapter Combinatória enumerativa.
%%%{{{ meta 
\label Enumerative_combinatorics
%%%}}}

\TODO terminar e arrumar.

%%{{{ Counting principles 
\section Princípios de contagem.
%%%{{{ meta 
%%%}}}

%%{{{ Informally 
\note Informalmente.
%%%{{{ meta 
%%%}}}

Queremos contar todas as maneiras possíveis para algo acontecer,
certas configurações, certos objetos ser escolhidos, ou ordenados, etc.
Baseamos nossas idéias em dois princípios de contagem:
da \emph{adição} e da \emph{multiplicação}.
\eop
{O princípio da adição, informalmente:}
Se podemos agrupar todos esses objetos em grupos \emph{distintos},
tais que cada objeto pertence em \emph{exatamente um} grupo,
o número total dos objetos é igual o somatório dos tamanhos dos grupos.
\eop
{O princípio da multiplicação, informalmente:}
Se cada configuração pode ser descrita completamente em $n$ passos,
onde para o primeiro passo temos $a_1$ opções,
para o segundo passo temos $a_2$ opções, etc., e
\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores},
então existem em total $a_1a_2\dotsb a_n$ configurações possíveis.

%%}}}

%%{{{ principle: principle_of_addition 
\principle Princípio da adição.
%%%{{{ meta 
\headerize
\label principle_of_addition
\defines
    * princípio!da adição
    ;;
%%%}}}

Seja $A$ conjunto finito, e $A_1,\dotsc,A_n$ subconjuntos dele tais que cada elemento $a\in A$, pertence em \emph{exatamente} um dos $A_i$.
Logo,
$$
|A| = \Sum_{i=1}^n |A_i|.
$$

%%}}}

%%{{{ principle: principle_of_multiplication 
\principle Princípio da multiplicação.
%%%{{{ meta 
\headerize
\label principle_of_multiplication
\defines
    * princípio!da multiplicação
    ;;
%%%}}}

Sejam $A_1,\dotsc,A_n$ conjuntos finitos.
Logo
$$
|A_1\times\dotsb\times A_n| = |A_1|\dotsb|A_n|.
$$

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string de tamanho $3$\dots
\tlist:
\li (i): Usando o alfabeto
$\set{\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z}$?
\li (ii): Usando o mesmo alfabeto, mas proibindo o mesmo caractere se repetir no string?
\endtlist

\solution.
Consideramos a formação de cada string em passos, caractere a caractere.
Temos 3 posições para colocar os caracteres:
$
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
$.
\eop
Para a questão (i), temos:
$26$ maneiras para escolher o primeiro caractere,
$26$ para o segundo, e
$26$ para o último:
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;.
$$
A escolha em cada passo não é afeitada por as escolhas dos passos anteriores.
Logo, pelo princípio da multiplicação tem
$$
26\ntimes 26\ntimes 26 = 26^3
$$
strings possíveis.
\eop
Para a questão (ii), temos:
$26$ maneiras para escolher o primeiro caractere,
$25$ para o segundo (todos menos aquele que escolhemos no passo anterior), e
$24$ para o último (similarmente):
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{25}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{24}
\;.
$$
Agora a escolha em cada passo realmente \emph{é afeitada} por as escolhas
dos passos anteriores!
Por exemplo, se no primeiro passo escolher o caractere $\txt C$, para
o segundo passo as opções incluem o caractere $\txt A$; 
mas se no primeiro passo escolher o caractere $\txt A$, as opções para o segundo
mudam: não temos essa opção mais.
\emph{Mesmo assim, podemos usar o princípio da multiplicação!}
Por quê?
As escolhas dos passos anteriores afeitam \emph{quais} são as escolhas do passo atual,
mas não afeitam \emph{quantas} elas são!
Por isso, chegamos no resultado aplicando mais uma vez o princípio da multiplicação:
temos
$$
26\ntimes 25\ntimes 24
$$
maneiras possíveis.

%%}}}

%%{{{ x: 4 gifts for 3 kids 
\exercise.
%%%{{{ meta 
%%%}}}

Temos $4$ presentes e queremos dar para $3$ crianças tal que cada criança vai
receber apenas um presente.
\tlist:
\li (i): De quantas maneiras podemos disribuir os presentes para as crianças?
\li (ii): O que muda se as crianças são $4$?  Explique.
\endtlist

%%}}}

%%{{{ x: in how many ways can we write strings of length 2 using ABCD 
\exercise.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever strings de tamanho $2$ usando o alfabeto
$$
\set{\txt A, \txt B, \txt C, \txt D},
$$
tais que as letras aparecem em ordem que concorda com a do alfabeto?
Por exemplo os string $\txt A \txt C$, $\txt B \txt B$, e $\txt C \txt D$ são aceitáveis,
mas os $\txt D \txt C$ e $\txt B \txt A$, não.

\hint
Cuidado: aqui a \emph{quantidade} das opções da segunda escolha, depende sim na escolha
anterior!

\hint
Separa os strings possíveis em colecções e conta os strings de cada colecção separadamente,
somando no final (princípio de adição) para achar o resultado.

%%}}}

\endsection
%%}}}

%%{{{ Permutations and combinations 
\section Permutações e combinações.
%%%{{{ meta 
\label Permutations_and_combinations
%%%}}}

%%{{{ Q: in how many ways can we choose r from n? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escolher $r$ objetos de $n$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essa questão é bastante ambígua;
por exemplo:
Os $n$ objetos são todos distintos?
Podemos repetir o mesmo objeto na nossa escolha?

%%}}}

%%{{{ df: comb_perm_totperm 
\definition.
%%%{{{ meta 
\label comb_perm_totperm
\defines
    * \comb {~n} {~r}  -- o número de $r$-combinações de $n$ objetos
    * \perm {~n} {~r}  -- o número de $r$-permutações de $n$ objetos
    * \totperm {~n}  -- o número de permutações (totais) de $n$ objetos
    ;;
%%%}}}

Usamos os símbolos:
$$
\align
\totperm n &:\quad\text{o número de permutações totais de $n$ objetos}\\
\perm n r  &:\quad\text{o número de $r$-permutações de $n$ objetos}\\
\comb n r  &:\quad\text{o número de $r$-combinações de $n$ objetos}
\endalign
$$
Onde entendemos que:
\elist i:
\li: os $n$ objetos são distíntos;
\li: não podemos repeti-los.
\endelist
Observe que as permutações totais são apenas casos especiais de $r$-permutações.
Na literatura encontramos $r$-permutações também com o nome \dterm{arranjos},
mas nós vamos evitar esse termo aqui para evitar confusão.

%%}}}

%%{{{ prop: total_permutations 
\proposition Permutações totais.
%%%{{{ meta 
\label total_permutations
\defines
    * permutação!total
    ;;
\indexes
    * arranjo    see: permutação
    ;;
%%%}}}

$$
\totperm n = {n!}.
$$

%%}}}

%%{{{ prop: permutations 
\proposition Permutações.
%%%{{{ meta 
\defines
    * permutação
    ;;
%%%}}}

$$
\perm n r = \frac {n!} {(n-r)!}.
$$

%%}}}

%%{{{ prop: combinations 
\proposition Combinações.
%%%{{{ meta 
\defines
    * combinação
    ;;
%%%}}}

$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$

%%}}}

%%{{{ eg: 10_friends_car_trip 
\example.
%%%{{{ meta 
\label 10_friends_car_trip
%%%}}}

$10$ amigos têm vontade viajar com um carro de $5$ vagas.
De quantas maneiras diferentes $5$ deles podem entrar no carro?
Considere que o que diferencia mesmo a configuração são apenas a posição
do motorista e do copiloto.

\solution.
Vamos ver dois jeitos diferentes para contar essas configurações:
\crtabproofalt{Jeito 1:}
Escrevendo
$$
\comb {10} 1
\ntimes
\comb 9 1
\ntimes
\comb 8 3
$$
já é meio auto-explicativo: formamos cada configuração em passos:
{(i)}      escolher o motorista;
{(ii)}     escolher o copiloto;
{(iii)}    escolher os passangeiros de trás.
\crtabproofalt{Jeito 2:}
Outra método para formar cada configuração seria:
{(i)}      escolher os 5 que vão entrar no carro;
{(ii)}     escolher qual vai ser o motorista;
{(iii)}    escolher qual vai ser o copiloto.
pensando assim chegamos no cálculo
$$
\tubrace{\comb {10} 5} {(i)}
\ntimes
\tubrace{\comb 5 1} {(ii)}
\ntimes
\tubrace{\comb 4 1} {(iii)}.
$$
\eop
Olhando para os dois cálculos
$$
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
\askeq
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
$$
não é óbvio que seus valores são iguais.
Calculamos
$$
\alignat2
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
&= 10 \ntimes 9 \ntimes \frac {8!} {5!\stimes3!}
&&= \frac {10!} {5!\stimes3!}
\\
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
&= \frac {10!} {5!\stimes 5!} \ntimes 5 \ntimes 4
&&= \frac {10!} {5!\stimes 3!}
\endalignat
$$
e respondemos (felizmente) que em total temos
$$
\frac {10!} {5!\stimes3!}
= \frac{10 \ntimes 9 \ntimes 8\ntimes7\ntimes6} { 3! }
= 10 \ntimes 9 \ntimes 8\ntimes7
= 5040
$$
configurações diferentes.

%%}}}

\endsection
%%}}}

%%{{{ Permutations in a circle 
\section Permutações cíclicas.
%%%{{{ meta 
%%%}}}

%%{{{ eg: circle_dance_of_8 
\example.
%%%{{{ meta 
\label circle_dance_of_8
%%%}}}

$8$ pessoas querem dançar uma dança em qual
todos precisam formar um ciclo pegando as mãos
(e olhando para o interior do ciclo).
Em quantas configurações diferentes essa dança pode começar?

\solution.
Vamos resolver esse problema seguindo duas idéias bem diferentes:
\crtabproofalt{Idéia~1.}
Consideramos primeiro a questão:
``\emph{de quantas maneiras podemos permutar as $8$ pessoas numa ordem?}''
Respondemos $8!$, o número das permutações totais de $8$ objetos
(sabendo que hipercontamos para o problema original).
Mas podemos calcular \emph{exatamente quanto} hipercontamos:
cada resposta do problema original corresponde em exatamente
$8$ respostas do problema novo (uma para cada ``circular shift'').
Então basta só dividir a ``hiperconta'' por $8$, e chegamos
no resultado final: $8! / 8$, ou seja, $7!$.
\crtabproofalt{Idéia~2.}
\emph{Fixamos uma pessoa como ``determinante'' da configuração;}
a idéia sendo que para comparar duas configurações nós vamos
começar com o determinante, e depois comparar em ordem fixa
o resto da configuração
(por exemplo indo cada vez de uma pessoa
para quem tá no lado direito dela).
Assim, para cada permutação total das 7 outras pessoas,
temos uma permutação circular das 8 e vice-versa,
ou seja, a resposta final é $7!$.

%%}}}

%%{{{ fig for circle_dance_of_8 
\midinsert
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{p_0}$};
\node[circle,fill=white] at (a0)   {$p_0$};
\node[circle,fill=white] at (a45)  {$p_1$};
\node[circle,fill=white] at (a90)  {$p_2$};
\node[circle,fill=white] at (a135) {$p_3$};
\node[circle,fill=white] at (a180) {$p_4$};
\node[circle,fill=white] at (a225) {$p_5$};
\node[circle,fill=white] at (a270) {$p_6$};
\node[circle,fill=white] at (a315) {$p_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=white] at (a315)  {$p_0$};
\node[circle,fill=white] at (a0)    {$p_1$};
\node[circle,fill=white] at (a45)   {$p_2$};
\node[circle,fill=white] at (a90)   {$p_3$};
\node[circle,fill=white] at (a135)  {$p_4$};
\node[circle,fill=white] at (a180)  {$p_5$};
\node[circle,fill=white] at (a225)  {$p_6$};
\node[circle,fill=white] at (a270)  {$p_7$};
\endtikzpicture
%%}}}
\hfil
\eop\centerline{Uma configuração do~\reftag[circle_dance_of_8] representada em dois jeitos diferentes no papel.}
\endinsert
%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando concluimos que:

%%}}}

%%{{{ prop: permutations_in_circle 
\proposition.
%%%{{{ meta 
\label permutations_in_circle
%%%}}}

As configurações circulares diferentes de $n$ objetos, $n>0$ são
$$
(n-1)!.
$$

%%}}}

%%{{{ x: circle_dance_of_8_inorout 
\exercise.
%%%{{{ meta 
\label circle_dance_of_8_inorout
%%%}}}

O que mudará na contagem do~\ref[circle_dance_of_8],
se cada dançador pode olhar ou para o interior ou para o exterior do círculo?

\hint
Começando com a mesma resposta ($7!$) do~\ref[circle_dance_of_8],
claramente nos hipocontamos---mas quanto?

\hint
Considere uma configuração do~\ref[circle_dance_of_8].
Com quantas configurações do problema atual ela corresponde?

%%}}}

%%{{{ x: circle_dance_of_8_couples 
\exercise.
%%%{{{ meta 
\label circle_dance_of_8_couples
%%%}}}

O que mudará na contagem do~\ref[circle_dance_of_8],
se temos $4$ mulheres e $4$ homens e as regras da dança
mandam alternar os sexos na configuração?

\hint
Construa cada configuração em passos.

\hint
Primeiramente, esqueça os homens (ou as mulheres)
e coloca as $4$ mulheres (ou os $4$ homens)
num ciclo.
De quantas maneiras pode escolher o resto para
entrar no círculo?

%%}}}

%%{{{ x: 8_bead_bracelet 
\exercise.
%%%{{{ meta 
%%%}}}

Temos $8$
miçangas
diferentes, e queremos pôr todas
numa
corrente
para criar uma pulseira.
Quantas maneiras diferentes temos para o criar?

\hint
Se tu achar o problema igual com o~\ref[circle_dance_of_8],
tu hipercontarás\dots Quanto?

\hint
Veja a figura.
Pode explicar por que as três representações
correspondem na mesma configuração?
\topinsert
\centerline{
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a0)   {$a_0$};
\node[circle,fill=green!33]     at (a45)  {$a_1$};
\node[circle,fill=blue!33]      at (a90)  {$a_2$};
\node[circle,fill=cyan!33]      at (a135) {$a_3$};
\node[circle,fill=magenta!33]   at (a180) {$a_4$};
\node[circle,fill=yellow!33]    at (a225) {$a_5$};
\node[circle,fill=orange!33]    at (a270) {$a_6$};
\node[circle,fill=brown!33]     at (a315) {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a0)    {$a_1$};
\node[circle,fill=blue!33]      at (a45)   {$a_2$};
\node[circle,fill=cyan!33]      at (a90)   {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a180)  {$a_5$};
\node[circle,fill=orange!33]    at (a225)  {$a_6$};
\node[circle,fill=brown!33]     at (a270)  {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a270)  {$a_1$};
\node[circle,fill=blue!33]      at (a225)  {$a_2$};
\node[circle,fill=cyan!33]      at (a180)  {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a90)   {$a_5$};
\node[circle,fill=orange!33]    at (a45)   {$a_6$};
\node[circle,fill=brown!33]     at (a0)    {$a_7$};
\endtikzpicture
%%}}}
}
\botcaption{}
\emph{Apenas uma} das configurações da pulseira, representada em três desenhos.
\endcaption
\endinsert

%%}}}

\endsection
%%}}}

%%{{{ Together or separated 
\section Juntos ou separados.
%%%{{{ meta 
%%%}}}

%%{{{ x: dinner_of_8_with_couple 
\example.
%%%{{{ meta 
\label dinner_of_8_with_couple
%%%}}}

Suponha que $8$ pessoas $A,B,C,D,E,F,G,H$ querem sentar num bar
mas $C$ e $D$ querem sentar juntos.
De quantas maneiras isso pode acontecer?

\solution.
\emph{Vamos imaginar que $C$ e $D$ são uma pessoa, chamada $CD$.}
Nos perguntamos de quantas maneiras as 7 pessoas $A,B,CD,E,F,G,H$ podem sentar
numa mesa de bar com $7$ banquinhos.
A resposta é os permutações totais de tamanho 7, ou seja, $7!$.
Mas para cada configuração desse problema,
correspondem \emph{duas} configurações do problema original, porque os
$C$ e $D$ podem sentar em duas ordens diferentes juntos.
A resposta final:
$7! \ntimes 2$.

%%}}}

%%{{{ x: 8_persons_are_sitting_on_a_bar 
\exercise.
%%%{{{ meta 
% TODO: fix reflabs 
%%%}}}

Suponha que 8 pessoas $A,B,C,D,E,F,G,H$ querem jantar numa mesa de bar.
Em quantas configurações diferentes eles podem sentar se\dots:
\tlist:
\li (1): os $C$ e $D$ e $E$ querem sentar juntos;
\li (2): os $F$ e $G$ não podem sentar juntos;
\li (3): as duas restricções (1) e (2).
\endtlist

\hint
\tlist:
\li (1): Como no \ref[dinner_of_8_with_couple],
         considere o problema onde $C$, $D$, e $E$ são uma pessoa só.
\li (2): Conte o complementar e subtraia do total sem restricção;
\li (3): Conte as configurações em quais $C$, $D$, e $E$ sentam juntos e subtraia
         as configurações onde, além disso, $F$ e $G$ também sentam juntos.
\endtlist

\solution
(1) Como no \ref[dinner_of_8_with_couple], traduzimos o problema para um onde
$C$, $D$, e $E$, são uma pessoa---vamos chamá-la de $CDE$---e as
$6$ pessoas $A,B,CDE,F,G,H$ querem jantar numa mesa de bar com 6 banquinhos.
Cada solução desse problema corresponde em tantas configurações quantas as $3$ pessoas
$C$, $D$, $E$ podem sentar numa ordem, ou seja $\totperm 3$ configurações.
A resposta final:
$$
\totperm 6 \ntimes \totperm 3 = 6!\stimes3! = 6!\stimes 6
$$
\eop
(2) Contamos o complementar:
todas as maneiras onde $F$ e $G$ sentam juntos ($7!\ntimes 2$),
e o tiramos de todas as maneiras sem restricção ($8!$):
$$
\totperm 8 - \totperm 7 \ntimes \totperm 2
= 8! - 7!\ntimes 2! = 7!(8 - 2)
= 7!\stimes 6
$$
(3) Já achamos quantas maneiras tem onde $C$, $D$, e $E$ sentam juntos: $6!\stimes6$.
Disso, precisamos subtrair as configurações onde $F$ e $G$ também sentam juntos:
para satisfazer as duas restricções, consideramos as $5$ ``pessoas''
$A,B,CDE,FG,H$, quais podem sentar numa mesa de bar de tamanho $5$ de
$$
\totperm 5 \stimes \totperm 3 \stimes \totperm 2
= 5! \stimes 3! \stimes 2!
= 5! \stimes 6 \stimes 2
= 6! \stimes 2
$$
maneiras.
A resposta final então é
$$
6!\stimes6 - 6!\stimes2 = 6!(6-2) = 6! \stimes 4.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando:

%%}}}

%%{{{ prop: total_permutations_with_consecutives_restriction 
\proposition.
%%%{{{ meta 
\label total_permutations_with_consecutives_restriction
%%%}}}

O número das permutações totais de $m$ objetos distintos com a restricção que
certos $c$ deles tem que estar consecutivos é
$$
(m-c+1)! \stimes c!.
$$

%%}}}

\endsection
%%}}}

%%{{{ Permutations of things not all distinct 
\section Permutações de objetos não todos distintos.
%%%{{{ meta 
%%%}}}

%%{{{ Q: in how many ways can we permute n not-all-distinct objects? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos permutar $n$ objetos se
eles não são todos distíntos?

%%}}}

%%{{{ eg: pessimissimo 
\example.
%%%{{{ meta 
\label pessimissimo
%%%}}}

Conte todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}.
$$

\solution.
Vamos contar em dois jeitos diferentes:
\crproofalt{Idéia 1:}
Construimos cada palavra possível ``em passos'',
usando o princípio da multplicação para achar o número total.
$$
\alignat 2
\text{Começamos com 12 espaços:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
\\
\text{escolhemos onde colocar o ${\txt P}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {12} 1$ opções;}
\\
\text{depois o ${\txt E}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {11} 1$ opções;}
\\
\text{depois os 4 ${\txt S}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {10} 4$ opções;}
\\
\text{depois os 3 ${\txt I}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb 6 3$ opções;}
\\
\text{depois os 2 ${\txt M}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 3 2$ opções;}
\\
\text{e finalmente o ${\txt O}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
          {         {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 1 1$ opção.}
\endalignat
$$
Pelo princípio da multiplicação, a resposta é o produto
$$
\align
\underbrace{\comb {12} 1}_{\dsize {\txt P}}
\underbrace{\comb {11} 1}_{\dsize {\txt E}}
\underbrace{\comb {10} 4}_{\dsize4{\txt S}}
\underbrace{\comb {6}  3}_{\dsize3{\txt I}}
\underbrace{\comb {3}  2}_{\dsize2{\txt M}}
\underbrace{\comb {1}  1}_{\dsize {\txt O}}
&=
\frac
{12!}
{\cancel{11!}\stimes 1!}
\frac
{\cancel{11!}}
{\cancel{10!}\stimes 1!}
\frac
{\cancel{10!}}
{\cancel{6!}\stimes 4!}
\frac
{\cancel{6!}}
{\cancel{3!}\stimes 3!}
\frac
{\cancel{3!}}
{\cancel{1!}\stimes 2!}
\frac
{\cancel{1!}}
{0!\stimes 1!}\\
&=
\frac
{12!}
{1!
\stimes 1!
\stimes 4!
\stimes 3!
\stimes 2!
\stimes 1!
}
=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$
\crproofalt{Idéia 2:}
Contamos as maneiras como se todas as letras fossem distintas,
por exemplo marcando cada letra com índices:
$$
{\txt P}_1\ 
{\txt E}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_1\ 
{\txt M}_1\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt M}_2\ 
{\txt O}_1\,.
$$
Sabemos que são $12!$ e que
assim temos \emph{hipercontado} para nosso problema.
Por exemplo, a palavra 
$
{\txt M}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt P}
{\txt O}
{\txt E}
{\txt M}
$
corresponde em várias palavras do problema novo;
escrevemos três delas aqui como exemplos:
$$
{\txt M}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt P}\ 
{\txt O}\ 
{\txt E}\ 
{\txt M}
\ 
\transto
\ 
\brace{
\gathered
{\txt M}_1\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_2
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_4\ 
{\txt S}_3\ 
{\txt I}_2\ 
{\txt S}_2\ 
{\txt S}_1\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
\vdots
\endgathered
\quad\qquad
}
\ \text{\dots quantas?}
$$
Mas é fácil calcular quanto hipercontamos:
\emph{cada} palavra do problema original corresponde em exatamente tantas palavras
quantas as maneiras de permutar cada grupo de letras ``subindicadas'' entre si,
ou seja:
$$
\underbrace{1!}_{{\txt P}} \ntimes
\underbrace{1!}_{{\txt E}} \ntimes
\underbrace{4!}_{{\txt S}} \ntimes
\underbrace{3!}_{{\txt I}} \ntimes
\underbrace{2!}_{{\txt M}} \ntimes
\underbrace{1!}_{{\txt O}}
$$
maneiras.
Para responder então, basta dividir o número da ``hipercontagem'' por esse:
$$
\frac
{12!}
{4!\stimes 3!\stimes 2!}.
$$
Pronto.

%%}}}

%%{{{ x: choices_may_depend_on_past_ones_but_not_their_quantity 
\exercise.
%%%{{{ meta 
\label choices_may_depend_on_past_ones_but_not_their_quantity
%%%}}}

Escolhendo outra ordem de colocar as letras
na \proofstylize{Idéia 1} do~\ref[pessimissimo]
nossas opções em cada passo seriam diferentes.
Explique porque podemos usar o princípio da multiplicação mesmo assim.

\hint
Presta atenção na frase
``\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores}''.

\solution
O imporante é que em cada passo, qual das nossas disponíveis opções
será escolhida, não vai afeitar a quantidade das nossas opções no passo seguinte.
Isso é realmente válido nesse caso.
Se escolher colocar as letras em outra ordem, por exemplo a
$
{\txt S},
{\txt E},
{\txt I},
{\txt P},
{\txt O},
{\txt M}
$, teriamos quantidades diferentes para cada passo sim,
\emph{mas}\/:
cada uma das nossas escolhas, não afeitaria a quantidade das escolhas próximas.
Com essa ordem, chegamos no mesmo resultado (com um cálculo que de longe aparece diferente):
$$
\align
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
&=
\frac
{12!}
{\cancel{8!}\stimes 4!}
\frac
{\cancel{8!}}
{\cancel{7!}\stimes 1!}
\frac
{\cancel{7!}}
{\cancel{4!}\stimes 3!}
\frac
{\cancel{4!}}
{\cancel{3!}\stimes 1!}
\frac
{\cancel{3!}}
{\cancel{2!}\stimes 1!}
\frac
{\cancel{2!}}
{0!\stimes 2!}\\
\vphantom{
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
}
&=
\frac
{12!}
{4!
\stimes 1!
\stimes 3!
\stimes 1!
\stimes 1!
\stimes 2!
}\\
&=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Binomial coefficients 
\section Binomial e seus coeficientes.
%%%{{{ meta 
%%%}}}

%%{{{ thm: binomial_theorem 
\theorem Binomial.
%%%{{{ meta 
\label binomial_theorem
\indexes
    * binomial!teorema    see: teorema
    * teorema!binomial
    ;;
%%%}}}

Sejam $x,y\in\ints$ e $n\in\nats$.
$$
\align
(x+y)^n
&= \binom n 0 x^n + \binom n 1 x^{n-1}y + \dotsb + \binom n {n-1} xy^{n-1} + \binom n n y^n\\
&= \Sum_{i=0}^n \binom n i x^{n-i}y^i.
\endalign
$$

\sketch.
Queremos achar quantas vezes o termo $x^{n-r}y^r$ aparece na expansão do binomial.
Escrevendo
$$
(x+y)^n = \tubrace {(x+y)(x+y)\dotsb(x+y)} {$n$ vezes}
$$
observamos que para cada das $\comb n r$ maneiras de escolher $r$ dos termos acima,
corresponde um termo $x^{n-r}y^r$:
``escolha quais dos termos do produto vão oferecer seu $y$
(o resto dos termos oferecerá seus $x$'s)''.
Isso justifica os coeficientes $\binom n r$.
Por exemplo, para $n=7$ e $r=4$, a escolha
$$
(x+y)^7
=
(x+y)
\tubrace {(x+y)} {``$y$''}\,
(x+y)
\tubrace {(x+y)} {``$y$''}
\tubrace {(x+y)} {``$y$''}\,
(x+y)
\tubrace {(x+y)} {``$y$''}
$$
corresponde no produto
$xyxyyxy = x^3y^4$, e cada diferente escolha das $\binom 7 4$
correspondará com uma maneira diferente para formar o $x^3y^4$.

%%}}}

\endsection
%%}}}

%%{{{ Number of subsets 
\section Número de subconjuntos.
%%%{{{ meta 
\label Number_of_subsets
%%%}}}

%%{{{ Q: how many subsets of a finite set? 
\question.
%%%{{{ meta 
%%%}}}

Quantos subconjuntos dum conjunto finito existem?

%%}}}

%%{{{ Idea 1: subset_count_using_strings 
\note Idéia 1.
%%%{{{ meta 
\label subset_count_using_strings
%%%}}}

Começamos com um exemplo de um conjunto $A$ de tamanho 6:
$$
A = \set{a, b, c, d, e, f}.
$$
Uns subconjuntos de $A$ são os:
$$
\set{a,d,e},
\qquad
\emptyset,
\qquad
\set{a},
\qquad
\set{b,c,e,f},
\qquad
A,
\qquad
\set{f},
\qquad
\dotsc
$$
Queremos contar todos os subconjuntos de $A$.
Vamos \emph{traduzir o problema} de contar os subconjuntos do $A$
para um problema que envolve $n$-tuplas de dois símbolos ``0'' e ``1'', ``sim'' e ``não'', ``$\in$'' e ``$\notin$'', etc.
(Obviamente \emph{quais} são esses símbolos não afeita nada; o que importa é
que são dois símbolos distintos.)
Podemos associar agora cada dessas tuplas (ou strings) de tamanho $n$ para um
subconjunto de $A$, e vice-versa, chegando numa correspondência entre as duas
colecções de objetos.
Naturalmente associamos, por exemplo,
$$
\def\Y{1}
\def\N{0}
\underbrace{
\matrix
a  & b  & c  & d  & e  & f \\
\Y & \N & \N & \Y & \Y & \N\\
\N & \N & \N & \N & \N & \N\\
\Y & \N & \N & \N & \N & \N\\
\N & \Y & \Y & \N & \Y & \Y\\
\Y & \Y & \Y & \Y & \Y & \Y\\
\N & \N & \N & \N & \N & \Y\\
\vdots&
\vdots&
\vdots&
\vdots&
\vdots&
\vdots
\endmatrix
}_{\text{Strings de tamanho 6 do alfabeto $\set{\N,\Y}$}}
\quad\bitrans\quad
\underbrace{
\matrix
\format
\c\\
\\
\set{a,d,e}\\
\emptyset\\
\set{a}\\
\set{b,c,e,f}\\
A\\
\set{f}\\
\vdots
\endmatrix
}_{\text{Subconjuntos de $A$}}
$$
e verificamos que realmente cada configuração do problema original de subconjuntos
corresponde exatamente numa configuração do problema novo dos strings e vice-versa.
\eop
\emph{O que ganhamos?}
Sabemos como contar todos esses strings: são $2^6$.
Concluimos que os subconjuntos do $A$ são $2^6$ também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando essa idéia chegamos no resultado:

%%}}}

%%{{{ prop: number_of_subsets_of_finite_set_as_power 
\proposition.
%%%{{{ meta 
\label number_of_subsets_of_finite_set_as_power
%%%}}}

Seja $A$ conjunto finito.
$$
\card{\pset A} = 2^{\card A}.
$$

%%}}}

%%{{{ Idea 2: subset_count_by_grouping 
\note Idéia 2.
%%%{{{ meta 
\label subset_count_by_grouping
%%%}}}

Um outro jeito para contar todos os subconjuntos dum dado conjunto $A$, seria
os separar em grupos baseados no seu tamanho.
Assim, percebos que esses subconjuntos são naturalmente divididos em $n+1$ colecções:
subconjuntos com $0$ elementos, com $1$ elemento, \dots, com $n$ elementos.
\eop
\emph{O que ganhamos?}
Sabemos como contar os elementos de cada uma dessas colecções:
para formar um subconjunto de tamanho $r$, precisamos escolher $r$ dos $n$ elementos,
ou seja, existem $\comb n r$ subconjuntos de tamanho $r$.
Agora, pelo princípio da adição basta apenas somar:
são
$\Sum_{i=0}^n \comb n i$.
\eop
\emph{Qual o problema?}
Comparando essa solução com a do item~\reftag[subset_count_using_strings],
aqui temos a dificuldade de realmente calcular todos os $n$ números $\comb n i$
para os somar.
O~\ref[sum_of_all_binomial_coefficients] mostre que na verdade,
não é nada dificil calcular o somatório diretamente sem nem
calcular nenhum dos seus termos separadamente!

%%}}}

%%{{{ prop: number_of_subsets_of_finite_set_as_sum 
\proposition.
%%%{{{ meta 
\label number_of_subsets_of_finite_set_as_sum
%%%}}}

Seja $A$ conjunto finito.
$$
\card{\pset A} = \Sum_{i=0}^n \comb n i,\qquad\text{onde $n = \card A$}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Combinando as duas proposições chegamos num resultado interessante:

%%}}}

%%{{{ cor: sum_of_binom_coefs 
\corollary.
%%%{{{ meta 
\label sum_of_binom_coefs
%%%}}}

Para todo $n\in\nats$,
$$
\Sum_{i=0}^n \binom n i
= \binom n 0 + \binom n 1 + \dotsb + \binom n {n-1} + \binom n n
= 2^n
$$

%%}}}

%%{{{ x: sum_of_all_binomial_coefficients 
\exercise.
%%%{{{ meta 
\label sum_of_all_binomial_coefficients
%%%}}}

Esqueça o corolário e demonstre que:
$$
\alignat 2
\Sum_{i=0}^n \binom n i
&= \binom n 0 + \binom n 1 + \binom n 2 + \dotsb + \binom n n
&&= 2^n\\
\Sum_{i=0}^n (-1)^i \binom n i
&=\binom n 0 - \binom n 1 + \binom n 2 - \dotsb + (-1)^n \binom n n
&&= 0
\endalignat
$$

\hint
Teorema binomial~\reftag[binomial_theorem].

\hint
Cada somatório é apenas um caso especial do teorema binomial.

\hint
Toma $x,y \asseq 1$ no teorema para resolver o primeiro.

\hint
Toma $x \asseq 1$ e $y \asseq -1$ para resolver o segundo.

%%}}}

\endsection
%%}}}

%%{{{ Pascal's triangle 
\section O triângulo de Pascal.
%%%{{{ meta 
%%%}}}

%%{{{ The first powers of the binomial 
\note As primeiras potências do binomial.
%%%{{{ meta 
%%%}}}

Calculamos:
$$
\align
(x+y)^0 &= 1\\
(x+y)^1 &= x   + y\\
(x+y)^2 &= x^2 + 2 xy    + y^2\\
(x+y)^3 &= x^3 + 3 x^2y  + 3 xy^2     + y^3\\
(x+y)^4 &= x^4 + 4 x^3y  + 6 x^2y^2   + 4xy^3      + y^4\\
(x+y)^5 &= x^5 + 5 x^4y  + 10 x^3y^2  + 10 x^2y^3  + 5 xy^4     + y^5\\
(x+y)^6 &= x^6 + 6 x^5y  + 15 x^4y^2  + 20 x^3y^3  + 15 x^2y^4  + 6 xy^5    + y^6\\
(x+y)^7 &= x^7 + 7 x^6y  + 21 x^5y^2  + 35 x^4y^3  + 35 x^3y^4  + 21 x^2y^5 + 7 xy^6    + y^7\\
(x+y)^8 &= x^8 + 8 x^7y  + 28 x^6y^2  + 56 x^5y^3  + 70 x^4y^4  + 56 x^3y^5 + 28 x^2y^6 + 8 xy^7 + y^8
\endalign
$$

%%}}}

%%{{{ pascal_triangle 
\note O triângulo de Pascal.
%%%{{{ meta 
\label pascal_triangle
\defines
    * triângulo!de Pascal
    ;;
%%%}}}

Tomando os coeficientes acima criamos o triângulo seguinte,
conhecido como \dterm{triângulo de Pascal}{\Pascal[triângulo]}:%
$$
\matrix
\format
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; &
\;\c\; \\
1\\
1&1\\
1&2&1\\
1&3&3&1\\
1&4&6&4&1\\
1&5&10&10&5&1\\
1&6&15&20&15&6&1\\
1&7&21&35&35&21&7&1\\
1&8&28&56&70&56&28&8&1\\
\;\vdots\;&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\ddots
\endmatrix
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observando o triângulo, percebemos que com umas exceções---quais?---cada
número é igual à soma de dois números \emph{na linha em cima}:
aquele que fica na mesma posição, e aquele que fica na posição anterior.
(Consideramos os ``espaços'' no triângulo como se fossem $0$'s.)

%%}}}

%%{{{ x: write this formally 
\exercise.
%%%{{{ meta 
%%%}}}

Escreva essa relação formalmente.

\hint
O $\binom a b$ está na linha $a$, na posição $b$
(começando contar com 0).

\solution
Temos as equações:
$$
\rightbrace {
\aligned
\binom 0 0          &= 1\\
\binom 0 r          &= 0\\
\binom n r          &= \binom {n-1} r + \binom {n-1} {r-1}
\endaligned
}
\quad
\text{equivalentemente}
\quad
\leftbrace {
\aligned
\binom 0     0      &= 1\\
\binom 0     {r+1}  &= 0\\
\binom {n+1} {r+1}  &= \binom n {r+1} + \binom n r.
\endaligned
}
$$

%%}}}

%%{{{ thm: combinations_recursive_equation 
\theorem.
%%%{{{ meta 
\label combinations_recursive_equation
%%%}}}

Para todos inteiros positivos $n$ e $r$ temos:
$$
\comb n r           = \comb {n-1} r + \comb {n-1} {r-1}.
$$

\sketch.
Lembramos que $\comb n r$ é o número das maneiras que podemos
escolher $r$ de $n$ objetos.
Fixe um dos $n$ objetos e o denote por $s$,
para agir como ``separador'':
separamos as maneiras de escolher em dois grupos:
aquelas que escolhem (entre outros) o $s$ e aquelas que não o escolhem.
Contamos cada colecção separadamente e somamos (princípio da adição)
para achar o resultado:
$$
\comb n r
= \underbrace{\comb {n-1} r}_{\text{escolhas sem $s$}}
+ \underbrace{\comb {n-1} {r-1}}_{\text{escolhas com $s$}}.
$$

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre o~\ref[combinations_recursive_equation] para todos os $n,r\in\nats$
com $0<r<n$, usando como definição do símbolo $\comb n r$ a
$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$

\hint
Demonstre diretamente usando apenas a definição de fatorial.

\solution
Sejam $r,n\in\nats$ com $0<r<n$.
Calculamos:
$$
\alignat 4
\intertext{$\comb n r = \comb {n-1} r + \comb {n-1} {r-1}$}
&\iff\quad& \frac {n!} {(n-r)!\stimes r!} &= \frac {(n-1)!} {(n-1-r)!\stimes r!}              &\!\!{}+{}\ & \frac {(n-1)!} {(n-1-(r-1))!\stimes (r-1)!} &\qquad&\qquad\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r-1)!\stimes r!}                  &\!\!{}+{}\ & \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r)!\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes\cancel{r!}} {(n-r-1)!\stimes \cancel{r!}} &\!\!{}+{}\ & \frac {(n-1)!\stimes\cancel{(n-r)!}\stimes r!} {\cancel{(n-r)!}\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)\!\cancel{\stimes!\stimes}} {\cancel{(n-r-1)!}}    &\!\!{}+{}\ & \frac {(n-1)!\stimes r\cancel{\stimes!\stimes}} {\cancel{(r-1)!}}\\
&\iff\quad& n! &= {(n-1)!\stimes(n-r)} &\!\!{}+{}\ & {(n-1)!\stimes r} \\
&\iff\quad& n! &= {(n-1)!\stimes((n-r) + r)}\\
&\iff\quad& n! &= {(n-1)!\stimes n}\\
&\iff\quad& n! &= n!
\endalignat
$$

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

\emph{Redefina} o símbolo $\comb n r$ para todo $n,r\in\nats$
recursivamente com
$$
\align
\comb 0 0          &= 1\\
\comb 0 r          &= 0\\
\comb n r          &= \comb {n-1} r + \comb {n-1} {r-1},
\endalign
$$
e demonstre que para todo $n,r\in\nats$,
$\comb n r = \dfrac {n!} {(n-r)!\stimes r!}$\,.

\hint
Indução.

%%}}}

\endsection
%%}}}

%%{{{ Counting recursively 
\section Contando recursivamente.
%%%{{{ meta 
%%%}}}

%%{{{ x: sequences_of_twos_and_threes 
\exercise.
%%%{{{ meta 
\label sequences_of_twos_and_threes
%%%}}}

Defina uma funcção $f : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada.
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $17$?

\hint
Recursão.

\hint
Separe as seqüências em dois grupos: aquelas que começam com 2, e aquelas que começam com 3.

\hint
Cuidado com a ``base'' $f(0)$.  Quantas seqüências de 2 e 3, somam em $0$?

\hint
Para calcular o valor de $f(17)$, \emph{não} use a definição recursiva ``top-down'',
mas ``bottom-up'': calcule os valores em seqüência linear
$f(0), f(1), f(2), \dotsc$ até o valor desejado.

%%}}}

%%{{{ x: sequences_of_twos_and_threes_restricted 
\exercise.
%%%{{{ meta 
\label sequences_of_twos_and_threes_restricted
%%%}}}

Defina uma funcção $g : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada, em quais aparecem os dois números (2 e 3).
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $18$?

\hint
Use a $f$ do~\ref[sequences_of_twos_and_threes].

\hint
Quando $g(n) \neq f(n)$?

\hint
Considere os casos:
(1) $n$ não pode ser escrito nem como $n = 2 + 2 + \dotsb + 2$, nem como $n = 3 + 3 + \dotsb + 3$;
(2) $n$ pode ser escrito como $n = 2 + 2 + \dotsb + 2$, e como $n = 3 + 3 + \dotsb + 3$ também;
(3) nenhum dos casos (1)--(2).

\hint
$
g(n) =
\knuthcases {
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}
}
$

%%}}}

%%{{{ x: infinite_city_1 
\exercise Dirigindo na cidade infinita (sem destino).
%%%{{{ meta 
\label infinite_city_1
%%%}}}

No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 3 opções:
virar esquerda; dirigir reto; virar direita.
No seu depósito tem $a$ unidades de combustível,
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
(Veja na figura, dois caminhos possíveis com $a=12$.)
\noi
\midinsert
\noi
\centerline{
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (0,1) -- (0,2) -- (-1,2) -- (-1,1) -- (-1,0) -- (-1,-1) -- (-2,-1) -- (-3,-1) -- (-3,0) -- (-3,1) -- (-2,1) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (1,0) -- (2,0) -- (3,0) -- (3,1) -- (3,2) -- (3,3) -- (3,4) -- (4,4) -- (4,3) -- (4,2) -- (3,2) -- (2,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
%
\endtikzpicture
%%}}}
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (-1.8,0) -- (-1.8,2);
\draw[rounded corners,line width=2mm,color=cyan!60] (0,0) -- (4,0) -- (4,2) -- (-3, 2) -- (-3,3) -- (-2,3) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (0,-1) -- (-2.1,-1) -- (-2.1,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
\node[circle,fill=gray!20] (DN)  at (-2,2) {$D$};
%
\endtikzpicture
%%}}}
\hfill
}
%\caption{Fig.~1}
\eop\centerline{Caminhos possíveis para os exercícios~\reftag[infinite_city_1] e~\reftag[infinite_city_2] respectivamente.}
%\endcaption
\endinsert

\hint
Sem recursão!

\hint
Em cada intersecção tem $3$ opções: $\mathtt L$, $\mathtt F$, $\mathtt R$.

\solution
Em cada das $a$ intersecções que ele encontra ele tem $3$ opções.
Logo, ele pode seguir $3^a$ caminhos diferentes dirigindo até seu combustível acabar.

%%}}}

%%{{{ x: infinite_mountain 
\exercise Dirigindo na montanha infinita.
%%%{{{ meta 
\label infinite_mountain
%%%}}}

No ``meio'' duma montanha de altura infinita, tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir subindo (gasta $4$ unidades de combutível);
dirigir descendo (gasta $1$);
dirigir na mesma altura clockwise (gasta $2$);
dirigir na mesma altura counter-clockwise (gasta $2$).
No seu depósito tem $a$ unidades de combistível.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
\ignore{
\midinsert
\tikzpicture[scale=2]
\axis[
hide axis,
domain=0:1,
y domain=0:-2*pi,
xmin=-1.5, xmax=1.5,
ymin=-1.5, ymax=1.5, zmin=-1.2, zmax=-1.2,
samples=10,
samples y=40,
z buffer=sort,
]
\addplot3[mesh,gray]
({1.1*x*cos(deg(y))},{1.1*x*sin(deg(y))},{-x});
\endaxis
\endtikzpicture
\endinsert
}

\hint
Recursão.

\hint
Seja $f(a)$ o número de caminhos diferentes que o motorista pode seguir com $a$ unidades de combustível.

\hint
Separa todos os caminhos possíveis em 3 grupos, dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

%%}}}

%%{{{ x: infinite_city_2 
\exercise Dirigindo na cidade infinita (com destino).
%%%{{{ meta 
\label infinite_city_2
%%%}}}

No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir na direção do norte; do leste; do sul; do oeste.
No seu depósito tem $c$ unidades de combustível
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até chegar no seu destino,
que fica numa distância $y$ unidades para norte e $x$ para leste?
Considere que números negativos representam descolamento para a direção oposta.
(Veja na figura onde o carro $C$ tem destino $D$, ou seja, seu descolamento
desejado é de $x=-2$, $y=2$.)

\hint
Recursão.

\hint
Seja $f(a,x,y)$ o número de caminhos diferentes que acabam com
descolamento total de $y$ unidades para norte e $x$ para leste,
para um motorista que tem $a$ unidades de combustível no seu carro.

\hint
Separa todos os caminhos possíveis em 4 grupos,
dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

%%}}}

\endsection
%%}}}

%%{{{ Solutions of equations in integers 
\section Soluções de equações em inteiros.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Combinations with repetitions 
\section Combinações com repetições.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The inclusion--exclusion principle 
\section O princípio da inclusão--exclusão.
%%%{{{ meta 
\label Inclusion_exclusion_principle
%%%}}}

%%{{{ x: 42_passengers_on_a_plane 
\exercise.
%%%{{{ meta 
\label 42_passengers_on_a_plane
%%%}}}

$42$ passangeiros estão viajando num avião.
\tlist:
\li: 11 deles não comem beef.
\li: 10 deles não comem peixe.
\li: 12 deles não comem frango.
\li: Os passangeiros que não comem nem beef nem frango são 6.
\li: O número de passangeiros que não comem nem beef nem peixe, é o mesmo com o número de passangeiros que não comem nem peixe nem frango.
\li: Os passangeiros que não comem nada disso são 3.
\li: Os passangeiros que comem tudo são 22.
\endtlist
Quantos são os passangeiros que não comem nem beef nem peixe?

%%}}}

\endsection
%%}}}

%%{{{ Elementary probability 
\section Probabilidade elementar.
%%%{{{ meta 
%%%}}}

%%{{{ x: russian_roulette 
\exercise Roleta russa.
%%%{{{ meta 
\label russian_roulette
%%%}}}

(Não tente isso em casa; vai acordar os vizinhos.)
No jogo da roleta russa, uma única bala é posicionada num
revolver de 6~balas e logo após o moinho é girado com força
em tal forma que a posição da bala é desconhecida e ``justa'',
ou seja, cada posição é igualmente provável de ter a bala.
A partir disso, o jogador 1 pega a arma e atira na sua própria cabeça.
Caso que sobreviveu, o jogador 2 faz a mesma coisa, e o jogo continua
assim alterando esse processo até um jogador acaba se matando.
Logo, a duração desse jogo é de 1 a 6 rodadas.
Supondo que ambos os jogadores querem viver, algum dos dois
tem vantagem?

%%}}}

%%{{{ x: russian_roulette_alt 
\exercise.
%%%{{{ meta 
\label russian_roulette_alt
%%%}}}

O que muda se os jogadores giram o moinho do revolver antes
de cada rodada e não apenas no começo do jogo?

%%}}}

\endsection
%%}}}

%%{{{ Derrangements 
\section Desarranjos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The pigeonhole principle 
\section O princípio da casa dos pombos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Generating functions and recurrence relations 
\section Funcções geradoras e relações de recorrência.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Uma turma de 28 alunos tem 12 mulheres e 16 homens.
\elist a:
\li:
De quantas maneiras podemos escolher 5 desses alunos,
para formar um time de basquete?
(Considere que as posições de basquete não importam).
\li:
De quantas maneiras podemos escolher 6 desses alunos,
para formar um time de volei, tal que o time tem pelo menos 4 homens?
(Considere que as posições de volei não importam).
\li:
De quantas maneiras podemos escolher 11 desses alunos,
para formar um time de futebol, tal que o time tem exatamente 3 mulheres,
e um homem goleiro?
(Considere que a única posição de futebol que importa é do goleiro.)
\li:
De quantas maneiras podemos escolher 3 times, um para cada esporte,
sem restricção de sexo?
\endelist

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Uma noite, depois do treino 3 times (uma de basquete, uma de vólei, e uma de
futebol), foram beber num bar que foi reservado para eles.
Como os jogadores de cada time querem sentar juntos,
o dono arrumou duas mesas cíclicas, uma com 5 e outra com 6 cadeiras, e 11 cadeiras no bar.
\eop
De quantas maneiras diferentes eles podem sentar?
(Considere que nas mesas cíclicas o que importa é apenas quem tá no lado de quem, mas no bar o que importa é a posição da cadeira mesmo.)

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Considere os inteiros $1,2,\dotsc, 30$.
Quantas das suas $30!$ permutações totais têm a propriedade que
não aparecem múltiplos de $3$ consecutivamente?

\hint
Construa cada configuração em passos e use o princípio da multiplicação.

\hint
Coloque os não-múltiplos de 3 primeiramente numa ordem, deixando espaços entre-si
para os múltiplos de 3.

\hint
Escolhe 10 dos 21 lugares possíveis para colocar os múltiplos de 3.

\solution
Primeiramente vamos esquecer os múltiplos de 3.
O resto dos (20) números pode ser permutado de
$20!$ maneiras.
Para qualquer dessa maneira, temos $\comb {21} {10}$
opções para escolher em quais $10$ das $20+1$ possíveis posições vamos colocar os múltiplos de 3,
e para cada escolha, correspondem $10!$ diferentes permutações dos múltiplos de 3 nessas $10$ posições.
Finalmente,
$$
\underbrace{\phantom(20!\phantom)}_{\text{ordena os não-múltiplos}}\ntimes \underbrace{\comb {21} {10}}_{\text{escolhe as posições dos múltiplos}}\ntimes \underbrace{\phantom(10!\phantom)}_{\text{escolhe a ordem dos múltiplos}}
$$
das $30!$ permutações têm a propriedade desejada.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Numa turma de $28$ alunos
precisamos formar duas comissões de $5$ e $6$ membros.
Cada comição tem seu presidente, seu vice-presidente, e seus membros normais.
De quantas maneiras podemos formar essas comissões\dots
\elist a:
\li: \dots sem restricções (cada um aluno pode participar nas duas comissões simultaneamente)?
\li: \dots se nenhum aluno pode participar simultaneamente nas duas comissões?
\li: \dots se os dois (únicos) irmãos entre os alunos não podem participar na mesma comissão,
e cada aluno pode participar simultaneamente nas duas?
\endelist

%%}}}

%%{{{ prob: {abc}* without ab 
\problem.
%%%{{{ meta 
\pdefs
    \pdef a {{\mathtt a}}
    \pdef b {{\mathtt b}}
    \pdef c {{\mathtt c}}
    ;;
%%%}}}

Do alfabeto $\set{\a,\b,\c}$ desejamos formar strings de tamanho $\ell$
onde não aparece o substring $\a\b$.
Em quantas maneiras podemos fazer isso?

%%}}}

%%{{{ prob: domino 2×n 
\problem.
%%%{{{ meta 
%%%}}}

Conte em quantas maneiras podemos cobrir um tabuleiro de dimensão
$2\times n$ com peças-dominô (ou seja, peças de dimensão $2\times 1$).

\hint
Recursão.

\hint
O quadradinho na posição $(1,1)$ pode ser coberto em apenas duas maneiras:
(A) por uma peça ocupando as posições $(1,1)$--$(1,2)$;
(B) por uma peça ocupando as posições $(1,1)$--$(2,1)$.

\solution
Seja $f(n)$ a quantidade de maneiras que podemos cobrir
um tabuleiro de tamanho $2 \times n$.
Começamos observando que para um tabuleiro $2 \times 0$
temos exatamente uma maneira de cobrir todos os quadradinhos:
fazendo nada.
Vamos pular outros casos específicos e voltar caso que precisar.
O quadradinho na posição $(1,1)$ pode ser coberto em apenas duas maneiras:
(A) por uma peça ocupando as posições $(1,1)$--$(2,1)$;
(B) por uma peça ocupando as posições $(1,1)$--$(1,2)$.
No caso (A), para cobrir o resto que é um tabuleiro
de $2 \times (n-1)$, temos $f(n-1)$ maneiras.
No caso (B), observe que tendo a peça cobrindo os $(1,1)$--$(1,2)$,
o quadradinho $(2,1)$ só pode ser coberto por uma peça no $(2,1)$--$(2,2)$.
Agora basta cobrir o resto que é um tabuleiro de $2 \times (n-2)$,
e logo temos $f(n-2)$ maneiras de fazer isso.
Agora percebemos que precisamos mais uma base (por causa do $n-2$).
Obviamente para cobrir um tabuleiro de tamanho $2 \times 1$ temos
exatamente uma maneira.
Temos então:
\mathcol
f(0) &= 1 \\
f(1) &= 1 \\
f(n) &= \tubrace {f(n-1)} {(A)} + \tubrace {f(n-2)} {(B)}.
\endmathcol

%%}}}

%%{{{ prob: nikos 
\problem.
%%%{{{ meta 
\label nikos
%%%}}}

Na figura abaixo temos um mapa (as linhas correspondem em ruas).
Nikos quer caminhar do ponto $A$ para o ponto $B$, \emph{o mais rápido possível}.
\elist:
\li: De quantas maneiras ele pode chegar?
\li: Se ele precisa passar pelo ponto $S$?
\li: Se ele precisa passar pelo ponto $S$ mas quer evitar o ponto $N$?
\endelist
\midinsert
\noi
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=red!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (5,4) -- (5,5) -- (7,5) -- (7,7) -- (8,7) -- (8,8) -- (9,8);
\node[circle,fill=gray!20] (SW)  at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20] (NE)  at (9.3,8.3) {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\eop\centerline{Um caminho aceitável e um inaceitável no caso (3) do \ref[nikos].}
\endinsert

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Num jogo de lotéria, tem os números de $1$ até $60$:
$$
\matrix
    01&02& 03 &04 &05 &06 &07 &08 &09 &10\\
    11&12& 13 &14 &15 &16 &17 &18 &19 &20\\
    21&22& 23 &24 &25 &26 &27 &28 &29 &30\\
    31&32& 33 &34 &35 &36 &37 &38 &39 &40\\
    41&42& 43 &44 &45 &46 &47 &48 &49 &50\\
    51&52& 53 &54 &55 &56 &57 &58 &59 &60
\endmatrix
$$
Os organizadores do jogo, escolhem aleatoriamente 6 números
deles (sem repetições).
Esses 6 números são chamados ``a megasena''.
Um jogador marca pelo menos 6 números na sua
lotéria e se conseguir ter marcados todos os 6 da megasena, ganha.

(Marcando mais que 6 números,
as chances do jogador aumentam, mas o preço da lotéria aumenta também.)

(1)
Um jogador marcou $6$ números.
Qual a probabilidade que ele ganhe?

(2)
Uma jogadora marcou $9$ números.
Qual a probabilidade que ela ganhe?

(3)
Generalize para um jogo com $N$ números, onde $w$ deles são escolhidos,
e com um jogador que marcou $m$ números, sendo $w\leq m \leq N$.

\solution
(1)
Apenas uma escolha é a certa, então a probabilidade de ganhar é:
    $$
    \dfrac 1 {\comb {60} 6}
    = \dfrac{6!\stimes 54!} {60!}
    = \dfrac {6!} {55 \ntimes 56 \ntimes 57 \ntimes 58 \ntimes 59 \ntimes 60}
    = \dfrac {1} {11\ntimes 14\ntimes 19\ntimes 29\ntimes 59\ntimes 10}
    = \dfrac 1 {50063860}\,.
    $$
(2)
Para ganhar, com certeza acertamos nos 6 números da megasena,
então temos que contar todas as maneiras de escolher os 3 outros números dos 9 que escolhemos:
    $$
    \dfrac {\comb {60-6} {9-6}} {\comb {60} 9}
    = \dfrac {\comb {54} 3} {\comb {60} 9}
    = \dfrac {54!\stimes \cancel{51!}\stimes 9!} {\cancel{51!} \stimes 3!\stimes 60!}
    = \dfrac {4\ntimes 5 \ntimes 6 \ntimes 7 \ntimes 8 \ntimes 9} {55\ntimes 56\ntimes 57\ntimes 58\ntimes 59 \ntimes 60}
    = \dfrac 3 {1787995}\,.
    $$
(3)
Generalizando a solução do (2), a probabilidade é
$$
\align
\frac
{\comb {N-w} {m-w}}
{\comb N m}
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N-w)-(m-w))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N\cancel{{}-{}w}-m\cancel{{}+w}))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes \cancel{(N-m)!} \stimes m!}
{\cancel{(N-m)!} \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes m!}
{(m-w)! \stimes N!}\\
&=
\Prod_{i=0}^{w-1}
\frac
{m-i}
{N-i}\,.
\endalign
$$

%%}}}

%%{{{ prob: aleco_bego 
\problem.
%%%{{{ meta 
\label aleco_bego
%%%}}}

Aleco e Bego são dois sapos.
Eles estão na frente de uma escada com 11 degraus.
No 6o degrau, tem Cátia, uma cobra, com fome.
Aleco pula 1 ou 2 degraus para cima.
Bego, 1, 2 ou 3.  E ele é tóxico: se Cátia comê-lo, ela morre na hora.
\midinsert
% TODO: this should be on a separate file
\tikzpicture[scale=0.666]%%{{{
%
\node[star,star points=17,fill=red!30,inner sep=3pt]    (boom) at (6.75,6.25) {\phantom{\niness C}};
\node[                                             ]    (catia) at (6.666,6.333) {{\niness C}};
\node[circle,fill=green!40]  (aleco) at (-0.333,0.5) {{\niness A}};
\node[circle,fill=blue!30]   (bego)  at (-1.75,0.5) {{\niness B}};
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=70] (2.333,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=66] (1.666,1);
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=60] (1.333,1);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=62] (2.666,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=60] (3.5,3);
\foreach \i in {1,2,3,4,5,6,7,8,9,10,11} {
  \path[fill=gray!10]
    (\i,\i) -- (\i,\i-1) -- (15,\i-1) -- (15,\i) -- (\i,\i);
  \node[circle,fill=black,inner sep=0pt] (b\i) at (\i,\i)   {};
  \node[circle,fill=black,inner sep=0pt] (e\i) at (\i+1,\i) {};
  \node[circle,fill=black,inner sep=0pt] (d\i) at (\i,\i-1) {};
  \node[                  inner sep=0pt] (s\i) at (\i+0.5,\i) {};
  \draw [-,line width=0.2mm] (b\i) -- (e\i);
  \draw [-,line width=0.2mm] (b\i) -- (d\i);
  \node[                  inner sep=0pt] (t\i) at (\i+0.5,\i-0.3) {\i};
}
\draw [-] (-3,0) -- (1,0);
\draw [-] (12,11) -- (15,11);
%\foreach \j in {0,1,2,3,4,5,6,7,8}
%  \draw [-] (0,\j) -- (9,\j);
%  \draw [line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
%\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
%\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
%\node[circle,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
%\node[circle,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
%\caption{Fig.~2}
\eop\centerline{Os dois sapos do~\ref[aleco_bego] e suas possibilidades para começar.}
%\endcaption
\endinsert
\tlist:
\li (1): Por enquanto, Cátia está dormindo profundamente.
         \tlist:
         \li a.:  De quantas maneiras Aleco pode subir a escada toda?
         \li b.:  De quantas maneiras Bego pode subir a escada toda?
         \endtlist
\li (2): Cátia acordou!
         \tlist:
         \li a.:  De quantas maneiras Aleco pode subir a escada toda?
         \li b.:  De quantas maneiras Bego pode subir a escada toda?
         \endtlist
\li (3): Bego começou subir a escada\dots{}
         Qual é a probabilidade que Cátia morra?
         (Considere que antes de começar, ele já decidiu seus
         saltos e não tem percebido a existência da cobra.)
\ignore{% TODO
\li (4): O que muda na questão (3) se ao invés de decidir seu caminho desde o
         início, Bega decida cada vez aleatoriamente (com probabilidades iguais)
         qual dos 3 possíveis saltos ele vai fazer?
\li (5): Generalize o problema (4)~para o caso onde a escada
         tem uma infinidade de degraus e Cátia fica no degrau $k$.
}
\endtlist

\hint
Recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.

\hint
Grupe as maneiras em colecções (para aplicar o princípio da adição),
olhando para o primeiro salto.

\solution
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.
Cada maneira do Aleco pode começar com 2 jeitos diferentes:
salto de 1 degrau, ou salto de 2 degraus.
Cada maneira do Bego pode começar com 3 jeitos diferentes:
salto de 1, de 2, ou de 3 degraus.
Observe que, por exemplo, se Bego começar com um pulo de 2
degraus, falta subir uma escada de $n-2$ degraus.
Pelo princípio da adição então, temos as equações recursivas:
$$
\xalignat 2
a(n) &= a(n-1) + a(n-2)                & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\intertext{válidas para $n\geq 2$ e $n \geq 3$ respectivamente.
Devemos definir os casos básicos de cada funcção recursiva:
$n=0,1$ para a $a(n)$, e $n=0,1,2$ para a $b(n)$:}
     &                                 & b(0) &= 1\qquad\explanation{fica} \\
a(0) &= 1 \qquad\explanation{fica}     & b(1) &= 1\qquad\explanation{pula $1$} \\
a(1) &= 1 \qquad\explanation{pula $1$} & b(2) &= 2\qquad\explanation{pula $1+1$; ou pula $2$} \\
a(n) &= a(n-1) +  a(n-2)               & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\endxalignat
$$
Calculamos os 11 primeiros valores:
$$
\matrix
a:\quad& \overbrace {1}^{a(0)}, & 1, & 2, & 3, & 5, & \phantom08,  & 13, & 21, & 34, & \phantom055,  & \phantom089,  & \overbrace {144}^{a(11)}, &\dotsc\\
b:\quad& \underbrace{1}_{b(0)}, & 1, & 2, & 4, & 7, & 13,          & 24, & 44, & 81, & 149, & 274, & \underbrace{504}_{b(11)}, &\dotsc
\endmatrix
$$
Agora temos tudo que precisamos para responder facilmente nas questões do problema.
\eop
{(1)}  Precisamos apenas os valores $a(11)$ e $b(11)$:
{(1a)} De $a(11) = 144$ maneiras.
{(1b)} De $b(11) = 504$ maneiras.
\eop
{(2)} Usamos ``$n\to m$'' para ``pula diretamente do degrau $n$ para o degrau $m$'' e ``$n\transto m$'' para ``vai do degrau $n$ para o degrau $m$ pulando num jeito''.
{(2a)} Para conseguir subir, Aleco necessariamente precisa chegar no degrau 5, saltar até o degrau 7, e depois continuar até o degrau 11.  Formamos cada maneira então em passos, e usando o princípio da multiplicação achamos que Aleco tem
$$
\underbrace{a(5)}_{0 \transto 5} \ntimes
\underbrace{\phantom(1\phantom)}_{5 \to 7} \ntimes
\underbrace{a(4)}_{7 \transto 11}
=
8 \ntimes 1 \ntimes 5
= 40
$$
maneiras de subir a escada toda.
{(2b)}
Para o Bego a situação não é tão simples, porque ele pode evitar a cobra de vários jeitos.
Vamos agrupá-los assim:
\tlist:
\li (i):   aqueles onde ele pulou a cobra com salto de tamanho 2;
\li (ii):  aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 5;
\li (iii): aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 4.
\endtlist
Contamos as maneiras em cada grupo como na questão anterior, e no final as somamos (princípio da adição) para achar a resposta final: Bego tem
$$
\tobrace {
\mubrace {b(5)} {0 \transto 5} \ntimes
\mubrace {\phantom(1\phantom)} {5 \to 7} \ntimes
\mubrace {b(4)} {7 \transto 11}
} {grupo (i)}
+
\tobrace {
\mubrace {b(5)} {0 \transto 5} \ntimes
\mubrace {\phantom(1\phantom)} {5 \to 8} \ntimes
\mubrace {b(3)} {8 \transto 11}
} {grupo (ii)}
+
\tobrace {
\mubrace {b(4)} {0 \transto 4} \ntimes
\mubrace {\phantom(1\phantom)} {4 \to 7} \ntimes
\mubrace {b(4)} {7 \transto 11}
} {grupo (iii)}
=
13 \ntimes 7 +
13 \ntimes 4 +
7 \ntimes 7
=
192
$$
maneiras de subir a escada toda.
\eop
{(3)}
Pela definição, a probabilidade que Cátia morra é a fracção
$$
\frac
{\text{todas as maneiras em quais Bego pisou no degrau 6}}
{\text{todas as maneiras possíveis}}\,,
$$
ou seja,
$$
\frac {504-192} {504}
= \frac {312} {504}
= \frac {156} {252}
= \frac {78} {126}
= \frac {39} {63}
= \frac {13} {21}
\,.
$$

%%}}}

%%{{{ prob: band_maker 
\problem.
%%%{{{ meta 
\label band_maker
%%%}}}

Temos $6$ músicos disponíveis, onde cada um toca:
\medskip
\halign{
\hfil## & ##\hfil &\quad \hfil## & ##\hfil\cr
Alex:       &violão, guitarra, baixo& Daniel:     &guitarra\cr
Bill:       &bateria                & Eduardo:    &piano, teclado, violão, fláuto\cr
Claudia:    &saxofone, clarineto    & Fagner:     &guitarra, baixo, teclado\cr
}
\medskip
\noi
(Considere que uma banda precisa \emph{pelo menos um membro},
todos os membros duma banda \emph{precisam tocar pelo menos algo na banda},
e que cada banda é diferenciada pelos músicos e
suas funcções.
Por exemplo: uma bande onde Alex toca o violão (apenas) e Bill a bateria,
é diferente duma banda onde
Alex toca o violão \emph{e} a guitarra, e Bill a bateria,
mesmo que seus membros podem ser os mesmos.
\tlist:
\li (1):
Quantas bandas diferentes podemos formar?
\li (2):
Quantas bandas diferentes podemos formar com a restricção que nenhum
músico tocará mais que um instrumento na banda (mesmo se em geral sabe tocar mais)?
\li (3):
Quantas bandas diferentes podemos formar onde todos os
músicos fazem parte da banda?
\endtlist

\solution
\proofpart{(1):}
$2^{14}-1$: para cada músico e cada instrumento, temos 2 opções: ``sim'' ou ``não''.
Tiramos $1$ porque hipercontamos (a ``banda vazia'').
\crproofpart{(2):}
Cada músico que toca $i$ instrumentos tem $i+1$ opções
(a extra $+1$ corresponde no ``não participar na banda''):
podemos formar $4 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 5 \ntimes 4 - 1$ bandas,
onde de novo tiramos 1 para excluir a ``banda vazia''.
\crproofpart{(3):}
Cada músico que toca $i$ instrumentos tem $2^i - 1$ opções
(tirando a opção de ``não tocar nada'').
Então podemos formar $7\ntimes 1 \ntimes 3 \ntimes 1 \ntimes 15 \ntimes 7$ bandas.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string ternário
(usando o alfabeto $\set{0, 1, 2}$)
de tamanho 7,
tais que \emph{não aparece neles o substring $00$}.
\eop
Por exemplo:
$$
\align
0112220                                           &\qquad\text{é um string aceitável;}\\
2\underline{00}1\underline{0\overline0}\overline0 &\qquad\text{não é.}
\endalign
$$

\hint
Recursão.

\hint
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.

\hint
Defina a $a(n)$ e depois calcule o $a(7)$, calculando em ordem os
$a(0),a(1),\dotsc,a(7)$.

\solution
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.
Queremos achar o $a(7)$.
\eop
Observe que:
$$
\align
    a(0) &= 1 \qqqquad\explanation{o string vazio: ``$\,$''} \\
    a(1) &= 3 \qqqquad\explanation{os strings: ``$0$'', ``$1$'', e ``$2$''} \\
    a(n) &=
      \underbrace{a(n-1)}_{1\ldots}
    + \underbrace{a(n-1)}_{2\ldots}
    + \underbrace{a(n-2)}_{{01}\ldots}
    + \underbrace{a(n-2)}_{{02}\ldots}\\
         &= 2a(n-1) + 2a(n-2)\\
         &= 2(a(n-1) + a(n-2))
\endalign
$$
Então calculamos os primeiros $8$ termos da seqüência:
$$
1,\quad 3,\quad 8,\quad 22,\quad 60,\quad 164,\quad 448,\quad \underbrace{1224}_{a(7)}.
$$

%%}}}

%%{{{ prob: pessimissimo 
\problem.
%%%{{{ meta 
\label pessimissimo
%%%}}}

Contar todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}
$$
onde\dots
% TODO: fix reflabs
\tlist:
\li (1): a palavra começa com $\txt P$;
\li (2): todos os $\txt I$ aparecem \emph{juntos}\/;
\li (3): os $\txt M$ aparecem \emph{separados}\/;
\li (4): nenhum dos $\txt S$ aparece ao lado de outro $\txt S$.
\endtlist

\hint
Para o (4), seria diferente se a restricção fosse
``os $\txt S$ não aparecem todos juntos''.

\solution
(1):
Como somos obrigados começar a palavra com ${\txt P}$,
precisamos apenas contar as permutações das letras da palavra
$
\txt{ESSIMISSIMO}
$,
que sabemos que são
$$
\frac
{11!}
{4!\stimes3!\stimes 2!}.
$$
\eop\medskip\noi
(2):
Podemos considerar que temos apenas um $I$:
$
\dfrac
 {10!}
 {4!\stimes  2!}
$
\eop\medskip\noi
(3):
Contamos em quantas palavras eles aparecem juntos,
e usando princípio da adição, os subtraimos das permutações sem restricção.
$$
\underbrace{
\,
\dfrac
 {12!}
 {4!\stimes  3!\stimes  2!}
\,
}_{\text{todas}}
 -
\underbrace{
\,
\dfrac
 {11!}
 {4!\stimes  3!}
\,
}_{\text{$\txt M$ juntos}}
$$
\eop\medskip\noi
(4):
Construimos cada dessas palavras em passos.
Primeiramente escolhemos uma das permutações da palavra sem os ${\txt M}$'s:
$$
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}
$$
(temos 
$
\dfrac
{8!}
{3!\stimes 2!}
$
opções).
\eop
\medskip
No próximo passo escolemos em qual das $9$ posições possíves colocamos os $M$:
$$
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}
$$
Pelo princípio da multiplicação então, temos
$
\dfrac
{8!}
{3!\stimes 2!}
\cdot
\comb 9 4
$
palavras que satisfazem essa restricção.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
% TODO: fix reflabs
%%%}}}

De quantas maneiras podemos escrever um string usando o alfabeto
de 26 letras
$$
\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z,
$$
tais que as vogais aparecem na ordem estrita alfabética, e as consoantes na órdem oposta?
(As vogais sendo as letras $\txt A$, $\txt E$, $\txt I$, $\txt O$, $\txt U$, $\txt Y$.)
{Por exemplo:}
$$
\align
\txt{TEDUCY}    &\qquad\text{é um string aceitável};\\
\txt{DETUCY}    &\qquad\text{não é ($\txt D \not> \txt T$)};\\
\txt{TEDUCA}    &\qquad\text{não é ($\txt U \not< \txt A$)}.
\endalign
$$
\tlist:
\li (1): \dots se os strings são de tamanho 26 e os vogais aparecem todos juntos;
\li (2): \dots se os strings são de tamanho 12 e aparecem todos os vogais;
\li (3): \dots se os strings são de tamanho 3;
\li (4): \dots se os strings são de tamanho $\ell$, com $0\leq\ell\leq 26$.
\endtlist

\solution
(1)
Como a ordem das consoantes e das vogais é predeterminada e as vogais devem aparecer juntas,
a única escolha que precisamos fazer é onde colocar as vogais, e temos $21$ possíveis posições.
Então existem $21$ tais strings.
\eop\medskip\noi
(2)
$$
\underbrace{\comb {20} 6}_{\text{\eightrm consoantes}},
\underbrace{\comb {12} 6}_{\text{\eightrm suas posições}}.
$$
\eop\medskip\noi
(3)
Separamos todos os strings que queremos contar em quatro grupos e contamos cada um separadamente:
$$
{
\overbrace{
\underbrace{\comb {20} 3}_{\text{as c.}}
}^{\text{3 c., 0 v.}}
}
+
{
\overbrace{
\underbrace{\comb {20} 2}_{\text{as c.}}
\underbrace{\comb 6 1}_{\text{a v.}}
\underbrace{\comb 3 2}_{\text{pos.~c.}}
}^{\text{2 c., 1 v.}}
}
+
\overbrace{
\underbrace{\comb {20} 1}_{\text{a c.}}
\underbrace{\comb 6 2}_{\text{as v.}}
\underbrace{\comb 3 1}_{\text{pos.~c.}}
}^{\text{1 c., 2 v.}}
+
\overbrace{
\underbrace{\comb 6 3}_{\text{as v.}}
}^{\text{0 c., 3 v.}}.
$$
Podemos descrever o resultado numa forma mais uniforme e mais fácil para generalizar:
$$
\Sum_{i=0}^3
\tubrace{\comb {20} {3-i}} {as $3-i$ c.}
\tubrace{\comb 6 i} {as $i$ v.}
\tubrace{\comb 3 i} {pos.~v.}
=
\Sum\submath{c+v=3\\c,v\in\nats}
\tubrace{\comb {20} c} {as c.}
\tubrace{\comb 6 v} {as v.}
\tubrace{\comb 3 v} {pos.~v.}
$$
\eop\medskip\noi
(4)
Seguindo a última forma do (3), temos
$$
\Sum_{i=0}^{\ell}
\tubrace{\comb {20} {\ell-i}} {as $\ell-i$ c.}
\tubrace{\comb 6 i} {as $i$ v.}
\tubrace{\comb {\ell} i} {pos.~v.}
$$
maneiras.  O somatório pode ser escrito também assim:
$$
\Sum
\bigg\{
\tubrace{\comb {20} c} {as c.}
\tubrace{\comb 6 v} {as v.}
\tubrace{\comb {\ell} v} {pos.~v.}
\ \Big|\ 
c+v=\ell, \ 0\leq c \leq 20, \ 0\leq v \leq 6, \ c,v\in\nats
\bigg\}.
$$
Note que como o conjunto acima é finito,
a adição é comutativa e associativa; logo, nosso somatório é bem-definido.

%%}}}

%%{{{ prob: roulette_multiple_balls 
\problem.
%%%{{{ meta 
\label roulette_multiple_balls
%%%}}}

Numa roleta dum cassino tem ``pockets'' (ou ``casas'') numerados com:
$$
00, 0, 1, 2, \dotsc, 36
$$
e cada um deles é suficientemente profundo para caber até 8 bolinhas.
O crupiê joga 8 bolinas na roleta no mesmo tempo.
De quantas maneiras elas podem cair nos pockets se\dots
\tlist:
\li (i):  \dots as bolinhas são distintas e não importa sua ordem dentro um pocket.
\li (ii): \dots as bolinhas são todas iguais.
\endtlist

\solution
\tlist:
\li (i):  Permutações com repetições: $38^8$.
\li (ii): Combinações com repetições: $\comb {38 + 8 - 1} 8 = \comb {45} 8$.
\endtlist

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string usando
letras do alfabeto $\set{\txt A, \txt B, \txt C, \txt D}$,
tais que \emph{cada letra é usada exatamente duas vezes
mas não aparece consecutivamente no string}?
Por exemplo:
$$
\align
\txt{ABADCDBC}                      &\qquad\text{é um string aceitável;}\\
\txt{ABAC$\underline{\txt{DD}}$BC}  &\qquad\text{não é.}
\endalign
$$

\hint
Inclusão--exclusão.

\hint
Considere as propriedades:
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$

\solution
Seja $N$ o número de permutações totais das létras
e defina as 4 propriedades
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$
Procuramos o número dos strings de tamanho 8 que não tenham nenhuma dessas 4 propriedades.
Assim que calcular os $N(\alpha),\dotsc,N(\alpha,\beta,\gamma,\delta)$
o princípio da inclusão--exclusão, vai nos dar o número que procuramos.
\eop
Observamos que
$$
\gather
N(\alpha) =N(\beta) =N(\gamma) =N(\delta)\\
N(\alpha,\beta) =N(\alpha,\gamma) = \dotsb = N(\gamma,\delta)\\
N(\alpha,\beta,\gamma) = \dotsb = N(\beta,\gamma,\delta).
\endgather
$$
\eop
Calculamos os
$$
\align
N
&= \frac {8!} {2!\stimes 2!\stimes 2!\stimes 2!} = 2520\\
N(\alpha)
&= \frac {7!} {2!\stimes 2!\stimes 2!} = \frac {7!} 8 = 7\ntimes 6 \ntimes 5 \ntimes 3 = 630\\
N(\alpha,\beta)
&= \frac {6!} {2!\stimes 2!} = \frac {6!} 4 = 180 \\
N(\alpha,\beta,\gamma)
&= \frac {5!} {2!} = \frac {5!} 2 = 60 \\
N(\alpha,\beta,\gamma,\delta)
&= {4!} = 24.
\endalign
$$
\eop
Para responder, temos
$$
\multline
    N
    - \comb 4 1 N(\alpha)
    + \comb 4 2 N(\alpha,\beta)
    - \comb 4 3 N(\alpha,\beta,\gamma)
    + N(\alpha,\beta,\gamma,\delta)\\
    =
    2520 - 4\ntimes 630 + 6\ntimes 180 - 4\ntimes 60 + 24
    =
    864
\endmultline
$$
tais permutações.

%%}}}

%%{{{ prob: parity_respecting_strings_mutual_recursion 
\problem.
%%%{{{ meta 
\label parity_respecting_strings_mutual_recursion
%%%}}}

De quantas maneiras podemos escrever um string binário
(usando o alfabeto $\set{0, 1}$) de tamanho 12,
tais que: 
\elist i:
\li: os $0$'s aparecem apenas em grupos maximais de tamanho par;
\li: os $1$'s aparecem apenas em grupos maximais de tamanho ímpar.
\endelist
Por exemplo:
$$
\align
{000000111001}                         &\qquad\text{é um string aceitável;}\\
{100\underline{11}001\underline{000}1} &\qquad\text{não é.}
\endalign
$$

\hint
Separe os strings em dois grupos,
aqueles que terminam em $0$ e aqueles que terminam em $1$,
e conta os strings de cada grupo usando recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de strings binários de tamánho $n$
que terminam em $0$ e em $1$ respectivamente.

%%}}}

%%{{{ prob: xyzzy_lemmings 
\problem.
%%%{{{ meta 
\label xyzzy_lemmings
\pdefs
    \pdef FB {{\mathtt F}}
    \pdef MM {{\mathtt M}}
    \pdef ST {{\mathtt B}}
    ;;
%%%}}}

Xÿźźÿ o Mago Bravo decidiu matar todos os lemmings que ele guarda no seu quintal.
Seus feitiços são os:
\tlist:
\li: ``magic missile'', que mata 2 lemmings simultaneamente, e gasta 1 ponto ``mana'';
\li: ``fireball'', que mata 3 lemmings simultaneamente, e gasta 2 pontos mana.
\endtlist
Além dos feitiços, Xÿźźÿ pode usar seu bastão para matar
os lemmings (que não custa nada, e mata 1 lemming com cada batida).
\eop
Suponha que o mago \emph{nunca} lançará um feitiço que mataria mais lemmings do
que tem (ou seu quintal vai se queimar).
Ele tem $m$ pontos mana e existem $n$ lemmings no seu quintal.
Em quantas maneiras diferentes ele pode destruir todos os lemmings se\dots
\elist i:
\li: os lemmings são indistinguíveis?
\li: os lemmings são distinguíveis?
\li: os lemmings são distinguíveis e cada vez que Xÿźźÿ mata um usando seu bastão,
ele \emph{ganha} um ponto de mana?
\endelist
(Para os casos que os lemmings são distinguíveis,
o mago escolhe também \emph{quais} dos lemmings ele matará cada vez.)

\hint
Recursão.

\hint
Seja $f(m,n)$ o número de maneiras que Xÿźźÿ pode matar todos os $n$ lemmings,
começando com $m$ pontos de mana.

%%}}}

\endproblems
%%}}}

%%{{{ History 
\history.

Pascal não foi o primeiro de estudar o ``triângulo aritmético'',
cuja existência e sua relação com o teorema binomial já eram
conhecidas desde uns séculos antes do seu nascimento.
Mesmo assim, seu estudo
\emph{``Traité du triangle arithmétique,
avec quelques autres petits traitez
sur la mesme matière''},
publicado no ano \yearof{1654} (depois da sua morte)
popularizou o triângulo e suas diversas aplicações e
propriedades~(\cite[pascaltriangle]).

\endhistory
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[nivencount].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The_integers 
\chapter Os inteiros.
%%%{{{ meta 
\label The_integers
%%%}}}

\TODO limpar, terminar, organizar.

%%{{{ intro 
\chapintro
Faremos aqui nossos primeiros passos na \dterm{teoria dos números}.
Estudamos os inteiros e sua teoria: encontramos e demonstramos os primeiros
teoremas realmente lindos e interessantes.
Terminamos com umas aplicações dessa teoria na área de
criptografia; algo que deixaria muitos matemáticos do passado
surpresos (e talvez frustrados):
como uma coisa tão \emph{pura}
acaba sendo aplicada em algo tão\dots aplicado!\foot
Oi, {\Hardy}G.~H.~Hardy!
\toof
%%}}}

%%{{{ The integers 
\section Os inteiros.
%%%{{{ meta 
%%%}}}

%%{{{ What I assume the reader knows and accepts 
\note.
%%%{{{ meta 
%%%}}}

Neste capítulo vou supor que o leitor aceita e já conhece
os (números) inteiros:
$$
\dotsc, \quad -3, \quad -2, \quad -1, \quad 0, \quad 1,\quad  2, \quad 3,\quad \dotsc
$$
Não questiona sua existência---qualquer coisa que isso pode significar---nem
questiona as propriedades que aprendeu---corretamente, eu espero---enquanto
criança.
Aqui não vamos \emph{definir} então \emph{o que é} um inteiro.
Caso que isso pareceu óbvio pra ti, segure tua reação
até o~\ref[Axiomatic_set_theory] onde vamos fazer exatamente isso:
construir mesmo os inteiros!
Os inteiros chegam junto com duas operações bem conhecidas:
a adição ($+$) e a multiplicação ($\ntimes$)
que tu já conheces.
Também conheces---sem questionar?---que
ambas são associativas, ambas possuem identidade (também
conhecida como ``elemento neutro''), ambas são comutativas,
cada inteiro $x$ tem um oposto que denotamos por $-x$,
se não é $0$ também tem um inverso que denotamos por $x^{-1}$ (ou $1/x$),
a multiplicação distribua-se sobre a adição, etc.~etc.!\foot
acabei assumindo que tu conheces certas palavras também (associativa, comutativa, etc.)~mas
isso não é essencial: se tu encontrou alguma palavra desconhecida (ou esquecida), se preocupe não; continue
\toof
Além dessas duas \emph{operações},
nos inteiros temos uma \emph{relação de ordem} cujas propriedades também aceitas.
Conheces, por exemplo, que para quaisquer inteiros $x,y$ tais que
$x \leq y$, temos $-y \leq -x$, e também $x - y \leq 0$, muitas mais
coisas.
Caso que tudo isso pareceu estranho pra ti,
especialmente a questão sobre o que aceitar e o que não,
paciência até o~\ref[Algebraic_structures].
Eu não vou supor conhecimento sobre outras operações, e sugiro esquecê-lo
desde já, pois pode acabar te confundindo.
Tradicionalmente denotamos o conjunto dos inteiros por $\ints$.\foot
\emph{Zahl} em alemão significa número.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Factorization 
\section Fatorização.
%%%{{{ meta 
%%%}}}

%%{{{ Q: given a positive integer n, how can we break it to construction blocks? 
\question.
%%%{{{ meta 
%%%}}}

Dado um inteiro positivo $n$, como podemos ``quebrá-lo'' em blocos de construção?

%%}}}

%%{{{ what is our cement? 
\note.
%%%{{{ meta 
%%%}}}

Vamos primeiramente responder nessa questão com outra:
\emph{Qual seria nosso ``cimento''?}
Tome como exemplo o número $n=28$.
Usando $+$ para construí-lo com blocos, podemos quebrá-lo:
$$
\align
28 &= 16 + 12.
\intertext{E agora quebramos esses dois blocos:}
   &= \overbrace{10 + 6}^{16} + \overbrace{11 + 1}^{12};
\intertext{e esses:}
   &= \overbrace{3 + 7}^{10} + \overbrace{3 + 3}^{6} + \overbrace{4 + 7}^{11} + 1
\intertext{e o $1$ não é mais ``quebrável''.
Nesse quesito, ele é um bloco atômico, um ``tijolo''.
Repetimos esse processo até chegar num somatório cujos termos são todos tijolos:}
 &= \tubrace{1 + 1 + 1 + 1 + \dotsb + 1} {$28$ termos}.
\endalign
$$
O leitor é convidado pensar sobre as observações seguintes:
\elist i:
\li:
Começando com qualquer inteiro positivo $n$,
depois um \emph{finito} número de passos, o processo termina:
nenhum dos termos que ficam pode ser quebrado.
\li:
Existe apenas um tipo de bloco atômico: o $1$.
Podemos então formar qualquer número $n$ começando com $n$ tijolos ($n$ $1$'s)
e usando a operação $+$ para juntá-los.
\li:
Não faz sentido considerar o $0$ como tijolo, pois escrevendo o $1$ como
$$
1 = 1 + 0 \qqqqtext{ou}
1 = 0 + 1
$$
não conseguimos ``quebrá-lo'' em peças menores.  Pelo contrário,
ele aparece novamente, da mesma forma, no lado direito.
\endelist

%%}}}

%%{{{ x: partitioning_restricted_best_strategy 
\exercise.
%%%{{{ meta 
\label partitioning_restricted_best_strategy
%%%}}}

Qual é a melhor estratégia para desconstruir o $n$ em $1$'s conseguindo
o menor número de passos possível?  Quantos passos precisa?
Suponha que em cada passo tu tens de escolher apenas \emph{um} termo
(não atômico) e decidir em quais duas partes tu o quebrarás.

\hint
Olha na forma final do somatório.
O que acontece em cada passo?

\solution
Todas as estratégias são iguais: em cada passo, um $+$ é adicionado,
e todas terminam no mesmo somatório com $n$ \symq{$1$}s e $n-1$ \symq{$+$}s.
Então começando com qualquer número $n$, depois de $n-1$ passos chegamos
na sua forma $n = 1 + 1 + \dotsb + 1$.

%%}}}

%%{{{ x: partitioning_restricted_best_strategy_proof 
\exercise.
%%%{{{ meta 
\label partitioning_restricted_best_strategy_proof
\pdefs
    \pdef steps {\namedfun{steps}}
    ;;
%%%}}}

Demonstre formalmente tua resposta no~\ref[partitioning_restricted_best_strategy].

\hint
Como nos livramos dos pontos informais ``$\dotsb$''?

\hint
Indução.

\hint
Seja $\steps(x)$ o número de passos necessários para quebrar o $x$ em $1$'s.

%%}}}

%%{{{ times in stead of plus 
\note ``Vezes'' em vez de ``mais''.
%%%{{{ meta 
\indexes
    * primo!informalmente
    ;;
%%%}}}

Vamos agora usar como cimento a operação $\ntimes$,
ilustrando o processo com o número $2016$:
\goodbreak
$$
\align
2016
&= 12 \ntimes 168
\intertext{e repetimos\dots}
&= \overbrace{4\ntimes 3}^{12} \ntimes \overbrace{28 \ntimes 6}^{12}
\intertext{e agora vamos ver:
o $4$ pode ser quebrado sim ($2\ntimes2$), mas o $3$?
Escrever $3 = 3\ntimes 1$ com certeza não é um jeito aceitável para quebrar o $3$
em blocos de construção ``mais principais'': o lado direto é mais complexo!
Quebrando com $\ntimes$ então, o $3$ é um bloco atômico, um tijolo!
Continuando:}
&= \overbrace{2\ntimes 2}^{4}{} \ntimes 3 \ntimes (7\ntimes 4) \ntimes (2\ntimes3)\\
&= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes \overbrace{2\ntimes2}^4{} \ntimes 2\ntimes3
\intertext{onde todos os fatores são atômicos.
Podemos construir o número $2016$ então assim:}
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3,
\endalign
$$
usando os tijolos 2, 3, e 7, e a operação de multiplicação.
Nos vamos definir formalmente esses tijolos (são os \dterm{primos},~\ref[prime]),
e estudar suas propriedades.
\eop
Ilustrando com o mesmo número $2016$, um outro caminho para processar seria o seguinte:
$$
\align
2016
&= 48 \ntimes 42 \\
&= \overbrace{8 \ntimes 6}^{48} \ntimes \overbrace{6\ntimes 7}^{42}\\
&= \overbrace{2\ntimes 4}^{8} \ntimes \overbrace{2\ntimes 3}^{6} \ntimes \overbrace{2\ntimes 3}^{6}{}\ntimes 7\\
&= 2 \ntimes \overbrace{2\ntimes 2}^{4}{} \ntimes 2\ntimes 3 \ntimes 2\ntimes 3\ntimes 7
\intertext{então no final temos:}
2016&= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endalign
$$

%%}}}

%%{{{ x: fundamental_theorem_of_arithmetic_omen 
\exercise.
%%%{{{ meta 
\label fundamental_theorem_of_arithmetic_omen
%%%}}}

O que tu percebes sobre as duas desconstruções?:
$$
\align
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3;\\
2016 &= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endalign
$$

\solution
Esquecendo a ordem que os fatores parecem, são iguais:
cada construção precisa os mesmos blocos atômicos (o $2$, o $3$, e o $7$),
e cada um deles foi usado o mesmo número de vezes:
$2016 = 2^5 3^2 7$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
\credits
    * Euclid : Elementos
    * Euclid : teorema fundamental de aritmética
    * Gauss : Disquisitiones Arithmeticæ
    * Gauss : teorema fundamental de aritmética
    ;;
%%%}}}

Logo chegaremos no resultado principal que esclarecerá
o que percebemos no~\ref[fundamental_theorem_of_arithmetic_omen]:
o~\ref[fundamental_theorem_of_arithmetic],
ilustrado (parcialmente) já por Euclides
(circa~\yearof{300}~a.C.)~nos seus \emph{Elementos}~\cite[elements]
e demonstrado completamente por Gauss (no ano \yearof{1798}) no seu
\emph{Disquisitiones Arithmeticæ}~\cite[disquisitiones].

%%}}}

%%{{{ x: factorize_some_integers 
\exercise.
%%%{{{ meta 
\label factorize_some_integers
%%%}}}

Fatorize os inteiros $15$, $16$, $17$, $81$, $100$, $280$, $2015$, e $2017$
em fatores primos.

\solution
Calculamos:
$$
\alignat 4
15   &= 3 \ntimes 5 \qquad&  17   &= 17          \qquad& 100  &= 2^2\ntimes 5^2           \qquad& 2015 &= 5\ntimes 13\ntimes 31  \\
16   &= 2^4         \qquad&  81   &= 3^4         \qquad& 280  &= 2^3 \ntimes 5 \ntimes 7  \qquad& 2017 &= 2017.
\endalignat
$$

%%}}}

%%{{{ codeit: program_factor_naive 
\codeit FactorNaive.
%%%{{{ meta 
\label program_factor_naive
%%%}}}

Escreva um programa que mostra para cada entrada, uma fatorização em primos.
Execute teu programa para verificar tuas respostas no~\ref[factorize_some_integers].

%%}}}

%%{{{ Q: how many different construction blocks for times? 
\question.
%%%{{{ meta 
%%%}}}

Usando adição, nos precisamos apenas um tipo de tijolo para construir qualquer
inteiro positivo: o $1$.
Usando a multiplicação nos já percebemos que vários tipos são necessários; mas quantos?

%%}}}

%%{{{ A: soon 
\note Resposta (Euclides).
%%%{{{ meta 
%%%}}}

Essa pergunta e sua resposta não são triviais!
Recomendo para ti, tentar responder e \emph{demonstrar} tua afirmação.
Logo vamos encontrar a resposta (de Euclides)
que é um dos teoremas mais famosos e importantes na história de matemática
(\ref[primes_is_infinite]).

%%}}}

\endsection
%%}}}

%{{{ Divisibility 
\section Divisibilidade.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Espero que lembras a definição formal da divisibilidade
(\ref[Real_life_proof_examples])
mas de qualquer forma repito aqui, a dando também um rótulo
pois vamos precisar citá-la bastante:

%%}}}

%%{{{ df: divides 
\definition Divisibilidade.
%%%{{{ meta 
\label divides
\defines
    * ~a \divides ~b  -- $a$ divide $b$
    * divide
    * divisor
    * divisível
    * multiplo
    ;;
%%%}}}

Sejam $a,b\in\ints$.
Digamos que \dterm{o $a$ divide o $b$} (ou \dterm{o $b$ é divisível por $a$}), sse $b = ak$ para algum $k\in\ints$.
Nesse caso, escrevemos $a \divides b$.
Em símbolos:
$$
a \divides b \defiff \lexists {k\in\ints} {b = ak}.
$$
Os \dterm{divisores} do $a$ são todos os inteiros $d$ tais que $d \divides a$.
Naturalmente, usamos a notação $a\ndivides b$ quando $a$ não divide $b$.

%%}}}

%%{{{ ppty: divides_properties 
\property.
%%%{{{ meta 
\label divides_properties
%%%}}}

Sejam $a,b,c,x,y,m$ inteiros.
Logo:
\elist:
\li: $1 \divides a$
\li: $a \divides 0$
\li: $a \divides b \implies a \divides bx$
\li: $a \divides b \implies a \divides -b \mland -a \divides b$
\li: $a \divides b \mland a \divides c \implies a \divides b + c$
\li: $a \divides b \mland a \divides c \implies a \divides bx + cy$
\li: $a \divides b \mland b \neq 0 \implies \abs a \leq \abs b$
\li: se $m\neq0$ então: $a \divides b \!\iff\! ma \divides mb$.
\endelist

%%}}}

%%{{{ prop: divides_is_almost_a_partial_order
\property Divide é quase uma ordem parcial.
%%%{{{ meta 
\label divides_is_almost_a_partial_order
%%%}}}

Para todos $a,b,c\in\ints$,
\mathcall
& a \divides a                                           \called {reflexividade} \\
& a \divides b \mland b \divides c \implies a \divides c \called {transitividade} \\
& a \divides b \mland b \divides a \implies \abs a = \abs b.
\intertext{Se $a,b\in\nats$, a terceira propriedade fica mais forte:}
& a \divides b \mland b \divides a \implies a = b.       \called {antissimetria} \\
\endmathcall

\proof Já demonstrado.
Este foi o~\ref[divides_is_almost_a_partial_order_proof].

%%}}}

%%{{{ x: implications_with_divisibility_of_linear_combinations 
\exercise.
%%%{{{ meta 
\label implications_with_divisibility_of_linear_combinations
%%%}}}

Sejam $a,b,c\in\ints$.
Demonstre ou refute cada uma das afirmações:
$$
\alignat2
\text{(i)}   &\qquad& a \divides \phantom1b + c\phantom1                          &\implies a \divides b \mland a \divides c\\
\text{(ii)}  &\qquad& a \divides b + c \mland a \divides \phantom1b - c\phantom2  &\implies a \divides b                    \\
\text{(iii)} &\qquad& a \divides b + c \mland a \divides \phantom1b + 2c          &\implies a \divides b                    \\
\text{(iv)}  &\qquad& a \divides b + c \mland a \divides 2b + 2c                  &\implies a \divides b                    \\
\text{(v)}   &\qquad& a \divides b + c \mland a \divides 2b + 3c                  &\implies a \divides 3b + 2c\,.
\endalignat
$$

\solution
A (ii) é falsa: um contraexemplo seria o $a = 2$, $b = c = 1$.
Realmente, temos
$$
2 \divides 1 + 1 = 2 \mland 2 \divides 1 - 1 = 0,
\qqtext{mas}
2\ndivides 1.
$$
\eop
A (iii) é verdadeira:
$$
\rightbrace {
\aligned
        a \divides b + c \implies a \divides 2b + 2c\\
                                 a \divides \phantom1b + 2c
\endaligned
}
\implies
a \divides \mubrace{(2b + 2c) - (b + 2c)} {\dsize b}.
$$

%%}}}

%%{{{ x: prove_humanely_properties_of_divisibility 
\exercise.
%%%{{{ meta 
\label prove_humanely_properties_of_divisibility
%%%}}}

Demonstre---novamente?---todos esses teoremas.
Tente escrever demonstrações curtíssimas e facilmente legíveis
e numa maneira ``humana'' e não mecânica.

%%}}}

\endsection
%%}}}

%{{{ Prime numbers 
\section Os números primos.
%%%{{{ meta 
%%%}}}

%%{{{ df: prime 
\definition Primo.
%%%{{{ meta 
\label prime
\indexes
    * composto   seealso: primo
    * primo      seealso: composto
    ;;
\defines
    * composto
    * primo
    ;;
%%%}}}

Seja $p\in\nats$, com $p \geq 2$.
Chamamos o $p$ \dterm{primo} sse $p$ é divisível apenas por $\pm 1$ e $\pm p$.
Caso contrário, ele é \dterm{composto}.

%%}}}

%%{{{ x: zero_and_one_prime_or_composite 
\exercise.
%%%{{{ meta 
%%%}}}

O $0$ é primo?  Composto?
O $1$ é primo?  Composto?

\solution
Nenhum dos dois é nem primo nem composto: a definição começa declarando
$p$ como um natural tal que $p \geq 2$.
Logo, não é aplicável nem para o 0 nem para o 1.

%%}}}

%%{{{ x: 2_is_the_only_even_prime 
\exercise.
%%%{{{ meta 
\label 2_is_the_only_even_prime
%%%}}}

2 é o único primo par.

%%}}}

%%{{{ x: define_composite_by_formula 
\exercise.
%%%{{{ meta 
\label define_composite_by_formula
%%%}}}

Usando uma fórmula de lógica, defina diretamente o que significa que
um $n\in\nats\setminus\set 1$ é composto.

\solution
Seja $n\in\nats$.
$$
\namedrel{Composite}(n) \defiff
\lexists {a,b\in\nats\setminus\set{0,1}} { n = ab }.
$$

%%}}}

%%{{{ eg: first_primes 
\example.
%%%{{{ meta 
\label first_primes
%%%}}}

Os primeiros 31 primos são os
  2,   3,   5,   7,  11,  13,  17,  19, 23,  29,
 31,  37,  41,  43,  47, 53,  59,  61,  67,  71,
 73,  79,  83,  89, 97, 101, 103, 107, 109, 113, e 127.

%%}}}

%%{{{ x: in_primes_divides_means_equals 
\exercise.
%%%{{{ meta 
\label in_primes_divides_means_equals
%%%}}}

Sejam $p$, $q$ primos, com $p \divides q$.
Mostre que $p=q$.

%%}}}

%%{{{ x: every_composite_number_is_divisible_by_a_prime 
\exercise.
%%%{{{ meta 
\label every_composite_number_is_divisible_by_a_prime
%%%}}}

Seja $b$ composto.
Demonstre que $b$ tem um divisor primo $d\leq \sqrt b$.

%%}}}

%%{{{ codeit: program_factor 
\codeit factor.
%%%{{{ meta 
\label program_factor
%%%}}}

Use o~\ref[every_composite_number_is_divisible_by_a_prime]
para melhorar teu programa do~\ref[program_factor_naive].

%%}}}

\endsection
%%}}}

%%{{{ Sieve_of_Eratosthenes 
\section O crivo de Eratosthenes.
%%%{{{ meta 
\label Sieve_of_Eratosthenes
\defines
    * crivo
    ;;
\credits
    * Eratosthenes : crivo
    ;;
%%%}}}

%%{{{ Q: How can we find all primes up to a given bound? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos achar todos os primos até um dado limitante $b\in\nats$?

%%}}}

%%{{{ A: answer_by_eratosthenes 
\note Resposta.
%%%{{{ meta 
\label answer_by_eratosthenes
\credits
    * Eratosthenes : crivo
    ;;
\pdefs
    \pdef ci {\uveryfaded}
    \pdef co {\phantom}
    ;;
%%%}}}

Eratosthenes (276--194 a.C.)~conseguiu responder com sua método conhecida como
o \dterm{crivo de Eratosthenes}.
Antes de descrever o seu algoritmo formalmente, vamos aplicar sua idéia
para achar todos os primos menores ou iguais que $b=128$.
Primeiramente liste todos os números de $2$ até $b=128$:
$$
\matrix
\format
~\r  &~\r  &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   \\
   {   }&   {  2}&   {   3}&   {   4}&   {   5}&   {   6}&   {   7}&   {   8}&   {   9}&   {  10}&   {  11}&   {  12}&   {  13}&   {  14}&   {  15}&   {  16}\\
   { 17}&   { 18}&   {  19}&   {  20}&   {  21}&   {  22}&   {  23}&   {  24}&   {  25}&   {  26}&   {  27}&   {  28}&   {  29}&   {  30}&   {  31}&   {  32}\\
   { 33}&   { 34}&   {  35}&   {  36}&   {  37}&   {  38}&   {  39}&   {  40}&   {  41}&   {  42}&   {  43}&   {  44}&   {  45}&   {  46}&   {  47}&   {  48}\\
   { 49}&   { 50}&   {  51}&   {  52}&   {  53}&   {  54}&   {  55}&   {  56}&   {  57}&   {  58}&   {  59}&   {  60}&   {  61}&   {  62}&   {  63}&   {  64}\\
   { 65}&   { 66}&   {  67}&   {  68}&   {  69}&   {  70}&   {  71}&   {  72}&   {  73}&   {  74}&   {  75}&   {  76}&   {  77}&   {  78}&   {  79}&   {  80}\\
   { 81}&   { 82}&   {  83}&   {  84}&   {  85}&   {  86}&   {  87}&   {  88}&   {  89}&   {  90}&   {  91}&   {  92}&   {  93}&   {  94}&   {  95}&   {  96}\\
   { 97}&   { 98}&   {  99}&   { 100}&   { 101}&   { 102}&   { 103}&   { 104}&   { 105}&   { 106}&   { 107}&   { 108}&   { 109}&   { 110}&   { 111}&   { 112}\\
   {113}&   {114}&   { 115}&   { 116}&   { 117}&   { 118}&   { 119}&   { 120}&   { 121}&   { 122}&   { 123}&   { 124}&   { 125}&   { 126}&   { 127}&   { 128.}
\endmatrix
$$
Agora começa com o primeiro número na lista, o $2$, e apaga todos os maiores múltiplos dele:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\ci{   4}&   {   5}&\ci{   6}&   {   7}&\ci{   8}&   {   9}&\ci{  10}&   {  11}&\ci{  12}&   {  13}&\ci{  14}&   {  15}&\ci{  16}\\
   { 17}&\ci{ 18}&   {  19}&\ci{  20}&   {  21}&\ci{  22}&   {  23}&\ci{  24}&   {  25}&\ci{  26}&   {  27}&\ci{  28}&   {  29}&\ci{  30}&   {  31}&\ci{  32}\\
   { 33}&\ci{ 34}&   {  35}&\ci{  36}&   {  37}&\ci{  38}&   {  39}&\ci{  40}&   {  41}&\ci{  42}&   {  43}&\ci{  44}&   {  45}&\ci{  46}&   {  47}&\ci{  48}\\
   { 49}&\ci{ 50}&   {  51}&\ci{  52}&   {  53}&\ci{  54}&   {  55}&\ci{  56}&   {  57}&\ci{  58}&   {  59}&\ci{  60}&   {  61}&\ci{  62}&   {  63}&\ci{  64}\\
   { 65}&\ci{ 66}&   {  67}&\ci{  68}&   {  69}&\ci{  70}&   {  71}&\ci{  72}&   {  73}&\ci{  74}&   {  75}&\ci{  76}&   {  77}&\ci{  78}&   {  79}&\ci{  80}\\
   { 81}&\ci{ 82}&   {  83}&\ci{  84}&   {  85}&\ci{  86}&   {  87}&\ci{  88}&   {  89}&\ci{  90}&   {  91}&\ci{  92}&   {  93}&\ci{  94}&   {  95}&\ci{  96}\\
   { 97}&\ci{ 98}&   {  99}&\ci{ 100}&   { 101}&\ci{ 102}&   { 103}&\ci{ 104}&   { 105}&\ci{ 106}&   { 107}&\ci{ 108}&   { 109}&\ci{ 110}&   { 111}&\ci{ 112}\\
   {113}&\ci{114}&   { 115}&\ci{ 116}&   { 117}&\ci{ 118}&   { 119}&\ci{ 120}&   { 121}&\ci{ 122}&   { 123}&\ci{ 124}&   { 125}&\ci{ 126}&   { 127}&\ci{ 128}
\endmatrix
$$
Toma o próximo número que está ainda na lista, o $3$, e faça a mesma coisa:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\ci{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\ci{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\ci{  21}&\co{  22}&   {  23}&\co{  24}&   {  25}&\co{  26}&\ci{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\ci{ 33}&\co{ 34}&   {  35}&\co{  36}&   {  37}&\co{  38}&\ci{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\ci{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\ci{  51}&\co{  52}&   {  53}&\co{  54}&   {  55}&\co{  56}&\ci{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\ci{  63}&\co{  64}\\
   { 65}&\co{ 66}&   {  67}&\co{  68}&\ci{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\ci{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\ci{ 81}&\co{ 82}&   {  83}&\co{  84}&   {  85}&\co{  86}&\ci{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\ci{  93}&\co{  94}&   {  95}&\co{  96}\\
   { 97}&\co{ 98}&\ci{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\ci{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\ci{ 111}&\co{ 112}\\
   {113}&\co{114}&   { 115}&\co{ 116}&\ci{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\ci{ 123}&\co{ 124}&   { 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Repeta o processo (o próximo agora seria o $5$) até não tem mais números para tomar.
Os números que ficarão são todos os primos até o $128$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\ci{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\ci{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\ci{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\ci{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\ci{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\co{  93}&\co{  94}&\ci{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\ci{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\ci{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Tomando o $7$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\ci{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\ci{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\ci{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\ci{ 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
Tomando o $11$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\co{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\co{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\co{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\co{ 119}&\co{ 120}&\ci{ 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}
\endmatrix
$$
E já podemos parar aqui, certos que os números que ainda ficam na lista, são todos os primos desejados.

%%}}}

%%{{{ Q: Why? 
\question.
%%%{{{ meta 
%%%}}}

Por quê?

%%}}}

\spoiler

%%{{{ x: prime_factor_sqrt_criterion 
\exercise.
%%%{{{ meta 
\label prime_factor_sqrt_criterion
%%%}}}

Seja $a>0$ inteiro composto.
Logo $a$ possui fator primo $p \leq {\sqrt a}$.

\hint
Considere o menor divisor de $a$.
O que pode afirmar sobre ele?

%%}}}

%%{{{ x: three_divides_abc 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $a,b,c$ inteiros tais que $a^2 + b^2 = c^2$.
Então $3 \divides abc$.

\hint
Caso que qualquer um dos $a,b,c$ é multiplo de $3$, já éra.
Basta então considerar o caso onde nenhum deles é multiplo de $3$.

\hint
O quadrado dum número que não é múltiplo de $3$ é congruente ao $1$ módulo $3$.

%%}}}

%%{{{ x: eratosthenian_algorithm 
\exercise.
%%%{{{ meta 
\label eratosthenian_algorithm
%%%}}}

Escreva formalmente o algoritmo do Eratosthenes.

%%}}}

%%{{{ codeit: implement_eratosthenian_algorithm 
\codeit.
%%%{{{ meta 
\label implement_eratosthenian_algorithm
%%%}}}

Implemente o algoritmo de Eratosthenes e o usando ache todos os primos até o $1024$.

%%}}}

\endsection
%%}}}

%%{{{ Euclid's division lemma 
\section O lemma da divisão de Euclides.
%%%{{{ meta 
%%%}}}

%%{{{ lemma: euclidean_division 
\lemma Lemma da Divisão de Euclides.
%%%{{{ meta 
\headerize
\label euclidean_division
\credits
    * Euclid : lemma da divisão
    ;;
\indexes
    * divisão!lemma
    * divisão    seealso: Euclides
    ;;
%%%}}}

Dados inteiros $a$ e $b$ com $b \neq 0$,
existem inteiros $q$ e $r$ tais que:
$$
a = bq + r,
\qquad
0 \leq r < \abs b.
\mtag[euclidean_div=EucDiv]
$$
Além disso, os $q$ e $r$ são \emph{determinados unicamente}.

\sketch.
\proofpart{Existência:}
Considera a seqüência infinita:
$$
\ldots ,~
-3b + r,~
-2b + r,~
 -b + r,~
      r,~
  b + r,~
 2b + r,~
 3b + r,~
\ldots
$$
Observe que ela tem elementos não-negativos e,
aplicando a PBO, considera o menor deles.
\proofpart{Unicidade:}
Suponha que $a=bq+r=bq'+r'$
para alguns $q,r,q',r'\in\ints$ tais que satisfazem as restricções
$0 \leq r < \abs b$ e $0 \leq r' < \abs b$.
Basta mostrar que $r=r'$ e $q=q'$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por causa dessa existência e unicidade, podemos definir:

%%}}}

%%{{{ df: division 
\definition Divisão.
%%%{{{ meta 
\label division
\defines
    * divisão
    * quociente!divisão
    * resto!divisão
    * \quot(~a,~b)  -- o quociente de $a$ dividido por $b$
    * \rem(~a,~b)   -- o resto de $a$ dividido por $b$
    ;;
%%%}}}

Dados $a,b\in\ints$ com $b>0$, são determinados os inteiros $q$ e $r$
que satisfazem a~\mref[euclidean_div].
Chamamos o $q$ de \dterm{quociente} e o $r$ de
\dterm{resto} da divisão de $a$ por $b$ e os denotamos por
$\quot(a,b)$ e $\rem(a,b)$ respectivamente:
$$
a = b \stimes \quot(a,b) + \rem(a,b)
\qquad
0\leq \rem(a,b) < \abs b.
$$

%%}}}

%%{{{ x: n_divides_exactly_one_of_n_consecutive_integers 
\exercise.
%%%{{{ meta 
\label n_divides_exactly_one_of_n_consecutive_integers
%%%}}}

Seja $n\in\nats$ positivo.  Se $a_0,a_1,\dotsc,a_{n-1}$ são $n$ inteiros consecutivos,
então $n \divides a_i$ para um único $i\in\set{0,\dots,n-1}$.

\hint
Seja $a=a_0$.  Assim $a_i = a + i$.

\hint
Divida o $a$ por $n$ e, olhando para o resto $r$,
ache o certo $i$ tal que $n \divides a_i$.

\hint
Para a unicidade, ache o resto da divisão de $n$ por o aleatório $a_j$.

%%}}}

%%{{{ x: 3|n or 3|n²-1 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n\in\ints$, se $3 \ndivides n$
então $3 \divides n^2 - 1$.

\hint
Ou fatorize o $n^2-1$ e use o~\ref[n_divides_exactly_one_of_n_consecutive_integers],
ou considere os casos possíveis dependendo dos restos da divisão de $n$ por $3$.

%%}}}

%%{{{ df: closed_under_addition 
\definition Conjunto fechado sobre $+$.
%%%{{{ meta 
\label closed_under_addition
\defines
    * conjunto!$+$-fechado
    ;;
%%%}}}

Seja $A$ conjunto de números
Dizemos que $A$ é \dterm{fechado pela} $+$ sse
a soma de quaisquer dois membros $a,b$ do $A$ está no $A$ também:
$$
\lforall {a,b \in A} {a+b \in A}.
$$
Chamamos o $A$ de $+$\dterm{-fechado}.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Os conjuntos $\nats$, $\ints$, $\ints_{>0}$, $\ints_{<0}$, são todos
exemplos de conjuntos $+$-fechados.

%%}}}

%%{{{ noneg 
\nonexample.
%%%{{{ meta 
%%%}}}

Os conjunto de todos os inteiros ímpares não é $+$-fechado (por quê?).
Nem o conjunto de todos os primos (por quê?).
Nem o conjunto de todos os racionais não inteiros (por quê?).

%%}}}

%%{{{ x: why? why? why? 
\exercise.
%%%{{{ meta 
%%%}}}

Por quê?
Por quê?
Por quê?

\hint
Para cada conjunto basta achar um testemunha, ou seja,
um parzinho $(x,y)$ de membros dele tal que $x+y$ não pertence a ele.

\solution
Aqui três testemunhas, um para cada conjunto respectivamente:
\mathcols 3
1 + 1     &= 2 &
3 + 5     &= 8 &
\frac 2 3 + \frac 4 3 &= 2
\endmathcols

%%}}}

%%{{{ x: Ø and {0} are +-closed 
\exercise.
%%%{{{ meta 
%%%}}}

O $\emptyset$ e o $\set{0}$ são fechados pela $+$.

%%}}}

%%{{{ x: generalize +-closed to op-closed for any op 
\exercise.
%%%{{{ meta 
%%%}}}

Generalize a noção acima para definir a noção
\dterm{conjunto fechado pela} $f$,
onde $f$ é uma operação no $A$ de aridade qualquer.

\solution
Seja $f$ uma operação $n$-ária num conjunto $A$.
Dizemos que $A$ é $f$-fechado sse para quaisquer
$a_1,\dotsc,a_n \in A$, temos $f(a_1,\dotsc,a_n) \in A$.

%%}}}

%%{{{ x: which of the following sets are closed under which ops? 
\exercise.
%%%{{{ meta 
%%%}}}

Quais dos conjuntos abaixo são fechados pela $+$,
quais sobre $-$, e quais sobre $\ntimes$?
$$
\aligned
    U &= \set{0}\\
    W &= \set{0,1}\\
    P &= \set{1,2,4,8,16,\dotsc}\\
    I &= \set{1,1/2,1/4,1/8,1/16,\dotsc}
\endaligned
\quad
\aligned
    A &= \set{0,4,6,10,12,16,18,22,24,\dotsc}\\
    B &= \set{0,2,4,6,8,10,12,\dotsc}\\
    C &= \set{\dotsc,-9,-6,-3,0,3,6,9,\dotsc}\\
    D &= \set{\dotsc,-8,-5,-2,1,4,7,10,\dotsc}.
\endaligned
$$

%%}}}

%%{{{ x: define some infinite sets without "…" 
\exercise.
%%%{{{ meta 
%%%}}}

Defina os conjuntos infinitos do exercício anterior sem usar ``$\ldots$\!''.

%%}}}

%%{{{ x: under which operations are rats and rats_≠0 closed? 
\exercise.
%%%{{{ meta 
%%%}}}

O $\rats$ é fechado por quais das quatro operações binárias
$+$, $-$, $\ntimes$, $\div$?
E o $\rats_{\neq0}$?

%%}}}

%%{{{ x: minus_closed_implies_plus_closed 
\exercise.
%%%{{{ meta 
\label minus_closed_implies_plus_closed
%%%}}}

Demonstre que se um conjunto é fechado pela $-$ então
ele deve ser fechado pela $+$ também, mas não o converso não é necessariamente
verdadeiro!

%%}}}

%%{{{ x: form_of_closed_under_minus_proof 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_minus_proof
%%%}}}

Seja $S\subset\ints$, com $S\neq\emptyset$, e fechado pela $-$.
Logo $S=\set 0$ ou existe inteiro $d>0$ tal que $S = \setst {kd} {k\in\ints}$.

\hint.
Princípio da Boa Ordem.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um conjunto de inteiros fechado pela $-$ (e logo pela $+$ também),
não tem muita liberdade na ``forma'' dele.
O lemma seguinte mostra essa forma geral que todos eles devem ter.

%%}}}

%%{{{ lemma: form_of_closed_under_minus 
\lemma.
%%%{{{ meta 
\label form_of_closed_under_minus
%%%}}}

Seja $S$ um conjunto de inteiros não vazio e fechado pela $-$.
Logo $S=\set{0}$ ou existe inteiro $d>0$ tal que
$S$ é o conjunto de todos os múltiplos de $d$:
$$
S = \setst {md} {m \in \ints}.
$$

\proof.
Suponha que $S\neq\set{0}$.  Basta demonstrar que
existe inteiro $d>0$ tal que
$$
S = \setst {md} {m \in\ints}.
$$
Organizamos o resto da demonstração em três partes:
\elist A:
\li:form_of_closed_under_minus_part1_task
Definir um $d>0$ que será o inteiro positivo desejado.
\li:form_of_closed_under_minus_part2_task
Demonstrar que todos os multiplos de $d$ pertencem ao $S$.
\li:form_of_closed_under_minus_part3_task
Demonstrar que nada mais pertence ao $S$.
\endelist
Com isso temos que o conjunto $S$ e o conjunto de todos os
múltiplos de $d$ possuem exatamente os mesmos membros,
que foi o que precisamos demonstrar.

%%}}}

%%{{{ x: form_of_closed_under_minus_part1 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_minus_part1
%%%}}}

Resolva a parte \reftag[form_of_closed_under_minus_part1_task] da
demonstração do~\ref[form_of_closed_under_minus].

\hint
Use o PBO (mas cuidado pois precisas de demonstrar algo antes de usá-lo).

\hint
Antes de usar o PBO precisas demonstrar que o $S$ possui membros positivos.

\solution
Vou demonstrar que $S$ tem membros positivos.
Seja $x \in S$ tal que $x \neq 0$ ($S\neq\emptyset$ e $S\neq\set{0}$).
Caso $x>0$, já encontramos um membro positivo do $S$.
Caso $x<0$, basta mostrar que $-x \in S$, pois $-x > 0$.
Como $S$ é fechado pela $-$, temos $x - x \in S$; ou seja, $0 \in S$.
Usando novamente que $S$ é $-$-fechado, temos $0 - x \in S$, ou seja $-x \in S$.
Pelo PBO, \emph{seja $d$ o menor membro positivo do $S$}.

%%}}}

%%{{{ x: form_of_closed_under_minus_part2 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_minus_part2
%%%}}}

E a \reftag[form_of_closed_under_minus_part2_task].

\hint
Use indução, mas cuidado para não esquecer nada.

\solution
Primeiramente vou demonstrar por indução que
para todo $n\in\nats$, $nd \in S$.
A base é imediata: $0d = 0 \in S$.
Seja $k \in \nats$ tal que $kd \in S$\fact{HI}.
Calculamos:
$$
(k+1)d = kd + d \in S
$$
pois $d \in S$ e $kd \in S$ (pela HI) e $S$ é $+$-fechado
(pelo~\ref[minus_closed_implies_plus_closed])
Seja $x < 0$, e observe que $(-x)d\in S$ (pois $-x > 0$) e logo
$0 - (-x)d \in S$, ou seja, $xd \in S$.

%%}}}

%%{{{ x: form_of_closed_under_minus_part3 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_minus_part3
%%%}}}

Preciso mesmo enunciar?

\hint
Tome um arbitrário $a \in S$ e use o lemma da Divisão de Euclides.

%%}}}

%%{{{ x: form_of_closed_under_minus_without_disjunction 
\exercise.
%%%{{{ meta 
%%%}}}

Sem usar disjuncção, escreva uma proposição equivalente com a conclusão do
\ref[form_of_closed_under_minus] e explique por que ela é equivalente.

\hint
Existe $n\in\nats$ tal que $S = \setst {kn} {k\in\ints}$.

%%}}}

\endsection
%%}}}

%%{{{ The_greatest_common_divisor 
\section O máximo divisor comum.
%%%{{{ meta 
\label The_greatest_common_divisor
%%%}}}

%%{{{ df: a_gcd 
\definition.
%%%{{{ meta 
\label a_gcd
\defines
    * máximo divisor    see: divisor
    * divisor!um máximo comum
    ;;
%%%}}}

Sejam $a,b\in\ints$.
O inteiro $d$ é \dterm{um máximo divisor comum (m.d.c.)} dos $a$~e~$b$,
sse $d$~é~um divisor comum e um multiplo de todos os divisores comuns.
Em símbolos:
\mathmistake
d = \gcd a b
\defiff
\tubrace {d \divides a \mland d \divides b}
         {divisor comun}
\mland
\tubrace {\lforall c {c \divides a \mland c \divides b \implies c \divides d}}
         {``máximo''}.
\endmathmistake

%%}}}

%%{{{ x: gcd is not well-defined yet 
\exercise.
%%%{{{ meta 
%%%}}}

A~\ref[a_gcd] tem um erro: o símbolo $\gcd a b$ não foi bem-definido!
O que precisamos demonstrar para definir realmente o símbolo $\gcd a b$?

\solution
Duas coisas:
\eop
\proofstylize{Existência:}
\emph{para todos inteiros $a$, $b$, existe inteiro $d$ que satisfaz as relações acima.}
\eop
\proofstylize{Unicidade:}
\emph{se $d$, $d'$, são inteiros que satisfazem essas relações, então $d=d'$.}

%%}}}

%%{{{ ppty: if d,d' are gcds then |d|=|d'| 
\property.
%%%{{{ meta 
%%%}}}

Sejam $a,b\in\ints$.  Se $d,d'\in\ints$ são máximos divisores comuns
dos $a$ e $b$, então $\abs d = \abs{d'}$.

\sketch.
Aplicamos a definição de m.d.c.~para cada um dos $d$ e $d'$,
para chegar em $d \divides d'$ e $d' \divides d$.

\proof.
Suponha que $d,d'$ são m.d.c.'s de $a$ e $b$.
Como $d$ é um m.d.c., todos os divisores em comum dos $a$ e $b$ o dividem.
Mas, como $d'$ é um divisor em comum, então $d' \divides d$.
Simetricamente concluimos que $d \divides d'$.
Logo $d = \pm d'$ (por~\ref[divides_is_almost_a_partial_order]).

%%}}}

%%{{{ cor 
\corollary.
%%%{{{ meta 
%%%}}}

Sejam $a,b\in\ints$.
Existe único $d\in\nats$ tal que $d$ é um m.d.c.~de $a$ e~$b$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora podemos finalmente definir o símbolo $\gcd a b$:

%%}}}

%%{{{ df: gcd 
\definition O máximo divisor comum.
%%%{{{ meta 
\label gcd
\indexes
    * mdc    seealso: divisor
    ;;
\defines
    * \gcd {~a} {~b}  -- o máximo divisor comum de $a$ e $b$
    * divisor!o máximo comum
    * mdc
    ;;
%%%}}}

Sejam $a,b\in\ints$.
$$
d = \gcd a b
\defiff
\tubrace { d \divides a \mland d \divides b } {divisor comun}
\mland
\tubrace { d\in\nats \mland \lforall c {\paren{c \divides a \mland c \divides b} \implies c \divides d} } {o máximo}
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos já demonstrar umas propriedades básicas de m.d.c.

%%}}}

%%{{{ x: gcd_signs 
\exercise.
%%%{{{ meta 
\label gcd_signs
%%%}}}

O m.d.c. não liga sobre sinais: para quaisquer inteiros $a,b$,
$$
\gcd a b
= \gcd a {-b}
= \gcd {-a} {b}
= \gcd {-a} {-b}.
$$

%%}}}

%%{{{ x: gcd_op_properties
\exercise.
%%%{{{ meta 
\label gcd_op_properties
%%%}}}

Sejam $a,b,c\geq 0$ inteiros.  Logo:
\mathcall
&\gcd a a = a  \\
&\gcd a 0 = a  \\
&\gcd a 1 = 1  \\
&\gcd a b = \gcd b a                    \called {comutatividade} \\
&\gcd {\gcd a b} c = \gcd a {\gcd b c}  \called {associatividade}
\endmathcall

%%}}}

%%{{{ lemma: bezout_lemma 
\lemma Lemma de Bezout.
%%%{{{ meta 
\label bezout_lemma
\headerize
\credits
    * Bezout : lemma
    ;;
\defines
    * combinação linear
    ;;
%%%}}}

Sejam $a,b\in\ints$.
Logo existe $d\in\nats$ que satisfaz a definição de $\gcd a b$,
ele pode ser escrito como \dterm{combinação linear}
dos $a$ e $b$, com coeficientes inteiros; ou seja,
$$
d = sa + tb,
\qquad
\text{para alguns $s,t\in\ints$}.
$$
Além disso, o $\gcd a b$ divide qualquer combinação linear dos $a$ e $b$.

\sketch.
Considere o conjunto $L$ de todas as combinações lineares.
Demonstre que existe $n_0\in\nats$ tal que $L = \setst {kn_0} {k\in\ints}$.
Verifique que $\gcd a b = n_0$.

%%}}}

%%{{{ x: bezout_coefs_are_not_unique 
\exercise.
%%%{{{ meta 
\label bezout_coefs_are_not_unique
%%%}}}

Investigue se a forma do $\gcd a b$ como combinação linear dos $a$ e $b$
é unicamente determinada.

\hint
Não é.  Mostre um contraexemplo.

\solution
Toma $3$ e $4$.  Temos $\gcd 4 3 = 1$, mas:
$$
\aligned
1 &= (-2)\ntimes 4 + 3\ntimes 3\\
1 &= \phantom{(-}4\phantom{)}\ntimes 4 - 5\ntimes 3.
\endaligned
$$

%%}}}

%%{{{ ppty: gcd_of_comparable 
\property.
%%%{{{ meta 
\label gcd_of_comparable
%%%}}}

$a \divides b \implies \gcd a b = a$.
Especificamente, $\gcd a 0 = a$.

\sketch.
Precisamos apenas verificar as condições da definição de m.d.c.,
que seguem por as propriedades de $\divides$ que já provamos.

%%}}}

%%{{{ x: common_divisor_written_as_linear_combination_means_gcd 
\exercise.
%%%{{{ meta 
\label common_divisor_written_as_linear_combination_means_gcd
%%%}}}

Demonstre ou refute:
se um inteiro $m\geq 0$ é divisor comum dos $a,b$ e pode ser
escrito como combinação linear deles, então $m = \gcd a b$.

\hint
Já demonstramos que
$$
\setst {ax + by} {x,y \in \ints}
=
\setst {md} {m \in \ints}
$$

%%}}}

%%{{{ x: gcd_of_two_is_gcd_of_one_plus_sum 
\exercise.
%%%{{{ meta 
\label gcd_of_two_is_gcd_of_one_plus_sum
%%%}}}

Sejam $a,b\in\ints$.
Demonstre que
$$
\gcd a b = \gcd a {a+b}.
$$

\hint
Lembre a definição de m.d.c.\,.

\hint
Talvez as propriedades seguintes são úteis:
\tlist:
\li: para todos $x,y\in\nats$, $x \divides y \mland y \divides x \implies x = y$;
\li: para todos $a,x,y\in\ints$, $a \divides x \mland a \divides y \implies a \divides {x+y}$.
\endtlist

\solution
\proofstylize{Idéia 1:}
Sejam $d = \gcd a b$ e $d' = \gcd a {a + b}$.
Pela definição, $d$ é divisor comum dos $a$ e $b$,
então $d \divides a $ e $d \divides b$, e logo $d \divides a + b$.
Temos então que $d$ é um divisor comum dos $a$ e $a + b$, e, pela definição de mdc,
como $d' = \gcd a {b+c}$, temos $d' \divides d$.
Similarmente, $d \divides d'$.
Então $|d| = |d'|$ e como ambós são naturais (parte da definição de $\gcd x y$), temos:
$$
\gcd a b = d = d' = \gcd a {a + b}.
$$
\eop
\proofstylize{Idéia 2:}
Seja $d = \gcd a b$.  Vamos mostrar que $d = \gcd a {a + b}$.
Pela definição, $d\geq0$ e é divisor comum dos $a$ e $b$,
então $d \divides a$ e $d \divides b$, e logo $d \divides a + b$.
Temos então que $d\geq0$ e é um divisor comum dos $a$ e $a + b$, e, pela definição de mdc,
falta só demonstrar que cada divisor comum deles divide o $d$.
Seja $c\in\ints$ tal que $c \divides a$ e $c \divides {a+b}$.
Logo, $c \divides a - (a+b)=-b$.  Concluimos que $c \divides b$, então
$c$ é um divisor comum dos $a$ e $b$, então $c \divides d$ pela definição do $d$
como m.d.c.~dos $a$ e $b$.

%%}}}

%%{{{ x: consecutive_fibs_are_coprime 
\exercise.
%%%{{{ meta 
\label consecutive_fibs_are_coprime
\indexes
    * Fibonacci!seqüência
    ;;
%%%}}}

Demonstre que para todo $n\in\nats$, $\gcd {F_n} {F_{n+1}} = 1$,
onde $F_n$ é o $n$-ésimo termo da seqüência
Fibonacci~(\ref[fibonacci]).

\hint
Tu não pulou o~\ref[gcd_of_two_is_gcd_of_one_plus_sum], certo?

\solution
Vamos demonstrar o pedido por indução.
A base
$$
\gcd {F_0} {F_1} = \gcd 0 1 = 1.
$$
Seja $k\in\nats$ tal que $\gcd {F_k} {F_{k+1}} = 1$\fact{HI}.
Precisamos mostrar que $\gcd {F_{k+1}} {F_{k+2}} = 1$.
Calculando,
\compute
\gcd {F_{k+1}} {F_{k+2}}
    &= \gcd {F_{k+1}} {F_{k+1} + F_k}   \by {pela definição da $F_n$} \\
    &= \gcd {F_{k+1}} {F_k}             \by {pelo~\ref[gcd_of_two_is_gcd_of_one_plus_sum], com $a\asseq F_{k+1},\ b\asseq F_k$} \\
    &= \gcd {F_k} {F_{k+1}}             \by {pelo~\ref[gcd_op_properties]} \\
    &= 1.                               \by {pela hipótese indutiva} \\
\endcompute

%%}}}

%%{{{ lemma: euclid_lemma 
\lemma Lemma de Euclides.
%%%{{{ meta 
\headerize
\label euclid_lemma
\credits
    * Euclid : lemma
    ;;
%%%}}}

Sejam $a,b\in\ints$ e $p$ primo.
Se $p \divides ab$, então $p \divides a$ ou $p \divides b$.

\sketch.
Suponha que $p \ndivides a$.
Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$:
$$
1 = as + pt,    \qquad\text{para alguns $s,t\in\ints$}.
$$
Multiplica os dois lados por $b$, e explica por que necessariamente $p \divides b$.

\proof.
Suponha que $p\ndivides a$.  Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$,
ou seja, existem $s,t\in\ints$ tais que:
$$
\align
1 &= as + pt.
\intertext{Multiplicando os dois lados por $b$, temos:}
b &= asb + ptb.
\endalign
$$
Observe que como $p \divides ab$, segue que $p \divides asb$ (por~\ref[divides_properties]).
Obviamente $p \divides ptb$ também.
Logo, $p \divides asb + ptb = b$.

%%}}}

%%{{{ lemma: lemma_euclides_coprime_version 
\lemma.
%%%{{{ meta 
\label lemma_euclides_coprime_version
%%%}}}

Se $\gcd d a = 1$ e $d \divides ab$, então $d \divides b$.

\sketch.
A prova é practicamente a mesma com aquela do~\ref[euclid_lemma]:
lá nós precisamos da primalidade do $p$ apenas para
concluir que $\gcd a p = 1$.
Aqui temos diretamente a hipótese $\gcd a d = 1$.

\proof.
Seja $a,b,d\in\ints$, tais que
$\gcd d a = 1$ e $d \divides ab$.
Como $\gcd a d = 1$, podemos escrevê-lo como combinação linear dos $a$ e $d$:
$$
1 = sa + td,\qquad\text{para alguns $s,t\in\ints$}.
$$
Multiplicando por $b$, ganhamos
$$
b = sab + tdb,
$$
e argumentando como na demonstração do~\ref[euclid_lemma]
concluimos que $d \divides b$.

%%}}}

%%{{{ cor: product_of_coprimes_divides_common_multiple 
\corollary.
%%%{{{ meta 
\label product_of_coprimes_divides_common_multiple
%%%}}}

Se $a \divides m$, $b \divides m$, e $\gcd a b = 1$, então $ab \divides m$.

\proof.
Como $a \divides m$, temos $m = au$ para algum $u\in\ints$.
Mas $b \divides m=au$, e como $\gcd b a = 1$, temos $b \divides u$
(por~\ref[lemma_euclides_coprime_version]).
Então $bv = u$ para algum $v\in\ints$.
Substituindo, $m = au = a(bv) = (ab)v$, ou seja, $ab \divides m$.

%%}}}

%%{{{ thm: primes_is_infinite 
\theorem Euclid.
%%%{{{ meta 
\label primes_is_infinite
\credits
    * Euclid : infinidade de primos
    ;;
\indexes
    * infinidade!de primos
    * infinito      seealso: infinidade
    ;;
%%%}}}

Existe uma infinidade de primos.

\sketch.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$, considere o número
$p_1\dotsb p_n + 1$ e use-o para achar um primo fora do $P$.

\proof.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$,
observe que o número $p=p_1\dotsb p_n + 1$ não é divisível por nenhum dos $p_i$'s
(porque $p_i \divides p$ e $p_i \divides p_1\dotsb p_n$ implicam
$p \divides 1$, absurdo).
Então, como $p\geq 2$, ou o $p$ é primo e $p\not\in P$,
ou $p$ é divisível por algum primo $q \not\in P$
(por~\ref[every_composite_number_is_divisible_by_a_prime]).
Nos dois casos, existe pelo menos um primo fora do $P$.

%%}}}

%%{{{ x: pq|n² ⇒ pq|n 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para quaisquer primos distintos $p,q$,
$$
pq \divides n^2  \implies  pq \divides n.
$$

\hint
Tá certo.  Demonstre.

\hint
Temos $p,q$ primos distintos e logo coprimos e logo o
\ref[product_of_coprimes_divides_common_multiple] ajuda.

\solution
Como $p \divides pq$ e $pq \divides n^2$, logo $p \divides n^2$.
Ou seja $p \divides n$\fact1 pelo \ref[euclid_lemma].
Similarmente $q \divides n$\fact2.
Mas $p,q$ são primos distintos, logo coprimos, e
ambos dividem o $n$ (\byfact1 e \byfact2)
logo $pq \divides n$
(pelo \ref[product_of_coprimes_divides_common_multiple]).

%%}}}

\endsection
%%}}}

%%{{{ The_Euclidean_algorithm 
\section O algoritmo de Euclides.
%%%{{{ meta 
\label The_euclidean_algorithm
%%%}}}

%%{{{ Idea 
\note Idéia.
%%%{{{ meta 
%%%}}}

Sejam $a,b$ inteiros positivos.
Como achamos o $\gcd a b$?
Nos vamos aplicar o lemma da divisão~(\reftag[euclidean_division]) repetetivamente,
até chegar em resto $0$:
$$
\matrix
\format
\r\;    &\;\c\;  & \; \c \;                   & \l      & \;\c\; & \c      & \qquad\qquad\l          \\
a       &   =    & b                          & q_0     &  +     & r_0,    & 0\leq r_0 < b           \\
b       &   =    & r_0                        & q_1     &  +     & r_1,    & 0\leq r_1 < r_0         \\
r_0     &   =    & r_1                        & q_2     &  +     & r_2,    & 0\leq r_2 < r_1         \\
r_1     &   =    & r_2                        & q_3     &  +     & r_3,    & 0\leq r_3 < r_2         \\
        & \vdots &                            &         &        &         & \hfil\vdots\hfil        \\
r_{n-3} &   =    & r_{n-2}                    & q_{n-1} &  +     & r_{n-1},& 0\leq r_{n-1} < r_{n-2} \\
r_{n-2} &   =    & \boxed{\mathstrut r_{n-1}} & q_n     &  +     & \mubrace {r_n} {0},     & 0 = r_n < r_{n-1}.      
\endmatrix
$$
O $\gcd a b$ estará na posição marcada acima.
Vamos agora descrever o algoritmo formalmente, e demonstrar
(informalmente e formalmente) sua corretude!

%%}}}

%%{{{ algorithm: euclidean_algorithm 
\algorithm Algoritmo de Euclides.
%%%{{{ meta 
\headerize
\label euclidean_algorithm
\credits
    * Euclid : algoritmo
    ;;
\defines
    * algoritmo!de Euclides
    ;;
%%%}}}

% TODO: XXX: URGENT: fix this!
\eop\noi\centerline{$\euclid(a,b)$}
{\hrule width \hsize height 1pt\relax}
\vskip4pt
\algospec
 INPUT: $a,b\in\nats$
OUTPUT: $\gcd a b$
\endspec
\elist:
\li: Se $b=0$, retorna $a$.
\li: Retorna $\euclid(b,r)$, onde $r = a \bmod b$.
\endelist
{\hrule width \hsize height 1pt\relax}

%%}}}

%%{{{ eg: euclidean_algorithm_example 
\example.
%%%{{{ meta 
\label euclidean_algorithm_example
%%%}}}

Ache o $\gcd {101} {73}$ com o algoritmo de Euclides.

\solution.
Sabendo que os dois números são primos, fica imediato que eles são coprimos
entre si também: a reposta é 1.
\eop
Aplicando o algoritmo de Euclides, para achar o $\gcd {101} {73}$, dividimos o $101$ por $73$:
$$
\alignat 2
101 &= 73       \ntimes \tubrace {\phantom 1} {quociente} + \tubrace {\phantom{28}} {resto},      &\qquad&0 \leq \tubrace {\phantom{28}} {resto} < 73
\intertext{e sabemos que assim reduziremos o problema para o alvo de achar o $\gcd {73} {\text{resto}}$.  Pensando, achamos os valores:}
101 &= 73       \ntimes \tubrace {1} {quociente} + \tubrace {28} {resto},      &\quad&0 \leq \tubrace {28} {resto} < 73 
\intertext{ou seja, $\gcd {101} {73} = \gcd {73} {28}$.  Então, repetimos:}
73  &= 28       \ntimes \tubrace {2} {quociente} + \tubrace {17} {resto},      &&0 \leq \tubrace {17} {resto} < 28
\intertext{ou seja, $\gcd {73} {28} = \gcd {28} {17}$.  Repetimos:}
28  &= 17       \ntimes \tubrace {1} {quociente} + \tubrace {11} {resto},      &&0 \leq \tubrace {11} {resto} < 17
\intertext{ou seja, $\gcd {28} {17} = \gcd {17} {11}$.  Repetimos:}
17  &= 11       \ntimes \tubrace {1} {quociente} + \tubrace {6}  {resto},      &&0 \leq \tubrace {6} {resto} < 11
\intertext{ou seja, $\gcd {17} {11} = \gcd {11} 6$.  Repetimos:}
11  &= 6        \ntimes \tubrace {1} {quociente} + \tubrace {5}  {resto},      &&0 \leq \tubrace {5} {resto} < 6
\intertext{ou seja, $\gcd {11} 6 = \gcd 6 5$.  Repetimos:}
6   &= 5        \ntimes \tubrace {1} {quociente} + \tubrace {1}  {resto},      &&0 \leq \tubrace {1} {resto} < 5
\intertext{ou seja, $\gcd 6 5 = \gcd 5 1$.  Como $\gcd 5 1 = 1$, nem precisamos repetir, mas vamos mesmo assim:}
5   &= \boxed 1 \ntimes \tubrace {5} {quociente} + \tubrace {0} {resto}.      &&
\endalignat
$$
Mais compactamente, os passos são:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l  & \c     & \c & \c       & \c & \c    & \c & \c     & \r            & \c    & \l          \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28, & \qquad & 0  & {}\leq{} & 28 & {}<{} & 73 & \qquad & \gcd{101}{73} & {}={} & \gcd{73}{28}\\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17, &        & 0  & {}\leq{} & 17 & {}<{} & 28 &        & \gcd{73 }{28} & {}={} & \gcd{28}{17}\\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11, &        & 0  & {}\leq{} & 11 & {}<{} & 17 &        & \gcd{28 }{17} & {}={} & \gcd{17}{11}\\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6,  &        & 0  & {}\leq{} & 6  & {}<{} & 11 &        & \gcd{17 }{11} & {}={} & \gcd{11}{6 }\\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5,  &        & 0  & {}\leq{} & 5  & {}<{} & 6  &        & \gcd{11 }{6 } & {}={} & \gcd{6 }{5 }\\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1,  &        & 0  & {}\leq{} & 1  & {}<{} & 5  &        & \gcd{6  }{5 } & {}={} & \gcd{5 }{1 }\\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0   &        &    &          &    &       &    &        & \gcd{5  }{1 } & {}={} & \gcd{1 }{0 } = \boxed 1.
\endmatrix
$$
Pronto: $\gcd {101} {73} = 1$.

%%}}}

%%{{{ remark: using euclidean_algorithm for gcd of ints 
\remark.
%%%{{{ meta 
%%%}}}

Podemos utilizar o algoritmo de Euclides para achar o $\gcd a b$
onde $a,b\in\ints$ também,
graças ao~\ref[gcd_signs]:
$(a,b) = (\abs a, \abs b) = \euclid(\abs a, \abs b)$.

%%}}}

%%{{{ x: find_a_couple_of_gcds 
\exercise.
%%%{{{ meta 
\label find_a_couple_of_gcds
%%%}}}

Usando o algoritmo de Euclides, ache os:
(i) $\gcd {108} {174}$; 
(ii) $\gcd {2016} {305}$.

\solution
(i) Para o $\gcd {108} {174} = \gcd {174} {108}$ calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l    & \c     & \c & \c       & \c & \c    & \c & \c     & \r             & \c    & \l            \\
174 & {}={} & 108      & {}\ntimes{} & 1  & {}+{} &{66},  & \qquad & 0  & {}\leq{} & 66 & {}<{} & 108& \qquad & \gcd{174}{108} & {}={} & \gcd{108}{66 }\\
108 & {}={} & 66       & {}\ntimes{} & 1  & {}+{} &{42},  &        & 0  & {}\leq{} & 42 & {}<{} & 66 &        &                & {}={} & \gcd{66 }{42 }\\
66  & {}={} & 42       & {}\ntimes{} & 1  & {}+{} &{24},  &        & 0  & {}\leq{} & 24 & {}<{} & 42 &        &                & {}={} & \gcd{42 }{24 }\\
42  & {}={} & 24       & {}\ntimes{} & 1  & {}+{} &{18},  &        & 0  & {}\leq{} & 18 & {}<{} & 24 &        &                & {}={} & \gcd{24 }{18 }\\
24  & {}={} & 18       & {}\ntimes{} & 1  & {}+{} &{6 },  &        & 0  & {}\leq{} & 6  & {}<{} & 18 &        &                & {}={} & \gcd{18 }{6  }\\
18  & {}={} & \boxed 6 & {}\ntimes{} & 3  & {}+{} &{0 }   &        &    &          &    &       &    &        &                & {}={} & \gcd{6  }{0  } = \boxed 6.
\endmatrix
$$
\eop
\noi
(ii) Calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
2016& {}={} & 305      & {}\ntimes{} & 6  & {}+{} &{186},  & \qquad & 0  & {}\leq{} &186 & {}<{} &305 & \qquad & \gcd{2016}{305} & {}={} & \gcd{305}{186}\\
305 & {}={} & 186      & {}\ntimes{} & 1  & {}+{} &{119},  &        & 0  & {}\leq{} &119 & {}<{} &186 &        &                 & {}={} & \gcd{186}{119}\\
186 & {}={} & 119      & {}\ntimes{} & 1  & {}+{} &{67 },  &        & 0  & {}\leq{} &67  & {}<{} &119 &        &                 & {}={} & \gcd{119}{67 }\\
119 & {}={} & 67       & {}\ntimes{} & 1  & {}+{} &{52 },  &        & 0  & {}\leq{} &52  & {}<{} &67  &        &                 & {}={} & \gcd{67 }{52 }\\
67  & {}={} & 52       & {}\ntimes{} & 1  & {}+{} &{15 },  &        & 0  & {}\leq{} &15  & {}<{} &52  &        &                 & {}={} & \gcd{52 }{15 }\\
52  & {}={} & 15       & {}\ntimes{} & 3  & {}+{} &{7  },  &        & 0  & {}\leq{} &7   & {}<{} &15  &        &                 & {}={} & \gcd{15 }{7  }\\
15  & {}={} & 7        & {}\ntimes{} & 2  & {}+{} &{1  },  &        & 0  & {}\leq{} &1   & {}<{} &7   &        &                 & {}={} & \gcd{7  }{1  }\\
7   & {}={} & \boxed 1 & {}\ntimes{} & 7  & {}+{} &{0  }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{1  }{0  } = \boxed 1.
\endmatrix
$$
%$$
%\matrix
%\format
%\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  & \qquad & 0  & {}\leq{} &    & {}<{} &    & \qquad & \gcd{    }{   } & {}={} & \gcd{   }{   }\\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  &        & 0  & {}\leq{} &    & {}<{} &    &        &                 & {}={} & \gcd{   }{   }\\
%    & {}={} & \boxed 1 & {}\ntimes{} &    & {}+{} &{   }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{   }{   } = .
%\endmatrix
%$$

%%}}}

%%{{{ codeit: implement_euclidean_algorithm 
\codeit.
%%%{{{ meta 
\label implement_euclidean_algorithm
%%%}}}

Implemente o algoritmo de Euclides e verifique tuas soluções nos exercícios anteriores.

%%}}}

%%{{{ codeit: implement_verbose_euclidean_algorithm 
\codeit.
%%%{{{ meta 
\label implement_verbose_euclidean_algorithm
%%%}}}

Implemente um modo ``verbose'' no teu programa
do~\ref[implement_euclidean_algorithm],
onde ele mostra todas as equações e desigualdades, e não apenas o resultado final.

%%}}}

%%{{{ lemma: euclid_gcd_lemma 
\lemma Euclides.
%%%{{{ meta 
\label euclid_gcd_lemma
\credits
    * Euclid : lemma de mdc
    ;;
\indexes
    * mdc!lemma
    ;;
%%%}}}

Se $a,b\in\ints$ com $b > 0$, então $\gcd a b = \gcd b r$,
onde $r$ o resto da divisão de $a$ por $b$.

\wrongproof.
Dividindo o $a$ por $b$, temos $a = bq + r$.
Vamos mostrar que qualquer inteiro $d$ satisfaz a equivalência:
$$
\align
d \divides a
\mland
d \divides b
&\iff
d \divides b
\mland
d \divides r.\\
\intertext{Realmente, usando as propriedades~\reftag[divides_properties], temos:}
d \divides a
\mland
d \divides b
&\implies
d \divides \mobrace {a - bq} {\dsize r}\\
d \divides \mubrace {bq + r} {\dsize a}
&\impliedby
d \divides b
\mland
d \divides r.
\endalign
$$
Isso mostra que os divisores em comum dos $a$ e $b$, e dos $b$ e $r$ são os mesmos,
ou, formalmente:
$$
\setst {c\in\ints} {c \divides a \mland c \divides b}
=
\setst {c\in\ints} {c \divides b \mland c \divides r}.
$$
Logo,
\compute
\gcd a b
&= \max\setst {c\in\ints} {c \divides a \mland c \divides b}  \by {def.~$\gcd a b$} \\
&= \max\setst {c\in\ints} {c \divides b \mland c \divides r}  \by {demonstrado acima} \\
&= \gcd b r                                                 \by {def.~$\gcd b r$} \\
\endcompute
que mostra a corretude do algoritmo.

%%}}}

%%{{{ x: what_is_the_problem_with_euclid_gcd_lemma 
\exercise.
%%%{{{ meta 
\label what_is_the_problem_with_euclid_gcd_lemma
%%%}}}

Qual é o problema com a prova do~\ref[euclid_gcd_lemma]?

\solution
A definição do maior divisor comum $(a,b)$ não foi
``o maior divisor comum dos $a$ e $b$''.
Lembre-se a~\ref[gcd].
Veja também o~\ref[gcd_alternative_definition].

%%}}}

%%{{{ thm: euclidean_algorithm_correctness 
\theorem Corretude do \sayname{algorithm} de Euclides.
%%%{{{ meta 
\label euclidean_algorithm_correctness
%%%}}}

O~\ref[euclidean_algorithm] é correto.

\sketch.
Precisamos demonstrar duas coisas: \emph{terminação\/}\/ e \emph{corretude}.
\eop
\proofstylize{Corretude.}
Se o algoritmo precisou $n$ passos, temos que verificar:
Temos
$$
\gcd a b
= \gcd b {r_0}
= \gcd {r_0} {r_1}
= \gcd {r_1} {r_2}
= \dotsb
= \gcd {r_{n-1}} {r_n}
= \gcd {r_n} 0
= r_n.
$$
Todas as igualdades exceto a última seguem por causa do~\ref[euclid_gcd_lemma];
a última por causa da~\ref[gcd_of_comparable].
\eop
\proofstylize{Terminação.}
Note que a seqüência de restos $r_0, r_1, \ldots$ é estritamente
decrescente, e todos os seus termos são não negativos:
$$
0\leq \dotsb < r_2 < r_1 < r_0 < b.
$$
Logo, essa seqüência não pode ser infinita.
Realmente, o tamanho dela não pode ser maior que $b$,
então depois de no máximo $b$ passos, o algorítmo terminará.

\proof.
Demonstrado no \ref[euclidean_algorithm_correctness_formal_proof_by_induction]
por indução e no \reftag[euclidean_algorithm_correctness_formal_proof_by_wop]
pelo princípio da boa ordem.

%%}}}

%%{{{ x: euclidean_algorithm_proof_why_informal 
\exercise.
%%%{{{ meta 
\label euclidean_algorithm_proof_why_informal
%%%}}}

Explique por que as argumentações acima
(\reftag[euclidean_algorithm_correctness])
tanto de corretude quanto de terminação
são \emph{esboços} mesmo e não demonstrações.

\hint
${}\dotsb{}$

\hint
${}\dotsb{}$

\solution
São os ``${}\dotsb{}$'' mesmo!
Para formalizá-los em definições usamos recursão;
pra formalizá-los em demonstrações usamos indução.

%%}}}

%%{{{ How do we find the coefs of the linear combination 
\note.
%%%{{{ meta 
%%%}}}

Nós já demonstramos que o m.d.c.~de dois inteiros $a$ e $b$
pode ser escrito como uma combinação linear deles, mas como podemos
realmente \emph{achar}\/ inteiros $s,t\in\ints$ que satisfazem a
$$
\gcd a b = as + bt,     \qquad s,t\in\ints?
$$
Surpresamente a resposta já está ``escondida'' no mesmo algoritmo de Euclides!

%%}}}

%%{{{ algorithm: extended_euclidean_algorithm 
\algorithm Algoritmo estendido de Euclides.
%%%{{{ meta 
\label extended_euclidean_algorithm
\credits
    * Euclid : algoritmo estendido
    ;;
\defines
    * algoritmo!estendido de Euclides
    ;;
%%%}}}

% TODO: XXX: URGENT: fix this 
\algospec
 INPUT: $a,b\in\ints$, $b>0$
OUTPUT: $s,t\in\ints$ tais que $\gcd a b = as + bt$.
\endspec

%%}}}

%%{{{ eg: write_a_gcd_as_a_linear_combination 
\example.
%%%{{{ meta 
\label write_a_gcd_as_a_linear_combination
%%%}}}

Escreva o $\gcd {101} {73}$ como combinação linear dos $101$ e $73$.

\solution.
Primeiramente, precisamos aplicar o algoritmo de Euclides para achar o m.d.c.,
como no~\ref[euclidean_algorithm_example],
mas vamos também resolver cada equação por o seu resto:
$$
\matrix
\format
\r  & \c    & \c       & \l          & \l & \c    & \l & \c           & \r & \c    & \c & \c    &\c & \c         & \c  \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28 & \qquad\qquad &28  & {}={} &101 & {}-{} &   &{}       {} & 73 \\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17 &              &17  & {}={} &73  & {}-{} & 2 &{}\ntimes{} & 28 \\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11 &              &11  & {}={} &28  & {}-{} &   &{}       {} & 17 \\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6  &              &6   & {}={} &17  & {}-{} &   &{}       {} & 11 \\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5  &              &5   & {}={} &11  & {}-{} &   &{}       {} & 6  \\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1  &              &1   & {}={} &6   & {}-{} &   &{}       {} & 5  \\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0. &              &    &       &    &       &    &          &     \\
\endmatrix
$$
Utilizando as equações no lado direto, de baixo para cima, calculamos:
$$
\def\hl{\underline}
\alignat 2
1 &= \hl6 - \hl5                                           &\quad&\text{(6 e 5)   }\\
  &= \hl6 - (\hl{11} - \hl6)
   = \hl6 - \hl{11} + \hl6
   = -\hl{11} + 2\ntimes \hl6                                   &&\text{(11 e 6)  }\\
  &= -\hl{11} + 2\ntimes (\hl{17} - \hl{11})
   = -\hl{11} + 2\ntimes \hl{17} - 2\ntimes \hl{11}
   = 2\ntimes \hl{17} - 3\ntimes \hl{11}                        &&\text{(17 e 11) }\\
  &= 2\ntimes \hl{17} - 3\ntimes (\hl{28} - \hl{17})
   = 2\ntimes \hl{17} - 3\ntimes \hl{28} + 3\ntimes 17
   = -3\ntimes \hl{28} + 5\ntimes \hl{17}                       &&\text{(28 e 17) }\\
  &= -3\ntimes \hl{28} + 5\ntimes (\hl{73} - 2\ntimes \hl{28})
   = -3\ntimes \hl{28} + 5\ntimes \hl{73} - 10\ntimes \hl{28}
   = 5\ntimes \hl{73} -13\ntimes \hl{28}                        &&\text{(73 e 28) }\\
  &= 5\ntimes \hl{73} -13\ntimes (\hl{101} - \hl{73})
   = 5\ntimes \hl{73} -13\ntimes \hl{101} + 13\ntimes \hl{73}
   = -13\ntimes \hl{101} + 18\ntimes \hl{73}                    &&\text{(101 e 73)}
\endalignat
$$
No lado direto mostramos nosso progresso, no sentido de ter conseguido
escrever o m.d.c.~como combinação linear de quais dois números.
Sublinhamos os inteiros que nos interessam para não perder nosso foco.
Em cada nova linha, escolhemos o menor dos dois números sublinhados,
e o substituimos por a combinação linear que temos graças ao algoritmo de Euclides.
Obviamente, essa notação e metodologia não tem nenhum sentido matematicamente
falando.  Serve apenas para ajudar nossos olhos humanos.
\eop
Achamos então $s,t\in\ints$ que satisfazem a equação $1 = sa + tb$:
são os $s = -13$ e $t = 18$.

%%}}}

%%{{{ x: more_gcds_as_linear_combinations 
\exercise.
%%%{{{ meta 
\label more_gcds_as_linear_combinations
%%%}}}

Usando o algoritmo estendido de Euclides, escreve:
(i) o $\gcd {108} {174}$ como combinação linear dos 108 e 174; 
(ii) o $\gcd {2016} {305}$ como combinação linear dos 2016 e 305.

%%}}}

%%{{{ diophantine_equations 
\note Equações de Diophantus.
%%%{{{ meta 
%%%}}}

\TODO escrever e posicionar.

%%}}}

%%{{{ Steps in Euclid's algorithm 
\note Passos do algoritmo de Euclides.
%%%{{{ meta 
%%%}}}

Para demonstrar a terminação do algoritmo de Euclides
estabelecemos uma garantia que o $\euclid(a,b)$ depois
$b$ passos no máximo termina.
Como o exercício seguinte mostra, o algoritmo de Euclides
é \emph{bem mais eficiente} do que isso:
depois dois passos, as duas entradas, nos piores dos casos,
são reduzidas à metade!

%%}}}

%%{{{ x: less_steps_in_euclid
\exercise.
%%%{{{ meta 
\label less_steps_in_euclid
%%%}}}

Se $a \geq b$, então $r < a/2$, onde $r$ o resto da divisão de $a$ por $b$.

\hint
Separe os casos: ou $b > a/2$ ou $b \leq a/2$.

\hint
Qual seria o resto em cado caso?

\hint
Num caso, dá para achar exatamente o resto.
No outro, use a restricção que o resto satisfaz.

\solution
\case{Caso $b > a/2$:}
Então $r = a-b < a/2$.
\case{Caso $b < a/2$:}
Então $r < b < a/2$.

%%}}}

%%{{{ Q: How efficient is Euclid's algorithm? 
\question.

Quão eficiente é o algoritmo de Euclides?

%%}}}

\spoiler

\TODO Sobre eficiência, operações primitivas, oráculos.

%%{{{ lemma: euclid_algorithm_efficiency 
\lemma.
%%%{{{ meta 
\label euclid_algorithm_efficiency
%%%}}}

\TODO Eficiência de Euclides.

%%}}}

%%{{{ x: euclid_vs_fibonacci 
\exercise Euclides \vs Fibonacci.
%%%{{{ meta 
\label euclid_vs_fibonacci
%%%}}}

Para todo $n\geq1$ e quaisquer inteiros $a > b > 0$,
se $\euclid(a,b)$ precisa $n$ passos (divisões) para terminar,
então $a \geq F_{n+2}$ e $b \geq F_{n+1}$, onde $F_i$ é o $i$-ésimo
número Fibonacci.

\hint
Indução.

\hint
$x>y \implies \quot(x,y) \geq 1$.

\solution
Por indução.
\proofpart{Base.}
Sejam inteiros $a > b > 0$
tais que $\euclid(a,b)$ precisa $1$ passo para terminar:
Precisamos inferir que $a \geq F_3 = 2$ e $b \geq F_2 = 1$,
imediato pois $a > b > 0$.
\proofpart{Passo indutivo.}
Seja $k \geq 1$ tal que para quaisquer inteiros $u > v > 0$,
se $\euclid(u,v)$ precisa $k$ passos (divisões) para terminar,
emtão $u \geq F_{k+2}$ e $v \geq F_{k+1}$:
$$
\lforall {u > v > 0} {\text{$\euclid(u,v)$ termina em $k$ passos} \implies u \geq F_{k+2} \mland v \geq F_{k+1}}.
\tag{HI}
$$
Sejam inteiros $a > b > 0$ tais que $\euclid(a,b)$ termina em $k+1$ passos.
Executamos o primeiro desses passos, obtendo os $q_0, r_0$:
$$
\matrix
\format
\r\;    &\;\c\;  & \; \c \;                   & \l      & \;\c\; & \c      & \qquad\qquad\l          \\
a       &   =    & b                          & q_0     &  +     & r_0,    & 0\leq r_0 < b           \\
\endmatrix
$$
Agora em $k$ passos o algoritmo terminará, mas neste ponto o algoritmo
manda executar o $\euclid(b,r_0)$.  Ou seja o $\euclid(b,r_0)$ precisa
$k$ passos, e $b > r_0 > 0$, e logo pela HI com $u \asseq b$ e $v \asseq r_0$
inferimos:
$$
b \geq F_{k+2}
\qqquad
r_0 \geq F_{k+1}.
\tag{HI*}
$$
Calculamos:
\compute
a &=    bq_0 + r_0                  \\
  &\geq F_{k+2} q_0 + F_{k+1}       \by {HI*} \\
  &\geq F_{k+2} \stimes 1 + F_{k+1} \by {$q_0 \geq 1$ pois $a>b$} \\
  &=    F_{k+2} + F_{k+1}           \\
  &=    F_{k+3}.                    \by {def.~$F_{k+3}$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ The_fundamental_theorem_of_arithmetic 
\section O teorema fundamental da aritmética.
%%%{{{ meta 
\label The_fundamental_theorem_of_arithmetic
%%%}}}

%%{{{ thm: fundamental_theorem_of_arithmetic 
\theorem Teorema fundamental da aritmética.
%%%{{{ meta 
\aka fatorização única.
\headerize
\label fundamental_theorem_of_arithmetic
\indexes
    * teorema!fatorização única    see: fundamental da aritmética
    * teorema!fundamental da aritmética
    * indução!forte
    ;;
\credits
    * Gauss
    * Euclid
    ;;
%%%}}}

Todo $n\in\nats$ com $n > 1$, pode ser escrito como um produtório de primos.
Essa expressão é única se desconsiderar a ordem dos fatores do produtório.

\proof.
Seja $n\in\nats$ com $n > 1$.
\eop
\proofstylize{Existência:}
Usamos indução forte (veja~\reftag[Strong_induction]).
Caso que $n$ seja primo,
trivialmente ele mesmo é o produtório de primos (produtório de tamanho 1).
Caso contrário, $n = ab$, para uns $a,b\in\nats$ com $1<a<n$ e $1<b<n$,
logo sabemos (hipoteses indutivas) que cada um deles pode ser
escrito na forma desejada:
$$
\alignat 2
a &= p_1p_2\dotsb p_{k_a},          &\quad& \text{para alguns $p_i$'s primos;}\\
b &= q_1q_2\dotsb q_{k_b},          &\quad& \text{para alguns $q_j$'s primos.}
\endalignat
$$
Então temos
$$
n = ab = (p_1p_2\dotsb p_{k_a})(q_1q_2\dotsb )
       = p_1p_2\dotsb p_{k_a}q_1q_2\dotsb q_{k_b}
$$
que realmente é um produtório de primos.
\eop
\proofstylize{Unicidade:}
Suponha que para alguns primos $p_i$'s e $q_j$'s, e uns $s,t\in\nats$, temos:
$$
\align
n &= p_1 p_2 \dotsc p_s,\\
n &= q_1 q_2 \dotsc q_t.
\endalign
$$
Vamos mostrar que $s = t$ e que para todo $i\in\set{1,\dotsc,s}$,  $p_i = q_j$.
Temos
$$
p_1 p_2 \dotsc p_s = q_1 q_2 \dotsc q_t,
$$
e $p_1$ é primo que divide o lado esquerdo, então divide também o lado direito:
$$
p_1 \divides q_1 q_2 \dotsc q_t.
$$
Pelo \ref[euclid_lemma], $p_1\divides q_{j_1}$ para algum $j_1$.
Mas o $q_{j_1}$, sendo um dos $q_j$'s, também é primo.
Logo $p_1 = q_{j_1}$ (veja~\ref[in_primes_divides_means_equals]).
Cancelando o $p_1$, temos:
$$
p_2 \dotsc p_s = q_1 q_2 \dotsc q_{j_1 - 1} q_{j_1 + 1} q_t,
$$
Agora repetimos até um dos dois lados não ter mais fatores primos.
Necessariamente, isso vai acontecer ``simultaneamente'' nos dois lados
(caso contrário teriamos um produtório
de primos igual com 1, impossível), ou seja: $s = t$.
Note que as equações $p_i = q_{j_i}$ mostram a unicidade desejada.

%%}}}

\TODO Gauss, Euclides.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Graças ao teorema fundamental da aritmética podemos definir a:

%%}}}

%%{{{ df: canonical_representation_of_ints 
\definition Representação canônica de inteiros.
%%%{{{ meta 
\label canonical_representation_of_ints
\defines
    * representação canônica!de inteiro
    ;;
%%%}}}

Seja $0\neq n\in\ints$.
Sua \dterm{representação canônica} é o produtório
$$
n =
(\pm 1)
\Prod_{i=1}^k
p_i^{a_i}
=
(\pm 1)
p_1^{a_1}
p_2^{a_2}
\dotsb
p_k^{a_k},
$$
onde os $p_1 < p_2 < \cdots < p_k$'s são primos, e $a_i\in\nats_{>0}$ para $i=1,\dotsc,k$.
\eop
Observe que se relaxar a restricção nos exponentes tal que $a_i\in\nats$,
cada $n\in\ints$ ($n\neq 0$) pode ser representado (também únicamente) como o produtório
$$
n =
(\pm 1)
\Prod_{i=0}^k
p_i^{a_i}
=
(\pm 1)
p_0^{a_0}
p_1^{a_1}
\dotsb
p_k^{a_k},
$$
onde agora os $p_0 < p_1 < \cdots < p_k$ são \emph{todos os $k+1$ primeiros primos},
sendo então $p_0 = 2$, e $p_k$ o maior primo divisor do $n$.
Chamamos essa forma a \dterm{representação canônica completa} do $n$.
(Veja também o~\ref[encoding_of_finite_sequences].)

%%}}}

%%{{{ x: canonical_representation_with_int_exponents 
\exercise.
%%%{{{ meta 
\label canonical_representation_with_int_exponents
%%%}}}

O que acontece se relaxar a restricção nos exponentes ainda mais?:
$a_i\in\ints$.

%%}}}

\endsection
%%}}}

%%{{{ Expansions_and_positional_systems 
\section Expansão e sistemas posicionais.
%%%{{{ meta 
\label Expansions_and_positional_systems
%%%}}}

%%{{{ intro 
\secintro
Até agora temos usado os numerais que conheçemos desde crianças
para referir aos números inteiros.  Considerei dado que tu já
sabes todos esses (infinitos!)~nomes de números, e que tu entendes
como interpretar e \dq{como funciona} esse sistema de numerais.
Mas suponha que um ser alienígeno que usa um sistema de numerais
completamente diferente do nosso acha difícil acreditar que nosso
sistema funciona mesmo:  \utter{Como vós sabeis\foot
os alienigenos conjugam até no segundo plural, pelo jeito\dots
\toof
que não tem números inteiros sem numeral?}
Nesta secção estudamos esse sistema, respondemos nessa e em mais
perguntas, e encontramos outros sistemas posicionais de numerais.
%%}}}

%%{{{ thm: expansion_in_base 
\theorem expansão em base.
%%%{{{ meta 
\label expansion_in_base
\indexes
    * teorema!expansão em base
    ;;
%%%}}}

Seja $b \geq 2$.
Todo inteiro $x \geq 0$ tem uma única expansão em base $b$:
existem únicos $m, d_0, \dotsc, d_m$ tais que:
$$
x = d_m b^m + \dotsb + d_1 b^1 + d_0 b^0
$$
onde:
\tlist:
\li  (i): para todo $i \in \set{0,\dotsc,m}$, $d_i \in \set{0,\dotsc,b-1}$;
\li (ii): $d_m = 0 \implies m=0$.
\endtlist

%%}}}

%%{{{ Symbols for digits 
\note Símbolos para os dígitos e separadores de casas.
%%%{{{ meta 
%%%}}}

Para os sistemas posicionais com base $b \leq 10$ usamos os símbolos
$$
\mathtt 0, \mathtt 1, \mathtt 2, \mathtt 3, \mathtt 4,
\mathtt 5, \mathtt 6, \mathtt 7, \mathtt 8, \mathtt 9.
$$
como dígitos.
Quando a base $b$ é maior mas ainda $b \leq 36$ usamos os
$$
\mathtt A, \mathtt B, \mathtt C, \dotsc, \mathtt X, \mathtt Y, \mathtt Z
$$
com valores $10,11,12,\dots,33,34,35$ respectivamente.
O sistema mais usado com base $b>10$ é o \dterm{hexadecimal} com $b = 16$,
onde realmente usamos os dígitos
$$
\mathtt 0, \mathtt 1, \mathtt 2, \mathtt 3, \mathtt 4,
\mathtt 5, \mathtt 6, \mathtt 7, \mathtt 8, \mathtt 9,
\mathtt A, \mathtt B, \mathtt C, \mathtt D, \mathtt E, \mathtt F.
$$
Tendo estabelecido um sistema de numerais para os \emph{valores dos dígitos},
podemos simplesmente usar esses numerais sem se preocupar com os símbolos
dos dígitos para escrever numerais de outros sistemas.
Nesse caso separamos as casas com um símbolo novo (que não faz parte do
nosso sistema de numerais estabelecido) como separador:
usando o decimal escolhemos por exemplo o símbolo $:$ como separador
das casas e assim podemos escrever o número $151208$ no sistema
sexagesimal assim:
$$
42 : 0 : 8 = 42 \ntimes 60^2 + 0 \ntimes 60^1 + 8 \ntimes 60^0.
$$

%%}}}

%%{{{ remark: 0x_etc 
\remark.
%%%{{{ meta 
\label 0x_etc
%%%}}}

Muitas linguagens de programação usam o prefixo $\mathtt{0x}$ como indicação
que o numeral que segue é hexadecimal.  Similarmente o $\mathtt{0o}$ (ou simplesmente
um numeral que começa com $\mathtt 0$) indica octal, e o $\mathtt{0b}$ binário.
Por examplo $\mathtt{0x20}$ seria o numero $\numbase 16 {20}$, ou seja o $32$;
$\mathtt{0b100}$ seria o $\numbase 2 {100}$, ou seja o $4$, e $\mathtt{0750}$ ou $\mathtt{0o750}$ seria o $\numbase 8 {750}$, ou seja o $488$.
Essas são apenas convenções que certas linguagens seguem, então em forma geral
não conte com nenhuma delas (a mais estabelecida sendo a do $\mathtt{0x}$).

%%}}}

\TODO reescrever e terminar.

\TODO mencione mais non-standard positional systems: negabinary, complex-base, gray code.

%%{{{ x: negative_remainders 
\exercise.
%%%{{{ meta 
\label negative_remainders
%%%}}}

Demonstre que dado qualquer inteiro $a$, existem únicos inteiros $q$ e $r$
tais que $a = 3q + r$ e $-1\leq r \leq 1$.

\hint
Use a divisão de Euclides.

%%}}}

%%{{{ x: balanced_ternary 
\exercise Balanced ternary.
%%%{{{ meta 
\label balanced_ternary
\pdefs
    \pdef T {{\mathtt T}}
    \pdef O {{\mathtt O}}
    \pdef I {{\mathtt I}}
    ;;
%%%}}}

Para qualquer inteiro $x$ existem únicos $m,d_0,\dotsc,d_m$ tais que
$$
x = d_m 3^m + \dotsb + d_1 3^1 + d_0 3^0,
$$
onde:
\tlist:
\li  (i): para todo $i \in \set{0,\dotsc,m}$, $d_i \in \set{-1,0,1}$;
\li (ii): $d_m = 0 \implies m=0$.
\endtlist
Usando como digitos os símbolos $\T$, $\O$, $\I$ com valores $-1$, $0$, $1$ respectivamente
podemos então escrever qualquer inteiro sem sequer precisar um símbolo de sinal para os negativos.  Uns exemplos:
$$
\matrix
\format
\r\ &\;\c\;& \ \r\         &\c & \ \r\           &\c & \ \r\           &\c & \ \r\            &\quad\c\quad& \ \r     \\
0   &=     &               &   &                 &   &                 &   &    0 \ntimes 3^0 &\leadsto    & \O       \\
1   &=     &               &   &                 &   &                 &   &    1 \ntimes 3^0 &\leadsto    & \I       \\
7   &=     &               &   &   1 \ntimes 3^2 & + &(-1) \ntimes 3^1 & + &    1 \ntimes 3^0 &\leadsto    & \I\T\I   \\
-7  &=     &               &   &(-1) \ntimes 3^2 & + &   1 \ntimes 3^1 & + & (-1) \ntimes 3^0 &\leadsto    & \T\I\T   \\
26  &=     & 1 \ntimes 3^3 & + &   0 \ntimes 3^2 & + &   0 \ntimes 3^1 & + & (-1) \ntimes 3^0 &\leadsto    & \I\O\O\T \\
\endmatrix
$$

%%}}}

%%{{{ x: factorial_base_system_lemma 
\exercise.
%%%{{{ meta 
\label factorial_base_system_lemma
%%%}}}

Demonstre por indução que para todo $n \in \nats$,
$\quad\dsize\Sum\limits_{i=0}^n i \ntimes \factorial i = \factorialp {n+1} - 1$.

%%}}}

%%{{{ x: factorial_base_system 
\exercise.
%%%{{{ meta 
\label factorial_base_system
%%%}}}

Os sistemas posicionais de numerais que encontramos até agora usam um fixo conjunto de dígitos para cada posição.
Agora vamos encontrar um onde para cada posição $i$, podemos usar dígitos com valores nos $0,\dotsc,i$.
Na posição $0$ então temos apénas uma opção: o próprio $0$, e logo essa posição sempre tá ocupada por $0$.
Na posição $1$ já temos dois dígitos disponíveis, com valores $0$ e $1$.
Na posição $42$ temos quarenta e dois dígitos disponíveis; seus valores são: o $0$, o $1$, o $2$, \dots, o $40$, o $41$, e o $42$.
Cuidado, vamos usar aqui seus valores como dígitos, mesmo que no papel o $42$
que acabei de escrever dá a impressão que ele mesmo é composto por dois dígitos,
mas não é o caso aqui!
Por isso, usamos o $:$ para separarar ``as casas''.
O primeiro numeral em baixo seria válido, mas o segundo não
\mathcols 2
&4:0:2:2:0:0 &
&5:2:4:2:0:0
\endmathcols
pois na posição $3$ tem o $4>3$.
Novamente os valores dos dígitos vão acabar sendo coeficientes de algo que depende da posição e todos os termos serão somados.
Como sempre, escrevemos um número $x$ como
\mathcols 2
x & = d_n a_n + d_{n-1} a_{n-1} + \dotsb d_2 a_2 + d_1 a_1 + d_0 a_0  &
0 &\leq d_i \leq D_i
\endmathcols
onde $D_i$ denota o maior valor de dígito para a $i$-ésima posição.
Neste sistema temos:
\mathcols 3
a_i &= \factorial i    &
D_i &= i
\endmathcols
Demonstre que tal sistema ``funciona'':
cada inteiro pode ser escrito neste sistema numa única maneira.

%%}}}

\endsection
%%}}}

%%{{{ Open problems 
\section Problemas em aberto.
%%%{{{ meta 
\label Open_problems_in_number_theory
%%%}}}

%%{{{ Goldbach 
\note Goldbach.
%%%{{{ meta 
%%%}}}

No ano \yearof{1742} {\Goldbach}Goldbach comunicou para {\Euler}Euler
as conjecturas seguintes:

%%}}}

%%{{{ conjecture: weak_goldbach_conjecture 
\conjecture.
%%%{{{ meta 
\aka fraca de Goldbach.
\label weak_goldbach_conjecture
\credits
    * Goldbach : conjectura
    ;;
%%%}}}

Todo número maior que $5$ pode ser escrito como soma de três primos.

%%}}}

%%{{{ conjecture: goldbach_conjecture 
\conjecture Goldbach.
%%%{{{ meta 
\label goldbach_conjecture
\credits
    * Goldbach : conjectura
    ;;
%%%}}}

Todo número par maior que $2$ pode ser escrito como soma de dois primos.

%%}}}

%%{{{ Twin primes 
\note Primos gêmeos.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ conjecture: twin_primes_conjecture 
\conjecture Twin primes.
%%%{{{ meta 
\label twin_primes_conjecture
%%%}}}

Existe uma infinidade de primos gêmeos.

%%}}}

%%{{{ Legendre 
\note Legendre.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ conjecture: legendre_conjecture 
\conjecture Legendre.
%%%{{{ meta 
\label legendre_conjecture
\credits
    * Legendre : conjectura
    ;;
%%%}}}

{\Legendre}Para todo $n > 0$, existe primo entre $n^2$ e $(n+1)^2$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: p_divides_comb_p_r 
\problem.
%%%{{{ meta 
\label p_divides_comb_p_r
%%%}}}

Para todo $p$ primo, e todo $r\in\set{1,\dotsc,p-1}$,
$$
p \divides \comb p r.
$$
O que acontece se $r=0$ ou $r \geq p$?

\hint
$\comb p r \in\ints$, $r < p$, e $p-r < p$.

%%}}}

%%{{{ prob: implications_with_divisibility_of_linear_combinations_generalization 
\problem.
%%%{{{ meta 
\label implications_with_divisibility_of_linear_combinations_generalization
%%%}}}

(Generalização do~\ref[implications_with_divisibility_of_linear_combinations].)
Para quais $u,v\in\ints$, a afirmação
$$
a \divides b + c \mland a \divides ub + vc \implies a \divides xb + yc \quad \text{para todos $x,y\in\ints$}
$$
é válida?

%%}}}

%%{{{ prob: factorial_bound_for_prime 
\problem.
%%%{{{ meta 
\label factorial_bound_for_prime
%%%}}}

Seja $n\in\nats$, $n>1$.
Entre $n$ e $n!$ existe primo.

\hint
Olha para o $n!-1$.

\hint
Se $n!-1$ não é primo, toma um dos seus primos divisores, $p$.

\hint
Necessariamente $p > n$.

%%}}}

%%{{{ prob: n consecutive composite numbers 
\problem.
%%%{{{ meta 
%%%}}}

Seja $n\in\nats$.
Ache $n$ consecutivos números compostos.

\hint
$!$

\hint
$m!+2$.

\hint
$m!+3$\dots

\hint
$m!+m$.

%%}}}

%%{{{ gcd_alternative_definition 
\problem {Definição alternativa de m.d.c.}.
%%%{{{ meta 
\label gcd_alternative_definition
%%%}}}

Uma definição alternativa do m.d.c.~é a seguinte:
{\it Sejam $a,b\in\ints$.
O m.d.c.~dos $a$ e $b$ é o maior dos divisores em comum de $a$ e $b$.}
Ache um problema com essa definição, corrige-o, e depois compare
com a~\ref[gcd].

\hint
O que acontece se $a=b=0$?
O que acontece se pelo menos um dos $a$ e $b$ não é o $0$?

\solution
Se $a=b=0$, o símbolo $\gcd a b$ não é definido,
porque todo $n\in\nats$ é um divisor em comum,
mas como o $\nats$ não tem um elemento máximo,
não existe o maior deles.
\eop
Precisamos restringir a definição para ser aplicável
apenas nos casos onde pelo menos um dos $a$ e $b$
não é o $0$ (escrevemos isso curtamente: $ab\neq 0$).
Assim, quando a nova definição é aplicável, ela realmente
defina o mesmo número, fato que segue pelas propriedades:
$$
\align
\gcd x 0 = 0 &\implies x = 0\\
x \divides y \mland y \neq 0 &\implies \abs x \leq \abs y.
\endalign
$$

%%}}}

%%{{{ prob: partitioning_restricted_best_strategy_parallel 
\problem Contando os passos.
%%%{{{ meta 
\label partitioning_restricted_best_strategy_parallel
%%%}}}

O que muda no~\ref[partitioning_restricted_best_strategy]
se em cada passo podemos quebrar todos os termos que aparecem?
Qual é a melhor estratégia, e quantos passos são necessários?

\hint
Tente quebrar o $10$ usando várias estratégias.
O que tu percebes?

\hint
Qual é o maior termo e como ele muda depois cada passo?

\solution
Agora a estratégia ótima seria quebrar cada termo ``no meio''.
Assim, para o $10$ temos:
$$
\align
10 &= 5 + 5\\
   &= (2 + 3) + (2 + 3)\\
   &= [(1 + 1) + (1 + 2)] + [(1 + 1) + (1 + 2)]\\
   &= 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1
\endalign
$$
em apenas $4$ pássos.
Depois de cada passo, se o maior termo fosse o $m$, agora é o $\ceil {\frac m 2}$.
Precisamos tantos passos quantas vezes que podemos dividir o $n$ por $2$ até
chegar na unidade $1$: precisamos $\ceil {\log_2(n)}$ passos.

%%}}}

%%{{{ prob: WOP_iff_PFI 
\problem.
%%%{{{ meta 
\label WOP_iff_PFI
%%%}}}

$\text{PBO} \iff \text{PIF}$.

\hint
Nos já provamos a direção \lrdir.
Para demonstrar a \rldir, considere o predicado
``todos os conjuntos $A$ com $k\in A$ para algum natural $k\leq n$ têm mínimo'',
ou o ``todos os conjuntos $A$ com $n\in A$ têm mínimo''.

\hint
Demonstre que todos os naturais satisfazem o predicado que tu consideraste.
(Para um dos dois, tu precisará indução \emph{forte}.)

%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_induction 
\problem.
%%%{{{ meta 
\label euclidean_algorithm_correctness_formal_proof_by_induction
\pdefs
    \pdef euclid {{\algorithmstylize{Euclid}}}
    ;;
%%%}}}

Como tu percebeu resolvendo o~\ref[euclidean_algorithm_proof_why_informal],
nenhuma das duas partes do~\ref[euclidean_algorithm_correctness]
foi demonstrada mesmo.
Demonstre as duas partes usando indução.

\hint
Precisa expressar o alvo na forma $\lforall n {\phi(n)}$.

\hint
``\emph{Para todo $x\in\ints$, o $\euclid(x,n)$ termina com o resultado certo}.''

\hint
O que significaria $\phi(0)$?  $\phi(b)$?

\hint
Ser forte é coisa boa.

\solution
Seja
$$
\phi(n) \defiff \lforall {x\in\ints} {\text{$\euclid(x,n)$ termina com $\gcd x n$}}
$$
Vamos demonstrar que $\lforall {n\in\nats} {\phi(n)}$ por indução forte.
Seja $k\in\nats$ tal que $\phi(i)$ para todo $i<k$ (hipótese indutiva).
Precisamos demonstrar o $\phi(k)$, ou seja, que
\emph{para todo $x\in\ints$, $\euclid(x,k)$ termina e $\euclid(x,k) = \gcd x k$}.
Seja $x\in\ints$, e aplica o $\euclid(x,k)$ para um passo.
Se $k=0$, a computação termina imediatamente com o resultado $x$, que é correto
(\reftag[gcd_of_comparable]).
Se $k>0$, o algoritmo manda reduzir sua computação para a computação do $\euclid(k,r)$,
onde $r = x \bmod k < k$.
Seguindo o~\ref[euclid_gcd_lemma] $\gcd x k = \gcd k r$, então
falta verificar que o $\euclid(k,r)$ termina mesmo com $\gcd k r$,
que é verdade pela hipótese indutiva porque $r < k$ e logo $\phi(r)$ é válido.

%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_wop 
\problem.
%%%{{{ meta 
\label euclidean_algorithm_correctness_formal_proof_by_wop
%%%}}}

Demonstre as duas partes
do~\ref[euclidean_algorithm_correctness] usando o princípio da boa ordem.

\hint
Considera as duas partes separamente:
qual conjunto é o não vazio em cada parte?

\hint
Vai pelo absurdo.

\hint
O que seria um contraxemplo para cada parte?
\emph{O que acontece se existem contraexemplos?}

\hint
Sobre sua terminação:
Considere o menor $m$ tal que o $\euclid(x,m)$ não termina
para algum $x\in\ints$.

\hint
Sobre sua corretude:
Considere o menor $m$ tal que o $\euclid(x,m)$
termina com resultado errado par algum $x\in\ints$.
Mas mostre primeiro a terminação.

\solution
Provamos cada parte separamente:
\crtabproofpart{Terminação.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\euclid(a,c)$
não termina para algum $x\in\ints$.}
Seja $m$ o menor deles (PBO):
$$
m = \min\setst {c\in\nats} {\lexistst {x\in\ints} {$\euclid(x,c)$ não termina}}.
$$
Logo, para algum certo $a\in\ints$, temos que $\euclid(a,m)$ não termina.
Com certeza $m\neq 0$, porque nesse caso o algoritmo termina imediatamente.
Logo $m > 0$ e aplicando o $\euclid(a,m)$ para apenas um passo
a sua computação é reduzida no computação do $\euclid(m,r)$,
onde $r = a \bmod m < m$, \emph{e agora precisamos mostrar que o
$\euclid(m,r)$ termina para chegar num absurdo}.
Pela escolha do $m$ como \emph{mínimo} dos contraexemplos,
o $r$ não pode ser contraexemplo também.
Em outras palavras, o $\euclid(x,r)$ realmente termina para qualquer $x$,
então para $x=m$ também, que foi o que queriamos demonstrar.
\crtabproofpart{Corretude.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\euclid(x,c)$
acha resultado errado para algum $x\in\ints$.}
Seja $m$ o menor desses contraexemplos (PBO):
$$
m = \min\setst {c\in\nats} {\lexists {x\in\ints} {\euclid(x,c) \neq \gcd x c}}.
$$
Logo, para algum certo $a\in\ints$, temos $\euclid(a,m) \neq \gcd a m$.
Esse $m$ não pode ser $0$, porque nesse caso o algoritmo retorna sua primeira entrada $a$;
resultado correto por causa do~\ref[gcd_of_comparable].
Então $m>0$.
Aplicamos para um passo o $\euclid(a,m)$.
Como $m\neq 0$, o algoritmo manda realizar o segundo passo:
retornar o que $\euclid(m,r)$, onde $r = a \bmod m < m$.
(E sabemos que o $\euclid(m,r)$ vai retornar algo, porque
já provamos a terminação do algoritmo para todas as suas possíveis entradas!)
Para concluir, observe:
\compute
\euclid(m,r) 
&= \euclid(a,m)     \by {pelas instruções do algoritmo} \\
&\neq \gcd a m      \by {escolha dos $m$ e $a$} \\
&= \gcd m r.        \by {pelo~\ref[euclid_gcd_lemma]} \\
\endcompute
Então $\euclid(m,r) \neq \gcd m r$ e achamos um contraexemplo (o $r$)
menor que o mínimo (o $m$)---absurdo!

%%}}}

%%{{{ prob: encoding_of_finite_sequences 
\problem Codificação de seqüências finitas.
%%%{{{ meta 
\label encoding_of_finite_sequences
%%%}}}

Seja $S$ o conjunto de seqüências finitas de números naturais.
Descreva uma método para ``codificar'' os elementos de $S$
com os elementos de $\nats\setminus\set0$.
Tua método deve ser uma \emph{revertível}, no sentido que
cada seqüência finita
$$
s = \tup{s_0,s_1,\dotsc,s_{k_s}}\in S
$$
deve corresponder em exatamente um número natural $n_s\in\nats\setminus\set0$,
e, dado esse número $n_s\in\nats_{>0}$, deveria ser possível ``extrair''
a seqüência $s$ cuja codificação é o $n_s$.
Não se preocupe se existem naturais que não são codificações de nenhuma
seqüência.

\hint
Use o teorema fundamental da aritmética~(\reftag[fundamental_theorem_of_arithmetic]).

\hint
Seja $p_i$ o $i$-ésimo primo ($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
Como podemos escrever o aleatório $n\in\nats$?

\hint
Olha nos exponentes na forma
$
n =
p_0^{a_0}
p_1^{a_1}
p_2^{a_2}
\cdots
p_{k_n}^{a_{k_n}}
$.

\hint
Teste tua codificação nas seqüências $\tup{1,3}$ e $\tup{1,3,0}$.
Como essas seqüências são diferentes, suas codificações devem ser diferentes também.
E a seqüência vazia $\tup{}\in S$?  

\solution
Seja
$$
p_0 < p_1 < p_2 < p_3 < \dotsb
$$
a seqüência infinita dos primos.  (Assim, $p_0 = 2$, $p_1 = 3$, $p_2 = 5$, etc.)
Seja
$$
\tup{s_0, s_1, \dotsc, s_{n-1}} \in S
$$
uma seqüência de naturais de tamanho $n$.
Vamos codificá-la com o inteiro
$$
c_s
= \Prod_{i=0}^{n-1} p_i^{s_i + 1}
= p_0^{s_0 + 1} p_1^{s_1 + 1} p_2^{s_2 + 1} \cdots p_{n-1}^{s_{n-1} + 1}.
$$
(Note que a seqüência vazia ($n=0$) correponde no número $1\in\nats_{>0}$.)
\eop
Conversamente, dado um número $c\in\nats_{>0}$ que codifica uma seqüência,
como podemos ``decodificar'' a seqüência que corresponda com ele?
Graças o teorema fundamental da aritmética~(\reftag[fundamental_theorem_of_arithmetic]),
temos
$$
c = p_0^{a_0} p_1^{a_1} \cdots p_{m-1}^{a_{m-1}}.
$$
Se existe exponente $a_j = 0$, o $c$ não codifica nenhuma seqüência.
Caso contrário, todos os exponentes são positivos, e o $c$ codifica
a seqüência
$$
\tup{a_0-1, a_1-1, \dotsc, a_m-1} \in S.
$$

%%}}}

%%{{{ prob: canonical_representation_of_rats 
\problem Representação canônica de racionais.
%%%{{{ meta 
\label canonical_representation_of_rats
%%%}}}

Generalize a representação canônica de inteiros para racionais.

\hint
Qual foi tua resposta no~\ref[canonical_representation_with_int_exponents]?

%%}}}

\endproblems
%%}}}

%%{{{ The idea behind congruence relation 
\section A idéia da relação de congruência.
%%%{{{ meta 
%%%}}}

\TODO pintar com cores, metafora de times.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos fixar um inteiro positivo $m\in\nats$.
Graças à divisão de Euclides~(\reftag[euclidean_division]),
qualquer inteiro $a\in\ints$ pode ser escrito na forma
$$
a = mk + r,
\qquad
0 \leq r < m,
$$
num jeito único, ou seja, os inteiros $k,r$ são determinados
pelos $a,m$.
\eop
Enquanto investigando a (ir)racionalidade dos $\sqrt 2$, $\sqrt 3$, $\sqrt {\vphantom3 m}$,
etc., nós percebemos que foi útil separar os inteiros em classes,
``agrupando'' aqueles que compartilham o mesmo resto quando divididos por $m$.
Trabalhando com essa idéia nós encontramos nosso primeiro contato com
\emph{aritmética modular}.\foot
Mentira.  Não foi o primeiro não: somos todos acostumados com
aritmética modular mesmo sem perceber.  Um desses contatos é por causa de ter
que contar com horas e relógios, cuja aritmética não parece muito com aquela
dos inteiros.  Por exemplo: $21 + 5 = 26$, mas se agora são 21h00, que horas
serão depois de 5 horas?  Nossos relógios não vou mostrar 26h00, mas 02h00.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Two equivalent definitions 
\section Duas definições equivalentes.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Precisamos definir formalmente a noção de ``\emph{dois inteiros $a$ e $b$ pertencem na
mesma classe, quando separamos eles em grupos usando o inteiro $m$}''.
A primeira coisa que precisamos perceber é que essa frase é uma afirmação sobre 3 objetos.
Queremos então uma definição e uma notação que captura essa relação \emph{de aridade 3}.

%%}}}

%%{{{ Congruences intuitively 
\note Congruência intuitivamente.
%%%{{{ meta 
%%%}}}

Chamamos dois inteiros \dterm{congruentes} módulo um terceiro inteiro,
sse eles têm o mesmo resto, quando divididos por ele.

%%}}}

%%{{{ Critique 
\note Crítica.
%%%{{{ meta 
%%%}}}

Primeiramente, o texto da definição é bem informal e ambíguo.
Para tirar essas ambigüidades, precisamos introduzir variáveis para
referir sobre os ``mesmos restos'':

%%}}}

%%{{{ df: congruence_intuitive_definition 
\definition Intuitiva.
%%%{{{ meta 
\label congruence_intuitive_definition
%%%}}}

Sejam $a,b,m\in\ints$ com $m>0$, e sejam $q_a$, $r_a$, $q_b$, e $r_b$
os inteiros determinados por as divisões:
$$
\alignat 2
a &= mq_a + r_a     &\qquad& 0 \leq r_a < m\\
b &= mq_b + r_b     &      & 0 \leq r_b < m
\endalignat
$$
Digamos que os $a$ e $b$ são \dterm{congruentes} módulo~$m$,
sse $r_a = r_b$.

%%}}}

%%{{{ remark: from_same_remainders_to_divides_the_diference 
\remark.
%%%{{{ meta 
\label from_same_remainders_to_divides_the_diference
%%%}}}

Olhando para dois números $a$ e $b$, congruêntes módulo~$m$,
o que podemos dizer sobre a diferença deles?
Observe:
$$
\rightbrace {
\aligned
a - b
&= (mq_a + r_a) - (mq_b + r_b)\\
&= mq_a - mq_b + r_a - r_b\\
&= m(q_a - q_b) + (r_a - r_b)\\
&= m(q_a - q_b) + 0\\
&= m(q_a - q_b)
\endaligned
}
\qquad
\aligned
\text{ou seja, $m \divides a - b$.}
\endaligned
$$
Essa observação nos mostra um caminho mais curto e elegante para definir o mesmo
conceito.  É o seguinte:

%%}}}

%%{{{ df: congruence_modulo_int 
\definition Congruência (Gauss).
%%%{{{ meta 
\label congruence_modulo_int
\credits
    * Gauss : definição de congruência
    ;;
\defines
    * ~a \cong {~b} \pmod {~m}  -- $a$ é congruente com $b$ módulo $m$
    * congruência
    * módulo
    ;;
%%%}}}

Sejam $a,b,m\in\ints$ com $m>0$.
Digamos que os $a$ e $b$ são \dterm{congruentes} \dterm{módulo} $m$,
sse $m \divides a - b$.
Em símbolos, escrevemos
$$
a \cong b \pmod m
\defiff m \divides a - b
$$
e lemos: \emph{o $a$ é congruente com $b$ módulo~$m$}.

%%}}}

%%{{{ beware: cong_mod_is_a_ternary_relation 
\beware.
%%%{{{ meta \label cong_mod_is_a_ternary_relation
%%%}}}

A notação de congruência às vezes iluda de ser interpretada como se fosse
uma relação entre o lado esquerdo $L$ e o lado direito $R$, assim:
$$
\tubrace {a} {L} \cong \tubrace {b \pmod m} {R}.
$$
\emph{Não!}
Principalmente, o lado direito, $b \pmod m$, nem é definido, então não tem significado,
e nem faz sentido afirmar algo sobre ele.
Prestando mais atenção, percebemos que o $\hole \cong \hole$ também não foi definido!
O que nós definimos foi o:
$$
\holed u \cong \holed v \pmod {\holed w}
$$
dados $u,v,w\in\ints$ com $w>1$.

%%}}}

%%{{{ notation: a ≡ₘ b 
\note Notação.
%%%{{{ meta 
%%%}}}

Talvez ficaria mais intuitivo (e menos confúso) usar a notação
$$
a \congmod m b \defiff a \cong b \pmod m
$$
que introduzimos aqui pois às vezes ajuda.
Mas a notação mais usada é a da \ref[congruence_modulo_int]

%%}}}

%%{{{ Intuition 
\note Intuição.
%%%{{{ meta 
%%%}}}

Se precisamos para algum motivo pessoal---porque sim---separar mentalmente a
notação de congruência em dois lados, o único jeito que faz algum sentido
seria o:
$$
\tubrace {\mathstrut a \cong b} {L}
\quad
\tubrace {\!\!\pmod m} {R}.
$$
Assim, entendemos que ``algo acontece'' (lado $L$), ``dentro algo'' (lado $R$),
onde ``algo acontece'' seria ``o $a$ \emph{parece} com $b$'',
e ``dentro algo'' seria ``módulo~$m$''.
Mas, claramente tudo isso é apenas uma guia (caso que queremos)
e nada mais que isso.  Para argumentar sobre a relação de congruência,
usamos \emph{apenas sua definição formal!}

%%}}}

%%{{{ blah: to use both definitions so we must prove their equivalence 
\blah.
%%%{{{ meta 
%%%}}}

Para ganhar o direito de usar qualquer uma das duas definições, precisamos
mostrar que são equivalentes:

%%}}}

%%{{{ thm: cong_mod_equivalence_of_definitions 
\theorem Equivalência das duas definições.
%%%{{{ meta 
\label cong_mod_equivalence_of_definitions
%%%}}}

Sejam $a,b,m\in\ints$ com $m>0$, e sejam $q_a, r_a, q_b, r_b\in\ints$
os números determinados por as divisões:
$$
\alignat 2
a &= mq_a + r_a     &\qquad& 0 \leq r_a < m\\
b &= mq_b + r_b     && 0 \leq r_b < m
\endalignat
$$
Temos a equivalência:
$$
a \cong b \pmod m
\iff
r_a = r_b.
$$

\sketch.
Precisamos mostrar as duas direções do \bidir.
A direção \rldir, é practicamente
a~\ref[from_same_remainders_to_divides_the_diference].
Para a direção \lrdir, vamos mostrar que $r_a - r_b = 0$.
Usamos a hipótese e propriedades de~$\divides$
para mostrar que $m \divides r_a - r_b$,
e depois as duas desigualdades para confirmar que, com suas restricções,
o único inteiro múltiplo de $m$ que as satisfaz é o~$0$.

\proof.
Precisamos mostrar as duas direções do \bidir:
\eop
\lrdir:
Suponha que
$a \cong b \pmod m$, ou seja,
$m \divides a - b$.
Resolvendo as duas equações das divisões por os restos $r_a$ e $r_b$,
temos:
$$
\rightbrace {
\aligned
r_a &= a - mq_a \\
r_b &= b - mq_b 
\endaligned
}
\implies
\aligned
r_a - r_b
&= (a - mq_a) - (b - mq_b)\\
&= (a - b) - (mq_a - mq_b)\\
&= (a - b) - m(q_a - q_b).
\endaligned
$$
Observe que $m \divides a-b$ e $m \divides m(q_a - q_b)$.
Então $m$ tem que dividir a diferença deles também:
$$
m \divides \mubrace {(a - b) - m(q_a - q_b)} {\dsize r_a - r_b}
$$
Usando as duas desigualdades: $0 \leq \abs{r_a - r_b} < m$.
Como $\abs{r_a-r_b}$ é um múltiplo de $m$, concluimos que necessariamente
$0 = \abs{r_a - r_b}$, ou seja: $r_a = r_b$.
\eop
\rldir:
Suponha que $r_a = r_b$.
Temos:
\compute
a - b
&= (mq_a + r_a) - (mq_b + r_b)  \\
&= (mq_a - mq_b) - (r_a - r_b)  \\
&= (mq_a - mq_b) - 0            \by {hipótese} \\
&= m(q_a - q_b),
\endcompute
e como $q_a - q_b\in\ints$,
concluimos que
$m \divides a - b$, ou seja:
$a \cong b \pmod m$.

%%}}}

%%{{{ beware: binary_mod 
\beware A operação binária ``mod''.
%%%{{{ meta 
\label binary_mod
%%%}}}

Em linguagens de programação é comum encontrar o operador \emph{binário}
``mod'', frequentemente denotado com o símbolo \symq{\code \%}.
Em matemática, essa funcção \emph{binária} (aridade 2) é mais
encontrada como \symq{$\bmod$} mesmo.
Cuidado não confundir a \emph{funcção}
$\bmod : \ints\times\nats_{>0} \to \nats$
com a \emph{relação} $a \cong b \pmod m$.
Faz sentido escrever:
$$
69 \bmod 5 = 4.
$$
Isso significa apenas que o resto da divisão de 69 por 5, é 4.
No outro lado, nenhuma das expressões abaixo tem significado!:
$$
69 \pmod 5 = 4
\qquad\qquad
4 = 69 \pmod 5
$$

%%}}}

%%{{{ x: explain_the_type_of_bmod 
\exercise.
%%%{{{ meta 
\label explain_the_type_of_bmod
%%%}}}

Explique o tipo da funcção $\bmod : \ints\times\nats_{>0} \to \nats$.

\hint
Qual seria o valor de $4 \bmod 0$?

\solution
Por~\ref[euclidean_division],
precisamos $a\in\ints$ e $b\in\nats_{>0}$ para definir a divisão
de $a$ por $b$.

%%}}}

%%{{{ x: mod_vs_mod 
\exercise mod \vs mod.
%%%{{{ meta 
\label mod_vs_mod
%%%}}}

Para cada uma das expressões abaixo uma das três opções é válida:
(a) ela denota um termo;
(b) ela denota uma afirmação; ou
(c) ela não tem significado.
Para cada expressão, decida qual é a opção certa e:
se for a (a), ache o seu valor (objeto);
se for a (b), ache o seu valor (de verdade).
% TODO: fix reflabs
\elist 1:
\li: $69 \pmod 5 = 4$
\li: $12 = 3 \pmod 8 $
\li: $12 \cong 20 \pmod 4 $
\li: $8 \pmod 3 \cong 12$
\li: $108 \cong 208 \pmod {(43 \bmod 30)}$
\li: $x \bmod 4 = 2 \implies x \cong 0 \pmod 2$
\li: $5^{192\,\bmod\,3}$
\li: $13\pmod 8 \cong 23 \pmod {18}$
\endelist

\solution
Vamo lá:
\elist 1:
\li:
$69 \pmod 5 = 4$ não significa nada.
\li:
$12 = 3 \pmod 8$ não significa nada.\foot
Se o $=$ fosse $\cong$, então significaria que $8 \divides 12 - 3 = 9$ (que é falso).
\toof
\li:
$12 \cong 20 \pmod 4$ significa que $4 \divides 12 - 20 = -8$, que é verdade.
\li:
$8 \pmod 3 \cong 12$ não significa nada.
\li:
$108 \cong 208 \pmod {(43 \bmod 30)}$ significa que $43\bmod 30 \divides 108 - 208$,
e para achar se é verdade ou não, calculamos $43\bmod 30 = 13$,
e $108 - 208 = -100$ e substituimos: $13 \divides -100$, que é falso.
\li:
$\lforall {x\in\ints} {x \bmod 4 = 2 \limplies x \cong 0 \pmod 2}$
denota a afirmação que para todo $x\in\ints$,
se $x \bmod 4 = 2$ então $x \cong 0 \pmod 2$, que é verdade:
seja $x\in\ints$ tal que $x \bmod 4 = 2$.
Logo $x = 4k + 2 = 2(2k + 1)$ para algum $k\in\ints$,
ou seja, $2 \divides x = x - 0$.
\li:
$5^{192 \bmod 3}$ é o número 5 elevado ao resto da divisão de 192 por 3.
Como $3 \divides 192$ (por quê?  1 + 9 + 2 = 12; 1 + 2 = 3;
veja o~\ref[divisibility_criterion_3_9]), temos $192 \bmod 3 = 0$,
então o valor da expressão é o número $5^0 = 1$.
\li:
$13\pmod 8 \cong 23 \pmod {18}$ não significa nada.
\endelist

%%}}}

\endsection
%%}}}

%%{{{ The relation congruence modulo some integer 
\section A relação de congruência módulo um inteiro.
%%%{{{ meta 
%%%}}}

%%{{{ Fixing an $m$ 
\note Fixando um $m$.
%%%{{{ meta 
%%%}}}

Se fixar um inteiro $m>0$, então a expressão
$$
\holed a \cong \holed b \pmod m
$$
tem duas variáveis livres: a $a$ e a $b$.
Assim, a ``congruência módulo~$m$'' é uma relação binária,
cujas propriedades investigamos agora.

%%}}}

%%{{{ thm: congruence_mod_m_is_an_eqrel 
\theorem.
%%%{{{ meta 
\label congruence_mod_m_is_an_eqrel
%%%}}}

Fixe um inteiro $m > 0$.
Para todos os $a,b,c\in\ints$,
temos:
$$
\xxalignat 2
(1)\quad&a \cong a \pmod m                             &&\textrm{(reflexividade)}\\
(2)\quad&a \cong b \pmod m \mland b \cong c \pmod m
\implies
a \cong c \pmod m                                      &&\textrm{(transitividade)}\\
(3)\quad&a \cong b \pmod m \implies b \cong a \pmod  m &&\textrm{(simetria)}.
\endxxalignat
$$

\sketch.
Todas são facilmente provadas aplicando diretamente
a definição de congruência módulo~$m$ (\reftag[congruence_modulo_int])
e as propriedades básicas da $\divides$.

\proof.
(1) Óbvio porque $m \divides a - a = 0$.
(2) Pela hipótese temos $m \divides a-b$ e $m \divides b-c$.
Então pelo~\ref[divides_properties] $m \divides (a-b) + (b-c) = a-c$.
(3) Pela hipótese temos $m \divides a - b$\thinspace; logo (\reftag[divides_properties] de novo) $m \divides -(a - b) = b - a$.

%%}}}

%%{{{ remark: equivalence relation 
\remark.
%%%{{{ meta 
\indexes
    * relação!de equivalência
    ;;
%%%}}}

Uma relação que satisfaz essas três propriedades é chamada
\dterm{relação de equivalência}~(\reftag[Equivalence_relations]).
Estudamos relações no~\ref[Relations].  Paciência!

%%}}}

\endsection
%%}}}

%%{{{ Modular arithmetic 
\section Aritmética modular.
%%%{{{ meta 
%%%}}}

%%{{{ prop: modular_arithmetic_properties 
\property.
%%%{{{ meta 
\label modular_arithmetic_properties
%%%}}}

Se $a \cong b \pmod m$, então para todo $x\in\ints$ temos:
$$
(1)\quad a + x \cong b + x   \pmod m;
\quad\enspace
(2)\quad ax \cong bx         \pmod m;
\quad\enspace
(3)\quad -a \cong -b         \pmod m.
$$

\sketch.
Todas seguem facilmente pela definição (\reftag[congruence_modulo_int]) de congruência módulo~$m$.

%%}}}

%%{{{ beware: wrong_cancellation_law_modulo_m 
\beware.
%%%{{{ meta 
\label wrong_cancellation_law_modulo_m
%%%}}}

O lei de cancelamento, mesmo válido nas igualdades,
não é válido nas congruências em geral.
Por exemplo,
$3\ntimes 2 \cong 3\ntimes 8 \pmod {18}$,
mas não podemos cancelar os $3$ nos dois lados:
$2 \ncong 8 \pmod {18}$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Felizmente, o teorema seguinte mostra quando realmente podemos cancelar:

%%}}}

%%{{{ thm: cancellation_law_modulo_m 
\theorem Lei de cancelamento módulo $m$.
%%%{{{ meta 
\label cancellation_law_modulo_m
%%%}}}

Seja $c\in\ints$ tal que $\gcd c m = 1$.
$$
ca\cong cb\pmod m
\implies
a \cong b \pmod m.
$$

\sketch.
Multiplicamos tudo por $c^{-1}$, cuja existência (módulo~$m$) é garantida
pela hipótese (aplicando o~\ref[find_inverse_modulo_m]).

\proof.
Como $\gcd c m = 1$, existe $c^{-1}$ (módulo~$m$) então:
$$
\align
ca\cong cb\pmod m
&\implies          c^{-1}c a\cong          c^{-1}c b\pmod m\\
&\implies \phantom{c^{-1}c}a\cong \phantom{c^{-1}c}b\pmod m.
\endalign
$$

%%}}}

%%{{{ x: cancellation_law_modulo_m_altproof 
\exercise.
%%%{{{ meta 
\label cancellation_law_modulo_m_altproof
%%%}}}

Aplicando as definições e propriedades de congruência e da relação $\divides$,
ache uma outra prova do~\reftag[cancellation_law_modulo_m].

\solution
Pela hipótese $m \divides ca - cb = c(a - b)$.
Mas $\gcd m c = 1$, então
(pelo~\ref[lemma_euclides_coprime_version])
$m \divides a - b$, ou seja, $a \cong b \pmod m$.

%%}}}

%%{{{ x: from_mod_m_to_mod_am 
\exercise.
%%%{{{ meta 
\label from_mod_m_to_mod_am
%%%}}}

Suponha que $x \cong t \pmod m$, e seja $a$ um inteiro positivo.
O que podemos concluir sobre o $x$ módulo~$ma$?

\hint
Use as definições de congruência (\reftag[congruence_modulo_int]) e de $\divides$ (\reftag[divides])
para escrever o $x$ na forma $x = mk + t$ para algum $k\in\ints$.

\hint
Agora divida o $k$ por $a$.

\solution
Pela definição de congruência (\reftag[congruence_modulo_int]) e de $\divides$ (\reftag[divides]) temos que:
$$
\align
x &= mk + t, \quad\text{para algum $k\in\ints$}.
\intertext{Dividindo o $k$ por $a$,
temos $k = aq + i$, onde $q,i\in\ints$ e $0\leq i < a$.  Substituindo:}
x &= m(aq + i) + t\\
  &= maq + (mi + t).
\intertext{Logo, chegamos nas $a$ congruências}
x &\cong mi + t \pmod{ma}, \quad\text{para $i=0,\dotsc,a-1$},
\endalign
$$
e $x$ tem que satisfazer (exatamente) uma delas.

%%}}}

%%{{{ x: from_equality_to_congruence 
\exercise De igualdades para congruências.
%%%{{{ meta 
\label from_equality_to_congruence
%%%}}}

Seja $a,b\in\ints$.
Se $a = b$, então $a\cong b\pmod m$ para qualquer inteiro $m\in\nats$.

%%}}}

\endsection
%%}}}

%%{{{ Exponentiation 
\section Exponenciação.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Divisibility criteria 
\section Critéria de divisibilidade.
%%%{{{ meta 
\label Divisibility_criteria
\indexes
    * divisibilidade!critéria
    ;;
%%%}}}

%%{{{ criterion: divisibility_criterion_powers_of_10 
\criterion Divisibilidade por potências de 10.
%%%{{{ meta 
\label divisibility_criterion_powers_of_10
%%%}}}

Um inteiro $c\neq 0$ é divisível por $10^k$
sse
o $c$ escrito em base decimal termina com $k$ dígitos 0.

%%}}}

%%{{{ criterion: divisibility_criterion_2_5 
\criterion Divisibilidade por 2 ou 5.
%%%{{{ meta 
\label divisibility_criterion_2_5
%%%}}}

Seja $m\in\set{2, 5}$.
Um inteiro $c$ é divisível por $m$
sse
o valor do último dígitos do $c$ (em base decimal) é $m$.

%%}}}

%%{{{ criterion: divisibility_criterion_3_9 
\criterion Divisibilidade por 3 ou 9.
%%%{{{ meta 
\label divisibility_criterion_3_9
%%%}}}

Seja $m\in\set{3, 9}$.
Um inteiro $c$ é divisível por $m$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) é
divisível por $m$.

%%}}}

%%{{{ criterion: divisibility_criterion_4_20_25_50
\criterion Divisibilidade por 4, 20, 25, 50.
%%%{{{ meta 
\label divisibility_criterion_4_20_25_50
%%%}}}

Seja $m\in\set{4, 20, 25, 50}$.
Um inteiro $c$ é divisível por $m$
sse
o número formado pelos dois últimos dígitos do $c$ (em base decimal)
é divisível por $m$.

%%}}}

%%{{{ criterion: divisibility_criterion_11 
\criterion Divisibilidade por 11.
%%%{{{ meta 
\label divisibility_criterion_11
%%%}}}

Um inteiro $c$ é divisível por $11$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) em posição par
menos o somatório dos valores dos seus dígitos em posição ímpar
é divisível por $11$.

%%}}}

%%{{{ x: divisibility_criterion_6 
\exercise Divisibilidade por 6.
%%%{{{ meta 
\label divisibility_criterion_6
%%%}}}

Ache um critério (para o sistema decimal) para divisibilidade por 6.

\hint
$6 = 2\ntimes 3$

\solution
Observe que por causa do~\ref[product_of_coprimes_divides_common_multiple], temos:
$$
6\divides c
\iff
2 \divides c
\mland
3 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $3$.

%%}}}

%%{{{ prop: divisibility_criterion_8_wrong 
\proposition Divisibilidade por 8.
%%%{{{ meta 
\label divisibility_criterion_8_wrong
%%%}}}

Um número $c$ é divisível por 8 sse ele satisfaz
os critéria de divisibilidade por $2$ e $4$.

\wrongproof.
Observe que por causa do~\ref[product_of_coprimes_divides_common_multiple], temos:
$$
8 \divides c
\iff
2 \divides c
\mland
4 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $4$.

%%}}}

%%{{{ x: divisibility_criterion_8_wrong_why 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_8_wrong_why
%%%}}}

Ache o erro no~\ref[divisibility_criterion_8_wrong],
e compare com a solução do~\ref[divisibility_criterion_6].

\hint
Veja o~\ref[product_of_coprimes_divides_common_multiple].

\solution
Como $\gcd 4 2 = 4 \neq 1$, não podemos aplicar
o~\ref[product_of_coprimes_divides_common_multiple].
Um contraexemplo:
$2 \divides 12$ e $4 \divides 12$, mas $2\ntimes 4 = 8 \ndivides 12$.

%%}}}

%%{{{ x: divisibility_criterion_8_powers_of_2 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_8_powers_of_2
%%%}}}

Ache um critério (no sistema decimal) para divisibilidade por 8,
e generalize para divisibilidade por $2^k$

\hint
$8 = 2^3$, e $2 \divides 10$.

\hint
$2 \divides 10 \implies 2^3 \divides 10^3$.

%%}}}

%%{{{ x: divisibility_criterion_2_exp_x_times_5_exp_y 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_2_exp_x_times_5_exp_y
%%%}}}

Ache um critério (no sistema decimal) para divisibilidade por $2^x5^y$, onde $x,y\in\nats$.

\hint
Os $2$ e $5$ são divisores de $10$.

%%}}}

\endsection
%%}}}

%%{{{ Inverses modulo $m$ 
\section Inversos módulo um inteiro.
%%%{{{ meta 
%%%}}}

%%{{{ df: inverse_modulo_m 
\definition Inverso.
%%%{{{ meta 
\label inverse_modulo_m
\defines
    * ~a^{-1}  -- o inverso (multiplicativo) do $a$ (módulo~$m$)
    * inverso!multiplicativo módulo~$m$
    ;;
%%%}}}

Seja $a,a',m\in\ints$.
Chamamos $a'$ \dterm{um inverso (multiplicativo) de $a$ módulo~$m$},
sse
$$
aa' \cong 1 \pmod m.
$$
Se existe inverso do $a$, o denotamos com $a^{-1}$ (dado um módulo~$m$).\mistake

%%}}}

%%{{{ x: what is wrong? 
\exercise.
%%%{{{ meta 
%%%}}}

Qual o problema com a definição do $a^{-1}$?

\solution
Para o símbolo $a^{-1}$ ser bem-definido, precisamos mostrar que, caso que
existe um inverso, ele é único, que nos realmente mostramos
no~\ref[inverse_modulo_m_uniqueness].

%%}}}

%%{{{ blah: we speak of *the* inverse thanks to the following thm 
\blah.
%%%{{{ meta 
%%%}}}

Podemos falar sobre \emph{o} inverso (em vez de \emph{um} inverso)
graças ao teorema seguinte:

%%}}}

%%{{{ thm: inverse_modulo_m_uniqueness 
\theorem Unicidade do inverso.
%%%{{{ meta 
\label inverse_modulo_m_uniqueness
%%%}}}

Sejam $a,m\in\ints$.
Se $b,b'\in\ints$ satisfazem a $ax \cong 1 \pmod m$, então $b \cong b' \pmod m$.

\proof.
Como
$$
ab  \cong 1 \pmod m \qquad\mland\qquad ab' \cong 1 \pmod m,
$$
pela transitividade e reflexividade da congruência módulo~$m$, temos:
$$
ab \cong ab' \pmod m.
$$
Pela~\ref[modular_arithmetic_properties], podemos multiplicar os dois
lados por $b$:\foot
Nada especial sobre $b$ contra o $b'$.
Poderiamos multiplicar por qualquer inverso do $a$ aqui.
\toof
$$
bab \cong bab' \pmod m.
$$
Daí,
$(ba)b \cong (ba)b' \pmod m$,
ou seja $b \cong b' \pmod m$.

%%}}}

%%{{{ eg: the mod9-inverse of 2 is 5 
\example.
%%%{{{ meta 
%%%}}}

O inverso de $2$ módulo~$9$ é o $5$, porque $2\ntimes 5 = 10 \cong 1 \pmod 9$.

%%}}}

%%{{{ blah: as the following eg shows, inverses are not guaranteed 
\blah.
%%%{{{ meta 
%%%}}}

Como o exemplo seguinte mostra, inversos não existem sempre:

%%}}}

%%{{{ eg: 4 has no mod6-inverse 
\example.
%%%{{{ meta 
%%%}}}

O $4$ não tem inverso módulo~$6$.

\solution.
Podemos verificar com força bruta:
$$
\align
4 \ntimes 1 = \phantom04    &\cong 4 \pmod 6\\
4 \ntimes 2 = \phantom08    &\cong 2 \pmod 6\\
4 \ntimes 3 = 12            &\cong 0 \pmod 6\\
4 \ntimes 4 = 16            &\cong 4 \pmod 6\\
4 \ntimes 5 = 20            &\cong 2 \pmod 6
\endalign
$$
Pronto.

%%}}}

%%{{{ blah: the following thm clears things up 
\blah.
%%%{{{ meta 
%%%}}}

O teorema seguinte esclarece a situação:

%%}}}

%%{{{ thm: find_inverse_modulo_m 
\theorem Inverso módulo $m$.
%%%{{{ meta 
\label find_inverse_modulo_m
%%%}}}

Sejam $a,m\in\ints$.
$$
\text{$a$ tem inverso módulo~$m$}
\iff
\gcd a m = 1.
$$

\proof.
Precisamos mostrar as duas direções do \bidir.
\eop
\lrdir:
Escrevemos o $\gcd a m = 1$ como combinação\indexed[combinação linear] linear dos $a$ e $m$
(sabemos que é possível por \ref[bezout_lemma], e, até melhor construtível
graças ao algoritmo estendido de Euclides,~\ref[extended_euclidean_algorithm]):
$$
\alignat 2
1 &= sa + tm, &&\qquad\text{para alguns $s,t\in\ints$.}
\intertext{Então temos:}
1 &\cong sa + tm    &&\pmod m\\
  &\cong sa + 0     &&\pmod m\\
  &\cong sa         &&\pmod m.
\endalignat
$$
Acabamos de achar um inverso de $a$ módulo~$m$: o $s$.
\eop
\rldir:
Seja $b$ um inverso de $a$ módulo~$m$; em outras palavras:
$$
ab \cong 1 \pmod m,
$$
ou seja, $m \divides ab - 1$, e $mu = ab - 1$ para algum $u\in\ints$.
Conseguimos escrever
$$
1 = um - ba,
$$
a combinação linear dos $a$ e $m$.
Pelo~\ref[bezout_lemma], $\gcd a m \divides 1$,
logo $\gcd a m = 1$.

%%}}}

\endsection
%%}}}

%%{{{ Solving_some_congruences 
\section Resolvendo umas congruências.
%%%{{{ meta 
\label Solving_some_congruences
%%%}}}

%%{{{ cor: ax_cong_1_mod_m 
\corollary.
%%%{{{ meta 
\label ax_cong_1_mod_m
%%%}}}

Dados inteiros $a,b$, a congruência
$$
ax \cong 1 \pmod m
$$
tem resolução para $x$ sse $\gcd a m = 1$.

\proof.
Observe que aqui <<$x$ é resolução>> significa
<<$x$ é o inverso de $a$>>, e logo a proposição
é corolário imediato do \ref[find_inverse_modulo_m].

%%}}}

\TODO a congruência $ax \cong b \pmod m$.

\TODO a congruência $x^2 \cong 1 \pmod m$.

\endsection
%%}}}

%%{{{ The_chinese_remainder_theorem 
\section O teorema chinês do resto.
%%%{{{ meta 
\label The_chinese_remainder_theorem
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já sabemos como resolver congruências do tipo
$$
ax \cong b \pmod m,
$$
e agora vamos ver como resolver uns \emph{sistemas}
de congruências.

%%}}}

%%{{{ thm: chinese_remainder_theorem_binary_case 
\theorem Chinês do resto: caso binário.
%%%{{{ meta 
\label chinese_remainder_theorem_binary_case
%%%}}}

Sejam $m_1,m_2,b_1,b_2\in\ints$,
com $\gcd {m_1} {m_2} = 1$.
Então existe $x\in\ints$ que satisfaz o sistema de congruências
\system
x &\cong    b_1    \pmod {m_1}\\
x &\cong    b_2    \pmod {m_2}.
\endsystem
Além disso, a solução do sistema é única módulo~$m_1\dotsb m_2$.

\sketch.
\proofstylize{Existência:}
Observe que o inteiro $b_1$ com certeza satisfaz a primeira congruência.
O problema é que talvez não satisfaça a segunda.
Felizmente, temos mais inteiros que satisfazem a primeira na nossa disposição.
Muito mais: uma infinidade deles: cada congruente ao $b_1$, ou seja
os membros do conjunto
$$
\setst {m_1k + b_1} {k \in \ints}
$$
são exatamente todos os inteiros que satisfazem a primeira.
Agora estamos numa situação bem melhor, basta achar algum deles que satisfaz
a segunda.
Observe que cada membro desse conjunto é determinado por uma escolha de $k\in\ints$.
Ou seja, basta achar um inteiro $k$ tal que $m_1k + b_1$ satisfaz a segunda.
Talvez conseguimos achar até uma infinidade de tais inteiros.
Vamo lá!
Procuramos inteiros $k$ tais que
$$
m_1k + b_1 \cong b_2 \pmod {m_2},
$$
ou seja, tais que
$$
m_1k \cong b_2 - b_1 \pmod {m_2}.
$$
(Por quê?)
Mas sabemos como resolver essa congruência para $k$.
(Né?  Por quê?)

%%}}}

%%{{{ x: passing_a_term_on_the_other_side_of_a_congruence 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no primeiro <<por quê?>> acima.

\solution
Adicionamos o $-b_1$ aos dois lados.

%%}}}

%%{{{ x: second why 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no segundo <<por quê?>> acima.

\solution
É da forma $ax \cong b \pmod m$ com $a$ invertível (pois $\gcd a m = 1$),
ou seja, sabemos como resolver desde a \ref[Solving_some_congruences].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver isso na prática:

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
\system
x &\cong 1 \pmod 5\\
x &\cong 7 \pmod {12}.
\endsystem

\solution.
Os inteiro que satisfazem a primeira congruência são os membros do
$$
\setst {5k + 1} {k\in\ints}.
$$
Basta achar os valores de $k$ tais que $5k+1$ também satisfaz a segunda,
ou seja, resolver a
$$
\alignat 2
5k+1 &\cong 7 &&\pmod {12}
\intertext{por $k$.  Passando o $(+1)$ peloutro lado (por que podemos
fazer isso numa congruência?)~temos}
5k &\cong 7-1 &&\pmod {12}\\
   &\cong 6   &&\pmod {12}.
\intertext{Agora basta ``dividir por $5$'', ou seja, multiplicar ámbos
os lados pelo inverso de $5$ módulo $12$, que sabemos que existe pois
$\gcd 5 {12} = 1$ e logo $5$ é invertível módulo $12$.
Percebemos que $5$ é seu próprio inverso, pois
$$
5^2 = 25 \cong 1 \pmod {12},
$$
e se não percebemos isso, usamos o algoritmo de Euclides para calcular
o inverso de $5$ módulo $12$.
Temos:}
k  &\cong 5\ntimes 6 &&\pmod {12}\\
   &\cong 30         &&\pmod {12}\\
   &\cong 6          &&\pmod {12}.
\endalignat
$$
Logo, para qualquer inteiro $k'$, tomando $k = 12k' + 6$,
o $5k+1$ satisfaz ambas as congruências.
Substituindo:
$$
5k + 1
= 5(12k' + 6) + 1
= 60k' + 30 + 1
= 60k' + 31.
$$
Em termos de classes módulo $60$, achamos a única resolução:
$$
x \cong 31 \pmod {60}.
$$

%%}}}

%%{{{ Q: What if we have more congruences? 
\question.
%%%{{{ meta 
%%%}}}

E se o sistema tem mais congruências?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Supondo que os módulos são \emph{coprimos dois-a-dois},
nenhum problema!
Basta só focar em duas congruências cada vez,
e substituí las por uma, que corresponde na sua
resolução (módulo o produto dos seus módulos).

%%}}}

%%{{{ x: chinese_from_binary_to_ternary 
\exercise.
%%%{{{ meta 
\label chinese_from_binary_to_ternary
%%%}}}

Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
\system
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12} \\
x &\cong 3 \pmod 7.
\endsystem

\hint
Já descobrimos que
$$
x \cong 31 \pmod {60}
\iff
\systemed {
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12}
}
$$
e logo
$$
\systemed {
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12} \\
x &\cong 3 \pmod 7
}
\iff
\systemed {
x &\cong 31 \pmod {60} \\
x &\cong \phantom03  \pmod 7.
}
$$
Como $\gcd {60} 7 = 1$, sabemos que o sistema tem resolução única módulo $420$
e ainda mais, sabemos como achar essa resolução
(tudo isso graças ao \ref[chinese_remainder_theorem_binary_case]).

%%}}}

%%{{{ thm: chinese_remainder_theorem 
\theorem Teorema Chinês do resto.
%%%{{{ meta 
\headerize
\label chinese_remainder_theorem
\indexes
    * chinês!teorema do resto    see: teorema chinês
    * congruência!sistema
    * sistema!de congruências
    * teorema!chinês do resto
    ;;
%%%}}}

Sejam $a_1,\dotsc,a_k,m_1,\dotsc,m_k\in\ints$,
com os $m_i$'s coprimos dois-a-dois:
$$
\lforall {i,j\in\set{1,\dotsc,k}} {i\neq j \implies \gcd {m_i} {m_j} = 1}.
$$
Logo existe $x\in\ints$ que satisfaz o sistema de congruências
\mathcol
x &\cong    a_1  \pmod {m_1} \\
x &\cong    a_2  \pmod {m_2} \\
  &\eqvdots                    \\
x &\cong    a_k  \pmod {m_k}.
\endmathcol
Além disso, a solução do sistema é única módulo~$m_1\dotsb m_k$.

\sketch.
\proofstylize{Existência:}
Seja
\mathcol
M   &\asseq \Prod_{i=1}^k m_i = m_1m_2\dotsb m_k
\intertext{e, para todo $i\in\set{1,\dotsc,k}$, defina o}
M_i &\asseq \Prod\submath{j=1\\j\neq i}^k m_j
     = m_1\dotsb m_{i-1}m_{i+1}\dotsb m_k
     = \frac M {m_i}.
\endmathcol
Observe que $M_i$ é invertível módulo~$m_i$,
então seja $B_i$ o seu inverso.
Verificamos que o inteiro
$$
x = \Sum_{i=1}^k a_i M_i B_i
$$
satisfaz todas as $k$ congruências,
e é então uma solução do sistema.
\eop
\proofstylize{Unicidade:}
Suponha que $x'\in\ints$ é uma solução do sistema.
Usando a definição de congruência e propriedades
de $\divides$, mostramos que $x' \cong x \pmod M$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
$$
\align
x &\cong 2 \pmod 9\\
x &\cong 1 \pmod 5\\
x &\cong 2 \pmod 4.
\endalign
$$

\solution.
Observamos primeiramente que os módulos $9$, $5$, e $4$ realmente são coprimos
dois-a-dois.  Então, pelo teorema chinês do resto,
o sistema realmente tem solução.
Seguindo sua método---e usando os mesmos nomes para as variáveis como
no~\ref[chinese_remainder_theorem] mesmo---calculamos os:
$$
\xalignat2
M_{\phantom0}   &= 9\ntimes5\ntimes4 = 180  &      &               \\
M_1 &= \phantom{9\ntimes{}}5\ntimes4 = 20   &  B_1 &\cong 5 \pmod 9\\
M_2 &= 9\phantom{{}\ntimes5}\ntimes4 = 36   &  B_2 &\cong 1 \pmod 5\\
M_3 &= 9\ntimes5\phantom{{}\ntimes4} = 45   &  B_3 &\cong 1 \pmod 4, 
\endxalignat
$$
onde os invérsos $B_i$'s podemos calcular usando o algoritmo estendido de
Euclides~(\reftag[extended_euclidean_algorithm]) como na prova
do~\ref[find_inverse_modulo_m]), mas nesse caso, sendo os módulos tão pequenos
fez mas sentido os achar testando, com ``força bruta''.
Então, graças ao teorema chinês, as soluções são exatamente os inteiros $x$ que satisfazem
$$
\alignat2
x &\cong a_1M_1B_1 + a_2M_2B_2 + a_3M_3B_3                                      &&\pmod M\\
  &\cong 2 \ntimes 20\ntimes 5 + 1 \ntimes 36\ntimes 1 + 2 \ntimes 45\ntimes 1  &&\pmod {180}\\
  &\cong 200 + 36 + 90                                                          &&\pmod {180}\\
  &\cong 146                                                                    &&\pmod {180}.
\endalignat
$$
Para resumir, as soluções do sistema são todos os elementos do
$\setst {180k + 146} {k\in\ints}$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Ache todos os inteiros $x\in\ints$ com $\abs x < 64$ que satisfazem o sistema de congruências:
$$
\align
x  &\cong 1 \pmod 3\\
3x &\cong 1 \pmod 4\\
4x &\cong 2 \pmod 5.
\endalign
$$

\solution.
Para aplicar o teorema chinês do resto precisamos os $3$, $4$, e $5$ coprimos dois-a-dois,
que realmente são.
Mas observe que o sistema não está na forma do teorema;
aí, não podemos aplicá-lo diretamente.
Nosso primeiro alvo então seria transformar a segunda e a terceira congruência para
equivalentes, na forma necessária para aplicar o teorema.
Na segunda vamos nos livrar do fator $3$, e na terceira do fator $4$.
Como $\gcd 3 4 = 1$,\foot
Qual \sq{4} foi esse?
\toof
o $3$ é invertível módulo~$4$.
Como o $3\cong -1 \pmod 4$, temos diretamente que $3^{-1} \cong -1 \pmod 4$.
Similarmente achamos o inverso $4^{-1} \cong -1 \pmod 4$.
Então temos:
$$
\rsystemed {
x  &\cong 1 \pmod 3\\
3x &\cong 1 \pmod 4\\
4x &\cong 2 \pmod 5
}
\iff
\bsystemed {
x  &\cong \phantom{1^{-1}}1 \pmod 3\\
3^{-1}3x &\cong 3^{-1}1 \pmod 4\\
4^{-1}x &\cong 4^{-1}2 \pmod 5
}
\iff
\lsystemed {
x &\cong \phantom{-}1 \pmod 3\\
x &\cong -1 \pmod 4\\
x &\cong -2 \pmod 5.
}
$$
Agora sim, podemos aplicar o teorema chinês.
Usando os mesmos nomes para as variáveis
como no~\ref[chinese_remainder_theorem], calculamos:
\mathcols 2
M_{\phantom0} &= 3\ntimes4\ntimes5              = 60  &      &               \\
M_1           &= \phantom{3\ntimes{}}4\ntimes5  = 20  &  B_1 &\cong 2 \pmod 3\\
M_2           &= 3\phantom{{}\ntimes4}\ntimes5  = 15  &  B_2 &\cong 3 \pmod 4\\
M_3           &= 3\ntimes4\phantom{{}\ntimes5}  = 12  &  B_3 &\cong 3 \pmod 5, 
\endmathcols
onde os invérsos $B_1$ e $B_2$ calculamos percebendo que
$20\cong-1 \pmod 3$ e $15\cong-1 \pmod 4$, e o $B_3$ com força bruta mesmo.
Pronto: as soluções do sistema são exatamente os inteiros $x$ que satisfazem:
$$
\alignat 3
x &\cong a_1M_1B_1 + a_2M_2B_2 + a_3M_3B_3                            &&\pmod M\\
  &\cong 2\ntimes20\ntimes1 + 3\ntimes15\ntimes3 + 3\ntimes12\ntimes3 &&\pmod {60}\\
  &\cong 40 + 135 + 108                                               &&\pmod {60}\\
  &\cong 40 + 15 + 108                                                &&\pmod {60}\by {$135\cong15\pmod{60}$} \\
  &\cong 55 + 48                                                      &&\pmod {60}\by {$108\cong48\pmod{60}$} \\
  &\cong -5 + 48                                                      &&\pmod {60}\by {$\phantom055\cong-5\pmod{60}$} \\
  &\cong 43                                                           &&\pmod {60}.
\endalignat
$$
Logo, o conjunto de todas as soluções do sistema é o $\setst {60k + 43} {k\in\ints}$.
Facilmente verificamos que os únicos dos seus elementos que satisfazem nossa
restricção $\abs x < 64$ são os inteiros obtenidos pelos valores de $k = 0$ e $-1$:
$x_1 = 43$, $x_2 = -17$.

%%}}}

%%{{{ x: coprime_vs_pairwise_coprime 
\exercise ``entre si'' vs ``dois-a-dois''.
%%%{{{ meta 
\label coprime_vs_pairwise_coprime
%%%}}}

Considere as frases:
\tlist:
\li (i):  Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos entre si.
\li (ii): Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos dois-a-dois.
\endtlist
São equivalentes?
Se sim, demonstre as duas direções da equivalência; se não, ache um contraexemplo.

\hint
Não são equivalentes.

\hint
Procure um contraexemplo com três inteiros.

\solution
Os $2$, $4$, $5$ são coprimos entre si (têm m.d.c.~1)
mas mesmo assim não são coprimos dois-a-dois:
$\gcd 2 4 = 2$.

%%}}}

%%{{{ x: solve systems of congruences 
\exercise.
%%%{{{ meta 
%%%}}}

Ache as soluções dos seguinte sistemas de congruências:
\mathcols 2
\text{(1)}\quad&
\lsystemed {
x  &\cong 3\phantom0 \pmod 4\\
5x &\cong 1\phantom0 \pmod 7\\
x  &\cong 2\phantom0 \pmod 9
}
&
\text{(2)}\quad&
\lsystemed {
x  &\cong 3\phantom0 \pmod 3\\
3x &\cong 3\phantom0 \pmod 4\\
4x &\cong 2\phantom0 \pmod 5\\
5x &\cong 1\phantom0 \pmod 7.
}
\endmathcols

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O exercício seguinte te convida descobrir que o teorema chinês pode ser aplicado
em casos mais gerais do que aparece inicialmente!

%%}}}

%%{{{ x: solve more systems of congruences 
\exercise.
%%%{{{ meta 
%%%}}}

Resolva os sistemas de congruências:
\mathcols 2
\text{(1)}\quad&
\lsystemed {
5x &\cong 2\phantom0  \pmod 6\\
x  &\cong 13 \pmod {15}\\
x  &\cong 2\phantom0  \pmod 7
}
&
\text{(2)}\quad&
\lsystemed {
x  &\cong 2\phantom0  \pmod 6\\
x  &\cong 13 \pmod {15}\\
x  &\cong 2\phantom0  \pmod 7.
}
\endmathcols

\hint
Observe que não podes aplicar o teorema chinês diretamente: $\gcd 6 {15} > 1$.

\hint
Tente substituir a congruência $5x \cong 2  \pmod 6$ com um sistema equivalente, de \emph{duas} congruências.

\hint
Mostre que para qualquer $a\in\ints$,
$$
\rightbrace {
a \cong 2 \pmod 6
}
\iff
\lsystemed {
a &\cong 0 \pmod 2 \\
a &\cong 2 \pmod 3.
}
$$

\hint
Não todos os sistemas de congruências tem soluções.
(Acontéce quando temos restricções contraditórias.)
Nesse exercício um dos dois sistemas não tem solução.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: infinitely_many_primes_3_mod_4 
\problem.
%%%{{{ meta 
\label infinitely_many_primes_3_mod_4
%%%}}}

Existe uma infinidade de primos ``da forma $4n+3$'', ou seja, o conjunto
$$
\setstt {4n+3} {$n\in\nats$ e $4n+3$ primo}
$$
é infinito.

\hint
Esquecendo o $2$, todos os primos são da forma $4n+1$ ou $4n+3$.
Suponha que $p_1, p_2,\dotsc, p_k$ ($k\in\nats$)
são todos os primos da segunda forma.

\hint
O que Euclides faria?

\hint
Tente achar (criar) um número da mesma forma tal que nenhum dos $p_i$ o divide.

\hint
$N = 4p_1p_2\dotsb p_k - 1$.

\hint
$N$ não pode ter apenas divisores da forma $4n+1$.  Por quê?

\hint
\dots porque multiplicando numeros da forma $4n+1$ seu produto continua da mesma forma.

\solution
Considere $k\in\nats$ arbitrário.
Basta encontrar um primo da forma $4n+3$ que é maior que o $k$-ésimo primo.
Seja $N = 4p_1p_2\dotsb p_k - 1$, que é um numero da forma $4n+3$
que não é divisível por nenhum dos $p_1,\dotsb,p_k$.
Agora observe que $N$ não pode ter apenas divisores da forma $4n+1$,
pois se fosse o caso ele seria da mesma forma.
Logo pelo menos um dos primos que o dividem é da forma $4n+3$
e maior que o $p_k$ (pelo \byfact1) e logo achamos o primo que estavamos procurando.

%%}}}

%%{{{ prob: why 4n+1 is more difficult? 
\problem.
%%%{{{ meta 
%%%}}}

Depois de ter resolvido o \ref[infinitely_many_primes_3_mod_4],
explique por que sua demonstração não é trivialmente adaptável
para resolver a mesma questão sobre os primos da forma $4n+1$.

\hint
\mathcols 2
(4n+3)(4n+3) &\askeq 4n'+3  & (-1)^n &\askeq -1
\endmathcols

%%}}}

%%{{{ thm: dirichlet_theorem_arithmetic_progression 
\theorem Dirichlet.
%%%{{{ meta 
\label dirichlet_theorem_arithmetic_progression
\credits
    * Dirichlet : teorema
    * Legendre : conjecura
    ;;
%%%}}}

Sejam inteiros $a,m \geq 1$ coprimos.
Existe uma infinidade de primos $p$ tal que $p \cong a \pmod m$.

\preproof.
Este teorema foi conjecturado---e usado!---por Legendre no ano
\yearof{1785} e finalmente demonstrado por Dirichlet no ano \yearof{1837}.

\sketch Cadê?.
Infelizmente, não temos uma demonstração com as ferramentas elementares
que temos elaborado aqui.  Para matá-lo usamos artilharia pesada,
\dterm{teoria dos números analítica}, que traz a Análise para estudar
assuntos da teoria dos números.
O livro \cite[serrearithmetic: Chapter VI] dedica um capítulo inteiro
à demonstração deste teorema, e o \cite[apostolant: Chapter 7] também!

%%}}}

\TODO elaborar e adicionar mais problemas relevantes; virar secção.

\endproblems
%%}}}

%%{{{ Some_ideas_of_Fermat 
\section Umas idéias de Fermat.
%%%{{{ meta 
\label Some_ideas_of_Fermat
\credits
    * Fermat
    ;;
%%%}}}

\TODO elaborar {\Fermat}Fermat~(\yearof{1607}--\yearof{1665}).

%%{{{ cor: fermat_little_theorem_2 
\theorem Fermat.
%%%{{{ meta 
\label fermat_little_theorem_2
\aka segundo pequeno Fermat.
\credits
    * Fermat : segundo teorema pequeno
    ;;
\indexes
    * teorema!segundo pequeno Fermat
    ;;
%%%}}}

Sejam $p$ primo e $a\in\ints$.
Então
$$
a^p \cong a \pmod p.
$$

\sketch.
Considere dois casos: $\gcd a p = 1$ ou $\gcd a p > 1$.
No primeiro usamos o~\ref[fermat_little_theorem_1].
No segundo, necessariamente temos $0\cong a^p\cong a \pmod p$.

\proof.
Temos dois casos:
\eop
\case{Caso $\gcd a p$ = 1}:
Pelo~\ref[fermat_little_theorem_1] temos:
$$
\align
a^{p-1} &\cong 1 \pmod p
\intertext{e multiplicando por $a$,}
a^p     &\cong a \pmod p.
\endalign
$$
\case{Caso $\gcd a p$ > 1}:
Nesse caso, como $p$ é primo, necessariamente $p \divides a$,
ou seja, $a \cong 0 \pmod p$,
logo $a^p \cong 0 \pmod p$.
Agora pela transitividade e
simetria da $congruência$ módulo~$m$, finalmente temos:
$a^p \cong a \pmod p$

%%}}}

%%{{{ eg: last_digit_of_big_number_example 
\example.
%%%{{{ meta 
\label last_digit_of_big_number_example
%%%}}}

Ache o último dígito do $2^{800}$.

\solution.
Procuramos um $y$ tal que $2^{800}\cong y \pmod {10}$
(por quê?).
Usando o teorema de Fermat~(\ref[fermat_little_theorem_1]) temos:
$$
\align
2^4 &\cong 1 \pmod 5,
\intertext{logo}
2^{800} = (2^4)^{200} &\cong 1 \pmod 5.
\endalign
$$
Então módulo~$10$ temos duas possibilidades (por quê?):
$$
2^{800} \cong
\knuthcases {
1 \pmod {10}\cr
6 \pmod {10}.\cr
}
$$
Podemos já eliminar a primeira porque $2^{800}$ é par.
Finalmente, o último dígito de $2^{800}$ é o $\digit6$.

%%}}}

%%{{{ x: first why 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no primeiro ``por quê?'' do~\ref[last_digit_of_big_number_example].

\hint
Escreva o inteiro como somatório baseado na sua forma decimal.

\hint
Divide ele por 10.

\solution
Para o número $n$ escrito em base decimal como
$\delta_k\delta_{k-1}\dotsb \delta_1\delta_0$,
temos:
$$
\align
n
&= d_0 + 10d_1 + 100d_2 + \dotsb 10^{k-1}d_{k-1} + 10^kd_k\\
&= \tubrace {d_0} {resto} + 10\tubrace {(d_1 + 10d_2 + \dotsb 10^{k-2}d_{k-1} + 10^{k-1}d_k)} {quociente},
\endalign
$$
onde $d_i$ é o correspondente valor do dígito $\delta_i$.
(Evitamos aqui confundir o ``dígito'' com seu valor usando notação diferente
para cada um, para enfatizar a diferença entre os dois conceitos.)

%%}}}

%%{{{ x: second why and new proof via chinese 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no segundo também, e ache um outro caminho para chegar no resultado,
usando o teorema chinês do resto (\ref[chinese_remainder_theorem]).

\hint
Qual a solução do sistema
$$
\align
x &\cong 1 \pmod 5\\
x &\cong 0 \pmod 2?
\endalign
$$

\solution
Podemos ou aplicar o teorema chinês (\ref[chinese_remainder_theorem]) no sistema de congruências
$$
\align
x &\cong 1 \pmod 5\\
x &\cong 0 \pmod 2,
\endalign
$$
ou, como $5\divides 10$, usar diretamente o~\ref[from_mod_m_to_mod_am],
para concluir que $x = 10k + 5i + 1$, onde $i=0,1$.

%%}}}

%%{{{ x: 41^75 mod 3 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o resto da divisão de $41^{75}$ por $3$.

\hint
Procure $y$ tal que $41^{75} \cong y \pmod 3$.

\hint
$\gcd {41} 3 = 1$.

\hint
$41^{75} = 41^{74}\ntimes 41$.

\hint
Fermat.

\solution
Como $\gcd {41} 3 = 1$, pelo teorema de Fermat (\ref[fermat_little_theorem_1])
temos
$$
41^{\tot 3} = 41^2 \cong 1 \pmod 3,
$$
e agora dividindo o $75$ por $2$, temos $75 = 2\ntimes 37 + 1$, então:
$$
\alignat 3
41^2 \cong 1 \pmod 3 &\implies (41^2)^{37}  &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}      &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}41    &&\cong 41 &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong 41 &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong \phantom02  &&\pmod 3.
\endalignat
$$
Outro jeito para escrever exatamente a mesma idéia,
mas trabalhando ``de fora pra dentro'', seria o seguinte:
$$
\alignat 2
41^{75} &= 41^{2\ntimes 37 + 1}\\
        &= 41^{2 \ntimes 37} 41\\
        &= (41^2)^{37} 41\\
        &\cong  1^{37} 41       &&\pmod 3\\
        &\cong  41              &&\pmod 3\\
        &\cong  2               &&\pmod 3.
\endalignat
$$
Então $41^{75} \bmod 3 = 2$.

%%}}}

\TODO Nova maneira de achar inversos.

\endsection
%%}}}

%%{{{ Primality 
\section Primalidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Residue systems 
\section Sistemas de resíduos.
%%%{{{ meta 
\label Residue_systems
%%%}}}

\endsection
%%}}}

%%{{{ Enter Euler 
\section Euler entra.
%%%{{{ meta 
\label Enter_Euler
%%%}}}

%%{{{ df: euler_phi_function 
\definition Funcção totiente de Euler.
%%%{{{ meta 
\label euler_phi_function
\credits
    * Euler : funcção totiente
    ;;
\indexes
    * Euler!funcção    see: funcção totiente
    * totiente         see: funcção totiente
    ;;
\defines
    * {\totsym} -- a funcção totiente de Euler
    * funcção!totiente de Euler
    ;;
%%%}}}

Seja inteiro $n>0$.
Definimos
$$
\tot n \defeq \size { \setst {i \in \set{1,\dotsc,n}} {\gcd i n = 1} }.
$$
Em palavras, $\tot n$ é o número dos inteiros entre $1$ e $n$ que são coprimos com $n$.

%%}}}

%%{{{ x: calculate some values of phi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule os valores da $\tot n$ para $n=1,2,3,4,8,11,12,16.$

%%}}}

%%{{{ prop: tot_of_prime 
\property.
%%%{{{ meta 
\label tot_of_prime
%%%}}}

$\text{$p$ primo} \implies \tot p = p-1.$

\proof.
Como $p$ é primo, ele é coprimo com todos os $1,\dotsc,p-1$.
E como $\gcd p p = p \neq 1$, pela definição da $\totsym$ temos
$\tot p = p-1$.

%%}}}

%%{{{ x: number_of_multiples_of_a_until_an 
\exercise.
%%%{{{ meta 
\label number_of_multiples_of_a_until_an
%%%}}}

Quantos multiplos de $a$ existem no $\set{1,2,\dotsc,a^n}$?

%%}}}

%%{{{ x: tot_is_par_for_n_greater_than_2 
\exercise.
%%%{{{ meta 
\label tot_is_par_for_n_greater_than_2
%%%}}}

$\tot n$ é par para todo $n\geq 3$.

\hint
Ache uma maneira de ``casar'' todos os $1 \leq i < n$ que são
coprimos com o $n$ entre-si.

%%}}}

%%{{{ x: tot_of_power_of_prime 
\exercise.
%%%{{{ meta 
\label tot_of_power_of_prime
%%%}}}

$
\text{$p$ primo} \implies
\tot {p^a} = p^a - p^{a-1} = p^{a-1} (p-1)
$.

\hint
Use a definição de $\totsym$ e o~\ref[number_of_multiples_of_a_until_an].

\solution
Seguindo a definição de $\totsym$, vamos contar todos os números
no $\set{1,2,\dotsc,p^i}$ que são coprimos com $p^i$.
Quantos não são?
Observe que como $p$ é primo,
os únicos que não são coprimos com ele,
são os múltiplos de $p$.
Pelo~\ref[number_of_multiples_of_a_until_an] temos a resposta.

%%}}}

%%{{{ x: sum_of_tots_of_powers_of_prime 
\exercise.
%%%{{{ meta 
\label sum_of_tots_of_powers_of_prime
%%%}}}

Sejam $p$ primo e $k\in\ints$.  Calcule o valor do somatório
$\Sum_{i=0}^k \tot {p^i}$.

\hint
Calcule o valor de cada termo aplicando o~\ref[tot_of_power_of_prime].

%%}}}

%%{{{ x: tot_of_product_of_primes 
\exercise.
%%%{{{ meta 
\label tot_of_product_of_primes
%%%}}}

$\text{$p,q$ primos, $p\neq q$} \implies \tot {pq} = (p-1)(q-1)$.

%%}}}

%%{{{ thm: tot_is_multiplicative 
\theorem.
%%%{{{ meta 
\label tot_is_multiplicative
\indexes
    * multiplicativa    see: funcção
    ;;
\defines
    * funcção!multiplicativa
    ;;
%%%}}}

A funcção $\totsym$ é \dterm{multiplicativa}:
$$
\gcd m n = 1 \implies \tot {mn} = \tot m \tot n.
$$

%%}}}

%%{{{ cor 
\corollary.
%%%{{{ meta 
%%%}}}

Se $n\geq 2$, então
$$
\tot n
= n \!\!\Prod\submath{\text{$p$ primo}\\p \divides n}\!\! \paren{1-\frac 1 p}
= n
\paren{1-\frac 1 {p_1}}
\paren{1-\frac 1 {p_2}}
\dotsb
\paren{1-\frac 1 {p_k}},
$$
onde os $p_i$'s são todos os primos divisores de $n$.

\sketch.
Escrevemos o $n$ na sua representação canônica pelo
\ref[fundamental_theorem_of_arithmetic]
e aplicamos repetetivamente o~\ref[tot_is_multiplicative].

\proof.
Pelo \ref[fundamental_theorem_of_arithmetic] seja
$$
n \eqass p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}
$$ a
\indexed[representação canônica!de inteiro]representação canônica do $n$.
Calculamos:
\compute
\tot n
&= \tot {p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}}              \\
&= \tot {p_0^{a_0}} \tot{p_1^{a_1}} \dotsb \tot{p_k^{a_k}}  \by {\ref[tot_is_multiplicative]} \\
&=
p_0^{a_0}\paren{1 - \frac 1 {p_0}}
p_1^{a_1}\paren{1 - \frac 1 {p_1}}
\dotsb
p_k^{a_k}\paren{1 - \frac 1 {p_k}}                          \by {\ref[tot_of_power_of_prime]} \\
&=
p_0^{a_0}p_1^{a_1}\dotsb p_k^{a_k}
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}\\
&=
n
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}.
\endcompute

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

$a \divides b \implies \tot a \divides \tot b$.

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

$
\tot {2n} =
\knuthcases {
2\tot n,& $n$ é par \cr
\tot n, & $n$ é ímpar.
}
$

%%}}}

%%{{{ thm: euler_congruence_theorem 
\theorem Euler, de congruência.
%%%{{{ meta 
\label euler_congruence_theorem
\credits
    * Euler : teorema de congruência
    ;;
%%%}}}

Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$

\sketch.
Considere o conjunto
$$
\align
 R &= \set{r_1, r_2, \dotsc, r_{\tot m}}
\intertext{de todos os inteiros $r$ com $1 \leq r \leq m$, e $\gcd r m = 1$, e o conjunto}
aR &= \setst {ar} {r \in R}\\
   &= \set{ar_1, ar_2, \dotsc, ar_{\tot m}}.
\endalign
$$
Observamos agora que (módulo~$m$) os $ar_1,ar_2,\dotsc,ar_{\tot m}$
são apenas uma permutação dos $r_1,r_2,\dotsc,r_{\tot m}$.
Logo os seus produtórios são congruentes:
$$
(ar_1)(ar_2)\dotsb (ar_{\tot m})
\cong
r_1r_2\dotsb r_{\tot m}
\pmod m.
$$
Trabalhando na última congruência chegamos na congruência desejada.

%%}}}

%%{{{ cor: fermat_little_theorem_1 
\corollary.
%%%{{{ meta 
\label fermat_little_theorem_1
\aka primeiro pequeno Fermat.
\credits
    * Fermat : primeiro teorema pequeno
    ;;
\indexes
    * teorema!primeiro pequeno Fermat
    ;;
%%%}}}

Sejam $p$ primo e $a\in\ints$ com $\gcd a p = 1$.
Então
$$
a^{p-1} \cong 1 \pmod p.
$$

\sketch.
O resultado é imediato usando o teorema de Euler
(\reftag[euler_congruence_theorem]) e a~\ref[tot_of_prime].

\proof.
Como $p$ é primo, sabemos que $\tot p = p-1$, então temos:
\compute
a^{p-1}
&= a^{\tot m}       \by {\ref[tot_of_prime]} \\
&\cong 1 \pmod m.   \by {\ref[euler_congruence_theorem]} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: little_fermat_multionomial_proof 
\problem.
%%%{{{ meta 
\label little_fermat_new_proof
%%%}}}

Ache mais uma demonstração do ``pequeno Fermat'' usando o teorema multinominal.
Essa provavelmente é a primeira demonstração do teorema, feita (sem publicar)
por {\Leibniz[demonstração do pequeno Fermat]}Leibniz,
e redescoberta depois por {\Euler[demonstração do pequeno Fermat]}Euler.

%%}}}

\endproblems
%%}}}

%%{{{ Cryptography 
\section Criptografía.
%%%{{{ meta 
%%%}}}

%%{{{ The idea of cryptography 
\TODO A idéia da criptografia.
%%}}}

%%{{{ Public-key cryptography 
\TODO Criptografia ``public-key''.
%%}}}

%%{{{ Criptografia RSA 
\TODO RSA criptografia e descriptografia.
%%}}}

%%{{{ thm 
\theorem.
%%%{{{ meta 
%%%}}}

Sejam $e, M\in\ints$ com $\gcd e {\tot M} = 1$,
e seja $d$ um inverso de $e$ módulo~$\tot M$: $ed \cong 1 \pmod {\tot M}$.
Para cada $m$ com $\gcd m M = 1$,
$$
\paren{m^e}^d \cong m \pmod M.
$$

\proof.
Observe primeiramente que:
\compute
ed \cong 1 \pmod {\tot M}
&\iff \tot M \divides ed - 1                    \by {pela def.~de congruência \reftag[congruence_modulo_int]} \\
&\iff \lexists {k\in\ints} {k\tot M = ed - 1}.  \by {pela def.~de divide \reftag[divides]} \\
\endcompute
Seja $k\in\ints$ então um tal $k$, e agora resolvendo por $ed$:
$$
ed = k\tot M + 1.
\tag{*}
$$
Calculamos:
\compute
\paren{m^e}^d
&= m^{ed}                   \\
&= m^{k\tot M + 1}          \by {por~(*)} \\
&= m^{k\tot M} m            \by {def.~de exponenciação} \\
&= \paren{m^k}^{\tot M} m   \\
&\cong m  \pmod M,          \by {por teorema de Euler~\reftag[euler_congruence_theorem]} \\
\endcompute
onde no último pásso precisamos a hipótese que $m$ e $\tot M$ são coprimos
e logo, $m^k$ e $\tot M$ também são: $\gcd m {\tot M} = \gcd {m^k} {\tot M} = 1$.

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

O que acontece se $m$ e $\tot M$ não são coprimos?

%%}}}

\endsection
%%}}}

%%{{{ Digital signatures 
\section Assinaturas digitais.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: odd_to_any_power_is_odd_oneliner 
\problem.
%%%{{{ meta 
\label odd_to_any_power_is_odd_oneliner
%%%}}}

Demonstre numa linha o~\ref[odd_to_any_power_is_odd]:
\proclaim{para todo $n\in\nats$ e todo ímpar $k\in\ints$, $k^n$ é ímpar.}

%%}}}

%%{{{ prob: generalization of odd_to_any_power_is_odd 
\problem.
%%%{{{ meta 
%%%}}}

(Generalização do~\ref[odd_to_any_power_is_odd].)
Sejam $a\in\ints$ e $m\in\nats$.
Demonstre numa linha que para todo $n\in\nats$, existe $b\in\ints$ tal que $(am + 1)^n = bm + 1$.

%%}}}

%%{{{ prob: m! divides the product of m consecutive ints 
\problem.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $m\in\nats$, o produto de $m$ consecutivos inteiros é divisível por $m!$.

%%}}}

%%{{{ prob: freshmans_dream 
\problem O sonho do calouro.
%%%{{{ meta 
\label freshmans_dream
\indexes
    * sonho do calouro
    ;;
%%%}}}

Seja $p$ primo, $x,y\in\ints$.
$$
(x + y)^p \cong x^p + y^p \pmod p.
$$

\hint
Use o teorema binomial~\reftag[binomial_theorem].

\hint
Use o \ref[p_divides_comb_p_r].

\solution
Temos
\compute
(x + y)^p
&= \Sum_{i=0}^p \binom p i x^{p-i}y^i             \by {por~\ref[binomial_theorem]} \\
&= \binom p 0 x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + \binom p p y^p             \by {$p\geq2$} \\
&= x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + y^p     \\
&= x^p + \Sum_{i=1}^{p-1} p c_i x^{p-i}y^i + y^p, \quad\text{para algum $c_i\in\ints$}  \by {por~\ref[p_divides_comb_p_r]} \\
&= x^p + p \Sum_{i=1}^{p-1} c_i x^{p-i}y^i + y^p          \\
&\cong x^p + y^p \pmod p.
\endcompute

%%}}}

%%{{{ prob: little_fermat_new_proof 
\problem.
%%%{{{ meta 
\label little_fermat_new_proof
%%%}}}

Ache uma nova prova, \emph{por indução}, do teorema de Fermat~\reftag[fermat_little_theorem_2]:
\eop\noi
{\sl Para todo primo $p$ e todo $a\in\ints$},
$$
a^p \cong a \pmod p.
$$
(Note que $a\in\ints$ e não $a\in\nats$.)

\hint
Use o sonho de calouro (\ref[freshmans_dream]).

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Demonstre que
$$
\tot {mn}
=
{\tot m \tot n}
\frac
d
{\tot d}
,\qquad\text{onde $d={\gcd m n}$}.
$$
Note quantas e quais das propriedades que já provamos são casos especiais dessa!

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Sejam $p,q$ primos com $p\neq q$.
Demonstre que
$$
p^{q-1} + q^{p-1} \cong 1 \pmod {pq}.
$$

\hint
O que seria o $p^{q-1} + q^{p-1}$ módulo~$p$?
E módulo~$q$?

\hint
China.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Ache uma generalização do problema anterior,
aplicável para inteiros $a,b$ com $\gcd a b = 1$:

\hint
Nesse caso \emph{não} temos
$$
a^{b-1} + b^{a-1} \cong 1 \pmod {ab}.
$$

\hint
$p-1 = \tot p$ para qualquer primo $p$.

\hint
Demonstre que:
$$
a^{\tot b} + b^{\tot a} \cong 1 \pmod {ab}.
$$

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[babybm: \S\S1.6--1.9].

\cite[elements],
\cite[disquisitiones].

\cite[andrewsnumber].

\cite[nivennumbers],
\cite[hardywright].

Se os vários sistemas de numerais te deixaram com vontade de conhecer e analisar
mais, veja no \cite[taocp2: \S4.1].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Sets 
\chapter Conjuntos.
%%%{{{ meta 
\label Sets
%%%}}}

%%{{{ intro: sets like assembly 
\chapintro
Neste capítulo estudamos um tipo de objeto matemático: o \emph{conjunto}.
Além dele, encontramos seus tipos-amigos: \emph{tuplas}, \emph{seqüências},
e \emph{famílias indexadas}.
Como nós vamos apreciar no~\ref[Axiomatic_set_theory],
os conjuntos e sua linguagem têm um papel importante para a
\emph{fundação de matemática}.
Mas por enquanto nos importa apenas nos acostumar com esses tipos,
seus objetos, suas operações e relações; aprender usá-los e nada mais!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

%%{{{ Q: What does it mean to be a set? 
\question.
%%%{{{ meta 
%%%}}}

O que significa ser conjunto?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

{\Cantor}Cantor deu a seguinte resposta:

%%}}}

%%{{{ pseudodf: set 
\pseudodefinition.
%%%{{{ meta 
\label set_pseudodefinition
\defines
    * conjunto!definição intuitiva
    ;;
%%%}}}

Um \dterm{conjunto} $A$ é a colecção numa totalidade
de certos objetos (definidos e separados) da nossa intuição ou mente, que chamamos de \dterm{elementos} de $A$.

%%}}}

%%{{{ x: set_pseudodefined 
\exercise.
%%%{{{ meta 
%%%}}}

Qual é o problema principal com a definição acima?

\solution
O que é uma ``colecção (numa totalidade)''?
Cuidado: para responder nessa pergunta
tu não podes usar a palavra ``conjunto'', pois assim teria uma
definição circular.
Em outras palavras, definimos a palavra ``conjunto'' em termos da palavra
``colecção'', que no final das contas, é algo sinónimo.

%%}}}

%%{{{ prim: set 
\primitive conjunto.
%%%{{{ meta 
\label set_primitive
\defines
    * ~x \in ~A  -- $x$ é um membro do conjunto $A$
    * conjunto
    ;;
%%%}}}

Aceitamos apenas duas \emph{noções primitivas} (\reftag[Axioms_and_primitive_notions]):
$$
\gathered
\text{ser conjunto}\\
\Set(\dhole)
\endgathered
\qqqquad
\gathered
\text{pertencer}\\
\dhole\in\dhole
\endgathered
$$
Escrevemos \sq{$x \in A$} e pronunciamos
\utter{(o objeto) $x$ é um membro do (conjunto) $A$},
ou simplesmente \utter{$x$ pertence ao $A$}.

%%}}}

%%{{{ notation: set_notation 
\notation.
%%%{{{ meta 
\label set_notation
\defines
    * conjunto!heterogêneo
    * conjunto!homogêneo
    * conjunto!notação
    * heterogeneidade
    * homogeneidade
    ;;
\pdefs
    \pdef Natal  {{\mathrm{Natal}}}
    \pdef Thanos {{\mathrm{Thanos}}}
    ;;
%%%}}}

A notação mais simples para denotar um conjunto é usar
``chaves'' (os símbolos~\symq{$\{$}~e~\symq{$\}$}) e listar todos
os seus elementos dentro, os escrevendo numa ordem da nossa escolha.
Por exemplo:
$$
\xalignat2
A &=\set {0,1}                          &E &=\set {2,3,\set{5,7}, \set{\set{2}}}\\
B &=\set {\nats, \ints, \rats, \reals}  &F &=\set {\Thanos}\\
C &=\set {2}                            &G &=\set {1,2,4,8,16,31,A,B,\nats}\\
D &=\set {2,3,5,7}                      &H &=\set {\Thanos, \Natal, \set{E,\set{F,G}}}
\endxalignat
$$

%%}}}

%%{{{ df: homogeneous_and_heterogeneous_sets 
\definition.
%%%{{{ meta 
\label homogeneous_and_heterogeneous_sets
%%%}}}

Chamamos os conjuntos cujos elementos são ``do mesmo tipo'' \dterm{homogêneos},
e os outros \dterm{heterogêneos}.
Deixamos sem explicação o que significa ``do mesmo tipo'', mas, naturalmente,
consideramos os $A, B, C, D, F$ da~\ref[set_notation] homogêneos
e os $E, G, H$ heterogêneos.
Até o $\set{ \set{1,2}, \set{\set{2,3}, \set{3,4}} }$ acaba heterogêneo
se olhar bem: um dos seus membros é conjunto \emph{de números},
mas o outro é conjunto \emph{de conjuntos de números}.

%%}}}

%%{{{ Dealing with more complicated sets 
\blah.
%%%{{{ meta 
%%%}}}

Todos os conjuntos que acabamos de escrever aqui são \emph{finitos},
seus elementos são conhecidos, e ainda mais são poucos e conseguimos listar todos eles.
Nenhuma dessas três propriedades é garantida!
Se não temos a última fica impráctico listar todos elementos,
e quando não temos uma das duas primeiras, é plenamente impossível.
Considere por exemplo os conjuntos seguintes:
$$
\align
X &= \text{o conjunto de todos os números reais entre 0 e 1}\\
Y &= \text{o conjunto dos assassinos do Richard {\Montague}Montague}\\
Z &= \text{o conjunto de todos os números naturais menores que $2^{256!}$}.
\endalign
$$

%%}}}

%%{{{ df: set_builder 
\definition Set builder.
%%%{{{ meta 
\label set_builder
\indexes
    * set!comprehension    seealso: set builder
    * definitiva               see: condição
    ;;
\defines
    * \setst {~x} {~{\phi(x)}}  -- o conjunto de todos os $x$ tais que $\phi(x)$
    * condição definitiva
    * set builder
    * set comprehension
    ;;
%%%}}}

Uma notação diferente e bem útil é chamada
notação \dterm{set-builder} (ou \dterm{set comprehension}),
onde escrevemos
$$
\setstt x {\thole$x$\thole}
$$
para denotar <<o conjunto de todos os objetos $x$ tais que \thole$x$\thole>>.\foot
Na literatura aparecem também os símbolos~\symq{$:$}~e~\symq{$;$}~em
vez do~\symq{$\st$}~que usamos aqui.
\toof
Entendemos que no lado direito escrevemos o \dterm{filtro},
uma \emph{condição definitiva},
e não algo ambíguo ou algo subjectivo.  Por exemplo, não podemos escrever 
algo do tipo
$$
\setst p { \text{$p$ é uma pessoa linda} }.
$$
Mas como podemos formalizar o que é uma \dterm{condição definitiva}?
Bem, concordamos escrever apenas algo que podemos (se precisarmos e se quisermos)
descrever usando uma fórmula de FOL $\phi(x)$ onde possivelmente aparece
a variável $x$ livre e todos os símbolos da FOL tem interpretações bem-definidas.\foot
Pouco mais sobre isso na~\ref[fol_filter_by_fraenkel_and_skolem].
\toof
Chegamos então na forma
$$
\setst x {\phi(x)}.
$$
A notação set-builder é bem mais poderosa do que acabamos de mostrar,
pois nos permite utilisar \emph{termos} mais complexos na sua parte esquerda,
e não apenas uma variável.
Vamos investigar isso e mais variações logo na~\ref[full_setbuilder].

%%}}}

%%{{{ remark: variable_binder_in_set_builder 
\remark.
%%%{{{ meta 
\label variable_binder_in_set_builder
\defines
    * variável!ligada
    * variável!livre
    ;;
%%%}}}

Na notação
$$
\setstt {\alert x} {\thole$x$\thole}
$$
temos um \emph{ligador de variável}, pois o $\alert x$ no lado esquerdo
liga todos os $x$'s que aparecem no lado direito livres (e assim viram ligados).
Por exemplo, o conjunto
$$
\setst x {x^2 < xy}
$$
depende do $y$ (mas não do $x$).

%%}}}

%%{{{ beware: variable_capturing_in_set_builder 
\beware Capturação de variável.
%%%{{{ meta 
\label variable_capturing_in_set_builder
\indexes
    * variável!capturada
    * variável!dummy
    ;;
\defines
    * variável!capturada
    ;;
%%%}}}

Podemos trocar o ``dummy'' $x$ por qualquer variável
\emph{que não aparece livre na parte direita},
tomando cuidado para renomiar as ligadas também.
Por exemplo
$$
\setst {\alert x} {\alert x^2 < \alert x y} \inteq
\setst {\alert z} {\alert z^2 < \alert z y}
$$
Mas
$$
\setst {\alert x} {\alert x^2 < \alert x y} \intneq
\setst {\alert y} {\alert y^2 < \alert y \alert y}
$$
pois o $y$ que tava livre no ``filtro'' acabou sendo
\emph{capturado} pelo ligador no set builder:
dentro dos $\set{\dots}$ perdemos o
acesso no objeto denotado por $y$ fora.
O $\setst y {y^2 < yy}$ não depende mais do $y$.

%%}}}

%%{{{ set_synonyms_and_fonts 
\note Sinônimos e fontes.
%%%{{{ meta 
\label set_synonyms_and_fonts
\defines
    * colecção
    * família
    ;;
%%%}}}

Às vezes usamos os termos \dterm{família} e \dterm{colecção}
como sinónimos da palavra \wq{conjunto}---mas veja a \ref[collection_vs_set] também.
Seguindo uma práctica comum, quando temos conjuntos de conjuntos
dizemos \emph{família de conjuntos}, e depois
\emph{colecção de famílias}, etc., pois soam melhor e ajudam raciocinar.
Com o mesmo motivo (de agradar ou facilitar nossos olhos,
ouvidos, ou cerebros humanos), às vezes mudamos (``elevamos'')
a fonte que usamos para denotar esses conjuntos:
de $A,B,C,\dots$
para $\cal A, \cal B, \cal C, \dots$
para $\scr A, \scr B, \scr C, \dots$
por exemplo, dependendo de quantos ``níveis de conjuntamentos aninhados''
temos.
Para ilustrar, imagine que já temos definido uns conjuntos $A_1, A_2, A_3, B, C$
e agora queremos falar sobre os conjuntos $\set{A_1, A_2, A_3}$ e $\set{B,C}$
e dar nomes para eles.
Uma escolha razoável seria usar $\scr A$ e $\scr B$ para denotá-los:
$$
\xalignat2
\scr A &= \set{A_1, A_2, A_3} &
\scr B &= \set{B,C}
\endxalignat
$$
mas isso é apenas questão de costume.  Nada profundo aqui.

%%}}}

%%{{{ remark: collection_vs_set 
\remark.
%%%{{{ meta 
\label collection_vs_set
\defines
    * colecção
    ;;
%%%}}}

Eu vou tentar usar a palavra \dterm{colecção} principalmente
com seu significado intuitivo e informal que suponho que
tu entendes; deixando assim as outras duas (\emph{conjunto}
e \emph{família}) para usar na matemática.

%%}}}

%%{{{ teaser: collection_vs_set_teaser 
\teaser.
%%%{{{ meta 
\label collection_vs_set_teaser
%%%}}}

Em geral um conjunto (metamático) realmente representa
uma colecção (a dos seus membros), mas como veremos
no~\ref[Axiomatic_set_theory] isso não é sempre o caso.
Encontramos \emph{colecções que não podem ser representadas
por conjunto nenhum} (o motivo mais comum sendo que são
grandes demais, algo que deve aparecer estranho já que
temos \emph{conjuntos infinitos}); mas pode ter outros
motivos também!

%%}}}

%%{{{ warning: set_synonyms_warning 
\warning.
%%%{{{ meta 
\label set_synonyms_warning
\defines
    * classe
    * espaço
    ;;
%%%}}}

Mais duas palavras que às vezes são usadas como sinônimos da \wq{conjunto}
são as \emph{classe} e \emph{espaço}.
Evitarei seu uso aqui por motivos diferentes para cada uma.
A primeira (viz.~\dterm{classe}) é usada em teorias de fundamentos
matemáticos, como teorias axiomáticas de conjuntos,
(\ref[Axiomatic_set_theory]) e seu papel é exatamente isso:
diferenciar o conceito que ela denota por aquele de conjunto!
A segunda, (viz.~\dterm{espaço}) dá a idéia que tal conjunto
tem ``algo mais'' do que \emph{apenas}
seus membros: um certo tipo de \emph{estrutura} (\ref[Structured_sets]):
talvez alguma relação, e/ou operações, etc.:
\wq{\dots mais que conjuntos: espaços!}
Temos espaços:
métricos (\ref[Metric_spaces]),
topológicos (\reftag[General_topology]),
vetoriais (\reftag[Vector_spaces]),
sóbrios(!),
poloneses,
projetivos,
afim,
de {\Euclid}Euclides,
de {\Cantor}Cantor,
de {\Baire}Baire,
de {\Borel}Borel,
de {\Hilbert}Hibert,
de {\Banach}Banach,
de {\Hausdorff}Hausdorff (\reftag[Hausdorff_and_separation_axioms]),
de {\Frechet}Fréchet,
de {\Stone}Stone,
e muitos mais de\dots muita gente boa!
E mesmo assim, não temos uma definição matemática do que significa
a palavra (\emph{espaço}) sozinha!
Note também que em linguagens naturais \emph{grupo} é mais uma palavra que
pode servir como sinônimo de \wq{conjunto} mas em matemática não:
no~\ref[Group_theory] definimos o que essa palavra significa \wq{grupo}
em matemática e estudamos sua linda teoria: a teoria dos grupos.

%%}}}

%%{{{ What we need to specify for each new type 
\note Tipos.
%%%{{{ meta 
%%%}}}

Cada vez que introduzimos um novo tipo de objetos,
devemos especificar:
\elist i:
\li: Quando dois objetos desse tipo são \emph{iguais}?
\li: Qual é o ``interface'' desses objetos?
\endelist

%%}}}

%%{{{ Black boxes 
\note Black boxes.
%%%{{{ meta 
\label blackbox_set
\indexes
    * black box    seealso: white box
    * white box    seealso: black box
    * conjunto!como black box    see: black box
    ;;
\defines
    * black box
    * black box!de conjunto
    * white box
    ;;
%%%}}}

O conceito de \dterm{black box} (ou \dterm{caixa preta}) é uma ferramenta muito
útil para descrever tipos.
A idéia é que queremos descrever o que realmente determina um objeto desse tipo,
e \emph{esconder} os detalhes ``de implementação'', apresentando apenas seu
``interface''.
Podemos então pensar que um conjunto $A$ é um black box que tem apenas uma
``entrada'' onde podemos botar qualquer objeto $x$ que desejamos, e tem também
uma luz que pode piscar ``sim'' ou ``não'' (correspondendo nos casos
$x\in A$ e $x\notin A$ respectivamente).
\Tikzi blackboxset;
Usamos o termo \emph{black} box para enfatizar que não temos como ``olhar dentro''
desse aparelho, dessa caixa, e ver o que acontece assim que botar uma entrada;
nossa única informação será a luz da caixa que vai piscar ``sim'' ou ``não''.
Quando temos acesso nos ``internals'' da caixa a gente chama de \dterm{white box}
ou \dterm{transparent box}; mas não vamos precisar o uso desse conceito agora.
\eop
A única \emph{estrutura interna} de um conjunto é a capabilidade de
\emph{decidir se dois elementos $x,y$ do conjunto são iguais ou não}.

%%}}}

%%{{{ Q: When are two sets equal? 
\question.
%%%{{{ meta 
%%%}}}

Quando dois conjuntos são iguais?

%%}}}

\spoiler

%%{{{ pseudodf: set_eq_pseudodefinition 
\pseudodefinition.
%%%{{{ meta 
\label set_eq_pseudodefinition
%%%}}}

Consideramos dois conjuntos $A,B$ \dterm{iguais} sse não tem como diferenciar
eles como black boxes.  Em outras palavras, para cada objeto $x$
que vamos dar como entrada para cada um deles, eles vão concordar:
ou ambos vão piscar ``sim'', ou ambos vão piscar ``não''.
O ``slogan'' aqui é:
$$
\text{\emph{um conjunto é determinado por seus membros}}.
$$

%%}}}

%%{{{ df: set_eq 
\definition Igualdade de conjuntos.
%%%{{{ meta 
\label set_eq
%%%}}}

Dois conjuntos são iguais sse têm exatamente os mesmos membros.
Em símbolos,
$$
A = B \defiff \lforall x {x\in A \iff x\in B}.
$$

%%}}}

%%{{{ defining_sets 
\note Definindo conjuntos.
%%%{{{ meta 
\indexes
    * condição definitiva
    ;;
%%%}}}

Para determinar então um conjunto $A$ precisamos dizer exatamente
quando um objeto arbitrário $x$ pertence ao $A$.
As notações que viermos até agora realmente deixam isso claro;
mas um outro jeito muito útil para \emph{definir} um certo conjunto $A$,
seria apenas preencher o
$$
x \in A  \defiff  \text{\xlthole}
$$
com alguma condição definitiva
(veja~\ref[set_builder]).
\eop
Concluimos que as duas formas seguintes de definir um conjunto $A$,
são completamente equivalentes:
$$
\xalignat2
x &\in A \defiff \text{\lthole}
&
A &\defeq \setst x {\text{\lthole}}.
\endxalignat
$$
As duas afirmações tem exatamente o mesmo efeito:
definir o mesmo conjunto $A$.
Qual das duas usamos, será mais questão de gosto ou de contexto.

%%}}}

%%{{{ remark: what_is_being_defined_really_sets 
\remark O que tá sendo definido mesmo?.
%%%{{{ meta 
\label what_is_being_defined_really_sets
%%%}}}

Definindo um conjunto $A$ pela
$$
x \in A \defiff \xlthole
$$
o que estamos definindo diretamente não é o \sq{$A$} mas o \sq{$x \in A$}.
Só que: o $A$, sendo conjunto, ele é \emph{determinado por seus membros}
(lembra a~\ref[set_eq_pseudodefinition]) ou seja, sabendo
o que $x \in A$ significa para todo $x$, sabemos \emph{quem é} o $A$.

%%}}}

%%{{{ note: order_and_multiplicity 
\note Ordem e multiplicidade.
%%%{{{ meta 
\label order_and_multiplicity
\indexes
    * conjunto!multiplicidade
    * conjunto!ordem de membros
    ;;
%%%}}}

Considere os conjuntos seguintes:
$$
\xalignat3
A&=\set{2,3},&
B&=\set{3,2},&
C&=\set{3,2,2,2,3}.
\endxalignat
$$
Observe que $A = B = C$.
Ou seja, esses não são três conjuntos, mas apenas \emph{um} conjunto
denotado em três jeitos diferentes.
O ``dispositivo'' conjunto não sabe nem de \dterm{ordem}
nem de \dterm{multiplicidade} dos seus membros.
Não podemos perguntar a um conjunto
<<qual é teu \emph{primeiro} elemento?>>, nem 
<<\emph{quantas vezes} o tal elemento pertence a ti?>>.
Lembre o conjunto como black box!
Sua única interface aceita qualquer objeto,
e responde apenas com um pleno sim ou não.
Logo encontraremos outros tipos de ``recipientes'',
onde as informações de ordem e de multiplicidade são preservadas
(e perguntáveis):
multisets~(\reftag[Multisets]), tuplas~(\reftag[Tuples]), e seqüências~(\reftag[Sequences]).
Bem depois vamos estudar \emph{conjuntos ordenados} (\ref[Posets_Lattices]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por enquanto temos apenas duas relações entre conjuntos:
igualdade ($=$)---que sempre temos para qualquer tipo de objetos---e
essa ``nova'' de pertencer ($\in$);
Logo vamos definir mais;
mas antes disso, bora discutir sobre dois conceitos de igualdade diferentes
que mencionei já na~\ref[Intension_vs_extension].\foot
Vai que não ficou claro lá, ou que tu pulou
o \ref[Introductions]---mas tu nunca faria isso, né?
\toof

%%}}}

\endsection
%%}}}

%%{{{ Intension_vs_extension_in_sets 
\section Intensão \vs extensão.
%%%{{{ meta 
\label Intension_vs_extension_in_sets
%%%}}}

%%{{{ Consider four extensionally equal sets 
\note.
%%%{{{ meta 
%%%}}}

Condidere os conjuntos
$$
\align
P &= \setst d {\text{$d$ é um divisor primo de $2^{256!}$}}\\
Q &= \setst p {\text{$p$ é primo e par}}\\
R &= \setst x {\text{$x$ é raiz real do polinómio $x^3 - 8$}}\\
S &= \set {2}.
\endalign
$$

%%}}}

%%{{{ Q: what_are_the_extensions_of_these_four_sets} 
\question.
%%%{{{ meta 
\label what_are_the_extensions_of_these_four_sets
%%%}}}

Quais são os membros de cada um dos conjuntos acima?


%%}}}

%%{{{ A: thinking a bit, they're all the same set 
\blah Resposta.
%%%{{{ meta 
%%%}}}

\emph{Pensando um pouco} percebemos que esses quatro conjuntos
consistem em exatamente os mesmos membros, viz.~o número $2$ e nada mais.
Lembrando na idéia de black box, realmente não temos como diferenciar
entre esses black boxes.
Começando com o $S$, é direto que ele responda ``sim'' apenas no número $2$
e ``não'' em todos os outros objetos.
Continuando com o $P$, realmente temos que o único objeto que satisfaz
seu filtro é o número $2$.  Mesma coisa sobre os $Q$ e $R$.

%%}}}

%%{{{ intension_description 
\note.
%%%{{{ meta 
\label intension_description
\defines
    * extensão!de conjunto
    * igualdade!extensional
    * igualdade!intensional
    * intensão!de conjunto
    ;;
%%%}}}

Como comporta o $S$?
Recebendo sua entrada $a$, ele a compara com o $2$ para ver se $a=2$ ou não,
e responde ``sim'' ou ``não'' (respectivamente) imediatamente.
E o $R$?
Recebendo sua entrada $a$, ele verifica se $a$ é uma raiz do $x^3 - 8$.
Substituindo então o $x$ por $a$, elevando o $a$ ao $3$ e subtraindo $8$,
se o resultado for $0$ responda ``sim''; caso contrário, ``não''.
E o $Q$?
Recebendo sua entrada $a$, ele verifica se $a$ é primo, e se $a$ e par.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
E o $P$?
Recebendo sua entrada $a$, ele verifica se $a \divides 2^{256!}$ e se $a$ é
um número primo.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
\eop
Acabamos de descrever a \dterm{intensão} de cada conjunto.
Mas, sendo black boxes, dados esses conjuntos $P,Q,R,S$,
não conseguimos diferenciá-los, pois a única interação que sua interface
permite é botar objetos $a$ como entradas, e ver se pertencem ou não.
Falamos então que \dterm{extensionalmente} os quatro conjuntos
são iguais, mas \dterm{intensionalmente}, não.
Usamos os termos \dterm{igualdade extensional} e \dterm{igualdade intensional}.
E para abusar a idéia de black box:
provavelmente o black box $Q$ demora mais para responder, ou fica mais quente,
ou faz mais barulho, etc., do que o $S$.
\eop
Quando definimos um conjunto simplesmente listando todos os seus membros,
estamos escrevendo sua \dterm{extensão}.  E nesse caso, a intensão é a mesma.
Quando usamos a notação builder com um filtro, estamos mostrando a \dterm{intensão}
do conjunto.  Nesse caso as duas noções podem ser tão diferentes, que nem
sabemos como achar sua extensão!

%%}}}

%%{{{ eg: number_theory_conjectures_set_intension 
\example.
%%%{{{ meta 
\label number_theory_conjectures_set_intension
%%%}}}

Revise a~\ref[Open_problems_in_number_theory] e considere os conjuntos
$$
\align
T &\defeq
\setstt p {$p$ e $p+2$ são prímos}\\
L &\defeq
\setstt n {$n \in \nats_{>0}$ e não existe primo entre $n^2$ e $(n+1)^2$}\\
G &\defeq
\setstt n {$n \in \nats_{>1}$ e $2n=p+q$ para alguns primos $p,q$}\\
C &\defeq
\setstt n {$n \in \nats_{>0}$ e a seqüência Collatz começando com $n$ nunca pega o valor $1$}.
\endalign
$$
Sobre o $T$ não sabemos se é finito ou não!
Sobre o $G$, não sabemos se $G = \nats_{>1}$ ou não!
E, sobre os $L$ e $C$ nem sabemos se eles têm elementos ou não,
ou seja, não sabemos nem se $L=\emptyset$ nem se $C=\emptyset$!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Fechando essa secção lembramos que em conjuntos (e em matemática em geral)
usamos igualdade \symq{$=$} como igualdade extensional.

%%}}}

\endsection
%%}}}

%%{{{ Relations between sets and how to define them 
\section Relações entre conjuntos e como defini-las.
%%%{{{ meta 
%%%}}}

%%{{{ df: subconjunto 
\definition.
%%%{{{ meta 
\label subconjunto
\defines
    * ~A \subset ~B  -- $A$ é um subconjunto de $B$
    * subconjunto
    * subconjunto!próprio
    ;;
%%%}}}

O conjunto $A$ é um \dterm{subconjunto} de $B$ sse todos os membros de
$A$ pertencem ao $B$.
Em símbolos:
$$
A \subset B
\defiff
\lforall {x\in A} {x\in B}.
$$
Se $B$ tem elementos que não pertencem ao $A$, chamamos o $A$
um \dterm{subconjunto próprio} de $B$, e escrevemos $A \psubset B$.

%%}}}

%%{{{ warning: psubset_vs_nsubset_notation 
\warning.
%%%{{{ meta 
\label psubset_vs_nsubset_notation
%%%}}}

Naturalmente escrevemos $A \nsubset B$ para a negação da $A \subset B$,
que é diferente da afirmação $A \psubset B$:
$$
\align
A \nsubset B &\intiff \text{$A$ não é um subconjunto de $B$}; \\
A \psubset B &\intiff \text{$A$ é um subconjunto próprio de $B$}.
\endalign
$$
E se quiser dizer que $A$ não é um subconjunto próprio de $B$?
Escreva isso mesmo, ou traduza para seu equivalente
(\wq{$A \nsubset B$ ou $A = B$})
pois ninguém merece ler algo do tipo \sq{$A \smartnot\psubset B$}.

%%}}}

%%{{{ x: eq_implies_subset 
\exercise.
%%%{{{ meta 
\label eq_implies_subset
%%%}}}

$A = B \implies A \subset B$.

\solution
Suponha $A = B$.
Vamos mostrar que $A \subset B$.
Seja $x \in A$.
Mas como $A = B$, logo $x \in B$ também; que foi o que queremos demonstrar.

%%}}}

%%{{{ x: eq_using_subsets 
\exercise.
%%%{{{ meta 
\label eq_using_subsets
%%%}}}

$A = B \iff A \subset B \mland B \subset A$

\solution
\proofpart{\lrdir}:
Imediata pelo~\ref[eq_implies_subset] (pois a igualdade é simétrica).
\crtabproofpart{\rldir}.
Suponha $A \subset B$ e $B \subset A$.
Vamos mostrar que $A = B$.
Seja $x$ um objeto arbitrário.
Calculamos:
\compute
x \in A &\implies x \in B \by {def.~$A \subset B$} \\
x \in B &\implies x \in A \by {def.~$B \subset A$} \\
\endcompute
Ou seja,
$$
x \in A \iff x \in B
$$
que foi o que queremos demonstrar.

%%}}}

%%{{{ x: define_subsetneq 
\exercise.
%%%{{{ meta 
\label define_subsetneq
%%%}}}

Defina com uma fórmula o $A\subsetneq B$.

\hint
Já definimos o $\subset$, então podemos usá-lo!

\solution
$
A \subsetneq B
\defiff
A \subset B \land A \neq B.
$
\quad
(Lembre-se que $A \neq B \abbreq \lnot(A = B)$.)

%%}}}

%%{{{ beware: notation of subsets 
\beware.
%%%{{{ meta 
%%%}}}

O uso dos símbolos $\knuthsubseteq$, $\knuthsubset$, e $\knuthsubsetneq$ não é muito
padronizado: encontramos textos onde usam $\knuthsubseteq$ e $\knuthsubset$ para
``subconjunto'' e ``subconjunto próprio'' respectivamente;
outros usam $\knuthsubset$ e $\knuthsubsetneq$.
Assim o símbolo $\knuthsubset$ é usado com dois significados diferentes.
Por isso usamos $\subset$ e $\proper$ aqui, evitando completamente
o uso do ambíguo $\knuthsubset$.

%%}}}

%%{{{ notation: supset_sugar 
\note Notação.
%%%{{{ meta 
\label supset_sugar
%%%}}}

Seguindo uma práctica comum que envolve símbolos ``direcionais'' de relações
binárias como os $\rightarrow$, $\leq$, $\subset$, etc., introduzimos os:
$$
\xalignat2
A \supset    B & \defiff B \subset A &
A \supsetneq B & \defiff B \subsetneq A
\endxalignat
$$

%%}}}

\endsection
%%}}}

%%{{{ Empty, universal, singletons 
\section Vazio, universal, singletons.
%%%{{{ meta 
%%%}}}

%%{{{ df: empty 
\definition Vazio.
%%%{{{ meta 
\label empty
\defines
    * vazio
    ;;
%%%}}}

Um conjunto é \dterm{vazio} sse ele não contem nenhum elemento.
Formalmente, definimos o predicado unário
$$
\Empty(A) \defiff \lforall x {x \notin A}.
$$

%%}}}

%%{{{ df: singleton 
\definition Singleton.
%%%{{{ meta 
\label singleton
%%%}}}

Um conjunto é \dterm{singleton} (ou \dterm{unitário}) sse ele contem
exatamente um elemento.
Formulamente,
$$
\Singleton(A)
\defiff
\lunique x {x \in A}.
$$

%%}}}

%%{{{ x: compare_altdef_of_singleton 
\exercise.
%%%{{{ meta 
\label compare_altdef_of_singleton
%%%}}}

Decida se o seguinte pode servir como definição de singleton:
$$
\Singleton(A)
\askiff
\lexists a
{ a \in A \mland \lforall x { x \in A \limplies x = a } }.
$$

\hint
Substitua a fórmula longa com uma equivalente aproveitando
uns açúcares sintácticos dos quantificadores $\forall, \exists$.

\hint
Escrevemos a fórmula
$$
\exists a
\paren{ a \in A \land \forall x \paren{ x \in A \limplies x = a } }
$$
como
$$
\pexists {a \in A}
\lforall {x \in A} { x = a }.
$$

%%}}}

%%{{{ df: emptyset 
\definition.
%%%{{{ meta 
\label emptyset_symbol
\defines
    * \emptyset  -- o conjunto vazio
    ;;
%%%}}}

Denotamos o conjunto vazio por $\emptyset$.
\mistake

%%}}}

%%{{{ x: what_is_wrong_with_the_emptyset_definition 
\exercise.
%%%{{{ meta 
\label what_is_wrong_with_the_emptyset_definition
%%%}}}

Na~\ref[emptyset_symbol] roubamos!
Resolva o crime.

\hint
``o''

\solution
Como não provamos a unicidade do vazio não podemos usar o artigo
definido ``o'', e conseqüentemente, não podemos usar um símbolo
para \emph{o} denotar.  Seria mal-definido.

%%}}}

%%{{{ Parallelism with Singleton(-) to emphasize error 
\note.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Para apreciar ainda mais a gravidade do erro acima:
se apenas a definição de $\Empty(\dhole)$ fosse suficiente
para introduzir a notação $\emptyset$ para denotar ``o conjunto vazio'',
poderiamos também escolher um símbolo para denotar ``o conjunto unitário'':
$$
\align
\text{$\Empty(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto vazio por $\emptyset$.>>}\\
\text{$\Singleton(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto unitário por $\cancel{1}$.>>}
\endalign
$$
Qual de todos---quantos são?---os conjuntos unitários seria o $\cancel{1}$?
Essa ambigüidade não é permitida em matemática.\foot
Se ainda não tá convencido, bota o artigo definido \wq{o} na frase
similar \wq{seja $x$ (um) inteiro}.
O que significaria se fosse \wq{seja $x$ \emph{o} inteiro}?!
\toof

%%}}}

%%{{{ x: how_many_singletons 
\exercise.
%%%{{{ meta 
\label how_many_singletons
%%%}}}

Quantos são mesmo?

\solution
Infinitos!  Pois, para cada objeto $x$ já temos um singleton $\set{x}$.
E agora o singleton dele $\set{\set{x}}$, e dele, e dele, \dots

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então precisamos demonstrar existência e unicidade.
Faça isso agora nos exercícios seguintes.

%%}}}

%%{{{ x: naive_existence_of_emptyset 
\exercise Existência do vazio.
%%%{{{ meta 
\label naive_existence_of_emptyset
%%%}}}

Usando as ferramentas que temos desenvolvido, construe um conjunto vazio.

\hint
Use o set-builder.

\hint
Basta achar um filtro que garante que nenhum objeto ``passa'':
$$
\setst x {\asklhole}
$$

\solution
O conjunto $\setst x {x \neq x}$ é um conjunto vazio.

%%}}}

%%{{{ x: naive_uniqueness_of_emptyset 
\exercise Unicidade do vazio.
%%%{{{ meta 
\label naive_uniqueness_of_emptyset
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

Supondo que existe pelo menos um conjunto vazio, mostre sua unicidade.
Não use reductio ad absurdum.

\hint
Em outras palavras, demonstre que:
$$
\text{se $A,B$ são vazios, então $A = B$.}
$$

\hint
Suponha que $A,B$ são vazios.
Qual é teu alvo agora, e o que ele significa mesmo?

\hint
Teu alvo é mostrar que $A = B$.
Para fazer isso é necessário lembrar a definição de $=$ nos conjuntos (\reftag[set_eq]).

\solution
Suponha que $A,B$ são vazios.
Preciso mostrar $A=B$, ou seja, que $\forall x( x\in A \liff x \in B )$.
Seja $x$ um objeto arbitrário.
Pela definição de vazio, as duas afirmações $x \in A$ e $x \in B$ são
falsas, e logo a equivalência $(x\in A \liff x\in B)$ verdadeira,
que foi o que queremos demonstrar.

%%}}}

%%{{{ x: naive_uniqueness_of_emptyset_absurdum 
\exercise.
%%%{{{ meta 
\label naive_uniqueness_of_emptyset_absurdum
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

Ache uma prova diferente, essa vez usando reductio ad absurdum.

\hint
Suponha que $A,B$ são vazios.
Queremos mostrar que $A = B$.
Então suponha o contrário ($A \neq B$) pera chegar num absurdo.

\hint
Qual é teu alvo agora?
Achar um absurdo qualquer!
Como podemos usar o fato de $A \neq B$?
Lembre-se que $A \neq B$ é apenas uma abreviação para $\lnot(A = B)$.

\solution
Suponha que $A,B$ são vazios.
Queremos demonstrar que $A = B$.
Para chegar num absurdo, suponha que $A \neq B$.
Logo, pela definição de igualdade, temos
que existe $x$ tal que:
$x \in A$ mas $x \notin B$; ou $x \in B$ mas $x \notin A$.
As duas alternativas chegam num absurdo:
a primeira pois $A$ é vazio e logo $x \notin A$, e similarmente
a segunda pois $B$ é vazio e logo $x \notin B$.

%%}}}

%%{{{ df: universal 
\definition Universal.
%%%{{{ meta 
\label universal
\indexes
    * universo    seealso: universal
    ;;
\defines
    * universal!conjunto
    ;;
%%%}}}

Um conjunto é \dterm{universal} sse todos os objetos pertencem nele.
Formalmente,
$$
\Universal(A) \defiff \forall x(x \in A).
$$

%%}}}

%%{{{ x: naive_uniqueness_of_universet 
\exercise Existência e unicidade do universal.
%%%{{{ meta 
\label naive_uniqueness_of_universet
\indexes
    * unicidade!do universal
    ;;
%%%}}}

Demonstre a existência e unicidade do conjunto universal.

\hint
Já demonstrou a existência (\ref[naive_existence_of_emptyset]) e a unicidade
(\ref[naive_uniqueness_of_emptyset] ou
\reftag[naive_uniqueness_of_emptyset_absurdum])
do vazio?

%%}}}

%%{{{ df: universet 
\definition.
%%%{{{ meta 
\label universet_symbol
\defines
    * \universet  -- o conjunto universal
    ;;
%%%}}}

Denotamos o conjunto universal por $\universet$.

%%}}}

%%{{{ Q: How do we use a fact that a set is nonempty? 
\question.
%%%{{{ meta 
\label how_do_we_use_nonempty
%%%}}}

Como podemos usar um fato do tipo $D\neq \emptyset$ em nossas provas?
O que ganhamos realmente?

%%}}}

\spoiler

%%{{{ A: We can pick an element from it! 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Ganhamos o direito de escrever ``Seja $d\in D$.''
Em outras palavras: de tomar um elemento arbitrário de $D$;
de declarar uma variável (não usada) para denotar um membro de $D$.

%%}}}

%%{{{ warning: letting_in_empty_like_division_by_0 
\warning.
%%%{{{ meta 
\label letting_in_empty_like_division_by_0
%%%}}}

Quando temos um conjunto $A$, escrever ``seja $x \in A$''
seria errado se não sabemos que $A \neq \emptyset$.
É um erro parecido quando dividimos uma expressão de aritmética
por $x$, ou apenas escrever uma expressão como a $a/x$,
sem saber que $x\neq 0$.
Como em aritmética precisamos separar em casos
(caso $x = 0$ e caso $x\neq 0$) e os tratar em formas diferentes,
precisamos fazer a mesma coisa trabalhando com conjuntos:
caso $A \neq \emptyset$, achamos uma prova onde podemos
realmente declarar uma variável não-usada para declarar
um elemento de $A$;
caso $A = \emptyset$, achamos uma prova
diferente---e na maioria das vezes esse caso vai ser trivial
para demonstrar.

%%}}}

\endsection
%%}}}

%%{{{ Eight simple propositions 
\section Oito proposições simples.
%%%{{{ meta 
%%%}}}

%%{{{ x: yes_no_depends_emptyset_arbitraryset 
\exercise.
%%%{{{ meta 
\label yes_no_depends_emptyset_arbitraryset
%%%}}}

Seja $A$ um conjunto.
Responda para cada uma das afirmações abaixo com
{``sim''},
{``não''}, ou
{``depende''}:
$$
\xalignat4
\emptyset &\subset \emptyset;& \emptyset &\in \emptyset; \\
\emptyset &\subset A        ;& \emptyset &\in A        ; \\
A         &\subset \emptyset;& A         &\in \emptyset; \\
A         &\subset A        ;& A         &\in A        .
\endxalignat
$$

\solution
Temos:
$$
\xalignat5
\emptyset &\subset \emptyset& &\text{(sim)}    &\qqqquad&&\emptyset &\in \emptyset&&\text{(não)} \\
\emptyset &\subset A        & &\text{(sim)}    &        &&\emptyset &\in A        &&\text{(depende)} \\
A         &\subset \emptyset& &\text{(depende)}&        &&A         &\in \emptyset&&\text{(não)} \\
A         &\subset A        & &\text{(sim)}    &        &&A         &\in A        &&\text{(depende)}.
\endxalignat
$$

%%}}}

%%{{{ beware: claiming yes/no/depends without proof isn't much 
\beware.
%%%{{{ meta 
%%%}}}

Nossa intuição muitas vezes nos engana, e por isso apenas responder no jeito
que o~\ref[yes_no_depends_emptyset_arbitraryset] pediu não vale muita coisa.
Precisamos demonstrar todas essas respostas.  Para cada uma das oito afirmações
então, precisamos dizer:
\tlist:
\li: \wq{Sim} e \emph{demonstrar} a afirmação;
\li: \wq{Não} e \emph{refutar} a afirmação;
\li: \wq{Depende} e \emph{mostrar} (pelo menos) dois casos:
um onde a afirmação é verdadeira, e outro onde ela é falsa.
\endtlist
Idealmente nesse último caso queremos determinar quando a afirmação é verdadeira,
achando condições \emph{suficientes} e/ou \emph{necessárias}.
Vamos fazer tudo isso agora.

%%}}}

%%{{{ x: attack_order 
\exercise.
%%%{{{ meta 
\label attack_order
%%%}}}

Em qual ordem tu escolharia ``atacar'' essas afirmações?

%%}}}

%%{{{ property: A_notin_emptyset 
\property.
%%%{{{ meta 
\label A_notin_emptyset
%%%}}}

Para todo conjunto $A$, $A \notin \emptyset$.

\proof.
Seja $A$ conjunto.  Agora diretamente pala definição de vazio
tomando $x\asseq A$, temos $A \notin \emptyset$.

%%}}}

%%{{{ cor: emptyset_notin_emptyset 
\corollary.
%%%{{{ meta 
\label emptyset_notin_emptyset
%%%}}}

$\emptyset \notin \emptyset$.

\proof.
Essa afirmação é apenas um \emph{caso especial} de~\ref[A_notin_emptyset]:
tome $A \asseq \emptyset$.

%%}}}

%%{{{ x: emptyset_notin_emptyset_direct_proof 
\exercise.
%%%{{{ meta 
\label emptyset_notin_emptyset_direct_proof
%%%}}}

Demonstre o~\ref[emptyset_notin_emptyset] diretamente, sem usar a~\ref[A_notin_emptyset].

\hint
Quais noções são envolvidas nessa afirmação?
Quais são as definições delas?

%%}}}

%%{{{ property: A_subset_A 
\property.
%%%{{{ meta 
\label A_subset_A
%%%}}}

Para todo conjunto $A$, temos $A \subset A$.

\proof.
Seja $A$ conjunto.  Suponha que $a \in A$.
Agora precisamos mostrar $a\in A$, algo que já temos.

%%}}}

%%{{{ x: A_subset_A_quickest_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Pode achar uma prova com menos passos?

\solution
A fórmula que queremos demonstrar é uma tautologia lógica!

%%}}}

%%{{{ cor: emptyset_subset_emptyset 
\corollary.
%%%{{{ meta 
\label emptyset_subset_emptyset
%%%}}}

$\emptyset\subset\emptyset$.

\proof.
Caso especial da~\ref[A_subset_A] tomando $A\asseq \emptyset$,
pois $\emptyset$ é um conjunto.

%%}}}

%%{{{ property: emptyset_subset_A 
\property.
%%%{{{ meta 
\label emptyset_subset_A
%%%}}}

Para todo conjunto $A$, temos $\emptyset \subset A$.

\sketch.
Para chegar num absurdo suponha que tem um contraexemplo:
um conjunto $A$ tal que $\emptyset\nsubset A$.
Daí achamos rapidamente o absurdo desejado lembrando a definição de $\nsubset$.
Sem usar reductio ad absurdum, vamos acabar querendo demonstrar que uma implicação é verdadeira.
Mas cuja premissa é falsa, algo que garanta a veracidade da implicação!

%%}}}

%%{{{ x: emptyset_subset_A_does_not_imply_A_subset_A_and_vv 
\exercise.
%%%{{{ meta 
\label emptyset_subset_A_does_not_imply_A_subset_A_and_vv
%%%}}}

Podemos ganhar a~\ref[A_subset_A] como corolário da~\reftag[emptyset_subset_A]
ou vice-versa?  Explique.

\solution
Não; nenhuma das duas proposições implica a outra.
Da $A\subset A$ não podemos substituir o $A$ com nenhum conjunto para chegar na $\emptyset\subset A$.
Nem como o $\emptyset$, pois ele teria sido substituito selectivamente em apenas na sua primeira instância, algo que obviamente não podemos fazer.
(Similarmente $x = x$ para todos os números $x$ mas não podemos concluir disso que $0 = x$ para todos os $x$.)
Da $\emptyset\subset A$ não podemos chegar na $A \subset A$, pois precisamos substituir a constante $\emptyset$ por a variável $A$.
(Similarmente $0 + x = x$ para todos os números $x$, mas não podemos concluir que $x + x = x$.)

%%}}}

%%{{{ prop: emptyset_in_A_sometimes 
\proposition.
%%%{{{ meta 
\label emptyset_in_A_sometimes
%%%}}}

Existe uma infinidade de conjuntos $A$ que satisfazem a $\emptyset \in A$
e uma infinidade de conjuntos $A$ que não a satisfazem.

%%}}}

%%{{{ property: A_subset_emptyset_iff_A_eq_emptyset 
\property.
%%%{{{ meta 
\label A_subset_emptyset_iff_A_eq_emptyset
%%%}}}

O único subconjunto do $\emptyset$ é ele mesmo.
Em outras palavras:
$$
A \subset \emptyset
\iff
A = \emptyset.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora falta apenas uma afirmação para examinar: $A \in A$?

%%}}}

%%{{{ x: can_you_find_an_irregular_set 
\exercise.
%%%{{{ meta 
\label can_you_find_an_irregular_set
%%%}}}

Consegues mostrar algum conjunto com a propriedade que ele pertence nele mesmo?
Ou seja, podes achar um conjunto $A$ tal que $A\in A$?

%%}}}

\endsection
%%}}}

%%{{{ More set-builder 
\section Mais set-builder.
%%%{{{ meta 
\label full_setbuilder
%%%}}}

%%{{{ blah section intro 
\blah.
%%%{{{ meta 
%%%}}}

Já encontramos a versão mais simples de set comprehension
(ou notação set-builder) que nos permite escrever
$$
\setstt { x } {\thole$x$\thole}
$$
onde $x$ é uma variável, e $\text{\thole$x$\thole}$
uma afirmação onde pode aparecer essa variável $x$.
Essa notação é bem mais flexível que isso.
Por exemplo
$$
\setst {p^n + x} {\text{$p$ é primo, $n$ é ímpar, e $x\in[0,1)$}}
$$
seria o conjunto de todos os números reais que podem ser escritos na forma
$p^n + x$ para algum primo $p$, algum ímpar $n$, e algum real $x$ com $0 \leq x < 1$.
\eop
Finalmente, mais uma extensão dessa notação é que usamos
$$
\setstt {x \in A} {\thole$x$\thole}
\defeq
\setst {x} {x \in A \mland \text{\thole$x$\thole}}.
$$

%%}}}

%%{{{ x: why_treat_x_in_A_sugar_separately 
\exercise.
%%%{{{ meta 
\label why_treat_x_in_A_sugar_separately
%%%}}}

Por que a notação
$$
\setst {x \in A} {\text{\thole$x$\thole}}
$$
não é apenas um caso especial da notação que nos permite escrever
termos na parte esquerda de set-builder?

\hint
O ``$x \in A$'' é um termo?

\solution
Pois o ``$x \in A$'' não é um termo, mas uma proposição (afirmação).

%%}}}

%%{{{ x: div_mul_pow_of_12_and_m_setbuilder_practice 
\exercise.
%%%{{{ meta 
\label div_mul_pow_of_12_and_m_setbuilder_practice
%%%}}}

Usando a notação set-builder defina os conjuntos
$D_{12}$, $M_{12}$, e $P_{12}$
de todos os divisores, todos os múltiplos, e todas as potências de $12$.
Generalize para um inteiro $m$.
Identifique quais variáveis que aparecem na tua resposta são livres e quais são ligadas.

\solution
$$
\xalignat2
D_{12} &\defeq \setst {n \in \ints} {n \divides 12}  &
D_m    &\defeq \setst {n \in \ints} {n \divides m}   \\
M_{12} &\defeq \setst {12n}  {n \in \ints}           &
M_m    &\defeq \setst {mn}   {n \in \ints}           \\
P_{12} &\defeq \setst {12^n} {n \in \nats}           &
P_m    &\defeq \setst {m^n}  {n \in \nats}
\endxalignat
$$
Onde aparece a variável \symq{$m$}, ela está livre, e
onde aparece a variável \symq{$n$}, ela está ligada.

%%}}}

%%{{{ x: set_builder_map_size_limit 
\exercise.
%%%{{{ meta 
\label set_builder_map_size_limit
%%%}}}

Seja $T = \set{u,v}$ um conjunto com dois elementos $u,v$.
Definimos um conjunto $A$ pela
$$
A \defeq \setst {f(n,m)} {n,m \in T}
$$
Quantos elementos tem o $A$?

\hint
Primeiramente calcule a extensão do $A$:
$$
A = \set{ \dots?\dots }.
$$

\solution
Calculando a extensão de $A$ achamos:
$$
A = \set{ f(u,u), f(u,v), f(v,u), f(v,v) }.
$$
Então o $A$ tem \emph{no máximo} $4$ elementos---mas pode acontecer que tem menos (veja~\ref[set_builder_map_exercise]).

%%}}}

%%{{{ x: set_builder_map_exercise 
\exercise.
%%%{{{ meta 
\label set_builder_map_exercise
%%%}}}

Escreva a extensão do conjunto
$$
B \defeq \setst {n^2 + m^2} {n,m \in \set{1,3}}.
$$

\solution
Calculamos:
$$
\align
B
&= \setst {n^2 + m^2} {n,m \in \set{1,3}}\\
&= \set{ 1^2 + 1^2, 1^2 + 3^2, 3^2 + 1^2, 3^2 + 3^2 }\\
&= \set{ 2, 10, 10, 18 }\\
&= \set{ 2, 10, 18 }.
\endalign
$$

%%}}}

%%{{{ x: rich_set_builder_sugar 
\exercise.
%%%{{{ meta 
\label rich_set_builder_sugar
%%%}}}

Mostre como a notação ``mais rica'' de
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
$$
pode ser definida como açúcar sintáctico se temos já a notação de
comprehensão que permite apénas uma variável no lado esquerdo.
Aqui considere que o $t(x_1,\dotsc, x_n)$ é um termo que pode ser
bem complexo, formado por outros termos complexos, etc., e onde
possivelmente aparecem as variáveis $x_1,\dotsc,x_n$.

\hint
Precisa descrever (definir) o conjunto
$$
\align
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)} &\\
\intertext{com uma notação que já temos:}
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
&\defeq
\dots?
\endalign
$$

\hint
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x {\text{\thole?\thole}}
$$

\solution
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x { \exists x_1\dotsb\exists x_n \paren{ x = t(x_1,\dotsc,x_n) \land \phi(x_1,\dotsc,x_n)}}.
$$

%%}}}

%%{{{ beware: variable-binding in set-builder 
\beware.
%%%{{{ meta 
\indexes
    * ligador
    ;;
%%%}}}

As variáveis que aparecem na parte esquerda de set-builder,
são \emph{ligadores} que ligam com as correspondentes variáveis livres
que aparecem na afirmação na parte direita (filtro).
Então cuidado com o uso dessas variáveis pois é fácil escrever
algo que mesmo que realmente determina um conjunto,
não é o conjunto desejado!

%%}}}

%%{{{ x: variable_binding_in_setbuilder_exercise 
\exercise.
%%%{{{ meta 
\label variable_binding_in_setbuilder_exercise
%%%}}}

Para cada um dos conjuntos abaixo,
decida se sua definição realmente é correta.
Caso que sim, determina a extensão do conjunto definido.
Caso que não, explique qual é o problema com a definição.
Em todas elas, considere que nosso universo é o $\reals$.
$$
\align
A &= \setstt x {$\sqrt{x^2 + 2} \mland x \in \reals$}\\
B &= \setstt x {$\sqrt{x^2 + 2}$ para algum $x\in \reals$}\\
C &= \setstt t {$\sqrt{x^2 + 2} = t$ para algum $x\in \reals$}\\
D &= \setstt x {$\sqrt{x^2 + 2} = x$ para algum $x\in \reals$}\\
E &= \setstt x {$\sqrt{x^2 + 2} = x$ para todo $x\in \reals$}\\
F &= \setstt x {$\sqrt{t^2 + 2} = x$ para todo $t\in \reals$}\\
G &= \setstt x {$\sqrt{t^2 + 2} = x$ para algum $t\in \reals$}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Operations on sets and how to define them 
\section Operações entre conjuntos e como defini-las.
%%%{{{ meta 
%%%}}}

%%{{{ Operações 
\note Operações.
%%%{{{ meta 
%%%}}}

Lembramos que uma operação num tipo de objetos
mapeia certos objetos desse tipo (suas entradas)
para \emph{exatamente um} objeto desse tipo (sua saída).

%%}}}

%%{{{ Definindo operações 
\note Definindo operações.
%%%{{{ meta 
%%%}}}

Então como podemos \emph{definir uma operação} nos conjuntos?
O que precisamos deixar claro?
\standout
\emph{Um operador é determinado por seu comportamento.}
\endstandout
Então se a ``saída'' (ou o ``resultado'') duma operação
é um conjunto, basta determinar esse conjunto para quaisquer entradas
aceitáveis pela operação.
E como determinamos um conjunto?
Para começar, podemos usar um dos jeitos que já encontramos para definir um conjunto $A$:
$$
\xalignat2
A       &\defeq \setst x {\text{\thole$x$\thole}} &
x \in A &\defiff \text{\thole$x$\thole}.
\endxalignat
$$
Bora definir umas operações conhecidas para aquecer.

%%}}}

%%{{{ df: union_def 
\definition.
%%%{{{ meta 
\label union_def
\defines
    * ~A \union ~B  -- a união dos $A$ e $B$
    * união
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos
$$
A \union B \defeq \setst x {\text{$x \in A$ ou $x\in B$}}
$$
Alternativamente, podemos definir a mesma operação na seguinte forma equivalente:
$$
x \in A \union B \defiff \text{$x \in A$ ou $x\in B $}.
$$
Chamamos o $A \union B$ a \dterm{união} dos $A$ e $B$.

%%}}}

%%{{{ remark: from_x_in_A_union_B_to_A_union_B_to_union 
\remark.
%%%{{{ meta 
\label from_x_in_A_union_B_to_A_union_B_to_union
%%%}}}

Primeiramente esquematicamente:
$$
\align
\alert{x \in A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in \alert{A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in A \mathbin{\alert{\union}} B &\alertdefiff \text{$x \in A$ ou $x \in B$}.
\endalign
$$
onde colorifiquei três maneiras de entender o que é que tá sendo definido mesmo.
\eop
E agora com palavras:
se eu determinar o que significa que um $x$ arbitrário pertence ao
$A \union B$, então eu determinei o $A \union B$, pois ele é um conjunto e
\emph{um conjunto é determinado por seus membros;}
e como eu fiz isso para quaisquer conjuntos $A,B$ (arbitrários),
então eu determinei o $\union$, pois ele é um operador e
\emph{um operador é determinado por seu comportamento}.
Vamos voltar nesse assunto nos capítulos~\reftag[Functions]
e~\reftag[Axiomatic_set_theory] onde estudamos funcções e teoria dos
conjuntos respectivamente.

%%}}}

%%{{{ df: inter_def 
\definition.
%%%{{{ meta 
\label inter_def
\defines
    * ~A \inter ~B  -- a intersecção dos $A$ e $B$
    * intersecção
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos
$$
x \in A \inter B \defiff x \in A \mland x\in B.
$$
Chamamos o $A\inter B$ a \dterm{intersecção} dos $A$ e $B$.

%%}}}

%%{{{ x: inter_altdef
\exercise.
%%%{{{ meta 
\label inter_altdef
%%%}}}

Defina a operação $\inter$ usando a notação set-builder.

\solution
Sejam $A,B$ conjuntos.
Qualquer uma das definições seguintes serve:
$$
\align
A \inter B &\defeq \setst {x} {x \in A \mland x\in B}\\
A \inter B &\defeq \setst {x\in A} {x\in B}\\
A \inter B &\defeq \setst {x\in B} {x\in A}
\endalign
$$

%%}}}

%%{{{ df: disjoint_sets 
\definition.
%%%{{{ meta 
\label disjoint_sets
\defines
    * disjuntos
    ;;
%%%}}}

Chamamos dois conjuntos \dterm{disjuntos}
sse não têm nenhum elemento em comum.
Em símbolos,
$$
\text{$A,B$ disjuntos} \defiff A \inter B = \emptyset.
$$

%%}}}

%%{{{ beware: type_errors 
\beware type errors.
%%%{{{ meta 
\label type_errors
%%%}}}

Não confunda o uso dos \symq{$\defeq$} e \symq{$\defiffsymbol$} (nem dos \symq{$=$} e~\symq{$\iffsymbol$}).
Usamos o \symq{$=$} para denotar \emph{igualdade} entre dois \emph{objetos},
e usamos o \symq{$\iffsymbol$} para denotar que as \emph{afirmações} que
aparecem nos dois lados são \emph{equivalentes}.
No mesmo jeito que não podemos escrever
$$
\xalignat3
2 + 3 &\iff 5 &&\text{nem} & (x \leq y) &\;=\; (x + 1 \leq y + 1)\\
\intertext{não podemos escrer também}
A \setminus B &\iff A \inter \compl B &&\text{nem} & (A \subsetneq B) &\;=\; (A \subset B \mland A \neq B).\\
\intertext{O que queriamos escrever nesses casos seria:}
2 + 3 &= 5                           &&& x \leq y &\iff x+1 \leq y + 1\\
A \setminus B &= A \inter \compl B &&& A \subsetneq B &\iff A \subset B \mland A \neq B.
\endxalignat
$$
Caso que tudo isso não foi óbvio, sugiro revisitar o~\ref[Introductions]:
\reftag[Propositions_vs_objects], \reftag[Type_errors], \reftag[Intension_vs_extension]).

%%}}}

%%{{{ remark: The rich language of sets 
\remark A linguagem rica dos conjuntos.
%%%{{{ meta 
%%%}}}

Observe que conseguimos traduzir a frase
``os $A,B$ não têm nenhum elemento em comum''
como uma igualdade entre dois conjuntos, o $A\inter B$
e o $\emptyset$:
$$
\textwq{os $A,B$ não têm nenhum elemento em comum}
\quad\leadsto\quad
A\inter B = \emptyset.
$$
A linguagem de conjuntos é realmente muito expressiva,
algo que vamos começar a apreciar ainda mais,
na~\reftag[Translating_from_and_to_the_language_of_sets].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Continuamos com mais operações, incluindo nossa primeira operação unária.

%%}}}

%%{{{ df: complement_def 
\definition.
%%%{{{ meta 
\label complement_def
\defines
    * \compl{~A}  -- o complemento de $A$
    * complemento
    ;;
%%%}}}

Seja $A$ conjunto.  Definimos
$$
\compl A \defeq \setst x {x\notin A}
$$
Chamamos o $\compl A$ o \dterm{complemento} de $A$.

%%}}}

%%{{{ df: setminus_def 
\definition.
%%%{{{ meta 
\label setminus_def
\defines
    * ~A \setminus ~B  -- o complemento relativo de $B$ no $A$
    * complemento!relativo
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
$$
A \setminus B
\defeq
\setst { x\in A } {x \notin B}
$$
Chamamos o conjunto $A\setminus B$ o \dterm{complemento relativo} de $B$ no $A$,
e pronunciamos o $A\setminus B$ como \utter{$A$ menos $B$} ou
\utter{$A$ fora $B$}.

%%}}}

%%{{{ x: setminus_practice 
\exercise.
%%%{{{ meta 
\label setminus_practice
%%%}}}

Calcule (a extensão d)os conjuntos:
% TODO: fix reflabs
\elist:
\li: $\set{0,1,2,3,4} \setminus \set{4,1}$
\li: $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3}$
\li: $\set{0,1,2} \setminus \nats$
\li: $\nats \setminus \set{0,1,2}$
\li: $\nats \setminus \ints$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1,2}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{0,1,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}}$
\li: $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}}$
\li: $\set{7,\emptyset} \setminus \emptyset$
\li: $\set{7,\emptyset} \setminus \set{\emptyset}$
\li: $\reals \setminus 0$
\li: $\reals \setminus \set{0}$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{1}}$
\endelist

\hint
Não siga tua intuição; siga fielmente a definição!

\solution
\elist:
\li: $\set{0,1,2,3,4} \setminus \set{4,1} = \set{0,2,3}$
\li: $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3} = \set{0,1,2}$
\li: $\set{0,1,2} \setminus \nats = \emptyset$
\li: $\nats \setminus \set{0,1,2} = \set{3,4,5,6,\dotsc} = \setst {n \in \nats} {n \geq 3}$
\li: $\nats \setminus \ints = \emptyset$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1,2} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{0,1,2}} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}} = \set{\set{0,1}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}} = \set{\set{0,1}, \set{1,2}}$
\li: $\set{7,\emptyset} \setminus \emptyset = \set{7,\emptyset}$
\li: $\set{7,\emptyset} \setminus \set{\emptyset} = \set{7}$
\li: $\reals \setminus 0 = \reals$
\li: $\reals \setminus \set{0} = (-\infty,0)\union(0,+\infty)$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1 = \set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}}$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{\set{1}}} = \set{1,\set{1}, \set{\set{\set{1}}}}$
\endelist

%%}}}

%%{{{ x: setminus_equalities_practice 
\exercise.
%%%{{{ meta 
\label setminus_equalities_practice
%%%}}}

Sejam $A,B$ conjuntos.
Considere as afirmações:
$$
\xalignat3
(1)  \quad& \emptyset \setminus \emptyset = \emptyset       &
(5)  \quad& A \setminus A = A                               &
(9)  \quad& A \setminus B = B                               \\
(2)  \quad& A \setminus \emptyset         = A               &
(6)  \quad& A \setminus A = \emptyset                       &
(10) \quad& A \setminus B                   = B \setminus A \\
(3)  \quad& \emptyset \setminus A         = \emptyset       &
(7)  \quad& A \setminus B = \emptyset                       &
(11) \quad& A \setminus \set{B}             = A             \\
(4)  \quad& \set{\emptyset} \setminus A   = \emptyset       &
(8)  \quad& A \setminus B = A                               &
(12) \quad& \set{A,B} \setminus (A\union B) = \emptyset     
\endxalignat
$$
Para cada uma delas:
demonstre, se é verdadeira;
refuta, se é falsa; mostre um exemplo e um contraexemplo,
se sua vericidade depende dos $A,B$ (e tente determinar
exatamente quando é verdadeira).

%%}}}

%%{{{ df: symdiff_def 
\definition.
%%%{{{ meta 
\label symdiff_def
\defines
    * ~A \symdiff ~B  -- a diferença simétrica dos $A$ e $B$
    * diferença simétrica
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Sua \dterm{diferença simétrica}
é o conjunto de todos os objetos que pertencem a exatamente um dos $A,B$.
O denotamos por $A \symdiff B$:
$$
x \in A \symdiff B \defiff \text{$x$ pertence a exatamente um dos $A,B$}.
$$

%%}}}

%%{{{ eg: symdiff_example 
\example.
%%%{{{ meta 
\label symdiff_example
%%%}}}

Calculamos (as extensões d)os conjuntos:
\tlist:
\li: $\set{0,1,2,3} \symdiff \set{1,2,4,8} = \set{0,3,4,8}$;
\li: $\set{\set{0,1}, \set{1,2}} \symdiff \set{0,1,2} = \set{ \set{0,1}, \set{1,2}, 0, 1, 2 }$;
\li: $\set{\set{0,1}, \set{1,2}} \symdiff \set{\set{0,1},\set{0,2}} = \set{ \set{0,2}, \set{1,2} }$;
\li: $(-2,1) \symdiff (-1,2) = (-2,-1] \union [1,2)$
\endtlist
(Veja a~\ref[intervals_of_reals] caso que não reconheceu
a notação de intervalos que aparece no último exemplo.)

%%}}}

%%{{{ x: what_is_A_symdiff_A_and_A_symdiff_emptyset 
\exercise.
%%%{{{ meta 
\label what_is_A_symdiff_A_and_A_symdiff_emptyset
%%%}}}

Dado $A$ conjunto, calcule os conjuntos $A\symdiff A$ e $A \symdiff \emptyset$.

%%}}}

%%{{{ Q: How would you call symdiff's members? 
\question.
%%%{{{ meta 
%%%}}}

O que interessante (e característico) têm os membros de $A \symdiff B$?
Como os chamarias com palavras de rua?

%%}}}

\spoiler

%%{{{ A: symdiff_heart 
\note Resposta.
%%%{{{ meta 
\label symdiff_heart
\indexes
    * testemunha
    ;;
%%%}}}

Pensando pouco nas definições de
$$
A \symdiff B
\qqqqtext{e}
A = B
$$
concluimos que a diferença simétrica de dois conjuntos tem exatamente
todas as \dterm{testemunhas} que mostram que
os conjuntos são diferentes:
$$
x \in A \symdiff B
\heartiff
\text{$x$ é um testemunha que $A,B$ são diferentes.}
$$
O que podes concluir então assim que souberes que $A \symdiff B = \emptyset$?
(Isso é o~\ref[when_A_symdiff_B_is_empty], que resolverás logo.)

%%}}}

%%{{{ Venn_diagrams 
\note Diagramas de Venn.
%%%{{{ meta 
\label Venn_diagrams
\defines
    * diagrama de Venn
    ;;
%%%}}}

O leitor provavelmente já encontrou os \dterm{diagramas de Venn}{\Venn} na sua vida,
uma ferramenta muito útil para descrever operações e ajudar em raciocinar sobre
relações de conjuntos.
Por exemplo, podemos visualizar as quatro operações binárias que definimos até agora
assim:
$$
\xalignat4
A\union B:
&\quad
\gathered
\tikzpicture
\tikzi venn2union;
\endtikzpicture
\endgathered
&
A\inter B:
&\quad
\gathered
\tikzpicture
\tikzi venn2inter;
\endtikzpicture
\endgathered
\\
A \setminus B:
&\quad
\gathered
\tikzpicture
\tikzi venn2setminus;
\endtikzpicture
\endgathered
&
A \symdiff B:
&\quad
\gathered
\tikzpicture
\tikzi venn2symdiff;
\endtikzpicture
\endgathered
\endxalignat
$$
E a única operação unária, o complemento, assim:
$$
\align
\compl A:
&\quad
\gathered
\tikzpicture
\tikzi venn1compl;
\endtikzpicture
\endgathered
\endalign
$$

%%}}}

%%{{{ Venn_diagrams_limitations 
\beware Limitações de Venn.
%%%{{{ meta 
%%%}}}

Assim que tiver mais que três conjuntos os diagramas de
Venn perdem sua clareza e logo sua utilidade.

%%}}}

%%{{{ x: Venn_4_what_is_wrong 
\exercise.
%%%{{{ meta 
\label Venn_4_what_is_wrong
%%%}}}

Um aluno desenhou o seguinte diagrama Venn para representar todas as
possíveis maneiras que $4$ conjuntos $A,B,C,D$ podem intersectar entre si:
$$
\tikzpicture
\tikzi venn4wrong;
\endtikzpicture
$$
Qual o problema com esse diagrama?

\hint
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Contamos $14$ regiões.
Qual o problema?

\solution
Temos $4$ conjuntos; e como cada objeto pode ou pertencer ou não pertencer
a cada um deles, temos no total $2^4=16$ distintas configurações.
Mas no diagrama do aluno aparecem apenas $14$:
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Logo tem duas configurações então que não são representadas por nenhuma parte do diagrama.
São essas:
$$
\gather
x \in A \mland x \notin B \mland x \in C \mland x \notin D \\
x \notin A \mland x \in B \mland x \notin C \mland x \in D.
\endgather
$$

%%}}}

\endsection
%%}}}

%%{{{ Proving equalities and inclusions 
\section Demonstrando igualdades e inclusões.
%%%{{{ meta 
%%%}}}

%%{{{ x: simple_inclusion_practice_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \subset B \mland A \subset C$ então $A \subset B \inter C$}.
$$

\solution
Vou demonstrar a afirmação.
\eop
Suponha que $A \subset B$ e $A \subset C$.
Tome um $a \in A$.  Precisamos mostrar que $a \in B \inter C$.
Como $a \in A$ e $A \subset B$, temos $a \in B$;
e como $a \in A$ e $A \subset C$, temos $a \in C$.
Logo $a \in B\inter C$, pela definição de $B\inter C$.

%%}}}

%%{{{ x: simple_inclusion_practice_refutation 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \subsetneq B \mland A \subsetneq C$, então $A \subsetneq B \inter C$.}
$$

\solution
Vou refutar a afirmação com um contraexemplo.
Tome
$$
\align
A &\asseq \set { 2 }\\
B &\asseq \set { 1,2 }\\
C &\asseq \set { 2,3 }.
\endalign
$$
Realmente $A \subsetneq B$ e $A \subsetneq C$, mas mesmo assim $A = B\inter C$.

%%}}}

%%{{{ prop: set_de_morgan 
\proposition De Morgan para conjuntos.
%%%{{{ meta 
\label set_de_morgan
%%%}}}

{\DeMorgan[leis para conjuntos]}%
Para quaisquer conjuntos $A,B,C$,
$$
\align
C \setminus (A \union B) &= (C \setminus A) \inter (C \setminus B)\\
C \setminus (A \inter B) &= (C \setminus A) \union (C \setminus B).
\endalign
$$

\proof.
Sejam $A,B,C$ conjuntos.
Vamos demonstrar a primeira igualdade e deixar a segunda como
exercício~(\reftag[set_de_morgan_exercise]).
Mostramos as duas inclusões separadamente:
\eop
\lrdirset:
Tome $x \in C \setminus (A \union B)$.
Daí $x \in C$ e $x \notin (A \union B)$, ou seja $x\notin A$ e $x \notin B$.
Como $x \in C$ e $x\notin A$, temos $x\in C\setminus A$, e,
similarmente $x\in C\setminus B$.
Logo chegamos no desejado $x\in (C\setminus A) \inter (C\setminus B)$.
\eop
A inclusão inversa \rldirset\ é similar.

%%}}}

%%{{{ x: set_de_morgan_exercise 
\exercise.
%%%{{{ meta 
\label set_de_morgan_exercise
%%%}}}

Demonstre a segunda igualdade da~\ref[set_de_morgan].

%%}}}

%%{{{ warning: set_de_morgan_using_formulas 
\warning Não escreva assim!.
%%%{{{ meta 
\label set_de_morgan_using_formulas
\indexes
    * dualidade
    ;;
%%%}}}

Uma outra maneira de demonstrar a~\ref[set_de_morgan],
é calcular usando fórmulas e leis de lógica:
\compute
x \in C \setminus (A \union B)
&    \iff x \in C \land \lnot (x \in A \union B)                       \by {def.~$C \setminus (A \union B)$} \\
&    \iff x \in C \land \lnot (x \in A \lor x \in B)                   \by {def.~$\union$} \\
&    \iff x \in C \land (x \notin A \land x \notin B)                  \by {De~Morgan} \\
&\dotsiff (x \in C \land x \notin A) \land (x \in C \land x \notin B)  \by {idemp.,~assoc.,~comut.~de~$\land$} \\
&    \iff (x \in C \setminus A) \land (x \in C \setminus B)            \by {def.~$\setminus$} \\
&    \iff x \in (C \setminus A) \inter (C \setminus B).                \by {def.~$\inter$} \\
\endcompute
Logo
$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B)
$
pela definição de igualdade de conjuntos.
E a demonstração da outra igualdade é de graça,
pois é a sua proposição \emph{dual}:
trocamos apenas os $\union$ com os $\inter$, e os $\lor$ com os $\land$!
\emph{Mas não fique muito empolgado com essa demonstração--cálculo:}
uma demonstração duma proposição é um texto, legível, que um humano consegue
seguir, entender, e verificar;
exatamente como fizemos na~\ref[set_de_morgan].

%%}}}

%%{{{ prop: symdiff_altdef1 
\proposition.
%%%{{{ meta 
%%%}}}

Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \setminus B) \union (B \setminus A).
$$

\sketch.
Antes de começar, traduzimos os dois lados:
<<em exatamente um dos dois>> na esquerda,
<<no primeiro mas não no segundo ou no segundo mas não no primeiro>> na direita.
Faz sentido que os dois conjuntos são iguais, pois as duas frases são equivalentes!
Mas para demonstrar formalmente a afirmação, mostramos as duas direções
$$
\xalignat3
A \symdiff B &\subset (A \setminus B) \union (B \setminus A) && \mland &
A \symdiff B &\supset (A \setminus B) \union (B \setminus A)
\endxalignat
$$
separadamente, usando as definições de $\subset$ e $\supset$.

%%}}}

%%{{{ prop: symdiff_altdef2 
\proposition.
%%%{{{ meta 
%%%}}}

Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \union B) \setminus (A \inter B).
$$

\sketch.
Novamente, começamos pensando nos dois lados e suas intensões:
<<em exatamente um dos dois>> na esquerda;
<<em pelo menos um dos dois, mas não nos dois>> na direita.
As duas frases são equivalentes, mas vamos mostrar formalmente
a igualdade desses conjuntos, mostrando novamente as
``$\subset$'' e ``$\supset$'' separadamente.

%%}}}

%%{{{ remark: we could have defined symdiff elsehow 
\remark.
%%%{{{ meta 
%%%}}}

No~\reftag[symdiff_def] eu dei uma definição elementária,
para determinar o conjunto $A\symdiff B$.
De fato, seria até melhor \emph{definir} a operação $\symdiff$ usando uma das
duas expressões que encontramos acima.

%%}}}

%%{{{ x: when_A_symdiff_B_is_empty 
\exercise.
%%%{{{ meta 
\label when_A_symdiff_B_is_empty
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todo conjunto $A,B$,
se $A\symdiff B = \emptyset$,
então $A = B$}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Cardinality 
\section Cardinalidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: naive_cardinality 
\definition.
%%%{{{ meta 
\label naive_cardinality
\defines
    * \card {~A}  -- a cardinalidade de $A$
    * cardinalidade!ingenuamente
    ;;
%%%}}}

Seja $A$ um conjunto.
A \dterm{cardinalidade} de $A$ é a quantidade de elementos de $A$.
A denotamos por $\size A$:
$$
\size A \defeq \knuthcases {
    n,      & se $A$ é finito com exatamente $n$ membros distintos\cr
    \infty, & se $A$ é infinito.
}
$$
Às vezes usamos a notação $\nsize A$ quando o $A$ é finito,
mas mesmo nesses casos evitarei essa notação.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nos capítulos~\reftag[Cantors_paradise] e~\reftag[Axiomatic_set_theory]
vamos \emph{refinar} essa notação pois como {\Cantor}Cantor percebeu,
o segundo caso na~\ref[naive_cardinality] é \emph{bem}, \emph{bem}, \emph{bem}
mais rico do que aparece!

%%}}}

%%{{{ property: size_of_union 
\property.
%%%{{{ meta 
\label size_of_union
%%%}}}

Sejam $A,B$ conjuntos finitos.
Logo
$$
\size {A\union B} \leq \size A + \size B.
$$

\proof.
Pelo princípio da inclusão--exclusão
(\reftag[Inclusion_exclusion_principle])
temos
$$
\size {A\union B} = \size A + \size B - \size {A \inter B}
$$
e como uma cardinalidade não pode ser negativa, segue a desigualdade desejada.

%%}}}

%%{{{ x: size_of_union_of_disjoint 
\exercise.
%%%{{{ meta 
\label size_of_union_of_disjoint
%%%}}}

Determine quando temos \symq{$=$} na desigualdade
da~\ref[size_of_union].

\solution
Exatamente quando $A,B$ são disjuntos.
Em símbolos,
$$
\size {A\union B} = \size A + \size B
\iff
A \inter B = \emptyset.
$$

%%}}}

\endsection
%%}}}

%%{{{ Powerset 
\section Powerset.
%%%{{{ meta 
\label Powerset
%%%}}}

%%{{{ df: powerset_def 
\definition.
%%%{{{ meta 
\label powerset_def
\indexes
    * conjunto!de partes    see: powerset
    ;;
\defines
    * \pset{~A}  -- o powerset de $A$ (conjunto de partes)
    * powerset
    ;;
%%%}}}

Seja $A$ conjunto.
Chamamos o \dterm{powerset} (ou \dterm{conjunto de partes}, ou
\dterm{conjunto potência}) de $A$,
denotado por $\pset A$, é o conjunto de todos os subconjuntos de $A$.
Formalmente:
$$
X \in \pset A \defiff X \subset A.
$$

%%}}}

%%{{{ x: size_of_pset 
\exercise justificativa do nome.
%%%{{{ meta 
\label size_of_pset
%%%}}}

Seja $A$ conjunto finito.  Qual a cardinalidade do $\pset A$ em termos
da cardinalidade do $A$?

\solution
Já resolvemos isso na~\ref[Number_of_subsets]!
Concluimos que:
$$
\size {\pset A} = 2^{\size A}.
$$

%%}}}

%%{{{ df: subset_setbuilder 
\definition Mais set-builder.
%%%{{{ meta 
\label subset_setbuilder
%%%}}}

Dado conjunto $A$, introduzimos a notação
$$
\setst {X \subset A} { \phi(X) }
\defeq
\setst {X \in \pset A} { \phi(X) }.
$$

%%}}}

%%{{{ x: calculating_powersets 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule (ache a extensão d)os conjuntos seguintes:
$$
\pset\set{1, 2}
\qquad \pset\set{a,b,\set{a,b}},
\qquad \pset\set{\emptyset,\set{\emptyset}},
\qquad \pset\set{\nats}.
$$

%%}}}

%%{{{ x: iterate_pset_on_emptyset 
\exercise.
%%%{{{ meta 
\label iterate_pset_on_emptyset
%%%}}}

Calcule os conjuntos seguintes:
$$
\pset\emptyset,
\qquad
\pset\pset\emptyset,
\qquad
\pset\pset\pset\emptyset.
$$

\solution
Calculamos pela definição de $\pset$:
$$
\align
\pset\emptyset &= \set { \emptyset }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset} }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\emptyset, \set{\emptyset}} }
\endalign
$$

%%}}}

%%{{{ x: powersingletons 
\exercise.
%%%{{{ meta 
%%%}}}

Defina usando duas maneiras diferentes um operador unário $\pset_1$
que forma o conjunto de todos os \emph{singletons} feitos por membros
da sua entrada.

\solution
Qualquer uma das duas definições serve:
$$
\align
\pset_1 A &\defeq \setst {\set{a}} {a \in A} \\
\pset_1 A &\defeq \setst {X \subset A} {\Singleton(X)}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Big_union_Big_intersection 
\section União grande; intersecção grande.
%%%{{{ meta 
\label Big_union_Big_intersection
%%%}}}

%%{{{ intro 
\blah.
%%%{{{ meta 
%%%}}}

Generalizamos agora as operações binárias de união e intersecção para suas
versões arbitrárias, as operações unitárias $\Union\dhole$ e $\Inter\dhole$.
Antes de dar uma definição, mostramos uns exemplos.
Esses operadores são mais interessantes e úteis quando são aplicados em
conjunto cujos membros são conjuntos também, pois---coloquiamente
falando---eles correspondem na união e na intersecção dos seus membros.

%%}}}

%%{{{ eg: Union_Inter_example 
\example.
%%%{{{ meta 
\label Union_Inter_example
%%%}}}

Aplicamos as operações $\Union$ e $\Inter$ nos conjuntos seguintes:
$$
\align
\Union \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{0,1,2,4,6,8,10}\\
\Inter \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{2}\\
\Union \set{ \nats, \ints, \rats, \reals }              &= \reals\\
\Inter \set{ \nats, \ints, \rats, \reals }              &= \nats\\
\Union \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \set{4,5,6}\\
\Inter \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \emptyset
\endalign
$$

%%}}}

%%{{{ from_binary_connectives_to_quantifiers 
\note De conectivos binários para quantificadores.
%%%{{{ meta 
\label from_binary_connectives_to_quantifiers
%%%}}}

Considere a afirmação:
$$
\text{<<Alex comeu manga ou Babis comeu manga.>>}
$$
Naturalmente essa proposição corresponde numa disjuncção:
$$
\mubraceleg {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceleg {\text{ou}} {\lor}
\mubraceleg {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
Dualmente (trocando o ``ou'' por ``e'') chegamos numa conjuncção:
$$
\mubraceleg {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceleg {\text{e}} {\land}
\mubraceleg {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
E agora a pergunta:

%%}}}

%%{{{ Q: How can you express those with exists and forall? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos descrever cada uma das
$$
\xalignat2
&\phi(A) \lor  \phi(B) &
&\phi(A) \land \phi(B)
\endxalignat
$$
(que são uma disjuncção e uma conjuncção) como uma fórmula
que começa com quantificador?

%%}}}

\spoiler

%%{{{ A: like this 
\note Resposta.
%%%{{{ meta 
%%%}}}

Assim!:
$$
\align
\phi(A) \lor  \phi(B) & \iff \lexists {x \in \set{A,B}} {\phi(x)} \\
\phi(A) \land \phi(B) & \iff \lforall {x \in \set{A,B}} {\phi(x)}.
\endalign
$$
Com palavras pouco mais humanas:
$$
\gather
\text{<<Alguém dos $A,B$ comeu manga.>>} \\
\text{<<Todos os $A,B$ comeram manga.>>}
\endgather
$$

%%}}}

%%{{{ Q: How would you define Union and Inter? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias as $\Union$ e $\Inter$ formalmente então?
Podes adivinhar definições que concordam com todos esses exemplos no
\reftag[Union_Inter_example]?

%%}}}

\spoiler

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observe que pela definição de $\union$ temos
$$
\align
x \in A \union B
&\iff x \in A \mlor  x \in B \\
&\iff \text{$x$ pertence àlgum dos $A, B$} \\
&\iff \lexists {X \in \set{A,B}} {x \in X}
\intertext{e dualmente para a intersecção:}
x \in A \inter B
&\iff x \in A \mland x \in B \\
&\iff \text{$x$ pertence a cada um dos $A, B$} \\
&\iff \lforall {X \in \set{A,B}} {x \in X}.
\endalign
$$
Chegamos assim na resposta formal:

%%}}}

%%{{{ df: Union_Inter_def 
\definition.
%%%{{{ meta 
\label Union_Inter_def
\defines
    * \Inter ~{\scr A}  -- a intersecção de $\scr A$
    * \Union ~{\scr A}  -- a união de $\scr A$
    * intersecção!grande
    * união!grande
    ;;
%%%}}}

Seja $\scr A$ um conjunto.
$$
\align
x \in \Union \scr A
&\defiff
\text{$x$ pertence àlgum dos membros do $\scr A$}\\
x \in \Inter \scr A
&\defiff
\text{$x$ pertence a todos os membros do $\scr A$}.
\intertext{Equivalentemente com fórmulas,}
x \in \Union \scr A
&\defiff
\lexists {A \in \scr A} {x \in A}\\
x \in \Inter \scr A
&\defiff
\lforall {A \in \scr A} {x \in A}.
\endalign
$$
Chamamos o $\Union\scr A$ a \dterm{união} de $\scr A$, e o $\Inter\scr A$
a \dterm{intersecção} de $\scr A$.

%%}}}

%%{{{ x: union_and_inter_from_Union_and_Inter_sugar 
\exercise.
%%%{{{ meta 
\label union_and_inter_from_Union_and_Inter_sugar
%%%}}}

Defina os operadores binários $\union$ e $\inter$ como açúcar sintáctico
definido pelos operadores unários $\Union$ e $\Inter$ respectivamente.

\solution
Sejam $A,B$ conjuntos.
Botamos
$$
\xalignat2
A \union B &\defeq \Union\set{A,B} &
A \inter B &\defeq \Inter\set{A,B}.
\endxalignat
$$

%%}}}

%%{{{ x: iterate_Union_on_emptyset 
\exercise.
%%%{{{ meta 
\label iterate_Union_on_emptyset
%%%}}}

Calcule os conjuntos:
$\Union \emptyset$;
$\Union\Union \emptyset$.

%%}}}

%%{{{ x: Inter_emptyset 
\exercise.
%%%{{{ meta 
\label Inter_emptyset
%%%}}}

Calcule o $\Inter\emptyset$.

\hint
Siga a definição e nada mais!

\solution
Por enquanto a resposta correta é $\Inter\emptyset = \universet$.
Mas ``stay tuned'' pois isso vai mudar no~\ref[Axiomatic_set_theory].
Em geral $\universet$ não é o que queremos, então vamo tomar cuidado
para verificar que uma família de conjuntos não é vazia antes de
considerar sua intersecção!

%%}}}

%%{{{ x: Inter_universet 
\exercise.
%%%{{{ meta 
\label Inter_universet
%%%}}}

Calcule o $\Inter\universet$.

\hint
Siga a definição e nada mais!

\hint
$\Inter\universet = \emptyset$.
Por quê?

%%}}}

%%{{{ x: Union_and_Inter_of_singleton 
\exercise.
%%%{{{ meta 
\label Union_and_Inter_of_singleton
%%%}}}

Seja $A$ conjunto.
Calcule os $\Union\set{A}$ e $\Inter\set{A}$.

%%}}}

%%{{{ x: Inter_of_supsets_supset 
\exercise.
%%%{{{ meta 
\label Inter_of_supsets_supset
%%%}}}

Sejam $C$ conjunto e $\scr A$ família de conjuntos tais que todos
contêm o $C$ (ou seja, $C$ é um subconjunto de cada membro da $\scr A$).
Demonstre que $C \subset \Inter \scr A$.

\solution
Seja $c \in C$.
Para mostrar que $c \in \Inter \scr A$, seja $A \in \scr A$ e agora
basta mostrar que $c \in A$.
Mas pela definição de $\scr A$ sabemos que $A \supset C$.
Logo $c \in A$.

%%}}}

%%{{{ x: Inter_is_contained_in_every_member 
\exercise.
%%%{{{ meta 
\label Inter_is_contained_in_every_member
%%%}}}

Seja $\scr A$ família não vazia de conjuntos.
Demonstre que $\Inter \scr A$ está contido em todo membro da $\scr A$.

\solution
Seja $A \in \scr A$.
Para demonstrar que $\Inter \scr A \subset A$,
tome $x \in \Inter \scr A$\fact1.
Agora basta mostrar que $x \in A$.
Pela \byfact1, $x$ pertence a todos os membros da $\scr A$, e logo $x \in A$ também.

%%}}}

%%{{{ note: intuition_about_Inter_Union_powerset_and_set_braces 
\note.
%%%{{{ meta 
\label intuition_about_Inter_Union_powerset_and_set_braces
%%%}}}

Bem, bem, bem informalmente podemos dizer que: a operação $\Union$ tire o nível
mais externo de chaves; a $\Inter$ também mas jogando fora bem mais elementos
(aqueles que não pertencem em todos os membros do seu argumento); e o $\pset$
bote todas as chaves em todas as combinações possíveis para ``o nível mais
próximo''.

%%}}}

%%{{{ x: scr_A_might_not_contain_union 
\exercise.
%%%{{{ meta 
\label scr_A_might_not_contain_union
%%%}}}

Sejam $A$ conjunto e $\scr A \subset \pset A$ tal que
$$
\Union \scr A = A.
$$
A afirmação
$$
A \in \scr A
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir,
mostre um exemplo e um contraexemplo.

\hint
Depende: ache um exemplo e contra exemplo.

\solution
\proofpart{Exemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{1, 2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
e que $A \in \scr A$.
\crproofpart{Contraexemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
mas mesmo assim $A \notin \scr A$.

%%}}}

%%{{{ x: card_of_set_its_Union_and_its_Inter_comparison 
\exercise.
%%%{{{ meta 
\label card_of_set_its_Union_and_its_Inter_comparison
%%%}}}

Ache conjuntos finitos $A,B$ tais que
$$
\xalignat2
&0 < \card { \Inter A } < \card A < \card { \Union A } &
&0 < \card B < \card { \Inter B } < \card { \Union B }.
\endxalignat
$$

\solution
Tome
$$
\xalignat2
A &\asseq \set{ \set{ 1,2,3 },   \set{ 3,4,5 }   } &&(0 < 1 < 2 < 5)\\
B &\asseq \set{ \set{ 1,2,3,4 }, \set{ 2,3,4,5 } } &&(0 < 2 < 3 < 5).
\endxalignat
$$

%%}}}

%%{{{ x: inter_subset_union_for_nondisjoint_families 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $\scr A, \scr B$ famílias de conjuntos
com $\scr A \inter \scr B \neq \emptyset$.
Demonstre ou refute a afirmação:
$$
\Inter\scr A \subset \Union\scr B.
$$

\hint
A afirmação é verdadeira.  Demonstre!

\hint
O teu alvo é demonstrar que um conjunto está contido em outro.
Como atacamos isso?

\hint
Como usarás a hipótese $\scr A \inter \scr B \neq \emptyset$?

\hint
Use as definições de $\Inter$ e $\Union$.

\solution
Vamos demonstrar a afirmação.
Suponha $x \in \Inter\scr A$\fact1.
Para mostrar que $x \in \Union\scr B$, basta achar um membro da $\scr B$ em que o $x$ pertence.
Seja $W \in \scr A \inter \scr B$ (sabemos que $\scr A \inter \scr B \neq \emptyset$).
Logo $W \in \scr A$\fact2~e $W \in \scr B$ (def.~$\inter$).
Pelas \byfact1,\byfact2 temos $x\in W$,
e como $W \in \scr B$, temos o desejado $x \in \Union\scr B$.
\eop
(Obs.: demonstramos assim um $W$ tal que
$\Inter\scr A \subset W \subset \Union\scr B$.)

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: equal_Union_and_Inter 
\problem.
%%%{{{ meta 
\label equal_Union_and_Inter
%%%}}}

Seja $\scr A$ família de conjuntos tal que
$$
\Union \scr A = \Inter \scr A.
$$
O que podes concluir sobre o $\scr A$?

\solution
Vou demonstrar que $\scr A$ tem exatamente um membro ($\scr A$ é um singleton).
\crtabproofpart{$\scr A$ tem pelo menos um membro.}
Se $\scr A$ fosse vazio não teriamos
$\Union \scr {A} = \Inter \scr {A}$,
pois o primeiro é o vazio e o segundo o universo.
\crtabproofpart{$\scr A$ tem no máximo um membro.}
Sejam $A,B \in \scr A$.
Vou mostrar que $A=B$.
\crproofpart{\lrdirset}:
Para qualquer $x$ temos:
\compute
x \in A
&\implies x \in \Union \scr A   \by {$A \in \scr A$ e def.~$\Union\scr A$} \\
&\implies x \in \Inter \scr A   \by {$\Union \scr A = \Inter \scr A$} \\
&\implies x \in B               \by {$B \in \scr A$ e def.~$\Inter\scr A$} \\
\endcompute
\proofpart{A {\rldirset}} é similar:
\crproofalt{Alternativa usando reductio ad absurdum.}
Para chegar numa contradição suponha que $A \neq B$.
Logo seja $t \in A \symdiff B$, ou seja $t$ pertence a um dos $A,B$ mas não ao outro.
Logo $t \in \Union \scr A$ e $t \notin \Inter \scr A$, absurdo.

%%}}}

%%{{{ prob: dualize_and_prove_Inter_of_supsets_supset 
\problem.
%%%{{{ meta 
\label dualize_and_prove_Inter_of_supsets_supset
%%%}}}

Dualize e demonstre o resultado do~\ref[Inter_of_supsets_supset].

%%}}}

%%{{{ prob: unions_left_adjoint_pset
\problem.
%%%{{{ meta 
\label unions_left_adjoint_pset
%%%}}}

Sejam $A,B$ conjuntos.
Para cada direcção de
$$
\Union A \subset B
\askiff
A \subset \pset B
$$
demonstre ou refute.

%%}}}

%%{{{ prob: arbitrary_finite_symdiff 
\problem.
%%%{{{ meta 
\label arbitrary_finite_symdiff
%%%}}}

Sejam $n\in\nats$ com $n\geq 2$ e $n$ conjuntos
$A_1, A_2, \dotsc, A_n$.
Seja
$$
A = A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n.
$$
Observe que como a operação $\symdiff$ é associativa e comutativa,
o $A$ é bem-definido.
Demonstre que:
$$
A = \setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$

\hint
Introduza uma notação para o conjunto
$$
\setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$
Já que ele depende de $n$, algo do tipo $A_{[n]}$ serve bem aqui.
Assim, basta demonstrar o seguinte:
$$
\lforall {n \in \nats} {\Delta_{i=1}^n A_i = A_{[n]}}.
$$

\hint
Indução.

\solution
Dado qualquer natural $n$, denotamos por
$$
\oddAs n \defeq
\setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$
Provamos por indução que para todo inteiro $n \geq 2$,
$$
A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n
= \oddAs n
$$
\proofpart{Base ($n \asseq 2$):}
$x \in A_1 \symdiff A_2 \iff \text{$x$ pertence a uma quantidade ímpar dos $A_1,A_2$}$ (óbvio).
\crtabproofpart{Passo indutivo:}
Seja $k\in\nats$ tal que 
$$
A_1 \symdiff \dotsb \symdiff A_k = \oddAs k. \tag{H.I.}
$$
Precisamos mostrar que:
$$
A_1 \symdiff \dotsb \symdiff A_{k+1}
= \oddAs {k+1}
$$
\proofpart{\lrdirset}:
Suponha que $x\in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_{k+1}$,
ou seja, $x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
Pela definição de $\symdiff$, temos dois casos:
\crtabcase{Caso 1:}
$x \in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\notin A_{k+1}$.\CR
Pela {H.I.}, $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$,
e não ao $A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\crtabcase{Caso 2:}
$x \notin A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\in A_{k+1}$.\CR
Pela H.I., $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$ e também ao
$A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\eop
\bigskip
\eop
\proofpart{\rldirset}:
Suponha que $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
Separamos em dois casos:
\crtabcase{Caso 1:} $x \in A_{k+1}$.\CR
Logo $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$
e logo
$x\notin A_1\symdiff\dotsb\symdiff A_k$ (pela H.I.).
Ou seja,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
\crtabcase{Caso 2:} $x \notin A_{k+1}$.\CR
Nesse caso $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$,
ou seja $x \in \oddAs k$,
e pela H.I.~temos que $x\in A_1\symdiff\dotsb\symdiff A_k$.
De novo,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.

%%}}}

%%{{{ prob: arbitrary_finite_symdiff_gen 
\problem.
%%%{{{ meta 
\label arbitrary_finite_symdiff_gen
%%%}}}

O que devemos mudar (e como) no~\ref[arbitrary_finite_symdiff] e sua resolução,
se apagar o ``$n \geq 2$''?

\hint
O que significa $A_1\symdiff\dotsb\symdiff A_n$ nesse caso?
Por quê?

\solution
Precisamos verificar que a expressão $A_1\symdiff\dotsb\symdiff A_n$
faz sentido no caso que $n=0$, ou seja, definir razoavelmente a
diferença simétrica de uma seqüência vazia de conjuntos.
Formalmente verificamos que
$\emptyset\symdiff C = C = C\symdiff\emptyset$ para qualquer
conjunto $C$:
$\emptyset$ é o elemento neutro da operação $\symdiff$,
e logo o valor próprio da expressão acima.
\eop
Na prova, a base muda para $n=0$, onde devemos apenas demonstrar que nenhum $a$ pertence numa quantidade ímpar dos (zero) $A_i$'s, que é óbvio.

%%}}}

%%{{{ prob: df: chain_in_sets 
\definition.
%%%{{{ meta 
\label chain_in_sets
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos a $\scr A$ de \dterm{$\subset$-chain} sse
$$
\text{para todo $A,B\in \scr A$, temos $A\subset B$ ou $B \subset A$}.
$$

%%}}}

%%{{{ prob: chain_first_encounter 
\problem.
%%%{{{ meta 
\label chain_first_encounter
%%%}}}

Seja $\scr C$ uma $\subset$-chain e seja $T = \Union \scr C$.
A afirmação
$$
\text{$\scr C \union \set{T}$ é uma chain}
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir, mostre um exemplo e um contraexemplo.

\hint
A airmação é verdadeira.  Demonstre.

\solution
Vou demonstrar que $\scr C \union \set {T}$ é uma chain.
\eop
Sejam $A,B \in \scr C \union \set T$.
Preciso mostrar que $A \subset B$ ou $B\subset A$.
Vou separar em casos dependendo de se os $A,B$ pertencem à $\scr C$ ou ao $\set{T}$.
\crcase{Caso ambos pertencem à $\scr C$.}
Como $\scr C$ é chain, temos imediatamente $A\subset B$ ou $B \subset A$.
\crcase{Caso exatamente um pertence à $\scr C$.}
Chame $C$ aquele que pertence à $\scr C$.
O outro pertence ao $\set{T}$ e logo é o próprio $T = \Union \scr C$.
Vou mostrar que $C \subset T$.
Seja $c \in C$.
Preciso mostrar que $c$ pertence em algum dos membros do $\scr C$,
que acontece pois $C \in \scr{C}$.
\crcase{Caso nenhum pertence à $\scr C$.}
Ou seja, ambos pertencem ao $\set{T}$; ou seja $A = B = T$; e logo $A\subset B$
e pronto.

%%}}}

%%{{{ prob: chain_first_encounter_interesting_example 
\problem.
%%%{{{ meta 
\label chain_first_encounter_interesting_example
%%%}}}

Uma chain $\scr C$ que atende as hipotéses do~\ref[chain_first_encounter]
pode ter a propriedade que
$$
\Union\scr C \in \scr C.
$$
Mostre um exemplo duma chain infinita $\scr C$ cujos membros são todos
conjuntos infinitos, e tal que $\Union\scr C \notin \scr C$.
Dá pra garantir (com a mesma $\scr C$) que $\Inter\scr C\notin \scr C$ também?
Demonstre tuas afirmações!

\hint
Procure uma $\scr C \subset \pset \reals$.

\hint
Intervalos não triviais (com pelo menos $2$ membros) de reais
com certeza são infinitos.

\solution
\proofpart{Defino a $\scr C$} pela
$$
\scr C \defeq \setst {(-a,a)} {a \in \reals_{>0}}
$$
onde $(-a,a)$ denota o intervalo aberto de
reais $\setst {x\in\reals} {-a < x < a}$ (veja~\reftag[intervals_of_reals]).
Realmente temos
$$
\xalignat2
\Union\scr C &= \reals    \notin \scr C; &
\Inter\scr C &= \emptyset \notin \scr C.
\endxalignat
$$
\proofpart{Demonstração que $\emptyset,\reals\notin\scr C$.}
Seja $C \in \scr C$, e logo seja $a_C \in \reals$ tal que $C = (-a_C,a_C)$.
Como $a_C+1 \notin C$ e $a_C+1 \in \reals$, temos $C \neq \reals$.
Como $0 \in C$, temos $C \neq \emptyset$.
Demonstrei então que o arbitrário membro da $\scr C$ não pode ser
nem o $\emptyset$ nem o $\reals$ e logo nenhum dos dois pertence à $\scr C$.

%%}}}

%%{{{ prob: Venn_4_correct 
\problem.
%%%{{{ meta 
\label Venn_4_correct
%%%}}}

No~\ref[Venn_4_what_is_wrong] encontramos um desenho errado.
Tem como desenhar um correto?

\hint
Esqueça a idéia de usar $4$ cíclos.

\hint
Começa assim:
$$
\tikzpicture
\tikzi venn4correcthint;
\endtikzpicture
$$

\solution
Uma maneira de dezenhá-lo seria assim:
$$
\tikzpicture
\tikzi venn4correct;
\endtikzpicture
$$
Se tu achou outra e realmente tem todas as $16$ configurações possíveis,
tá tranqüilo!

%%}}}

\endproblems
%%}}}

%%{{{ Tuples 
\section Tuplas.
%%%{{{ meta 
\label Tuples
%%%}}}

%%{{{ intro 
\secintro
Até agora temos trabalhado bastante com conjuntos,
e sabemos que podemos perguntar um conjunto se qualquer
objeto é um membro dele ou não, mas um conjunto não pode
nos dar uma informação de ordem (\ref[order_and_multiplicity]).
Imagine que temos os dois primeiros ganhadores dum campeanato
num conjunto $W$; não temos como saber quem ganhou o
ouro e quem o prata.
Precisamos um outro tipo nesse caso, cuja interface é
perguntar
\emph{<<quem é teu primeiro objeto?>>}~e
\emph{<<quem é teu segundo objeto?>>}~também.
Oi, tuplas!
\eop
Nessa secção vamos estudar a idéia de \dterm{par ordenado},
ou \dterm{dupla}, ou \dterm{$2$-tupla},
ou---por enquanto---apenas \dterm{tupla}.
O que é?
\emph{Dois objetos (não necessariamente distintos)
onde um deles é considerado primeiro e o outro segundo.}
Só isso mesmo!
Vamos denotar o par ordenado dos objetos $a$ e $b$ (nessa ordem)
por $\tupa{a, b}$ ou $\tupp{a, b}$.
%%}}}

%%{{{ tuples_towards_interface_equality_notation 
\note Interface, igualdade, notação.
%%%{{{ meta 
\label tuples_towards_interface_equality_notation
%%%}}}

Precisamos: descrever qual é o ``interface primitivo'' desse novo
tipo, \emph{em tal forma que deixamos claro o que precisamos definir
para determinar uma tupla}.
Tendo isso vamos também definir o que significa $=$ entre tuplas.
Pensando em black boxes ajudou nos conjuntos; que tal tentar agora também?

%%}}}

%%{{{ Q: How would you describe a black box for tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como descreverias um black box de tupla?

%%}}}

\spoiler

%%{{{ Black boxes for tuples 
\note Tupla como black box.
%%%{{{ meta 
\label blackbox_tuple
\indexes
    * tupla!como black box    see: black box
    ;;
\defines
    * black box!de tupla
    ;;
%%%}}}

Aqui duas maneiras equivalentes de visualizar uma tupla como black box:
$$
\xalignat2
&\tikzpicture
\tikzi blackboxtuple;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxtuplebuttons;
\endtikzpicture
\endxalignat
$$
O da direita, o black box duma tupla $\tup{a,b}$ tem dois butões, e uma saida,
e cada vez que apertamos um botão cria um objeto: apertando o primeiro
sai o objeto $a$, apertando o segundo sai o $b$.
O da esquerda não tem nenhum botão nem entradas, mas só duas saidas:
na primeira sempre sai o $a$, na segunda o $b$.
Como nos black boxes de conjuntos, os black boxes de tuplas também são
deterministas: apertando o mesmo botão sempre sai o mesmo objeto
(na primeira versão), e olhando para o mesmo cabo-saida sempre sai o mesmo objeto.
No outro lado, existe uma grande diferença: um black box de conjunto
\emph{recebe} um objeto e \emph{vira uma proposição;} um black box de tupla
\emph{não recebe nenhum objeto} (apenas escolhemos se queremos extrair o
primeiro ou o segundo componente dele, e ele \emph{retorna} mesmo esse
\emph{objeto}.

%%}}}

%%{{{ tuple_interface 
\note Interface.
%%%{{{ meta 
\label tuple_interface
%%%}}}

As operações primitivas de tuplas são as operações unárias
$\proj 0$ e $\proj 1$,
chamadas \dterm{projecções}.
Nada mais!
Para qualquer tupla $t$,
$\proj 0 t$ é seu primeiro componente e
$\proj 1 t$ o seu segundo.

%%}}}

%%{{{ remark: Alternative notations 
\remark Notações alternativas.
%%%{{{ meta 
%%%}}}

Outros nomes para as projecções $\proj 0$ e $\proj 1$ são:
$$
\tproj0,\ \tproj1,\ \dotsc;
\qquad
\pproj0 {\dhole},\ \pproj1 {\dhole},\ \dotsc;
\qquad
\outl,\ \outr;
\qquad
\fst,\ \snd.
$$
Em vez de decorar os símbolos das projecções com índices começando
no $0$, às vezes é mais útil começar no $1$.  Mas não se preocupe
tanto com isso pois pelo contexto vai sempre ser claro qual é a
notação seguida.

%%}}}

%%{{{ Q: How to determine a tuple 
\question.
%%%{{{ meta 
%%%}}}

O que preciso fazer para ter o direito de dizer que eu determinei uma tupla?

%%}}}

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Preciso ter dois objetos, numa ordem.
Querendo ou não, é isto que é uma tupla.
Vamos ver isso em mais detalhe.

%%}}}

%%{{{ tuple_determine 
\note Como determinar.
%%%{{{ meta 
\label tuple_determine
%%%}}}

A partir da interface de tuplas (\reftag[tuple_interface]),
é claro que para determinar uma tupla $\alert t$ precisamos
definir como ela comporta, ou seja, isto:
\quote
Seja $\alert t$ a tupla definida pelas
$$
\xalignat2
\proj 0 \app {\alert t} &\alertdefeq x &
\proj 1 \app {\alert t} &\alertdefeq y.
\endxalignat
$$
\endquote
Observe que aqui os $x$ e $y$ supostamente já são objetos
bem-definidos.
Em vez de escrever tudo isso, usamos diretamente
a notação-construtor de tuplas:

%%}}}

%%{{{ tuple_constructor 
\definition Construtor de tupla.
%%%{{{ meta 
\label tuple_constructor
\defines
    * construtor!de tuplas
    ;;
%%%}}}

Sejam $x,y$ objetos.
Denotamos por $\tup{x,y}$ a tupla definida pelas
$$
\xalignat2
\proj 0 {\tup{x,y}} &= x & \proj 1 {\tup{x,y}} &= y
\endxalignat
$$
Consideramos então o $\tup{\dhole,\dhole}$ como um
\dterm{construtor de tuplas}.

%%}}}

%%{{{ warning: dont_redefine_the_constructor_of_tuples 
\warning.
%%%{{{ meta 
\label dont_redefine_the_constructor_of_tuples
%%%}}}

Acabamos de \emph{definir} o símbolo $\tup{x,y}$ para quaisquer $x,y$.
Não é apenas que <<não precisa>>, ainda mais: é que \emph{não podes}
re-definir isso.  Se tu tens dois objetos $x$ e $y$, não tenta justificar
nem introduzir para teu leitor o que é o $\tup{x,y}$.
Ele já sabe, a partir da \ref[tuple_constructor].
Ele também sabe o que significa somar;
tu não escreverias
\quote
Seja $x+y$ inteiro tal que ele é a soma dos $x$ e $y$.
\endquote
Certo?

%}}}

%%{{{ tuple_fundamental_equations 
\note Equações fundamentais.
%%%{{{ meta 
\label tuple_fundamental_equations
%%%}}}

Considere que temos $x,y$, dois objetos.
Podemos então formar a tupla $\tup{x,y}$ deles,
e depois usar as projecções $\proj 0$ e $\proj 1$ nessa tupla.
O que cada uma delas vai retornar para nos?
$$
\xalignat2
\proj 0 \tup{x,y} &= x &
\proj 1 \tup{x,y} &= y
\endxalignat
$$
Conversamente agora, considere que temos uma tupla $t$.
E nela usamos as projecções $\proj 0$ e $\proj 1$,
e botamos esses valores (e nessa ordem) para construir
uma tupla. Onde chegamos?
Olhe isso; e olhe isso bem:
$$
t = \tup{ \proj 0 \app t , \proj 1 \app t }.
$$

%%}}}

%%{{{ Q: How would you describe equality for tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como definarias igualdade entre tuplas?

%%}}}

\spoiler

%%{{{ A: informal answer 
\blah Resposta informal.
%%%{{{ meta 
%%%}}}

Duas tuplas são iguais sse ``concordam em cada posição''.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Sem aspas, chegamos na seguinte

%%}}}

%%{{{ df: tuples_equality 
\definition Igualdade.
%%%{{{ meta 
\label tuples_equality
%%%}}}

Sejam $s,t$ tuplas.
Definimos
$$
s = t \defiff \proj 0 s = \proj 0 t \mland \proj 1 s = \proj 1 t.
$$
Com a notação que usamos para tuplas, escrevemos o (talvez) mais amigável:
$$
\tup{x,y} = \tup{x',y'}
\defiff
x = x' \mland y = y'.
$$

%%}}}

%%{{{ Do we need bigger tuples? 
\note Precisamos tuplas maiores?.
%%%{{{ meta 
%%%}}}

Introduzimos então esse novo \emph{tipo primitivo} de $2$-tuplas.
E se precisar uma tripla?  Precisamos escolher se vamos aceitar
mais tipos como primitivos ($3$-tuplas (triplas), $4$-tuplas,
(quadruplas), $5$-tuplas (quintuplas), etc., etc.) ou não.
\eop
Caso que sim, vamos precisar uma $n$-tupla para cada $n\in\nats$.
E precisamos definir a igualdade e o intreface para cada um desses tipos,
algo que fazemos facilmente:
$$
\tup{x_1, \dots, x_n}
=
\tup{x'_1, \dots, x'_n}
\defiff
x_1 = x'_1
\mland \cdots \mland
x_n = x'_n
$$
e naturalmente dizemos que uma $n$-tupla $t$ é \emph{determinada
por os objetos em cada uma das suas $n$ posições}.
Então para definir uma $n$-tupla basta só definir as
$$
\projfrom n 0 t,
\projfrom n 1 t,
\dotsc,
\projfrom n {n-1} t.
$$
\eop
E caso contrário?  Será que podemos utilizar apenas as $2$-tuplas
para conseguir o que nossos amigos que trabalham com $n$-tuplas como
tipos primitivos conseguem?
A resposta é sim;
mas vamos primeiro definir uma operação importantíssima entre conjuntos,
o produto!

%%}}}

\endsection
%%}}}

%%{{{ Cartesian_product 
\section Produto cartesiano.
%%%{{{ meta 
\label Cartesian_product
%%%}}}

%%{{{ df: cartesian_product 
\definition.
%%%{{{ meta 
\label cartesian_product
\indexes
    * cross    see: produto
    ;;
\defines
    * ~A \times ~B  -- o produto cartesiano dos $A,B$
    * produto cartesiano
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Definimos o conjunto
$$
A \times B \defeq \setst {\tup{a,b}} {a\in A,\ b\in B}
$$
que chamamos de \dterm{produto cartesiano}
(ou simplesmente \dterm{produto}) dos $A,B$.
Pronunciamos \utter{$A$ cross $B$}.

%%}}}

%%{{{ x: size_of_cartesian_product 
\exercise.
%%%{{{ meta 
\label size_of_cartesian_product
%%%}}}

Justifique a notação $A \times B$, ou seja,
ache uma conexão entre o produto cartesiano e o produto de números.
Suponha que os $A,B$ são finitos.

\solution
Temos $\size {A \times B} = \size A \ntimes \size B$.
Isso \emph{é} o princípio da multiplicação (\reftag[principle_of_multiplication]).

%%}}}

%%{{{ x: times_distributes_over_union_and_inter 
\exercise.
%%%{{{ meta 
\label times_distributes_over_union_and_inter
%%%}}}

Sejam $A,B,C$ conjuntos.
emonstre que:
$$
\align
A \times (B \union C) &= (A \times B) \union (A\times C)\\
A \times (B \inter C) &= (A \times B) \inter (A\times C).
\endalign
$$

\solution
Vamos demonstrar a
$$
A \times (B \union C) = (A \times B) \union (A\times C).
$$
Mostramos as duas inclusões separadamente:
\crproofpart{\lrdirset:}
Seja $w \in A \times (B\union C)$.
Logo $w = \tup{a,d}$ para algum $a \in A$ e algum $d\in B\union C$ (def.~$\times$).
Logo $d\in B$ ou $d \in C$ (def.~$\union$).
Caso $d \in B$, temos $w = \tup{a,d} \in A \times B$ (def.~$\times$).
Caso $d \in C$, temos $w = \tup{a,d} \in A \times C$ (def.~$\times$).
Nos dois casos concluimos que $w \in (A \times B) \union (A\times C)$ pela definição de $\union$.
\crproofpart{\rldirset:}
Seja $w \in (A \times B) \union (A\times C)$.
Logo $w\in (A\times B)$ ou $w \in (A\times C)$ (def.~$\union$).
Caso $w \in (A \times B)$, temos $w = \tup{a,b}$ para algum $a\in A$ e algum $b\in B$ (def.$\times$).
Logo $b \in B\union C$ (pois $b\in B$) (def.~$\union$).
Logo pela definição de $\times$ temos o desejado $w = \tup{a,b} \in A \times (B\union C)$.
O caso $w \in (A \times C)$ é similar.
\crproofpart{A igualdade}
$$
A \times (B \inter C) = (A \times B) \inter (A\times C)
$$
é provada similarmente.

%%}}}

%%{{{ x: commutativity of AxB doesn't imply A=B 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para todos os conjuntos $A,B$,
$$
A\times B = B \times A \implies A=B.
$$

\hint
Se conseguiu demonstrar, tá errado.
Eu imagino que em algum ponto tu ``sejou'' algum objeto
em algum conjunto que não podia!
Lembra a~\ref[how_do_we_use_nonempty]?

\solution
Como contraexemplo tome $A \asseq \emptyset$ e $B\asseq\nats$
(qualquer $B\neq\emptyset$ serve).
Observe que $A\neq B$, mas mesmo assim
$$
A\times B = B \times A
$$
pois
$$
\emptyset \times \nats = \emptyset = \nats \times \emptyset.
$$

%%}}}

%%{{{ x: when_cartesian_commutes 
\exercise.
%%%{{{ meta 
\label when_cartesian_commutes
%%%}}}

Suponha que $A,B\neq\emptyset$.
Escreva uma prova direta (sem usar reductio ad absurdum) do
$A \times B = B\times A \iff A = B$.

\hint
Uma direção é trivial---por quê?

\hint
Como usamos os fatos $A\neq\emptyset$ e $B\neq\emptyset$?

%%}}}

%%{{{ x: when_cartesian_commutes_absurdum 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre usando reductio ad absurdum a direção não-trivial
do~\ref[when_cartesian_commutes].

%}}}

%%{{{ x: calculate_set_extensions 
\exercise.
%%%{{{ meta 
\label calculate_set_extensions
%%%}}}

Calcule as extensões dos conjuntos:
$$
\set{\set{\emptyset}}\cross\pset\emptyset;
\qqqquad
\set{\set{\emptyset}}\symdiff\Union\emptyset
$$

\solution
Calculamos:
$$
\align
\set{\set{\emptyset}}\cross \pset\emptyset &
= \set{\set{\emptyset}}\cross\set{\emptyset}
= \set{(\set{\emptyset},\emptyset)} \\
\set{\set{\emptyset}}\symdiff\Union\emptyset &
= \set{\set{\emptyset}}\symdiff\emptyset
= \set{\set{\emptyset}}
\endalign
$$

%%}}}

%%{{{ remark: let_pair_in_product 
\remark.
%%%{{{ meta 
\label let_pair_in_product
%%%}}}

Sabemos que para ``sejar'' algum membro dum conjunto $A$ (sabendo claramente que $A$ não é vazio)
escrevemos algo do tipo
\quote
Seja $x \in A$.
\endquote
onde precisamos tomar cuidado escolhendo um \emph{nome fresco de variável} para denotar esse objeto.
Como $A \times B$ também é um conjunto, e também supondo que não é vazio, obviamente faz sentido escrever
\quote
Seja $x \in A\times B$.
\endquote
A partir disso, pela definição do $A\times B$, que tipo de objeto é esse $x$?
Uma tupla cujo primeiro componente pertence a $A$, e o segundo ao $B$;
pois todos os membros de $A\times B$ são tais tuplas.
E o que podemos fazer com esse $x$ então?
Bem, é uma 2-tupla, e logo podemos projectar: $\proj 0 x$ e $\proj 1 x$ são objetos já definidos que podemos usar.
O que mais podemos fazer?
Lembrando a notação de set-builder que permite termos (\reftag[full_setbuilder]),
percebemos que a \ref[cartesian_product] do próprio
$A \times B$ usou tal set-builder:
$$
A \times B \defeq \setst {\tup{a,b}} {a\in A,\ b\in B}.
$$
A partir da definição dessa notação (\ref[rich_set_builder_sugar]) temos
$$
x \in A \times B \intiff \pexists {a \in A} \lexists {b \in B} {x = \tup{a,b}}.
$$
Para voltar na nossa pergunta de \wq{o que podemos fazer com esse $x$} então:
\quote
Seja $x \in A\times B$.\CR
Logo sejam $a\in A$ e $b \in B$ tais que $x = \tup{a,b}$.
\endquote
Tudo bem até agora.
Mas essa declaração do $x$ parece inútil.
Pra que poluir nosso escopo com esse objeto
se a único coisa que planejamos fazer com ele
é extrair seus componentes para usá-los?
Não seria melhor escrever
\quote
Seja $\tup{a,b} \in A\times B$.
\endquote
assim ganhando diretamente os $a,b$ sem o bobo $x$?
Seria, mas\dots
já aprendemos que declaramos apenas variáveis (\ref[only_declare_variables]), né?
\eop
Mas já que $\tup{\dhole,\dhole}$ é um \emph{construtor} de tuplas
podemos considerar a linha
\quote
Seja $\tup{a,b} \in A\times B$.
\endquote
Como abreviação das linhas
\quote
Seja $a \in A$.
Seja $b \in B$.
\endquote
E sobre o $\tup{a,b}$?  Como que vamos introduzí-lo para usá-lo?
Nem precisamos nem podemos!
Como já temos agora os objetos $a,b$, querendo ou não a tupla $\tup{a,b}$
já é definida e podemos usá la.
Isso vai ficar ainda mais claro daqui a pouco
(no~\ref[picking_elements_from_indexed_sets])
onde discutimos o que significa
\emph{tomar um arbitrário membro dum conjunto indexado}.

%%}}}

\endsection
%%}}}

%%{{{ Type_implementation_triples 
\section Implementação de tipo: triplas.
%%%{{{ meta 
\label Type_implementation_triples
%%%}}}

%%{{{ intro 
\secintro
Nessa secção temos nosso primeiro contato com a idéia
fundamental---literalmente---de \emph{implementação}.
Nosso objetivo aqui é só isso: brincar um pouco para entender o conceito.
Bem depois, no~\ref[Axiomatic_set_theory] vamos mergulhar mais profundamente.
%%}}}

%{{{ friend_with_triples 
\note Um amigo com triplas.
%%%{{{ meta 
\label friend_with_triples
%%%}}}

Tudo ótimo até agora neste capítulo (né?):
Introduzimos dois \emph{tipos primitivos:} conjuntos e tuplas
junto com operações neles, e tudo mais.
chega nosso amigo da outra turma que mostra para nos um tipo primitivo deles,
a tripla:
\quote
<<Cara, triplas têm $3$ projecções em ves de $2$, que denotamos por
$$
\projfrom 3 0, \quad
\projfrom 3 1, \quad
\projfrom 3 2.
$$
A própria tupla $t$ com
$$
\projfrom 3 0 \app t = x, \quad
\projfrom 3 1 \app t = y, \quad
\projfrom 3 2 \app t = z
$$
denotamos por $\tup{x,y,z}$,
e definimos igualdade pela
$$
\tup{x,y,z} = \tup{x',y',z'}
\defiff
x=x'
\mland
y=y'
\mland
z=z'
$$
e as equações fundamentais são as óbvias.
Lembra da conversa no começo da~\ref[Tuples]?
Com triplas consigo saber quem ganhou o bronze também!>>
\endquote

%%}}}

%%{{{ triple_interface 
\note Interface.
%%%{{{ meta 
\label triple_interface
%%%}}}

O interface duma tripla, consiste em $3$ projecções:
$\projfrom 3 0$, $\projfrom 3 1$, $\projfrom 3 2$.

%%}}}

%%{{{ x: fundamental_equations_triple 
\exercise.
%%%{{{ meta 
\label fundamental_equations_triple
%%%}}}

Quais são essas <<óbvias>> equações fundamentais do amigo
do~\ref[friend_with_triples]?

\hint
Inspire-se a roubar o~\ref[tuple_fundamental_equations].

\solution
As projecções e o construtor $\tup{\dhole,\dhole,\dhole}$
devem satisfazer:
$$
\xalignat3
\projfrom3 0 \tup{x,y,z} &= x &
\projfrom3 1 \tup{x,y,z} &= y &
\projfrom3 2 \tup{x,y,z} &= z;
\endxalignat
$$
$$
t = \tup{ \projfrom 3 0 t , \projfrom 3 1 t , \projfrom 3 2 t }.
$$

%%}}}

%%{{{ implementation_of_primitive_type 
\note Implementação de tipo primitivo.
%%%{{{ meta 
\label implementation_of_primitive_type
\indexes
    * tipo!primitivo
    ;;
%%%}}}

Nosso amigo nos apresentou esse tipo primitivo dele:
descreveu seu interface, introduziu sua notação, definiu igualdade,
e pronto.  Podemos copiar essa idéia e fazer a mesma coisa.
Em vez disso, vamos tentar algo diferente:
\dterm{implementar} o tipo de triplas!
O que significa mesmo ``implementar''?
Vamos tratar tudo que ele falou como uma \dterm{especificação}
dum tipo desejado, que nos vamos \emph{definir} em termos de outros
tipos já conhecidos.
Cuidado: nossa implementação deve \dterm{atender a especificação}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então \emph{implementamos}---ou seja, definimos mesmo---as triplas assim:

%%}}}

%%{{{ imp: triple_implementation 
\implementation Tripla.
%%%{{{ meta 
\label triple_implementation
%%%}}}

Sejam $x,y,z$ objetos.
Definimos a tripla
$$
\tup{x,y,z} \defeq \tup {x, \tup{y,z}}.
$$
Ou seja, a tripla dos objetos $x,y,z$ nessa ordem
é a tupla cujo primeiro componente é o $x$
e cujo segundo componente é a tupla $\tup{y,z}$.
Definimos igualdade entre triplas pela
$$
\tup{x,y,z} = \tup{x',y',z'}
\defiff x = x' \mland y = y' \mland z = z'.
$$
\mistake

%%}}}

%%{{{ Q: We just cheated!  How?
\question.
%%%{{{ meta 
%%%}}}

Acabamos de roubar.  Como?

%%}}}

\spoiler

%%{{{ beware: thou_shalt_not_redefine 
\beware Não redefinirás.
%%%{{{ meta 
\label thou_shalt_not_redefine
%%%}}}

A partir do momento que \emph{definimos} triplas
(pra ser certas 2-tuplas) não temos o direito de
\emph{redefinir} igualdade entre triplas, pois,
simplesmente, agora triplas \emph{são} 2-tuplas,
e a igualdade entre 2-tuplas já foi definida,
e logo a igualdade
$$
\tup{x,y,z} = \tup{x',y',z'}
$$
já tem significado: os objetos nos seus dois
lados são 2-tuplas, e logo a igualdade acima
\emph{realmente é} a seguinte:
$$
\tup{x,y,z} = \tup{x',y',z'}
\means
\tup{x,\tup{y,z}} = \tup{x',\tup{y',z'}}.
$$

%%}}}

%%{{{ implementator_duties 
\note Deveres do implementador.
%%%{{{ meta 
\label implementor_duties
%%%}}}

O que \emph{devemos} fazer para implementar mesmo um tipo
dada uma especificação?
Devemos demonstrar que nossa implementação atende a especificação.
E note que nossa implementação não é completa ainda, pois
precisamos \emph{definir} o interface também.
Para nosso amigo as operações $\projfrom30, \projfrom31, \projfrom32$
são \emph{primitivas}.  Ele não as definiu, pelo contrario:
determinado seus comportamentos, ele determina uma tripla.
Mas aqui queremos implementar as triplas, então devemos definir
essas projecções!
Bora terminar esses deveres agora.

%%}}}

%%{{{ x: implement_triple_interface 
\exercise.
%%%{{{ meta 
\label implement_triple_interface
%%%}}}

Complete a implementação de triplas: defina as três projecções.

\hint
Já que definimos triplas em termos de duplas,
para definir o interface de triplas vamos precisar
usar o interface de duplas, ou seja, as projecções
$\proj0,\proj1$.

\hint
Seja $t$ tripla.  Definimos
$$
\xalignat3
\projfrom30 t &= \askdots &
\projfrom31 t &= \askdots &
\projfrom32 t &= \askdots
\endxalignat
$$

\solution
Seja $t$ tripla.
Definimos
$$
\xalignat3
\projfrom30 t &= \proj0 t &
\projfrom31 t &= \proj0 \paren{\proj1 t} &
\projfrom32 t &= \proj1 \paren{\proj1 t}.
\endxalignat
$$

%%}}}

%%{{{ x: tuples_of_size_2_are_good_for_3 
\exercise.
%%%{{{ meta 
\label tuples_of_size_3_are_good_for_3
%%%}}}

Mostre que com a definição de
$$
\tup{x,y,z} \defeq \tup{x,\tup{y,z}}
$$
conseguimos a igualdade \emph{desejada}
$$
\tup{x,y,z} = \tup{x',y',z'}
\iff x = x' \mland y = y' \mland z = z'.
$$
Mais uma vez, cuidado: é um \symq{$\iffsymbol$} acima,
não um \symq{$\defiffsymbol$}!
Ou seja, definindo as $3$-tuplas nessa maneira, querendo
ou não, a igualdade entre seus objetos já é definida!
Não temos o direito de redefini-la!

\solution
Calculamos
\compute
\tup{x,y,z} = \tup{x',y',z'}
&\sugariff \tup{x,{y,z}} = \tup{x',\tup{y',z'}} \\
&\iff x = x' \mland \tup{y,z} = \tup{y',z'}     \by {def.~de~$=$~para $2$-tuplas} \\
&\iff x = x' \mland y = y' \mland z = z'.       \by {def.~de~$=$~para $2$-tuplas} \\
\endcompute
que é exatamente o que desejamos mostrar!

%%}}}

%%{{{ cartesian_product_ternary 
\note Produto ternário.
%%%{{{ meta 
\label cartesian_product_ternary
\indexes
    * produto cartesiano!tripla
    ;;
%%%}}}

Uma das mais interessantes coisas que fizemos assim começamos trabalhar
com as duplas foi definir o produto cartesiano duma dupla de conjuntos!
Agora que definimos as triplas, naturalmente queremos considerar o produto
cartesiano duma tripla de conjuntos.
Parece então que temos uma operação ternaria,
que para quaisquer conjuntos $A,B,C$
$$
A \times B \times C \defeq \setst {\tup{a,b,c}} {a \in A,\ b\in B,\ c\in C}.
$$

%%}}}

%%{{{ beware: implementation_agnostic 
\beware Implementação agnóstico.
%%%{{{ meta 
\label implementation_agnostic
\indexes
    * implementação!agnóstico    see: agnóstico
    * implementação
    ;;
\defines
    * agnóstico!implementação
    ;;
%%%}}}

\emph{Definimos} o que significa $\tup{x,y,z}$,
e \emph{definimos} as projecções $\projfrom30,\projfrom31,\projfrom32$.
Dada uma tripla $\tup{x,y,z}$, podemos chamar a $\proj1$ nela?
Intuitivamente, alguém pensaria que não, pois parece ter um ``type error''
essa aplicação: a projecção $\proj1$ funcciona com $2$-tuplas,
e $\tup{x,y,z}$ é uma tripla, então só podemos chamar as
$\projfrom30,\projfrom31,\projfrom32$ nela.
Certo?
Errado!
Podemos sim, pois, pela nossa definição,
a tripla $\tup{x,y,z}$ \emph{é} a dupla $\tup{x,\tup{y,z}}$.
Ou seja, temos:
\compute
\proj1 \tup{x,y,z}
&\inteq \proj1 \tup{x,\tup{y,z}}    \by {def.~$\tup{x,y,z}$} \\
&= \tup{y,z}                        \by {def.~$\tup{x,\tup{y,z}}$} \\
\endcompute
O fato que \emph{podemos} não significa que \emph{devemos}.
O que estamos fazendo nesse caso é \emph{usar os detalhes da implementação
em vez do seu interface}.
Tudo que vamos construir a partir desse abuso vale apenas para \emph{nossa}
implementação.  Nosso amigo que usa triplas como tipo primitivo não pode
aproveitar dos nossos cálculos e das nossas teorias.  Nem alguém que escolheu
implementar triplas em outra maneira.  A moral da estória é o seguinte:
precisamos ficar \dterm{implementação agnósticos}, ou seja,
esquecer os detalhes da nossa implementação, usando apenas o interface
dos nossos objetos.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Não faz sentido nenhum se limitar em 2-tuplas e 3-tuplas.
Partiu $n$-tuplas para qualquer $n\in\nats$!

%%}}}

\endsection
%%}}}

%%{{{ More_tuples 
\section n-tuplas.
%%%{{{ meta 
\label More_tuples
%%%}}}

%%{{{ n_tuples_interface_notation 
\note Interface e notação.
%%%{{{ meta 
\label n_tuples_interface_notation
%%%}}}

Nossa única interface dada uma tupla de tamanho $n$, é que podemos
pedir seu $i$-ésimo elemento, onde $0 \leq i < n$.
Conversamente, para definir uma tupla de tamanho $n$, basta
determinar todos os objetos (distintos ou não) nas suas $n$ posições.
Usamos as notações $\tupa{a_0, a_1, \dotsc, a_{n-1}}$
e~$\tupp{a_0, a_1, \dotsc, a_{n-1}}$ para tuplas de tamanho~$n$.
Às vezes é mais legível usar índices começando com $1$---tanto faz.
Quando queremos enfatizar o tamanho da tupla, falamos de
\dterm{$n$-tupla}.
Em geral, para tuplas de tamanho $n$, usamos a notação
$\projfrom n i$ para a $i$-ésima projecção.
Por exemplo:
$$
\xalignat4
\projfrom 2 1 \tup{x,y}                 &= y ; &
\projfrom 3 1 \tup{x_1,x_2,x_3}         &= x_2 ; &
\projfrom 5 4 \tup{x_2,x_3,y_1,x_8,y_0} &= y_0 ; &
\text{etc.}
\endxalignat
$$
Quando o $n$ é implícito pelo contexto, não se preocupamos
com ele.  Obviamente então $\proj 1$ da \symq{$\proj 1 \tup{x,y,z}$}
denota a $\projfrom 3 1$ mesmo, mas a $\proj 1 $ da \symq{$\proj 1 \tup{x,y}$}
denota a $\projfrom 2 1$.
Até agora temos chamado de ``tupla'' o par ordenado.
Na verdade, um par ordenado é uma $2$-tupla.
\eop
Às vezes escolhemos como nome duma tupla uma variável
decorada com uma setinha em cima dela, e usando a mesma
letra com índices para seus membros, por exemplo
$\vec x = \tup{x_0,x_1,\dotsc,x_n}$, $\vec w = \tup{w_1,w_2}$, etc.
Outra convençao comum é usar uma fonte em ``negrito'', por exemplo
$\mathbf{a} = \tup{a_1,a_2,a_3}$, $\mathbf{u} = \tup{u_0,u_1}$, etc.

%%}}}

%%{{{ pseudodf: set_exp 
\pseudodefinition.
%%%{{{ meta 
%%%}}}

Sejam $A$ conjunto e $n\in\nats$ com $n\geq 2$.
$$
A^n \pseudodefeq \setstt {\tup{a_1,\dotsc,a_n}} {$a_i \in A$ para todo $1\leq i\leq n$}.
$$

%%}}}

%%{{{ messy quantifier 
\note.
%%%{{{ meta 
%%%}}}

Na definição acima aparece a frase \wq{para todo $1\leq i\leq n$}.
Qual é a variável ligada com esse \wq{para todo}?
Bem, $1$ é um constante, e $n$ já foi declarado, então entendemos que a
frase corresponde na quantificação:
$$
\lforall {i\in\nats} {1\leq i \leq n \implies a_i \in A}.
$$

%%}}}

%%{{{ df: set_exp_first_recursive_definition 
\definition.
%%%{{{ meta 
\label set_exp_first_recursive_definition
%%%}}}

Seja $A$ conjunto.
Para $n\in\nats$ com $n\geq 1$ definimos as \dterm{potências} de $A$ recursivamente pelas:
$$
\align
A^1 &= A\\
A^n &= A^{n-1} \times A \qquad \text{(para $n \geq 2$)}.
\endalign
$$

%%}}}

%%{{{ Comparison with numbers (I) 
\note Comparação com números (I).
%%%{{{ meta 
%%%}}}

A semelhança entre a definição de potências de conjuntos e de números é gritante.
Vamos investigar.
Na~\ref[set_exp_first_recursive_definition] das duas equações recursivas
$$
\xalignat3
A^n &= A^{n-1} \times A &
A^n &= A \times A^{n-1}.
\intertext{escolhemos a primeira.  Por quê?
Observe que no caso de números, para a equação recursiva, as duas opções óbvias}
a^n &= a^{n-1} \ntimes a &
a^n &= a \ntimes a^{n-1} 
\intertext{servem e são equivalentes.
Uma explicação disso usa apenas o fato que a multiplicação de números é comutativa,
então imediatamente temos $a^{n-1} \ntimes a = a \ntimes a^{n-1}$.
Infelizmente não podemos contar nessa propriedade no caso de conjuntos,
pois já sabemos que a $\times$ não é comutativa~(\ref[when_cartesian_commutes]).
Mas as duas equações correspondem nas expressões}
a^n &= \paren{\paren{\paren{\paren{\dotsb\paren{a\ntimes a}\ntimes a}\ntimes a} \dotsb} \ntimes a} &
a^n &= \paren{a\ntimes \paren{\dotsb\paren{a\ntimes\paren{a\ntimes\paren{a \ntimes a}\dotsb}}}} &
\endxalignat
$$
que são iguais agora por causa da \emph{associatividade} da operação $\ntimes$.

%%}}}

%%{{{ Q: is times associative? 
\question.
%%%{{{ meta 
%%%}}}

O produto cartesiano é associativo?

%%}}}

\spoiler

%%{{{ A: answer with another question 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Respondemos nessa pergunta com outra:
\emph{as tuplas}
$$
\tup{a_0, \tup{a_1, a_2}}
\qquad
\tup{\tup{a_0, a_1}, a_2}
\qquad
\tup{a_0, a_1, a_2}
$$
\emph{são iguais?}
Não, pois já temos uma maneira de observar comportamento
diferente usando o interface dessas 2-tuplas.
Mas também depende:
podemos considerá-las \emph{como se fossem iguais}, pois
qualquer uma delas serve para satisfazer a especificação de tuplas:
podemos definir as $i$-ésimas projecções para cada uma,
e a especificação vai acabar sendo atendida usando uma delas
sse é atendida usando qualquer uma das outras.
Pense na idéia sobre a \emph{informação} que uma tupla carrega com ela.
Agora tente ler as três tuplas acima:
$$
\gather
\text{<<Primeiro o objeto $a_0$, e depois temos: primeiro o $a_1$ e depois o $a_2$.>>}\\
\text{<<Primeiro temos: primeiro o objeto $a_0$ e depois o $a_1$; e depois temos o $a_2$.>>}\\
\text{<<Primeiro temos o objeto $a_0$ e depois o $a_1$ e depois o $a_2$.>>}
\endgather
$$
Mas esse ponto de visto é confundindo implementação com interface.
Como enfatisei no~\ref[implementation_agnostic], quando queremos referir
a uma tripla de objetos, usamos a notação $\tup{a_0, a_1, a_2}$,
e não alguma que corresponde na nossa implementação peculiar.
Assim, se escrever $\tup{a_0, \tup{a_1,a_2}}$ deve ser porque tu tá
considerando a 2-tupla mesmo, cujo primeiro componente é o $a_0$
e cujo segundo o $\tup{a_1,a_2}$.
Para resumir: depende do contexto, e do objetivo de cada conversa.

%%}}}

%%{{{ Comparison with numbers (II) 
\note Comparação com números (II).
%%%{{{ meta 
%%%}}}

Uma diferença entre as definições de potências de números e de conjuntos
é que no caso de conjuntos definimos o $A^n$ para todo $n \geq 1$,
mas no caso de números naturáis conseguimos uma definição mais geral,
definindo o $a^n$ para todo $n \geq 0$.
Nossa base da recursão então foi $a^0 = 1$.
Por que $1$?

%%}}}

%%{{{ Unit 
\note Unit.
%%%{{{ meta 
%%%}}}

Se é para generalizar bem a definição de potências de números para o caso de
conjuntos, procuramos nosso $1$, ou seja, uma \dterm{unidade}
(também \dterm{identidade}, ou \dterm{elemento neutro})
da nossa ``multiplicação'', $\times$.
Essa unidade é chamada \dterm{unit}, e muito usada em linguagens de programação.
Vamos usar o $\tup{}$ para denotá-la.
Isso é um abuso notacional, pois $\tup{}$ também denota a tupla vazia,
que é o único membro da unit;
mas o contexto é em geral suficiente para tirar a ambigüidade.
Caso contrário, use $\set{\tup{}}$, ou introduza alguma outra notação,
por exemplo $I$.

%%}}}

%%{{{ df: equality_of_n_tuples 
\definition igualdade.
%%%{{{ meta 
\label equality_of_n_tuples
%%%}}}

Seja $n\in\nats$ e sejam $s,t$ $n$-tuplas.
Definimos
$$
\align
s = t
&\defiff \lforall {1 \leq i \leq n} {\projfrom n i s = \projfrom n i t},
\intertext{ou, usando a notação $\tup{\dhole,\dotsc,\dhole}$, temos:}
\tup{s_1,\dotsc,s_n} = \tup{t_1,\dotsc,t_n}
&\defiff \text{para todo $i\in\set{1,\dotsc,n}$, $s_i=t_i$.}
\endalign
$$

%%}}}

%%{{{ Q: How would you define $n$-tuples for n > 2, given 2-tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias os tipos de $n$-tuplas para $n>2$, dado um tipo
de $2$-tuplas?

%%}}}

\spoiler

%%{{{ pseudodf: n_tuples_based_on_2_tuples 
\pseudodefinition.
%%%{{{ meta 
\label n_tuples_based_on_2_tuples
%%%}}}

Seja $n\in\nats$ com $n > 2$.
Dados $n$ objetos $x_1,x_2,\dotsc,x_n$ definimos a $n$-tupla
$$
\tup{x_1, x_2, \dotsc, x_n}
\defeq
\tup{x_1, \tup{x_2, \dotsc, x_n}}.
$$

%%}}}

%%{{{ Tuples of extreme sizes 
\note Tuplas de tamanhos extremos.
%%%{{{ meta 
%%%}}}

O que seria uma $1$-tupla?
E, pior ainda, o que seria uma $0$-tupla?
E uma tupla infinita?
Vamos responder apenas na primeira pergunta agora.
Os outros dois casos vamos discutir logo depois:
sobre a(s?)\ $0$-tupla(s?) aqui mesmo;
e sobre tuplas infinitas nas \reftag[Sequences] e
\reftag[Indexed_families] onde conhecemos \emph{seqüências}
e \emph{famílias indexadas} respectivamente.

%%}}}

%%{{{ df: tuples_of_size_1 
\definition Tuplas de tamanho 1.
%%%{{{ meta 
\label tuples_of_size_1
%%%}}}

Observe que escolhendo definir a $1$-tupla como
$$
\tup{x} \defeq x
$$
atendemos nossas exigências:
$$
\tup{x} = \tup{y} \iff
x = y
$$
que é exatamente a igualdade desejada.
Ou seja, para nossos objectivos podemos \emph{identificar os objetos}
$\tup{x}$ e $x$.
A partir disso, faz sentido considerar que o produto cartesiano
dum conjunto só é o próprio conjunto, e logo ter $A^1 = A$

%%}}}

%%{{{ Q: what about 0-tuples? 
\question.
%%%{{{ meta 
%%%}}}

E sobre 0-tuplas?  Faz sentido considerar esse tipo?
Teria ``habitantes'', ou seja, objetos desse tipo?
Se sim, quantos, e quais são?  Se não, por que não?

%%}}}

\spoiler

%%{{{ zero_tuple 
\note A 0-tupla.
%%%{{{ meta 
\label zero_tuple
\defines
    * tupla!zero
    ;;
%%%}}}

Seguindo nossa intuição com as tuplas dos outros tamanhos,
o que seria uma $0$-tupla?
Bem, para determinar um objeto $\vec t$ desse tipo, precisamos
definir suas\dots $0$ projecções.
Vamos fazer isso aqui:
$$
~
$$
Pronto.
Acabei de definir as\dots $0$ coisas que precisava definir.
Logo existe uma única $0$-tupla, que denotamos por $\tup{}$ mesmo.
E qual seria o produto cartesiano $0$-ário, duma---na verdade,
da única---$0$-tupla de conjuntos?

%%}}}

%%{{{ cartesian_product_nullary 
\note O produto cartesiano 0-ário.
%%%{{{ meta 
\label cartesian_product_nullary
%%%}}}

Dados\dots $0$ conjuntos, seu produto cartesiano deve ser
o conjunto de todas as $0$-tuplas cujo $i$-ésimo componente
pertence ao $i$-ésimo dos $0$ conjuntos.
Mas só tem uma $0$-tupla e ela satisfaz essa condição, então
o produto cartesiano de 0 conjuntos, é o singleton $\set{\tup{}}$.
Logo devemos definir
$$
A^0 \defeq \set{\tup{}}
$$
e consideramos o $\set{\tup{}}$ como identidade (elemento neutro)
da $\times$, identidicando, por exemplo, as tuplas
$$
\tup{\tup{}, \tup{x,y}} \qqqtext{e} \tup{x,y}
$$
nesse contexto.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E agora, prontos para tamanho infinito: seqüências.

%%}}}

\endsection
%%}}}

%%{{{ Sequences 
\section Seqüências.
%%%{{{ meta 
\label Sequences
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A generalização de tuplas para seqüências é bem simples.
Uma $n$-tupla $\tup{a_0,\dotsc,a_{n-1}}$ tem um componente para cada uma das
$n$ posições $i = 0, \dotsc, n-1$, e nada mais.  Uma se

%%}}}

%%{{{ prim: sequence 
\primitive seqüência.
%%%{{{ meta 
\label sequence
\defines
    * \sequence {~{a_n}} n  -- a seqüência $a_0,a_1,a_2,\dotsc$
    * seqüência
    ;;
%%%}}}

Uma \dterm{seqüência} tem um componente para cada natural $i \in \nats$.
Usamos a notação $\seqn a n$ para denotar a seqüência cujos primeiros termos são
$$
a_0, a_1, a_2, a_3, \dotsc
$$
O interface de seqüências então é uma infinidade de perguntas-projecções,
uma para cada natural, que costumamos denotar apenas por índices subscritos mesmo,
como fizemos em cima.

%%}}}

%%{{{ remark: variable_binder_in_sequences 
\remark Ligador de variável.
%%%{{{ meta 
\label variable_binder_in_sequences
%%%}}}

Na notação $\sequence {a_n} {\alert n}$ o $\alert n$
é um \emph{ligador} da variável $n$.

%%}}}

%%{{{ remark: seq = infinite; finite seq = tuple 
\remark.
%%%{{{ meta 
%%%}}}

O que chamamos de seqüência é também conhecido como \dterm{seqüência infinita}.
Uma \dterm{seqüência finita} é apenas uma $n$-tupla, para algum $n\in\nats$.

%%}}}

%%{{{ warning: notational abuse 
\warning abuso notacional.
%%%{{{ meta 
%%%}}}

Quando escrevemos uma seqüência $\seqn a n$ onde pelo contexto
esperamos ver um conjunto, a entendemos como uma denotação do
conjunto $\setst {a_n} {n \in \nats}$.
Por exemplo, escrevemos
$$
\seqn a n \subset A \abusedefiff \setst {a_n} {n \in \nats} \subset A,
\qquad
\frac 1 2 \in \seqn a n \abusedefiff \frac 1 2 \in \setst {a_n} {n \in \nats},
$$
etc.

%%}}}

%%{{{ beware: ambiguous notations for sequences 
\beware.
%%%{{{ meta 
%%%}}}

Em certos textos aparece a notação $a_n$ ou $\set{a_n}$ para denotar
uma inteira seqüência.
Aqui não vamos usar nenhuma dessas, pois introduzem ambigüidades
possivelmente perigosas:
\tlist:
\li: Se encontrar a expressão \symq{$a_n$}, é a seqüência inteira ou apenas o $n$-ésimo membro dela?
\li: Se encontrar a expressão \symq{$\set{a_n}$}, ele denota a seqüência inteira,
o singleton cujo único membro é a seqüência inteira, ou o singleton cujo único
membro é o $n$-ésimo membro da seqüência?
\endtlist

%%}}}

%%{{{ Q: how_would_you_define_equality_of_sequence 
\question.
%%%{{{ meta 
\label how_would_you_define_equality_of_sequence
%%%}}}

Como definarias igualdade para seqüências?

%%}}}

\spoiler

%%{{{ df: sequences_equality 
\definition Igualdade.
%%%{{{ meta 
\label sequences_equality
%%%}}}

Sejam
$\seqn a n$,
$\seqn b n$
seqüências.
Definimos sua igualdade por
$$
\seqn a n = \seqn b n
\defiff \lforall {n\in\nats} {a_n = b_n}.
$$

%%}}}

%%{{{ Limits of sequences 
\note Seqüências e limites.
%%%{{{ meta 
%%%}}}

No coração de calculus é o estudo de seqüências
de números reais.  No~\ref[The_reals] definimos a noção de \dterm{limite}
de uma seqüência de reais $\seqn a n$, e no~\ref[Metric_spaces]
estendemos essa idéia num contexto mais geral e abstrato, onde
os membros da seqüência não são necessariamente números reais,
mas membros de um \emph{espaço métrico}.
Nada mais por enquanto---paciência!

%%}}}

%%{{{ Sequences of sets 
\note Seqüências de conjuntos.
%%%{{{ meta 
%%%}}}

Mais interessantes para a gente neste momento são \emph{seqüências de conjuntos}.

%%}}}

%%{{{ Q: how_would_you_define_Union_of_sequence 
\question.
%%%{{{ meta 
\label how_would_you_define_Union_of_sequence
%%%}}}

Imagina que temos definido, para cada $n\in\nats$, um conjunto $A_n$.
Como tu definirias os conjuntos
$\Union_{n=0}^{\infty} A_n$
e 
$\Inter_{n=0}^{\infty} A_n$
?

%%}}}

\spoiler

%%{{{ df: Union_Inter_of_sequence 
\definition.
%%%{{{ meta 
\label Union_Inter_of_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os operadores unários
$\Union_{n=0}^{\infty}$ e
$\Inter_{n=0}^{\infty}$ pelas:
$$
\align
x \in \Union_{n=0}^{\infty} A_n &\defiff \lexists {n \in \nats} {x \in A_n} \\
x \in \Inter_{n=0}^{\infty} A_n &\defiff \lforall {n \in \nats} {x \in A_n}.
\endalign
$$
Às vezes usamos a notações mais curtas: $\Union_n A_n$ e $\Inter_n A_n$
respectivamente, mas cuidado:
$\Union A_n$ é a união (grande) do conjunto $A_n$,
que é o $n$-ésimo membro da seqüência de conjuntos $\seqn A n$.
No outro lado, $\Union_n A_n$ é a união da seqüência,
ou seja o $\Union_{n=0}^{\infty}A_n$.
Mesmo cuidado sobre intersecções.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_1 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_1
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo $n\in\nats$, $A_n \subset B_{n+1}$.}
$$
Demonstre que:
$$
\Union_{n=0}^\infty A_n \subset \Union_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Union_{n=0}^\infty A_n$\fact1.
Preciso mostrar que $x \in \Union_{n=0}^{\infty} B_n$,
ou seja, mostrar que $x$ pertence a pelo menos um dos $B_n$'s.
(Ou seja, procuro um $k\in \nats$ tal que $x \in B_k$.)
Seja $m\in \nats$ tal que $x \in A_m$
(tal $m$ existe pela \byfact1).
Agora pela hipótese (com $n \asseq m$) $A_m \subset B_{m+1}$,
e logo $x \in B_{m+1}$, algo que mostra que
$x \in \Union_{n=0}^{\infty} B_n$, pois $m+1\in\nats$.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_2 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_2
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número par $m$, $A_m \subset B_{m/2}$.}
$$
Demonstre que:
$$
\Inter_{n=0}^\infty A_n \subset \Inter_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.
Preciso mostrar que $x \in \Inter_{n=0}^{\infty} B_n$,
ou seja, demonstrar que $x\in B_k$ para todo $k\in\nats$.
Seja $k \in \nats$.
Como $x \in \Inter_{n=0}^{\infty}A_n$, temos $x \in A_{2k}$.
Mas $A_{2k} \subset B_k$, logo $x \in B_k$.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_3 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_3
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número primo $p$, $A_p \subset B_{2p}$.}
$$
Demonstre ou refute:
$$
\Inter_{n=0}^\infty A_n \subset \Union_{n=28}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.\fact1
Preciso mostrar que $x \in \Union_{n=28}^{\infty} B_n$,
ou seja, achar um inteiro $m\geq 28$ tal que $x\in B_m$.
Pela {\byfact1} temos $x\in A_{17}$; e como $17$ é primo,
$A_{17}\subset B_{34}$ (pela hipótese).
Logo $x \in B_{34}$.
Então realmente $x \in \Union_{n=28}^{\infty} B_n$.

%%}}}

%%{{{ x: Union_Inter_of_sequences_as_sugar 
\exercise.
%%%{{{ meta 
\label Union_Inter_of_sequences_as_sugar
%%%}}}

Na~\ref[Union_Inter_of_sequence] definimos \emph{elementariamente}
as operações $\Union_{n=0}^{\infty}$ e $\Inter_{n=0}^{\infty}$.
Defina-las usando as operações de $\Union$ e $\Inter$.

\solution
Seja $A_n$ uma seqüência de conjuntos.
Defina
$$
\xalignat2
\Union_{n=0}^{\infty} &\defeq \Union\setst {A_n} {n\in\nats} &
\Inter_{n=0}^{\infty} &\defeq \Inter\setst {A_n} {n\in\nats}.
\endxalignat
$$

%%}}}

%%{{{ prop: set_de_morgan_gen 
\proposition.
%%%{{{ meta 
\label set_de_morgan_gen
\indexes
    * dualidade
    ;;
%%%}}}

Para todo conjunto $C$ e cada seqüência de conjuntos $\seqn A n$,
$$
\align
C \setminus {\Union_{n=0}^\infty A_n} &= \Inter_{n=0}^{\infty} \paren{C \setminus A_n}\\
C \setminus {\Inter_{n=0}^\infty A_n} &= \Union_{n=0}^{\infty} \paren{C \setminus A_n}.
\endalign
$$

\proof.
Sejam $C$ conjunto e $\seqn A n$ seqüência de conjuntos.
\eop
Mostramos as duas inclusões da primeira igualdade separadamente:
\crproofpart{\lrdirset}:
Seja $x \in C \setminus \Union_n A_n$, ou seja,
$x \in C$\fact1 e $x\notin \Union_n A_n$\fact2.
Vamos demonstrar que $x \in \Inter_n \paren{C \setminus A_n}$,
ou seja, que para todo $u\in \nats$, $x \in C \setminus A_u$.
Seja $u\in\nats$.
Basta demonstrar então duas coisas: $x \in C$ e $x \notin A_u$.
A primeira já temos (é a~\byfact1).
A segunda é direta conseqüêcia da~\byfact2:
$x$ não pertence a nenhum dos $A$'s, então nem ao $A_u$.
\crproofpart{\rldirset}: Deixo pra ti (\ref[set_de_morgan_gen_exercise_1rl]).
\eop
Temos mais uma igualdade para demonstrar, novamente em duas partes:
\crproofpart{\lrdirset}:
Seja $x \in C \setminus {\Inter_n A_n}$,
ou seja $x \in C$\fact1 e $x \notin {\Inter_n A_n}$\fact2.
Vamos demonstrar que $x \in \Union_n \paren{C \setminus A_n}$,
ou seja procuramos $w$ tal que $x \in C \setminus A_w$,
ou seja, tal que $x \in C$ e $x \notin A_w$.
Observe que nosso primeiro alvo não tem nada a ver com $w$,
e na verdade já temos: é o~\byfact1.
Agora usando a~\byfact2 achamos o desejado natural:
seja $w\in\nats$ tal que $x \notin A_w$.
\crproofpart{\rldirset}: Deixo pra ti também (\ref[set_de_morgan_gen_exercise_2rl]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora terminar a demonstração da~\ref[set_de_morgan_gen]:

%%}}}

%%{{{ x: set_de_morgan_gen_exercise_1rl 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_exercise_1rl
%%%}}}

Demonstre a primeira {\rldirset} que deixamos na demonstração da~\ref[set_de_morgan_gen].

%%}}}

%%{{{ x: set_de_morgan_gen_exercise_2rl 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_exercise_2rl
%%%}}}

E a segunda.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tu provavelmente adivinhaste:
a~\ref[set_de_morgan_gen] é uma generalização
da~\reftag[set_de_morgan], algo que---que surpresa!---tu
demonstrarás no exercício seguinte:

%%}}}

%%{{{ x: set_de_morgan_gen_indeed 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_indeed
%%%}}}

O que precisamos fazer para ganhar a~\ref[set_de_morgan] como um corolário
da~\ref[set_de_morgan_gen]?

\hint
Quais são os dados que precisamos ter per aplicar a~\ref[set_de_morgan_gen]?

\solution
Dados conjuntos $A,B,C$, precisamos mostrar que:
$$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B).
$$
Seja $\set{A_n}_n$ a seqüência $A,B,B,B,\dotsb$, (ou seja, a seqüência definida pelas:
$A_0 = A$; e $A_i = B$ para $i > 0$).
Pela~\ref[set_de_morgan_gen] temos então:
$$
C \setminus \mubrace{\Union_{n=0}^\infty A_n} {A \union B}
=
\mubrace{\Inter_{n=0}^{\infty} (C \setminus A_n)} {(C\setminus A) \inter (C\setminus B)}.
$$

%%}}}

%%{{{ x: set_de_morgan_gen_using_formulas 
\exercise.
%%%{{{ meta 
%%%}}}

Tente escrever uma prova da~\ref[set_de_morgan_gen] usando fórmulas
como no~\ref[set_de_morgan_using_formulas].

\solution
Calculamos
\compute
x \in C \setminus \Unionl_{n=0}^{\infty}A_n
&\iff x \in C \land \lnot \biggparen{x \in \Unionl_{n=0}^{\infty}A_n}   \by {def.~$\setminus$} \\
&\iff x \in C \land \lnot (\exists n\in\nats)[x \in A_n]  \by {def.~$\Unionl_{n=0}^{\infty}$} \\
&\iff x \in C \land (\forall n\in\nats)[x \notin A_n]     \by {De Morgan} \\
&\iff (\forall n\in\nats)[x \in C \land x \notin A_n]     \by {$n$ não livre em $x\in C$} \\
&\iff (\forall n\in\nats)[x \in C \setminus A_n]          \by {def.~$\setminus$} \\
&\iff x \in \Interl_{n=0}^{\infty}(C \setminus A_n).      \by {def.~$\Interl_{n=0}^{\infty}$} \\
\endcompute
(Observe a semelhança entre essa prova e a prova da~\ref[set_de_morgan],
até nas justificativas de cada passo!)
A prova da outra igualdade é de graça pois é sua dual:
é só trocar os $\Union$ com os $\Inter$, e os $\exists$ com os $\forall$!

%%}}}

%%{{{ x: distributivity over a sequence of sets 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para todo conjunto $A$ e toda seqüência de conjuntos $\seqn B n$
$$
A \union \Inter_{n=0}^{\infty} B_n
=
\Inter_{n=0}^\infty \paren{A \union B_n}
$$

\solution
A afirmação é verdadeira.
\crproofpart{\lrdirset}:
Suponha $x \in A \union \Inter_{n=0}^{\infty} B_n$.
Logo $x\in A$ ou $x \in \Inter_{n=0}^{\infty} B_n$.
\case{Caso $x\in A$.}
Temos que para todo $n\in\nats$, $x\in A\union B_n$ (pois $x \in A$), e logo $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
\case{Caso $x\in \Inter_{n=0}^{\infty} B_n$.}
Seja $n\in\nats$.  Preciso mostrar que $x \in A \union B_n$,
que é verdade pois $x \in B_n$ pela hipótese do caso.
\crproofpart{\rldirset}:
Suponha $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
Logo $x \in A \union B_n$ para todo $n \in \nats$.
\case{Caso $x\in A$,} o resultado é imediato.
\case{Caso $x\notin A$.}
Seja $m\in \nats$.
Vou mostrar que $x\in B_m$.
Sabemos pela hipótese que $x \in A \union B_m$, e como $x \notin A$, logo $x\in B_m$.
Como o $m$ foi arbitrário, concluimos que para todo $m\in \nats$, $x \in B_m$, que foi
exatamente o que precisamos demonstrar.

%%}}}

%%{{{ x: running_intervals_on_nats
\exercise.
%%%{{{ meta 
\label running_intervals_on_nats
%%%}}}

Para $n\in\nats$, defina os conjuntos de naturais
$$
\xalignat2
A_n &= \setst {i\in\nats} {i \leq n} &
B_n &= \nats \setminus A_n.
\endxalignat
$$
Calcule os conjuntos $\Union_n A_n$ e $\Inter_n B_n$.

\hint
Use as definições e/ou a~\ref[set_de_morgan_gen].

\solution
Temos
$$
\align
a \in \Unionl_n A_n
&\iff \lexists {n\in \nats} {a\in A_n}
\iff a \in \nats \\
b \in \Interl_n B_n
&\iff \lforall {n\in \nats} {b\in B_n}
\iff \False.
\endalign
$$
Ou seja: $\Union_n A_n = \nats$ e $\Inter_n B_n = \emptyset$.
Equivalentemente ganhamos a segunda imediatamente pela primeira
e a~\ref[set_de_morgan_gen].

%%}}}

%%{{{ x: nested_indexed_Inters 
\exercise.
%%%{{{ meta 
\label nested_indexed_Inters
%%%}}}

Seja $\seqn A n$ uma seqüência (infinita) de conjuntos.
A afirmação
$$
\Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m
=
\Inter_{n=0}^{\infty} A_n
$$
é verdadeira?
Se sim, demonstre;
se não, refute;
se os dados não são suficientes para concluir,
mostre um exemplo e um contraexemplo.

\hint
Cuidado com os ligadores de variáveis na notação dos operadores grandes limitados.

\solution
Resposta: sim!
\crproofpart{\lrdirset}:
    Seja $x \in \Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m$.
    Pela hipótese, para todo $n\in\nats$, $x \in \Inter_{m=n}^{\infty} A_m$ (def.~$\Inter_{n=0}^{\infty}$).
    Logo (com $n := 0$) temos o desejado $x \in \Inter_{m=0}^{\infty} A_m$.
\crproofpart{\rldirset}:
    Seja $x\in\Inter_{n=0}^{\infty} A_n$, ou seja, $x$ pertence a todos os $A_n$'s.
    Preciso mostrar que
    $$
    x \in \Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m.
    $$
    Seja $w \in \nats$ então, e agora basta mostrar que
    $$
    x \in \Inter_{m=w}^{\infty} A_m.
    $$
    Seja $m\geq w$ então.
    Preciso mostrar que $x \in A_m$; que segue imediatamentea pela hipótese (tomando $n := m$).

%%}}}

%%{{{ warning: big_setops_vs_sum 
\warning.
%%%{{{ meta 
\label big_setops_vs_sum
%%%}}}

Uma diferença importantíssima entre os operadores ${\Sum}$ e ${\Union}$ e seus índices:
um ``somatório infinito'' não é nem associativo nem comutativo!
O seguinte teorema de {\Riemann}Riemann é bastante impressionante!

%%}}}

%%{{{ thm: riemann_rearrangement 
\theorem Riemann's rearrangement.
%%%{{{ meta 
\label riemann_rearrangement
%%%}}}

Se uma série infinita $\Sum a_i$ de reais é \emph{condicionalmente convergente},\foot
Uma série $\Sum a_i$ é \dterm{condicionalmente convergente}
sse ela é convergente, mas a $\Sum |a_i|$ não é.
\toof
então podemos apenas permutando seus termos criar uma nova série infinita que
converga em \emph{qualquer} $x\in[-\infty,\infty]$ que desejamos.

\sketch.
Separe as metas: (i) mostrar como criar uma série que converge num dado número $\ell$;
(ii) mostrar como criar uma série divergente.
\eop
Observe que como $\Sum a_i$ é condicionalmente convergente, ela contem uma infinidade
de termos positivos, e uma infinidade de termos negativos.
Para o (i), fixe um $\ell\in\reals$.
Fique tomando termos positivos da série $a_i$ até seu somatório supera o $\ell$.
Agora fique tomando termos negativos da $a_i$ até seu somatório cai embaixo do $\ell$.
Agora fique tomando termos positivos até superar o $\ell$, etc.~etc.
Continuando assim conseguimos construir uma série feita por termos da
$\Sum a_i$ que converge no $\ell$.
Para o (ii), a idéia é similar.

\proof.
Veja~\cite[apostol1: \S10.21~\&~Teorema~10.22].

%%}}}

%%{{{ Limits of sequences of sets. 
\note Limites de seqüências de conjuntos.
%%%{{{ meta 
%%%}}}

Seja $\sequence {A_n} n$ uma seqüência de conjuntos.
Podemos definir a noção $\lim_n A_n$ de \emph{limite}
dessa seqüência.  Claramente, não todas as seqüências
de conjuntos convergem em algum limite.  Investigamos
isso nos problemas (\ref[set_liminf_limsup_problem]
e~\ref[set_limits]).

%%}}}

\endsection
%%}}}

%%{{{ Intervals on the real line 
\section Intervalos na reta real.
%%%{{{ meta 
%%%}}}

%%{{{ intervals_of_reals 
\definition Intervalos.
%%%{{{ meta 
\label intervals_of_reals
\defines
    * intervalos!de números
    ;;
%%%}}}

Sejam $\alpha,\beta\in\reals$.
Definimos os \dterm{intervalos} seguintes:
$$
\xalignat2
(\alpha, \beta) &\defeq \setst {x\in\reals} {\alpha < x < \beta} &
(\alpha, \beta] &\defeq \setst {x\in\reals} {\alpha < x \leq \beta} \\
[\alpha, \beta) &\defeq \setst {x\in\reals} {\alpha \leq x < \beta} &
[\alpha, \beta] &\defeq \setst {x\in\reals} {\alpha \leq x \leq \beta}.
\endxalignat
$$
(Pronunciamos as parentêses de \utter{aberto} e os colchetes de \utter{fechado}.)

%%}}}

%%{{{ x: running_intervals_on_reals 
\exercise.
%%%{{{ meta 
\label running_intervals_on_reals
%%%}}}

Para $n=1,2,3,\dotsc$ defina os intervalos de reais
$$
\xalignat2
F_n &= \ival[ {-1+\frac1n \,,\; 1-\frac1n} ] &
G_n &= \ival( {-1-\frac1n \,,\; 1+\frac1n} ).
\endxalignat
$$
Calcule os conjuntos $\Union_n F_n$ e $\Inter_n G_n$.

\hint
Use as definições!

\solution
Temos
$$
\align
x \in \Unionl_n F_n
&\iff \lexists {n\in \nats} {x\in F_n}
\iff x \in (-1,1) \\
x \in \Interl_n G_n
&\iff \lforall {n\in \nats} {x\in G_n}
\iff x \in [-1,1].
\endalign
$$
Ou seja: $\Union_n F_n = (-1,1)$ e $\Inter_n G_n = [-1,1]$.

%%}}}

%%{{{ x: epsilon-dependent and n-dependent intersections 
\exercise.
%%%{{{ meta 
%%%}}}

Para todo real $\epsilon>0$ e todo $n\in\nats$,
sejam os intervalos de reais
\mathcols 2
I_\epsilon &= [0,1 + \epsilon) &
U_n        &= [n,+\infty).
\endmathcols
Calcule os conjuntos:
(i) $\Inter \setst {I_\epsilon} {\epsilon>0}$;
(ii) $\Inter_{n=2}^{\infty} U_n$.

\solution
(i) $[0,1]$;
(ii) $\emptyset$.

%%}}}

\endsection
%%}}}

%%{{{ Multisets 
\section Multisets.
%%%{{{ meta 
\label Multisets
\indexes
    * multiset
    * bag    see: multiset
    ;;
%%%}}}

%%{{{ multiset_description 
\note Descripção.
%%%{{{ meta 
\label multiset_description
%%%}}}

Coloquiamente falando, um \dterm{multiset}
(também \dterm{bag} ou \dterm{sacola}) $M$ é como um conjunto,
só que ele não pode responder apenas em perguntas do tipo
<<o objeto $x$ pertence ao $M$?>>, mas também em
<<\emph{quantas vezes pertence} o $x$ ao $M$?>>.
Seus membros continuam sem ordem, mas agora tem \dterm{multiplicidade}.
Usamos a notação
$\bag{x_0, x_1, \dots, x_n}$
para denotar multisets, ou até
$\set{x_0, x_1, \dots, x_n}$
sobrecarregando a notação $\set{\dots}$ se é claro pelo contexto
que é um multiset e não um conjunto.

%%}}}

%%{{{ multiset_equality 
\note Igualdade.
%%%{{{ meta 
\label multiset_equality
%%%}}}

Consideramos os multisets $M$ e $M'$ iguais sse para todo $x$,
$$
\text{$x$ pertence $n$ vezes ao $M$}
\iff
\text{$x$ pertence $n$ vezes ao $M'$}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Multisets têm muitos usos na ciência da computação: acabam sendo a ferramenta
ideal para (d)escrever muitos algoritmos, e muitas linguagens de programação
já têm esse tipo implementado.
Mas seu uso em matemática é menos comum.
De qualquer forma, fez sentido introduzí-los agora junto com seus tipos-amigos,
pelo menos para saber sobre sua existência na literatura.
Voltamos depois para implementá-los
(\ref[implement_multisets],
\ref[multiset_formally_defined]);
não se preocupe neste momento com eles.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: sequence_of_sets_inclusions_counterexample 
\problem.
%%%{{{ meta 
\label sequence_of_sets_proper_inclusions_counterexample
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos,
tais que para todo $n\in\nats$,
$A_n \subsetneq B_n$.
Podemos concluir alguma das afirmações seguintes?:
$$
\xalignat2
\Union_{n=0}^\infty A_n &\subsetneq \Union_{n=0}^{\infty} B_n &
\Inter_{n=0}^\infty A_n &\subsetneq \Inter_{n=0}^{\infty} B_n
\endxalignat
$$

\hint
Procure contraexemplos:
para cada afirmação,
defina duas seqüências $\seqn A n$ e $\seqn B n$
que satisfazem a condição do problema, e mesmo assim,
não é válida a conclusão proposta.

\solution
Vamos construir um contraexemplo para cada afirmação.
\eop
Considere as seqüências de conjuntos seguintes:
para todo $n\in\nats$ define
$$
A_n \eqass (-n,n)
\qqqquad
\aligned
B_0     &\asseq \emptyset\\
B_{n+1} &\asseq [-n,n].
\endaligned
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \subsetneq B_{n+1}$:
$$
A_n = (-n,n) \subsetneq [-n,n] = B_{n+1}.
$$
Mesmo assim,
$$
\Union_{n=0}^\infty A_n = \reals = \Union_{n=0}^{\infty} B_n.
$$
\eop
Para refutar a segunda afirmação, considere
as seqüências de conjuntos seguintes:
para todo $n\in\nats$ defina
$$
A_n \eqass \setst {k \in \nats}  {k > n}
\qquad\qquad
B_n \eqass \setst {k \in \nats}  {k \geq n}
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \subsetneq B_n$.
Mesmo assim,
$$
\Inter_{n=0}^\infty A_n = \emptyset = \Inter_{n=0}^{\infty} B_n.
$$

%%}}}

%%{{{ prob: bounded_Union_and_Iter_def_and_prop 
\problem.
%%%{{{ meta 
\label bounded_Union_and_Iter_def_and_prop
%%%}}}

Seja $\seqn A n$ seqüência (infinita) de conjuntos.
Defina recursivamente uma seqüência de conjuntos $\seqn D n$
tal que (informalmente):
$$
\text{para todo $k\in\nats$, $D_k = A_0 \union A_1 \union \dotsb \union A_{k-1}$}.
$$
Em outras palavras,
precisas definir formalmente a operação união unária \dterm{limitada}
($\Union_{i=0}^{k-1} \dhole$) para qualquer $k\in\nats$.
Demonstre que para todo $n\in\nats$,
$$
\mubrace {\Union_{i=0}^{n-1} A_i} {D_n} \subset \Union_{m=0}^{\infty} A_m.
$$
O que muda se trocar de uniões para intersecções?

\solution
\proofpart{Definição da $D_n$} por recursão:
$$
\align
D_0     &= \emptyset \\
D_{n+1} &= D_n \union A_n.
\endalign
$$
\proofpart{Demonstração da afirmação} por indução no $n$:
\crtabproofpart{Base:} $D_0 \subset \Union_{m=0}^{\infty} A_m$.
Imediato pois $D_0 = \emptyset$.
\crtabproofpart{Passo indutivo.}
Seja $w \in \nats$ tal que
$$
D_w \subset \Union_{m=0}^{\infty} A_m.    \tag{H.I.}
$$
Preciso demonstrar que
$$
D_{w+1} \subset \Union_{m=0}^{\infty} A_m.
$$
Seja $d \in D_{w+1}$.
Basta mostrar que
$$
d \in \Union_{m=0}^{\infty} A_m,
$$
ou seja, que $d$ pertence àlgum dos $A_m$'s.
Pela definição de $D_{w+1} = D_w \union A_w$, temos
que
$d \in D_w$
ou
$d \in A_w$.
Separo em casos:
\crcase{Caso $d \in D_w$.}
Imediatamente pela (H.I.)
$$
d \in D_w \subset \Union_{m=0}^{\infty} A_m.
$$
\case{Caso $d \in A_w$.}
Imediato.
\crproofpart{O que muda trocando de uniões para intersecções:}
(1) a intersecção vazia tem de ser o $\universet$ em vez do $\emptyset$,
pois $\universet$ é a identidade da $\inter$ binária;
(2) o $\subset$ da afirmação tem de mudar pra $\supset$;
(3) a base da indução também é imediata pois $\universet$
é superconjunto de qualquer conjunto;
(4) o passo indutivo muda numa maneira mais interessante:
nosso alvo é mostrar que um arbitrario membro $a$ que pertence
a intersecção infinita dos $A_i$'s pertence ao $D_{w+1}$ tambem,
dado que qualquer membro dela pertence ao $D_w$;
e temos então ambas as coisas que precisamos
(o $a \in D_w$ pela (H.I.) e o $a \in A_w$
pois $a$ pertence a todos os $A_i$'s).

%%}}}

%%{{{ prob: sandwiching_a_set_sequence 
\problem Sanduichando uma seqüência de conjuntos.
%%%{{{ meta 
\label sandwiching_a_set_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Demonstre que para todo $k\in\nats$,
$$
\Inter_{i=k}^{\infty} {A_i}
\subset
A_k
\subset
\Union_{i=k}^{\infty} {A_i}.
$$
Ou seja, temos:
$$
\matrix
\format
\c      & \;\c\; & \r                                                 & \quad\c\quad & \c     & \quad\c\quad & \r                                                 & \;\c\; & \c  \\
C_0     & \asseq & A_0 \inter A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_0    & \subset    & A_0 \union A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_0 \\
C_1     & \asseq &            A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_1    & \subset    &            A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_1 \\
C_2     & \asseq &                       A_2 \inter A_3 \inter \dotsb & \subset    & A_2    & \subset    &                       A_2 \union A_3 \union \dotsb & \eqass & D_2 \\
        & \vdots &                     \ddots \phantom{\inter \dotsb} & \vdots       & \vdots & \vdots       &                     \ddots \phantom{\union \dotsb} &        & \vdots \\
\endmatrix
$$

%%}}}

\endproblems
%%}}}

%%{{{ Indexed_families 
\section Famílias indexadas.
%%%{{{ meta 
\label Indexed_families
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na \reftag[Sequences] vimos como nos livrar da restricção de usar
um conjunto $\set{0,\dotsc,n-1}$ como ``rótulos'' para indexar os
membros duma tupla e, usando o conjunto infinito $\nats$,
chegamos na idéia de \emph{seqüências}.
Agora vamos generalizar os conceitos tanto de tuplas, quanto de
seqüências: oi, famílias indexadas!

%%}}}

%%{{{ Motivation 
\note Motivação.
%%%{{{ meta 
%%%}}}

A idéia que nos motiva é: \emph{por que nos limitar ``acessando''
os membros de uma tupla apenas usando inteiros como índices (rótulos),
enquanto podemos ``liberar'' qualquer objeto para servir como rótulo?}
E é assim que fazemos mesmo.

%%}}}

%%{{{ eg: daughters_of_p 
\example.
%%%{{{ meta 
\label daughters_of_p
%%%}}}

Seja $\cal C$ o conjunto de todos os países do mundo e,
para cada $c \in \cal C$, seja $V_c$ o conjunto de todos os vilarejos do $c$.
Em símbolos,
$$
V_c = \setstt v {$v$ é um vilarejo no país $c$}.
$$
O que acabamos de definir aqui?
Para \emph{cada} país $c\in\cal C$ um novo objeto foi definido:
o conjunto de todos os vilarejos de $c$.
Ou seja, acabamos de definir vários objetos,
\emph{exatamente um para cada membro do $\cal C$}.
Assim que determinar isso, dizemos que temos uma \dterm{família indexada
por $\cal C$}.

%%}}}

%%{{{ df: indexed_family 
\definition família indexada.
%%%{{{ meta 
\label indexed_family
\defines
    * \family {~{a_i}} {~i\in ~{\cal I}}  -- a família indexada dos $a_i$'s
    * conjunto!de índices
    * família!indexada
    * tupla!$\cal I$-tupla
    ;;
%%%}}}

Chegamos assim na idéia de \dterm{família indexada} por
algum conjunto $\cal I$, cuja totalidade denotamos por
$\family {a_i} {i\in \cal I}$ ou $\famst {a_i} {i\in \cal I}$,
onde $a_i$ é um determinado objeto para cada $i \in \cal I$.
Chamamos o $\cal I$ o \dterm{conjunto de índices} da família,
e quando ele é implícito pelo contexto denotamos a família apenas
com $\family {a_i} i$.
Alternativamente usamos como sinônimo o termo \dterm{$\cal I$-tupla},
enfatizando assim que o conceito de família indexada é apenas
uma generalização da $n$-tupla.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mais uns exemplos de famílias indexadas:

%%}}}

%%{{{ eg: anscestors_and_children 
\example.
%%%{{{ meta 
\label ancestors_and_children
%%%}}}

Seja $\pers$ o conjunto de todas as pessoas do mundo.
Definimos para cada pessoa $p\in \pers$, os conjuntos $A_p$ e $C_p$ de todos
os ancestrais e todos os filhos de $p$, respectivamente.
Ou seja, acabamos de definir duas \emph{famílias indexadas} de conjuntos:
a $\famil A p \pers$ e a $\famil C p \pers$.

%%}}}

%%{{{ eg: airports_direct_flights 
\example.
%%%{{{ meta 
\label airports_direct_flights
%%%}}}

Seja $\cal A$ o conjunto de todos os aeroportos.
Para cada aeroporto $a\in\cal A$, seja
$$
D_a \defeq \setst { b \in \cal A } { \text{existe vôo direto de $a$ para $b$} }.
$$
Acabamos de definir uma família de conjuntos
$\famst {D_a} {a \in \cal A}$.

%%}}}

%%{{{ eg: books_and_authors 
\example.
%%%{{{ meta 
\label books_and_authors
%%%}}}

Seja $\cal B$ o conjunto de todos os livros.
Para cada livro $b\in\cal B$, sejam
$$
\align
A_b &\defeq \setstt a {$a$ é um autor do livro $b$}\\
W_b &\defeq \setstt w {$w$ é uma palavra que aparece no texto do livro $b$}.
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Sabendo a definição de igualdade entre tuplas, definir
igualdade entre famílias indexadas é fácil.

%%}}}

%%{{{ df: indexed_families_equality 
\definition Igualdade.
%%%{{{ meta 
\label indexed_families_equality
%%%}}}

Sejam
$\family {a_i} {i\in \cal I}$,
$\family {b_i} {i\in \cal I}$
famílias indexadas por um conjunto de índices $\cal I$.
Chamamo-nas iguais sse
$$
\lforall {i\in\cal I} {a_i = b_i}.
$$

%%}}}

%%{{{ Q: How would you define union and intersection of a family?
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias as operações (unárias!) de união e de intersecção
para famílias?

%%}}}

\spoiler

%%{{{ df: Union_Inter_of_family 
\definition.
%%%{{{ meta 
\label Union_Inter_of_family
%%%}}}

Seja $\famil A i {\cal I}$ é uma família de conjuntos indexada por um
conjunto de índices $\cal I$.
Definimos
$$
\xalignat2
x \in \Union_{i\in\cal I} A_i &\defiff \lexists {i\in \cal I} {x \in A_i}&
x \in \Inter_{i\in\cal I} A_i &\defiff \lforall {i\in \cal I} {x \in A_i}.
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Note que em palavras de rua, as definições são igualzíssimas:
um objeto pertence à união da família sse ele pertence a pelo
menos um dos seus membros; e perence à sua intersecção sse ele
pertence a todos os seus membros.

%%}}}

%%{{{ x: intersection_of_indices_of_families_exercise 
\exercise.
%%%{{{ meta 
\label intersection_of_indices_of_families_exercise
%%%}}}

Sejam $I,J$ conjuntos de índices e para cada $k\in I\union J$ seja $A_k$ um conjunto.
A afirmação
$$
\Union_{k\in I\inter J} A_k
=
\Union_{k\in I} A_k \inter
\Union_{k\in J} A_k
$$
é verdadeira?
Responda\dots
(1) \emph{sim}, e demonstre;
(2) \emph{não}, e refute; ou
(3) \emph{depende}, e mostre um exemplo e um contraexemplo.

\hint
Depende.
Agora ache um exemplo e um contraexemplo.

\solution
Depende!
Primeiramente um exemplo onde a afirmação é válida:
$$
\xalignat2
I = J &= \set{1} &
A_1 &= \set{5}
\intertext{\dots e um onde a afirmação é falsa:}
I &=\set{1} &
A_1 = A_2 &= \set{5} \\
J &=\set{2}
\endxalignat
$$
Realmente, verificamos calculando no primeiro exemplo:
$$
\xalignat2
\Union_{k\in I\inter J} A_k &= A_1 &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_1 = A_1
\intertext{\dots e no segundo:}
\Union_{k\in I\inter J} A_k &= \Union_{k\in\emptyset} A_k = \emptyset &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_2 = \set{5}
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixando o \ref[intersection_of_indices_of_families_exercise]
nos guiar, chegamos numa investigação interessante:

%%}}}

%%{{{ x: unions_and_intersections_of_indices 
\exercise.
%%%{{{ meta 
\label unions_and_intersections_of_indices
%%%}}}

Sejam $\cal I$, $\cal J$ conjuntos de índices, e suponha que
para cada membro $k \in \cal I \union \cal J$ um conjunto
$A_k$ é determinado.
O que podemos concluir sobre os conjuntos
$$
\xalignat4
\Union_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \union
\Union_{j\in\cal J} {A_j} &
\Union_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \inter
\Union_{j\in\cal J} {A_j} \\
\Inter_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \union
\Inter_{j\in\cal J} {A_j} &
\Inter_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \inter
\Inter_{j\in\cal J} {A_j}
\endxalignat
$$
das opções: \symq{$=$}, \symq{$\subset$}, \symq{$\supset$}, etc.
Investigue.

%%}}}

\endsection
%%}}}

%%{{{ Indexed_sets_vs_indexed_families 
\section Conjuntos indexados \vs famílias indexadas.
%%%{{{ meta 
\label Indexed_sets_vs_indexed_families
%%%}}}

%%{{{ df: indexed_set 
\definition Conjuntos indexados.
%%%{{{ meta 
\label indexed_set
\defines
    * conjunto!indexado por conjunto
    ;;
%%%}}}

Quando usamos um conjunto $B$ para ``indexar'' um conjunto $A$,
chamamos o $A$ um \dterm{conjunto indexado por $B$}.
Temos então:
$$
A = \setst {\dots b \dots} {b \in B}.
$$

%%}}}

%%{{{ remark: every_set_can_be_indexed 
\remark.
%%%{{{ meta 
\label every_set_can_be_indexed
%%%}}}

Todo conjunto $A$ pode ser indexado por ele mesmo, pois
$$
A = \setst a {a \in A}.
$$
Em outras palavras, o ``conjunto indexado'' não é um tipo
diferente do tipo ``conjunto''.  Não faz sentido nos perguntar
se um conjunto $A$ é indexado ou não, pois todos são
(pelo menos por eles mesmo).

%%}}}

%%{{{ remark: picking_elements_from_indexed_sets 
\remark Tomando elementos de conjuntos indexados.
%%%{{{ meta 
\label picking_elements_from_indexed_sets
%%%}}}

Suponha que temos um conjunto $A$ indexado
por um conjunto $B\neq\emptyset$:
$$
A = \setst {\bla(b)} {b\in B}.
$$
Como podemos ``tomar um arbitrario membro de $A$''?
Claramente podemos dizer: ``seja $a \in A$'', algo válido
para qualquer conjunto $A \neq \emptyset$.
Mas nesse caso, ``sejando'' um $b\in B$, determinamos
um membro de $A$: o $\bla(b)$.
Assim, se demonstrarmos algo sobre o $\bla(b)$,
isso é suficiente para concluir que todos os elementos
de $A$ satisfazem esse algo.
Imagine então que queremos demonstrar que
$$
A \subset C.
$$
Podemos seguir o caminho padrão, demonstrando
$$
\lforall {a \in A} {a \in C},
$$
mas temos um caminho alternativo que podemos seguir nesse caso:
demonstrar que
$$
\lforall {b \in B} {\bla(b) \in C}.
$$

%%}}}

%%{{{ indexed_sets_equality 
\note Igualdade entre conjuntos indexados.
%%%{{{ meta 
\label indexed_sets_equality
%%%}}}

Para mostrar que dois \emph{conjuntos}
indexados pelo mesmo conjunto são iguais, é \emph{suficiente}
mostrar que são iguais como famílias---mas não \emph{necessário}:
veja~\ref[equal_as_fam_not_necessary_for_equal_as_sets].
\eop
Por exemplo, sejam $A,B$ conjuntos indexados pelo mesmo conjunto $C$:
$$
\xalignat2
A &= \setst {\bla(c)} {c \in C} &
B &= \setst {\blu(c)} {c \in C}.
\endxalignat
$$
Suponha que queremos demonstrar $A=B$.
O caminho orthódoxo seria seguir a definição de igualdade de conjuntos
e demonstrar
$$
\lforall x {x\in A \iff x \in B},
\qqqtext{ou seja,}
A \subset B \mland A \supset B.
$$
Mas, vendo eles como \emph{conjuntos indexados por o $C$},
podemos matar o alvo $A=B$ numa maneira alternativa, aplicando
a definição de igualdade de famílias indexadas.
No final das contas, parecem famílias indexadas por o mesmo conjunto
de índices (o $C$).
Então demonstrando a afirmação
$$
\lforall {c \in C} {\bla(c) = \blu(c)}
$$
é \emph{suficiente} para demonstrar que $A=B$.

%%}}}

%%{{{ beware: equal_as_fam_not_necessary_for_equal_as_sets 
\beware Suficiente mas não necessário!.
%%%{{{ meta 
\label equal_as_fam_not_necessary_for_equal_as_sets
%%%}}}

Observe que mostramos algo ainda mais forte: não é apenas
que $A=B$ como conjuntos, mas como \emph{famílias} indexadas também,
ou seja, \emph{concordam em todo índice}.
Mas: pode ser que como famílias
não são iguais, mas como conjuntos, são, como o exemplo
seguinte mostra:

%%}}}

%%{{{ eg: equal_as_fam_not_necessary_for_equal_as_sets_example 
\example.
%%%{{{ meta 
\label equal_as_fam_not_necessary_for_equal_as_sets_example
%%%}}}

Considere os
$$
\xalignat2
A &= \setst {x + 1} {x \in \ints} &
B &= \setst {x - 1} {x \in \ints}.
\endxalignat
$$
São dois conjuntos indexados pelo mesmo conjunto $\ints$.
Obviamente $A=B$, mas para nenhum índice $x \in \ints$ temos
$x + 1 = x - 1$.

%%}}}

\endsection
%%}}}

%%{{{ Pairwise-disjointness 
\section Disjuntos dois-a-dois.
%%%{{{ meta 
%%%}}}

%%{{{ df: pairwise_disjoint 
\definition.
%%%{{{ meta 
\label pairwise_disjoint
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos seus membros \dterm{disjuntos dois-a-dois} sse nenhum deles
tem elementos em comum com nenhum outro deles.
Em símbolos:
$$
\text{os conjuntos da $\scr A$ são disjuntos dois-a-dois}
\defiff
\lforall {A,B \in \scr A} {A \neq B \implies A\inter B = \emptyset }.
$$
Similarmente para famílias indexadas:
$$
\align
\text{os conjuntos da $\famil A i {\cal I}$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \cal I} {i\neq j \implies A_i \inter A_j = \emptyset}.
\intertext{E logo para seqüências também:}
\text{os conjuntos da $\seqn A n$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \nats} {i\neq j \implies A_i \inter A_j = \emptyset}.
\endalign
$$

%%}}}

%%{{{ x: disjoint_not_pairwise_disjoint 
\exercise.
%%%{{{ meta 
\label disjoint_not_pairwise_disjoint
%%%}}}

Ache uma família de conjuntos $\scr A$ com $\Inter \scr A = \emptyset$
mas cujos membros não são disjuntos dois-a-dois.

\solution
Tome
$$
\scr A \asseq \set{ \set{0,1}, \set{1,2}, \set{7} }.
$$

%%}}}

\endsection
%%}}}

%%{{{ Coverings and partitions 
\section Coberturas e partições.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Translating_from_and_to_the_language_of_sets 
\section Traduzindo de e para a linguagem de conjuntos.
%%%{{{ meta 
\label Translating_from_and_to_the_language_of_sets
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Lembra os exemplos~\reftag[ancestors_and_children],~\reftag[airports_direct_flights],
e~\reftag[books_and_authors]?
Bom.  Vamos practicar nossa fluência em cojuntos usando esses exemplos agora.

%%}}}

%%{{{ x: ancestors_and_children_translations 
\exercise.
%%%{{{ meta 
\label ancestors_and_children_translations
%%%}}}

Para toda pessoa $p\in\pers$ defina $A_p$ e $C_p$ como
no~\ref[ancestors_and_children].
Suponha que $p,q,r$ denotam pessoas.
Traduza as afirmações descritas na linguagem de conjuntos para
linguagem natural e vice versa.
% TODO: fix reflabs
\elist a:
\li: $p$ e $q$ são irmãos;
\li: $C_p \neq \emptyset$;
\li: $p$ é filho único;
\li: $p$ e $q$ são parentes;
\li: $p$ e $q$ são primos de primeiro grau;
\li: $r$ é filho dos $p$ e $q$;
\li: $C_p \inter C_q \neq \emptyset$;
\li: $A_p \subset A_q$;
\li: $\emptyset \subsetneq C_p \subsetneq C_q$;
\li: $\lexists {p\in\pers} {p \in C_p}$.
\endelist

\solution
Traduzimos:
$$
\align
\text{$p$ e $q$ são irmãos}                      &: \text{$p\neq q \mland \exists r \paren{\set{p,q}\subset C_r}$} \\
\text{$C_p \neq \emptyset$}                      &: \text{$p$ tem pelo menos um filho} \\
\text{$p$ é filho único}                         &: \text{$\lexists {r\in A_p} {C_r = \set{p}}$} \\
\text{$p$ e $q$ são parentes}                    &: \text{$A_p \inter A_q \neq \emptyset$} \\
\text{$p$ e $q$ são primos de primeiro grau}     &: \text{$\exists r,r'\paren{p\in C_r \mland q \in C_{r'} \mland \text{$r$ e $r'$ são irmãos}}$} \\
\text{$r$ é filho dos $p$ e $q$}                 &: \text{$r \in C_p \inter C_q$} \\
\text{$C_p \inter C_q \neq \emptyset$}           &: \text{$p$ e $q$ têm pelo menos um filho juntos} \\
\text{$A_p \subset A_q$}                         &: \text{$p$ é um anscestor ou irmão de $q$} \\
\text{$\emptyset \subsetneq C_p \subsetneq C_q$} &: \text{$q$ tem filho(s) com $p$ mas com outra pessoa também} \\
\text{$\lexists {p\in\pers} {p \in C_p}$}        &: \text{existe pessoa que é seu próprio filho}.
\endalign
$$
(Tuas traduções podem variar, especialmente se tuas definições
dessas palavras são diferentes que aquelas que eu usei aqui.)

%%}}}

\endsection
%%}}}

%%{{{ Generalized_cartesian_product 
\section Produto cartesiano generalizado.
%%%{{{ meta 
\label Generalized_cartesian_product
%%%}}}

%%{{{ idea 
\note.
%%%{{{ meta 
%%%}}}

Vamos começar com
\emph{dois objetos} $a$ e $b$, nessa ordem,
ou seja com uma tupla $\tup{a,b}$.
Já sabemos como generalizar essa idéia para uma \emph{família indexada}
por um conjunto abstrato de índices $\cal I$, chegando assim
na $\famil a i {\cal I}$.
\eop
Agora comece com \emph{dois conjuntos} $A$ e $B$, nessa ordem,
ou seja com uma tupla $\tup{A,B}$.
Podemos formar o \emph{produto cartesiano} dela,
que em vez de escrever $\times\tup{A,B}$ escrevemos com
notação comum e infixa $A\times B$.
$$
\text{produto de $\tup{A,B}$}
= \setst {\tup{a,b}} {a \in A \mland b \in B} 
$$
Com mais detalhes:
o \emph{produto da tupla de conjuntos} $\tup{A,B}$
é \emph{o conjunto de todas as tuplas} $\tup{a,b}$ tais que seu \emph{primeiro}
membro pertence no \emph{primeiro} membro da nossa tupla de conjuntos
$\tup{A,B}$, e seu \emph{segundo} membro pertence no \emph{segundo} membro de
$\tup{A,B}$.

%%}}}

%%{{{ Q: How to generalize from tuples to indexed families? 
\question.
%%%{{{ meta 
%%%}}}

Como generalizar isso de tuplas para famílias indexadas?
Lembre-se que em famílias indexadas não existe mais essa idéia de
\emph{primeiro} e \emph{segundo} membro.
Em vez disso, temos \emph{membro no índice $i$},
um para cada $i\in\cal I$.

%%}}}

\spoiler

%%{{{ In search for a generalization 
\note Procurando uma generalização.
%%%{{{ meta 
%%%}}}

Antes de responder na pergunta, vamos construir nosso caminho
numa forma mais metódica.
$$
\matrix
\format
\c & \quad\c\quad & \c \\
\tup{A,B} & \leadsto & A\times B \\
\famil A i {\cal I} & \leadsto & ??
\endmatrix
$$
Um passo importante é perceber que nessa situação são envolvidos
dois processos: um de ``formar o produto de coisas'',
e outro de ``generalizar de tuplas para famílias indexadas''.
Então uma imagem melhor seria o diagrama
$$
\cdopt{sep=2cm}
\tup{A,B}   \ar[r, "\text{product}"]\ar[d, "\text{generalize}"'] \| A\times B\ar[d, dashed, "\text{generalize}"]\\
\famil A i {\cal I}   \ar[r, dashed, "\text{product}"]           \| ??
\endcd
$$
onde idealmente deveria \dterm{comutar}, que informalmente quis dizer que
os dois caminhos que nos levam de $\tup{A,B}$ para o desejado $??$
vão chegar na mesma coisa.
(Teremos muito mais a falar sobre \dterm{diagramas comutativos} nos próximos
capítulos.)
\eop
Assim fica mais fácil achar o $??$:
$$
\cdopt{column sep=2cm, row sep=6mm}
\tup{A,B}       \ar[r]\ar[d] \| \setst  {\tup{a,b}}     {a\in A \mland b\in B}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setst  {\tup{a_0,a_1}} {a_0\in A_0 \mland a_1\in A_1}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setstt {\tup{a_0,a_1}} {$a_i\in A_i$ para todo $i\in\set{0,1}$}\ar[d, dashed]\\
\famil A i {\cal I}   \ar[r, dashed]                          \| ??
\endcd
$$
A definição correta agora da idéia que estávamos procurando é óbvia:
$$
\text{o produto da $\famil A i {\cal I}$ é o conjunto
$\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}$}.
$$
Só basta achar uma notação legal para esse conjunto, e essa escolha também é fácil.

%%}}}

%%{{{ df: gartesian porduct of an indexed family of sets 
\definition Produto cartesiano de família.
%%%{{{ meta 
\label cartesian_product_generalized
\defines
    * \Prod_{~i\in{~{\cal I}}} {~{A_i}}  -- o produto cartesiano da família indexada de conjuntos $\famil A i {\cal I}$.
    * produto cartesiano!generalizado
    ;;
%%%}}}

Seja $\famil A i {\cal I}$ uma família indexada de conjuntos.
Definimos seu \dterm{produto cartesiano}
$$
\Prod_{i\in\cal I} A_i
\defeq
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}.
$$

%}}}

%%{{{ x: cardinalidade_of_product_of_finite_sets 
\exercise.
%%%{{{ meta 
\label cardinalidade_of_product_of_finite_sets
%%%}}}

Seja $\cal I$ um conjunto finito de índices e para cada
$i \in \cal I$ seja $A_i$ um conjunto finito.
Qual a cardinalidade do $\Prod_i {A_i}$?

\hint
$\card{A\times B} = ?$

%%}}}

%%{{{ choosers_product 
\note Escolhedores.
%%%{{{ meta 
\label choosers_product
\defines
    * escolhedor!produto
    * produto!nívelo coração
    ;;
%%%}}}

Vou tentar dar um ponto de vista ``no nível coração'' sobre o produto duma família.
Vamos começar com o produto cartesiano ``normal'' (ou seja, aquele que forma $n$-tuplas mesmo).
Como exemplo real, vamos considerar os $3$ conjuntos: $A,B,C$
Nesse caso o que seria o $A \cross B \cross C$?
Agora tome um membro $t$ do $A \cross B \cross C$.
O que ele \emph{é}?
Uma tripla, certo.
Com certeza tem a forma
$$
t = \tup{ a, b, c }
$$
para alguns $a\in A$, $b\in B$, e $c \in C$.
Mas o que ele é no meu coração?
Como a gente o chama no meu bairro?
Posso pensar que ele é um \dterm{escolhedor}.
Ele escolhe \emph{exatamente um membro de cada um dos conjuntos $A,B,C$}.
Pense que os $A$, $B$, e $C$ por exemplo são conjuntos de
``starter'', ``main course'', e sobremesa respectivamente
$$
\align
A &= \set{ \textrm{salada}, \textrm{sopa}, \textrm{tzatziki} } \\
B &= \set{ \textrm{pizza}, \textrm{carbonara}, \textrm{pastitsio} } \\
C &= \set{ \textrm{tiramisu}, \textrm{yogurte} }
\endalign
$$
E esse é o menu dum restaurante onde para jantar o cliente (escolhedor)
precisa escolher exatamente uma opção de cada.
O produto cartesiano $A \cross B \cross C$ então, que é o
$$
\align
A \cross B \cross C = {}
   &\{ \tup{\textrm{salada},   \textrm{pizza},     \textrm{tiramisu}} \\
   & , \tup{\textrm{salada},   \textrm{pizza},     \textrm{yogurte}} \\
   & , \tup{\textrm{salada},   \textrm{carbonara}, \textrm{tiramisu}} \\
   & \vdots \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}} \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{yogurte}} \}.
\endalign
$$
representa todos os possíveis escolhedores.
A tripla
$$
\tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}}
$$
então além de ser ``apenas uma tripla'', pode ser vista como
o escolhedor que escolheu:
$$
\align
\textrm{tzatziki}  &\in A \\
\textrm{pastitsio} &\in B \\
\textrm{tiramisu}  &\in C.
\endalign
$$
Observe que a $i$-ésima escolha do escolhedor, pertence ao
$i$-ésimo argumento do produto $A\cross B \cross C$,
onde aqui $i \in \set{0,1,2}$.
\eop
Na mesma maneira então,
dada família indexada de conjuntos $\famil A i {\cal I}$ cada
membro do seu produto cartesiano
$$
\Prod_{i\in\cal I} A_i
=
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}
$$
é uma família indexada
$$
\text{$\famil a i {\cal I}$
tal que $a_i \in A_i$ para todo $i\in\cal I$},
$$
ou seja, um escolhedor que escolha um membro de cada um
dos membros da família $\famil A i {\cal I}$:
a $i$-ésima escolha $a_i$ do escolhedor $\famil a i {\cal I}$
pertence ao $i$-ésimo argumento $A_i$ do produto $\Prod_{i\in\cal I} A_i$.
Pense nisso.

%%}}}

\TODO Notação: $\Pi_i$ \vs $\Pi$.

\endsection
%%}}}

%%{{{ Structured_sets 
\section Conjuntos estruturados.
%%%{{{ meta 
\label Structured_sets
%%%}}}

\TODO Elaborar.

%%{{{ concept, notation, equality 
\note Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

Já encontramos a idéia de estrutura (interna) dum
conjunto~(foi no~\ref[blackbox_set]).

%%}}}

%%{{{ warning: notational_abuse_structured_sets 
\warning abuso notacional.
%%%{{{ meta 
\label notational_abuse_structured_sets
\pdefs
    \pdef A {{\ssetfont A}}
    ;;
%%%}}}

Suponha $\A = \sset A {\dotsc}$ é algum conjunto estruturado.
Tecnicamente falando, escrever \sq{$a\in \A$} seria errado.
Mesmo assim escrevemos sim \sq{$a\in \A$} em vez de \sq{$a\in A$},
e similarmente falamos sobre \wq{os elementos de~$\A$}
quando na verdade estamos se referendo aos elementos de~$A$,
etc.
Em geral, quando aparece um conjunto estruturado~$\A$ num contexto
onde deveria aparecer algum conjunto, identificamos o~$\A$
com seu \dterm{carrier set}~$A$.
Às vezes usamos até o mesmo símbolo na sua definição, escrevendo
$A = \sset A {\dotsc}$.

%%}}}

%%{{{ Structured sets with constants 
\note Conjuntos estruturados com constantes.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Structured sets with operations 
\note Conjuntos estruturados com operações.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Structured sets with relations 
\note Conjuntos estruturados com relações.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: dictionary_of_operation_properties 
\definition.
%%%{{{ meta 
\label dictionary_of_operation_properties
%%%}}}

Sejam conjunto $A$,
uma operação binária $\ast$ no $A$,
e um $g \in A$.
Dizemos que:
$$
\align
\text{$A$ é $\ast$-fechado}                     &\defiff \lforall {a,b \in A}   {a \ast b \in A}\\
\text{$\ast$ é associativa}                     &\defiff \lforall {a,b,c \in A} {(a \ast b) \ast c = a \ast (b \ast c)}\\
\text{$\ast$ é comutativa}                      &\defiff \lforall {a,b \in A}   {a \ast b = b \ast a}\\
\text{$u$ é uma $\ast$-identidade esquerda}     &\defiff \lforall {a \in A}     {u \ast a = a}\\
\text{$u$ é uma $\ast$-identidade direita}      &\defiff \lforall {a \in A}     {a \ast u = a}\\
\text{$u$ é uma $\ast$-identidade}              &\defiff \lforall {a \in A}     {u \ast a = a = a \ast u}\\
\text{$y$ é um $\ast$-inverso esquerdo de $g$}  &\defiff \text{$y \ast g = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso direito de $g$}   &\defiff \text{$g \ast y = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso de $g$}           &\defiff \text{$y \ast g = e = g \ast y$, \ onde $e$ é uma $\ast$-identidade}
\endalign
$$
onde não escrevemos os ``$\ast$-'' quando são implícitos pelo contexto.

%%}}}

%%{{{ operating_on_an_empty_list_of_objects 
\note Operando numa lista vazia de objetos.
%%%{{{ meta 
\label operating_on_an_empty_list_of_objects
%%%}}}

Suponha que para algum $k\in\nats$ temos uns objetos
$$
a_0,a_1,\dotsc,a_{k-1}
$$
definidos.  Ou seja, temos $k$ objetos.
O que seria o resultado operando eles entre si?
Isso é algo que denotamos por
$$
a_0 \ast a_1 \ast \dotsb \ast a_{k-1}
\qqqqtext{ou}
a_0 a_1 \dotsb a_{k-1}.
$$
Como \emph{a operação associativa}, essa expressão faz sentido,
assim sem parênteses, para qualquer $k>0$.
E, se \emph{a operação tem identidade}, então ela é definida até
para o caso extremo de $k=0$.
Se $k=0$ temos uma lista de $0$ membros para operar.
E realmente definimos esse resultado para ser a identidade da operação.

%%}}}

%%{{{ df: rel_fechado 
\definition.
%%%{{{ meta 
\label rel_fechado
%%%}}}

Seja $R$ uma relação num conjunto $A$ e $X \subset A$.
Chamamos o $X$ de \dterm{$R$-fechado}
sse para todo $x \in X$, e todo $a \in A$
com $x \rel R a$, temos $a \in X$ também.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\TODO Maybe have a first contact with $\sigma$-rings, $\sigma$-fields, topologies, {etc.}.

%%{{{ prob: set_liminf_limsup_problem 
\problem.
%%%{{{ meta 
\label set_liminf_limsup_problem
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os conjuntos
$$
\xalignat 2
A_* &= \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
A^* &= \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endxalignat
$$
É verdade que um desses conjuntos é subconjunto do outro?
São iguais?  São disjuntos?

\hint
Podemos demonstrar que $A_* \subset A^*$.

\hint
Use as definições, passo a passo.

\solution
Vamos demonstrar que $A_* \subset A^*$.
\eop
Seja então $x\in A_* = \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j$.
Logo seja $i_0 \in \nats$ tal que $x \in \Inter_{j=i_0}^{\infty} A_j$.
Sabemos então que
$$
\lforall {j \geq i_0} {x \in A_j}.   \tag{*}
$$
Queremos demonstrar que $x\in A^* = \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j$.
Seja então $n_0\in\nats$.
Agora basta demonstrar que
$$
x \in \Union_{j=n_0}^{\infty} A_j.
$$
Em outras palavras, procuramos um $k\in\nats$ que satisfaz: $k \geq n_0$ e $x \in A_k$.
Tome $k \asseq \max\set{i_0, n_0}$ e observe que esse $k$ satisfaz ambas as condições.
Pela escolha de $k$ a primeira condição é satisfeita imediatamente.
Sobre a segunda, como $k \geq i_0$, pela (*) temos que $x \in A_k$,
que foi o que queremos demonstrar.

%%}}}

%%{{{ prob: set_liminf_limsup_problem_heart_level 
\problem Nível coração.
%%%{{{ meta 
\label set_liminf_limsup_problem_heart_level
%%%}}}

Entenda no teu coração o que tu provaste no~\ref[set_liminf_limsup_problem].
Como descreverias os elementos dos $A_*$ e $A^*$?
Explique com ``palavras da rua'' justificando o resultado obtenido.

\hint
Comece rascunhando os dois lados, usando \symq{$\dotsb$}, etc.

\hint
Vamos primeiramente analizar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência.
Quais são?

\hint
Os primeiros membros são:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Faça a mesma coisa sobre o $A^* = \Inter_i \Union_{j\geq i} A_j$.

\hint
Cada um desses membros também é uma intersecção ou união duma seqüência.
Escrava cada uma delas como uma expressão que envolve \symq{$\dotsb$}.

\hint
Temos:
$$
\xalignat2
A_* &= \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
A^* &= \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
E agora precisamos \emph{entender} as proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
para enxergar se uma implica a outra, etc.

\hint
O que podemos concluir sobre a \emph{quantidade} dos $A_n$'s que
$x$ pertence, sabendo a primeira?  O que sabendo a segunda?

\hint
Em ambos os casos podemos concluir que $x$ pertence a uma quantidade
infinita de $A_i$'s, então isso não é suficiente para nosso objectivo.
A segunda proposição realmente é \emph{equivalente} a essa afirmação,
ou seja:
$$
x \in A^* \iff \text{$x$ pertence a uma quantidade infinita de $A_n$'s}.
$$
Mas a primeira afirma algo \emph{mais forte}, ou seja, realmente
$$
x \in A_* \implies x \in A^*.
$$
Mas para enxergar isso precisamos entender qual é toda a informação
que a proposição \symq{$x \in A^*$} contem:
$$
x \in A_* \iff \askdots
$$

\hint
Se $x \in A_*$, a quantos dos $A_n$'s pode ser
que o $x$ \emph{não} pertence?
E se $x \in A^*$?

\solution
A idéia é entender o que cada uma das proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
quis dizer, para enxergar se uma implica a outra, etc.
Como já demonstramos ``mecanicamente'' no~\ref[set_liminf_limsup_problem]
que $A_* \subset A^*$, queremos então chegar na conclusão que
$$
x \in A_* \implies x \in A^*
$$
num caminho diferente: do coração.
\eop
Vamos primeiramente analizar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Cada um desses membros também é uma intersecção duma seqüência.
Vamos escrever numa maneira que deixa os primeiros termos vizíveis:
$$
\align
\Inter_{j\geq 0} A_j &= A_0 \inter A_1 \inter A_2 \inter \dotsb \\
\Inter_{j\geq 1} A_j &= A_1 \inter A_2 \inter A_3 \inter \dotsb \\
\Inter_{j\geq 2} A_j &= A_2 \inter A_3 \inter A_4 \inter \dotsb \\
&\eqvdots
\endalign
$$
Trabalhando dualmente no $A^*$, chegamos nas:
$$
\xalignat2
x &\in \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
x &\in \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
Sabendo a primeira concluimos que $x$ pertence a \emph{pelo menos uma}
das linhas da esquerda, vamos dizer a $u$-ésima, ou seja
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
Logo sabemos que
$$
\text{$x$ pertence a todos os $A_u, A_{u+1}, A_{u+2}, \dotsc$}.
$$
Em outras palavras:
\emph{a partir dum ponto, $x$ pertence a todos os membros da seqüência original}.
Provamos então que
$$
x \in A_* \implies \text{a partir dum ponto, $x$ pertence a todos os $A_n$'s}.
$$
Vamos demonstrar o converso agora.
Suponha que a partir dum $u\in\nats$, sabemos que $x$ pertence a todos os
$A_u, A_{u+1}, A_{u+2}, \dotsc$, ou seja,
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
ou seja, achamos uma linha onde $x$ pertence e logo $x \in A_*$.
\eop
Agora a segunda proposição ($x \in A^*$)
concluimos que $x$ pertence a \emph{todas} as linhas
da direita, ou seja:
$$
\alignat 2
x &\in {}& A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
Observe que a $j$-ésima linha afirma que
\emph{mesmo depois de andar $j$ passos na seqüência,
ainda terá $A_n$'s com $x$ neles}.
Sabendo então que cada uma dessas linhas é verdade, podemos concluir
que $x$ pertence a uma infinidade dos $A_n$'s, e vice versa:
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Vamos demonstrar isso.
\eop
\lrdir:
Temos como hipótese todas as
$$
\alignat 2
x &\in {}& A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
e queremos mostrar que $x$ pertence a uma infinidade dos $A_n$'s.
Basta mostrar que para qualquer ``desafio'' $v\in\nats$,
$x$ pertence àlgum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Seja $v\in\nats$ então.
Olha na $v$-ésima linha e é exatamente o que queremos.
\eop
\rldir:
Agora sabendo que $x$ pertence a uma quantidade infinita de $A_n$'s precisamos
mostrar que
$$
\text{para todo $v\in\nats$},
\quad
x \in A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
Seja $v\in\nats$ então.
Para chegar num absurdo, suponha que
$$
x \notin A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
ou seja, $x$ não pertence a nenhum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Mas isso quis dizer que $x$ pertence no máximo em $v$ dos $A_n$'s,
contradizendo nossa hipótese que $x$ pertence numa infinidade deles.
\eop
Concluimos então que
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Como comparam essas afirmações?
\tlist:
\li: $x\in A_*$: a partir dum ponto, $x$ pertence a todos os $A_n$'s;
\li: $x\in A^*$: $x$ pertence a uma infinidade dos $A_n$'s.
\endtlist
Deve ser óbvio que
$$
x \in A_* \implies x \in A^*.
$$
E como já entendemos o que cada proposição quis dizer mesmo,
podemos facilmente demonstrar que o converso não é sempre
válido.
Para um contraexemplo onde
$$
x \in A_* \notimpliedby x \in A^*
$$
considere a seqüência
$$
\align
A_0 &= \set {0} \\
A_1 &= \set {0,1} \\
A_2 &= \set {0} \\
A_3 &= \set {0,1} \\
A_4 &= \set {0} \\
A_5 &= \set {0,1} \\
    &\eqvdots
\endalign
$$
Observe que os $0,1$ são aqueles que pertencem a uma infinidade dos $A_n$'s.
Mas apenas o $0$ pertence a todos os $A_n$'s a partir dum certo ponto.

%%}}}

%%{{{ prob: set_liminf_limsup_problem_not_converse 
\problem.
%%%{{{ meta 
\label set_liminf_limsup_problem_not_converse
%%%}}}

Demonstre que a inclusão conversa não é sempre válida.
Ou seja: construa seqüência de conjuntos $\seqn A n$ tal que
$$
A_* \subsetneq A^*.
$$
Podes construir uma tal que ambos os $A_*, A^*$ são infinitos
e cada um dos $A_n$'s é um subconjunto finito de $\nats$?

\solution
Sem a restricção uma tal seqüência seria a
$$
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\dotsc
$$
Assim temos $A_* = \emptyset$ e $A^* = \set{1}$.
\eop
Para satisfazer a restricção, considere a seqüência:
$$
A_n =
\knuthcases {
\setstt {k \leq n} {$k$ é primo}, & se $n$ par; \cr
\setstt {k \leq n} {$k$ é ímpar}, & caso contrário.
}
$$
Seus primeiros termos:
$$
\xalignat 2
A_0 &= \emptyset            & A_1 &= \set{1} \\
A_2 &= \set{2}              & A_3 &= \set{1,3} \\
A_4 &= \set{2,3}            & A_5 &= \set{1,3,5} \\
A_6 &= \set{2,3,5}          & A_7 &= \set{1,3,5,7} \\
A_8 &= \set{2,3,5,7}        & A_9 &= \set{1,3,5,7,9} \\
    &\eqvdots               &     &\eqvdots
\endxalignat
$$
Nesse caso,
$$
\alignat2
A_* &= \set{3, 5, 7, 11, 13, 17, \dotsc}      &&= \setstt {n\in\nats} {$n$ é um primo ímpar} \\
A^* &= \set{1, 2, 3, 5, 7, 9, 11, 13, \dotsc} &&= \setstt {n\in\nats} {$n=2$ ou $n$ ímpar}.
\endalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os $A_*$ e $A^*$ do \ref[set_liminf_limsup_problem]
merecem seus próprios nomes!

%%}}}

%%{{{ df: set_limits 
\definition.
%%%{{{ meta 
\label set_limits
\defines
    * \lim_{~n} {~{A_n}}  -- o limite da seqüência $\seqn A n$
    * \liminf_{~n} {~{A_n}}  -- o limite inferior da seqüência de conjuntos $\seqn A n$
    * \limsup_{~n} {~{A_n}}  -- o limite superior da seqüência de conjuntos $\seqn A n$
    * limite!de seqüência de conjuntos
    * limite!de seqüência de conjuntos
    ;;
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos seu \dterm{limite inferior} e seu \dterm{limite superior} pelas:
$$
\xalignat2
\liminf_n A_n &\defeq \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
\limsup_n A_n &\defeq \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endxalignat
$$
Note que pelo~\ref[set_liminf_limsup_problem] sabemos se um é subconjunto
de outro ou não.  Mas pode ser que os dois conjuntos são iguais.
Digamos que a seqüência de conjuntos $\seqn A n$ \dterm{converge} sse
$$
\liminf_n A_n = \limsup_n A_n.
$$
Nesse caso, chamamos esse conjunto de \dterm{limite} da $\seqn A n$
e usamos a notação $\lim_n A_n$ para denotá-lo.

%%}}}

%%{{{ df: increasing_decreasing_sequence 
\definition.
%%%{{{ meta 
\label increasing_decreasing_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Dizemos que $\seqn A n$ é uma \dterm{seqüência crescente} sse
$A_i \subset A_{i+1}$ para todo $i\in \nats$.
Similarmente, $\seqn A n$ é uma \dterm{seqüência decrescente} sse
$A_i \supset A_{i+1}$ para todo $i\in \nats$.
Rascunhamente:
$$
\align
\text{$\seqn A n$ crescente}
&\defiff A_0 \subset A_1 \subset A_2 \subset \cdots \\
\text{$\seqn A n$ decrescente}
&\defiff A_0 \supset A_1 \supset A_2 \supset \cdots
\endalign
$$
Uma seqüência é \dterm{monótona} (ou \dterm{monotônica}) sse
ela é crescente ou decrescente.

%%}}}

%%{{{ prob: monotone_sequences_have_limits 
\problem.
%%%{{{ meta 
\label monotone_sequences_have_limits
%%%}}}

Seja $\seqn A n$ uma seqüência monótona.
Demonstre que $\seqn A n$ tem limite.
Qual é?

%%}}}

%%{{{ prob: sandwich_breads_are_monotone_and_optimal 
\problem Os pães do sanduiche são monótonos e ótimos.
%%%{{{ meta 
\label sandwich_breads_are_monotone_and_optimal
%%%}}}

No~\ref[sandwiching_a_set_sequence] definimos duas seqüências
``sanduichando'' a $\seqn A n$: uma crescente (a $\seqn C n$)
e uma decrescente (a $\seqn D n$).
Pelo~\ref[monotone_sequences_have_limits] então ambas
têm limites, e realmente temos
$$
\limit_n C_n = \liminf_n A_n \subset \limsup_n A_n = \limit_n D_n.
$$
Ainda mais é verdade:
de todas as seqüências crescentes, $\seqn C n$ é a maior tal que
$C_n\subset A_n$ para todo $n\in\nats$; e similarmente
de todas as decrescentes, $\seqn D n$ é a menor tal que
$A_n\subset D_n$ para todo $n\in\nats$.
Formalize o que significam as palavras ``maior'' e ``menor''
na afirmação acima, e demonstre sua veracidade.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Podes achar boas explicações, dicas, muitos exemplos resovidos,
e exercícios e problemas para resolver no \cite[velleman: \S1.3~\&~\S2.4].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Functions 
\chapter Funcções.
%%%{{{ meta 
\label Functions
%%%}}}

% BABY

%%{{{ intro 
\chapintro
Neste capítulo estudamos mais um \emph{tipo} importantíssimo e fundamental em
matemática: a \emph{funcção}.
Nosso objectivo aqui é familiarizar-nos com funcções,
entender como podemos defini-las, usá-las, combiná-las para criar novas,
operar nelas, etc.
\eop
Vamos brincar com a poderosa \emph{notação lambda do $\lambda$-calculus}
(\reftag[A_touch_of_lambda]), e com funcções de \emph{ordem superior}
(\reftag[Higher_order_functions])
e apreciar que graças a \emph{currificação}~(\reftag[Currying]) nem
precisamos funcções de aridades maiores que $1$.
Aqui aprendemos também o que são mesmo os
\emph{diagramas comutativos}~(\reftag[Commutative_diagrams]),
ferramentas que vamos usar constantemente a partir de agora!
Estudamos também o que realmente significa definir funcções
\emph{recursivamente}~(\reftag[Recursive_definitions_as_systems]),
algo que temos feito ``sem pensar'', baseados na nossa intuição e no
nosso insticto muitas vezes até agora.
Finalmente~(\reftag[Categories_a_first_taste])
teremos nosso primeiro contato com \emph{categorias}, que oferecem uma abordagem
e linguagem unificativa para diversos cantos de matemática (e mais).
(O~\ref[Category_theory] e dedicádo na teoria das categorias.)
\eop
Bem depois, no~\ref[Axiomatic_set_theory], vamos nos preocupar com
a questão de \emph{como implementar} esse tipo (o tipo de funcções),
\emph{como fundamentar} esse conceito---mas esqueça isso por enquanto.
Primeiramente precisamos entender bem o que é uma funcção e como se comporta.
E muitas ferramentas relevantes.
Bora!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
\label Function_contept
%%%}}}

%%{{{ unlabeled black box for function 
\note Black boxes.
%%%{{{ meta 
\indexes
    * funcção!como black box    see: black box
    ;;
\defines
    * black box!de funcção
    ;;
%%%}}}

Começamos imaginando funcções como black boxes;
parecidos mas diferentes daqueles que usamos para conjuntos
(\reftag[blackbox_set]), pois essas caixas têm uma entrada mas
também uma saída própria:
$$
\tikzpicture
\tikzi blackboxfun;
\endtikzpicture
$$

%%}}}

%%{{{ prim: function_primitive 
\primitive funcção.
%%%{{{ meta 
\label function_primitive
\indexes
    * codomínio    see: funcção
    * domínio    see: funcção
    ;;
\defines
    * funcção!codomínio
    * funcção!definição intuitiva
    * funcção!domínio
    * funcção!valor
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos $f$ uma \dterm{funcção de $A$ para $B$}, sse
para todo $x \in A$, o símbolo $f(x)$ é definido e $f(x)\in B$.
O $f(x)$ é o \dterm{valor} da $f$ no $x$.
O \dterm{domínio} da $f$ é o conjunto $A$,
e seu \dterm{codomínio} é o conjunto $B$.
Consideramos então que a funcção $f$ associa \emph{para todo} elemento $a \in A$,
\emph{exatamente um} elemento $f(a) \in B$.

%%}}}

%%{{{ df: function_notation 
\definition.
%%%{{{ meta 
\label function_notation
\defines
    * \cod {~f}  -- o codomínio da funcção $f$
    * \dom {~f}  -- o domínio da funcção $f$
    * ~A \toby {~f} ~B  -- $f$ é uma funcção de $A$ para $B$
    * ~f : ~A \to ~B  -- $f$ é uma funcção de $A$ para $B$
    * ponto!de conjunto
    ;;
%%%}}}

Escrevemos
$$
f : A \to B
\qqqqtext{e sinonimamente}
A \toby f B
$$
para dizer que \emph{$f$ é uma funcção de $A$ para $B$},
e escrevemos
$$
x \mapstoby f y
$$
para dizer que \emph{$f$ mapeia o $x$ para o $y$}.
Definimos também as operações $\dom$ e $\cod$
que retornam o domínio e o codomínio do seu argumento.
Resumindo:
$$
f : A \to B
\quad\defiff\quad
\text{$f$ é uma funcção}
\;\mland\;
\dom f = A
\;\mland\;
\cod f = B.
$$
Às vezes o tipo da funcção aparece olhando para a direção oposta:
$f : B \from A$ em vez de $f : A \to B$.
Escrevemos também $f\app x$ em vez de $f(x)$,
e em certos casos (mais raros) $f_x$ ou $x^f$ ou até $x\app f$.
Podemos referir aos membros do domínio e do codomínio duma
funcção como \dterm{pontos} desses conjuntos.

%%}}}

%%{{{ remark: explicit_application 
\remark.
%%%{{{ meta 
\defines
    * ~f \at ~x  -- notação explícita para o $f(x)$
    * funcção!aplicação
    ;;
%%%}}}

Quando escrevemos \sq{$f\app x$} (ou \sq{$f(x)$}),
estamos escrevendo algo que representa a \dterm{aplicação}
da $f$ no $x$.
(E o que estamos denotando é o \dterm{valor} da $f$ no $x$.)
O símbolo da aplicação é invisível, ou seja, a aplicação é denotada
pela juxtaposição do nome da funcção (aqui \sq{$f$}) e do nome
do seu argumento (aqui \sq{$x$}).
(já discutimos isso no~\ref[clearer_functional_notation]).
Quando precisamos vê-la mesmo na nossa sintaxe podemos usar
a notação infixa
$$
f \at x \sugeq f (x).
$$

%%}}}

%%{{{ f : A -> B  and  A --f--> B  notations 
\note.
%%%{{{ meta 
%%%}}}

Escrevemos ``sejam $f,g : A \to B$'' e entendemos como:
``sejam funcções $f$ e $g$ de $A$ para $B$'', e (abusando) se não temos já
declarados os conjuntos $A,B$, a mesma frase entendemos com um implícito
``sejam conjuntos $A,B$ e funcções \dots''.
Do mesmo jeito, a frase
$$
\text{<<{Sejam $A \toby f B \toby g C$.}>>}
$$
pode ser equivalente à frase
$$
\text{<<{Sejam conjuntos $A,B,C$, e funcções $f:A\to B$ e $g:B\to C$.}>>}
$$
Espero que dá para apreciar a laconicidade dessa notação.

%%}}}

%%{{{ function vs. application of function 
\note Funcção \vs aplicação de funcção.
%%%{{{ meta 
%%%}}}

Em matemática muitas vezes falamos frases como as seguintes:
$$
\gather
\text{<<a funcção $\sin(x)$ é periódica>>}, \\
\text{<<a funcção $f(t)$ é monótona>>}, \\
\endgather
$$
etc.  Literalmente estamos falando algo errado!
As funcções, nesse exemplo, são as $\sin$ e $f$, não as $\sin(x)$ e $f(t)$.
Denotamos por $\sin(x)$ o \emph{valor} da funcção $\sin$ no ponto $x$,
e com $f(t)$ o \emph{valor} da funcção $f$ no ponto $t$.
Claramente, esse ``erro'' é algo que não vai confundir nenhum matemático,
e com a mínima maturidade matemática não vamos encontrar problema nenhum
trabalhando assim.
Entendemos então que é apenas um ``modo de falar'' usado em certos casos.
Mas aqui nosso objectivo é estudar e \emph{fundamentar} bem a idéia e a ``alma''
dos vários tipos matemáticos, e não podemos nos permitir nenhum abuso desse tipo!
Essa distinção vai ficar ainda mais crucial, com a notação de $\lambda$-calculus
e com as funcções de órdem superior.

%%}}}

%%{{{ The type of a function 
\note O tipo duma funcção.
%%%{{{ meta 
%%%}}}

Seja $f : A \to B$.
Chamamos o \sq{$A \to B$} o tipo da $f$, e pronunciamos
\utter{funcção de $A$ para $B$}.

%%}}}

%%{{{ x: what_is_the_type_of_foo_for_C_programmers 
\exercise.
%%%{{{ meta 
\label what_is_the_type_of_foo_for_C_programmers
\indexes
    * C
    * C++
    * Java
    ;;
%%%}}}

Aqui um programa escrito em C:
\sourcecode typefoo.c;
Qual é o tipo desse $\code{x}$ no corpo da $\code{foo}$?
Qual o tipo da $\code{foo}$?
Cuidado: programadores de C (e C++, Java, etc.) tendem errar nessa última questão!

\hint
O tipo de $\code{foo}$ não é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.

\solution
O tipo de $\code{x}$ é $\code{int}$.
O tipo de $\code{foo}$ é: ``funcção de $\code{int}$ para $\code{int}$''.
Programadores de $C$ muitas vezes erram nessa terminologia, dizendo que o tipo de $\code{foo}$ é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.
O que eles querem dizer é que o \emph{return type} de $\code{foo}$ é $\code{int}$, e isso tá certo.
Mas a pergunta foi identificar o \emph{tipo} de $\code{foo}$.

%%}}}

%%{{{ a_taste_of_type_inference 
\note Um toque de inferência de tipos.
%%%{{{ meta 
\label a_taste_of_type_inference
%%%}}}

Sabendo que $f : A \to B$ e $x : A$, o que podemos inferir?
A resposta óbvia aqui é essa:
$$
\PROOFmr {
\A {f \is A \to B}    \A {x \is A}
\I2------------------------------- {FunApp}
         {f \fa x \is B}
}
$$
Escolhi chamar essa regra de \namedrule{FunApp} de ``Function Application'',
talvez dando a impressão errada que é uma regra muito original
e nova, que nunca a encontramos antes mas\dots
isso seria mentira:

%%}}}

%%{{{ x: curry_howard_teaser_exercise 
\exercise.
%%%{{{ meta 
\label curry_howard_teaser_exercise
%%%}}}

Bem antes de estudar funcções, a gente
encontrou a ``mesma'' regra, só que com
roupas diferentes, mas nem tanto!
De que eu tô falando?

\hint
Já que falei que isso foi bem antes de estudar funcções,
apague da
$$
\PROOFm {
\A {f \is A \to B}    \A {x \is A}
\I2------------------------------- {FunApp}
         {f \fap x \is B}
}
$$
as partes que têm a ver com funcções:
$$
\PROOFm {
\A {\aR{f \is{}} A \to B}    \A {\aR{x \is {}}A}
\I2----------------------------------------------------- {\aR{FunApp}}
               {\aR{f \fap x \is{}} B}
}
$$

\solution
Esquecendo as partes que têm a ver com funcções chegamos na regra
$$
\PROOFm {
\A {A \to B}    \A {A}
\I2-------------------- {ModusPonens?!}
           {B}
}
$$
que é\dots a modus ponens (\ref[modus_ponens]) mesmo?
A regra de como usar implicação?!
Sim.  Continue lendo o texto agora.

%%}}}

%%{{{ teaser: curry_howard_teaser 
\teaser Curry--Howard.
%%%{{{ meta 
\label curry_howard_teaser
\indexes
    * Curry--Howard!teaser
    ;;
%%%}}}

{\Curry}%
{\Howard}%
O que tu acabou de descobrir no~\ref[curry_howard_teaser_exercise]
é uma manifestação duma \emph{conexão muito profunda entre lógica
e computação}, conhecida como \dterm{correspondência Curry--Howard},
ou também \dterm{propositions-as-types and proofs-as-programs interpretation}.
A idéia é que podemos ver tipos de funcções como proposições e vice versa.
E nesse caso \emph{definir uma funcção} de certo tipo e \emph{demonstrar}
a correspondente proposição são ações equivalentes.
Com esse ponto de vista as demonstrações são objetos \emph{bem vivos!}
Podemos executá-las (pois são programas), observar sua execução
e receber a informação que elas retornam.
Espero que isso não é \emph{tão} surpresa, pois já tenho dado muitos
spoilers e elaborado essa dinámica de demonstrações desde os primeiros
capítulos, especialmente no~\ref[Proofs].
Estudando programação funccional, lógica intuicionista, teoria das provas,
e teoria dos tipos, tudo isso vai fazer mais sentido, e essa correspondência
vai acabar sendo um dos assuntos mais importantes do nosso estudo nesse texto!
Por enquanto paciêcia até esses capítulos
(viz:
\reftag[Functional_programming],
\reftag[Intuitionistic_logic],
\reftag[Proof_theory],
\reftag[Type_theory]).

%%}}}

%%{{{ df: funs_set 
\definition.
%%%{{{ meta 
\label funs_set
\defines
    * \funs {~A} {~B}  -- o conjunto das funcções de $A$ para $B$
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Denotamos por $\funs A B$ o conjunto das funcções de $A$ para $B$:
$$
f \in \funs A B \defiff {f : A \to B}.
$$
O mesmo conjunto denotamos também por $B^A$.

%%}}}

%%{{{ x: size_of_funs 
\exercise.
%%%{{{ meta 
\label size_of_funs
%%%}}}

Por quê?
Supondo que os $A,B$ são finitos, justifique a notação $B^A$
para o conjunto $\funs A B$.
(Primeiro objetivo desse exercício então é entender o que significa
\emph{justificar uma notação} nesse caso.)

\hint
Cardinalidade.

\hint
Se por acaso $\size{\funs A B} = {\size A}^{\size B}$,
isso seria uma justificativa boa para a notação $B^A$.
(Lembra da 

\solution
Temos $\size A$ coisas para definir até determinar uma funcção de $A$ para $B$.
Para cada uma delas (para cada $a\in A$) temos $\size B$ opções para mandá-lo
(nossas escolhas não afetam a quantidade de opções que teremos nas próximas).
Logo pelo princípio da multiplicação
$$
\size{\funs A B} = {\size A}^{\size B}.
$$

%%}}}

%%{{{ Conditions: functionhood_conditions 
\note Condições de funccionalidade.
%%%{{{ meta 
\label functionhood_conditions
\defines
    * funccionalidade!condições
    * funcção!determinabilidade
    * funcção!totalidade
    ;;
\indexes
    * univocidade    see: determinabilidade
    ;;
%%%}}}

Na~\ref[function_primitive] aparece a frase
\wq{o símbolo $f(x)$ é definido}.
Com isso entendemos que não existe ambigüidade, ou seja, para uma entrada $x$,
a $f$ não pode ter mais que uma saída.
E graças a outra frase, \wq{para todo $x\in A$}, sabemos que tem
\emph{exatamente uma} saída.  Esta saída é o que denotamos por $f(x)$.
Resumindo:
\eop\noi
Para todo $x\in\dom f$,
\tlist:
\li (F-Tot):totality
existe pelo menos um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{totalidade});
\li (F-Det):determinacy
existe no máximo  um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{determinabilidade}).
\endtlist
Quando a \ref[totality] acontece dizemos que
\emph{a $f$ é definida em todo o seu domínio}.
Usamos o termo \dterm{univocidade} como sinônimo de determinabilidade.

%%}}}

%%{{{ Arity and tuples 
\note Aridade e tuplas.
%%%{{{ meta 
\indexes
    * aridade
    ;;
%%%}}}

No jeito que ``definimos'' o que é uma funcção, ela só pode depender
em apenas um objeto, apenas uma entrada.
Isso parece bastante limitante, pois estamos já acostumados
com funcções com aridades diferentes.\foot
Lembra-se que \dterm{aridade} é a quantidade de argumentos-entradas.
\toof
Caso que uma funcção precisa mais que um argumento como entrada,
usamos a notação $f(x_1, \dotsc, x_n)$.
Identificamos isso com uma funcção que recebe ``apenas um'' objeto
como entrada: a $n$-tupla $\tup{x_1,\dotsc,x_n}$.
Então identificamos as notações
$$
\gather
f(x_1,\dotsc,x_n) = f( \tup{x_1,\dotsc,x_n} ) = f \tup{x_1,\dotsc,x_n}\\
f(x)              = f( \tup{x} )              = f \tup{x} = f \app x\\
f()               = f( \tup{}  )              = f \tup{}
\endgather
$$
onde na última linha às vezes identificamos com o próprio $f$
também---quando não existe possibilidade de confusão---mas vamos evitar
isso aqui.
\eop
Similarmente, se queremos ``retornar'' mais que um objeto,
podemos ``empacotar'' todos eles numa tupla, e retornar apenas essa tupla,
satisfazendo assim a demanda de unicidade de funcção---cuidado pois isso
tem que ser refletido no codomínio da funcção!

%%}}}

%%{{{ Synonyms 
\note Sinônimos.
%%%{{{ meta 
\indexes
    * operador    seealso: funcção
    * operação    seealso: funcção
    * procedimento    seealso: funcção
    * mapa    see: funcção
    * mapeamento    see: funcção
    * map    see: funcção
    * transformação    see: funcção
    ;;
\defines
    * funcção!sinônimos
    ;;
%%%}}}

Lembra que usamos várias palavras como sinônimos de ``conjunto''?
(Quais?)
Pois é, para funcções a situação é parecida.
\emph{Dependendo do contexto e da ênfase},
as palavras seguintes podem ser usadas como
sinônimos de ``funcção'':
mapeamento,
mapa,
map,
operação,
operador,
transformação,
etc.

%%}}}

%%{{{ Intension vs. extension 
\note Intensão \vs extensão.
%%%{{{ meta 
\label intension_vs_extension_in_functions
%%%}}}

Como nos conjuntos (\ref[Intension_vs_extension_in_sets]),
temos novamente a idéia de \dterm{intensão} e \dterm{extensão} de uma funcção.
Pensando uma funcção como uma caixa que dentro dela tem um \emph{programa},
a extensão dela não seria o que ela faz mesmo internalmente (isso seria sua
\emph{intensão}), mas o que ela \emph{consegue}.
Imaginando duas ``caixas pretas'' $f$ e $g$ onde podemos apenas observar
seus comportamentos usando as suas interfaces e nada mais, faz sentido
considerar iguais aquelas que não conseguimos demonstrar nenhum comportamento diferente.
Ou seja: qualquer entrada \emph{aceitável} para uma, deve ser \emph{aceitável}
para a outra também (pois, se não, isso já seria uma diferença observável);
e ainda mais, para a mesma entrada, as funcções têm de atribuir o mesmo
valor---novamente: se não, isso já seria um comportamento diferente e
observável.

%%}}}

%%{{{ Programs vs. functions 
\note Programas \vs funcções.
%%%{{{ meta 
\label programs_vs_functions
\indexes
    * Python
    ;;
%%%}}}

Considere as duas funcções $\code{f}$ e $\code{g}$ implementadas
no programa seguinte em Python:
\sourcecode intext.py;
Suponha que queremos considerar ambas definidas nos inteiros.
A \emph{extensão} da $\code{f}$ é a mesma com a extensão da $\code{g}$.
Ou seja, como funcções, temos $f = g$.
Suas \emph{intensões} são diferentes.
A primeira funcção, dado um número grande vai fazer bem mais operações até
finalmente retornar um valor.
Tente calcular as duas no interpretador de Python e também perceberás uma diferença
no tempo que cada uma precisa: compare os
$\code{f(1000000000)}$ e $\code{g(1000000000)}$.
Os \emph{programas} então são diferentes (pois num programa é a intensão que importa)
mas as funcções são iguais.
Note que quando observamos caixas pretas, não podemos nem medir o tempo que
cada uma precisa para responder com seu valor, nem podemos tocar elas para ver
qual ficou mais quente, nem escutar para possíveis barulhos, etc.
Podemos apenas dar uma entrada e observar a saída e nada mais!

%%}}}

%%{{{ What about the codomain? (I) 
\note E o codomínio? (I).
%%%{{{ meta 
\label what_about_the_codomain_1
%%%}}}

Em matemática clássica, e especialmente em teoria de
conjuntos~(\ref[Axiomatic_set_theory]) e análise,
em geral não consideramos que o codomínio duma funcção ``faz parte dela''.
Ou seja, a mesma funcção $\sin$, por exemplo, pode ser considerada como
$$
\xalignat3
\sin_1 &: \reals\to\reals     &
\sin_2 &: \reals\to[-1,1]     &
\sin_3 &: \reals\to(-\infty,2).
\endxalignat
$$
Para esse matemático então, \emph{o codomínio não é algo observável:}
como tu vai diferenciar entre as $\sin_1, \sin_2, \sin_3$ acima,
se tua única interface é dando objetos para elas, e observando seus valores (saídas)?
Pois é, não tem como.
No outro lado, se alterar os domínios isso já é uma diferença demonstrável
(observável) com essa mesma única interface.

%%}}}

%%{{{ x: how? 
\exercise.
%%%{{{ meta 
%%%}}}

Como?

\hint
O que significa que os domínios de duas funcções são diferentes?

\solution
Se $f : A \to B$ e $g : C \to D$ são funcções com $A\neq C$,
pela definição de igualdade de conjuntos, existe $x \in A\symdiff C$.
Para esse $x$, as funcções vão comportar diferentemente.
Se $x \in A$ (e logo $x\notin C$), a $f$ vai aceitar o $x$
e vamos observar sua saída $f(x)$, mas a $g$ não vai aceitar
o $x$, e assim não vamos ver nenhuma saída;
Similarmente, se $x \in C$ (e logo $x\notin A$).

%%}}}

%%{{{ dom_and_cod_recoverable_or_not 
\note Recuperável ou não?.
%%%{{{ meta 
\label dom_and_cod_recoverable_or_not
%%%}}}

Com esse ponto de vista, o domínio é um conjunto \emph{recuperável}
pela própria funcção $f$, pois podemos definir:
$$
\dom f
\defeq
\setst x {\lexists y {x \mapstoby f y}}.
$$
Mas o codomínio não!

%%}}}

%%{{{ x: cod_wrongdef 
\exercise.
%%%{{{ meta 
\label cod_wrongdef
%%%}}}

Qual o problema com essa suposta definição de codomínio de uma funcção $f$?:
$$
\cod f
\defeq
\setst y {\lexists x {x \mapstoby f y}}.
$$

\hint
Aplique a $\cod$ nos $\sin_1,\sin_2,\sin_3$ do \ref[what_about_the_codomain_1].

\solution
Aplicando essa definição de $\cod$ nas $\sin_1,\sin_2,\sin_3$ do \ref[what_about_the_codomain_1],
temos que
$$
\cod (\sin_1)
= \cod (\sin_2)
= \cod (\sin_3)
$$
mesmo que claramente não foi essa a nossa intenção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O conjunto definido no~\ref[cod_wrongdef] realmente é interessante
e importante, só que ele não é (necessariamente) o codomínio da
funcção, mas o que chamamos de range:

%%}}}

%%{{{ df: range 
\definition.
%%%{{{ meta 
\label range
\indexes
    * funcção!range    seealso: imagem
    ;;
\defines
    * \range {~f}  -- o range (também: imagem) da funcção $f$
    * funcção!range
    ;;
%%%}}}

Seja $f : A \to B$ funcção.
Seu \dterm{range} é o conjunto
$$
\range (f)
\defeq
\setst y {\lexists x {x \mapstoby f y}}.
$$
Observe que $\range(f) \subset B$.

%%}}}

%%{{{ beware: ima 
\beware.
%%%{{{ meta 
\label ima
\indexes
    * funcção!imagem    seealso: range
    * imagem    see: funcção, imagem
    ;;
\defines
    * \ima {~f}  -- o range (também: imagem) da funcção $f$
    * funcção!imagem
    ;;
%%%}}}

O conjunto que acabamos de definir na~\ref[range]
é também chamado de \dterm{imagem} da~$f$,
e a notação $\ima f$ também é usada para denotá-lo.
Esse conjunto é a imagem \emph{duma funcção}.
Não confunda isso com a imagem \emph{dum conjunto} (\emph{através} duma funcção),
algo que estudamos na~\ref[Images_preimages].

%%}}}

%%{{{ x: what about these types for sin? 
\exercise.
%%%{{{ meta 
%%%}}}

Podemos considerar a funcção $\sin$ como uma funcção com os tipos seguintes?:
$$
\xalignat4
\sin_4 &: \rats \to \reals &
\sin_5 &: \reals\setminus\rats \to \reals\setminus\rats &
\sin_6 &: \rats \to \rats  &
\sin_7 &: \set{\pi} \to \set{0}
\endxalignat
$$

\solution
É fácil responder sobre as $\sin_4$ e $\sin_7$, pois realmente são
apenas restricções da funcção $\sin : \reals\to\reals$
(veja~\ref[fresto]).
Mas a situação com as $\sin_5$ e $\sin_6$ é bem mais complicada
que isso!
Sobre a $\sin_5$, supondo que sabemos que $\pi \notin \rats$,
concluimos que o seu tipo está errado,
pois $\sin(\pi) = 0 \notin \reals\setminus\rats$.
Note que para responder nisso precisamos saber a irracionalidade
de $\pi$, algo que não é trivial!
Mesmo sabendo disso, não é fácil responder sobre a $\sin_6$.
Seu tipo é realmente errado, pois
$$
\text{para todo $x \in \rats_{\neq0}$,  $\sin(x) \notin \rats$}
$$
mas a prova desse resultado é fora do escopo desse texto.
(Veja~\cite[nivenirrational: Cor.~2.7] para mais detalhes.)
Ou seja, podemos considerar a $\sin$ com tipo
$$
\sin_8 : \rats_{\neq0} \to \reals\setminus\rats.
$$

%%}}}

%%{{{ remark: codomain is any superset of range 
\remark.
%%%{{{ meta 
%%%}}}

Seguindo o ponto de vista do~\reftag[what_about_the_codomain_1],
tendo uma funcção $f : A \to B$,
podemos considerar ela como uma funcção com codomínio qualquer superconjunto de
$B$, sem mudar nada observável.
Em símbolos:
$$
f : A \to B  \mland  \range(f) \subset B'  \implies  f : A \to B'.
$$
Esse ponto de vista, identifica funcções com gráficos iguais,
mas nem definimos ainda o que é um gráfico de funcção.
É o seguinte.

%%}}}

%%{{{ df: function_graph 
\definition.
%%%{{{ meta 
\label function_graph
\defines
    * \graph{~f}  -- o gráfico da funcção $f$
    * funcção!gráfico
    ;;
%%%}}}

Dado funcção $f : X\to Y$, o \dterm{gráfico da $f$}, é o conjunto
$$
\graph f \defeq \setst {\tup{x,f(x)}} {x \in X}.
$$
Observe que $\graph f \subset X\times Y$.

%%}}}

%%{{{ What about the codomain? (II) 
\note E o codomínio? (II).
%%%{{{ meta 
\label what_about_the_codomain_2
%%%}}}

Em outras partes de matemática, especialmente em teoria das
categorias~(\ref[Category_theory]),
teoria dos tipos~(\ref[Type_theory]),
e álgebra,
consideramos que o codomínio duma funcção faz parte dela sim!
Pensando em funcções como black boxes então, com essa visão,
temos que imaginar que as caixas pretas tem dois rótulos
impressos: um na sua entrada com o domínio escrito nele,
e um na sua saída com o codomínio.
Assim, a diferença do codomínio vira uma coisa imediatamente
observável: é só olhar no rótulo da saída!

%%}}}

%%{{{ labeled black box for function 
\note Funcções como black boxes com rótulos.
%%%{{{ meta 
%%%}}}

Com a idéia (II) de funcção visualizamos uma funcção
$f : A \to B$ assim:
$$
\tikzpicture
\tikzi blackboxfuncat;
\endtikzpicture
$$

%%}}}

%%{{{ Equality in functions 
\note Igualdade de funcções.
%%%{{{ meta 
%%%}}}

Dependendo qual ponto de vista de funcção seguimos,
a definição de igualdade para o tipo de funcção vai ser diferente!
Mostramos primeiramente as definições corretas para
o ponto de vista~(I) e o ponto de vista~(II)
(explicados nos~\reftag[what_about_the_codomain_1]
e~\reftag[what_about_the_codomain_2]).
Depois, escrevendo num jeito diferente, chegamos numa definição que
vamos realmente usar e que é aplicável independente do ponto de vista.
Nesse texto vamos sempre deixar claro para cada funcção encontrada qual
conjunto consideramos como seu domínio e qual como seu codomínio.\foot
Exceto numas partes onde esclarecemos
qual a noção de funcção que utilizamos.
\toof
Assim, a escolha de ponto de vista de funcção não vai nos afetar.

%%}}}

%%{{{ df: f_eq_g_setist 
\definition Igualdade (I): ``Conjuntista''.
%%%{{{ meta 
\label f_eq_g_setist
%%%}}}

Sejam $f,g$ funcções.
Digamos que $f=g$ sse \emph{quaisquer duas} das afirmações seguintes são válidas:
\elist 1:
\li: $\dom f = \dom g$;
\li: para todo $x \in \dom f$, $f(x) = g(x)$;
\li: para todo $x \in \dom g$, $f(x) = g(x)$.
\endelist
Equivalentemente,
$$
f = g \defiff \graph f = \graph g.
$$

%%}}}

%%{{{ df: f_eq_g_catist 
\definition Igualdade (II): ``Categorista''.
%%%{{{ meta 
\label f_eq_g_catist
%%%}}}

Sejam $f,g$ funcções.
Dizemos que $f=g$ sse 
\elist 1:
\li: $\dom f = \dom g$;
\li: $\cod f = \cod g$;
\li: para todo $x \in \dom f$, $f(x) = g(x)$.
\endelist

%%}}}

%%{{{ Two religions 
\note Duas religiões.
%%%{{{ meta 
\label two_religions
%%%}}}

Podemos pensar então que tem duas religiões, que vamos chamar
aqui de Conjuntista e de Categorista.  Cada um tem sua idéia
do que se trata uma funcção.
Note que cada um vai ler as notações $f : A \to B$ e $A \toby f B$
numa maneira diferente:
$$
\align
\text {Conjuntista:}\  &
\text{<<$f$ é uma funcção com domínio $A$, e $\range(f) \subset B$>>}\\
\text {Categorista:}\  &
\text{<<$f$ é uma funcção com domínio $A$, e codomínio $B$>>}.
\endalign
$$
Vamos escrever agora uma definição de igualdade flexível
para satisfazer os dois:

%%}}}

%%{{{ df: f_eq_g 
\definition Igualdade (agnóstica).
%%%{{{ meta 
\label f_eq_g
%%%}}}

Sejam $f,g : A\to B$ funcções.
Definimos
$$
f=g
\defiff
\text{para todo $x \in A$, $f(x) = g(x)$.}
$$

%%}}}

%%{{{ f_eq_g is indeed flexible 
\remark.
%%%{{{ meta 
%%%}}}

Assuma a fé do Conjuntista e leia a~\ref[f_eq_g]:
ela é equivalente à~\reftag[f_eq_g_setist].
Agora assuma a fé do Categorista e leia a~\reftag[f_eq_g]
novamente: ela é equivalente à~\reftag[f_eq_g_catist].

%%}}}

%%{{{ df: endomapping 
\definition.
%%%{{{ meta 
\label endomapping
\indexes
    * funcção!endomapa
    * endomapa          see: funcção
    ;;
\defines
    * endomapa
    ;;
%%%}}}

Uma funcção $f$ é um \dterm{endomapa} no $A$ sse $\dom f = \cod f = A$.

%%}}}

%%{{{ eg: succ and its black box 
\example.
%%%{{{ meta 
%%%}}}

A funcção $\succ : \nats\to\nats$
que retorna para cada natural $n$ seu sucessor $n+1$.
Dando por exemplo $2$ como entrada nela, observamos o valor
$\succ (2) = 3$:
$$
\tikzpicture
\tikzi blackboxfunsucc;
\endtikzpicture
$$
O $\succ$ é um exemplo de endomapa.

%%}}}

%%{{{ remark: Some notions don't make sense for the Setist 
\remark.
%%%{{{ meta 
\indexes
    * funcção!endomapa
    ;;
%%%}}}

Observe que a noção de ``ser endomapa'' não faz sentido
para quem escolher definir \emph{funcção} pela~\ref[f_eq_g_setist]
(ou seja, para o ``Conjuntista'')
pois ele nem sabe dizer qual é o codomínio duma funcção.
Logo vamos encontrar mais noções que também não fazem
sentido pra ele---fique alerto!

%%}}}

\endsection
%%}}}

%%{{{ Internal_and_external_diagrams 
\section Diagramas internos e externos.
%%%{{{ meta 
\label Internal_and_external_diagrams
%%%}}}

%%{{{ Internal diagrams 
\note Diagramas internos.
%%%{{{ meta 
\defines
    * diagrama!interno
    ;;
%%%}}}

Em certos casos podemos representar toda a informação numa funcção
usando \dterm{diagramas internos}, ou seja, diagramas que mostram
o interno do domínio e codomínio duma funcção, e como ela comporta
nele.

%%}}}

%%{{{ eg: internal_diagram_example 
\example.
%%%{{{ meta 
\label internal_diagram_example
%%%}}}

Aqui um diagrama interno de duas funcções $A \toby f B \toby g C$:
$$
\tikzpicture
\tikzi internaldiagram;
\endtikzpicture
$$
Aqui o conjunto $A$ tem 2 membros---não importa quais são, ou seja,
os nomes deles---o $B$ tem 3, e o $C$ tem 2 também.

%%}}}

%%{{{ names_of_elements 
\note Nomes de elementos.
%%%{{{ meta 
\label names_of_elements
%%%}}}

É muito comum desenhar esse tipo de diagramas para construir exemplos e
contraexemplos que envolvem funcções, e quando os \emph{quais são}
os membros não é importante desenhamos apenas um $\bullet$ para
representar os membros, com o entendimento que pontos distintos
representam membros distintos.
Note que \emph{se} quisermos definir formalmente um exemplo baseado num
desenho, nossa tarefa é trivial: é só escolher nomes para os $\bullet$
e pronto.
Por exemplo, dando esses nómes nos pontos
do~\ref[internal_diagram_example] chegamos no seguinte:
$$
\tikzpicture
\tikzi internaldiagramnames;
\endtikzpicture
$$
E agora para definir isso formalmente na escrita podemos apenas dizer:
Sejam os conjuntos
$$
A = \set{\mathrm a, \mathrm b} \qqqquad
B = \set{\mathrm c, \mathrm d, \mathrm e} \qqqquad
C = \set{\mathrm u, \mathrm v}
$$
e as funcções $f : A\to B$ e $g : B\to C$ definidas pelas:
$$
\aligned
f(\mathrm a) &= \mathrm e\\
f(\mathrm b) &= \mathrm d
\endaligned
\qqqquad
\aligned
g(\mathrm c) &= \mathrm u\\
g(\mathrm d) &= \mathrm v\\
g(\mathrm e) &= \mathrm v.
\endaligned
$$
Observe que os $\mathrm a, \mathrm b, \mathrm c$, etc.~\emph{não são variáveis},
mas as próprias letras \symq{a}, \symq{b}, \symq{c}, etc.
Naturalmente escolhemos nomes bem conhecidos, como números, letras, etc.

%%}}}

%%{{{ remark: to what do those barred arrows correspond? 
\remark.
%%%{{{ meta 
%%%}}}

Então em que corresponde cada uma das setinhas barradas do diagrama interno?
Numa das \emph{equações} que definam a correspondente funcção,
ou seja, num par da forma $\tup{x, f(x)}$.

%%}}}

%%{{{ External diagrams 
\note Diagramas externos.
%%%{{{ meta 
\defines
    * diagrama!externo
    ;;
%%%}}}

Muitas vezes queremos olhar para a ``big picture'' e os detalhes
``internos'' da configuração não nos importam.
Pelo contrário, nos atrapalham: \emph{perdemos a floresta pelas árvores}.
Nesse caso usamos \dterm{diagramas externos}.

%%}}}

%%{{{ eg: external_of_previous_example 
\example.
%%%{{{ meta 
\label external_of_previous_example
%%%}}}

O diagrama externo da configuração do~\ref[internal_diagram_example]
é o seguinte:
$$
A \longtoby f B \longtoby g C.
$$

%%}}}

%%{{{ diagram_of_endomap 
\note Diagramas de endomapas.
%%%{{{ meta 
\label diagram_of_endomap
\indexes
    * funcção!endomapa
    ;;
%%%}}}

No caso especial que temos um endomapa $f:A\to A$,
podemos desenhar seu diagrama interno
sem usar duas cópias de $A$, mas apenas mostrando os mapeamentos assim
como o exemplo seguinte sugere.

%%}}}

%%{{{ eg: internal_diagram_of_endomap 
\example.
%%%{{{ meta 
%%%}}}

Considere o diagrama interno:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramendo1;
\endtikzpicture
$$
Esse é o diagrama interno da funcção $f : A \to A$ definida pelas
$$
\xalignat8
f(1) &= 2; &
f(2) &= 1; &
f(3) &= 1; &
f(4) &= 4; &
f(5) &= 5; &
f(6) &= 8; &
f(7) &= 5; &
f(8) &= 5;
\endxalignat
$$
onde $A = \set {1,2,3,4,5,6,7,8}$.
Tecnicamente as setinhas deveriam ter bundas, mas já que é
um diagrama interno só tem esse tipo de setas (as \sq{$\mapsto$})
então não dá pra confundir e o diagrama fica mais fácil de desenhar
sem tanta bunda.

%%}}}

\endsection
%%}}}

%%{{{ How to define and how not to define functions 
\section Como definir e como não definir funcções.
%%%{{{ meta 
%%%}}}

%%{{{ Q: what must we do to correctly define a function f : A -> B ? 
\question.
%%%{{{ meta 
%%%}}}

O que precisamos fazer para definir corretamente uma funcção?

%%}}}

%%{{{ A: We must make clear what its values are for all of its domain. 
\note Resposta.
%%%{{{ meta 
%%%}}}

Precisamos deixar claro qual é o seu domínio e o seu valor
para cada ponto no seu domínio (totalidade e determinabilidade).
Se consideramos que o codomínio da funcção faz parte dela também
(veja conversa na~\reftag[Function_contept]), precisamos deixar
claro seu codomínio também---aqui sempre faremos isso.

%%}}}

%%{{{ Definition by expression 
\note Definição por expressão.
%%%{{{ meta 
%%%}}}

Uma das maneiras mais comuns para definir funcções, é escrever algo do tipo:
\emph{Seja $f:A\to B$ a funcção definida pela \thole}

%%}}}

%%{{{ remark: what we define is f(x) not f 
\remark.
%%%{{{ meta 
%%%}}}

Literalmente, o que estamos definindo assim é o ``$f(x)$'' para todo $x \in A$,
e não o próprio $f$.  Mas, a $f$ sendo funcção, realmente é determinada para
seu comportamento (seus valores) das todas as entradas possíveis do seu domínio,
então isso realmente defina a própria funcção $f$---graças a definição de igualdade
de funcções.  (Veja também a~\ref[from_x_in_A_union_B_to_A_union_B_to_union].)

%%}}}

%%{{{ eg: a_polynomial_function_on_reals 
\example.
%%%{{{ meta 
\label a_polynomial_function_on_reals
%%%}}}

Seja $f : \reals \to \reals$ definida pela
$$
f(x) = x^2 + 2x + 1, \qquad \text{para todo $x\in \reals$}.
$$
Em geral, cada polinómio de $n$ variáveis,
pode ser visto como uma funcção de aridade $n$.

%%}}}

%%{{{ not_well_defined_function_danger_argument_name_dependence
\beware depender de nome de parametro.
%%%{{{ meta 
\label not_well_defined_function_danger_argument_name_dependence
%%%}}}

Quando definimos uma funcção vale a pena pensar como programador
que está tentando programar essa funcção, ou até assumir o papel
da própria funcção que vai receber seus argumentos e vai precisar
decidir qual seria o seu valor.
Imagine alguém programando uma funcção $\code{foo}$
de $\code{int}$ para $\code{int}$ numa linguagem de programação.
O programador e sua funcção não têm como saber o \emph{nome}
que o chamador da funcção vai usar quando chamando-la.
Em algum ponto ela pode ser chamada pelo $\code{foo(42)}$
passando assim diretamente o \emph{literal} $\code{42}$,
ou, depois de umas atribuições como $\code{int a = 42; int num = 42;}$,
chamá-la $\code{foo(a)}$ ou $\code{foo(num)}$.
Não tem como programar a funcção depender nesses nomes.
Por exemplo:
<<se for chamada com nome que começa com vogal, retorna o inteiro 0;
caso contrário, retorna o inteiro 1>>;
ou
<<retorna o tamanho do nome do teu argumento>>
(querendo retornar $\code{1}$ caso que for chamada pelo $\code{foo(a)}$,
e $\code{3}$ caso que for chamada pelo $\code{foo(num)}$).

%%}}}

%%{{{ noneg: not_well_defined_function_choice_dependence_noneg 
\nonexample.
%%%{{{ meta 
\label not_well_defined_function_choice_dependence_noneg
%%%}}}

Seja $f : \ints \to \ints$ definida pela
$$
f(x+y) = y.
$$

%%}}}

%%{{{ not_well_defined_function_danger_choice_dependence 
\beware depender de escolhas.
%%%{{{ meta 
\label not_well_defined_function_danger_choice_dependence
%%%}}}

Por que o~\ref[not_well_defined_function_choice_dependence_noneg]
é um nãœxemplo mesmo?
Imagine que definimos uma
``funcção'' $f$ pela
$$
f(x+y) = y.
$$
O que seria o $f(2+3)$?  $3$?  Por que não $0$?
No final das contas (literalmente)
$$
2 + 3 \spaceq
5 + 0 \spaceq
4 + 1 \spaceq
12 + (-5) \spaceq
\dots
$$
e $f$ não tem como saber o jeito que tu imaginou ``quebrar''
sua entrada em dois somantes!
A $f$ está olhando ao seu argumento (aqui o $5$) e está tentando
decidir qual seria o seu valor nesse ponto!  E não tem como saber
pois, consultando a sua ``definição'' o resultado vai depender
da escolha desses $x$ e $y$.

%%}}}

%%{{{ Definitive description 
\note Descripção definitiva.
%%%{{{ meta 
\defines
    * descripção definitiva
    ;;
%%%}}}

Podemos definir uma funcção $f : A \to B$ dando uma \dterm{descripção definitiva}
do seu valor num ponto $x$ do seu domínio:
$$
f(x) = \text{aquele $b \in B$ que {\xlthole}}.
$$
Cuidado pois nesse caso precisamos verificar que realmente para cada $x\in A$,
existe exatamente um $b\in B$ que satisfaz a afirmação no {\xlthole}.%

%%}}}

%%{{{ Definitive descriptor 
\remark Descritor definitivo.
%%%{{{ meta 
\defines
    * \descrsym  -- descritor definitivo
    * descritor definitivo
    ;;
%%%}}}

Existe uma notação especial para a frase <<aquele $b$ que {\xlthole}>>:
o \dterm{descritor definitivo} $\descrsym$:
$$
\textwq{aquele $b$ que {\xlthole}} \quad\leadsto\quad \descr b {{\xlthole}}.
$$
Essa notação parece bastante com a $\lambda$-notação que encontramos logo
na~\ref[A_touch_of_lambda], mas é diferente pois na {\thole} aqui precisamos
algo que denota uma afirmação; na notação lambda algo que denota um objeto.
Aqui não vamos usar o descritor definitivo~$\descrsym$,
mas a $\lambda$-notação é importantíssima e ficaremos a usando o tempo todo.
Paciência até~\reftag[A_touch_of_lambda] então.

%%}}}

%%{{{ eg: mother_and_son_function_and_wannabe_example 
\example.
%%%{{{ meta 
\label mother_and_son_function_and_wannabe_example
%%%}}}

\emph{Queremos} definir as funcções $m,s : \pers \to \pers$ pelas equações
$$
\align
m(p) &= \text{a mãe de $p$}\\
s(p) &= \text{o filho de $p$}
\endalign
$$
(onde ``mãe'' significa ``mãe biológica'').
Mas\dots

%%}}}

%%{{{ x: mother_and_son_function_and_wannabe 
\exercise.
%%%{{{ meta 
\label mother_and_son_function_and_wannabe
%%%}}}

Ache o problema no~\ref[mother_and_son_function_and_wannabe_example] acima.

\hint
Lembe-se as condições no~\reftag[functionhood_conditions].

\solution
A funcção $m$ é bem definida, ou seja, é uma funcção mesmo:
\emph{cada pessoa} tem (totalidade) exatamente uma (determinabilidade)
mãe e logo ambas as condições de funccionalidade (\reftag[functionhood_conditions])
são satisfeitas.
No outro lado, a $s$ não satisfaz nenhuma das condições:
tem pessoas sem filhos, e logo a totalidade já era; e também
tem pessoas com mais que um filho, e logo nem determinabilidade
temos.

%%}}}

%%{{{ x: mother_and_son_function_and_wannabe_even_restricting 
\exercise.
%%%{{{ meta 
%%%}}}

Considere o problema do~\ref[mother_and_son_function_and_wannabe_example]
que achaste no~\ref[mother_and_son_function_and_wannabe].
Vamos tentar resolvê-lo restringindo o $\pers$:
em vez do conjunto de todas as pessoas,
$\pers'$ denota o conjunto de todas as pessoas
que possuem exatamente um filho.
Assim garantimos que $s(p)$ é bem definido, pois $s(p)$
é a única pessoa $y$ tal que $y$ é filho de $p$:
e sabemos que tal $y$ existe, e que é único,
pela definição de $\pers'$.
Então para esse conjunto as $m,s$
do~\reftag[mother_and_son_function_and_wannabe]
realmente definam funcções.

\hint
Não.
Em vez de melhorar, a situação piorou:
agora nem $m$ nem $s$ são funcções!

\solution
Não.
O $s(p)$ é a única pessoa $y$ tal que $y$ é filho de $p$
e sim, sabemos que tal $y$ existe e que é único mas\dots
talvez essa pessoa $y$ não possui exatamente um filho,
ou seja, talvez $y \notin \pers'$.
De fato, a situação piorou, pois agora nem a $m$ é funcção,
pelo mesmo motivo: uma pessoa $p$ mesmo tendo exatamente
um filho, a mesma coisa não é garantida para a mãe de $p$,
e logo o $m(p)$ talvez não pertence ao $\pers'$.

%%}}}

%%{{{ x: does it depend on religion? 
\exercise.
%%%{{{ meta 
%%%}}}

Tua resposta dependeu da tua religião?

\hint
Lembre o que $f : A \to B$ significa para cada religião.

\solution
Não: tanto para Conjuntistas quanto para Categoristas
a saida $f(x)$ duma funcção $f : A \to B$ deve
pertence ao $B$.

%%}}}

%%{{{ definition by cases (branching) 
\note Definição por casos (branching).
%%%{{{ meta 
%%%}}}

Às vezes os valores $f(x)$ duma funcção $f$ não seguem o mesmo ``padrão'',
a mesma ``regra'' para todos os $x\in\dom f$.

%%}}}

%%{{{ eg: branching_example_1 
\example.
%%%{{{ meta 
\label branching_example_1
%%%}}}

Seja $f : \reals \to \reals$ definida pela
$$
f(x)
=
\knuthcases {
x^2,     & se $x\in\rats$;\cr
0,       & se $x = \sqrt p$ para algum primo $p$;\cr
2x + 1,  & caso contrário.
}
$$

%%}}}

%%{{{ beware: function_definition_by_cases_mistakes 
\beware.
%%%{{{ meta 
\label function_definition_by_cases_mistakes
%%%}}}

Cada vez que definimos uma funcção por casos, precisamos verificar que:
\elist 1:
\li: contamos para todos os casos possíveis da entrada;
\li: não existe sobreposição inconsistente em nossos casos.
\endelist
Seguem uns exemplos que demonstram esses erros.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Definimos a funcção $f : \nats \to \nats$, pela
$$
f(n) = \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
k, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$.\cr
}
$$
Aqui o problema é que $f$ não foi definida para todo o seu domínio, pois
existem números (por exemplo o $2$) que não satisfazem nenhum dos casos da
definição da $f$.

%%}}}

%%{{{ remark: use of otherwise 
\remark.
%%%{{{ meta 
%%%}}}

Para ter certeza que tomamos cuidado de todos os casos possíveis,
podemos descrever o último caso com um ``otherwise''
(ou ``caso contrário'').
Observe que as funcções $f_1, f_2 : \nats \to \nats$ definidas pelas
$$
\align
f_1(n) &= \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$;\cr
2, & otherwise.\cr
}\\
f_2(n) &= \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & otherwise.\cr
}\\
\endalign
$$
são realmente duas funcções bem-definidas e diferentes.

%%}}}

%%{{{ x: prove that they are different 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que são diferentes!

\solution
Temos
$$
f_1(5) = 2 \neq 5 = f_2(5),
$$
logo $f_1 \neq f_2$.

%%}}}

%%{{{ eg: overlapping_inconsistent_cases 
\example.
%%%{{{ meta 
\label overlapping_inconsistent_cases
%%%}}}

Definimos a funcção $g : \nats \to \nats$, pela
$$
g(n) = \knuthcases {
0,  & se $n$ é primo;\cr
1,  & se $n$ é par;\cr
12, & caso contrário.
}
$$
Aqui o problema é que não determinamos um único valor para cada membro do domínio da $g$.
Por exemplo o $2$, satisfaz os dois primeiros casos da definição acima.
Então $g(2) = 0$, pois $2$ é primo, e também $g(2) = 1$, pois $2$ é par!
Por isso essa $g$ é mal-definida, e não uma funcção.

%%}}}

%%{{{ x: is g a well-defined function? 
\exercise.
%%%{{{ meta 
%%%}}}

A $h : \nats \to \nats$, definida pela
$$
h(n) = \knuthcases {
n+2, & se $n$ é primo;\cr
n^2, & se $n$ é par;\cr
12,  & caso contrário.
}
$$
é uma funcção bem-definida?

\hint
Qual é a sobreposição dos casos que aparecem na definição da $h$ e quais os
valores da $h$ seguindo cada um deles?

\solution
A $h$ realmente é bem-definida, mas isso não é imediatamente óbvio,
pois os dois primeiros casos na sua definição não são distintos,
e os valores que cada um escolhe para a $h$ são aparentemente diferentes.
Para demonstrar que a $h$ é uma funcção bem-definida 
precisamos ver quais são os membros do seu codomínio que satisfazem
mais que um caso (aqui os dois primeiros casos, pois o terceiro é o ``caso contrário'')
e verificar que o valor da $h$ para esses membros são os mesmos, independente
do caso escolhido.
O único número natural que é primo e par e o $2$.
Seguindo o primeiro caso temos
$$
h(2) = 2 + 2 = 4,
$$
e seguindo o segundo caso temos
$$
h(2) = 2^2 = 4.
$$
Logo, a $h$ realmente é uma funcção bem-definida.

%%}}}

%%{{{ remark: compatible cases (cases agree) 
\remark.
%%%{{{ meta 
%%%}}}

Quando dois casos diferentes duma definição de funcção atribuem os mesmos
valores para as mesmas entradas da sua sobreposição comum, dizemos que
são \emph{compatíveis}, ou que \emph{concordam}.

%%}}}

%%{{{ Else-if 
\note Else-if.
%%%{{{ meta 
%%%}}}

Programadores são bastante acostumados com o uso do
``else-if'', e isso é algo que podemos usar definindo funcções por casos.
Alterando a definição da funcção do~\ref[overlapping_inconsistent_cases]
podemos realmente (bem) definir uma funcção $g : \nats \to \nats$ pela
$$
g(n) = \knuthcases {
0,  & se $n$ é primo;\cr
1,  & se não; e se $n$ é par;\cr
12, & caso contrário.
}
$$
Assim, cada caso é necessariamente separado de todos os casos anteriores.
Em programação o múltiplo uso de ``else-if'', é chamado uma
\dterm{if-else-if ladder}.

%%}}}

%%{{{ defining_function_by_formula 
\note Por fórmula.
%%%{{{ meta 
\label defining_function_by_formula
%%%}}}

Outro jeito para definir uma funcção $f : A \to B$, é
determinar completamente quando é que $f(x) = v$,
para todo $x\in A$ e $v \in B$:
$$
f(x) = v \defiff \tubrace {\phi(x,v)} {function-like}.
$$
Onde a fórmula (ou a afirmação) $\phi(x,v)$ deve ser \dterm{function-like}
no $A$, ou seja, $\phi$ é tal que para todo $x\in A$, exatamente um $v \in B$
satisfaz a $\phi(x,v)$.\foot
Pode olhar também na definição formal disso,~\reftag[functionlike].
\toof

%%}}}

%%{{{ x: welldefined_functionlike 
\exercise.
%%%{{{ meta 
\label welldefined_functionlike
%%%}}}

As ``funcções'' abaixo são bem-definidas?
$$
\xalignat2
f &: \reals_{\geq0} \to \reals &
f(x) = y &\defiff y^2 = x \\
g &: \nats \to \nats &
g(x) = y &\defiff y^2 = x \\
h &: \reals \to \reals &
h(x) = y &\defiff \text{$y$ é o maior inteiro que satisfaz $y \leq x$} \\
u &: \ints^2 \to \ints &
u(x,y) = z &\defiff \text{$z$ é primo} \mland z \divides x+y; \\
v &: \ints^2 \to \ints &
v(x,y) = z &\defiff \text{$z$ é o menor primo tal que $z \divides x+y$}.
\endxalignat
$$
Justifique tuas refutações.

\solution
A $f$ não é bem-definida: perdemos a unicidade; pois, por exemplo, como $1^2 = 1 = (-1)^2$, o $f(1)$ fica sem valor unicamente determinado.
\eop
A $g$ não é bem-definida: perdemos a totalidade; pois para o $2\in\nats$
por exemplo, não existe nenhum $y\in\nats$ com $y^2 = 2$.
\eop
A $h$ realmente é bem-definida, conhecida como ``floor''.
\eop
A $u$ não é bem-definida: perdemos a unicidade; por exemplo o
$u(1,5)$ fica sem valor determinado, pois $2$ é primo e $2 \divides 6$ mas $3$ também é primo e $3\divides 6$.
\eop
A $v$ também não é bem-definida: perdemos a totalidade; por exemplo o
$v(0,1)$ fica sem valor nenhum, pois nenhum primo divide o $0+1=1$.

%%}}}

%%{{{ defining_function_by_graph 
\note Por gráfico.
%%%{{{ meta 
\label defining_function_by_graph
%%%}}}

Podemos definir uma funcção $f : A \to B$ se definir qual é o seu
gráfico $\graph f$.  Observe que do gráfico já podemos recuperar
o domínio mas o codomínio não (veja~\reftag[dom_and_cod_recoverable_or_not]).
Então basta so deixar isso claro e pronto.
Claro que precisamos tomar cuidado: o gráfico tem que satisfazer
as condições de ser funcção: totalidade e
determinabilidade~(\ref[functionhood_conditions]).
Olhando apenas para o gráfico, só a determinabilidade pode ser
quebrada.  Mas se o domínio foi especificado separadamente,
precisamos verificar a totalidade também.
(Aqui vamos sempre deixar claro o domínio e o codomínio.)
Seguem uns exemplos.

%%}}}

%%{{{ eg: defining_function_by_graph_eg 
\example.
%%%{{{ meta 
\label defining_function_by_graph_eg
%%%}}}

Sejam $A = \set{0,1,2,3}$ e $f : A \to \nats$ a funcção com gráfico
$$
\graph f = \set{ \tup{0,0}, \tup{1,1}, \tup{2,4}, \tup{3,2} }.
$$
Temos, por exemplo, $f(0) = 0$ e $f(2) = 4$.

%%}}}

%%{{{ x: which_of_the_graphs_define_functions 
\exercise.
%%%{{{ meta 
%%%}}}

Quais dos gráficos abaixo podem ser usados
para definir funcções com codomínio o $\nats$?
Quais os seus domínios recuperados por seus gráficos?
$$
\align
\graph(f) &= \set{ \tup{0,1}, \tup{2,4}, \tup{3,8}, \tup{1,2} } \\
\graph(g) &= \set{ \tup{0,12^{12}} } \\
\graph(h) &= \set{ \tup{0,1}, \tup{1,1}, \tup{0,1}, \tup{8,1}, \tup{3,2} } \\
\graph(k) &= \set{ \tup{\nats,0}, \tup{\ints,0}, \tup{\rats,0}, \tup{\reals,1} } \\
\graph(r) &= \emptyset \\
\graph(s) &= \set{ \tup{0,0}, \tup{1,1}, \tup{2,2^3}, \tup{3,3^{-1}} } \\
\graph(t) &= \set{ \tup{3,0}, \tup{2,0}, \tup{2,1}, \tup{2,7} } \\
\graph(w) &= \set{ \tup{0,0}, \tup{\tup{1,2},2}, \tup{\tup{12,12},2}, \tup{\tup{0,1,0,0},1} }
\endalign
$$

\solution
Temos:
$$
\xalignat2
f &: \set{ 0,1,2,3 } \to \nats &
r &: \emptyset \to \nats \\
g &: \set{ 0 } \to \nats &
s &: \text{não é (range não contido no codomínio)} \\
h &: \set{ 0,1,3,8 } \to \nats &
t &: \text{não é (quebrou determinabilidade)} \\
k &: \set{ \nats,\ints,\rats,\reals } \to \nats &
w &: \set{ 0, \tup{1,2}, \tup{12,12}, \tup{0,1,0,0} } \to \nats
\endxalignat
$$

%%}}}

%%{{{ defining_function_by_drawing 
\note Por desenho.
%%%{{{ meta 
\label defining_function_by_drawing
%%%}}}

Conhecemos no~\ref[Internal_and_external_diagrams] dois tipos
de diagramas relacionados a funcções: internos e externos.
Lá observamos que desenhando o diagrama \emph{interno} já temos
determinado tudo que precisamos determinar para definir uma funcção
(\ref[names_of_elements]).
O que deve te deixar surpreso é que usando certos diagramas \emph{externos}
podemos \emph{definir} sim funcções muito interessantes e importantes em
muitos casos!
(Faremos isso bastante no~\ref[Category_theory].)
Isso \emph{deve} mesmo ser algo dificilmente aceitável neste momento:
se tu estiveres com dúvidas estás no caminho certo:
\wq{Como assim determinou uma funcção pelo diagrama externo?
Lá só tem domínio e codomínio!  Qual o comportamento da tua funcção?}
Calma:
é porque não conhecemos ainda o poder---nem a beleza,
nem a elegância---dos diagramas comutativos,
que encontraremos logo na \ref[Commutative_diagrams].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ainda não encontramos a notação mais interessante para definir funcções.
Vamos estudá-la logo; ela merece uma secção própria (\ref[A_touch_of_lambda]).
Antes disso, vamos ver mais uma maneira de definir funcções: com buracos!

%%}}}

\endsection
%%}}}

%%{{{ Empty (co)domains 
\section (Co)domínios vazios.
%%%{{{ meta 
%%%}}}

%%{{{ x: f_from_A_to_emptyset 
\exercise.
%%%{{{ meta 
\label f_from_A_to_emptyset
%%%}}}

Seja $f : A \to \emptyset$.
O que podemos concluir sobre o $A$?
Quantas funcções têm esse tipo?

\hint
O que significa ser funcção?

\solution
$A=\emptyset$, pois, caso contrário, pegando um $a\in A$,
chegamos na contradição $f(a) \in \emptyset$.
Quantas funcções $f$ têm esse tipo?
Vamos resolver isso logo: veja~\ref[emptyfun] e~\ref[a_or_the_emptyfun].

%%}}}

%%{{{ x: f_from_emptyset_to_A 
\exercise.
%%%{{{ meta 
\label f_from_emptyset_to_A
%%%}}}

Seja $f : \emptyset \to A$.
O que podemos concluir sobre o $A$?
Quantas funcções têm esse tipo?

%%}}}

%%{{{ df: emptyfun 
\definition Funcção vazia.
%%%{{{ meta 
\label emptyfun
\indexes
    * vazia!funcção    see: funcção
    ;;
\defines
    * funcção!vazia
    ;;
%%%}}}

Uma funcção $f$ com $\dom f = \emptyset$ é chamada \dterm{funcção vazia}.

%%}}}

%%{{{ x: a_or_the_emptyfun 
\exercise.
%%%{{{ meta 
\label a_or_the_emptyfun
%%%}}}

<<Uma>> ou <<a>>?

\solution
\proofpart{Para o conjuntista:} <<a>> mesmo!
Pois, tome $f,g$ funcções vazias.
Logo $f : \emptyset \to A$ e $g : \emptyset \to B$
para alguns conjuntos $A,B$.
Vacuamente temos que para todo $x\in \emptyset$, $f(x) = g(x)$.
\crproofpart{Para o categorista:} para cada conjunto $A$,
temos exatamente uma funcção vazia com codomínio $A$.

%%}}}

%%{{{ remark: emptyfun_is_not_strange 
\remark.
%%%{{{ meta 
\label emptyfun_is_not_strange
%%%}}}

Com tudo que o leitor tem visto até agora a \ref[emptyfun] não deve aparecer nada estranha.
Caso contrário---talvez tu pulou diretamente pra cá?---pense na maneira seguinte:
Já determinamos o domínio da funcção: é o $\emptyset$.
O que falta fazer para ter o direito de falar que definimos uma funcção?
Sendo conjuntista, basta determinar para cada um dos membros do domínio seu valor.
Se o domínio tivesse três membros, por exemplo se fosse o $\set{1,2,3}$, bastaria
definir as
$$
\align
f(1) &= \askdots \\
f(2) &= \askdots \\
f(3) &= \askdots
\endalign
$$
Mas agora o domínio tem zero membros, então temos zero valores para determinar,
e vamos fazer isso com uma equação para cada um deles mesmo.
Aqui, então, minhas zero equações:
$$
~
$$
Pronto, defini minha funcção.
(Lembrou da 0-tupla (\reftag[zero_tuple]), né?)
E se eu fosse categorista, teria mais um trabalho
para fazer: determinar o seu codomínio (\reftag[a_or_the_emptyfun]).

%%}}}

\endsection
%%}}}

%%{{{ Holed_expressions 
\section Expressões com buracos.
%%%{{{ meta 
\label Holed_expressions
%%%}}}

%%{{{ What is a holed expression? 
\note O que é uma expressão com buraco?.
%%%{{{ meta 
\indexes
    * buraco    seealso: funcção
    ;;
\defines
    * buraco
    ;;
%%%}}}

Podemos criar uma funcção através duma expressão,
escolhendo um dos objetos que aparecem nela e o substituindo por um \dterm{buraco}.
Criamos assim \emph{aquela funcção} que recebendo um argumento,
retorna a expressão criada botando sua entrada no buraco da expressão.
Usamos $\bhole$, $\dhole$, e $\_$, para denotar esses buracos.

%%}}}

%%{{{ eg: holed_expression 
\example.
%%%{{{ meta 
\label holed_expression
%%%}}}

Considere a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Qual o tipo dela?
Ela denota um número real, ou seja,}
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals.
\intertext{Escolhemos um objeto nela e botamos um buraco no seu lugar:}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Assim criamos uma funcção.
Qual o tipo dela?
Para decidir o domínio dela, olhamos para o tipo do objeto
substituido por esse buraco.  Nesse caso, consideramos $1 : \reals$, então
temos}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5) &: \reals \to \reals
\intertext{
Uma outra opção seria escolher o $2$ no $5\cbrt2$, ou até o próprio $5\cbrt2$,
criando assim a funcção}
\cos(1 + \bhole)^{2a} + \sin(5) &: \reals \to \reals
\endalign
$$
do mesmo tipo.

%%}}}

%%{{{ more than one hole 
\blah.
%%%{{{ meta 
%%%}}}

Podemos botar mais que um buraco na mesma expressão,
assim criando funcções de aridades maiores.
Seguimos a convenção que os seus argumentos são botados
nos buracos que aparecem na ordem de esquerda para direita,
e de cima pra baixo.

%%}}}

%%{{{ eg: holed_expression_many 
\example.
%%%{{{ meta 
\label holed_expression_many
%%%}}}

Considere de novo a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals,
\intertext{mas agora bote os buracos}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&.
\intertext{Qual o tipo dessa funcção?
Cada um dos buracos está esperando receber um real,
ou seja:}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&:\reals^3\to\reals
\intertext{Uma outra opção seria criar a funcção}
\cos(1 + \bhole\cbrt\bhole)^{\bhole a} + \sin(\bhole) &: \reals^4 \to \reals,
\endalign
$$
etc.

%%}}}

%%{{{ x: calculate_holes 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule:
\elist a:
\li: $(2 + \bhole)(40)$;
\li: $(\bhole + 2\bhole)(2,4)$;
\li: $(\dhole \ntimes 2^{\dhole})(3,0)$;
\li: $(\set{1,2,3} \union \dhole)(\set{2,8})$.
\endelist

\solution
Calculamos:
$$
\align
(2 + \bhole)(40) &= 2 + 40 = 42 \\
(\bhole + 2\bhole)(2,4) &= 2 + 2^4 = 18 \\
(\dhole \ntimes 2^{\dhole})(3,0) &= 3 \ntimes 2^0 = 3 \\
(\set{1,2,3} \union \dhole)(\set{2,8}) &= \set{1,2,3} \union \set{2,8} = \set{1,2,3,8}
\endalign
$$

%%}}}

%%{{{ remark: fractions and the symbol of division 
\remark.
%%%{{{ meta 
%%%}}}

Da expressão
$$
\frac 1 2 : \rats
$$
podemos criar as funcções
$$
\xalignat3
\frac {\bhole} 2 & : \ints \to \rats &
\frac 1 {\bhole} & : \ints_{\neq0} \to \rats &
\frac {\bhole} {\bhole} & : \ints\times\ints_{\neq0} \to \rats
\endxalignat
$$
Agora o símbolo $\div$ da operação binária de divisão que aparece nos calculadores
talvez faz mas sentido, né?

%%}}}

%%{{{ Limitations 
\note Limitações.
%%%{{{ meta 
%%%}}}

Para um uso simples e rápido as expressões com buracos oferecem uma
ferramenta muito útil.  Mas, temos umas limitações importantes:
\elist a:
\li:
Não podemos ``ligar'' dois ou mais buracos para representar
a idéia que o mesmo argumento vai ser copiado em todos eles.
\li:
Não podemos escolher a órdem que os argumentos da funcção
criada vão preencher os buracos.
\endelist
Finalmente vamos estudar a notação lambda e com ela vamos
superar essas limitações facilmente!

%%}}}

\endsection
%%}}}

%%{{{ A_touch_of_lambda 
\section Um toque de lambda.
%%%{{{ meta 
\label A_touch_of_lambda
%%%}}}

%%{{{ Useless namings 
\note Nomeamentos inúteis.
%%%{{{ meta 
\label useless_namings
%%%}}}

Imagine que precisamos identificar uma certa funcção dum conjunto
$A$ prum conjunto $B$, e depois de muitos cálculos e usando várias
outras funcções e objetos dados pelo nosso problema,
concluimos com a frase:
\emph{<<\dots a funcção desejada é aquela funcção que recebendo
como entrada um número $x$, ela retorna o $2x+5$.>>}.
Vamos isolar esta subfrase:
$$
\text{aquela funcção que recebendo como entrada um $x$, retorna o \thole$x$\thole}.
$$
O que ela denota?
Claramente uma funcção.
Mas qual é o \emph{nome} dessa funcção?
Pois é, ela não tem.
É uma funcção \emph{anônima}.
Isso talvez parece estranho, mas acontece o tempo todo com outros tipos
de objetos matemáticos, por exemplo com números.
Suponha que temos um triângulo com base $b$ e altura $h$.
Falamos
$$
\textwq{a área do triângulo é $bh/2$}
$$
sem nenhuma obrigação de nomear essa área com um nome para usá-la;
e ninguém reclama.
Se tivessimos essa obrigação deveriamos falar:
$$
\textwq{\dots seja $a = bh/2$.  A área do triângulo é $a$.}
$$
Claramente isso é inútil.
Introduzimos um novo nome apenas para usá-lo logo após e nunca mais.
Em nossa última frase ``a área do triângulo é $a$'', a informação
nem é mais visível.  O leitor vai ter que lembrar qual foi a definição desse $a$,
ou ir procurar achá-la.
Obviamente a abordagem anterior é melhor.
Com ela podemos enunciar nossa proposição numa maneira melhor:
$$
\textwq{a área dum triângulo com base $b$ e altura $h$ é $bh/2$}
$$
em vez de falar algo do tipo
$$
\textwq{a área dum triângulo com base $b$ e altura $h$ é $a$, onde $a = bh/2$.}
$$
\eop
Para usar um exemplo de ``nomeamento inútil'' em programação,
considere as funcções seguintes em \indexed[Python]Python
cada uma programada por um programador diferente:
\sourcecode uselessnaming.py;
Como funcções são iguais, mas o programador que programou $\code{g}$,
fez algo estranho.
Decidiu nomear a expressão $\code{2 * x + 1}$ com o nome $\code{r}$,
e a única coisa que ele fez com esse $\code{r}$, foi returnar seu
valor.  Pra quê isso, programador?

%%}}}

%%{{{ from_words_to_lambda 
\note De palavras para lambda.
%%%{{{ meta 
\label from_words_to_lambda
\defines
    * funcção!epônima
    * funcção!anônima
    ;;
%%%}}}

Voltamos na frase
$$
\text{``aquela funcção que recebendo como entrada um $x$,
retorna o \thole$x$\thole''}
$$
onde \sq{\thole$x$\thole} é uma expressão que determina um único objeto e que,
possivelmente depende (refere) no $x$, como aconteceu por exemplo com o $2x+5$ acima.
Se essa frase realmente determina uma funcção, então podemos também
definir uma funcção \dterm{epônima} (``com nome'') quando desejamos,
escrevendo:
$$
\gather
\text{<<Seja $f : A \to B$ tal que}\\
\text{$f \defeq \text{aquela funcção que recebendo\dots}$>>}.
\endgather
$$
Mas escrever tudo isso toda vez que queremos ``construir'' uma funcção anônima
é muito chato.  Bem vindo $\lambda$ (lambda) da notação de
$\lambda$-calculus~(\ref[Lambda_calculus])!
Escrevemos apenas
$$
\lam x {2x+5}
$$
para a frase:
$$
\mobraceleg {\text{aquela funcção que recebendo como entrada um}} {\lambda}~~x~~\mobraceleg {\text{retorna o}} {.}~~2x+5.
$$

%%}}}

%%{{{ df: lambda_abstraction 
\definition lambda abstracção.
%%%{{{ meta 
\label lambda_abstraction
\defines
    * \lam {~x} {~{\thole}}  -- $\lambda$-abstracção
    * $\lambda$-abstracção
    * $\lambda$-abstracção!corpo
    ;;
%%%}}}

A expressão
$$
\lam x {\text{\thole$x$\thole}}
$$
é chamada \dterm{$\lambda$-abstracção} e \emph{denota uma funcção}:
$$
\text{``aquela funcção que recebendo como entrada um $x$,
retorna o \thole$x$\thole''}
$$
Supomos aqui que o domínio e codomínio são claros pelo contexto.
Chamamos a parte ``\thole$x$\thole'' o \dterm{corpo} da abstracção.

%%}}}

%%{{{ df: barred arrow 
\definition.
%%%{{{ meta 
\label mapsto
\defines
    * (~x \mapsto ~\thole)  -- funcção anônima
    * setinha barrada
    ;;
%%%}}}

Uma notação diferente usada em matemática para criar funcções anônimas
utiliza a \dterm{setinha barrada} \symq{$\mapsto$}:
$$
\text{escrevemos}\qquad
(x \mapsto \thole)
\qqtext{como sinônimo de}
\lam x {\thole}.
$$

%%}}}

%%{{{ remark: we won't use mapsto, we'll use lambdas instead 
\remark.
%%%{{{ meta 
%%%}}}

Não vamos usar muito a notação $(x \mapsto \thole)$.
Pois a notação $\lam x {\thole}$ serve bem melhor para a maioria dos nossos usos.

%%}}}

%%{{{ remark: variables_and_binding_in_lambda 
\remark.
%%%{{{ meta 
\label variables_and_binding_in_lambda
\indexes
    * ligador!de variável
    ;;
\defines
    * ligador!lambda
    ;;
%%%}}}

O $\lambda$ é um \emph{ligador de variável}.
Todos os $x$ que aparecem livres no {\thole$x$\thole}
viram ligados com o $\alert x$ do $\lambda \alert x$.
Naturalmente consideramos funcções que são diferentes apenas nos
nomes das variáveis ligadas como iguais.
Por exemplo:
$$
\lam x x = \lam y y.
$$
Compare com programação onde uma troca \emph{com cuidado} de variáveis
resulta em programas e procedimentos equivalêntes.
Precisamos tomar os mesmos cuidados aqui, e deixamos os
detalhes formais para o~\ref[Lambda_calculus].

%%}}}

%%{{{ remark: comparison with set builder 
\remark Comparação com set builder.
%%%{{{ meta 
%%%}}}

Num certo sentido o papel de $\lam x {\thole}$ é parecido com o papel
do $\setst x {\thole}$.  O set builder construe conjuntos (anônimos),
e o $\lambda$ parece então um ``function builder'' que construe funcções
(anônimas).

%%}}}

%%{{{ Is it functions that we are really constructing? 
\warning Construimos funcções mesmo?.
%%%{{{ meta 
%%%}}}

É ``forte demais'' afirmar que a expressão $\lam x {x^2}$ determina
uma funcção.  Qual é o seu domínio?  E o categorista vai perguntar também
sobre seu codomínio.
Sem essa informação faz mais sentido considerar que um termo como o $\lam x {x^2}$
corresponde numa \emph{alma}, ou seja, \emph{um comportamento} que em geral
pode ``animar o corpo'' de várias funcções.\foot
Aqui tô usando a palavra \wq{corpo} numa maneira mais antropomórfica,
e nesse caso corresponde num \emph{tipo} de funcção, que tá esperando
uma \emph{alma para habitá-lo}.
Quando pegamos emprestada a terminologia de programação a mesma palavra
\wq{corpo} acaba significando algo diferente:
aí, o corpo duma ``funcção'' seria o código que
determina o seu comportamento.
\toof
Se as informações de domínio (e codomínio dependendo da fé) não estão
claras pelo contexto escrevemos o tipo logo após da $\lambda$-expressão
para realmente determinar uma funcção.
Podemos ``tipar'' o termo $\lam x {x^2}$ então
$$
\xalignat3
\lam x {x^2} & \eqtype \reals\to\reals &
\lam x {x^2} & \eqtype \nats\to\nats &
\lam x {x^2} & \eqtype \set{0}\to\nats
\endxalignat
$$
etc., e agora sim cada uma dessas determina mesmo uma funcção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então:
o $\lambda$ nos permite criar funcções anônimas numa maneira simples e útil.
E o que podemos fazer com uma expressão dessas?
\emph{Tudo} que podemos fazer com uma funcção!

%%}}}

%%{{{ eg: applying an anonymous function to an argument 
\example.
%%%{{{ meta 
%%%}}}

Calculamos:
$$
\align
\plam x {2x+5} (4) &= 2\ntimes 4 + 5 = 13 \\
\plam x x (2)      &= 2.
\endalign
$$
Em geral omitimos as parenteses no argumento, escrevendo:
$$
\plam x {2x+5} \lapp 4, \qquad
\plam x x \lapp 2, \qquad
\text{etc.},
$$
algo que acontece com funcções epônimas também
(veja~\ref[function_notation]).

%%}}}

%%{{{ dot-till-end convention 
\note Convenção.
%%%{{{ meta 
%%%}}}

Para evitar uso excessivo de parenteses, acordamos que o corpo duma
$\lambda$-abstracção estende o maior possível, por exemplo:
$$
\plam x {x + y + z}
\qqtext{significa}
\plam x {\paren{x + y + z}}.
$$

%%}}}

%%{{{ The soul of λ-computation 
\note A alma da λ-computação.
%%%{{{ meta 
%%%}}}

Assim que aparecer uma coisa $\heart$ no lado duma
$\lambda$-abstracção $\plam x {\dotswithsome x}$
temos uma expressão \dterm{reductível} (chamada \dterm{redex})
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \lapp \heart
$$
ou seja, podemos fazer um passo computacional:
\emph{substituir o redex inteiro por uma nova expressão
criada substituindo todas as instâncias livres de $x$ no $\tau(x)$
por $\heart$, chegando assim no $\tau(\heart)$}.
Denotando esse passo com um \symq{$\lamstep$}, temos então
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \lapp \heart
\lamstep
\mubrace {\dotswithsome \heart} {\tau(\heart)}.
$$

%%}}}

%%{{{ eg: calculate lambda reduction 
\example.
%%%{{{ meta 
%%%}}}

Calcule a expressão:
$$
\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50.
$$
\solution.
Procuramos achar \emph{redexes} e achamos dois:
$$
\xalignat2
&\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50} &
&\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50.
\endxalignat
$$
Então temos dois caminhos diferentes para seguir.
Vamos tentar ambos:
$$
\align
\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50}
&\lstep 2 + \redex {\plam y {50 - y} \lapp 8} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\intertext{%
Escolhendo o outro caminho, talvez chegamos em algum valor
diferente.
Vamos ver:
}
\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50
&\lstep \redex {\plam x {2 + \paren{x - 8}} \lapp 50} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\endalign
$$
Interessante.
Chegamos no mesmo valor.
Mas talvez foi coincidência.

%%}}}

%%{{{ Church--Rosser: No it wasn't 
\note Church--Rosser: <<Foi não>>.
%%%{{{ meta 
%%%}}}

{\Church[teorema Church--Rosser]}%
{\Rosser[teorema Church--Rosser]}%
Graças ao teorema Church--Rosser que vamos estudar no~\ref[Lambda_calculus]
sabemos que se existem dois caminhos que chegam em dois valores ``finais'',
não podem ser valores diferentes.
Isso não quis dizer que as escolhas não importam,
pois pode ser que um caminho nem termine!
Mas se dois caminhos realmente chegarem em valores finais mesmo,
então chegaram no mesmo valor!\foot
Essa é uma grande hipersimplificação do teorema de Church--Rosser;
para a versão ``raiz'', paciência até o~\ref[Lambda_calculus].
\toof

%%}}}

%%{{{ x: calculate_lambda_expressions 
\exercise.
%%%{{{ meta 
\label calculate_lambda_expressions
%%%}}}

Calcule os seguintes:
% TODO: fix reflabs
\elist a:
\li: $\plam x x \la 5$;
\li: $\plam y {42} \la 5$;
\li: $\plam z x \la 5$;
\li: $\plam x {x+1} \la 41$;
\li: $\plam x {2 + \plam y {3y} \la 5} \la 3$;
\li: $\plam x {2 + \plam y {3y} \lap {x^2} } \la 3$;
\li: $\plam x {2 + \plam y {xy} \la 4 } \la 3$;
\li: $\lam x {\plam x {x + 1} \la 1 \ntimes \plam y {xy} \la 4}$. % <- cited as "last"
\endelist
Em cada passo, sublinhe o redex que tu escolheu para reduzir.
Não se preocupe se uns deles parecem errados ou bizarros,
nem se tu errar calculando uns deles; mas verifique tuas respostas.

\solution
Calculamos:
$$
\align
\redex {\plam x x \la 5}      &\lstep 5 \\
\redex {\plam y {42} \la 5}   &\lstep 42 \\
\redex {\plam z x \la 5}      &\lstep x \\
\redex {\plam x {x+1} \la 41} &\lstep 41 + 1 \\
&\isteq 42 \\
\redex {\plam x {2 + \plam y {3y} \la 5} \la 3}
&\lstep 2 + \redex{\plam y {3y} \la 5} \\
&\lstep 2 + 3\ntimes 5 \\
&\isteq 17 \\
\redex {\plam x {2 + \plam y {3y} (x^2)} \la 3}
&\lstep 2 + \redex {\plam y {3y} \lap {3^2}} \\
&\lstep 2 + 3 \ntimes 3^2 \\
&\isteq 29 \\
\plam x {2 + \redex {\plam y {xy} \la 4}} \la 3
&\lstep \redex {\plam x {2 + x\ntimes 4} \la 3} \\
&\lstep 2 + 3 \ntimes 4 \\
&\isteq 14 \\
\lam x {\plam x {x + 1} \la 1 \ntimes \redex {\plam y {xy} \la 4}}
&\lstep \lam x {\redex {\plam x {x + 1} \la 1} \ntimes x\ntimes 4} \\
&\lstep \lam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \lam x {8x}.
\endalign
$$
Se o último cálculo parece insatisfatório, é apenas
por causa de um preconceito teu que favorece os objetos
de tipo ``número'' contra os objetos de tipo ``funcção''.
Mais sobre isso no~\ref[first_class_citizens].

%%}}}

%%{{{ x: find_expressions_with_given_types_abstract 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_abstract
%%%}}}

Quando puder, escreva $\lambda$-expressões que podem ser
tipadas com os tipos seguintes:
$$
\xalignat2
&\aligned
&: A \to A \\
&: A\cross B \to A \\
&: A\cross B \to B \\
&: A\cross A \to A \\
&: A \to A \cross A \\
&: A \to A \cross B
\endaligned
&
&\aligned
&: A \cross B \to B \cross A \\
&: A \union B \to A \\
&: A \to A \union B \\
&: A \cross B \to A \union B \\
&: A \union B \to A \cross B \\
&: \paren{\pfcross A B \union \pfcross C D} \to \pfcross {(A \union C)} {(B \union D)}.
\endaligned
\endxalignat
$$
Observe que sobre os $A,B$ tu não tens nenhuma informação.
Pode achar mais que uma resolução para algum desses desafios?

%%}}}

%%{{{ x: find_expressions_with_given_types 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types
%%%}}}

Escreva $\lambda$-expressões que podem ser tipadas com os tipos seguintes:
$$
\align
&: \nats \to \nats \\
&: \nats^2 \to \nats \\
&: \nats \to \nats^2 \\
&: \pset\nats\setminus\set{\emptyset} \to \nats \\
&: \pset\nats \to \nats \\
&: \psetfin\nats \to \nats.
\endalign
$$
Tente usar o argumento no corpo dos teus $\lambda$-termos se puder.

%%}}}

%%{{{ x: eta_conversion_first_encounter 
\exercise.
%%%{{{ meta 
\label eta_conversion_first_encounter
%%%}}}

Seja $f : A \to B$.
Qual nome tu daria para a funcção $\lam x {f \app x}$?
Lembre-se que graças as convenções notacionais essa expressão é a mesma com a
$\lamp x {f(x)}$.

\hint
Como a funcção $\lam x {f \app x}$ comporta?

\solution
$f$.

%%}}}

%%{{{ β-reduction 
\note β-reducção.
%%%{{{ meta 
%%%}}}

O nome real desse passo computacional de $\lambda$-cálculo que encontramos
aqui é \dterm{$\beta$-reducção}, e o redex é formalmente chamado um
\dterm{$\beta$-redex}.
Para enfatisar quando for necessário escrevemos \symq{$\betastep$} para denotar
um passo de $\beta$-reducção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tem mais duas regras de $\lambda$-computação:
$\alpha$-renomeamento e $\eta$-conversão.

%%}}}

%%{{{ α-renaming 
\note α-renomeamento.
%%%{{{ meta 
%%%}}}

O princípio que nos permite identificar como equivalentes as $\lambda$-expressões
que diferem apenas nas escolhas das suas variáveis ligadas é chamado
\dterm{$\alpha$-renomeamento} ou \dterm{$\alpha$-conversão} ou
\dterm{$\alpha$-equivalência}.
Podemos considerar cada $\lambda$-abstracção um \dterm{$\alpha$-redex};
denotamos por \symq{$\alphastep$} um passo onde aconteceu um $\alpha$-renomeamento.

%%}}}

%%{{{ eg: alpharename_code 
\example em programação.
%%%{{{ meta 
\label alpharename_code
%%%}}}

Considere o código seguinte:
\sourcecode alpharename1.py;
Aqui parece que o $\code{z}$ é uma variável já declarada e definida
no escopo exterior.
Deve ser óbvio que podemos trocar a variável $\code{x}$ por
qualquer variável que não aparece livre no corpo da $\code{f}$.
Escolhendo trocá-la por $\code{y}$, por exemplo, chegamos na funcção
equivalente:
\sourcecode alpharename2.py;
onde semanticamente nada mudou no nosso programa.
Mas seria errado ter escolhido a $\code{z}$, pois ela capturaria
a antes-livre $\code{z}$ do corpo da $\code{f}$:
\sourcecode alpharename3.py;
Isso não é mais o mesmo programa.
Antes a funcção $\code{f}$ poderia ser descrita como
\standout
<<a funcção que retorna o produto da sua entrada com $z$>>;
\endstandout
uma descripção que serve para qualquer um dos dois primeiros programas.
Observe que não usei nem \symq{$x$} nem \symq{$y$} nessa frase,
mas não teria como descrevé-la sem usar a \symq{$z$}.
Já a terceira funcção seria
\standout
<<a funcção que retorna o quadrado da sua entrada>>;
\endstandout
algo claramente diferente.

%%}}}

%%{{{ eg: alpharename_sets 
\example em conjuntos.
%%%{{{ meta 
\label alpharename_sets
\indexes
    * variável!capturada
    ;;
%%%}}}

Considere o conjunto seguinte:
$$
\setst x {x < z^2}.
$$
Obviamente podemos trocar o \symq{$x$} por qualquer variável que não aparece
livre no filtro \symq{$x < z^2$}, por exemplo por \symq{$y$}:
$$
\setst x {x < z^2}
\inteq
\setst y {y < z^2};
$$
mas não poderiamos ter escolhido substituir o \symq{$x$} por \symq{$z$},
pois assim aconteceria \emph{captura de variável}
(já discutimos isso no~\ref[variable_capturing_in_set_builder]).

%%}}}

%%{{{ η-conversion 
\note η-conversão.
%%%{{{ meta 
%%%}}}

Essa é a idéia de \emph{extensionalidade} para o sistema:
se duas expressões comportam na mesma maneira, as consideramos equivalentes.
Qualquer expressão da forma $\lam x {f \app x}$ é um \dterm{$\eta$-redex},
e denotamos por \symq{$\etastep$} o passo onde o substituimos por $f$.

%%}}}

%%{{{ pic: η-wrapping 
\note η-wrapping desenhado.
%%%{{{ meta 
%%%}}}

Começa com uma funcção $g$; agora pega um embrulho preto e embrulhe;
e pronto, tu criou uma ``nova'' funcção.
Só que não é tão nova né?
Talvez tu vai rotulá-la como $f$ ou talvez vai escolher um rótulo
mais honesto, como $\lam x {g \app x}$.
$$
\xalignat3
&\tikzpicture
\tikzi blackboxfuneta0;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta1;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta2;
\endtikzpicture
\endxalignat
$$
A $\eta$-conversão nos permite identificar as duas caixas acima.

%%}}}

%%{{{ eg: etawrap_code 
\example em programação.
%%%{{{ meta 
\label etawrap_code
%%%}}}

Considere o código seguinte, que corresponde no desenho acima:
\sourcecode etawrap.py;
Deve ser óbvio que essa $\code{f}$, como funcção,
comporta na mesma maneira que a $\code{g}$.

%%}}}

%%{{{ x: etawrap_sets 
\exercise em conjuntos.
%%%{{{ meta 
\label etawrap_sets
%%%}}}

Qual seria o equivalente de $\eta$-conversão para os conjuntos?

\solution
$A = \setst x {x \in A}$.

%%}}}

%%{{{ eg: alpha beta eta steps 
\example.
%%%{{{ meta 
%%%}}}

Computamos a mesma expressão usando dois caminhos diferentes:
$$
\xalignat2
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\estep \redex {\plam y {y^2}} \lapp 3 \\
&\astep \redex {\plam x {x^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
&
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\astep \redex {\plam y {\plam y {y^2} \lapp y}} \lapp 3 \\
&\estep \redex {\plam y {y^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
\endxalignat
$$
Observe que provavelmente nenhum humano sano escolheria esse
$\alpha$-renomeamento no segundo caminho, pois a expressão
piorou para nossos olhos humanos; aqui escolhi proceder assim
para enfatizar que não tem nada (literalmente) errado nisso.

%%}}}

\endsection
%%}}}

%%{{{ Implementations_seq_fam 
\section Novas implementações: seqüências e famílias.
%%%{{{ meta 
\label Implementations_seq_fam
%%%}}}

%%{{{ Q: Can you implement sequences and indexed families? 
\question.
%%%{{{ meta 
%%%}}}

Suponha que alguém robou de ti os tipos (primitivos) de seqüências
e de famílias indexadas.  Dá para se virar sem esses?
Ou seja, tem como defini-los em termos dos outros tipos
que tu (ainda) tens?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Agora que temos funcções, podemos apreciar
que qualquer seqüência $\seqn a n$
\emph{pode ser representada por uma funcção} com domínio $\nats$
e codomínio o conjunto de todos os membros da $\seqn a n$.
Similarmente, uma família $\famst {a_i} {i \in \cal I}$
indexada por um conjunto $\cal I$ \emph{pode ser representada por uma funcção}
com domínio $\cal I$ e codomínio o conjunto de todos os membros
da $\family {a_i} i$.

%%}}}

%%{{{ imp: sequences_as_functions 
\implementation Seqüências como funcções.
%%%{{{ meta 
\label sequences_as_functions
%%%}}}

Chamamos qualquer $a : \nats \to A$
de \dterm{seqüência}.
Introduzimos como açúcar sintáctico o
$$
a_n \sugeq a(n).
$$
Com essa definição, quando duas \emph{seqüências} são iguais?
Elas precisam concordar em cada $n \in \dom a$;
e essa implementação atende a especificação pois concorda com
a definição de igualdade do tipo que estamos implementando
(\ref[sequences_equality]).

%%}}}

%%{{{ imp: indexed_families_as_functions 
\implementation Famílias indexadas como funcções.
%%%{{{ meta 
\label indexed_families_as_functions
%%%}}}

Chamamos qualquer $a : \cal I \to A$.
de \dterm{família indexada por $\cal I$}.
Introduzimos como açúcar sintáctico o
$$
a_i \sugeq a(i).
$$
Com essa definição, quando duas \emph{famílias} indexadas são iguais?
Os conjuntos de índices têm que ser iguais, e as famílias precisam
concordar em cada índice.
Essa implementação atende a especificação pois concorda com
a definição de igualdade do tipo que estamos implementando
(\ref[indexed_families_equality]).

%%}}}

%%{{{ x: implement_tuples 
\exercise.
%%%{{{ meta 
%%%}}}

Implemente as tuplas;
tome cuidado para deixar claro como usá-las;
lembre-se o que elaboramos nas secções~\reftag[Tuples],
\reftag[Cartesian_product], \reftag[Type_implementation_triples],
e~\reftag[More_tuples].

%%}}}

%%{{{ x: implement_multisets 
\exercise.
%%%{{{ meta 
\label implement_multisets
%%%}}}

Implemente os multiset (\reftag[Multisets]);
tome cuidado para deixar claro como usá-las;
lembre-se o~\reftag[multiset_equality].

%%}}}

%%{{{ df: indexed_sets_adult_version 
\definition Conjuntos indexados: versão adulta.
%%%{{{ meta 
\label indexed_sets_adult_version
\defines
    * conjunto!indexado por conjunto
    ;;
%%%}}}

Já conhecemos o quesignifica que um conjunto $A$ é indexado
por um conjunto $B$~(\ref[indexed_set]).
Isso praticamente quis dizer que o $A$ pode ser escrito na forma
$$
A = \setst {\dots b \dots} {b \in B},
$$
ou, mais ``adultamente'' e plenamente:
$$
\text{$A$ é indexado por $B$}
\defiff
\text{existe funcção sobrejetora $f : B \surto A$}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Composition 
\section Composição.
%%%{{{ meta 
\label Composition
%%%}}}

%%{{{ Composition with black boxes 
\note Composição com black boxes.
%%%{{{ meta 
%%%}}}

Suponha que temos uma configuração de conjuntos e funcções assim:
$$
A \toby f B \toby g C.
$$
Note então que a saída da $f$ pode ser usada como entrada para
a $g$:
$$
\tikzpicture
\tikzi blackboxfuncomp1;
\endtikzpicture
$$
Podemos criar um novo black box, conectando os ``cabos'' assim:
$$
\tikzpicture
\tikzi blackboxfuncomp2;
\endtikzpicture
$$
Pintamos preta essa construção, botando os rótulos certos
de domínio e codomínio, e pronto:
$$
\tikzpicture
\tikzi blackboxfuncomp3;
\endtikzpicture
$$
Criamos assim a composição $g\of f$ das funcções $f$ e $g$.
Formalmente, chegamos na definição seguinte.

%%}}}

%%{{{ df: fcompose 
\definition.
%%%{{{ meta 
\label fcompose
\indexes
    * composição!de funcções    see: funcção
    ;;
\defines
    * funcção!composição
    ;;
%%%}}}

Sejam
$A \toby f B \toby g C$.
Definimos a funcção $g\of f : A\to C$ pela
$$
\paren{g\of f}(x) \defeq g\paren{f(x)}.
$$
Assim temos
$$
\xalignat2
\dom (g\of f) &= \dom f &
\cod (g\of f) &= \cod g.
\endxalignat
$$
Chamamos a $g\of f$ a \dterm{composição} da $g$ com $f$.
Pronunciamos a $g\of f$ também como:
\utter{$g$ seguindo $f$},
\utter{$g$ after $f$},
ou até \wq{$g$ de $f$}.

%%}}}

%%{{{ beware: diagrammatic_notation 
\beware.
%%%{{{ meta 
\label diagrammatic_notation
\indexes
    * diagramática            see: composição
    * notação!diagramática    see: composição
    ;;
\defines
    * ~f \dcom ~g  -- composição escrita na ordem diagramática
    * composição!diagramática
    ;;
%%%}}}

Escrevemos $g\of f$ e não $f\of g$ para a composição na~\ref[fcompose]!
Então quando temos $A\toby f B\toby g C$, a composição é
$A \toby {g\of f} C$, que parece o oposto da ordem das setinhas.
Definimos a notação alternativa
$$
f \dcom g \sugeq g\of f,
$$
chamada \dterm{notação diagramática}
pois concorda com a posição das setinhas do diagrama:
$$
A \toby {f \dcom g} C.
$$
Mas vamos principalmente usar a notação $g\of f$ mesmo.

%%}}}

%%{{{ x: when_is_fog_defined 
\exercise.
%%%{{{ meta 
\label when_is_fog_defined
%%%}}}

Sejam $A \toby f B \toby g C$.
Qual funcção é a $f \of g$?

\solution
Nem é definida a $f \of g$ no caso geral!
Para ser definida, é necessário e suficiente ter
$A = C$.

%%}}}

%%{{{ defining_functions_as_compositions 
\note Definindo funcções como composições.
%%%{{{ meta 
\label defining_functions_as_compositions
%%%}}}

Como $\of$ é uma operação de funcções, ganhamos então mais uma maneira
de definir funcções.
Dadas componíveis funcções $A \toby f B \toby g C$ podemos
definir uma funcção $h : A \to C$ apenas escrevendo:
$$
\textwq{Seja $h = g\of f$.}
$$
Claramente (e seguindo a discussão no~\reftag[useless_namings])
não precisamos dar um nome para essa funcção.
Podemos apenas falar sobre a $g\of f$, exatamente no mesmo
jeito que falamos do número $2\ntimes 8$ sem precisar
dar um nome pra ele!

%%}}}

%%{{{ factorize_a_function_example 
\example.
%%%{{{ meta 
\label factorize_a_function_example
%%%}}}

Seja $f : \ints\to\ints$ a funcção definida pela
$$
f(x) = 2(x^2 + 3).
$$
Mostre como definir a $f$ como composição
de três funcções $g,h,k : \ints\to\ints$
sem nenhuma das $g,h,k$ ser a $\lam x x$.
Sim, use lambdas (só pra praticá-los mais).

\solution.
Idéia: vamos tentar descrever o processo do que
acontece na entrada $x$ passo por passo até
chegar na saida $2(x^2 + 3)$.
Primeiramente acontece um quadramento,
depois um incremento por $3$,
e depois uma dobração.
Vamo lá então:
sejam as $g,h,k : \ints\to\ints$
definidas pelas
$$
\xalignat3
g &= \lam x {x^2} &
h &= \lam x {x + 3} &
k &= \lam x {2x}.
\endxalignat
$$
Assim definimos a $f$ como
$$
f = k \of h \of g.
$$
Sem ambigüidade podemos omitir os \sq{$\of$}
pois já estamos em modo ``de longe'' (sem mexer
com pontinhos):
$$
f = khg.
$$
Simplíssimo!

%%}}}

%%{{{ advice: to_name_or_not_to_name 
\advice to name or not to name.
%%%{{{ meta 
\label to_name_or_not_to_name
%%%}}}

Observe que nem precisamos nomes para as funcções
``intermediárias'' do~\ref[factorize_a_function_example].
Poderiamos simplesmente definir a funcção
$f : \ints\to\ints$ assim:
$$
f = 
\plam x {2x} \of
\plam x {x + 3} \of
\plam x {x^2}.
$$
(Nesse caso não vamos omitir os \sq{$\of$} pois aparecem os
pontinhos (os \sq{$x$}) e poderia confundir entre composição
e aplicação.)
Então: usamos funcções anônimas ou epônimas?
Depende!
E a escolha não é nada de boba.
Pelo contrário, é muito importante elaborar uma intuição
boa sobre:
% TODO: use bullets if not ref'ed
\tlist:
\li (i):  \emph{se} vamos nomear algo (lembra do~\reftag[useless_namings]);
\li (ii): \emph{qual} vai ser o seu nome, caso que decidirmos dar um.
\endtlist
Isso tanto em programação quanto em matemática!
Vamos voltar no nosso \ref[factorize_a_function_example] onde
temos três ``componentes intermediários'' e precisamos
decidir para cada um deles se vamos nomeá-lo e como.
Uns fatores importantes para considerar:
\tlist:
\li: esse componente é algo já bem conhecido?  já possui um nome?
\li: esse componente vai ser reutilizado?
\endtlist
Com essa guia, faria sentido definir a $f$ assim:
$$
f = \double \of \plam x {x+3} \of \square
$$
onde
$$
\xalignat2
\double &\eqtype \ints\to\ints & \square &\eqtype \ints\to\ints \\
\double(x) &= 2x               & \square(x) &= x^2.
\endxalignat
$$
Aqui não me pareceu tão útil ter um nome para a operação
$\lam x {x+3}$ e logo escolhi deixá-la anônima.
Se fosse $\lam x {x+1}$ teria escolhido usar o $\succ$.
Não existe maneira correta ou errada aqui: nomeá-las por $g,h,k$
também não foi bizarro não, nem deixá-las todas anônimas!
Depende da situação, do contexto, da intenção, do uso, etc.

%%}}}

%%{{{ x: factorize_a_function_exercise 
\exercise.
%%%{{{ meta 
\label factorize_a_function_exercise
%%%}}}

Fatorize as funcções seguintes na maneira mais legal que tu consegues:
$$
\xalignat2
f      &\eqtype \rats \to \rats &
f(x)   &= \frac 1 {\sqrt{(x+1)^2 + 1}} \\
g      &\eqtype \nats\cross\nats \to \nats &
g(x,y) &= y^2 + 1 \\
h      &\eqtype \nats\cross\nats \to \nats &
h(x,y) &= 2(x+y) + 1 \\
k      &\eqtype \nats\cross\nats \to \nats &
k(x,y) &= 2(x+2y) + 1.
\endxalignat
$$

\hint
Aqui uma maneira de definir a $f$ como composição
de $4$ fatores:
$$
f = \inverse \of \namedfun{squareRoot} \of \succ \of square \of succ.
$$
A definição de cada um deve ser óbvia pelo próprio nome.

\hint
Não se preocupe se não conseguir a $k$ neste momento.
Daqui a pouco (\reftag[Pointfree_style]) vai parecer fácil.

\solution
Temos:
$$
\align
f &= \inverse \of \namedfun{squareRoot} \of \succ \of \square \of succ \\
g &= \succ \of \square \of \outl \\
h &= \succ \of \double \of \plus \\
k &= \succ \of \double \of \plus \of \namedfun{doubleHeight}.
\endalign
$$
A definição de cada funcção-fator que aparece na direita
deve ser óbvia pelo próprio nome, exceto talvez da
$\namedfun{doubleHeight}$.
(Tá vendo como é bom escolher nomes bons?)
Definimos a $\namedfun{doubleHeight} : \nats^2\to\nats$
pela $\namedfun{doubleHeight}(x,y) = \tupp{x,2y}$.
Observe também que a $\succ$ da primeira linha é diferente
da $\succ$ das outras, por causa do seu tipo.
Mesma coisa sobre a $\square$.
Teria sido melhor usar $\succ_\rats$ para diferenciá-la
mas escolhi deixar pra lá essa decoração e todo o resto
da informação de tipos dos componentes intermediários
contando que tu consegues inferir cada domínio e cada
codomínio envolvido.
Espero que tu achou a resolução de $k$ meio ``meh'',
por causa dessa bizarra (muito \emph{ad hoc}) funcção
$\namedfun{doubleHeight}$ que talvez até ``forcei a
barra'' para nomeá-la.
Se preocupe não: como avisei na dica, daqui a pouco
(\reftag[Pointfree_style]) vamos ver como resolver isso
numa maneira bem legal mesmo.
Por enquanto, podemos melhorar a resolução assim:
$$
\align
k &= h \of \namedfun{doubleHeight}
\intertext{%
que com certeza é mais elegante, já que
}
k &= {\mubrace {(\succ \of \double \of \plus)} h}
     \of {\namedfun{doubleHeight}}.
\endalign
$$

%%}}}

%%{{{ why_not_compose_more 
\note Por que não compor mais?.
%%%{{{ meta 
\label why_not_compose_more
%%%}}}

Sejam $f : A \to B$ e $g : B' \to C$, e suponha que $B \subsetneq B'$.
É tentador definir uma funcção de composição $g\of f : A \to C$ pela
$$
(g\of f)(x) = g\big(f(x)\big) \quad \text{para todo $x\in A$}.
$$
No final das contas, para qualquer $x\in A$ temos $f(x)\in B$
e como $B\subsetneq B'$, também temos $f(x) \in B'$.
Então $g(f(x))$ é definido!
Então por que não relaxar pouco a restricção que temos na
definição da composição
$$
\text{de}
\quad
\cod f = \dom g
\quad
\text{para}
\quad
\cod f \subset \dom g
\ \ \text{?}
$$
Usando black boxes, temos as funcções
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)   at (4.5,0)    {$x$};
\node (fx) at (0,0)       {$f(x)$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\endtikzpicture
$$
e queremos ``conectar os cabos'' para criar um novo black box
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0.25mm, fill=gray!50]
      (-0.3,0.04)--(-0.3,-0.04)--(0.3,-0.04)--(0.3,0.04)--cycle;
\endtikzpicture
$$
pintar ele preto e considerar como a $g\of f$ de $A$ para $C$ mesmo:
$$
\tikzpicture
\tikzi blackboxfuncompthree;
\node (x)   at (4.5,0)    {$x$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\node (gof) at (0,0)      {$g\of f$};
\node (A)   at (2.7,0.7)  {$A$};
\node (C)   at (-2.7,0.7) {$C$};
\endtikzpicture
$$
Qual o problema com isso?
\wq{Nenhum}, disse o Conjuntista orgulhoso.
E realmente muitos matemáticos responderiam a mesma coisa---até
uns irreligiosos---e ficariam usando esse tipo de composição
``mais geral''.
Mas para a gente aqui, vamos supor que para motivos que não
importam---talvez religiosos, ou um TOC mesmo---\emph{não podemos}
conectar esse cabo no meio quando os conjuntos são diferentes:
\standout
\emph{\wq{Não comporás funcções $g$ e $f$ se $\cod f \neq \dom g$!}}
\endstandout
Essa suposta restricção, na verdade não nos restringe---pelo contrário:
nos ajuda criar composições ``limpas'' sem gambiarras como essa
``fita durex'' no cabo conectando o $B$ com o $B'$!
Trabalhe agora no exercício seguinte para demonstrar exatamente isso!

%%}}}

%%{{{ x: inclusions_for_compositions 
\exercise.
%%%{{{ meta 
\label inclusions_for_compositions
%%%}}}

Mostre como construir a funcção criada no~\ref[why_not_compose_more]
como composição de black boxes que contenha as $f$ e $g$ mas
sem nenhuma conexão ``proibida''.

\hint
Tu vai precisar definir uma terceira funcção $i$, e usar
seu black box na tua construção.

\hint
O que falta é decidir o que botar nos ``?'' abaixo,
e definir formalmente a funcção que corresponde nesta caixa:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$?$};
\node (iS) at (0.3,0.3)  {$?$};
\node (iT) at (-0.3,0.3) {$?$};
\endtikzpicture
$$

\solution
Definimos a funcção $i : B \to B'$ pela regra
$$
i(x) = x,   \quad\text{para todo $x\in B$}.
$$
Seu black box então, parece assim:
$$
\tikzpicture
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\endtikzpicture
$$
e é exatamente o ``missing link'' para construir nosso black box:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\endtikzpicture
$$
Construimos e usamos então a $g\of i\of f : A \to C$
em vez da ``gambiarrada'' e proibida $g\of f$.
Essa funcção $i$ é chamada a \dterm{inclusão do $A$ no $B$}
que definimos na~\ref[inclusion_function].

%%}}}

%%{{{ clearer_functional_notation 
\note Preguiça ({clareza!}) na notação funccional.
%%%{{{ meta 
\label clearer_functional_notation
\indexes
    * juxtaposição
    * notação!funccional
    ;;
%%%}}}

Como tu já se acostumou---eu espero---às vezes denotamos a aplicação duma
funcção no seu argumento silenciosamente, ou seja, por \dterm{juxtaposição:}
escrevemos $f x$ em vez do (mais comum em matemática clássica) $f(x)$.
Agora que temos \emph{uma operação padrão} entre funcções queremos
pegar emprestada a mesma preguiça e denotar por juxtaposição a
composição também:
$$
\msymq{fg}
\qqtext{quis dizer}
\msymq{f \of g}.
$$
Com essa convenção, o que seria o
\symq{$f g x$}?
Acontece que ambas as interpretações
$$
\msymq{(f g) x}
\qqtext{ou}
\msymq{f (g x)}
$$
são iguais nesse caso (deu sorte \emph{extensional}\/),
mas \emph{intensionalmente} falando elas correspondem
nas notações tradicionais
$$
\msymq{(f \of g) (x)}
\qqtext{e}
\msymq{f (g(x))}
$$
respectivamente.
E até pior---nossa preguiça não tem fim---entre números também
temos uma operação padrão que denotamos por juxtaposição:
$$
xy
\qqtext{é o produto}
x\ntimes y.
$$
E supondo que $f,g:\reals\to\reals$ e $x,y\in\reals$,
a expressão
$
\msymq{g f x y}
$
denota o quê?
Sem parenteses, nada, por isso vamos escrever
$$
\msymq{g \fa f \fa (xy)}
\qqtext{ou}
\msymq{(gf)(xy)}
$$
que (ambas!)~denotam o
$$
(g \of f)(x\ntimes y)
$$
que é igual ao $g (f (x\ntimes y))$ pela definição da $\of$.
Eu vou ficar misturando a notação mais tradicional e a notação mais
``funccional'' dependendo do contexto e assim vamos se acostumar com ambas.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora ver uns examplos para resumir:

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Sejam $f,g,h:\reals\to\reals$ e $x,y,z\in\reals$.
Usando \symq{$\syneq$} para igualdade sintáctica e \symq{$=$} para igualdade
semántica (veja~\ref[Arithmetic_expressions_syntax_vs_semantics]) temos:
$$
\align
fx         &\syneq f(x) \\
(fg)x      &\syneq (f\of g)(x) = f(g(x))\\
f(gx)      &\syneq f(g(x)) \\
fgh        &\syneq (f\of g\of h) \\
f(ghx)     &\syneq f ((g\of h)(x)) = f(g(h(x))) \\
(fg)h(xy)  &\syneq ((f\of g) \of h)(x\ntimes y)
                   = (f\of g)(h(x\ntimes y)) = f(g(h(x\ntimes y))).
\endalign
$$
Espero que ficou claro.

%%}}}

\endsection
%%}}}

%%{{{ Functions_for_free 
\section Funcções de graça.
%%%{{{ meta 
\label Functions_for_free
%%%}}}

%%{{{ intro 
\secintro
Investigamos aqui umas primeiras funcções garantidas para
existir assim que tivermos alguns outros objetos:
conjuntos, funcções, etc.
%%}}}

%%{{{ df: identity_function 
\definition Identidade.
%%%{{{ meta 
\label identity_function
\indexes
    * identidade    see: funcção
    ;;
\defines
    * \idof {~A}  -- a identidade do $A$
    * funcção!identidade
    ;;
%%%}}}

Seja $A$ conjunto.
A funcção $\lam x x : A \to A$ é chamada
\dterm{identidade do $A$}.
Denotamos a identidade do conjunto $A$ por $\idof A : A \to A$ ou $1_A : A \to A$.

%%}}}

%%{{{ beware: a_or_the_idof 
\beware <<uma>> ou <<a>>.
%%%{{{ meta 
\label a_or_the_idof
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Podemos falar \emph{da} funcção identidade?
Não, pois para usar o artigo definido precisamos \emph{unicidade}
e não existe uma única <<funcção identidade>>.
Pelo contrário: para cada conjunto $A$, temos uma funcção identidade:
a identidade \emph{do $A$}.

%%}}}

%%{{{ df: inclusion_function 
\definition Inclusão.
%%%{{{ meta 
\label inclusion_function
\defines
    * \incofin {~A} {~B}  -- a inclusão do $A$ no $B$
    * ~i : ~A \incto ~B  -- $i$ é a inclusão do $A$ no $B$ (ou uma injecção)
    * ~i : ~A \subset ~B  -- $A \subsetto B$ (notação alternativa)
    * ~i : ~A \subsetto ~B  -- $i$ é a inclusão do $A$ no $B$
    * funcção!inclusão
    ;;
%%%}}}

Sejam $A,B$ conjuntos com $A\subset B$.
A funcção $\lam x x : A \to B$ é chamada \dterm{inclusão do $A$ no $B$}.
Usamos o $\inc$ para denotar uma inclusão e escrevemos
$$
\inc : A \incto B
\qqtext{ou}
\inc : A \subsetto B
\qqtext{ou até}
\inc : A \subset B
$$
para enfatizar que é uma inclusão mesmo.
Decoramos a notação escrevendo $\incofin A B$ quando essa informação
não é implícita pelo contexto.
Todos os $i,\imath,\iota$ são símbolos freqüentemente usados para
denotar inclusões.

%%}}}

%%{{{ remark: inclusion_is_not_id 
\remark.
%%%{{{ meta 
\label inclusion_is_not_id
%%%}}}

Note que seguindo o ponto de vista categorial (\reftag[f_eq_g_catist]),
se $A \subsetneq B$ então $\incofin A B \neq \idof A$,
mas seguindo o ponto de vista conjuntista (\reftag[f_eq_g_setist]),
temos $\incofin A B = \idof A$.

%%}}}

%%{{{ x: idof_is_not_unique_for_any_religion 
\exercise.
%%%{{{ meta 
\label idof_is_not_unique_for_any_religion
%%%}}}

O~\ref[a_or_the_idof] afirmou que para conjuntos distintos
temos identidades distintas.
Isso é válido para o Conjuntista também?
Ou é como o que descobrimos resolvendo o~\ref[a_or_the_emptyfun]
sobre as funcções vazias?:
que para o Categorista tem muitas funcções vazias
(uma para cada conjunto) mas para o Conjuntista tem apenas uma
única.
Compare!

\hint
\ref[dom_and_cod_recoverable_or_not].

\solution
Sim: até para o Conjuntista cada conjunto tem sua própria identidade.
Para conjuntos distintos $A \neq B$ temos
$$
\dom(\idof A) = A \neq B = \dom(\idof B)
$$
e logo as identidades são distintas também: $\idof A \neq \idof B$.
Lembre que o domínio é observável pelo Conjuntista:
\ref[dom_and_cod_recoverable_or_not].
O mesmo argumento não passaria sobre as funcções vazias,
pois para diferenciá-las precisamos olhar para os seus
codomínios, e isso é algo inobservável pelo Conjuntista.

%%}}}

%%{{{ x: composition_of_inclusions 
\exercise.
%%%{{{ meta 
\label composition_of_inclusions
%%%}}}

Verifique que composição de inclusões é inclusão.

\hint
$A \subset B \mland B \subset C \implies A \subset C$.

%%}}}

%%{{{ beware: incto might be some other injection 
\beware.
%%%{{{ meta 
%%%}}}

A notação $A \incto B$ não sempre denota a própria inclusão; pode ser usada
para denotar uma \emph{injecção} diferente dependendo do
contexto.  A idéia é que mesmo sem ter $A \subset B$ pensamos que uma
injecção determina uma cópia fiel do $A$ dentro do $B$.
Isso vai fazer muito mais sentido na \reftag[Jections], pois per enquanto
nem sabemos o que significa \wq{injecção}!

%%}}}

%%{{{ df: constant_function_steady_function
\definition constante; invariável.
%%%{{{ meta 
\label constant_function_steady_function
\indexes
    * funcção!steady    see: invariável
    ;;
\defines
    * funcção!constante
    * funcção!invariável
    ;;
%%%}}}

Dados conjuntos $A,B$, e $b\in B$, definimos a funcção
$\kon b : A \to B$ pela
$$
\kon b (x) = b.
$$
A $\kon b$ é chamada
\dterm{funcção constante (do $A$ para $B$) com valor $b$}.
Aqui tanto seu domínio quanto se codomínio estavam
claros pelo contexto então não precisamos sobrecarregar
nossa notação com muitas decorações.
Quando não são e quando importam escrevemos
$\kondom A b$ ou até $\kondomcod A B b$.
Dizemos que uma funcção $f : A \to B$ é \dterm{constante}
sse ela é constante com valor $b$ para algum $b \in B$:
$$
\align
\text{$f : A \to B$ constante}
&\defiff
\lexists {b \in B} {f = \kon b}.
\intertext{%
Chamamos uma funcção de \dterm{invariável} (ou \dterm{steady})
sse ela mapeia todos os membros do seu domínio para o mesmo objeto.
Formulamente,
}
\text{$f : A \to B$ invariável}
&\defiff
\lforall {x, y \in A} {f(x) = f(y)}.
\endalign
$$

%%}}}

%%{{{ beware: constant_may_mean_something_different 
\beware O termo ``constante''.
%%%{{{ meta 
\label constant_may_mean_something_different
%%%}}}

Muitos textos usam o termo ``constante'' para descrever o que
chamamos de ``invariável'' (ou ``steady'').
Na maioria dos casos não existe confusão, pois as duas definições
concordam.  Mas precisamos tomar cuidado, como tu vai descobrir
agora fazendo o~\ref[constant_notiff_steady].

%%}}}

%%{{{ x: constant_notiff_steady 
\exercise.
%%%{{{ meta 
\label constant_notiff_steady
%%%}}}

Às vezes aparece como definição de constante a seguinte:
\emph{\wq{A funcção $f : A \to B$ é constante sse mapeia todos
os membros do seu domínio para o mesmo objeto.}}
Essa definição é equivalente com a~\ref[constant_function_steady_function]?
Ou seja, com nossa terminologia aqui:
$$
\text{$f$ invariável}
\askiff
\text{$f$ constante}.
$$
(Verifique ambas as direcções.)

\hint
$\emptyset$.

\solution
Não.
Por exemplo a funcção vazia $f : \emptyset\to\emptyset$ é invariável
mas não constante.
Mas realmente temos que
$$
\text{$f$ invariável}
\impliedby
\text{$f$ constante}:
$$
Suponha $f : A \to B$ constante, e logo
seja $b\in B$ tal que $f = \kon b$.
Sejam $x,y \in A$ e calculamos:
$$
f(x) = \kon b (x) = b = \kon b (y) = f(y)
$$
e logo $f$ é invariável.

%}}}

%%{{{ x: constant_with_more_than_one_value 
\exercise.
%%%{{{ meta 
%%%}}}

Uma funcção $f : A \to B$ pode ser constante com valor $b$
e com valor $b'$ também, com $b \neq b'$?

\hint
$\emptyset$.

\solution
Pode sim.
Isso aconrece exatamente quando $A = \emptyset$
e $B$ possui pelo menos dois membros distintos $b\neq b'$.
Nesse caso temos
$$
\kondom A b = \kondom A {b'}.
$$

%%}}}

%%{{{ x: constant_function_definitions_almost_agree 
\exercise.
%%%{{{ meta 
\label constant_function_definitions_almost_agree
%%%}}}

Sejam $A \toby f B$ com $A \neq \emptyset$.
Demonstre que:
$$
\text{$f$ constante}
\iff
\pexists {b\in B}
\lforall {x\in A}
{f(x) = b}.
$$

\solution
\proofpart{\lrdir:}
Seja $a\in A$ ($A\neq\emptyset$).
Vamos mostrar que tomando $b\asseq f(a)$ a proposição na direita é satisfeita.
Observe que o $f(a)\in B$ e satisfaz
$$
\lforall {x\in A} {f(x) = f(a)}
$$
pela definição de constante.
\crproofpart{\rldir:}
Seja $b_0\in B$ tal que para todo $x\in A$, $f(x) = b_0$.
Agora para todo $x,y \in A$ temos $f(x) = b_0 = f(y)$ pela hipótese,
ou seja, $f$ é constante.

%%}}}

%%{{{ x: constant_function_which_definition_is_stronger 
\exercise.
%%%{{{ meta 
\label constant_function_which_definition_is_stronger
%%%}}}

No caso geral, alguma das direções
da~\ref[constant_function_definitions_almost_agree] é válida ainda?

\solution
Sim, a {\rldir}.
Observe \emph{bem} que na demonstração dessa direção não precisamos $A\neq\emptyset$.
E pelo~\ref[constant_notiff_steady] já sabemos que a {\lrdir} não é
válida em geral.

%%}}}

%%{{{ x: gof_constant_does_not_imply 
\exercise.
%%%{{{ meta 
\label gof_constant_does_not_imply
%%%}}}

Demonstre ou refute a afirmação seguinte:
\emph{se $(g \of f)$ é constante, então pelo menos uma das $f,g$ também é}.

\hint
Tente achar contraexemplo desenhando diagramas internos.

\solution
Falso.
Um contraexemplo é o seguinte:
$$
\tikzpicture
\tikzi gofconstantdoesnotimply;
\endtikzpicture
$$

%%}}}

%%{{{ x: wrong_order_of_quantifiers 
\exercise.
%%%{{{ meta 
\label wrong_order_of_quantifiers
%%%}}}

O que é errado na definição seguinte de funcção constante?
$$
\text{$f:A\to B$ constante}
\defiff
\pforall {a \in A}
\lexists {b \in B} {f(a) = b}.
$$
Será que substituindo o $\exists$ por $\unique$ o problema tá resolvido?
Sugira uma outra resolução simples.

\hint
Siga essa definição e tente achar alguam funcção que não vai ser chamada
constante.

\solution
A definição tem o problema que vai aceitar toda funcção como constante,
pois o que ela exige é satisfeito por toda funcção.
\emph{Substituindo} o $\exists$ por $\unique$ nada muda nesse sentido,
pois toda funcção satisfaz essa afirmação mais forte
(determinabilidade de funcção, \reftag[functionhood_conditions]).
\eop
O problema é que os quantificadores estão na ordem errada!
Simplesmente \emph{trocando a ordem deles}, chegamos numa
definição equivalente à do~\ref[constant_notiff_steady]:
$$
\text{$f:A\to B$ constante}
\defiff
\pexists {b \in B}
\lforall {a \in A}
{f(a) = b}.
$$

%%}}}

%%{{{ df: characteristic_funcion 
\definition Característica.
%%%{{{ meta 
\label characteristic_function
\indexes
    * característica    see: funcção
    ;;
\defines
    * \chr {~C}  -- a funcção característica do $C$ (com domínio implícito)
    * \chrdom {~A} {~C}  -- a funcção característica do $C$ no $A$
    * funcção!característica
    ;;
%%%}}}

Sejam $A$ conjunto e $C \subset A$.
A \dterm{funcção característica do $C$ no $A$} é a funcção
$\chrdom A C : A \to \set{0,1}$ definida pela
$$
\chrdom A C (x) =
\knuthcases {
1, &se $x\in C$;\cr
0, &se $x\notin C$.
}
$$
Escrevemos apenas $\chr C$ quando o domínio $A$ é implícito pelo
contexto---e na práctica esse é quase sempre o caso!

%%}}}

%%{{{ warning: characteristic_function_inverted_values 
\warning.
%%%{{{ meta 
\label characteristic_function_inverted_values
%%%}}}

O uso de $1$ para representar ``true'' e o $0$ para o ``false'' é aleatório.
De fato, dependendo de caso, às vezes definimos a funcção característica
com esses valores invertidos!  Isso é muito comum em teoria de recursão
(veja~\cite[kleeneIM] por exemplo), mas não só:
nos shells de Unix\indexed[Unix!shell],
também o valor $0$ representa o ``true'' (ou ``deu certo'')
e cada valor positivo o ``false'' (ou ``deu errado'').\indexed[main]\foot
Nesse caso essa escolha é obviamente melhor, pois sabendo que ``deu certo'',
em geral não perguntamos <<por que deu certo?>>; mas se der errado, queremos
saber mais sobre o motivo que deu errado: talvez um arquivo não
existe, talvez uma conexão não pode ser feita, talvez faltou uma permissão,
etc., e cada um desses casos pode retornar um valor positivo diferente.
\eop
Esse ``retornar'' que eu tô me referindo aqui é o proprio $\code{return}$
que muitas vezes estudando programação o aluno acaba memorizando como
``regrinha'' que sua $\code{main}$ precisa terminar com um
``$\code{return 0}$''.  Por quê?  E pra quem que ta retornando isso?
Para o próprio sistema operacional.  No final das contas, foi ele que
chamou essa $\code{main}$.
\toof
\eop
\emph{A moral da estória:}
sempre verifique a definição da funcção característica
usada---e se quiseres usar num texto teu, sempre bota sua definição junto!
Nesse texto, quando aparece a notação $\chr C$ sem definição,
denota a funcção que definimos acima na~\ref[characteristic_function].

%%}}}

%%{{{ x: explain_unix_shell_connectives 
\exercise Para os Unixeiros.
%%%{{{ meta 
\label explain_unix_shell_connectives
\indexes
    * Unix!shell
    ;;
%%%}}}

Num shell de Unix (cujo ``prompt'' denoto aqui por \symq{$\code{\#}$})
escrevemos:
\shell
\# cmd1 \&\& cmd2 \CR
\# cmd1 || cmd2
\endshell
onde $\code{cmd1}$ e $\code{cmd2}$ são dois comandos.
Explique o comportamento sabendo que $\code{\&\&}$ e $\code{||}$
denotam os operadores lógicos da conjuncção e disjuncção (respectivamente).
Conclua que o shell de Unix é ``apenas'' um calculador de valores de verdade
nesse sentido.  Todas as coisas que vão acontecer executando isso
``no mundo real'' são nada mais que \dterm{side-effects} enquanto calculando
os seus comandos, para achar seus valores de verdade.
Como posso dar para o shell a ordem
\wq{executa o $\code{cmd1}$ e depois o $\code{cmd2}$}?

%%}}}

%%{{{ remark: replacing_cases_by_characteristic_functions 
\remark.
%%%{{{ meta 
\label replacing_cases_by_characteristic_functions
%%%}}}

Um dos usos comuns de funcções características é definir funcções num jeito mais
curto, aproveitando os fato que $0x = 0$ e $1x = x$ para todo $x\in\reals$.
Esse uso lembra das expressões $\namedfun{if-then-else}$ que usamos
em linguagens de programação.

%%}}}

%%{{{ eg: replacing_cases_by_characteristic_functions_example 
\example.
%%%{{{ meta 
\label replacing_cases_by_characteristic_functions_example
%%%}}}

Considere a $f : \reals \to \reals$ definida pela
$$
f(x) = \knuthcases {
2\cbrt{x + \log_2 |x+1|} + x^2, & se $x \in \rats$ \cr
2\cbrt{x + \log_2 |x+1|} + e^x, & caso contrário.
}
$$
Usando as funcções características de $\rats$ e $\reals\minus\rats$
podemos definir a $f$ com uma equação só, e ``sem repetição'':
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + x^2 \chr\rats (x) + e^x \chr{\reals\minus\rats} (x).
$$
Isso lembra um
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + \PIF x \in \rats \THEN x^2 \ELSE e^x \FIP.
$$
usado em linguagens de programação que suportam \dterm{if-then-else expressions}.

%%}}}

%%{{{ beware: expressions_vs_statemets 
\beware expressions \vs statements.
%%%{{{ meta 
\label expressions_vs_statemets
\indexes
    * C
    * Haskell
    ;;
\defines
    * expressão!\vs statement
    * statement!\vs expressão
    ;;
%%%}}}

Uma \dterm{if-then-else expression} não é a mesma coisa com um
\dterm{if-branching statement} encontrado em muitas linguagens de
programação imperativas.  A idéia é que uma expressão denota um
valor; um statement é apenas uma ordem para ser executada.
A linguagem C por exemplo tem ambas mas o que escrevemos em C
com ``\code{if}\dots''~corresponde no branching \emph{statement}.
Nunca faria sentido em C, por exemplo, multiplicar um
\emph{if statement} por um número.
A \emph{expressão} if-then-else de C corresponde no seu único
operador ternário, com a sintaxe (bizarra)
$$
\text{\code(\thole\code?\thole\code:\thole\code)}.
$$
Em Haskell, no outro lado, escrevemos mesmo
$$
\text{\code{if}\thole\code{then}\thole\code{else}\thole}.
$$

%%}}}

%%{{{ x: char_compose_char 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $A,X$ conjuntos com $A\subset X$.
Suponha que $\chrdom X A \of \chrdom X A$ é definida.
O que podes concluir sobre o $X$?
Podemos concluir que a $\chr A \of \chr A$ é constante ou a identidade?

\hint
O fato que uma composição é definida dá informação sobre um domínio
e um codomínio envolvido.

\solution
Temos $\chr A : X \to \set{0,1}$.
Como a composição $\chr A \of \chr A$ é definida,
concluimos que $\cod(\chr A) = \dom(\chr A)$.
Ou seja, $X = \set{0,1}$.
\eop
O $A$ sendo um subconjunto de $\set{0,1}$ so tem 4 possibilidades:
$$
\xalignat4
A &= \emptyset; &
A &= \set{0};   &
A &= \set{1};   &
A &= \set{0,1} = X.
\endxalignat
$$
Calculamos em todos os casos:
$$
\align
A = \emptyset &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 0
\endaligned
} \\
A = \set{0} &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(1) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(0) = 1
\endaligned
} \\
A = \set{1} &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(0) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(1) = 1
\endaligned
} \\
A = X &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 1 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 1\,.
\endaligned
}
\endalign
$$
Sobre a $\chr A\of\chr A$ então concluimos que
se $A$ é um dos singletons $\set{0}$ ou $\set{1}$ então ela é a identidade.
Caso contrário, ela é uma constante:
se $A = \emptyset$, a constante $0$; se $A = X$, a constante $1$.

%%}}}

%%{{{ df: fresto 
\definition Restricção.
%%%{{{ meta 
\label fresto
\defines
    * ~f \resto ~X  -- a restricção de $f$ no $X$
    * ~f \restosub {~X}  -- $f \resto X$ (notação alternativa)
    * funcção!restricção
    ;;
%%%}}}

Sejam $f : A \to B$ e $X \subset A$.
A \dterm{restricção da $f$ no $X$}, denotada por
$\resfun f X$ é a funcção de $X$ para $B$ definida pela
$$
(\resfun f X)(x) = f(x).
$$
Também é usada a notação $\resfunsub f X$.

%%}}}

%%{{{ x: type_of_f_resto_X 
\exercise.
%%%{{{ meta 
\label type_of_f_resto_X
%%%}}}

Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo de
$
f\resto X
$.

\solution
$f\resto X \is X \to B$.

%%}}}

%%{{{ x: fresto_pointfree 
\exercise restrição sem pontos.
%%%{{{ meta 
\label fresto_pointfree
%%%}}}

Sejam $A,B$ conjuntos e $X\subset A$.
Defina a funcção $f \resto X$ sem usar nenhuma referência aos membros desses conjuntos.
Na~\ref[fresto], por exemplo, usamos esse $x$ para representar um mebro de $A$.
(Esqueça o ``sem pontos'' no rótulo desse exercício;
vai fazer sentido depois:~\reftag[Pointfree_style].)

\hint
Defina como composição de funcções conhecidas.

\hint
Inclusão.

\solution
$f\resto X = \incofin X A \of f$.

%%}}}

\endsection
%%}}}

%%{{{ Partial_application 
\section Aplicação parcial.
%%%{{{ meta 
\label Partial_application
%%%}}}

%%{{{ Partial application with black boxes 
\note Aplicação parcial com black boxes.
%%%{{{ meta 
%%%}}}

Suponha que temos uma funcção de aridade~$2$:
$$
f : (A\times B) \to C.
$$
Ou seja, nossa funcção, ``para funccionar'', precisa receber
exatamente dois argumentos: algum $a\in A$ e algum $b\in B$
para ``produzir'' o valor $f(a,b) \in C$: $$
\tikzpicture
\tikzi blackboxfunpartapp1;
\endtikzpicture
$$
Queremos utilizar essa funcção de aridade~$2$,
para criar duas outras, cada uma de aridade~$1$.
A idéia é a seguinte: vamos ``fixar'' uma das suas entradas
com um valor, e deixar a outra como entrada mesmo.
Imagine que fixamos um certo $b_0\in B$ no segundo ``cabo'' de entrada,
puxamos o outro cabo, e criamos uma nova caixa assim:
$$
\tikzpicture
\tikzi blackboxfunpartapp2;
\endtikzpicture
$$
E agora pintamos preta nossa caixa, escrevemos seus rótulos (seu tipo),
e pronto, construimos uma nova funcção de aridade $1$:
$$
\tikzpicture
\tikzi blackboxfunpartapp3;
\endtikzpicture
$$
Observe que temos $f(\dhole,b_0):A \to C$.
Vamos agora ver a mesma idéia usando buracos, sem black boxes.

%%}}}

%%{{{ Partial application using holes 
\note Aplicação parcial usando buracos.
%%%{{{ meta 
%%%}}}

Considere uma funcção $f$ de aridade 3:
$$
A \times B \times C \longtoby f D.
$$
Lembre-se que
$$
f(\dhole, \dhole, \dhole) :
A \times B \times C \to D
$$
e ainda mais $f(\dhole, \dhole, \dhole)$ é a própria $f$!
Queremos preencher uns desses buracos, mas não todos.
E nada especial sobre esse $3$.
Em geral, dada uma funcção $f$ de aridade $n$,
podemos \emph{fixar} $k$ dos seus argumentos
com certos valores, botar buracos nos ouros,
e criar assim uma funcção de aridade $n-k$.
Uns exemplos vão esclarecer esse processo.

%%}}}

%%{{{ eg: partial_application_holes_eg 
\example.
%%%{{{ meta 
%%%}}}

Considere a funcção $f : \reals^3 \to \reals$, definida pela
$$
f(x,y,z) = x + y^2 + z^3.
$$
Temos então
$$
\align
f(\dhole,\dhole,\dhole) &: \reals^3 \to \reals.
\intertext{Com aplicação parcial, fixando uns dos seus argumentos,
criamos então as funcções seguintes:}
f(2,\dhole,\dhole)      &: \reals^2 \to \reals \\
f(2,\dhole,\sin(2))     &: \reals   \to \reals \\
f(\dhole,\sqrt2,\cbrt2) &: \reals   \to \reals \\
f(\dhole,0,0)           &: \reals   \to \reals.
\endalign
$$
A última, por exemplo, é a $\idof \reals$; a penúltima é a $\lam x {x+4}$.

%%}}}

%%{{{ eg: partial_application_holes_infix_eg 
\example.
%%%{{{ meta 
%%%}}}

Aplicando a funcção de adição $+ : \nats^2 \to \nats$
parcialmente fixando seu segundo argumento no número $1$,
criamos a funcção
$$
\align
(\bhole + 1) &: \nats \to \nats
\intertext{que é a funcção $\namedfun{succ}$ de sucessor;
e fixando seu primeiro argumento no $0$ criamos a}
(0 + \bhole) &: \nats \to \nats
\endalign
$$
que é a $\idof \nats$.

%%}}}

%%{{{ teaser: partial application and currying 
\teaser.
%%%{{{ meta 
%%%}}}

Já que entendeu a relação entre expressões que envovlem buracos
e abstracções lambda com variáveis, espero que nem preciso
explicar que podemos denotar a aplicação parcial $f(2,\dhole)$
por $\lam x {f(2,x)}$.
Mas trabalhando com lambdas é mais comum tratar funcções
de aridades maiores que $1$ numa outra maneira, chamada
currificação (\reftag[Currying]).  E a aplicação parcial
brilha ainda mais nesse caso: não precisa nem buracos,
nem variáveis (\ref[partial_application_and_currying])!

%%}}}

\endsection
%%}}}

%%{{{ Composition_laws 
\section Leis de composição.
%%%{{{ meta 
\label Composition_laws
%%%}}}

%%{{{ Composition as an operation 
\note Composição como operação.
%%%{{{ meta 
\label composition_as_an_operation
%%%}}}

No mesmo jeito que o produto $3\ntimes 2$ denota um número,
a composição $g \of f$ de certas funcções $f$ e $g$ denota uma funcção.
A $\of$ então realmente é uma operação (binária) nas funcções,
e agora vamos investigar as leis que ela satisfaz, fazendo uma
comparação com a multiplicação nos números, procurando similaridades
e diferêncas.  Note que já começamos com uma ambigüidade com esse
``nos números'', pois as leis satisfeitas pela~$\ntimes$~dependem de
\emph{qual multiplicação} estamos considerando:
a multiplicação nos reais, por exemplo, satisfaz a uma lei de inversos
(viz.~\wq{cada número diferente de zero tem um inverso multiplicativo})
mas nos inteiros não.  Mais sobre isso depois.

%%}}}

%%{{{ factorization_of_function 
\note Fatorização de funcção.
%%%{{{ meta 
\defines
    * fatorização!de funcção
    ;;
%%%}}}

Num certo sentido muito interessante, e fortalecendo
nossa metáfora entre composição e multiplicação,
o que fizemos no~\ref[factorize_a_function_example]
pode ser visto como uma \dterm{fatorização de funcção}:
escrevemos a $f$ como ``produto'' dos ``fatores''
$g,h,k$.
Sabendo como fatorizar funcções é importaníssimo
em programação, algo que vamos apreciar muito no
no~\ref[Functional_programming].

%%}}}

%%{{{ Totality 
\note Totalidade.
%%%{{{ meta 
%%%}}}

Primeiramente observe uma grande diferença entre composição e multiplicação:
a multiplicação é uma operação \dterm{total}, ou seja, para todo número
$x, y$, seu produto $x\ntimes y$ é definido.
Mas como vimos na~\ref[fcompose], para formar a composição $g\of f$
de duas funcções $f$ e $g$ elas precisam satisfazer a condição
$\cod f = \dom g$.  Caso contrário, o $g\of f$ nem tem significado!
Continuamos investigando mais propriedades.

%%}}}

%%{{{ Intuition with tasks 
\note Intuição com tarefas.
%%%{{{ meta 
%%%}}}

Vamos agora imaginar funcções como tarefas para ser feitas em algo,
e a composição como a idéia de ``seqüenciar as tarefas''.
Ou seja $g\of f$ seria a tarefa de \emph{fazer a tarefa $f$ e depois a $g$}.
Com essa intuição, parecem óbvias estas duas afirmações:
\elist i:
\li: a composição é associativa;
\li: a composição não é comutativa.
\endelist
Mas intuição nunca provou nada sozinha,
então bora demonstrar essas afirmações!

%%}}}

%%{{{ Associativity 
\note Associatividade.
%%%{{{ meta 
%%%}}}

Suponha que temos funcções
$$
A \toby f B \toby g C \toby h D.
$$
Podemos entao formar as composições $g\of f$ e $h\of g$.
Temos então:
$$
A \toby {g\of f} C \toby h D
\qqquad
A \toby f B \toby {h\of g} D.
$$
Compondo as funcções do primeiro diagrama criamos a funcção $h\of(g\of f)$,
e compondo aquelas do segundo criamos a $(h\of g)\of f$:
$$
A \longtoby {h\of (g\of f)} D
\qqquad
A \longtoby {(h\of g)\of f} D.
$$
Queremos saber se as duas funcções são iguais.
Vamos pensar sobre isso usando black boxes.
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc1;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc2;
\endtikzpicture
\endgathered
$$
Primeiramente observe que os tipos delas são iguais.
Então basta verificar que concordam para todo ponto $x\in A$.
Pela definição de composição sabemos que ``internalmente''
elas funccionam assim:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc3;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc4;
\endtikzpicture
\endgathered
$$
Agora pelas definições das $g\of f$ e $h\of g$,
o que precisamos comparar na verdade são as:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc5;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc6;
\endtikzpicture
\endgathered
$$
Agora que tá tudo transparente parece óbvio que as duas funcções são iguais,
e comportam como a seguinte:
$$
\tikzpicture
\tikzi blackboxfuncompassoc0;
\endtikzpicture
$$
Mas para demonstrar que as duas construções resultam na mesma funcção,
vamos precisar calcular os <<$?$>> do desenho acima, e seguir
fielmente as definições.

%%}}}

%%{{{ thm: fcom_associativity_law 
\theorem Lei de associatividade.
%%%{{{ meta 
\label fcom_associativity_law
%%%}}}

Sejam
$$
A \toby f B \toby g C \toby h D.
$$
Então
$$
h \of (g \of f) = (h \of g) \of f.
$$

\sketch.
Mostramos que as duas funcções são iguais seguindo a definição
de igualdade~\reftag[f_eq_g]:
mostrando que elas têm o mesmo domínio $A$,
e que comportam igualmente para o arbitrário $a \in A$.
Observe que seus codomínios também são iguais, satisfazendo
assim a definição de igualdade~\reftag[f_eq_g_catist] também.
Pegando cada lado da igualdade e aplicando a definição de $\of$
chegamos no mesmo valor.

\proof.
Primeiramente vamos verificar que as duas funcções tem o mesmo domínio:
\compute
\dom\paren{ h \of (g \of f) }
&= \dom (g \of f)               \by {def.~$h\of(g\of f)$} \\
&= \dom f                       \by {def.~$g\of f$} \\
\intertext{e do lado direito}
\dom\paren{ (h \of g) \of f }
&= \dom f.                      \by {def.~$(h\of g)\of f$} \\
\endcompute
Similarmente elas têm os mesmos codomínios
(caso que seguimos a definição~\reftag[f_eq_g_catist])
\compute
\cod\paren{ h \of (g \of f) }
&= \cod h                       \by {def.~$h\of(g\of f)$} \\
\intertext{e do lado direito}
\cod\paren{ (h \of g) \of f }
&= \cod (h \of g)               \by {def.~$(h\of g)\of f$} \\
&= \cod h.                      \by {def.~$h\of g$} \\
\endcompute
Agora precisamos mostrar que as duas funcções comportam no mesmo jeito
para todos os elementos no $A$.
Suponha $a\in A$ então, e calcule:
\compute
\paren{h \of (g \of f)}(a)
&= h\paren{\paren{g \of f}(a)}  \by {def.~$h\of(g\of f)$} \\
&= h\paren{g \paren{f(a)}}      \by {def.~$g\of f$} \\
\intertext{e o lado direito:}
\paren{(h \of g) \of f}(a)
&= \paren{h \of g}\paren{f(a)}  \by {def.~$(h\of g)\of f$} \\
&= h\paren{g \paren{f(a)}}      \by {def.~$h\of g$} \\
\endcompute

%%}}}

%%{{{ Commutativity 
\note Comutatividade.
%%%{{{ meta 
%%%}}}

É fácil demonstrar que a composição de funcções \emph{não é comutativa}.
Faça isso agora no exercício seguinte!

%%}}}

%%{{{ x: non_commutativity_of_fcom 
\exercise.
%%%{{{ meta 
\label non_commutativity_of_fcom
%%%}}}

Existem funcções $f,g$ entre conjuntos $A,B$
tais que $f\of g$ e $g\of f$ são ambas definidas,
mas mesmo assim
$$
f\of g \neq g\of f.
$$
Mostre pelo menos dois exemplos diferentes:
um com $A\neq B$; outro com $A = B$.

\solution
\DefFun flip
\DefFun zero
\DefFun one
Para o primeiro exemplo, escolhe $A = \set{0}$ e $B=\set{0,1}$.
Agora sejam $f : A \to B$ e $g : B \to A$ definidas pelas
$$
\xalignat2
f(0) &= 0  &  g(x) = 0
\endxalignat
$$
Ambas as $g\of f$ e $f\of g$ são definidas mas são diferentes
pois nem domínios iguais elas têm:
$$
\dom (g\of f) = \dom g = B \neq A = \dom f = \dom (f\of g).
$$
\eop
Para o segundo exemplo, tome $A=B=\set{0,1}$
e defina as funcções $\flip,\zero,\one:A \to A$ pelas:
$$
\xalignat3
\flip(0) &= 1  &  \zero(0) &= 0  &  \one(0) &= 1\\
\flip(1) &= 0  &  \zero(1) &= 0  &  \one(1) &= 1.
\endxalignat
$$
Calculando temos $\flip\of\zero = \one$ mas $\zero\of\flip = \zero$.
De fato, quaisquer duas dessas três funcções servem como um exemplo nesse caso!

%%}}}

%%{{{ Identity 
\note Identidades.
%%%{{{ meta 
%%%}}}

Investigamos agora se a operação de composição possui \emph{identidade}
mas primeiramente vamos lembrar o que isso significa.
Por enquanto não provamos nada a respeito disso, então trate
as funcções que chamamos de identidades na~\reftag[identity_function]
como uma coincidência.

%%}}}

%%{{{ Q: what_is_the_identity_of_composition 
\question.
%%%{{{ meta 
\label what_is_the_identity_of_composition
%%%}}}

Chamamos o $1$ a \dterm{identidade} da operação $\ntimes$ nos reais, pois:
$$
1\ntimes x = x = x\ntimes 1, \qquad \text{para todo $x\in \reals$}.
$$
Tentando achar uma similaridade entre funcções e números num lado, e composição e multiplicação no outro,
qual seria nosso $1$ aqui?
Ou seja,
procuramos objeto \holed?\ tal que
$$
\holed? \of f = f = f \of \holed?
$$
para toda funcção $f$.

%%}}}

\spoiler

%%{{{ x: id_compose_practice 
\exercise.
%%%{{{ meta 
\label id_compose_practice
%%%}}}

Sejam $A,B$ conjuntos diferentes, e $f : A \to B$.
Para cada uma das igualdades abaixo,
decida se ela é válida ou não, justificando tua resposta.
$$
\xalignat4
(1)\quad f &= {f \compose \idof A}; &
(2)\quad f &= {f \compose \idof B}; &
(3)\quad f &= {\idof A \compose f}; &
(4)\quad f &= {\idof B \compose f}.
\endxalignat
$$

\solution
\noi (1)
Válida: a composição é definida, e se $a\in A$ então:
\compute
(f \of \idof A)(a)
&= f(\idof A (a))  \by {def.~$f\of\idof A$} \\
&= f(a).           \by {def.~$\idof A$} \\
\endcompute
\eop
\noi (2) e (3): as composições não são definidas
\eop
\noi (4) Similar com (1): a composição é definida e se $a \in A$ então:
\compute
(\idof B \of f)(a)
&= \idof B (f(a))  \by {def.~$\idof B\of f$} \\
&= f(a).           \by {def.~$\idof B$} \\
\endcompute

%%}}}

%%{{{ thm: fcom_identity_laws  
\theorem Leis de identidade.
%%%{{{ meta 
\label fcom_identity_laws
%%%}}}

Para todo conjunto $A$,
existe unica funcção $\idof A : A \to A$ tal que:
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \idof A = f; \\
\text{para toda $f : B \to A$},&\quad \idof A \of f = f.
\endalign
$$

\sketch.
Primeiramente verificamos que a identidade do $A$ (\ref[identity_function])
que ``coincidentalmente'' denotamos por $\idof A$ realmente satisfaz tudo isso.
Depois mostramos que qualquer outra possível funcção $\idof A'$
com essas propriedades deve ser (igual) {\paraccenta à} própria $\idof A$.

\proof.
Observe que dado conjunto $A$, a $\idof A$ tem o domínio e codomínio certo.
Basta então verificar que ela tem as propriedades (i)--(ii) e que ela é única.
\crproofpart{$\idof A$ tem a primeira propriedade.}
Seja $f : A \to B$.
Preciso mostrar que $f \of \idof A = f$.
Primeiramente verifico que têm o mesmo domínio e---para satisfazer
até os categoristas---o mesmo codomínio:
$$
\align
\dom (f\of\idof A) &= \dom(\idof A) = A = \dom f; \\
\cod (f\of\idof A) &= \cod f.
\endalign
$$
Basta ver se tem o mesmo comportamento.
Seja $x\in A$ então, e calcule:
\compute
(f \of \idof A) x
&= f(\idof A x) \by {def.~$f \of \idof A$} \\
&= f(x).        \by {def.~$\idof A$} \\
\endcompute
\proofpart{$\idof A$ tem a segunda propriedade.}
Similar.
\crproofpart{$\idof A$ é única.}
Seja $\idof A' : A \to A$ funcção tal que
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \idof A' = f; \\
\text{para toda $f : B \to A$},&\quad \idof A' \of f = f.
\endalign
$$
Preciso mostrar que $\idof A = \idof A'$.
Calculamos:
\compute
\idof A
&= \idof A \of \idof A'  \by {primeira propriedade da $\idof A'$ com $f \asseq \idof A$} \\
&= \idof A'.             \by {segunda propriedade da $\idof A$ com $f \asseq \idof A'$} \\
\endcompute

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Terminamos essa secção sobre composição com mais uma definição
interessante e uns exercícios para praticar.

%%}}}

%%{{{ df: idempotent_function 
\definition Idempotente.
%%%{{{ meta 
\label idempotent_function
\indexes
    * idempotente!funcção    see: funcção idempotente
    ;;
\defines
    * funcção!idempotente
    ;;
%%%}}}

Seja $f : A \to A$ um endomapa.
Chamamos a $f$ \dterm{idempotente} sse
$$
f \of f = f.
$$

%%}}}

%%{{{ x: how_many_idempotents_on_AtoA_for_A_triset 
\exercise.
%%%{{{ meta 
\label how_many_idempotents_on_AtoA_for_A_triset
%%%}}}

Seja $A$ conjunto com $\card A = 3$.
Quantas funcções idempotentes podemos definir no $A$?

\hint
Use um diagrama interno para endomapas!

\hint
Observe que em geral, aparecem certos ``redemoinhos''
num diagrama interno de endomapa quando ela é idempotente.

\hint
Separe as funcções idempotentes dependendo na quantidade
de ``redemoinhos'' que aparecem nos seus diagramas.

\solution
Vamos tentar definir uma $f$ idempotente e contar as escolhas que temos.
Observe que assim que mandamos um $x \mapsto y$, o $f(y)$ ``não tem mais
escolha'': precisa ser $f(y) = y$, pois $f$ deve ser idempotente.
Ou seja, $y$ vai ser um \dterm{ponto fixo} (ou \dterm{fixpoint}) da $f$
(mais sobre isso na~\reftag[Fixpoints]).
A $f$ então deve ter pelo menos $1$ fixpoint, e no máximo $\card A = 3$.
Separamos então por casos, contamos as maneiras em cada caso e usamos
o Princípio da adição~(\reftag[principle_of_addition]) para contar
quantidade total das maneiras.
Defina então
$$
F_i \defeq \setstt {f : A \to A} {$f$ tem exatamente $i$ fixpoints}.
$$
Queremos achar o $\card{F_1} + \card{F_2} + \card{F_3}$.
Calculamos separadamente.:
\eop
\proofpart{Quantas funcções no $F_1$?}
Temos $3$ funcções, uma para cada escolha de fixpoint, pois
assim que determinamos o único fixpoint, todos os outros membros
devem ser mapeados nele.
\eop
\proofpart{Quantas funcções no $F_2$?}
Temos $\comb 3 2 = 3$ maneiras de escolher $2$ dos membros de $A$ para ser
os fixpoints da $f$.  Para cada uma dessas escolhas, temos $2$ opções para
o não-fixpoint (escolher em qual dos dois fixpoints vamos mandá-lo).
Pelo Princípio da multiplicação~(\reftag[principle_of_multiplication]) então
temos $3\ntimes 2 = 6$ funcções no $F_2$.
\eop
\proofpart{Quantas funcções no $F_3$?}
Apenas uma: a identidade.
\eop
Finalmente podemos responder: existem $3 + 6 + 1 = 10$ funcções idempotentes
num conjunto de cardinalidade $3$.

%%}}}

%%{{{ x: constant_implies_idempotent 
\exercise.
%%%{{{ meta 
\label constant_implies_idempotent
%%%}}}

Seja $f : A \to A$.
Demonstre ou refute a implicação:
$$
\text{$f$ constante}
\implies
\text{$f$ idempotente}.
$$

\hint
A implicação é válida.
Demonstre!

\solution
Vamos demonstrar a implicação.
Suponha que $f : A\to A$ é constante.
Caso $A=\emptyset$ a $f$ é a funcção vazia e a $f\of f$ também.
Caso $A\neq\emptyset$, usamos a definição alternativa
da~\ref[constant_function_definitions_almost_agree].
Seja $c\in A$ tal que para todo $x\in A$, $f(x) = c$\fact1.
Queremos mostrar que $f\of f = f$, ou seja, que para todo $a\in A$,
$$(f\of f)(a) = f(a)$$
(definição de igualdade de funcções~\reftag[f_eq_g]).
Calculamos no lado esquerdo:
\compute
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$\fcom$} \\
&= f(c)            \by {pelo \byfact1, com $x \asseq a$} \\
&= c               \by {pelo \byfact1, com $x \asseq c$} \\
\intertext{e no lado direito:}
f(a)
&= c.              \by {pelo \byfact1, com $x \asseq a$} \\
\intertext{Logo, $f \of f = f$ como desejamos.
\eop
Alternativamente, podemos nos livrar dum passo no calculo do lado esquerdo assim:
}
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$\fcom$} \\
&= c.              \by {pelo \byfact1, com $x \asseq f(a)$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Iterations 
\section Iterações.
%%%{{{ meta 
\label Iterations
%%%}}}

%%{{{ df: function_iterations 
\definition iterações.
%%%{{{ meta 
\label function_iterations
\defines
    * ~f^~n  -- a $n$-ésima iteração da $f$.
    * funcção!iteração
    ;;
%%%}}}

Seja $f : A \to A$.
Definimos as \dterm{iterações} de $f$ pela recursão
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f\of f^n.
\endalign
$$

%%}}}

%%{{{ eg: calculate_iterate_3_fx 
\example.
%%%{{{ meta 
%%%}}}

Seja $f : A \to A$.  Calculamos:
\compute
f^3(x)
&= (f \of f^2)(x)                      \by {def.~$f^3$} \\
&= (f \of (f \of f^1))(x)              \by {def.~$f^2$} \\
&= (f \of (f \of (f \of f^0)))(x)      \by {def.~$f^1$} \\
&= (f \of (f \of (f \of \idof A)))(x)  \by {def.~$f^0$} \\
&\dotseq (f \of f \of f)(x)            \by {ass.~$\of$; lei da~$\idof A$} \\
&\dotseq f (f (f (x)))                 \by {def.~$\of$} \\
\endcompute
Em geral omitimos parenteses quando a expressão envolve apenas uma operação
associativa;
botamos aqui para enfatizar cada aplicação de definição nesse cálculo.

%%}}}

%%{{{ x: succ3_is_plus_3 
\exercise.
%%%{{{ meta 
\label succ3_is_plus_3
%%%}}}

Como definarias numa maneira simples a funcção $\succ^3$ para alguém
que não sabe (e sequer quer saber) o que são as iterações duma funcção?

\solution
Temos $\succ^3 = \lam x {x+3} \eqtype \nats\to\nats$.

%%}}}

%%{{{ beware: notation of functions with exponents 
\beware.
%%%{{{ meta 
%%%}}}

Em certos textos de matemática, aparece a notação $f^n(x)$ como
sinónimo de $(f(x))^n$.
Por exemplo:
$$
\text{quem escreveu\dots}
\quad
\sin^2 x + \cos^2 x
\quad
\aligned
&\text{\dots quis dizer\dots}\\
&\text{\dots mas aqui seria\dots}
\endaligned
\quad
\aligned
&(\sin x)^2   + (\cos x)^2    \\
&\sin(\sin x) + \cos(\cos x).
\endaligned
$$

%%}}}

%%{{{ remark: function_iterations_altdef 
\remark.
%%%{{{ meta 
\label function_iterations_altdef
%%%}}}

Poderiamos ter escolhido definir as potências de $f$ pelas:
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f^n \of f
\endalign
$$
em vez da recursão que usamos na~\ref[function_iterations].
As duas definições são equivalentes, ou seja, as duas operações
de exponenciação definidas são iguais.
Por enquanto pode aceitar isso como um fato que vamos demonstrar
depois (\ref[associative_with_identity_exp_defs_equiv]),
ou esquecer completamente essa definição alternativa.

%%}}}

%%{{{ thm: properties_of_function_iterations 
\theorem.
%%%{{{ meta 
\label properties_of_function_iterations
%%%}}}

A operação de iteração que definimos
no~\ref[function_iterations]
nos endomapas dum conjunto $A$ satisfaz as leis:
% TODO: fix reflabs
\tlist:
\li (1): $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m+n}        = a^m \of a^n}$;
\li (2): $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m\ntimes n} = (a^m)^n}$;
\li (3): $\lforall {n\in\nats} {\id^n = \id}$.
\endtlist

\proof Já demonstrado.
Demonstramos por indução as três leis nos exercícios~\reftag[law_of_natexp_1],
\reftag[law_of_natexp_2], e~\reftag[law_of_natexp_3]---se tu não resolveu,
volte a resolver!
Verifique que nossas demonstrações precisaram apenas a \emph{associatividade}
e a \emph{identidade} da multiplicação e \emph{nada da sua definição},
então podemos substituir a multiplicação por nossa $\of$.
Sobre a outra operação envolvida nas provas, a adição, não precisamos
verificar nada, pois nos dois casos é a mesma operação:
a adição nos naturais.

%%}}}

\endsection
%%}}}

%%{{{ Fixpoints 
\section Fixpoints.
%%%{{{ meta 
\label Fixpoints
%%%}}}

%%{{{ df: fixpoint 
\definition Fixpoint.
%%%{{{ meta 
\label fixpoint
\indexes
    * funcção!fixpoint    see: fixpoint
    ;;
\defines
    * fixpoint
    ;;
%%%}}}

Seja $f : A \to A$ um endomapa num conjunto $A$.
Chamamos \dterm{fixpoint} da $f$ qualquer $x\in A$ tal que
$f(x) = x$.
Com palavras de rua,
$$
\text{$x$ é um fixpoint de $f$}
\heartiff
\text{$f$ deixa $x$ em paz}.
$$

%%}}}

%%{{{ eg: fixpoints_of_identities 
\example.
%%%{{{ meta 
\label fixpoints_of_identities
%%%}}}

Para qualquer conjunto $A$, todos os seus membros são
pontos fixos da $\idof A$.

%%}}}

%%{{{ noneg: succ and mother 
\nonexample.
%%%{{{ meta 
%%%}}}

No outro extremo, nem a $\succ : \nats\to\nats$ possui fixpoints,
nem a $\mother : \persons\to\persons$---o que seria
um fixpoint da $\mother$?

%%}}}

%%{{{ eg: fixpoints_of_sin 
\example trigonometria.
%%%{{{ meta 
\label fixpoints_of_sin
%%%}}}

$0$ é um fixpoint da $\sin$---tem outros?  E a $\cos$?

%%}}}

%%{{{ eg: fixpoints_of_square 
\example.
%%%{{{ meta 
\label fixpoints_of_square
%%%}}}

A $\square = \lam x {x^2} : \ints\to\ints$
possui dois fixpoints: o $0$ e o $1$.

%%}}}

%%{{{ remark: how fixpoints look like internally 
\remark.
%%%{{{ meta 
%%%}}}

Olhando para o diagrama interno dum endomapa (\reftag[diagram_of_endomap])
os fixpoints são os ``redemoinhos''
$
\tikzpicture[>=stealth, scale=0.5]
\node (dot-h) at (0 , 0.2 ) {};
\node (dot) at (0 , 0   ) {$\bullet$};
\draw[->] (dot-h) arc (10:290:0.25);
\endtikzpicture
$.

%%}}}

%%{{{ x: exact_number_of_fixpoints_challenge 
\exercise.
%%%{{{ meta 
\label exact_number_of_fixpoints_challenge
%%%}}}

Seja $d\in\nats$.
Defina uma funcção $f : \nats\to\nats$ com exatamente
$d$ fixpoints.

\hint
Isso é mais um exercício pra ver se tu consegue definir
funcções do que em fixpoints.

\solution
Seja $f : \nats \to \nats$
definida pela
$$
f(n) =
\knuthcases {
n,   &se $n\in D$;\cr
n+1, &caso contrário.
}
$$
onde $D \asseq \set{0,\dots,d}$.

%%}}}

%%{{{ teaser: fixpoints_teaser 
\teaser.
%%%{{{ meta 
\label fixpoints_teaser
%%%}}}

OK, eu sei: parece estranho dedicar uma secção só pra isso.
Mas os fixpoints vão fazer um papel importantíssimo depois,
e queria destacá-los desde já.
(Mentira: não um.  Muitos!)

%%}}}

\TODO Elaborar e adicionar secções específicas.

\endsection
%%}}}

%%{{{ Commutative_diagrams 
\section Diagramas comutativos.
%%%{{{ meta 
\label Commutative_diagrams
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Começamos com uma definição complicada; leia agora, mas veja logo os exemplos
seguintes.

%%}}}

%%{{{ pseudodf: commutative_diagram 
\pseudodefinition diagrama comutativo.
%%%{{{ meta 
\label commutative_diagram
\defines
    * diagrama!comutativo
    ;;
%%%}}}

Digamos que um diagrama externo de funcções \dterm{comuta} ou que é um
\dterm{diagrama comutativo} sse: para todo par de ``caminhos'' feitos
por seguindo setas, \emph{se pelo menos um dos dois caminhos tem tamanho
maior que $1$}, então os dois caminhos são iguais.

%%}}}

%%{{{ eg: triangle 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[dr, "h"'] \| B \ar[d, "g"] \\
                             \| C
\endcd
$$
Significa que $h = g\of f$.

%%}}}

%%{{{ eg: square 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "h"'] \| B \ar[d, "g"] \\
D   \ar[r, "k"]             \| C
\endcd
$$
Significa que $g\of f  = k\of h$

%%}}}

%%{{{ eg: cd_example_line 
\example.
%%%{{{ meta 
\label cd_example_line
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
Significa que $f\of g  = f\of h$.

%%}}}

%%{{{ beware: at least one path must have length greater than 1 
\beware.
%%%{{{ meta 
%%%}}}

Graças à parte enfatizada na~\ref[commutative_diagram], \emph{não podemos}
concluir no~\ref[cd_example_line] que $g = h$, pois mesmo que
existem esses dois caminhos de $A$ para $B$ (um seguindo a seta $g$, outro
seguindo a seta $h$), nenhum deles tem tamanho maior que 1.

%%}}}

%%{{{ eg: part of diagram commutes 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o rectângulo no diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "k"'] \| B \ar[d, "g"]  \ar[dr, "i"] \\
D                           \| C \ar[l, "h"'] \ar[r, "j"] \| D 
\endcd
$$
Apenas que $h \of g \of f = k$.
Observe que isso não nos permite concluir nada especial sobre as
setas~$i$ e~$j$ do triângulo.  Se soubéssemos que o diagrama
comuta (e não apénas seu rectângulo), poderiamos concluir
que $i = j\of g$ também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Afirmando a comutatividade de certos diagramas vira uma maneira curta de
afirmar proposições, como por exemplo essas duas leis que já encontramos
na~\reftag[Composition_laws].

%%}}}

%%{{{ eg: cd_associativity_law 
\example.
%%%{{{ meta 
\label cd_associativity_law
%%%}}}

Afirme a lei da associatividade da~\reftag[Composition_laws]
usando a comutatividade dum diagrama.

\solution.
Sejam $A\toby f B \toby g C \toby h D$.
Basta desenhar um diagrama cuja comutatividade quis dizer
$h \of (g \of f) = (h \of g) \of f$.
É o seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rr, bend left=30,  "g\of f"] \|
B   \ar[r, "g"]\ar[rr, bend right=30, "h\of g"'] \|
C   \ar[r, "h"] \|
D
\endcd
$$
Outra maneira para desenhar o mesmo diagrama seria a seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rd, "g\of f"'] \| B \ar[d, "g"]  \ar[dr, "h\of g"] \\
                                  \| C \ar[r, "h"']      \| D
\endcd
$$
Questão de gosto.

%%}}}

%%{{{ x: cd_id_laws 
\exercise.
%%%{{{ meta 
\label cd_id_laws
%%%}}}

Como podemos expressar as leis da identidade (\ref[Composition_laws])
usando apenas a comutatividade dum diagrama?

\hint
Use uma $f : A \to B$, e as identidades $\idof A,\idof B$.

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "f"']\ar[r, "\idof A"] \| A \ar[d, "f"]  \ar[dr, "f"]   \\
                                   \| B \ar[r, "\idof B"'] \| B
\endcd
$$

%%}}}

%%{{{ x: cd_copy_paste 
\exercise.
%%%{{{ meta 
\label cd_copy_paste
%%%}}}

Suponha que os quadrados no diagrama seguinte comutam:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
Demonstre que o rectângulo grande também comuta.

\solution
Temos que os quadrados do
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
comutam.
Precisamos demonstrar que o rectângulo também comuta, ou seja, que
\compute
k \of g \of f &= t \of s \of i.
\intertext{Calculamos:}
k \of g \of f
&= (k \of g) \of f   \by {assoc.~da~$\of$} \\
&= (t \of j) \of f   \by {comut.~do quad.~direito} \\
&= t \of (j \of f)   \by {assoc.~da~$\of$} \\
&= t \of (s \of i)   \by {comut.~do quad.~esquerdo} \\
&= t \of s \of i.    \by {assoc.~da~$\of$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Products_and_more_constructions 
\section Produtos e demais construções.
%%%{{{ meta 
\label Products_and_more_constructions
%%%}}}

%%{{{ df: fcross 
\definition cross.
%%%{{{ meta 
\label fcross
\defines
    * ~f \times ~g  -- a funcção-produto das $f,g$
    * funcção!cross
    * funcção!produto
    ;;
%%%}}}

Sejam
$$
\gather
A \longtoby f C\\
B \longtoby g D
\endgather
$$
Chamamos \dterm{funcção-produto das $f,g$},
que denotamos por $f \cross g$,
a funcção
$$
A \times B \longtoby {f\cross g} C \times D
$$
definida pela
$$
(f \cross g)(x,y) = \tup{f(x), g(y)}.
$$
Pronunciamos \utter{$f$ cross $g$}.

%%}}}

%%{{{ x: fcross_commutative_diagram 
\exercise.
%%%{{{ meta 
\label fcross_commutative_diagram
%%%}}}

Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']   \|  A\times B \ar[l, dash, ""]\ar[r, dash, ""]\ar[d, dotted, ""]   \| B \ar[d, "g"]  \\
C                \|  C\times D \ar[l, dash, ""]\ar[r, dash, ""]                     \| D
\endcd
$$

\solution
Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']   \|  A\times B \ar[l, "\outl"]\ar[r, "\outr"]\ar[d, dotted, ""]   \| B \ar[d, "g"]  \\
C                \|  C\times D \ar[l, ""]\ar[r, dash, ""]                     \| D
\endcd
$$


%%}}}

%%{{{ remark: commutative_diagrams_as_puzzles 
\remark Um puzzle.
%%%{{{ meta 
\label commutative_diagrams_as_puzzles
%%%}}}

Vamos fazer um ``rewind'' no momento exatamente antes de
definir nossa funcção de $A \cross B$ para $C \cross D$.
O diagrama parece como no~\ref[fcross_commutative_diagram],
exceto sem a setinha pontilhada no meio.
E esse é o ``missing piece'' do nosso puzzle.
Procuramos então achar uma \emph{seta} que é \dterm{legal}.
O que significa ``legal'' aqui?
\emph{Uma seta que faz o diagrama comutar!}

%%}}}

%%{{{ x: fcross_practise 
\exercise.
%%%{{{ meta 
\label fcross_pratise
%%%}}}

Para qualquer uma das expressões seguintes, calcule seu valor quando tiver.
$$
\xalignat2
(\sin \cross \cos) (\pi)        &= &
(\outl \cross \succ) (5, 6)     &= \\
(\sin \cross \cos) (\pi/2, \pi) &= &
(\idof\nats \cross \succ) (0,1) &= 
\endxalignat
$$
Pode ser que umas delas tem type errors, e logo nenhum valor.

%%}}}

%%{{{ x: fcross_is_total 
\exercise.
%%%{{{ meta 
\label fcross_is_total
%%%}}}

O operador binário $(\dhole\cross\dhole)$ nas funcções
que definimos no~\ref[fcross], é um operador total?

\solution
Sim.
A gente não necessitou nenhuma propriedade especial
sobre nossas funcções $f,g$ na definição.

%%}}}

%%{{{ df: fpair 
\definition pair.
%%%{{{ meta 
\label fpair
\defines
    * \fpair {~f} {~g}  -- a funcção-par $f$ ``pair'' $g$
    * funcção!par
    ;;
%%%}}}

Sejam
$$
A \longfromby f D \longtoby g B
$$
Chamamos \dterm{funcção-par da $f$ ``pair'' $g$},
que denotamos por $\fpair f g$,
a funcção
$$
D \longtoby {\fpair f g} A\times B
$$
definida pela
$$
\fpair f g (x) = \tup{f(x), g(x)}.
$$

%%}}}

%%{{{ x: fpair_commutative_diagram 
\exercise.
%%%{{{ meta 
\label fpair_commutative_diagram
%%%}}}

Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \| A\times B \ar[l, dash, ""]\ar[r, dash, ""] \| B \\
  \| D\ar[u, dotted, ""]\ar[ul, "f"]\ar[ur, "g"']
\endcd
$$

%%}}}

%%{{{ Q: Can you define the pointwise operation function? 
\question.
%%%{{{ meta 
%%%}}}

Dadas $f,g : A \to B$, e sabendo que no $B$ é definida uma operação
binária $\ast : B^2 \to B$, qual funcção interessante tu podes definir
de $A$ para $B$?  Qual notação tu gostaria de usar pra ela?

%%}}}

\spoiler

%%{{{ df: pointwise_operation 
\definition pointwise.
%%%{{{ meta 
\label pointwise_operation
\indexes
    * funcção!pointwise operação    see: pointwise
    ;;
\defines
    * pointwise!operação
    ;;
%%%}}}

Sejam $A,B$ conjuntos e $\ast$ uma operação binária no $B$.
Dadas funcções $f,g : A \to B$, definimos a funcção
$f \ast g : A \to B$
pela
$$
(f \ast g)(x) = f(x) \ast g(x) , \qquad \text{para todo $x\in A$}.
$$
Chamamos a $(\dhole \ast \dhole)$ a \dterm{operação pointwise}
da $\ast$ no conjunto $\funs A B$.

%%}}}

%%{{{ note: pointwise_operation_outside_the_forest 
\note Uma outra maneira de se inspirar.
%%%{{{ meta 
\label pointwise_operation_outside_the_forest
%%%}}}

Se tu realmente tentou responder na pergunta acima, provavelmente
tu chegou nessa mesma definição.  Uma maneira de chegar nela é
realmente ``entrar na floresta'', e começar brincar com as arvores,
ate achar o que tu ta procurando.
Uma outra abordagem seria observar a floresta de longe, por fora.
Desenhar as setas que tu tens, e ver o que tu podes fazer
interessante com elas; pra onde elas te guiam.
Nesse caso temos $f, g : A \to B$, e também a $\ast : B^2 \to B$.
Nosso desafio é definir uma funcção \emph{interessante}
$\alert ? : A \to B$.\foot
Claramente não é o desafio mais claro que tu já viu na vida,
mas isso faz parte do próprio desafio!
\toof
Desenhamos então:
$$
\phantom{A \longtoby ? {}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B.
$$
O que \emph{interessante} podemos definir agora?
Com certeza uma composição tem chances boas de ser interessante,
só que aqui a
$$
\ast \of \pfcross f g : A \cross A \longto B
$$
não tem o tipo desejado $A\to B$.
Agora podemos desistir dessa abordagem e entrar na floresta mesmo
para brincar com as arvores; \emph{ou podemos perceber que talvez
falta apenas uma setinha para nos ajudar}.
Se a gente tivesse uma setinha interessante assim:
$$
A \alert{{}\longtoby ?{}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B,
$$
a gente teria um candidato ótimo para algo interessante, pois
assim a composição de todas essas setinhas tem o tipo desejado.
Basta definir uma funcção interessante então de $A$ para $A\cross A$
e assim ganhar a
$$
A \xlongtoby {\ast \of \pfcross f g \of \alert ?} B.
$$

%%}}}

%%{{{ x: discover_diagonalizer 
\exercise.
%%%{{{ meta 
\label discover_diagonalizer
%%%}}}

Dado conjunto $A$, define uma funcção interessante de $A$ para $A \cross A$.
Começa descrevendo sua alma com um $\lambda$; consegue defini-la sem
descrever explicitamente o seu comportamento?

\solution
Usando $\lambda$, a funcção que procuramos é a seguinte:
$$
A \longtoby {\lam x {\tup{x,x}}} A \cross A.
$$
Essa funcção é a $\fpair {\idof A} {\idof A}$.

%%}}}

%%{{{ x: pointwise_operation_two_paths_to_solution_same_or_not 
\exercise.
%%%{{{ meta 
\label pointwise_operation_two_paths_to_solution_same_or_not
%%%}}}

Verifique se as duas funcções definidas na~\ref[pointwise_operation]
e no fim do~\ref[pointwise_operation_outside_the_forest]
(com o~\ref[discover_diagonalizer]) são as mesmas.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A funcção que tu definiu no~\ref[discover_diagonalizer] é muito útil
e freqüentemente usada e sim, tem seu próprio nome e sua própria notação:

%%}}}

%%{{{ df: diagonal_function 
\definition Funcção diagonal.
%%%{{{ meta 
\label diagonal_function
\defines
    * \diagdom {~A}  -- a funcção diagonal do $A$
    * \diag  -- a funcção diagonal do conjunto implicito pelo contexto
    * funcção!diagonal
    ;;
%%%}}}

Seja $A$ conjunto.
Definimos sua \dterm{funcção diagonal} $\diagdom A : A \to A \times A$
pela
$$
\diagdom A (x) = \tup{x,x}.
$$
Equivalentemente:
$$
\diagdom A \defeq \fpair {\idof A} {\idof A}.
$$
Quando o conjunto $A$ é implícito pelo contexto escrevemos apenas $\diag$.

%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Com o que já temos na nossa disposição podemos definir umas funcções
interessantes apenas usando composições, e \emph{diretamente} definindo
a funcção (sem utilizar um ponto do seu domínio nem a $\lambda$-notação).
Vamos investigar isso no~\ref[Pointfree_style].

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: succiter_for_dummies 
\problem.
%%%{{{ meta 
\label succiter_for_dummies
%%%}}}

Supondo que teu leitor não sabe o que são as iterações duma funcção
(\ref[function_iterations]) e que \emph{sequer quer saber},
defina a funcção $\succ^n$ numa maneira simples.
Demonstre tua afirmação, que a $\succ^n$ (oficial) realmente é igual
à funcção que tu escreveste para teu leitor.

\hint
Fez o~\ref[succ3_is_plus_3] né?

\hint
Basta demonstrar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
e como $\succ^n$ (oficial) foi definida recursivamente,
como tu vai demonstrar isso?

\hint
Indução!

\solution
Seja $n\in\nats$.
A $\succ^n : \nats\to\nats$ é a funcção definida pela
$$
\succ^n(x) = x + n.
$$
Basta demonstrar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
algo que vou demonstrar por indução no $n$.
\crproofpart{Base.}
Seja $x\in\nats$.
Calculamos:
\compute
\succ^0 (x)
&= \idof\nats (x)   \by {pela def.~da $\succ^0$} \\
&= x                \by {pela def.~da $1_A$} \\
&= x + 0.           \by {pelo ensino fundamental} \\
\endcompute
\crproofpart{Passo indutivo.}
Suponha $k\in\nats$ tal que
$$
\lforall {x\in\nats} {\succ^k(x) = x + k}. \tag{H.I.}
$$
Basta demonstrar que
$$
\lforall {y\in\nats} {\succ^{k+1}(y) = y + (k+1)}.
$$
Seja $y\in\nats$ então.
Calculamos:
\compute
\succ^{k+1}(y)
&= \paren{\succ\of\succ^{k}}(y) \by {pela def.~de $\succ^{k+1}$} \\
&= \succ\big( \succ^k(y) \big)  \by {pela def.~de $\succ\of \succ^k$} \\
&= \succ(y + k)                 \by {pela HI com $x := y$} \\
&= (y + k) + 1                  \by {pela def.~de $\succ$} \\
&= y + (k + 1).                 \by {pelo ensino fundamental} \\
\endcompute

%%}}}

%%{{{ prob: how_many_idempotents_on_AtoA_for_A_finite 
\problem.
%%%{{{ meta 
\label how_many_idempotents_on_AtoA_for_A_finite
%%%}}}

Generalize o~\ref[how_many_idempotents_on_AtoA_for_A_triset] para
um arbitrário conjunto finito $A$.

\hint
Seja $n = \card A$.

%%}}}

%%{{{ prob: constant_function_why_did_we_omit_unique 
\problem.
%%%{{{ meta 
\label constant_function_why_did_we_omit_unique
%%%}}}

Na definição do~\ref[constant_notiff_steady]
não escrevemos ``existe único'', mas apenas ``existe''.
O que mudaria com esse ``único''?
Demonstre tua afirmação.

\hint
Lembra se que a definição é apenas aplicável numa \emph{funcção}.
Mas cuidado com os casos especiais que envolvem o $\emptyset$.

\solution
\emph{Quase} nada!
Parece ser redundante, pois a definição é aplicável numa \emph{funcção}
e graças à determinabilidade sabemos que se existe, tem que ser
único---mas!
Vamos tentar demonstrar para achar algo interessante.
\eop
Suponha que temos $b,b'\in B$ que satisfazem a condição, ou seja,
temos:
$$
\align
\text{para todo $x \in A$,}& f(x) = b \\
\text{para todo $x \in A$,}& f(x) = b'
\endalign
$$
Logo tomando um $x\in A$, temos
$$
b = f(x) = b',
$$
ou seja, unicidade mesmo desse $b$,
dado qualquer $x\in A$.
Mas isso é, supondo que $A\neq\emptyset$.
O que acontece se $A=\emptyset$ e $B\neq\emptyset$?
Botando esse ``único'' na definição, uma funcção
$$
\emptyset\toby f B
$$
vai ser constante com valor $b$ sse $B$ é um singleton
e $b$ é seu único membro.
Sem o ``único'', ela vai ser constante sse $B\neq\emptyset$.
Veja também o exercício 

%}}}

%%{{{ prob: first_contact_with_initial_and_terminal_objects 
\problem Objetos iniciais e terminais.
%%%{{{ meta 
\label first_contact_with_initial_and_terminal_objects
%%%}}}

(1) Quais conjuntos $S$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única funcção $f:S \to A$.}
$$
(2) Quais conjuntos $T$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única funcção $f:A \to T$.}
$$

\solution
(1) Apenas o conjunto vazio:
a única funcção que existe de $\emptyset$ para $A$,
é a funcção vazia.
Se $S \neq \emptyset$ tome $s\in S$ e considere
o conjunto $A = \set{0,1}$.
Já temos duas funcções diferentes $f,g : S \to A$:
basta apenas diferenciar elas no $s$.
Tome por exemplo $f = \lam x 0$ e $g = \lam x 1$.
Como $f(s) = 0 \neq 1 = g(s)$, temos $f\neq g$.
(2) Todos os singletons.
Se $T = \emptyset$, tome $A\neq\emptyset$ e observe
que não existe nenhuma funcção $f : A \to T$.
E se $\card T > 1$, tome $u,v\in T$ com $u\neq v$
e considere o $A = \set 0$.
Já temos duas funcções $f,g : A \set T$:
a $f = \lam x u$ e a $g = \lam x v$.
Elas são realmente distintas,
pois $f(0) = u \neq v = g(0)$, e logo $f\neq g$.

%%}}}

%%{{{ prob: funion 
\problem união de funcções.
%%%{{{ meta 
\label funion
%%%}}}

Sejam $f : A \to C$ e $g : B \to D$.
Queremos definir a $f\union g : A\union B \to C\union D$,
consultando as $f$ e $g$, numa maneira parecida com aquela da
definição de $f\cross g$ (\reftag[fcross]).
Uma definição razoável deve fazer o diagrama seguinte comutar:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']\ar[r, hook] \| A\union B \ar[d, dashed, ""] \| B \ar[l,hook']\ar[d, "g"] \\
C \ar[r,hook]              \| C\union D                    \| D \ar[l,hook']
\endcd
$$
Explique quais são as condições necessárias para definir
a $f\union g$, e defina-a.

\solution
Chame as $f$ e $g$ \dterm{compatíveis} sse:
$$
\text{para todo $x\in\dom f \inter \dom g$, $f(x) = g(x)$}.
$$
Agora dadas compatíveis $f : A \to C$ e $g : B \to D$,
definimos a $f \union g : A\union B \to C\union D$ pela
$$
(f \union g)(x) =
\knuthcases {
f(x), & se $x \in A$ \cr
g(x), & se $x \in B$.
}
$$
Equivalentemente, podemos definir a $f\union g$ definindo seu gráfico:
$$
\graph (f\union g) \defeq \graph f \union \graph g.
$$
Observe que nas duas maneiras precisamos a condição de
compatibilidade para a $f\union g$ ser bem-definida.
\crproofalt{Resolução alternativa:}
Usamos a mesma definição mas exigimos que os $A,C$ são disjuntos.
A primeira resolução consegue definir a $f \union g$ em mais casos
que essa, mas no outro lado, essa seria aceitável também; e é mais
simples e ``arrumada''.

%%}}}

%%{{{ prob: fixpoints_of_different_square 
\problem.
%%%{{{ meta 
\label fixpoints_of_different_square
%%%}}}

Tem como mudar o $\ints$ do~\ref[fixpoints_of_square] para outro
conjunto $X$ de números, tal que tua $\square : X \to X$ terá mais
que dois fixpoints?

\hint
Tem sim.

\hint
Esqueceu o~\ref[The_integers]?

\hint
Use um dos $\intsmod n$'s.

\solution
A $\square : \intsmod 6 \to \intsmod 6$, por exemplo, tem quatro fixpoints: $0,1,3,4$.

%%}}}

%%{{{ prob: fixpoint_iff_iterations 
\problem.
%%%{{{ meta 
\label fixpoint_iff_iterations
%%%}}}

Seja $f : A\to A$.
Demonstre a afirmação:
$$
\text{$x$ é um fixpoint da $f$}
\iff
\text{para todo $n\in\nats$, $x$ é um fixpoint da $f^n$}.
$$

\hint
A {\rldir} é muito fácil; para a {\lrdir} use indução.

\solution
\proofpart{\lrdir}:
Suponha $x$ é um fixpoint da $f$.
Vamos demonstrar o que precisamos por indução no $n$.
\proofpart{Base:}
Calculamos:
\compute
f^0 (x)
&= 1_A (x)  \by {pela def.~da $f^0$} \\
&= x        \by {pela def.~da $1_A$} \\
\endcompute
e logo $x$ é um fixpoint da $f^0$.
\proofpart{Passo indutivo:}
Suponha $k\in\nats$ tal que $x$ é um fixpoint da $f^k$ (H.I.).
Calculamos:
\compute
f^{k+1}(x)
&= (f \of f^k)(x)   \by {pela def.~de $f^{k+1}$} \\
&= f\paren{f^k(x)}  \by {pela def.~de $f\of f^k$} \\
&= f( x )           \by {pois $x$ é um fixpoint da $f^k$ (H.I.)} \\
&= x                \by {pois $x$ é um fixpoint da $f$} \\
\endcompute
e logo $x$ é um fixpoint da $f^{k+1}$.
\crproofpart{\rldir}:
Usando nossa hipótese com $n \asseq 1$, temos que $x$ é um fixpoint da $f^1$.
Mas $f^1$ é a própria $f$ (pois $f^1 = f \of f^0 = f \of 1_A = f$)
e logo $x$ é um fixpoint da $f$.

%%}}}

%%{{{ prob: fixpoint_iff_iterations_generalization 
\problem.
%%%{{{ meta 
\label fixpoint_iff_iterations_generalization
%%%}}}

Seja $F \subset \funs A A$ e seja $a \in A$.
Demonstre ou refute a afirmação:
$$
\text{$a$ é um fixpoint de toda $f\in F$}
\iff
\brace{
\gathered
\text{para todo $d\in\nats$ e toda $\vec f \in F^d$}\\
\text{$a$ é um fixpoint da $f_1 \of f_2 \of \dotsb \of f_d$}
\endgathered
}
$$
Como isso se compara com o~\ref[fixpoint_iff_iterations]?

%%}}}

\endproblems
%%}}}

% JECTIONS, INVERSE, SHIFT

%%{{{ Jections : Injections, surjections, bijections 
\section Injecções, sobrejecções, bijecções.
%%%{{{ meta 
\label Jections
%%%}}}

%%{{{ noneg: not_injective 
\nonexample.
%%%{{{ meta 
%%%}}}

Nenhuma dessas funcções é injetora:
$$
\xxalignat3
&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw[|->] (a1) -- (b3);
\draw[|->] (a2) -- (b1);
\draw[|->] (a3) -- (b2);
\draw[|->,color=red] (a4) -- (b4);
\draw[|->,color=red] (a5) -- (b4);
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\node[color=red] (a5) at (0,-1)    {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw[|->,color=red] (a1) -- (b3);
\draw[|->]           (a2) -- (b3);
\draw[|->]           (a3) -- (b3);
\draw[|->,color=red] (a4) -- (b3);
\draw[|->]           (a5) -- (b3);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw[|->,color=red] (a1) -- (b2);
\draw[|->,color=red] (a2) -- (b2);
\draw[|->] (a3) -- (b2);
\draw[|->] (a4) -- (b4);
\draw[|->] (a5) -- (b4);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a2) at (0,.5)    {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Em cada caso \emph{uma} razão é enfatizada com cor.

%%}}}

%%{{{ noneg: not_surjective 
\nonexample.
%%%{{{ meta 
%%%}}}

E aqui nenhuma dessas funcções é sobrejetora:
$$
\xxalignat3
&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$B$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)    {$\bullet$};
\node (a2) at (0,0)       {$\bullet$};
\node (a3) at (0,-.666)   {$\bullet$};
\node (b1) at (3,1)       {$\bullet$};
\node (b2) at (3.2,.333)  {$\bullet$};
\node (b3) at (3.1,-.333) {$\bullet$};
\node (b4) at (2.8,-1)    {$\bullet$};
\draw[|->] (a1) -- (b1);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b3);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$C$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)  {$\bullet$};
\node (a2) at (0,0)     {$\bullet$};
\node (a3) at (0,-.666) {$\bullet$};
\node (b1) at (3,1)     {$\bullet$};
\node (b2) at (2.9,.7)  {$\bullet$};
\node (b3) at (3.1,0.1) {$\bullet$};
\node (b4) at (2.8,-.5) {$\bullet$};
\node (b5) at (3,-1)    {$\bullet$};
\node (b6) at (3.2,-0.8){$\bullet$};
\draw[|->] (a1) -- (b2);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b5);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$\emptyset$};
\draw (3,2.0) node {$D$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (b1) at (3.0,.333)  {$\bullet$};
\node (b2) at (3.0,-.333) {$\bullet$};
\node[color=red] (b2c) at (b2) {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Novamente em cada caso \emph{uma} razão é enfatizada com cor.

%%}}}

%%{{{ Q: how would you define injective and surjective? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias os conceitos de funcção injetora e sobrejetora?

%%}}}

\spoiler

%%{{{ df: jections 
\definition.
%%%{{{ meta 
\label jections
\indexes
    * bijecção    see: funcção bijectiva
    * injecção    see: funcção injectiva
    * sobrejecção    see: funcção sobrejectiva
    ;;
\defines
    * ~f : ~A \bijto ~B  -- $f : A \to B$ bijectiva
    * ~f : ~A \injto ~B  -- $f : A \to B$ injectiva
    * ~f : ~A \surto ~B  -- $f : A \to B$ sobrejectiva
    * funcção!bijectiva
    * funcção!injectiva
    * funcção!sobrecjetiva
    ;;
%%%}}}

Seja $f : A \to B$.
Chamamos a $f$ \dterm{injectiva} (ou \dterm{injetora}) sse
$$
\text{para todo $x,y \in A$, se $f(x) = f(y)$ então $x = y$}.
$$
Chamamos a $f$ \dterm{sobrejectiva} (ou \dterm{sobrejetora}) sse
$$
\text{para todo $b \in B$, existe $a\in A$ tal que $f(a) = b$}.
$$
Chamamos a $f$ \dterm{bijectiva} (ou \dterm{bijetora}, ou \dterm{correspondência}), sse
$f$ é injectiva e sobrejectiva.
Formulamente,
$$
\align
\text{$f$ injectiva}    &\defiff \lforall {x,y \in A} {f(x) = f(y) \implies x = y}; \\
\text{$f$ sobrejectiva} &\defiff \pforall {b \in B} \lexists {a \in A} {f(a) = b}; \\
\text{$f$ bijectiva}    &\defiff \text{$f$ injetora} \mland \text{$f$ sobrejetora}.
\endalign
$$
Usamos as notações
$$
\align
f : A \injto B &\defiff \text{$f:A\to B$ injectiva};\\
f : A \surto B &\defiff \text{$f:A\to B$ sobrejectiva};\\
f : A \bijto B &\defiff \text{$f:A\to B$ bijectiva}.
\endalign
$$
As palavras ``injectiva'', ``sobrejectiva'', e ``bijectiva''
são adjectivos.  Os substantivos correspondentes são os:
\dterm{injecção}, \dterm{sobrejecção}, \dterm{bijecção}.
Dizemos por exemplo que <<$f$ é uma bijecção>>, que significa
que <<$f$ é uma funcção bijectiva>>.

%%}}}

%%{{{ remark: contrapositive of injective 
\remark.
%%%{{{ meta 
\indexes
    * preservar    seealso: respeitar
    * respeitar    seealso: preservar
    * preservar!as distincções
    * respeitar!as distincções
    ;;
%%%}}}

A seguinte afirmação equivalente de $f : A \injto B$ é muito útil:
$$
\text{para todo $x,y \in A$, se $x\neq y$ então $f(x) \neq f(y)$}.
$$
(É a sua contrapositiva.)
Vamos traduzir essa afirmação mais perto ``no nível coração'':
\standout
<<$f$ \dterm{preserva} as distincções do seu domínio.>>
\endstandout
Também digamos que $f$ \dterm{respeita} as distincções.
Assim podemos pensar que uma funcção injetora embute seu domínio
no seu codomínio, criando uma \emph{cópia fiel} dele,
só que com nomes diferentes para seus membros.

%%}}}

%%{{{ remark: Setist vs. Categorist 
\remark Conjuntista \vs Categorista.
%%%{{{ meta 
%%%}}}

Observe que o conjuntista pode realmente se perguntar se uma funcção é
injetora ou não, pois a definição de ser injetora não mexe com o codomínio
da funcção. Mas pra ele, ser sobrejetora ou não, não é uma propriedade
da funcção ``sozinha''; ele afirma que <<a funcção $f$ é \dterm{sobre} o $B$>>,
e é isso que ele quis dizer quando ele afirma
<<a funcção $f : A\to B$ é sobrejetora>>.
Pense na diferença que suas caixas pretas têm:
como decidir se uma caixa preta dum conjuntista é sobrejetora
ou não?  Mas tem como decidir se ela é injetora sim.
Então o ``ser injetora'' é um predicado de aridade $1$ para ambos,
mas o predicado ``ser sobrejetora'' já difere dependendo da fé:
para o categorista tem aridade $1$;
para o conjuntista tem aridade $2$,
o segundo argumento sendo o conjunto $B$ nesse caso.

%%}}}

%%{{{ x: double_or_reverse_string_inj_or_surj 
\exercise.
%%%{{{ meta 
\label double_or_reverse_string_inj_or_surj
%%%}}}

Seja~$S$ o conjunto de todos os strings \emph{não vazios}
dum alfabeto $\Sigma$, com $\card{\Sigma} \geq 2$.
Considere a funcção
$f : S \times \set{0,1} \to S$ definida pela:
$$
f(w,i) =
\knuthcases {
ww, &se $i = 0$\cr
w', &se $i = 1$
}
$$
onde $w'$ é o string reverso de $w$,
e onde denotamos a concatenação de strings por juxtaposição.
(1) A $f$ é injetora?
(2) A $f$ é sobrejetora?

\hint
Quais são o domínio e o codomínio da $f$?

\solution
\proofpart{(1)}
Não, $f$ não é injetora.
Tome uma letra do alfabeto $a\in\Sigma$ e observe que
$$
f(a, 0) = aa = f(aa,1).
$$
Como $(a,0) \neq (aa,1)$, a $f$ não é injetora.
\crproofpart{(2)}
Sim, $f$ é sobrejetora.
Tome um aleatório string $w\in S$,
e seja $w'$ o string reverso de $w$.
Temos
$$
f(w',1) = (w')' = w.
$$

%%}}}

%%{{{ x: touch_of_godel_encoding 
\exercise.
%%%{{{ meta 
\label touch_of_godel_encoding_pairs
%%%}}}

Considere as $f,g,h : \nats^2 \to \nats$
definidas pelas
$$
\xalignat3
f (x,y) &= 2^x 3^y &
g (x,y) &= 2^x 6^y &
h (x,y) &= 12^x 18^y.
\endxalignat
$$
Para cada uma, decida se é injetora, e se é sobrejetora.

\hint
Nenhuma é sobrejetora.
As $f,g$ são injetoras; a $h$ não.
Demonstre tudo isso.

\hint
Para refutar que $h$ é injetora, observe que $12=2^2 \ntimes 3$ e $18=2 \ntimes 3^2$.

%%}}}

%%{{{ df: jection_sets 
\definition.
%%%{{{ meta 
\label jection_sets
\defines
    * (~A \bijto ~B)  -- o conjunto de todas as bijecções  de $A$ para $B$
    * (~A \injto ~B)  -- o conjunto de todas as injecções  de $A$ para $B$
    * (~A \surto ~B)  -- o conjunto de todas as surjecções de $A$ para $B$
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos os conjuntos:
$$
\align
(A \injto B) &\defeq \setstt {f : A \to B} {$f$ injetora} \\
(A \surto B) &\defeq \setstt {f : A \to B} {$f$ sobrejetora} \\
(A \bijto B) &\defeq \setstt {f : A \to B} {$f$ bijetora}
\endalign
$$

%%}}}

%%{{{ x: cardinalities_of_jection_sets 
\exercise.
%%%{{{ meta 
\label cardinalities_of_jection_sets
%%%}}}

Ache a cardinalidade dos conjuntos da~\ref[jection_sets]
em termos das cardinalidades dos $A$ e $B$, supondo que
ambas são finitas.

%%}}}

%%{{{ x: fcom_respects_jections 
\exercise Composição respeita ``-jectividade''.
%%%{{{ meta 
\label fcom_respects_jections
%%%}}}

Sejam $f : A\to B$ e $g : B \to C$.
Demonstre:
\item{(1)} Se $f$ e $g$ são injetoras, então $g\fcom f$ também é;
\item{(2)} Se $f$ e $g$ são sobrejetoras, então $g\fcom f$ também é;
\item{(3)} Se $f$ e $g$ são bijetoras, então $g\fcom f$ também é.

%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
%%%{{{ meta 
%%%}}}

Se $g\compose f$ é bijetora, o que podemos concluir sobre as $f,g$?  Justifique.

%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
%%%{{{ meta 
%%%}}}

Se $f$ é injetora e $g$ sobrejetora, a $g\compose f$ é necessariamente bijetora?

\solution
Não.
Aqui um contraexemplo:
$$
\tikzpicture
\draw (0,0) ellipse (-.75cm and 1.25cm);
\draw (3,0) ellipse (-.75cm and 1.25cm);
\draw (6,0) ellipse (-.75cm and 1.25cm);
\draw (0,-.5) node {$\bullet$};
\draw (3,.5)  node {$\bullet$};
\draw (3,-.5) node {$\bullet$};
\draw (6,.5)  node {$\bullet$};
\draw (6,-.5) node {$\bullet$};
\draw[|->] (0.2,-.5) -- (2.8,-.5);
\draw[|->] (3.2,-.5) -- (5.8,-.5);
\draw[|->] (3.2,.5) -- (5.8,.5);
\draw[->]  (0.5,1.5) -- (2.5,1.5);
\draw[->]  (3.5,1.5) -- (5.5,1.5);
\draw (0,1.5) node {$A$};
\draw (3,1.5) node {$B$};
\draw (6,1.5) node {$C$};
\draw (1.5,1.20) node {$f$};
\draw (4.5,1.20) node {$g$};
\endtikzpicture
$$

%%}}}

%%{{{ x: x_mapsto_singleton_x_properties 
\exercise.
%%%{{{ meta 
\label x_mapsto_singleton_x_properties
%%%}}}

Sejam $A\neq\emptyset$ um conjunto e $f : A \to \pset A$ definida pela equação
$$
f(a) = \set a.
$$
Investigue:
(i) A $f$ é injetora?
(ii) A $f$ é sobrejetora?

\solution
\noi
(i) Sim: se $x,y\in A$, então
$$
f(x) = f(y)
    \implies \set x = \set y
    \implies x = y.
$$
\eop
\noi
(ii) Não: para todo $a\in A$ temos
$f(a) = \set a \neq \emptyset \in \pset A$.

%%}}}

\endsection
%%}}}

%%{{{ Inverse_functions 
\section Funcções inversas.
%%%{{{ meta 
\label Inverse_functions
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Informalmente, para construir a inversa duma funcção
pegamos o seu diagrama interno, e viramos todas
as setinhas barradas para a direção oposta.
Vamos estudar essa idéia formalmente agora.

%%}}}

%%{{{ df: finverse 
\definition funcção inversa.
%%%{{{ meta 
\label finverse
\defines
    * \finv {~f}  -- a funcção inversa da $f$
    * funcção!inversa
    ;;
%%%}}}

Seja funcção bijetora $f : A \bijto B$.
Definimos a funcção $\finv f : B \to A$ pela
$$
\finv f (y) \defeq \text{aquele $x\in A$ que $x \mapstoby f y$}.
$$
Ou, \emph{equivalentemente}, pela
$$
\finv f (y) = x \defiff f(x) = y.
$$
Com outra notação:
$$
y \mapstoby {\finv f} x \defiff x \mapstoby f y.
$$
Chamamos a $\finv f$ a \dterm{funcção inversa} da $f$.

%%}}}

%%{{{ remark: human_eyes_are_not_symmetric 
\remark Os olhos humanos não são simétricos.
%%%{{{ meta 
\label human_eyes_are_not_symmetric
%%%}}}

Às vezes a direção em que a gente olha para uma igualdade faz diferença:
$$
\alpha = \beta \iff \beta = \alpha
$$
sim, ou seja, \symq{$=$} é simétrica,
mas nossos olhos humanos conseguem enxergar certas informações melhor na
forma $\alpha = \beta$, e outras na forma $\beta = \alpha$!
(Talvez nossos olhos não são tão simétricos.)
A mesma coisa é sobre relações ``direcionadas'' como por exemplo:
$$
\alpha \leq \beta \iff \beta \geq \alpha
$$
que também são afirmações equivalentes,
mas muitas vezes a gente enxerga uma numa maneira diferente da outra!
\eop
Na~\ref[finverse] acima, por exemplo, reescrevendo a igualdade
na outra direção temos:
$$
\finv f (y) = x \defiff y = f(x)
$$
que possivelmente nos permite enxergar a situação numa maneira diferente.
Similarmente, usando a notação das setinhas barradas podemos enxergar
a equivalência assim:
$$
x \mapsfromby {\finv f} y \defiff x \mapstoby f y.
$$

%%}}}

%%{{{ x: finv_is_well_defined 
\exercise A inversa é bem-definida.
%%%{{{ meta 
\label finv_is_well_defined
%%%}}}

Demonstre que a funcção $\finv f$ foi bem-definida.
O que precisas demonstrar?

\solution
Pelo menos um tal $x\in A$ existe, pois a $f$ é sobrejetora.
E como $f$ é injetora, existe no máximo um.
Provamos assim a unicidade, algo que nos permite
\emph{definir a funcção} no jeito que definimos
na~\ref[finverse].

%%}}}

%%{{{ x: finv_is_bij 
\exercise A inversa é bijetora.
%%%{{{ meta 
\label finv_is_bij
%%%}}}

Demonstre que quando a funcção inversa $\finv f$ é definida, ela é bijetora.

\hint
O que exatamente garanta a injectividade da $\finv f$, e o que a sua sobrejectividade?

\hint
Considere:
$$
\align
\text{totalidade da $f$}      &\implies \text{$\finv f$ sobrejetora} \\
\text{determinabilidade da $f$} &\implies \text{$\finv f$ injetora}.
\endalign
$$

%%}}}

%%{{{ x: finv_of_finv 
\exercise Inversa da inversa.
%%%{{{ meta 
\label finv_of_finv
%%%}}}

Demonstre que se a funcção inversa $\finv f$ é definida,
então a sua inversa $\finvp{\finv f}$ também é
e temos $\finvp{\finv f} = f$.

\hint
Quando a funcção inversa é definida?

\hint
Aplique duas vezes a~\ref[finverse] de funcção inversa para demonstrar
que as duas funcções são iguais.

\solution
Pelo~\ref[finv_is_bij] temos que $\finv f$ é bijetora,
então sua inversa $\finvp{\finv f}$ é definida sim
(e pelo~\ref[finv_is_bij] de novo ela é bijetora também).
As $f$ e $\finvp{\finv f}$ têm domínios e codomínios iguais.
Basta verificar que concordam em todo o seu domínio.
Seja $x \in \dom f$ então.
Calculamos
\compute
\finvp{\finv f}(x)    = f(x)
&\iff {\finv f}(f(x)) = x   \by {def.~$\finvp{\finv f}$} \\
&\iff f(x) = f(x)           \by {def.~$\finv f$} \\
\endcompute
e a última igualdade é trivialmente válida,
e logo $\finvp{\finv f} = f$.

%%}}}

%%{{{ x: finv_laws_pointful 
\exercise Leis da inversa (com pontos).
%%%{{{ meta 
\label finv_laws_pointful
%%%}}}

Seja $f: A \bijto B$.
Para todo $a\in A$ e todo $b\in B$, temos:
$$
\xxalignat4
\textrm{(L)} && \finv f (f a) &= a &
f (\finv f b) &= b. &&\textrm{(R)}
\endxxalignat
$$
(Esqueça o ``com pontos'' no rótulo desse exercício;
vai fazer sentido depois.)

\solution
Seja $a\in A$ e $b\in B$.
Calculamos:
\compute
\finv f (f(a))
&= \text{aquele $x\in A$ que $f(x) = f(a)$} \\
&= a.          \by {$f$ inj.} \\
\endcompute
Agora tomando $y\in B$ calculamos a outra numa maneira diferente:
\compute
f(\finv f(b)) = y
&\iff \finv f (b) = \finv f (y) \\
&\iff b = y    \by {$\finv f$ inj.~(\reftag[finv_is_bij])} \\
&\iff \idof B (b) = y.
\endcompute

%%}}}

%%{{{ x: finv_of_id 
\exercise Inversa da identidade.
%%%{{{ meta 
%%%}}}

Para todo conjunto $A$, $\finv {\idof A} = \idof A$.

\solution
Temos $\idof A, \finv{\idof A} : A \bijto A$ então basta
verificar que comportam igualmente.
\crproofalt{Jeito 1.}
Seja $a \in A$ então e calculamos:
\compute
\finv{\idof A} a
&= \text{aquele $v\in A$ que $\idof A v = a$}  \by {def.~$\finv{\idof A}$} \\
&= a                                           \by {def.~$\idof A$} \\
&= \idof A a.                                  \by {def.~$\idof A$} \\
\endcompute
\proofalt{Jeito 2.}
Sejam $a,a'\in A$.
Calculamos:
\compute
\finv{\idof A} a = v
&\iff a = \idof A v     \by {def.~$\finv{\idof A}$} \\
&\iff a = v             \by {def.~$\idof A$} \\
&\iff \idof A a = v.    \by {def.~$\idof A$} \\
\endcompute

%%}}}

%%{{{ Q: finv_of_fcompose_question 
\question.
%%%{{{ meta 
\label finv_of_fcompose_question
%%%}}}

Queremos descrever a inversa duma composição de bijecções
em termos das inversas dessas bijecções.
Ou seja, temos a configuração seguinte:
$$
\cd
A \ar[r, tail, two heads, "f"] \ar[rr, tail, two heads, bend left=36, "g\of f"] \| B \ar[r, tail, two heads, "g"] \| C
\endcd
$$
Agora, já que $g\of f$ é bijetora, sabemos que possui inversa.
O desafio é descrevê-la em termos das $\finv f$ e $\finv g$.
Como o farias?

%%}}}

\spoiler

%%{{{ beware: finv_of_fcompose_error 
\beware.
%%%{{{ meta 
\label finv_of_fcompose_error
%%%}}}

Um erro comum é afirmar que $\finvp{g\of f} = \finv g \of \finv f$.
Por que isso não faz sentido?
Pense em funcções como ``processos'' e na $g\of f$ como o processo
<<faça $f$ e depois faça $g$>>.
Como exemplo, considere $f$ o <<botar cueca>> e $g$ o
<<botar shorts>>.
Logo $g\of f$ é o processo <<botar a cueca e depois botar os shorts>>.
Assim, qual processo seria o $\finv g \of \finv f$?
<<Tirar a cueca e depois tirar os shorts.>>
O erro é óbvio: esquecemos de invertar a ordem das acções
(Mais um exemplo para enfatisar: tu tá usando teu editor de texto,
tu fez várias alterações, uma depois de outra, e agora quer desfazer
tudo que tu fez.  Começando fazer ``undo'' qual a primeira
alteração que vai ser ``undoada''?
Voltando: se eu quero desfazer o $g\of f$ mesmo, o que preciso fazer?
Praticamente já te dei a resposta para o exercício seguinte
(\reftag[finv_of_fcompose])---sorry.
Ainda bem que tem uma parte mais interessante: demonstrar.

%%}}}

%%{{{ x: finv_of_fcompose 
\exercise Inversa da composição.
%%%{{{ meta 
\label finv_of_fcompose
%%%}}}

Sejam
$
\cd
A \ar[r, tail, two heads, "f"] \| B \ar[r, tail, two heads, "g"] \| C
\endcd
$\!.
Descreva a $\finvp{g\of f}$ em termos das $\finv f$ e $\finv g$
e demonstre tua afirmação.

\hint
$\finvp{g\of f} = \finv f \of \finv g$.

\hint
Para demonstrar a $\finvp{g\of f} = \finv f \of \finv g$,
tome $x\in C$ e $z\in A$ e mostre a equivalência
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$

\hint
Calcule cada lado separadamente:
\compute
\finvp{g\of f}(x) = z
&\iff (g\of f)(z) = x  \by {def.~$\finvp{g\of f}$} \\
&\dotsiff \dots \\
\paren{\finv f \of \finv g}(x) = z
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f \of \finv g$} \\
&\dotsiff \dots
\endcompute

\solution
Vamos demonstrar que
$$
\finvp{g\of f} = \finv f \of \finv g.
$$
Tome $x \in C$ e $z \in A$.  Basta demonstrar que
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$
pois isso quis dizer que as duas funcções concordam em todo o seu domínio.
Calculamos:
\compute
\finvp{g\of f}(x) = z
&\iff x = (g\of f)(z)                     \by {def.~$\finvp{g\of f}$} \\
&\iff x = g(f(z))                         \by {def.~$g\of f$} \\
&\iff \finv g (x) = f(z)                  \by {def.~$\finv g$} \\
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f$} \\
&\iff \paren{\finv f \of \finv g}(x) = z. \by {def.~$\finv f \of \finv g$} \\
\endcompute

%%}}}

%%{{{ x: finv_atleastonelaw_if_f_bij 
\exercise Basta uma lei.
%%%{{{ meta 
\label finv_atleastonelaw_if_f_bij
%%%}}}

Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis
do~\ref[finv_laws_pointful], então $f'$ é a própria $\finv f$.

\solution
Sejam $b\in B$, $a\in A$.
Caso que $f'$ satisfaz a (L)
calculamos:
\compute
\finv f b = a
&\iff b = f a               \by {def.~$\finv f$} \\
&\iff f' b = f' (f a)       \by {$f'$ inj.} \\
&\iff f' b = (f' f) \fa a   \by {def.~$(f'f)$} \\
&\iff f' b = a.             \by {(L) da $f'$ (com $w \asseq a$)} \\
\intertext{E caso que $f'$ satisfaz a (R):}
f' b = a
&\iff f (f' b) = f a        \by {$f$ inj.} \\
&\iff (f f') \fa b = f a    \by {def.~$(f f')$} \\
&\iff b = f a               \by {(R) da $f'$ (com $w \asseq b$)} \\
&\iff \finv f b = a.        \by {def.~$\finv f$} \\
\endcompute

%%}}}

%%{{{ Boring, innit? 
\blah É chato, né?.
%%%{{{ meta 
%%%}}}

Mergulhar nos domínios e codomínios das funcções, mexendo com os
bichinhos que tem lá, tanto para enunciar teoremas quanto para
demonstrá-los espero que foi uma experiência não exatamente divertida.
Logo vamos ver uma outra maneira para enunciar e demonstrar
essas propriedades, ``de longe'', sem olhar os detalhes internos.

%%}}}

\endsection
%%}}}

%%{{{ Higher_order_functions 
\section Funcções de ordem superior.
%%%{{{ meta 
\label Higher_order_functions
%%%}}}

%%{{{ Holes again 
\note Buracos de novo.
%%%{{{ meta 
%%%}}}

Já encontramos a idéia de \emph{abstrair} certas partes de uma expressão,
botando \emph{buracos}, criando assim funcções de várias aridades.
Além de buracos, trabalhamos com \emph{$\lambda$-abstracção} que nos
permitiu dar nomes para esses buracos, ligar (identificar) certos buracos, etc.
Considere novamente uma expressão como a
$$
\cos(1 + 5\cbrt2)^{2a} + \sin(5)
$$
onde $\cos : \reals\to\reals$, $\sin : \reals\to\reals$, e $a\in \reals$.
Botando uns buracos ou abstraindo com lambdas, criamos, por exemplo, as funcções:
$$
\alignat2
f_1 &= \cos(1 + 5\cbrt2)^{\bhole a} + \sin(5)            &&\eqtype \reals   \to \reals\\
f_2 &= \cos(\bhole + 5\cbrt{\bhole})^{2a} + \sin(\bhole) &&\eqtype \reals^3 \to \reals\\
f_3 &= \cos(\bhole + \bhole\cbrt2)^{2\bhole} + \sin(5)   &&\eqtype \reals^3 \to \reals\\
f_4 &= \cos(\bhole + \bhole)^{\bhole} + \sin(5)          &&\eqtype \reals^3 \to \reals\\
f_5 &= \bhole + \sin(\bhole)                             &&\eqtype \reals^2 \to \reals\\
f_6 &= \lam x {\cos(1 + 5\cbrt2)^{2x} + \sin(5)}         &&\eqtype \reals   \to \reals\\
f_7 &= \lam {x,y} {\cos(1 + y\cbrt x)^{2a} + \sin(y)}    &&\eqtype \reals^2 \to \reals.
\endalignat
$$

%%}}}

%%{{{ x: verify_abstractions_of_expression 
\exercise.
%%%{{{ meta 
\label verify_abstractions_of_expression
%%%}}}

Para quais entradas cada uma dessas funcções retorna o valor da expressão inicial?

\hint
Respeite as aridades!

\solution
Temos
$$
\align
f_1&(2)\\
f_2&(1,2,5)\\
f_3&(1,5,a)\\
f_4&(1,5,2a)\\
f_5&(\cos(1 + 5\cbrt2)^{2a}, 5)\\
f_6&(a)\\
f_7&(2, 5).
\endalign
$$

%%}}}

%%{{{ Higher-order holes 
\note Buracos de ordem superior.
%%%{{{ meta 
%%%}}}

Em todos os exemplos acima, botamos os buracos para substituir
apenas termos cujos valores seriam números (reais).
Expressões tanto como as $2$, $1$, $5$, e $a$,
quanto como as $5\cbrt2$, $2a$, e $\cos(1 + 5\cbrt2)^{2a}$,
denotam, no final das contas, números reais.
Que tal botar um buraco assim:
$$
\cos(1 + 5\cbrt2)^{2a} + \bhole(5)
$$
O que substituimos aqui?  O próprio $\sin$!  Por que não?
E o que tipo de objetos podemos botar nesse buraco?
Um real, não serve: a expressão
$$
\cos(1 + 5\cbrt2)^{2a} + 7(5)
$$
não faz sentido: \emph{ela é mal-tipada}.
O $7$ não pode receber um argumento como se fosse uma funcção, pois não é.
Que tipo de coisas então cabem nesse buraco?
Funcções!
E não funcções quaisquer, mas precisam ter um tipo compatível,
com a aridade certa, etc.
Esses buracos são \emph{de ordem superior}.
E com buracos de ordem superior, vêm funcções de ordem superior.

%%}}}

%%{{{ pseudodf: higher_order_function 
\pseudodefinition.
%%%{{{ meta 
\label higher_order_function
\defines
    * funcção!de ordem superior
    ;;
%%%}}}

Dizemos que uma funcção $f : A \to B$ é de \dterm{ordem superior}
se ela recebe ou retorna funcções.

%%}}}

%%{{{ x: type_higher_order_holed_expressions 
\exercise.
%%%{{{ meta 
\label type_higher_order_holed_expressions
%%%}}}

Escreva os tipos das funcções seguintes:
$$
\align
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}
\endalign
$$

\solution
Temos
\compute
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)                     &&\eqtype \paren{(\reals\to\reals)\times(\reals\to\reals)} \to \reals\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)                    &&\eqtype (\reals^2\to\reals)\to\reals\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)             &&\eqtype \paren{(\reals^2\to\reals)\times(\reals\to\reals)\times\reals}\to\reals\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}  &&\eqtype \paren{(\reals^2\to\reals)\times\reals\times\reals}\to\reals
\endcompute

%%}}}

%%{{{ Returning functions 
\note Retornando funcções.
%%%{{{ meta 
%%%}}}

Até agora encontramos exemplos onde funcções recebem como
argumentos outras funcções, mas ainda não conhecemos alguma
funcção que \emph{retorna funcção}.
Ou será que conhecemos?
Se tu resolveu o~\ref[calculate_lambda_expressions],
tu já encontrou esse caso, na sua última expressão.
Seguem uns exemplos de operadores de ordem superior que
você talvez já encontrou e até usou na tua vida.

%%}}}

%%{{{ eg: Defining a higher-order functions 
\example Definindo uma funcção de ordem superior.
%%%{{{ meta 
\indexes
    * funcção!anônima
    ;;
%%%}}}

Considere a funcção $F : \nats \to (\nats \to \nats)$ definida pela
$$
\align
F(w) &= \text{aquela funcção $g : \nats \to \nats$ que recebendo um $x$, retorna $w + x$}.
\intertext{%
Ou, equivalentemente:
}
F(w) &= \text{aquela funcção $g : \nats \to \nats$ definida pela $g(x) = w + x$}.
\intertext{%
Que tipo de objetos a funcção $F$ retorna?
Funcções!  Nesse caso determinamos exatamente para qualquer entrada
dela, qual seria a funcção que vai ser retornada.
Observe que na definição de $F(w)$, apareceu a frase
``aquela funcção $g$\dots''.
Assim baptizamos temporariamente essa funcção com um nome (``$g$'') à toa:
apenas para referir a ela e retorná-la.
Usando a $\lambda$-notação, essa definição fica mais direta, mais elegante,
e (logo) mais legível:
}
F(w) &= \lam x {w + x} \eqtype \nats \to \nats.
\endalign
$$
Observe que no lado direito aparece uma funcção anônima.

%%}}}

%%{{{ eg: in Python 
\example em Python.
%%%{{{ meta 
\indexes
    * Python
    ;;
%%%}}}

Em Python podemos (ainda bem\dots)~por exemplo escrever:
\sourcecode higher.py;
que corresponde na primeira maneira de definir a $F$, criando e nomeando
a funcção para ser retornada.
Podemos com $\lambda$ também:
\sourcecode higherlam.py;
Não ficou melhor?

%%}}}

%%{{{ Q: what type of thing is F(25)? 
\question.
%%%{{{ meta 
%%%}}}

Que tipo de coisa é o $F(25)$?

%%}}}

\spoiler

%%{{{ Answer 
\note.
%%%{{{ meta 
%%%}}}

Antes de responder nessa pergunta, vamos responder numa outra,
ainda mais específica: quem \emph{é} o $F(25)$?
Ou seja:
$$
F(25) = \dots?\dots
$$
Não precisamos pensar nada profundo!
Vamos apenas \emph{copiar fielmente} sua definição (no lado depois do ``$=$''), substituindo cada ocorrência de $w$, por $25$:
$$
F(25) = \text{aquela funcção $g : \nats \to \nats$ que recebendo um $x\in\nats$, retorna o número $25 + x$}.
$$
Ou seja,
$$
F(25) : \nats\to\nats.
$$
Sendo funcção, podemos chamá-la com um argumento do certo tipo, por exemplo como o $3\in\nats$, e evaluá-la:
$$
\paren{F(25)}(3) = 28.
$$

%%}}}

%%{{{ x: where_did_28_come_from 
\exercise.
%%%{{{ meta 
\label where_did_28_come_from
%%%}}}

De onde chegou esse $28$?

\solution
Seguindo a definição da $F(25)$ ela é a funcção que recebendo um valor
(agora tá recebendo o $3$), retorna a soma de $25$ e esse valor:
$25 + 3 = 28$.

%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_higher_order
%%%}}}

Escreva $\lambda$-expressões que podem ser consideradas como funcções com os
tipos seguintes:
$$
\align
F_1&\eqtype \reals \to \reals \\
F_2&\eqtype \reals \to (\reals \to \reals) \\
F_3&\eqtype (\reals \to \reals) \to \reals \\
F_4&\eqtype (\reals \to \reals) \to (\reals \to \reals) \\
F_5&\eqtype (\reals^2 \to \reals) \to \reals \\
F_6&\eqtype (\reals^2 \to \reals) \to (\reals \to (\reals \to \reals)).
\endalign
$$

%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order_abstract 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_higher_order_abstract
%%%}}}

Escreva $\lambda$-expressões que podem ser consideradas como funcções com os
tipos seguintes, onde $A,B,C$ são conjuntos sobre quais tu não podes supor
absolutamente nada mais!
Para cada um dos tipos, tente escrever as mais $\lambda$-expressões realmente
diferentes que tu consegues.
Cuidado: para uns deles não é possível achar nenhuma!
$$
\align
&: A \to B \\
&: A \to (B \to A) \\
&: A \to (B \to B) \\
&: (A \to A) \to A \\
&: A \to (A \to A) \\
&: A \to \bigparen{B \to \paren{(A\to B) \times (A\union C) \times \nats}} \\
&: (A \to (B \to C) \to ((A\times B)\to C)) \\
&: ((A\times B)\to C) \to (A \to (B \to C))
\endalign
$$

%%}}}

%%{{{ first_class_citizens 
\note First-class citizens.
%%%{{{ meta 
\label first_class_citizens
\indexes
    * cidadão da primeira classe
    * first-class citizen    see: cidadão
    * C
    * C++
    * Java
    * Haskell
    * PureScript
    * Idris
    * Agda
    * Racket
    * Clojure
    * Scala
    * Python
    ;;
%%%}}}

O slogan aqui é que funcções são \emph{first-class citizens}.
Trabalhando no~\ref[calculate_lambda_expressions], o último cálculo
chega no valor seguinte:
$$
\align
\plam x {\plam x {x + 1} \lapp 1 \ntimes \redex {\plam y {xy} \lapp 4}}
&\lstep \plam x {\redex {\plam x {x + 1} \lapp 1} \ntimes x\ntimes 4} \\
&\lstep \plam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \plam x {8x}.
\endalign
$$
Como falei na resolução, se esse ``resultado'' (valor final)
não parece satisfatório, é por causa de um preconceito teu que
favorece os objetos de tipo ``número'' contra os objetos de tipo
``funcção''.
Os números têm o direito de ser valores finais; e as funcções
também têm!  Esse ``preconceito'' é bastante alimentado por causa
de varias linguagens de programação que realmente não tratam
as funcções em termos iguais com os outros tipos.
Em C, C++, ou Java, por exemplo, não é possível passar como
argumentos funcções, nem retorná-las; mas claramente números
podem ser argumentos e também podem ser retornados como saída
de funcções.
No outro lado, linguagens como Haskell, PureScript, Idris,
Agda, Racket, Clojure, Scala, Python, etc., adoptam o slogan
\standout
\emph{<<functions are first-class citizens>>}
\endstandout
ou seja, lá temos funcções de ordem superior---e logo, felicidade.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Funcções de ordem superior não é algo tão desconhecido como
talvez parece.
O leitor já está acostumado com os operadores nos exemplos seguintes:

%%}}}

%%{{{ eg: higher_order_example_composition 
\example Composição.
%%%{{{ meta 
\label higher_order_example_composition
%%%}}}

Sejam conjuntos $A,B,C$.
O operador da composição $\of$
(cuja notação decoramos aqui para especificar
o domínio e codomínio dele e dos seus argumentos)
é o seguinte:
$$
\dhole\oflab ABC\dhole : \bigparen{(B\to C) \times (A\to B)} \to (A\to C).
$$
Observe que ele é um operador de ordem superior, pois seus (dois) argumentos
são funcões, e também pois sua saída também é uma funcção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Definimos agora a funcção $\eval$\/ que faz algo bem simples:
aplica seu primeiro argumento (que deve ser uma funcção) no seu
segundo (que deve ser um ponto do domínio do primeiro argumento).

%%}}}

%%{{{ df: eval_operation 
\definition eval.
%%%{{{ meta 
\label eval_operation
\defines
    * \evaldc {~A} {~B}  -- a operação que aplica funcções de tipo $A\to B$ em objetos de tipo $A$
    * funcção!eval
    ;;
%%%}}}

Dados conjuntos $A,B$ definimos a funcção
$$
\align
\eval         &\eqtype \bigparen{(A \to B) \times A} \to B \\
\eval (f, a)  &= f(a).
\endalign
$$
Chamamos essa funcção de \dterm{evaluação} ou \dterm{avaliação}.
Como fizemos na composição, decoramos essa operação escrevendo
$\evaldc A B$ para esclarecer os conjuntos envolvidos, mas escrevemos
simplesmente $\eval$ quando os $A,B$ são implícitos pelo contexto.

%%}}}

%%{{{ eg: eval is indeed a higher order function 
\example.
%%%{{{ meta 
%%%}}}

Dados conjuntos $A,B$, a $\evaldc A B$ é claramente uma
operação de ordem superior.

%%}}}

%%{{{ x: type_of_restriction_op_with_hole 
\exercise.
%%%{{{ meta 
\label type_of_restriction_op_with_hole
%%%}}}

Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo dos:
$$
\align
f\resto \dhole  &\eqtype ?\\
(\dhole\resto X)\resto(A \to B)
                &\eqtype ?
\endalign
$$

\solution
Temos
$$
\align
f\resto \dhole  &\eqtype \pset A \to \Unionl_{X\in\pset A}(X\to B)\\
(\dhole\resto X)\resto (A \to B)
                &\eqtype \paren{(A \to B) \to (X \to B)}
\endalign
$$

%%}}}

%%{{{ eg: higher_order_example_derivation 
\example Derivação.
%%%{{{ meta 
\label higher_order_example_derivation
%%%}}}

Considere o operador da derivação $\deriv$.
Por exemplo, se $f(x) = x^3 + 5x$, temos
$$
\align
\deriv(f) &= g, \quad \text{onde $g(x) = 3x^2 + 5$}.
\intertext{%
Cuidado, não escrevemos aqui $\deriv(f) = 3x^2 + 5$,
mas podemos escrever
}
\deriv(f) &= \lam x {3x^2 + 5}
\endalign
$$
sim.
Qual o tipo da própria $\deriv$?
Ela recebe e retorna funcções de reais para reais, mas não podemos tipá-la
$$
\align
\deriv(\dhole) &: \funs\reals\reals \to \funs\reals\reals
\intertext{%
pois estariamos perdendo a totalidade da $\deriv$:
tem funcções no $\funs\reals\reals$ que não são deriváveis.
Ainda mais, seria legal poder iterar o $\deriv$ (\ref[function_iterations])
à vontade.
Logo tipamos assim:
}
\deriv(\dhole) &: \smooths \to \smooths
\endalign
$$
onde $\smooths$ é o conjunto de todas as funcções infinitamente
deriváveis: são deriváveis, e suas derivadas também são, e suas
derivadas também, etc.

%%}}}

%%{{{ teaser: partial_functions_teaser 
\teaser funcções parciais.
%%%{{{ meta 
%%%}}}

Mas talvez queremos mesmo considerar a $\deriv$ como uma operação
que opera no conjunto $\funs \reals \reals$
\emph{sacrificando} a totalidade.
Chegamos assim no conceito de \emph{funcção parcial}, que
voltamos a investigar na~\ref[Partial_functions].

%%}}}

%%{{{ eg: higher_order_example_integration 
\example Integração.
%%%{{{ meta 
\label higher_order_example_integration
\credits
    * Riemann : integral
    ;;
%%%}}}

Sejam $a,b\in\reals$ com $a<b$ e seja
$$
\riemannables a b \defeq \setstt {f : [a,b] \to \reals} {$f$ é Riemann-integrável}.
$$
Observe que $\riemannables a b$ é um conjunto de funcções.
Definimos o operador
$$
\lam f {\lam x {\int_a^{x} f}} : \riemannables a b \to {\funs {[a,b]} \reals}
$$
cujo argumento é uma funcção---e ainda mais,
sua saída também é uma funcção---e logo ele é um operador de ordem superior
também.
Para a integração ``indefinita'' (antiderivadas), seja
$$
R \defeq \setstt {f : \reals\to\reals} {$f$ é Riemann-integrável}
$$
e defina o operador
$$
\int\dhole : R \to \pset{(\reals\to\reals)}
$$
onde $\int f$ é o conjunto das antiderivadas da $F$:
$$
\int f = \setst {F : \reals\to\reals} {\deriv(F) = f}.
$$
Observe que a notação comum em análise é diferente: usamos por exemplo
$\intbv a x {f(t)} t$, e o $\int f$ é visto como uma antiderivada
(que depende duma constante) e não como o conjunto de todas
essas antiderivadas como definimos aqui.

%%}}}

\endsection
%%}}}

%%{{{ Images_preimages 
\section Imagens, preimagens.
%%%{{{ meta 
\label Images_preimages
%%%}}}

%%{{{ Two important subsets 
\note Dois subconjuntos importantes.
%%%{{{ meta 
%%%}}}

Sejam $A,B$ conjuntos e $f:A \to B$.
$$
\tikzpicture[scale=0.75,node distance=0mm]
\tikzi imgpreimgbase;
\endtikzpicture
$$
Vamos associar, com qualquer subconjunto $X$ de $A$, um certo subconjunto de $B$, que vamos chamá-lo a \emph{imagem} de $X$ através da $f$.
Similarmente, com qualquer subconjunto $Y$ de $B$, vamos associar um certo subconjunto de $A$, que vamos chamá-lo a \emph{preimagem} de $Y$ através da $f$.
Bem informalmente, parece que estamos ``elevando'' a funcção $f$ do nível ``membros'' para para o nível ``subconjuntos''.
Vamos ver como.

%%}}}

%%{{{ eg: sketches of image and preimage 
\example.
%%%{{{ meta 
%%%}}}

Nas figuras seguintes mostramos com azul o subconjunto com que começamos,
e com vermelho o subconjunto que associamos com ele.
Considere o $X\subset A$ como aparece no desenho abaixo,
e veja qual é o subconjunto $\img f X$ de $B$ que vamos associar com o $X$:
$$
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5) ellipse (0.9cm and 1.6cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-X) at (-0.7,-2.1) {$X$};
\endtikzpicture
\endgathered
\quad
\leadsto
\quad
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5) ellipse (0.9cm and 1.6cm);
\draw [fill=red!25] (4.9,-0.45) ellipse (0.7cm and 2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-X) at (-0.7,-2.1) {$X$};
\node [color=red] (subset-fX) at (5.9,-2.05) {$\img f X$};
\endtikzpicture
\endgathered
$$
Na direção oposta, comece por exemplo com esse $Y\subset B$
e observe qual é o subconjunto $\pre f Y$ de $A$ que queremos associar com o $Y$:
$$
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-Y) at (5.95,0.4) {$Y$};
\endtikzpicture
\endgathered
\quad
\leadsto
\quad
\gathered
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\draw [fill=red!25]  (0,1.0) ellipse (0.8cm and 2.0cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-Y)     at (5.95,0.4)  {$Y$};
\node [color=red]  (subset-fpreY) at (-0.9,-1.1) {$\pre f Y$};
\endtikzpicture
\endgathered
$$

%%}}}

%%{{{ remark: just a function from A to B is enough 
\remark.
%%%{{{ meta 
%%%}}}

Observe que na discussão acima não supusemos \emph{nada mais} além da
existência de uma funcção $f$ dum conjunto $A$ para um conjunto $B$.

%%}}}

%%{{{ Q 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir formalmente os conjuntos indicados nos desenhos acima?

%%}}}

\spoiler

%%{{{ df: img_and_pre 
\definition.
%%%{{{ meta 
\label img_and_pre
\defines
    * \img {~f} {~X}  -- a imagem de $X$ através da $f$
    * \pre {~f} {~Y}  -- a preimagem de $Y$ através da $f$
    * funcção!imagem
    * funcção!preimagem
    ;;
%%%}}}

Seja $f : A \to B$, e sejam subconjuntos $X\subset A$ e $Y\subset B$.
Definimos:
$$
\align
\img f X &\defeq \setst {f(x)} {x \in X}\\
\pre f Y &\defeq \setst {a \in A} {f(a) \in Y}.
\endalign
$$
Lembrando a notação set-builder~(\ref[set_builder]), temos as definições:
$$
\align
y \in \img f X &\defiff \lexists{x\in X} {f(x) = y} \\
x \in \pre f Y &\defiff f(x) \in Y.
\endalign
$$
Chamamos o conjunto $\img f X$ \dterm{imagem} do $X$ através da $f$ ou,
mais curtamente, a $f$-\dterm{imagem} do $X$.  O conjunto $\pre f Y$
é a \dterm{preimagem} do $Y$ através da $f$; ou a $f$-\dterm{preimagem}
do $Y$.
\mistake

%%}}}

%%{{{ x: type_of_img_f_hole_and_pre_f_hole  
\exercise.
%%%{{{ meta 
\label type_of_img_f_hole_and_pre_f_hole
%%%}}}

Quais os tipos das $\img f {\dhole}$ e $\pre f {\dhole}$?

\solution
$$
\align
\img f {\dhole} &\eqtype \pset X \to \pset Y \\
\pre f {\dhole} &\eqtype \pset Y \to \pset X
\endalign
$$

%%}}}

%%{{{ x: img_and_pre_of_emptyset 
\exercise.
%%%{{{ meta 
\label img_and_pre_of_emptyset
%%%}}}

Seja $f : X \to Y$.
Verifique:
$$
\img f \emptyset = \emptyset
\qqtext{e}
\pre f \emptyset = \emptyset.
$$

\solution
As duas afirmações seguem diretamente pelas definições:
$$
\align
\img f \emptyset &= \setst {f(x)}   {x \in \emptyset}    = \emptyset \\
\pre f \emptyset &= \setst {x\in X} {f(x) \in \emptyset} = \emptyset.
\endalign
$$

%%}}}

%%{{{ remark: range and surjection with f[-] notation 
\remark.
%%%{{{ meta 
%%%}}}

Se $f : A \to B$ então, temos que:
\elist i: \spaciouslist
\li: $\range f = \img f A$;
\li: $\img f A = B \iff \text{$f$ é sobrejetora}$.
\endelist
As duas afirmações são conseqüências imediatas das definições envolvidas.

%%}}}

%%{{{ x: our_img_notation_is_better 
\exercise.
%%%{{{ meta 
\label our_img_notation_is_better
%%%}}}

Em matemática, às vezes aparece a notação $f(X)$ para denotar a imagem do
$X\subset \dom f$ através da funcção $f$.
Aqui usamos a notação $\img f X$.
\emph{Sem usar o conjunto vazio em lugar nenhum na tua resposta},
dê um exemplo (completo) que mostra que a notação $f(X)$ pode ser problemática
(e logo nossa notação $\img f X$ é melhor).
Explique curtamente.

\hint
Pode acontecer que $X \in A$ e também $X \subset A$?

\hint
Vamos adoptar temporariamente a notação $f(X)$.
Daí, te pergunto: se $f : \nats\to\nats$ é o sucessor,
tem como calcular os seguinte?:
$$
f(5);\qquad
f(8);\qquad
f(\set{1,7});\qquad
f(2\nats);
$$
onde $2\nats \subset \nats$ é o conjunto dos pares naturais.
``Fácil'' tu pensou (certo?), e explicou:
$$
\align
f(5) &\ \text{\dots é o valor da $f$ no $5$, definido pois $5\in\dom f$} \\
\intertext{e similarmente sobre o $f(8)$, mas}
f(\set{1,7}) &\ \text{\dots não pode ser o valor da $f$ no $\set{1,7}$, pois $\set{1,7}\notin\dom f$.}
\endalign
$$
Então $f(\set{1,7})$ só pode ser a $f$-imagem do $\set{1,7}$ que realmente é um subconjunto do $\dom f$;
e similarmente sobre o $f(2\nats)$.
E assim tu calculou as respostas:
$$
\xalignat4
f(5) &= 6; & f(8) &= 9; & f(\set{1,7}) &= \set{2,8}; & f(2\nats) &= \set{1,3,5,\dots}.
\endxalignat
$$
Beleza, mas acontece que o $\nats$ é um conjunto homogêneo
(\reftag[homogeneous_and_heterogeneous_sets]).
Imagine que o domínio da $f$ tem todos os objetos seguintes como membros:
$$
1,\quad
7,\quad
\set{1,7}.
$$
Agora, se eu perguntar qual é o $f(\set{1,7})$ tu tens um dilemma:
$$
f(\set{1,7}) \askeq
\paths{
\text{a $f$-imagem do $\set{1,7}$}   & (que realmente é um subconjunto do seu domínio) \cr
\pathween {\dots\orword\dots}
\text{o valor da $f$ no $\set{1,7}$} & (que realmente é um membro do seu domínio)?
}
$$

\solution
Sejam $A = \set{ 1, 7, \set{1,7} }$, e $X = \set{1,7}$.
Observe que $X\in A$ e $X \subset A$.
Seja $f : A \to \set{3}$ a funcção constante definida pela $f(x) = 3$.
Assim a notação $f(X)$ fica ambígua: a $f$-imagem de $X\subset A$ é o $\set 3$,
mas o valor da $f$ no $X$ é o $3$.
E $3 \neq \set{3}$!

%%}}}

%%{{{ remark: img_paren_notation_almost_safe_when_homogenous
\remark.
%%%{{{ meta 
\label img_paren_notation_almost_safe_when_homogenous
%%%}}}

O perigo descrito no~\ref[our_img_notation_is_better] não existe quando
trabalhamos com conjuntos \emph{homogêneos} (\reftag[homogeneous_and_heterogeneous_sets]).
Em tal mundo podemos usar a notação $f(X)$ para o $\img f X$ sem problema:
um conjunto como o $\set{1, 7, \set{1,7}}$ seria considerado:
inconstrutível, mal-tipado, não definido, sem significado, blasfêmico, etc.
\mistake

%%}}}

%%{{{ x: erroneous_definition_of_pre 
\exercise.
%%%{{{ meta 
\label erroneous_definition_of_pre
%%%}}}

Podemos definir a $f$-preimagem de $Y$ assim?:
$$
\pre f Y \defeq \setst {\finv f (y)} {y \in Y}
$$

\solution
Não!
O símbolo $\finv f (y)$ nem é definido no caso geral:
o definimos \emph{apenas para funcções bijetoras}.

%%}}}

%%{{{ x: when_erroneous_definition_of_pre_is_valid 
\exercise.
%%%{{{ meta 
\label when_erroneous_definition_of_pre_is_valid
%%%}}}

Sejam $f: A \bijto B$, e $Y \subset B$.
Mostre que
$$
\pre f Y = \setst {\finv f (y)} {y \in Y}.
$$

\hint
É um igualdade de conjuntos, então mostre cada uma das~{\lrdirset}
e~{\rldirset} separadamente.

\solution
Caso $\pre f Y = \emptyset$, necessariamente $Y=\emptyset$ também
(pois $f$ é sobrejetora) e logo
$$
\setst {\finv f (y)} {y \in Y}=\emptyset
$$
também.
Caso contrário, mostramos as duas direções separadamente:
\crtabproofpart{\lrdirset:}
Seja $x\in \pre f Y$ e logo
seja $y_x\in Y$ tal que $f(x) = y_x$ (pela def.~$\pre f Y$).
Logo $x = \finv f (y_x)$ pela definição da funcção inversa (\reftag[finverse]),
ou seja $x \in \setst {\finv f (y)} {y \in Y}$.
\crtabproofpart{\rldirset:}
É só seguir os passos da {\lrdirset} em reverso.

%%}}}

%%{{{ x: pre_notation_problem 
\exercise.
%%%{{{ meta 
\label pre_notation_problem
%%%}}}

Qual o problema com a~\ref[img_and_pre]?

\hint
Quando $f$ \emph{não} é bijetora, nenhum.

\hint
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes.
Quais?  E isso é um problema mesmo por quê?

\solution
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes:
$$
\pre f Y \askeq
\paths{
\pre {\alert{(f)}} {\aB Y}
& a preimagem de $\aB Y$ através da funcção $\alert f$ \cr
\pathween {\dots\orword\dots}
\img {\alert{(\finv f)}} {\aB Y}
& a imagem de $\aB Y$ através da funcção $\alert{\finv f}$
}
$$
onde usamos cores e parenteses para enfatizar o ``parsing'' diferente
de cada interpretação.
Observe que a segunda alternativa não é possível quando $f$ não é bijetora,
pois a funcção $\finv f$ nem é definida nesse caso!

%%}}}

%%{{{ x: correctness_of_pre_notation 
\exercise.
%%%{{{ meta 
\label correctness_of_pre_notation
%%%}}}

Depois de resolver o~\ref[pre_notation_problem], justifique a corretude
da~\ref[img_and_pre]:
explique o que precisas demonstrar, e demonstre!

\hint
Precisamos demonstrar que no caso que $f:A\bijto B$ as duas
interpretações do símbolo $\pre f Y$ \emph{denotam o mesmo objeto}.

\hint
Temporariamente mude tua notação para ajudar teus olhos distinguir
entre as duas interpretações melhor.
Use, por exemplo, $f_{-1}\bracket{\dhole}$ para denotar
a preimagem através da $f$.
Assim teu alvo fica enxergável:
$$
\lforall {Y \subset B} {\img {\finv f} Y = f_{-1}\bracket Y}.
$$

\solution
Seja $f : A \bijto B$.
Introduzimos temporariamente a notação
$$
f_{-1}\bracket Y \defeq \text{a $f$-preimagem de $Y$}.
$$
Com essa notação precisamos demonstrar que
$$
\text{para todo $Y\subset B$,}\quad
\img {\finv f} Y = f_{-1}\bracket Y
$$
Seja $Y \subset B$.
\crtabproofpart{\lrdirset}.
Seja $x \in \img {\finv f} Y$\fact1.
Para mostrar que $x \in f_{-1}\bracket Y$ basta verificar que $f(x) \in Y$\fact1.
Seja $y_x \in Y$ tal que $\finv f y_x = x$ (pela~\byfact1).
Logo $y_x = f(x)$ pela definição de $\finv f$ e logo pertence ao $Y$
pela~\byfact2.
\crtabproofpart{\rldirset}.
Seja $x \in f_{-1}\bracket Y$\fact1.
Como $f x \in Y$ (pelo~\byfact1) e $f x \mapstoby {\finv f} x$
(pela definição da $\finv f$), logo $x \in \img {\finv f} Y$.

%%}}}

%%{{{ x: img_f_singleton_x_eq_singleton_f_x 
\exercise.
%%%{{{ meta 
\label img_f_singleton_x_eq_singleton_f_x
%%%}}}

Verdade ou falso?:
para toda funcção $f$ e todo $x$ no seu domínio temos
$$
\img f {\set{x}} = \set{f(x)}.
$$

\solution
Verdade:
$$
\img f {\set{x}}
= \setst {f(z)} {z \in \set{x}}
= \set{f(x)}.
$$

%%}}}

%%{{{ x: is any of img f, pre f, guaranteed to be inj or surj? 
\exercise.
%%%{{{ meta 
%%%}}}

É alguma das $\img f {\dhole}$, $\pre f {\dhole}$ garantidamente
injetora ou sobrejetora?

%%}}}

%%{{{ x: bij_iff_all_pre_are_singletons 
\exercise.
%%%{{{ meta 
\label bij_iff_all_pre_are_singletons
%%%}}}

Seja $f : A \to B$.
Demonstre que
$$
\text{$f$ bijetora} \iff \text{para todo $b \in B$, $\pre f {\set b}$ é um conjunto unitário}.
$$

\hint
Pense\dots
Como podes matar um alvo que um conjunto $S$ é unitário?
Como podes usar um fato que um conjunto $S$ é unitário?

\hint
Como matar o alvo que um conjunto $S$ é unitário?
Basta mostrar duas coisas:
(1) $S$ tem pelo menos um membro (ou seja: $S\neq\emptyset$);
(2) $S$ tem no máximo um membro (ou seja: para todo $s,s' \in S$,
temos $s=s'$).
E como usar o fato que um conjunto $S$ é unitário?
Para todos os $s, s' \in S$, ganhamos que $s=s'$.

\solution
\proofpart{\lrdir}:
Suponha que $f$ bijetora, e seja $b\in B$.
Vou demonstrar que $\pre f {\set b}$ é unitário.
Vamos chamá-lo de $A_b$.
Como $f$ é sobrejetora, logo seja $a_b \in A$ tal que $f(a_b) = b$.
Logo $a_b \in A_b$ pela definição da preimagem,
e logo $A_b \neq\emptyset$ (pois tem pelo menos um membro).
Basta mostrar que tem no máximo um membro.
Sejam $a, a' \in A_b$ então e vamos mostrar que $a=a'$.
Pela escolha dos $a,a'$, temos $f(a) = f(a') = b$;
e agora pela injectividade da $f$ temos o desejado $a=a'$.
\crtabproofpart{\rldir}.
Suponha que para todo $b \in B$, o $\pre f {\set b}$ é unitário.
Preciso mostrar que $f$ é injetora e sobrejetora.
\crproofpart{$f$ injetora:}
Suponha que temos $x,y\in A$ tais que $f(x) = f(y)$
e chame esse valor comum de $b$.
Basta demonstrar que $x=y$.
Pela hipótese, o $\pre f {\set b}$ é unitário,
e pela escolha dos $x,y$ sabemos que $x,y$ pertencem a ele.
Logo $x=y$.
\crproofpart{$f$ sobrejetora:}
Seja $b\in B$.
Procuramos $a\in A$ tal que $f(a) = b$.
Pela hipótese, o conjunto $\pre f {\set b}$ é unitário (e logo não vazio).
Tome $a$ o (único) membro desse conjunto e observe que pela definição
de preimagem temos que $f(a) = b$.

%%}}}

%%{{{ x: composition_with_inverse_subsets 
\exercise.
%%%{{{ meta 
\label composition_with_inverse_subsets
%%%}}}

Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Demonstre as afirmações:
$$
\align
A &\subset \pre f {\img f A}\\
B &\supset \img f {\pre f B}.
\endalign
$$

\solution
Vamos demonstrar as duas afirmações.
\eop\indent
\proofpart{{\proofname} de $A \subset \pre f {\img f A}$.}
Suponha $a\in A$.
Logo $f(a) \in \img f A$ pela definição da funcção-imagem,
e logo $a \in \pre f {\img f A}$ pela definição da funcção-preimagem.
\eop\indent
\proofpart{{\proofname} de $B \supset \img f {\pre f B}$.}
Suponha $y_0 \in \img f {\pre f B}$.
Logo tome $x_0 \in \pre f B$ tal que $y_0 = f(x_0)$\fact1.
Pela definição da funcção-preimagem $f(x_0) \in B$,
e agora pela~\byfact1~temos $y_0 \in B$.

%%}}}

%%{{{ x: composition_with_inverse 
\exercise.
%%%{{{ meta 
\label composition_with_inverse
%%%}}}

Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Considere as afirmações:
$$
\align
A &\askeq \pre f {\img f A}\\
B &\askeq \img f {\pre f B}.
\endalign
$$
Para cada uma delas: se podemos concluí-la, demonstre;
e caso contrário, mostre um contraexemplo.

\hint
Nenhuma é válida em geral.
Procure contraexemplos.

\hint
O enunciado do~\ref[jection_iff_composition_with_inverse]
pode te ajudar pensar em contraexemplos.

\solution
Mostramos dois contraexemplos, um para cada afirmação.
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,0.666) ellipse (5mm and 5mm);
\draw (-0.6,0.1) node {$A$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
\qqqquad
\tikzpicture
\draw (0,0) ellipse (1cm and 12mm);
\draw (3,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (8mm and 10mm);
\draw (2.4,0.1) node {$B$};
\draw (3,0.666)  node {$\bullet\,2$};
\draw (3,-0.666) node {$\bullet\,3$};
\draw (0,0)  node {$1\,\bullet$};
\draw[|->] (0.35,0.05) -- (2.7,0.6);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
$$
No primeiro contraexemplo temos:
$A=\set{1}$;
$\img f A = \set {3}$; e
$\pre f {\set 3} = \set {1,2}$.
Logo
$$
A = \set{ 1 } \neq \set {1, 2} = \pre f {\img f A}.
$$
No segundo contraexemplo temos:
$B = \set{2,3}$;
$\pre f B = \set {1}$; e
$\img f {\set 1} = \set {2}$.
Logo
$$
B = \set{ 2,3 } \neq \set {2} = \img f {\pre f B}.
$$

%%}}}

%%{{{ Q: what changes if f is inj or surj? 
\question.
%%%{{{ meta 
%%%}}}

O que muda no~\ref[composition_with_inverse] se $f$ é injetora?  Se é sobrejetora?

%%}}}

\spoiler

%%{{{ jection_iff_composition_with_inverse 
\theorem.
%%%{{{ meta 
\label jection_iff_composition_with_inverse
%%%}}}

Seja $f : X \to Y$.
Temos:
$$
\align
\text{$f$ injetora}    &\iff \text{para todo $A \subset X$, $A = \pre f {\img f A}$}  \tag{1}\\
\text{$f$ sobrejetora} &\iff \text{para todo $B \subset Y$, $B = \img f {\pre f B}$}. \tag{2}
\endalign
$$

\proof.
As duas idas tu demonstrarás
(agora!)~no~\reftag[jection_implies_composition_with_inverse];
as voltas no~\ref[jection_iff_composition_with_inverse_proof] (pode ser depois).

%%}}}

%%{{{ x: jection_implies_composition_with_inverse 
\exercise.
%%%{{{ meta 
\label jection_implies_composition_with_inverse
%%%}}}

Demonstre as idas do~\ref[jection_iff_composition_with_inverse].

\solution
Temos duas implicações para demonstrar.
\crtabproofpart{Ida da (i).}
Suponha que $f$ é injetora, e seja $A\subset X$.
Já temos a
$$
A \subset \pre f {\img f A}
$$
pelo~\ref[composition_with_inverse_subsets], então basta mostrar
$$
\pre f {\img f A} \subset A.
$$
Tome então $x_0 \in \pre f {\img f A}$.
Logo $f(x_0) \in \img f A$.
Logo $f(a) = f(x_0)$ para algum $a \in A$ (pela definição da funcção-imagem).
Mas $f$ é injetora, então $a = x_0$ e logo $x_0\in A$.
\crtabproofpart{Ida da (ii).}
Suponha que $f$ é sobrejetora, e seja $Y\subset B$.
Já temos a
$$
\img f {\pre f B} \subset B
$$
pelo~\ref[composition_with_inverse_subsets], então basta mostrar
$$
B \subset \img f {\pre f B}
$$
Tome então $b \in B$.
Agora seja $x_b \in X$ tal que $f(x_b) = b$ (pois $f$ é sobrejetora).
Então $x_b \in \pre f B$.
Logo $f(x_b) \in \img f {\pre f B}$.
Logo $b \in \img f {\pre f B}$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver agora como essas operações comportam
em combinação com as operações de conjuntos.

%%}}}

%%{{{ x: operations_respected_by_img 
\exercise.
%%%{{{ meta 
\label operations_respected_by_img
%%%}}}

Sejam $f : X \to Y$, $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\union B} &=       \img f A \union \img f B\\
\img f {A\inter B} &\askeq  \img f A \inter \img f B\\
\img f {A\minus B} &\askeq  \img f A \minus \img f B
\endalign
$$
onde nas $\askeq$ demonstre que a igualdade em geral não é válida,
mas uma das~\lrdirset~e~\rldirset, é.

\hint
Ataque cada direção ({\lrdirset} e {\rldirset}) da primeira separadamente.
Das duas $\askeq$, são válidas as inclusões:
$$
\align
\img f {A\inter B} &\subset \img f A \inter \img f B\\
\img f {A\minus B} &\supset \img f A \minus \img f B
\endalign
$$
Demonstre; e mostre contraexemplos que demonstram que as reversas
inclusões não são válidas em geral.

\solution
Vamos primeiramente demonstrar a
$\img f {A\union B} = \img f A \union \img f B$.
\proofpart{\lrdirset}:
Tome $y \in \img f {A\union B}$.
Logo seja $x \in A\union B$ tal que $f(x) = y$.
\case{Caso $x \in A$,} temos $f(x)\in \img f A$
e logo $f(x)$ pertence na união $\img f A \union \img f B$.
\case{Caso $x \in B$,} concluímos similarmente
que $f(x) \in \img f B \subset \img f A \union \img f B$.
\eop
\proofpart{\rldirset}:
Tome $y \in \img f A \union \img f B$.
\case{Caso $y \in \img f A$,} seja $a\in A$ tal que $f(a)=y$.
Mas $a \in A\union B$, logo $y\in \img f {A\union B}$.
\case{O caso $y \in \img f B$} é similar.
\eop
Vamos demonstrar a
$\img f {A\inter B} \subset \img f A \inter \img f B$ agora.
Tome $y \in \img f {A\inter B}$ e
seja $d \in A\inter B$ tal que $f(d) = y$.
Mas $d \in A$ e $d \in B$, ou seja $y \in \img f A$ e $y \in \img f B$,
e logo $y \in \img f A \inter \img f B$.
\eop
Vamos demonstrar a
$\img f {A\minus B} \supset \img f A \minus \img f B$ agora.
Tome $y \in \img f A \minus \img f B$ então, ou seja
$y \in \img f A$ e $y \notin \img f B$.
Traduzindo:
$$
\lexists {a\in A} {f(a) = y}
\qquad\mland\qquad
\lforall {b\in B} {f(b) \neq y}.
$$
Usando a primeira afirmação abaixo tome $a\in A$ tal que $f(a) = y$,
e observe que graças à segunda, $a \notin B$.
Logo $a \in A\minus B$, e chegamos no desejado
$y \in \img f {A\minus B}$.
\eop
Finalmente, usamos apenas um contraexemplo para refutar simultaneamente
as duas inclusões que são inválidas no caso geral:
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,.666) ellipse (5mm and 5mm);
\draw (0,-.666) ellipse (5mm and 5mm);
\draw (-0.6,0.25)  node {$A$};
\draw (-0.6,-0.25) node {$B$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\node (X) at (0,2.0) {$X$};
\node (Y) at (3,2.0) {$Y$};
\draw[->]  (0.5,2.0) -- (2.5,2.0) node[midway, below] {$f$};
\endtikzpicture
$$
Calculamos para verificar:
$$
\aligned
\img f {A \inter B}
&= \img f \emptyset
= \emptyset \\
\img f A \inter \img f B
&= \set{3} \inter \set{3}
= \set{3}
\endaligned
\qquad
\aligned
\img f {A \minus B}
&= \img f A
= \set {3}\\
\img f A \minus \img f B
&= \set {3} \minus \set {3}
= \emptyset.
\endaligned
$$
Um contraexemplo mais pictorial seria considerar uma funcção $f$
que mapeia pontos do plano $\reals^2$
para pontos da reta $\reals$, mandando cada
entrada $\tup{x,y}$ para sua ``sombra'' $x$.
Já conhecemos essa funcção: é a primeira projecção: $f = \pi_0$.
Observe que a $\img {\pi_0} {\dhole}$ manda cada subconjunto de $\reals^2$
para sua ``sombra'':
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A$};
\draw[-]  (-1,0) -- (6,0);
\draw[|->] (2,2.6) -- (2,0.5);
\endtikzpicture
$$
Para achar o contraexemplo agora, basta só escolher dois subconjuntos de
$\reals^2$ como esses:
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=3mm, fill=gray!10] (1,1)--(1,2)--(4,2)--(4,1)--cycle;
\node at (2.5,1.5) {$B$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A = \img {\pi_0} B$};
\draw[-]  (-1,0) -- (6,0);
\endtikzpicture
$$
Verifique que isso é um contraexemplo que refuta as duas igualdades
que queremos refutar.

%%}}}

%%{{{ x: operations_respected_by_img_of_inj 
\exercise.
%%%{{{ meta 
\label operations_respected_by_img_of_inj
%%%}}}

Sejam $f : X \injto Y$ injetora, e $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\inter B} &= \img f A \inter \img f B\\
\img f {A\minus B} &= \img f A \minus \img f B.
\endalign
$$

\hint
Já provou metade de cada igualdade no~\ref[operations_respected_by_img]
até sem a hipótese que $f$ é injetora.
Basta então demonstrar as duas inclusões:
$$
\align
\img f {A\inter B} &\supset \img f A \inter \img f B\\
\img f {A\minus B} &\subset \img f A \minus \img f B.
\endalign
$$

\solution
Já provamos metade de cada igualdade no~\ref[operations_respected_by_img]
para qualquer funcção, então para nossa injetora $f$ também.
Basta então demonstrar as duas inclusões:
$$
\align
\img f {A\inter B} &\supset \img f A \inter \img f B\\
\img f {A\minus B} &\subset \img f A \minus \img f B.
\endalign
$$
\proofpart{{\proofname} de $\img f {A\inter B} \supset \img f A \inter \img f B$}:
Suponha $y \in \img f A \inter \img f B$.
Logo $y \in \img f A$ e $y \in \img f B$.
Tome então $a\in A$ tal que $f(a) = y$ e $b \in B$ tal que $f(b) = y$.
Juntando as duas igualdades temos $f(a) = f(b)$.
Mas $f$ é injetora, e logo $a = b$.
Ou seja, $a \in A\inter B$, e chegamos no desejado
$y \in \img f {A \inter B}$.
\eop\noi
\proofpart{{\proofname} de $\img f {A\minus B} \subset \img f A \minus \img f B$}:
Suponha $y \in \img f {A\minus B}$.
Tome então $a_0 \in A\minus B$ tal que $f(a_0) = y$.
Logo $a_0 \in A$ e $a_0 \notin B$.
Já sabemos então que $y \in \img f A$.
Agora usamos a injectividade da $f$ para demonstrar que $y \notin \img f B$.
Se $y$ fosse um membro de $\img f B$, existiria $b\in B$ com $f(b) = y$.
Mas já temos o único ($f$ injetora) membro do domínio $X$ que $f$ mapeia no $y$,
o $a_0$, e sabemos que $a_0 \notin B$!
Logo $y \notin \img f B$ e chegamos no $y\in \img f A \minus \img f B$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A preimagem comporta bem melhor que a imagem: ela respeita
todas essas operações mesmo quando $f$ não é injetora,
algo que tu demonstrarás agora.

%%}}}

%%{{{ x: operations_respected_by_pre 
\exercise.
%%%{{{ meta 
\label operations_respected_by_pre
%%%}}}

Sejam $f : X \to Y$, $A,B\subset Y$.
Mostre que:
$$
\align
\pre f {A\union B} &= \pre f A \union \pre f B\\
\pre f {A\inter B} &= \pre f A \inter \pre f B\\
\pre f {A\minus B} &= \pre f A \minus \pre f B
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas propriedades generalizam naturalmente para uniões e intersecções
de seqüências e famílias de conjuntos;
veja por exemplo o~\ref[big_operations_respected_by_img_and_pre].

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

% JECTIONS AND INVERSES

%%{{{ prob: touch_of_godel_encoding_strings 
\problem.
%%%{{{ meta 
\label touch_of_godel_encoding_srings
%%%}}}

Seja $\kstar \nats = \Union_n \nats^n$ o conjunto de todos
os strings finitos feitos por naturais.
Considere a $f : \kstar \nats \to \nats_{>0}$ definida pela
$$
f (x_0,\dotsc,x_{n-1}) = \Prod_{i=0}^{n-1} p_i^{x_i}
$$
onde $\seqn p n$ é a seqüência dos números primos
($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
(1) Explique por que $f$ não é injetora.
(2) Demonstre que $f$ é sobrejetora.
(3) O que acontece se substituir os exponentes $x_i$ por $x_i + 1$?

\solution
\proofpart{(1) $f$ não é injetora}
pois
$$
f(1) = 2 = f(1,0).
$$
\proofpart{(2) $f$ é sobrejetora.}
Seja $y \in \nats_{>0}$.
Pelo teorema fundamental de aritmética~\reftag[fundamental_theorem_of_arithmetic]
$y$ pode ser escrito como produtório de primos
$$
y = q_0^{y_i}
$$
\proofpart{(3) Acontece}
que ganha injectividade
(veja o~\ref[encoding_of_finite_sequences] e sua resolução)
e perde sobrejectividade:
nenhuma entrada é mapeada para o $3$, pois o único ímpar
que realmente está no $\range f$ é o $1$ ($f() = 1$ pela definição
do produtório vazio); todos os outros pontos do domínio da $f$
são múltiplos de $2$ pela sua definição.
Observe que tem números pares que faltam também, por exemplo o
$$
10 = 2^1 \ntimes 3^0 \ntimes 5^1.
$$

%%}}}

%%{{{ prob: epimono_factorization_teaser 
\problem.
%%%{{{ meta 
\label epimono_factorization_teaser
%%%}}}

Sejam $A \toby f B$.
Então existem: injecção $m$, surjecção $e$, e conjunto $C$
tais que o diagrama seguinte comuta:
$$
\cdopt{sep=1cm}
A \ar[rr, "f"]\ar[dr, twoheadrightarrow, "e"'] \| \| B \\
                                                  \| C \ar[ur, rightarrowtail, "m"']
\endcd
$$
Em outras palavras, mostre que qualquer funcção $f : A \to B$
pode ser ``decomposta'' em
$$
f = m \of e
$$
onde $e$ é uma funcção sobrejetora e $m$ uma funcção injetora.

\hint
Para garantir que $e$ é sobrejetora escolher como $C$ 
o próprio $\range(f)$.

\solution
Sejam
$$
\align
C &= \range(f) \\
e &= \lam x {f x} : A \to C \\
m &= \inc : C \incto B
\endalign
$$
Basta demonstrar que $f = m \of e$.
Seja $x \in A$.
Calculamos:
\compute
(m \of e) x
&= m (e x)  \by {def.~$m \of e$} \\
&= m (f x)  \by {def.~$e$} \\
&= f x.     \by {def.~$m$} \\
\endcompute

%%}}}

%%{{{ prob: injto_surfrom_powerset 
\problem.
%%%{{{ meta 
\label injto_surfrom_powerset
%%%}}}

Seja conjunto $A\neq\emptyset$.
Defina funcções $f,g$ com os tipos seguintes:
$$
\align
f &: A \injto \pset A \\
g &: \pset A \surto A.
\endalign
$$
Demonstre que:
(i) a $f$ é injetora;
(ii) a $f$ não é sobrejetora;
(iii) a $g$ é sobrejetora;
(iv) a $g$ não é sobrejetora.
Como eu posso pedir pra tu demonstrar tudo isso (as (ii) e (iv))
sem sequer saber quais são as $f,g$ que tu escolheu definir?
(Essa pergunta não é retórica.)

\hint
Cuidado: sobre o $A$ não podes supor nada mais que $A\neq\emptyset$.

\hint
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref[x_mapsto_singleton_x_properties].
Falta a parte sobre a $g : \pset \surto A$.

\hint
É para a parte do problema sobre a $g : \pset A \surto A$
que precisas o $A\neq\emptyset$.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
\dots?\dots, & $\dots?\dots$ \cr
\dots?\dots, & caso contrário.
}
$$
Novamente: cuidado para não supor nada mais que $A\neq\emptyset$
sobre o $A$.  Por exemplo: não sabemos se $A$ tem \emph{mais}
que um elemento (sabemos apenas que tem \emph{pelo menos} um);
não sabemos se os membros dele são ordenados; etc.
Se a gente soubesse que os membros de $A$ são \emph{bem ordenados}
a gente poderia definir o primeiro caso acima pela
$$
g(X) = \knuthcases {
\min X, & se $X \neq \emptyset$ \cr
\dots?\dots, & caso contrário.
}
$$
mas sem a informação que o $A$ é bem ordenado a $g$ não seria
bem-definida.
Por enquanto: um conjunto é chamado \dterm{bem ordenado} sse todo
$\emptyset\subsetneq X \subset A$ possui elemento mínimo.
No~\ref[Wosets_Ordinals]
estudamos conjuntos bem ordenados e suas propriedades.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
x,   & se $X$ é o singleton $\set{x}$ \cr
a_0, & caso contrário.
}
$$
Falta demonstrar que ela é sobrejetora e que não é injetora.

\solution
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref[x_mapsto_singleton_x_properties], onde definimos a
$f : A \to \pset A$ pela $f(x) = \set{x}$ e provamos as (i)--(ii).
\eop
Fixe $a_0 \in A$ ($A\neq\emptyset$) e defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
x,   & se $X$ é o singleton $\set{x}$\cr
a_0, & caso contrário.
}
$$
\eop
(iii) \proofpart{A $g$ é sobrejetora.}
Seja $y \in A$.  Observe que $g(\set{y}) = y$.
Como $\set{y}\in\pset A$, temos que $g$ é sobrejetora.
\eop
(iv) \proofpart{A $g$ não é injetora.}
Observe que $\emptyset, \set{a_0} \in \pset A$ e que $\emptyset \neq \set{a_0}$,
mas mesmo assim $g(\emptyset) = a_0 = g(\set{a_0})$.
Logo, $g$ não é injetora.
\crproofpart{Para responder na pergunta não retórica}
precisamos \emph{demonstrar} que não existe nenhuma funcção
$A \bijto \pset A$ e nenhuma funcção $\pset A \bijto A$.
Na verdade basta apenas demonstrar apenas uma das duas afirmações,
pois quando temos uma funcção bijetora de $A$ para $\pset A$
também temos ``de graça'' uma bijetora de $\pset A$ para $A$:
sua inversa.
Mas como conseguimos então \emph{demonstrar} que não existe bijecção
entre o $A$ e o $\pset A$?
Isso eu vou te deixar pensar.
Mas te aviso: é algo \emph{muito difícil de pensar}.
(Seria fácil se tivermos que $A$ é finito, mas pode ser que não é.)
Mas dê uma chance nele!
E não se preocupe: no~\ref[Cantors_paradise] estudamos umas
idéias de {\Cantor[teorema]}Cantor; foi ele que se perguntou
sobre isso, e foi ele que deu a resposta mesmo
(teorema de Cantor~\reftag[cantor_theorem],
\reftag[Cantors_theorem_and_its_consequences]).
As conseqüências do seu teorema são{\dots}
Brutais!
Paciência.

%%}}}

%%{{{ prob: projection_inj_or_surj 
\problem.
%%%{{{ meta 
\label projection_inj_or_surj
%%%}}}

Sejam $A\neq\emptyset$ conjunto, $n\in\nats_{>0}$,
e $I = \setst {i\in\nats} {i < n}$.
Considere a funcção $\pi : I \times A^n \to A$ definida por
$$
\pi(i, \alpha)
= \pi_i(\alpha)
\qquad\Bigparen{
= \text{o $i$-ésimo membro da tupla $\alpha$}
}
$$
onde consideramos o primeiro membro duma tupla seu
``$0$-ésimo'' membro, etc.
Investigue a injectividade e a sobrejectividade da $\pi$.

\hint
Calcule uns valores primeiro.  Por exemplo,
$$
\xalignat3
\pi (2, \tup{2,3,5,7}) &= 5 &
\pi (0, \tup{2})       &= 2 &
\pi (3, \tup{2,0,0,1}) &= 1
\endxalignat
$$

\solution
\proofpart{Injectividade.}
A injectividade da $\pi$ depende no $n$:
\crcase{Caso $n>1$}, não é:
pois tomando $a\in A$,
$$
\pi(0,\tup{a,\dotsc,a}) = a = \pi(1,\tup{a,\dotsc,a}).
$$
\case{Caso $n=1$}, é:
tomando $w, w' \in I\times A^n$ com $w\neq w'$, temos
que $w = \tup{ 0, \tup{a} }$ e $w' = \tup{ 0, \tup{a'} }$
para alguns $a,a'\in A$.
Agora como $w\neq w'$ concluimos que $a\neq a'$ e logo
$\pi(0,w) \neq \pi(0,w')$, ou seja, $\pi$ é injetora
nesse caso.
\crproofpart{Sobrejectividade.}
A $\pi$ é sobrejetora sim:
pois para qualquer $a\in A$, $\pi(0,\tup{a,\dotsc,a}) = a$.

%%}}}

% SHIFTS

% img/pre

%%{{{ prob: jection_iff_composition_with_inverse_proof 
\problem.
%%%{{{ meta 
\label jection_iff_composition_with_inverse_proof
%%%}}}

Demonstre o~\ref[jection_iff_composition_with_inverse].

\solution
Já provou as idas no~\reftag[jection_implies_composition_with_inverse].
Vamos demonstrar as voltas.
\eop
\proofpart{Volta da (1).}
Suponha a hipótese:
$$
\text{para todo $A \subset X$, $A = \pre f {\img f A}$}.
$$
Para mostrar que $f$ é injetora, suponha que $x,x'\in X$ tais que $f(x) = f(x')$.
Basta verificar que $x = x'$.
Considere o conjunto $A = \set{x}$.
Observe que $A \subset X$, e logo pela hipótese temos
$$
A = \pre f {\img f A}.\tag{A}
$$
Temos $f(x) \in \img f A$ pela definição da funcção-imagem.
Como $f(x') = f(x)$ temos também $f(x') \in \img f A$.
Logo
$$
x, x' \in \pre f {\img f A} \eqlabel A A = \set{x}.
$$
Como $x, x' \in \set{x}$, logo $x = x'$.
\eop
\proofpart{Volta da (2).}
Suponha a hipótese:
$$
\text{para todo $B \subset Y$, $B = \img f {\pre f B}$}.
$$
Tome $y_0\in Y$.
Para mostrar que $f$ é sobrejetora
basta mostrar que $\pre f {\set{y_0}} \neq \emptyset$.
Considere o
$$
B = \set{y_0} \subset Y
$$
e logo pela hipótese temos
$$
B = \img f {\pre f B}.\tag{B}
$$
Ou seja, $\pre f B \neq \emptyset$
(caso contrário teriamos
$$
B
\eqlabel B \img f {\pre f B}
= \img f {\emptyset}
= \emptyset
$$
que é absurdo pois $B = \set{y_0}$).
Isso mostra que $f$ é sobrejetora.

%%}}}

%%{{{ prob: big_operations_respected_by_img_and_pre 
\problem.
%%%{{{ meta 
\label big_operations_respected_by_img_and_pre
\pdefs
    \pdef I {{\cal I}}
    \pdef J {{\cal J}}
    ;;
%%%}}}

Sejam $f : A \to B$, e duas famílias indexadas de conjuntos:
$\famil A i \I$ feita por subconjuntos de $A$, e
$\famil B j \J$ feita por subconjuntos de $B$.
Ou seja, par todo $i\in \I$, e todo $j \in \J$,
temos $A_i \subset A$ e $B_j \subset B$.
Mostre que:
$$
\align
\img f {\Unionl_{i \in \I} A_i} &=      \Unionl_{i \in \I} \img f {A_i} \tag1\\
\img f {\Interl_{i \in \I} A_i} &\askeq \Interl_{i \in \I} \img f {A_i} \tag2\\
\pre f {\Unionl_{j \in \J} B_j} &=      \Unionl_{j \in \J} \pre f {B_j} \tag3\\
\pre f {\Interl_{j \in \J} B_j} &=      \Interl_{j \in \J} \pre f {B_j} \tag4
\endalign
$$
onde na $\askeq$ demonstre que a igualdade em geral não é válida,
mas uma das~{\lrdirset}~e~{\rldirset} é.
A demonstre, e, supondo que $f$ é injetora, demonstre a outra também.

\solution
\proofpart{(1)}:
Provamos cada direção separadamente.
{\lrdirset}:
Seja $b \in \img f {\Union_{i\in\I} A_i}$.
Seja $a\in\Union_{i\in\I} A_i$ tal que $f(a) = b$\fact1 (pela definição de funcção-imagem).
Agora tome $i\in\I$ tal que $a\in A_i$\fact2.
Agora pelas~\byfact1,\byfact2~temos que $b\in\img f {A_i}$.
Ou seja, $b \in \Union_{i\in\I} \img f {A_i}$.
{\rldirset}:
Seja $b \in \Union_{i\in\I} \img f {A_i}$.
Seja $i\in\I$ tal que $b\in \img f {A_i}$.
Tome $a\in A_i$ tal que $f(a) = b$\fact1.
Como $a\in A_i$, logo $a\in\Union_{i\in\I} A_i$ e agora pela~\byfact1
ganhamos $b \in \img f {\Union_{i\in\I} A_i}$.
\eop
\proofpart{(2)}:
Provamos primeiro a {\lrdirset} que é verdade para toda $f$,
e mostramos que se $f$ é injetora, a {\rldirset} também é válida.
{\lrdirset}:
Seja $b \in \img f {\Inter_{i\in\I} A_i}$.
Logo tome $a \in \Inter_{i\in\I} A_i$\fact1 tal que $f(a) = b$\fact2.
Agora, como $a$ pertence a todos os $A_i$'s e $f(a) = b$,
então para cada $i\in\I$, $b\in\img f {A_i}$.
Ou seja, $b$ pertence a todos os $\img f {A_i}$'s.
Chegamos então no desejado $b\in\Inter_{i\in\I} \img f {A_i}$.
\eop
{\rldirset}:
Para essa direção vamos supor que $f$ é injetora.
Tome $b\in\Inter_{i\in\I} \img f {A_i}$, ou seja $b$
pertence a todos os $\img f {A_i}$'s.
Ou seja, para cada um dos $A_i$'s, existe $a_i\in A_i$
tal que $f(a_i) = b$.
Mas a $f$ é injetora, então todos esses $a_i$'s são iguais;
seja $a$ então esse membro comum dos $A_i$'s.
Temos então que:
$a \in \Inter_{i\in\I} {A_i}$ e $f(a) = b$.
Ou seja, $b \in \img f {\Inter_{i\in\I} A_i}$.
\eop
\proofpart{(3)}:
Calculamos:
\compute
a \in \pre f {\Unionl_{j\in\J} B_j}
&\iff f(a) \in \Unionl_{j\in\J} B_j           \by {def.~$\pre f {\Unionl_{j\in\J} B_j}$} \\
&\iff \lexists {j\in\J} {f(a) \in B_j}        \by {def.~$\Unionl_{j\in\J} B_j$} \\
&\iff \lexists {j\in\J} {a \in \pre f {B_j}}  \by {def.~$\pre f {B_j}$} \\
&\iff a \in \Unionl_{j\in\J} {\pre f {B_j}}.  \by {def.~$\Unionl_{j\in\J} {\pre f {B_j}}$} \\
\endcompute
Ou seja, $\pre f {\Unionl_{j \in \J} B_j} = \Unionl_{j \in \J} \pre f {B_j}$.
\eop
\proofpart{(4)}:
{\lrdirset}:
Seja $a \in \pre f {\Inter_{i\in\J}^\infty B_j}$.
Logo $f(a) \in {\Inter_{i\in\J}^\infty B_j}$,
ou seja, para todo $i\in\J$, $f(a) \in B_j$.
Logo $a \in \pre f {B_j}$ para todo $i\in\J$, ou seja,
$a \in {\Inter_{i\in\J}^\infty \pre f {B_j}}$.
{\rldirset}.
Similar: é só seguir os passos da {\lrdirset} em reverso.

%%}}}

%%{{{ prob: big_intersection_respected_by_img_wrong_proof 
\problem.
%%%{{{ meta 
\label big_intersection_respected_by_img_wrong_proof
%%%}}}

Um aluno ``demonstrou'' que se $f : A \to B$ e $\seqn A n$ é uma
seqüência de subconjuntos de $A$, então
$$
\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}.
$$
Sua ``prova'' foi a seguinte:
\quote
<<Calculamos:
\compute
b \in \img f {\Interl_{n=0}^\infty A_n}
&\ifflabel1 \lexists {a \in \Interl_{n=0}^\infty A_n} {f(a) = b}            \by {def.~$\img f {\dhole}$} \\
&\ifflabel2 \exists a \paren{a \in \Interl_{n=0}^\infty A_n \land f(a) = b} \by {lógica} \\
&\ifflabel3 \exists a \paren{\forall n \paren{a \in A_n} \land f(a) = b}    \by {def.~$\Interl_{n=0}^\infty$} \\
&\ifflabel4 \exists a \paren{\forall n \paren{a \in A_n \land f(a) = b}}    \by {lógica} \\
&\ifflabel5 \exists a \forall n \paren{a \in A_n \land f(a) = b}            \by {lógica} \\
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b}            \by {lógica} \\
&\ifflabel7 \forall n \lexists {a \in A_n} {f(a) = b}                       \by {lógica} \\
&\ifflabel8 \forall n \paren{b \in \img f {A_n}}                            \by {def.~$\img f {\dhole}$} \\
&\ifflabel9 b \in \Interl_{n=0}^\infty {\img f {A_n}}                       \by {def.~$\Interl_{n=0}^\infty$} \\
\endcompute
Logo temos
$\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}$
pela definição de igualdade de conjuntos.>>
\endquote
Ache os seus erros.

\hint
Justificar um passo de demonstração com a palavrinha
``lógica'' não vai aumentar a confiança de ninguém sobre
a validez de tal passo.
De fato, nessa demonstração pelo menos um desses passos é errado.

\hint
O problema está na $\ifflabel6$.
Uma da suas direções não é válida.

\solution
Um primeiro problema é esse ``lógica'' que aparece várias vezes
como suposta justificativa de passos.
Já que todos os passos que fazemos numa demonstração supostamente
são logicamente válidos, não faz sentido pensar que decorando
um tal passo com a palavrinha ``lógica'' pode convencer alguém
sobre algo.
\eop
O problema aqui é com a direção {\rldir} da $\ifflabel6$:
\compute
\cdots\iff  \exists a \forall n \paren{a \in A_n \land f(a) = b}
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b} \by {lógica} \\
\endcompute
Saber que
\emph{existe $a$ tal que para todo $n$ algo $P(a,n)$ acontece}
é uma afirmação bem mais forte do que saber que
\emph{para todo $n$ existe algum $a$ tal que $P(a,n)$ acontece}.
Na primeira temos pelo menos um $a$ que serve para todo $n$,
mas na segunda pode ser que para cada $n$, o $a$ ``que serve''
é diferente.  Para enfatizar essa dependência podemos escrever:
\emph{para todo $n$ existe algum $a_n$ tal que $P(a_n, n)$}.
É por isso que a ida é válida mas a vólta, em geral, não é.
Compare com o~\ref[wrong_order_of_quantifiers].

%%}}}

%%{{{ prob: f_surj_iff_pre_f_inj 
\problem.
%%%{{{ meta 
\label f_surj_iff_pre_f_inj
%%%}}}

Seja $f : A \to B$.
Considere a afirmação seguinte:
$$
\text{$f(\dhole)$ sobrejetora}
\askiff
\text{$\pre f {\dhole}$ injetora}.
$$
Para cada uma das direções responda\dots
(1) ``sim'', e demonstre;
(2) ``não'', e refute; ou
(3) ``depende'', e mostre dois exemplos:
um onde a implicação é válida, e outro onde não é.

\hint
Ambas as implicações são válidas.
(Observe que $f(\dhole)$ é a própria $f$.)

\solution
Ambas as direcções são válidas.
\crtabproofpart{\lrdir}:
Suponha $f$ sobrejetora e sejam $Y,Y'$ no $\dom(\pre f {\dhole})$
tais que $Y\neq Y'$.
(Temos então $Y,Y'\subset B$.)
Basta demonstrar que $\pre f {Y} \neq \pre f {Y'}$.
Como $Y\neq Y'$, sem perda de generalidade, seja $d \in Y \setminus Y'$.
Como $f$ é sobrejetora, seja $a_d \in A$ tal que $f(a_d) = d$.
Observe que $f(a_d) \in Y$ e que $f(a_d) \notin Y'$.
Logo $a_d \in \pre f Y$ e $a_d \notin \pre f {Y'}$,
pela definição da $\pre f {\dhole}$.
Logo $\pre f Y \neq \pre f Y'$.
\crtabproofpart{\rldir}:
Vou demonstrar a contrapositiva da afirmação.
Suponha então que $f$ não é sobrejetora.
Vou demonstrar que $\pre f {\dhole}$ não é injetora.
Basta então achar dois membros distintos no seu domínio
mapeados no mesmo objeto.
Como $f$ não é sobrejetora, seja $t\in B$ tal que
$t \notin \range(f)$, ou seja, tal que
para todo $a \in A$, $f(a) \neq t$.
Agora considere os: $\emptyset$ e $\set{t}$.
Ambos são subconjuntos de $B$, e eles são distintos,
mas mesmo assim
$$
\pre f {\emptyset} = \emptyset = \pre f {\set{t}}.
$$
Ou seja, a $\pre f {\dhole}$ não é injetora.

%}}}

%%{{{ prob: Halmos_advice_f_surj_iff_pre_f_inj 
\problem Don't just read it; fight it.
%%%{{{ meta 
\label Halmos_advice_f_surj_iff_pre_f_inj
%%%}}}

Ache a coisa mais óbvia para se perguntar depois
do~\ref[f_surj_iff_pre_f_inj];
pergunte-se; responda (demonstra ou refuta).

\hint
$$
f(\dhole)
\brace{%
\gathered
\text{injetora} \\
\text{sobrejetora}
\endgathered
}
\askiff
\brace{%
\gathered
\img f \dhole \\
\pre f \dhole
\endgathered
}
\brace{%
\gathered
\text{injetora} \\
\text{sobrejetora}
\endgathered
}
$$

%%}}}

% fix, img/pre

%%{{{ prob: fix_f_properties 
\problem.
%%%{{{ meta 
\label fix_f_properties
%%%}}}

Seja $f : A \to A$,
e seja $F$ o conjunto de todos os fixpoints da $f$.
$$
F = \setstt {x \in A} {$x$ é um fixpoint da $f$}
$$
Quais das igualdades seguintes podemos concluir?:
$$
\xalignat2
\img f F &= F &
\pre f F &= F
\endxalignat
$$
Demonstre aquelas que sim; mostre um contraexemplo daquelas que não,
mas verifique se alguma das duas inclusões
{\lrdirset} ou {\rldirset} é válida.
O que muda se $f$ é injetora?

\solution
Sempre temos $\img f F = F$ e $\pre f F \supset F$.
Se $f$ é injetora, ganhamos a $\pre f F \subset F$ também.
\eop
\proofpart{{\proofname} de $\img f F \subset F$.}
Seja $y\in\img f F$.
Logo tome $p\in F$ tal que $f(p) = y$\fact1 (pela definição da funcção-imagem).
Logo $p$ é um fixpoint da $f$, ou seja, $f(p) = p$\fact2.
Juntando as {\byfact1} e~{\byfact2}, ganhamos $p = y$, ou seja $y$ é um fixpoint da $f$, e logo $y\in F$.
\eop
\proofpart{{\proofname} de $\img f F \supset F$.}
Seja $p \in F$.
Logo $f(p) \in \img f F$ (pela definição da funcção-imagem).
Mas $p$ é um fixpoint da $f$ (pois $p\in F$), ou seja $f(p) = p$.
Logo $p \in \img f F$.
\eop
\proofpart{{\proofname} de $\pre f F \supset F$.}
Seja $p \in F$, ou seja $p$ é um fixpoint da $f$.
Logo $f(p) = p \in F$, e logo $p \in \pre f F$.
\eop
\proofpart{Contraexemplo para $\pre f F \subset F$.}
Tome $A = \set{0,1}$ e defina $f$ pela $f(x) = 0$.
Nesse caso temos $F = \set{0}$, mas $\pre f F = \set{0,1}$.
\eop
\proofpart{{\proofname} da $\pre f F \subset F$ quando $f$ injetora.}
Seja $a\in \pre f F$.
Logo $f(a)$ é um fixpoint da $f$.
Ou seja, $f(f(a)) = f(a)$
Agora, como $f$ é injetora, temos $f(a) = a$, ou seja,
$a$ é um fixpoint também e logo $a\in F$.

%%}}}

% iter, img/pre

%%{{{ prob: succiter_for_dummies_returns 
\problem.
%%%{{{ meta 
\label succiter_for_dummies_returns
%%%}}}

(Continuação do~\ref[succiter_for_dummies].)
Qual é (a extensão d)o conjunto
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}\,?
$$
Demonstre tua afirmação.

\hint
$\Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$.

\hint
Suponha que tem $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$
e chegue numa contradicção.

\solution
Eu vou demonstrar que
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}=\emptyset.
$$
Para chegar num absurdo,
suponha que $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, $w \in \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, existe $m\in\nats$ tal que $\succ^n(m) = w$.
Mas $\succ^n(m) = n + m$ (\ref[succiter_for_dummies]).
Ou seja:
$$
\text{para todo $n\in\nats$, existe $m\in\nats$ tal que $n + m = w$}.
$$
Ou seja, lembrando da \ref[natleq],
$$
\text{para todo $n\in\nats$, $n \leq w$}. \tag{*}
$$
Ou seja, $w$ é o máximo do $\nats$; absurdo pois $\nats$ não tem máximo!
\crproofalt{Alternativamente,}
bote $n := w+1$ na (*) para chegar no absurdo $w + 1 \leq w$.

%%}}}

% img/pre

%%{{{ prob: img_paren_notation_not_safe_when_homogenous 
\problem.
%%%{{{ meta 
\label img_paren_notation_not_safe_when_homogenous
%%%}}}

A~\ref[img_paren_notation_almost_safe_when_homogenous] tem um probleminha.
Mesmo trabalhando apenas com uma funcções homogêneas podemos cair em
ambigüidade!
Bem depois, no~\ref[Type_theory], vamos entender a situação melhor;
e tenho um teaser na resolução.
Mas por enquanto só resolva esse problema, ou seja,
ache um exemplo problemático para essa notação,
usando apenas conjuntos homogêneos.

\hint
Dá pra achar um tal exemplo usando uma funcção $f: \pset\nats \to \pset\nats$.

\hint
$\emptyset \in \pset\nats$, mas também $\emptyset \in \pset\pset\nats$
(pois $\emptyset \subset \pset\nats$).

\solution
Considere uma funcção $f : \pset\nats\to\pset\nats$.
Sobre a $f$-imagem do $\emptyset$, não tenho opção:
sei que vai ser o $\emptyset$ (\ref[img_and_pre_of_emptyset]).
Mas sobre o $f$-\emph{valor} do $\emptyset$ eu tenho
opção sim---minha funcção, minhas regras!
Defino a $f$ para ser a constante que sempre retorna o $\set{1,2}$
então.
Logo temos:
$$
f(\emptyset) = \set{1,2} \neq \emptyset = \img f \emptyset.
$$
Ou seja, a notação que usa as parenteses, tá buggada mesmo
que os conjuntos que trabalhamos são homogêneos.
\eop
\proofpartstylize{Teaser.}
Talvez o problema seria resolvido se cada objeto chegasse
junto com um rótulo, dizendo \emph{que tipo de coisa} ele é.
Assim talvez teriamos como diferenciar entre os
dois(!?)~$\emptyset$'s
(algo que no nosso contexto não faz sentido nenhum pois
violaria a unicidade do conjunto
vazio~\reftag[naive_uniqueness_of_emptyset]).
Um $\emptyset$ diria:
\quote
\wq{Eu sou um conjunto de naturais com nenhum membro.}
\endquote
E o outro $\emptyset$ diria:
\quote
\wq{Eu sou um conjunto de conjuntos de naturais com nenhum membro.}
\endquote
Vamos voltar nisso bem, bem, bem depois,
no~\ref[Type_theory]: teoria dos tipos.
Por enquanto, esqueça.

%%}}}

\endproblems
%%}}}

% EPICNESS

%%{{{ Currying 
\section Currificação.
%%%{{{ meta 
\label Currying
%%%}}}

%%{{{ Ha-ha!  My language is better than yours 
\note Ha-ha!  Minha linguagem é melhor que a tua.
%%%{{{ meta 
%%%}}}

Imagine que um amigo definiu uma funcção $f : \ints^2\to\ints$
trabalhando numa linguagem de programação que não permite
definições de funcções de ordem superior.
Queremos escrever um programa equivalente ao programa do nosso amigo
numa outra linguagem que permite sim definir funcções de ordem superior
mas não funcções de aridade maior que $1$.
Mesmo assim nossas funcções podem \emph{chamar} a funcção $f$ do nosso amigo nos seus corpos.

%%}}}

%%{{{ Q: How can we do this? 
\question.
%%%{{{ meta 
%%%}}}

Como fazer isso?

%%}}}

\spoiler

%%{{{ Answer in Python 
\note Resposta em Python.
%%%{{{ meta 
\label currying_in_python
\indexes
    * Python
    ;;
%%%}}}

Aqui uma resposta, escrita em Python.
\sourcecode currying.py;
Para computar a $\code{f(x,y)}$ usando a $\code{F}$,
usamos a $\code{F(x)(y)}$, ou seja, $\code{(F(x))(y)}$.

%%}}}

\TODO Explicar o que acontece.

%%{{{ x: uncurry first exercise
\exercise.
%%%{{{ meta 
%%%}}}

Resolva o problema converso:
começando com a funcção de ordem superior $F$,
defina sua versão $f$ (de aridade 2).

\solution
Dados a $F : \ints\to(\ints\to\ints)$,
é só definir a $f : \ints^2\to\ints$ pela $f(x,y) = F(x)(y)$.
Note que a expressão ``$F(x)(y)$'' quis dizer ``$\bigparen{F(x)}(y)$'' mesmo.

%%}}}

%%{{{ Currying 
\note Currificação.
%%%{{{ meta 
\defines
    * currificação
    ;;
%%%}}}

A maneira que conseguimos utilizar funcções de ordem
superior mas de aridade $1$, para ``emular'' funcções
de aridades maiores é chamada \dterm{currificação},
em homenagem ao Haskell~Curry{\Curry[currificação]}.\foot
O próprio {\Curry}Curry atribuiu o conceito
ao Schönfinkel{\Schonfinkel[currificação]},
mas Frege{\Frege[currificação]} já tinha usado isso antes.
\toof
No exemplo acima dizemos que \emph{$F$ é a currificação da
da $f$}, ou \emph{sua versão currificada}.

%%}}}

%%{{{ Q: How can we define the generic curry and uncurry functions? 
\question.
%%%{{{ meta 
%%%}}}

Usando a $\lambda$-notação como podemos definir funcções
$\curry, \uncurry$ para a situação mais genérica onde
a funcção de dois argumentos é do tipo $(A \times B) \to C$?

%%}}}

\spoiler

%%{{{ how_to_construct_curry_inhabitant 
\note Resposta.
%%%{{{ meta 
\label how_to_construct_curry_inhabitant
%%%}}}

Primeiramente vamos nos preocupar com os tipos dessas funcções.
São assim:
$$
\cdopt{sep=2cm}
\paren{(A\times B)\to C}  \ar[r, shift left, "\curry"] \| \paren{A \to (B\to C)} \ar[l, shift left, "\uncurry"]
\endcd
$$
Temos então
$$
\curry : \paren{(A\times B)\to C} \longto \paren{A \to (B\to C)}
$$
definida pela
\lmath
\curry(\alert{\dots?}
\endlmath
Como denotar o arbitrário membro do seu domínio $\paren{(A\times B)\to C}$?
Sendo uma funcção, vou escolher denotá-lo por $f$.  Ajuda.
Voltamos então:
\lmath
\curry(f) = \alert{\dots?}
\endlmath
Que tipo de coisa estamos tentando \emph{construir} no lado direito?
Pelo tipo da $\curry$, deve ser uma funcção de $A$ para $(B\to C)$.
E o que tenho na minha disposição?  Neste ponto apenas a $f$.
Facilita escrever claramente todas as coisas disponíveis e seus tipos.
Então por enquanto tenho apenas
$$
f : (A\times B) \to C.
$$
E eu quero construir uma funcção de tipo $A\to (B \to C)$.
Para defini-la preciso deixar claro o seu comportamento então:
\lmath
\curry(f) = \lamhead {\alert{\dots?}}
\endlmath
Como denotar a arbitrária entrada dessa funcção?
Bem, sendo uma funcção com domínio $A$, vou escolher denotar
seu argumento por $a$:
\lmath
\curry(f) = \lam a {\alert{\dots?}}
\endlmath
A mesma pergunta: o que eu ganhei e o que tipo de coisa preciso construir agora?
Ganhei um $a : A$, e preciso construir
algo do tipo $B\to C$, ou seja, uma funcção (então vou começar com um $\lambda$\dots)
que recebe $B$'s (então $\lam b {\dots}$) e retorna $C$'s:
\lmath
\curry(f) = \lam a {\lam b {\alert{\dots?}}}
\endlmath
Aqui preciso construir um $C$'zinho e eu tenho:
$$
\align
f &: (A\times B) \to C \\
a &: A \\
b &: B
\intertext{%
Fácil!  Pois eu tenho um fornecedor de $C$'s, e ele só
precisa de um par de um $A$'zinho e um $B$'zinho para
funccionar---pun intended---e felizmente eu tenho ambos, e logo
}
f(a,b) &: C
\endalign
$$
Com isso consigo finalmente terminar:
$$
\curry(f) = \lam a {\lam b {f(a,b)}}.
$$
Deixo a definição da $\uncurry$ pra ti:

%%}}}

%%{{{ x: uncurry_using_lambdas 
\exercise.
%%%{{{ meta 
\label uncurry_using_lambdas
%%%}}}

Defina a $\uncurry$.

\hint
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
então sabemos já como começar: basta definir o
$$
\uncurry(\alert{\dots?}\phantom)
$$
Peraí: qual seria uma opção boa para denotar esse argumento?

\hint
Que tipo de coisa é esse argumento?
Uma funcção $A \to (B\to C)$, ou seja, uma funcção de ordem
superior; vou escolher $F$ aqui, para me lembrar desse fato.
Voltando então:
$$
\uncurry(F) = \alert{\dots?}
$$
O que eu ganhei e o que eu preciso construir?
Ganhei
$$
F : A \to (B\to C)
$$
e preciso algo do tipo $(A\times B) \to C$.
Então já sei como começar.
Como?

\hint
Sendo uma funcção, vou já escrever:
$$
\uncurry(F) = \lam {\alert{\dots?}} {\dots}
$$
e preciso escolher como denotar a sua entrada.
E aqui tenho duas abordagens razoáveis:
ou escolher alguma variável como $w,t,\vec w, \vec t$, etc.,
onde ela terá o tipo $A\times B$;
ou usar a $\lambda$-notação de aridades maiores escrevendo
$\tup{a,b}$ para a arbitrária entrada dessa funcção.
Vamos escolher segunda opção (se quiser, pode escolher a primeira).
Continue!

\hint
Estamos aqui então:
$$
\uncurry(F) =
\lam {\tup{a,b}} {\alert{\dots?}}
$$
e o que precisamos construir aqui?
Sendo a ``saída'' duma funcção com tipo $(A\times B)\to C$,
eu preciso construir uma coisa do tipo $C$.
Mas o que mais eu tenho agora?
Meus dados tem aumentado:
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B)
\intertext{e logo}
a &: A \\
b &: B \\
\alert{??} &: C\\
\endalign
$$
Como posso usá-los para construir algo do tipo $C$?
Eu não tenho um ``fornecedor'' de $C$'s imediato,
mas percebo que tenho um\dots\ fornecedor de fornecedores
de $C$'s!  (Minha $F$.)
E para ela funccionar
preciso oferecer $A$'zinho, e pronto, ela vai fornecer
um fornecedor de $C$'s.
Felizmente temos um $a : A$.
Então temos:
$$
F(a) : ??
$$

\hint
Temos
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B) \\
a &: A \\
b &: B \\
F(a)    &: B \to C
\intertext{e logo}
F(a)(b) &: ??
\endalign
$$
Termine!

\solution
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
e \emph{seguindo as dicas} chegamos em:
$$
\uncurry(F) = \lam {\tup{a,b}} {\bigparen{F(a)}(b)}.
$$

%%}}}

%%{{{ type_inference_tree_for_curry 
\note Arvore de inferência de tipo.
%%%{{{ meta 
%%%}}}

A última parte da argumentação acima corresponde na arvore de inferência
seguinte:
$$
\PROOFm {
\A {f \is A \cross B \to C}      \A {x \is A}  \A {y \is B}
                               \I2------------------------- {}
                                   {(x,y) \is A \cross B}
\I2------------------------------------------------------- {}
                        {f(x,y) \is C}
}
$$
Verifique cada passo, e acostume-se com essa forma!

%%}}}

%%{{{ x: type_inference_tree_for_uncurry 
\exercise Acostume-se mesmo.
%%%{{{ meta 
\label type_inference_tree_for_uncurry
%%%}}}

Construa a arvore que corresponde na última parte da
tua resolução do~\ref[uncurry_using_lambdas] caso que
tu não fez isso já enquanto o resolvendo.

\solution
$$
\PROOFm {
\A {f \is A \to (B \to C)}     \A {t \is A \cross B}
                               \I1------------------ {}
                                   {\outl t \is A}
\I2------------------------------------------------- {}
               {f (\outl t) \is B\to C}
                                               \A {t \is A \cross B}
                                               \I1------------------ {}
                                                   {\outr t \is B}
\I2---------------------------------------------------------------- {}
                     {f (\outl t) (\outr t) \is C}
}
$$

%%}}}

%%{{{ syntactic_associativity 
\note Associatividade sintáctica.
%%%{{{ meta 
\label syntactic_associativity
%%%}}}

Considere que temos uma operação binária $\heartop$.
A frase
$$
\text{<<$\heartop$ é associativa>>}
$$
é uma \emph{afirmação matemática:}
$$
\text{para todo $x,y,z$},
\quad
(x \heartop y) \heartop z
=
x \heartop (y \heartop z).
$$
Isso é algo que pode ser demonstrado, suposto, refutado, etc.
No outro lado, considere as frases seguintes:
$$
\xalignat2
&\aligned
&\textwq{$\heartop$ é associativa na esquerda} \\
&\textwq{$\heartop$ associa na esquerda} \\
&\textwq{$\heartop$ é L-associativa}
\endaligned
&
&\aligned
&\textwq{$\heartop$ é associativa na direita} \\
&\textwq{$\heartop$ associa na direita} \\
&\textwq{$\heartop$ é R-associativa}
\endaligned
\intertext{%
Nenhuma dessas frases é algo que podemos demonstrar, refutar, ou supor!
O que significam então?
Apenas uma convenção sintáctica, que dá significado
às expressões como a \symq{$x \heartop y \heartop z$}
que sem uma associatividade sintáctica não denotam
absolutamente nada (pois têm um erro de aridade).
As frases acima então correspondem respectivamente nas:
}
&x \heartop y \heartop z \syndefeq (x \heartop y) \heartop z &
&x \heartop y \heartop z \syndefeq x \heartop (y \heartop z).
\endxalignat
$$

%%}}}

%%{{{ notational_abuse_curried 
\warning.
%%%{{{ meta 
\label notational_abuse_curried
%%%}}}

Às vezes abusarei essa idéia e escrever o nome duma funcção
currificada mas usá-la como se ela não fosse; e vice-versa.
Por exemplo, defini (\reftag[eval_operation]) a $\evaldc A B$
como uma funcção
$$
\evaldc A B : \pfcross {(A \to B)} A \to B.
$$
Ou seja, para chamá-la escrevemos
$$
\evaldc A B (f,a).
$$
Mas (abusando a notação!)~posso considerar o mesmo símbolo
$\evaldc A B$ para denotar sua currificação
$$
\evaldc A B : {(A \to B)} \to A \to B
$$
que \emph{é uma funcção diferente sim}, nesse caso escrevendo
$$
\evaldc A B \fa f \fa a.
$$
Tudo isso apenas no caso que pelo contexto tá claríssimo qual
das duas funcções tá sendo denotada.

%%}}}

\TODO notação de ``aridades maiores'' currificada.

%%{{{ human_eyes_and_ho_types 
\note Olhos humanos e os tipos higher-order.
%%%{{{ meta 
\label human_eyes_and_ho_types
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ partial_application_and_currying 
\note Aplicação parcial e currificação.
%%%{{{ meta 
\label partial_application_and_currying
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ eg: powTwo 
\example powTwo.
%%%{{{ meta 
\label powTwo
%%%}}}

Definimos a funcção $\namedfun{powTwo} : \nats\to\reals$ pela
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2.
$$
Assim $powTwo\fa 0 = 1$, $\namedfun{powTwo} \fa 10 = 1024$, etc.

%%}}}

%%{{{ remark: looks_like_cancellation 
\remark Parece cancelamento.
%%%{{{ meta 
\label looks_like_cancellation
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já entramos bastante to território de programação funccional;
paramos aqui agora, e voltamos re-visitar e expandir tudo isso
no~\ref[Functional_programming].

%%}}}

\endsection
%%}}}

%%{{{ An_epic_trip 
\section Uma viagem épica.
%%%{{{ meta 
\label An_epic_trip
%%%}}}

%%{{{ mathematical_OCD: Something irritating 
\note Algo irritante?.
%%%{{{ meta 
\label mathematical_OCD
\indexes
    * TOC!matemático
    ;;
%%%}}}

Seria bom desenvolver um certo ``TOC'' matemático:
ganhar certas frescuras matemáticas úteis, e sentir
\emph{matematicamente irritados} quando sentir algo bizarro.
E algo bizarro já aconteceu recentemente:
tá bem ali na~\ref[jections] de injetora e sobrejetora:
$$
\matrix
\format
\l & \;\c\; & \l\, & \l\, & \l \\
\text{$f$ injetora}    & \defiff & \pforall {x \in A} & \pforall {y \in A} & \quantified{f\fa x = f \fa y \implies x = y}; \\
\text{$f$ sobrejetora} & \defiff & \pforall {b \in B} & \pexists {a \in A} & \quantified{f \fa a = b}.
\endmatrix
$$
Consegues ver algo irritante?
\spoiler
Injectividade e sobrejectividade têm cara de conceitos que
deveriam ser intimamente relacionados.
Simétricos, duais, espelhados, sei lá o que,
algo que com certeza não parece olhando para suas definições!
A primeira começa com dois quantificadores do mesmo tipo,
universais, ambos no domínio, e acaba com uma implicação;
a segunda começa com dois quantificadores de tipos diferentes:
um existencial, agora no codomínio, o outro universal no domínio,
e acaba com uma igualdade!
\emph{Nada a ver}, pelo jeito!\foot
Existe uma justificativa muito boa sobre isso:
na própria idéia do que é uma funcção, não tratamos
seu domínio e seu codomínio numa maneira parecida:
a funcção foi ``total no seu domínio'' mas não no seu
codomínio, e foi ``univoca'', ou seja, do mesmo ponto
do seu domínio não podem sair duas setinhas (barrada),
mas estamos de boas se nuns pontos do seu codomínio
chegam mais que uma setinhas.
Esqueça esse ponto de vista para viajar comigo aqui;
prometo que no~\ref[Relations] tu pode voltar
a repensar nesse assunto.
\toof
Isso deveria te dar pelo menos uns arrepeios;
e no pior---melhor?---dos casos te deixar acordado até encontrar
definições desses dois conceitos que realmente são intimamente
relacionadas.
Agora calma---podes dormir tranqüilamente---pois vamos chegar
nessa satisfacção logo.

%%}}}

%%{{{ let_us_trip_1 
\note Bora viajar.
%%%{{{ meta 
\label let_us_trip_1
%%%}}}

Começamos na~\ref[Composition_laws] procurar conexões entre
a composição e a multiplicação e realmente achamos muitas
similaridades e essa influência já se tornou muito útil.
Vamos começar dando uma olhada novamente numa propriedade
de funcções, a injectividade.
Pela sua definição, $f$ é injetora exatamente quando
$$
\text{para todo $x,y$,} \quad f\fa x = f\fa y \implies x=y.
$$
Isso até parece pouco com cancelamento:
$$
\cancelspc f x = \cancelspc f y \implies x = y.
$$
Queremos investigar se e quando podemos cancelar uma
funcção quando operada com composições:
$$
\align
f \of g = f \of h &\askimplies g = h
\intertext{e como nossa operação já sabemos que não
é comutativa precisamos tratar essa questões similares separadamente:}
g \of f = h \of f &\askimplies g = h\\
g \of f = f \of h &\askimplies g = h.
\endalign
$$
Vamos voltar no
$$
\cancelspc f x = \cancelspc f y \implies x = y
$$
mas agora vamos fingir que os $f,x,y$ são números reais!
E logo as expressões $f x$ e $f y$ denotam apenas os produtos
$f\ntimes x$ e $f\ntimes y$.
Bem.
O que podemos concluir sabendo que
$$
f \fa x = f \fa y ?
$$
Caso $f\neq0$, podemos cancelá-lo:
$$
\cancelspc f x = \cancelspc f y
$$
chegando assim na
$$
x = y.
$$
Caso $f=0$, a $f$ não é cancelável.\foot
Por que não?
Se tu aprendeu numa maneira religiosa algum poeminha
do tipo ``não cancelarás $0$ nas multiplicações'', esqueça;
ninguém se importa com que teu padre falou.
A gente vai voltar nessa questão mais tarde
(\ref[Algebraic_structures] (\reftag[Rings]);
\ref[The_reals]).
\toof
\eop
Parece ótimo: exatamente o tipo da coisa que estamos procurando!
Será que podemos já trazer essa sabedoria da $\ntimes$
nos números para a $\of$ nas funcções?
O que seria nosso ``zero'' nas funcções?
Uma resposta boba seria <<a funcção constante 0>>.
Com certeza para funcções numéricas
a funcção constante $\kon 0 = \lam x 0$ não é nada de cancelável.
(Veja~\ref[kon_is_not_cancellable_in_general].)
Por que boba então?
Pois dizendo isso já perdemos a generalidade:
\emph{queremos algo descrevível para qualquer
funcção e não algo que serve apenas para funcções cujos codomínios
tem o $0$ como membro.}
Mas peraí.
Talvez não é o ``ser zero'' que é importante nesse ponto de
cancelamento!
Realmente: por que esse \wq{se $f \neq 0$} acima?
\emph{\wq{É que se $f=0$ então $f$ não é cancelável.}}
Mas essa resposta não é exatamente iluminante.
O que nos permite cancelar números na multiplicação?
Vamos tentar algo mais cuidadoso e formal:\foot
Mesmo sendo cedo neste momento para essa abordagem
creio que o leitor vai conseguir acompanhar a idéia.
Estudando algebra abstrata nos capítulos~\reftag[Group_theory]
e~\reftag[Algebraic_structures] tudo isso vai aparecer
bem tranqüilo e natural.  Prometo.
\toof
\compute
f x = f y
&\implies f^{-1} (f x) = f^{-1} (f y)   \by {multiplicando por $f^{-1}$} \\
&\implies (f^{-1} f) x = (f^{-1} f) y   \by {pela associatividade da $\ntimes$} \\
&\implies 1 x = 1 y                     \by {pela def.~da $f^{-1}$} \\
&\implies x = y.                        \by {pela def.~de $1$} \\
\endcompute
O único passo duvidoso seria o primeiro:
como sabemos que existe esse inverso?
\emph{Não sabemos.}
Então talvez é isso que estamos procurando!
Talvez
$$
\text{$f$ tem inversa} \iff \text{$f$ é cancelável}!
$$
Para demonstrar essa afirmação precisamos saber
o que ``cancelável'' significa formalmente aqui.
Qual das três implicações que consideramos acima vamos escolher?:
$$
\text{$f$ é cancelável}
\askiff
\leftbrace {
\aligned
f \of g = f \of h &\implies g = h \\
g \of f = h \of f &\implies g = h \\
g \of f = f \of h &\implies g = h.
\endaligned
}
$$
A $\ntimes$ nos números, sendo uma operação \emph{comutativa},
não consegue diferenciar entre essas afirmações.
Ou seja, por causa da riquesa das leis que temos
na multiplicação nos números, certas distinções desaparecem,
``se desabam''---algo que podemos pensar como pobresa também!
E vice versa: com menos leis ganhamos mais distinções---riquesa!
No mundo dos reais, um certo $x$ ou tem inverso
ou não.  De qual lado inverso?  Não faz sentido perguntar
isso nos números pois o lado não importa.
Quando importa, não vamos falar apenas sobre ``inverso'' mas sim sobre
\dterm{inverso esquerdo} e \dterm{inverso direito}.
Similarmente, nos números só tem uma $1$ para considerar;
nas funcções, cada conjunto $A$ chega com sua própria $1_A$!
\emph{O mundo das funcções é suficientemente rico para enxergar
essas noções inenxergáveis no mundo dos números!}

%%}}}

%%{{{ x: kon_is_not_cancellable_in_general 
\exercise.
%%%{{{ meta 
\label kon_is_not_cancellable_in_general
%%%}}}

Demonstre que a funcção constante $\kon 0 : \reals \to \reals$
em geral não é cancelável nem pela direita nem pela esquerda.

\solution
\proofpart{Incancelável pela esquerda.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\cos"']
\| \reals \ar[r, "\kon 0"]
\| \reals
\endcd
$$
que obviamente comuta; ou seja $\kon 0 \sin = \kon 0 \cos (= \kon 0)$)
mas mesmo assim $\sin \neq \cos$.
\crproofpart{Incancelável pela direita.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, "\kon 0"]
\|\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\id"']
\|\reals
\endcd
$$
que obviamente comuta; ou seja $\sin \kon 0 = \id \kon 0 (= \kon 0)$)
mas mesmo assim $\sin \neq \id$.

%%}}}

%%{{{ let_us_trip_2 
\note.
%%%{{{ meta 
\label let_us_trip_2
%%%}}}

Olhe de novo na implicação que tem na definição da injetora:
$$
f \fa x = f \fa y \implies x = y. \tag{L-canc}
$$
Ela lembra muito do que acabamos de demonstrar, mas nosso objectivo
foi investigar a composição $\of$ usando a multiplicação $\ntimes$.
Quando escrevi a (L-canc) em números, a juxtaposição denotou
a $\ntimes$ mesmo; mas na definição da injetora que temos,
a juxtaposição não denota a $\of$, mas a $\eval$!
Então vamos ver o que acontece se mudar para a $\of$, obviamente
tomando cuidado para usar objetos dos certos tipos:
$$
f \of g = f \of h \askimplies g = h
$$
que escrevemos por juxtaposição sem confusão:
$$
f \of g = f \of h \askimplies g = h.
$$
Vamos tentar imitar a demonstração anterior:
\compute
f g = f h
&\implies {\finv f} (f g) = {\finv f} (f h) \by {??} \\
&\implies ({\finv f} f) g = ({\finv f} f) h \by {(F-Ass)} \\
&\implies \idoneof A g = \idoneof A h       \by {(F-Inv)} \\
&\implies g = h                             \by {(F-Id)} \\
\endcompute
O que precisamos no \symq{??} acima?

%%}}}

\spoiler

%%{{{ let_us_trip_3 
\note.
%%%{{{ meta 
\label let_us_trip_3
%%%}}}

Uma resposta ``de preguiça'' seria <<preciso $f$ bijetora>>.
Claro que isso é \emph{suficiente}, mas é \emph{necessário}
também?  Começamos pensanso que <<$f$ injetora>> é algo que
corresponde nesse cancelamento aí, então será que basta só
isso?
Mas parece que precisei a existência de $\finv f$,
ou seja, precisamos que $f$ seja invertível.  Ou não?
Lembre que o inverso $\finv f$ de $f$ é um objeto que
satisfaz \emph{ambas} as
$$
\xxalignat3
&\text{LInv} & \finv f f &= \idoneof A;  & f \finv f &= \idoneof B & \text{RInv}
\endxxalignat
$$
mas, olhando de novo para nosso caminho, a gente precisou
apenas a (LInv).
Então não necessitamos mesmo que $f$ tem um inverso $\finv f$;
basta ter um inverso-esquerdo $\labL f$ e a prova rola:
\compute
f g = f h
&\implies {\labL f} (f g) = {\labL f} (f h) \by {$f$ é L-invertível} \\
&\implies ({\labL f} f) g = ({\labL f} f) h \by {(F-Ass)} \\
&\implies \idoneof A g = \idoneof A h       \by {(F-LInv)} \\
&\implies g = h                             \by {(F-Id)} \\
\endcompute
Já temos descoberto umas idéias interessantes:
L-cancelável e L-invertível, e obviamente temos as noções
laterais de R-cancelável e R-invertível.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Influenciados por toda essa viagem, podemos chegar nuns resultados
muito importantes e interessantes sobre as ``jectividades''
(`in-' e `sobre-'); as invertibilidades laterais;
e as cancelabilidades laterais das funcções.

%%}}}

%%{{{ Q: guess the theory that's about to come 
\question.
%%%{{{ meta 
%%%}}}

Quais resultados tu acha que vamos demonstrar?
Consegues prová-los?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Pare ser o seguinte:
$$
\matrix
\format
\l & \c & \l & \c & \l & \c & \l \\
\text{$f$ mono} & \defiff & \text{$f$ L-cancelável} & \askiff & \text{$f$ L-invertível} & \askiff & \text{$f$ injetora} \\
\text{$f$ epí}  & \defiff & \text{$f$ R-cancelável} & \askiff & \text{$f$ R-invertível} & \askiff & \text{$f$ sobrejetora}.
\endmatrix
$$
Sim, tem esses nomes ``chique'' mesmo:

%%}}}

%%{{{ df: mono_epi_functions
\definition mono, epi.
%%%{{{ meta 
\label mono_epi_functions
\indexes
    * mônica   see: funcção, mono
    * épica    see: funcção, epí
    ;;
\defines
    * funcção!epi
    * funcção!mono
    ;;
%%%}}}

Seja $f : A \to B$.
Dizemos que $f$ é uma funcção \dterm{mônica}
(ou simplesmente que $f$ é uma \dterm{mono}) sse $f$ é $\of$-cancelável pela esquerda.
Dizemos que $f$ é uma funcção \dterm{épica}
(ou simplesmente que $f$ é uma \dterm{epí}\/) sse $f$ é $\of$-cancelável pela direita.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora investigar então!

%%}}}

%%{{{ thm: injection_iff_mono 
\theorem.
%%%{{{ meta 
\label injection_iff_mono
%%%}}}

Sejam $B \toby f C$.
A $f$ é injetora sse ela é \dterm{$\of$-cancelável pela esquerda:}
$$
f\of g = f \of h \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.

\sketch.
A direção {\lrdir} é o~\ref[injection_iff_mono_lrproof].
Para a direção {\rldir}, tome $b,b'\in B$ tais que $f(b)=f(b')$.
Basta demonstrar que $b=b'$.
Tome $A\asseq\set{0}$ e defina $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
em tal maneira que o diagrama comuta (tem que definir mesmo as $g,h$).
Usamos agora a hipótese para concluir que $b=b'$.

\proof.
\proofpart{\lrdir:} \ref[injection_iff_mono_lrproof]:
\crproofpart{\rldir:}
Suponha $b,b' \in B$ tais que $f(b) = f(b')$.
Basta mostrar que $b = b'$.
Temos então o diagrama interno seguinte:
$$
\tikzpicture
\tikzi mono_implies_inj0;
\endtikzpicture
$$
Seja $A = \set{0}$ e defina as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
como as funcções constantes definidas pelas 
$$
g(0) = b
\qqtext{e}
h(0) = b'.
$$
Então agora estamos com o diagrama interno assim:
$$
\tikzpicture
\tikzi mono_implies_inj1;
\endtikzpicture
$$
Observe que como
$$
\align
(f\of g)(0) &= f(g(0)) = f(b) \\
(f\of h)(0) &= f(h(0)) = f(b')
\endalign
$$
e $f(b) = f(b')$, temos
$f\of g = f\of h$ e agora usamos a hipótese para ganhar $g = h$.
Logo as $g,h$ concordam no $0$, ou seja, $b = b'$.

%%}}}

%%{{{ x: injection_iff_mono_lrproof 
\exercise.
%%%{{{ meta 
\label injection_iff_mono_lrproof
%%%}}}

Demonstre a direção {\lrdir} do~\ref[injection_iff_mono].

\solution
Suponha então que $f\of g = f\of h$.
Vamos mostrar que $g = h$.
Seja $x \in A$.
Pela hipótese,
$$
(f\of g)(x) = (f\of h)(x)
$$
logo $f(g(x)) = f(h(x))$
e como $f$ injetora, chegamos no desejado $g(x) = h(x)$.

%%}}}

%%{{{ thm: surjection_iff_epic 
\theorem.
%%%{{{ meta 
\label surjection_iff_epic
%%%}}}

Sejam $B \toby f C$.
A $f$ é sobrejetora sse ela é \dterm{$\of$-cancelável pela direita:}
$$
g\of f = h\of f \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.
Digamos então que $f$ é \dterm{$\of$-cancelável pela direita}.

\sketch.
A direção {\lrdir} é o~\ref[surjection_iff_epic_lrproof].
Para a direção {\rldir}, tomamos $c \in C$ e procuramos achar
$b\in B$ tal que $f(b) = c$.
Defina o $D$ (cuidado: aqui não ajuda tomar $D=\set{0}$)
e as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
em tal maneira que $g\neq h$,
mas mesmo assim \emph{concordam em todo o $C$ exceto no ponto $c$}.
Usando a contrapositiva da hipótese ganhamos
$g\of f \neq h\of f$, mas isso só pode acontecer se a $f$ mandou pelo
menos um ponto do domínio dela para o $c$.

\proof.
\lrdir:
\ref[surjection_iff_epic_lrproof].
\eop
\rldir:
Suponha $c\in C$.
Procuramos $b\in B$ tal que $f(b) = c$.
Começamos então com o diagrama interno seguinte:
$$
\tikzpicture
\tikzi epic_implies_surj0;
\endtikzpicture
$$
Seja $D=\set{0,1}$ e defina as funcções $g,h:C\to D$ pelas
$$
g(y) = 0
\qqtext{e}
h(y) = \knuthcases {
1, &se $y = c$; \cr
0, &se $y \neq c$.
}
$$
Logo $g(c) \neq h(c)$, mas $g(y)=h(y)$ para todo $y\neq c$.
Agora estamos assim:
$$
\tikzpicture
\tikzi epic_implies_surj1;
\endtikzpicture
$$
Como $g\neq h$ então, pela hipótese concluimos que $g\of f \neq h\of f$, ou seja,
as $g\of f$ e $h\of f$ discordam em pelo menos um membro de $B$,
e seja $b$ um tal membro:
$$
(g\of f)(b) \neq (h\of f)(b).
$$
Logo
$$
g(f(b)) \neq h(f(b)),
$$
ou seja, $g$ e $h$ discordam no $f(b)$.
Mas $g$ e $h$ discordam apenas no $c$; ou seja,
$f(b) = c$ como desejamos.

%%}}}

%%{{{ x: surjection_iff_epic_lrproof 
\exercise.
%%%{{{ meta 
\label surjection_iff_epic_lrproof
%%%}}}

Demonstre a direção {\lrdir} do~\ref[surjection_iff_epic].

\solution
Suponha que $g\of f = h\of f$.  Vamos mostrar que $g = h$.
Seja $c\in C$.
Logo existe $b\in B$ tal que $f(b) = c$.
Como
$$
(g\of f)(b) = (h\of f)(b)
$$
temos $g(f(b)) = h(f(b))$; e, pela escolha de $b$, $g(c) = h(c)$.
Logo $g = h$.

%%}}}

%%{{{ x: mono_epi_commutative_diagrams 
\exercise Mono e epí com diagramas comutativos.
%%%{{{ meta 
\label mono_epi_commutative_diagrams
%%%}}}

Descreva as propriedades das definições de mono e
epi~(\reftag[mono_epi_functions]) usando diagramas comutativos.

\solution
\proofpart{A funcção $f$ é mônica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
temos $g=h$.
\crproofpart{A funcção $f$ é épica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
temos $g=h$.

%%}}}

%%{{{ df: isomorphic_sets 
\definition conjuntos isómorfos.
%%%{{{ meta 
\label isomorphic_sets
\defines
    * ~A \iso ~B  -- os conjuntos $A,B$ são isómorfos
    * ~f : ~A \iso ~B  -- $f : A \isoto B$ (notação alternativa)
    * ~f : ~A \isoto ~B  -- $f$ é um isomorfismo do $A$ para o $B$
    * isomorfismo!de conjuntos
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos os $A,B$ \dterm{conjuntos isómorfos} (ou \dterm{isomórficos})
sse existe bijecção $f : A \bijto B$.
Nesse caso chamamos a $f$ um \dterm{isomorfismo de conjuntos}.
Escrevemos $A \iso B$, e também
$f : A \iso B$ ou $f : A \isoto B$ para denotar que
$f$ é um isomorfismo do conjunto $A$ para o conjunto $B$.

%%}}}

%%{{{ remark: etymology_of_isomorphic 
\remark etimologia.
%%%{{{ meta 
\label etymology_of_isomorphic
%%%}}}

As palavras vêm do grego \emph{ίσο}
que significa ``igual'' e \emph{μορφή} que significa ``forma''.
Isómorfos então são aqueles que têm a mesma forma; ``a mesma cara''.
Mas o que significa forma, cara?
Depende do contexto!
Aqui nos conjuntos, podemos pensar que $A\iso B$ quis dizer
que os $A$ e $B$ só podem variar nos \emph{nomes} usados para
seus membros e em nada mais: um isomorfismo seria um renomeamento,
uma tradução \emph{fiel} de $A$ para $B$.  Podemos considerar
então o $B$ como uma \emph{cópia} do $A$ onde apenas re-rotulámos
seus membros.
Começando no~\ref[Group_theory] vamos estudar tipos de coisas
onde sua forma é bem mais rica que isso, e lá ``isómorfos'' vai
acabar sendo uma noção bem mais forte.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já tivemos definido os conceitos de inversa e de identidade
antes de fazer essa viagem que fizemos aqui.
Mas com essa experiência podemos voltar e repensar
em mais motivações e influências para chegar nesses
conceitos, e mais provas para demonstrar nossos
teoremas.
Pode viajar à vontade!
Graças a tudo isso, já podemos dormir tranqüilamente
pois encontramos finalmente umas definições para satisfazer
nossas frescuras.

%%}}}

\endsection
%%}}}

%%{{{ Pointfree_style 
\section Funcções estilo pointfree---``de fora''.
%%%{{{ meta 
\label Pointfree_style
%%%}}}

%%{{{ Defining concepts 
\note Definindo conceitos.
%%%{{{ meta 
%%%}}}

\TODO Elaborar.

%%}}}

%%{{{ function_laws 
\note Leis de funcções (com equações).
%%%{{{ meta 
\label function_laws
%%%}}}

As configurações na esquerda implicam as identidades na direita:
$$
\align
A \toby f B \toby g C \toby h D
& \;\;\implies\;\;
(h \of g) \of f = h \of (g \of f)
\tag{F-Ass}\\
A \toby f B
& \;\;\implies\;\;
\leftbrace {
\aligned
f \of \idof A &= f \\
\idof B \of f &= f
\endaligned
}
\tag{F-Id} \\
A \bijtoby f B
& \;\;\implies\;\;
\leftbrace {
\aligned
\finv f \of f &= \idof A \\
f \of \finv f &= \idof B
\endaligned
}
\tag{F-Inv}
\endalign
$$

%%}}}

%%{{{ x: cd_finv_laws 
\exercise.
%%%{{{ meta 
\label cd_finv_laws
%%%}}}

Como podemos expressar as leis da inversa (F-Inv)
usando apenas a comutatividade dum diagrama?

\hint
A forma do diagrama parece com o diagrama das
leis de identidade (\ref[cd_id_laws]).

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "\id"']\ar[r, "f"] \| B \ar[d, "\finv f"]  \ar[dr, "\id"]   \\
                               \| A \ar[r, "f"'] \| B
\endcd
$$

%%}}}

%%{{{ Defining functions 
\note Definindo funcções.
%%%{{{ meta 
%%%}}}

\TODO Elaborar.

%%}}}

%%{{{ eg: two_x_plus_one 
\example.
%%%{{{ meta 
\label two_x_plus_one
%%%}}}

Defina a funcção $f = \lam x {2x+1} : \nats\to\nats$ diretamente como
composição de funcções sem usar $\lambda$-notação.
Desenha o diagrama externo da configuração e confirme tua resolução.
\solution.
Temos as funcções
$$
\cdopt{sep=1.666cm}
\nats
\ar[r, "\dsize\diag"]   \| \nats\cross\nats
\ar[r, "\dsize\nplus"]  \| \nats
\ar[r, "\dsize\succ"]   \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{\succ} \of \mathord{\nplus} \of {\diagdom\nats}} : \nats \to \nats
$$
e tomando um $x\in\nats$ calculo:
\compute
f(x)
&= \paren{\succ \of \mathord{\nplus} \of \diag} (x) \by {def.~$f$} \\
&= \succ(\mathord{\nplus}(\diag(x)))                \by {def.~$\of$} \\
&= \succ(\mathord{\nplus}(x,x))                     \by {def.~$\diag$} \\
&= \succ(2x)                                        \\
&= 2x+1                                             \by {def.~$\succ$} \\
\endcompute
confirmando assim que minha definição foi correta.

%%}}}

%%{{{ x: two_x_squared_pointfree 
\exercise.
%%%{{{ meta 
\label two_x_squared_pointfree
%%%}}}

Faça a mesma coisa para a funcção $f = \lam x {2x^2} : \nats\to\nats$.

\solution
Temos as funcções
$$
\cd
\nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "\ntimes"] \| \nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "+"]       \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{+} \of \diagdom\nats \of {\ntimes} \of \diagdom\nats} : \nats \to \nats
$$
e tomando um $x\in\nats$ confirmo:
\compute
f(x)
&= \paren{\mathord{+} \of \diag \of \mathord{\ntimes} \of \diag} (x) \by {def.~$f$} \\
&= \mathord{+}(\diag(\mathord{\ntimes}(\diag(x))))                   \by {def.~$\of$} \\
&= \mathord{+}(\diag(\mathord{\ntimes}(x,x)))                        \by {def.~$\diag$} \\
&= \mathord{+}(\diag(x^2))                                           \\
&= \mathord{+}(x^2,x^2)                                              \by {def.~$\diag$} \\
&= x^2 + x^2                                                         \\
&= 2x^2.
\endcompute

%%}}}

%%{{{ df: retraction_section 
\definition Retracções, secções.
%%%{{{ meta 
\label retraction_section
\defines
    * funcção!inversa direita
    * funcção!inversa esquerda
    * funcção!retracção
    * funcção!secção
    ;;
%%%}}}

Seja $f : A \to B$.
Se $r : B \to A$ satisfaz a
$$
r \of f = \idof A
$$
dizemos que $r$ é uma \dterm{retracção} ou uma
\dterm{$\of$-inversa esquerda} da $f$.
Se $s : B \to A$ satisfaz a
$$
f \of s = \idof B
$$
dizemos que $s$ é uma \dterm{secção} ou uma
\dterm{$\of$-inversa direita} da $f$.
Observe que no primeiro caso, $f$ é uma secção da $r$;
e no segundo caso $f$ é uma retracção da $s$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ganhamos imediatamente dois corolários fáceis dos teoremas
\reftag[injection_iff_mono]--\reftag[surjection_iff_epic]:

%%}}}

%%{{{ cor: retraction_implies_injection 
\corollary.
%%%{{{ meta 
\label retraction_implies_injection
%%%}}}

Se $f : A \to B$ tem retracção, então $f$ é injetora.

\proof.
Seja $r$ uma retracção da $f$.
Temos
$$
f \of g = f \of h
\implies r \of f \of g = r \of f \of h
\implies \idof A \of g = \idof A \of h
\implies g = h
$$
e logo $f$ é injetora pelo~\ref[injection_iff_mono].

%%}}}

%%{{{ cor: section_implies_surjection 
\corollary.
%%%{{{ meta 
\label section_implies_surjection
%%%}}}

Se $f : A \to B$ tem secção, então $f$ é sobrejetora.

\proof.
Seja $s$ uma secção da $f$.
Temos
$$
g \of f = h \of f
\implies g \of f \of s = h \of f \of s
\implies g \of \idof B = h \of \idof B
\implies g = h
$$
e logo $f$ é sobrejetora pelo~\ref[surjection_iff_epic].

%%}}}

%%{{{ x: retraction_implies_injection_elementary_proof 
\exercise.
%%%{{{ meta 
\label retraction_implies_injection_elementary_proof
%%%}}}

Demonstre o~\ref[retraction_implies_injection] elementariamente
(sem o~\reftag[injection_iff_mono]).

\solution
Suponha que $f : A \to B$ e que $r : B \to A$ é uma retracção da $f$.
Tome $x, x' \in A$ tais que $f(x) = f(x')$.
Logo $r(f(x)) = r(f(x'))$.
Logo $(r\of f)(x) = (r\of f)(x')$.
Como $r$ é retracção, temos $\idof A(x) = \idof A(x')$,
ou seja, $x = x'$ e $f$ é injetora.

%%}}}

%%{{{ x: section_implies_surjection_elementary_proof 
\exercise.
%%%{{{ meta 
\label section_implies_surjection_elementary_proof
%%%}}}

Demonstre o~\ref[section_implies_surjection] elementariamente
(sem o~\reftag[surjection_iff_epic]).

\solution
Suponha que $f : A \to B$ e que $s : B \to A$ é uma secção da $f$.
Tome $b \in B$.
Logo $s(b) \in A$, e como $s$ secção, temos $f(s(b)) = b$, ou seja
a $f$ é sobrejetora pois mapeia $s(b) \mapstoby f b$.

%%}}}

\TODO Como chegar na definição alternativa.
% Exceto um detalhe que ainda falta verificar:

%%{{{ x: finv_altdef_missing_detail 
\exercise.
%%%{{{ meta 
\label finv_altdef_missing_detail
%%%}}}

O que mais falta demonstrar?
Apenas enuncie o que é, sem demonstrar.

\hint
A $\finv f$ foi definida apenas quando $f$ é bijetora.

%%}}}

%%{{{ thm: finv_atleastonelaw_if_f_bij_pointless 
\theorem Basta uma lei: agora sem pontos.
%%%{{{ meta 
\label finv_atleastonelaw_if_f_bij_pointless
%%%}}}

Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis da
inversa~(\ref[function_laws]), então $f' = \finv f$.

\proof.
Caso que $f'$ satisfaz a (L):
\compute
f'
&= f' \of \idof B          \by {lei da $\idof B$} \\
&= f' \of (f \of \finv f)  \by {(R) da $\finv f$} \\
&= (f' \of f) \of \finv f  \by {assoc.} \\
&= \idof A \of \finv f     \by {(L) da $f'$} \\
&= \finv f.                \by {lei da $\idof A$} \\
\intertext{E caso que $f'$ satisfaz a (R):}
f'
&= \idof A \of f'          \by {lei da $\idof A$} \\
&= (\finv f \of f) \of f'  \by {(L) da $\finv f$} \\
&= \finv f \of (f \of f')  \by {assoc.} \\
&= \finv f \of \idof B     \by {(R) da $f'$} \\
&= \finv f.                \by {lei da $\idof B$} \\
\endcompute

%%}}}

%%{{{ x: retraction_and_section_implies_inverse 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $f : A \to B$ tal que $r,s : A \from B$ são retracção
e secção da $f$ respectivamente.
Podemos concluir a afirmação seguinte?:
$$
\text{$f$ é bijetora}
\quad\mland\quad
\text{$r = \finv f = s$}.
$$
Se sim, demonstre; se não, refute.

\hint
Primeiramente observe:
$$
\rightbrace {
\aligned
\text{$f$ tem retracção} &\implies   \text{$f$ é injetora} \\
\text{$f$ tem secção}    &\implies   \text{$f$ é sobrejetora}
\endaligned
}
\implies \text{$f$ bijetora}.
$$

\solution
Como $f$ tem retracção, ela é injetora;
e como ela tem secção, ela é sobrejetora;
logo $f$ é bijetora e a $\finv f$ é definida.
Aplicamos então o~\ref[finv_atleastonelaw_if_f_bij] com $f'\asseq r$
e com $f'\asseq s$ e ganhamos:
$$
r = \finv f = s.
$$

%%}}}

\endsection
%%}}}

%%{{{ Partial_functions 
\section Funcções parciais.
%%%{{{ meta 
\label Partial_functions
%%%}}}

%%{{{ intro 
\secintro
A restricção que uma funcção $f : A \to B$ precisa ser \emph{totalmente}
definida no $A$, não nos permite considerer naturalmente situações onde
um certo programa, por exemplo, retorna valores para certas entradas
aceitáveis, e para as outras não:
talvez ele fica num \emph{loop infinito}; ou ele faz a máquina explodir;
ou simplesmente não termina com uma saída---não importa o porquê.
Definimos então o conceito de \emph{funcção parcial}, que é exatamente
isso: funcções que para certas entradas aceitáveis delas, possivelmente
\dterm{divergem}.
%%}}}

%%{{{ df: partial_function 
\definition.
%%%{{{ meta 
\label partial_function
\defines
    * \pars {~A} {~B}  -- o conjunto das funcções parciais de $A$ para $B$
    * ~f : ~A \parto ~B  -- $f$ é uma funcção parcial de $A$ para $B$
    * funcção!parcial
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos a $f$ uma \dterm{funcção parcial} de $A$ para $B$ sse:
$$
\text{para todo $x\in A$, se $f(x)$ é definido então $f(x) \in B$.}
$$
Nesse caso, chamamos \dterm{domínio de convergência} o conjunto
$$
\domain f \defeq \setstt {x \in A} {$f(x)$ é definido}
$$
e \dterm{codomínio} o $B$ mesmo.
Escrevemos $f : A \parto B$ para \wq{$f$ é uma funcção parcial de $A$ para $B$}.
Naturalmente denotamos o conjunto de todas as funcções parciais de $A$ para $B$ por
$$
(A \parto B) \defeq \setst f {f : A \parto B}.
$$

%%}}}

%%{{{ x: size_of_pars 
\exercise.
%%%{{{ meta 
\label size_of_pars
%%%}}}

Se $A,B$ são finitos,
qual a cardinalidade do $\pars A B$?

\hint
Já calculou como achar a cardinalidade de $\funs X Y$ para
quaisquer finitos $X,Y$.
Então \emph{hackeia!}

\hint
Considere um objeto $\bottom$ fora do $B$.

%%}}}

%%{{{ remark: total vs partial: default 
\remark.
%%%{{{ meta 
%%%}}}

Com essas definições cada funcção total é uma funcção parcial.
Escrevemos esse \wq{total} quando queremos enfatizar, mas normalmente
\wq{funcção} sem o adjectivo \wq{parcial} significa \wq{funcção total}.
Claramente, quando trabalhamos principalmente com funcções parciais,
seguimos a convenção oposta.

%%}}}

%%{{{ remark: partial function conditions 
\remark Condições.
%%%{{{ meta 
%%%}}}

Encontramos então aqui o que acontece se apagar a primeira das
condições~\reftag[functionhood_conditions]:
\tlist: \notags
\li: \strikeout{(1)~totalidade};
\li: (2)~determinabilidade.
\endtlist
e ficar só com a (2).
No~\ref[Relations] vamos estudar também o caso onde apagamos ambas as condições.

%%}}}

\endsection
%%}}}

%%{{{ Recursive_definitions_as_systems 
\section Definições recursivas.
%%%{{{ meta 
\label Recursive_definitions_as_systems
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já encontramos várias definições recursivas.
Agora vamos analizar com que precisamos tomar cuidado para garantir
que nossas ``funcções'' realmente são funcções bem-definidas.
Vamos começar lembrando como exemplo duas funcções recursivas famosas demais.

%%}}}

%%{{{ eg: fact_and_fib_recursive_eg 
\example.
%%%{{{ meta 
\label fact_and_fib_recursive_eg
%%%}}}

Sejam $a:\nats\to\nats$ definida pelas
$$
\align
a(0) &= 1\\
a(n) &= n \ntimes a(n-1), \quad\text{para todo $n>0$};
\intertext{e $b:\nats\to\nats$ definida pelas}
b(0) &= 1\\
b(1) &= 1\\
b(n) &= b(n-1) + b(n-2), \quad\text{para todo $n>1$}.
\endalign
$$
Muitas vezes deixamos as frases ``para todo $n>0$'' como
implícitas pelo contexto---mas entenda que elas precisam estar lá,
e \emph{estão} lá mesmo quando escolhemos omiti-las.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora, assuma que tu aceita ambas as $a,b : \nats\to\nats$ do
exemplo assima como funcções \emph{bem-definidas}, e continue lendo.

%%}}}

%%{{{ mutual_recursion 
\note Recursão mutual.
%%%{{{ meta 
\label mutual_recursion
%%%}}}

Podemos definir duas ou mais funcções, cada uma chamando recursivamente
outras, tomando certos cuidados como sempre para garantir que realmente
todas as funcções vão ser definidas mesmo para todas as entradas
aceitas pelos domínios delas.

%%}}}

%%{{{ eg: mutual_recursion_even_odd 
\example.
%%%{{{ meta 
\label mutual_recursion_even_odd
%%%}}}

Vamos definir as funcções $\even,\odd:\nats\to\set{0,1}$ pelas
$$
\xalignat2
\even(0)   &= 1       & \odd(0)   &= 0 \\
\even(n+1) &= \odd(n) & \odd(n+1) &= \even(n)
\endxalignat
$$
Calculamos, por exemplo:
$$
\align
\even(3) &
= \odd(2)
= \even(1)
= \odd(0)
= 0 \\
odd(3) &
= \even(2)
= \odd(1)
= \even(0)
= 1
\endalign
$$

%%}}}

%%{{{ Safe recursion 
\note Recursão segura.
%%%{{{ meta 
%%%}}}

Na maioria das vezes que definimos funcções recursivamente
existe ``algo''---muitas vezes esse ``algo'' é o próprio
argumento da funcção (como no~\ref[fact_and_fib_recursive_eg])
mas não sempre---que com cada ``chamada recursiva''
da funcção fica menor e menor, até cair num valor que garanta
uma ``saída da recursão''.
(Essa descripção é bem vaga sim.)

%%}}}

%%{{{ eg: recursion_with_powers_of_two 
\example.
%%%{{{ meta 
\label recursion_with_powers_of_two
%%%}}}

Seja $p : \nats\to\nats$ a funcção definida pela:
$$
p(x) =
\knuthcases {
\log_2(x), & se $x$ é uma potência de $2$;\cr
p(x+1), & se não.
}
$$
Aqui nas chamadas recursivas não é o próprio argumento que é
``cada vez menor''---pelo contrário: as chamadas recursivas
estão sendo cada vez com argumento maior!
Mesmo assim, a recursão ``sempre termina'', e a $f$ realmente
é bem-definida.
Calculamos como exemplo uns valores:
$$
\align
p(0) &= p(1) = \log_2(1) = 0 \\
p(4) &= \log_2(4) = 2 \\
p(5) &= p(6) = p(7) = p(8) = \log_2(8) = 3 \\
p(1020) &= p(1021) = p(1022) = p(1023) = p(1024) = \log_2(1024) = 10.
\endalign
$$

%%}}}

%%{{{ x: find invariant 
\exercise.
%%%{{{ meta 
%%%}}}

Ache um ``algo'' que fica cada vez menor com cada chamada recursiva
da $p$ do~\ref[recursion_with_powers_of_two].

\hint
Uma ``distância'' está sendo cada vez menor.  Qual?

\solution
Com cada chamada com entrada $x$, o número $b - x$ é cada vez menor,
onde
$$
b = \min \setst {2^n} {x \leq 2^n, \ n\in\nats}.
$$

%%}}}

%%{{{ Dangerous recursion 
\note Recursão perigosa.
%%%{{{ meta 
%%%}}}

Não é cada equação recursiva que realmente defina uma funcção!
Vamos ver agora uns exemplos que mostram exatamente isso.

%%}}}

%%{{{ eg: dangerous_recursion_f 
\example.
%%%{{{ meta 
\label dangerous_recursion_f
%%%}}}

Seja $f : \nats\to\nats$ a funcção definida pela
$$
f(n) = f(n),
\quad\text{para todo $n\in\nats$}.
$$
É óbvio que isso não \emph{determina} uma funcção.
Mas por quê?

%%}}}

%%{{{ eg: dangerous_recursion_g 
\example.
%%%{{{ meta 
\label dangerous_recursion_g
%%%}}}

Seja $g : \nats\to\nats$ a funcção definida pela
$$
\align
g(0) &= 1 \\
g(n) &= g(n)+1, \quad\text{para todo $n>0$}.
\endalign
$$
Isso também não \emph{determina} uma funcção.
Por quê?

%%}}}

%%{{{ eg: dangerous_recursion_h 
\example.
%%%{{{ meta 
\label dangerous_recursion_h
%%%}}}

Seja $h : \nats\to\nats$ a funcção definida pela
$$
h(n) = h(n+1), \quad\text{para todo $n\in\nats$}.
$$
Isso também não \emph{determina} uma funcção---mas por quê?

%%}}}

%%{{{ x: what_is_the_problem_with_those_recursive_definitions 
\exercise.
%%%{{{ meta 
\label what_is_the_problem_with_those_recursive_definitions
%%%}}}

As perguntas sobre as $f,g,h$ acima não foram rhetóricas!

%%}}}

%%{{{ eg: pre_collatz_safe 
\example.
%%%{{{ meta 
\label pre_collatz_safe
%%%}}}

Considere a funcção $k : \nats \to \nats$ definida pela recursão
$$
\align
k(0) &= 1\\
k(1) &= 1\\
k(n) &=
\knuthcases {
k(n/2), & se $n$ é potência de $2$\cr
k(n+1), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma funcção $k : \nats\to\nats$?

%%}}}

%%{{{ eg: pre_collatz_unsafe 
\example.
%%%{{{ meta 
\label pre_collatz_unsafe
%%%}}}

Considere a funcção $d : \nats \to \nats$ definida pela recursão
$$
\align
d(0) &= 1\\
d(1) &= 1\\
d(n) &=
\knuthcases {
d(n/2), & se $n$ é potência de $2$\cr
d(n+3), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma funcção $d : \nats\to\nats$?

%%}}}

%%{{{ x: reply 
\exercise.
%%%{{{ meta 
%%%}}}

Responda nas perguntas dos exemplos acima~(\reftag[pre_collatz_safe]
e~\reftag[pre_collatz_unsafe]).

%%}}}

%%{{{ x: calculate_pre_collatz 
\exercise.
%%%{{{ meta 
\label calculate_pre_collatz
%%%}}}

Usando as $k,d : \nats\to\nats$ dos exemplos \reftag[pre_collatz_safe]
e~\reftag[pre_collatz_safe] acima calcule os:
$$
k(6); \quad
k(9); \quad
d(5); \quad
d(11);\quad
d(6).
$$
(Confira teus resultados com minha dica e minha resolução!)

\hint
Se tu achou valores para todas as expressões,
tu errou (pelo menos uma vez).
Todos eles são definidos exceto um!

\solution
Calculamos:
$$
\align
k(6)  &= k(7) = k(8) = k(4) = k(2) = k(1) = 1 \\
k(9)  &= k(10) = k(11) = k(12) = \dotsb = k(16) = k(8) \dotseq 1 \\
d(5)  &= d(8) = d(4) = d(2) = d(1) = 1 \\
d(11) &= d(14) = d(17) = d(20) = d(23) = d(26) = d(29) = d(32) = d(16) \dotseq 1 \\
d(6)  &= d(9) = d(12) = d(15) = d(18) = d(21) = d(24) = d(27) = d(30) = d(33) = d(36) = \dotsb
\endalign
$$
onde parece que o último cálculo \emph{nunca terminará}.
Deixo você se preocupar com a veracidade dessa afirmação
no~\ref[why_pre_collatz_unsafe_diverges_on_6].

%%}}}

%%{{{ x: k_is_the_constant_one 
\exercise.
%%%{{{ meta 
%%%}}}

Qual é a funcção $k$ do~\ref[pre_collatz_safe]?
(Tu deves saber um nome dela bem simples.)

\solution
Ela é a funcção constante do $\nats$ com valor $1$.

%%}}}

%%{{{ eg: collatz_recursive 
\example.
%%%{{{ meta 
\label collatz_recursive
%%%}}}

Considere a funcção $c : \nats \to \nats$ definida pela recursão
$$
\align
c(0) &= 1\\
c(1) &= 1\\
c(n) &=
\knuthcases {
c(n/2),  & se $n$ é par\cr
c(3n+1), & caso contrário
}\quad\text{(para $n > 1$)}.
\endalign
$$
E a mesma pergunta: aceita?

%%}}}

%%{{{ x: calculate three values 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule os valores $c(8), c(3), c(7)$ da funcção $c$ acima.

%%}}}

%%{{{ What's going on? 
\note O que tá acontecendo?.
%%%{{{ meta 
\label what_is_going_on_with_recursive_definitions
%%%}}}

Já deve ser claro que apenas escrevendo umas equações que envolvem
a funcção que queremos definir não é uma maneira segura que garanta
que realmente nossas equações \emph{determinam} (definam) uma funcção.
Umas vezes deu certo, outras não.
Mas em todos os casos, a ``definição'' da funcção foi apenas uma
\emph{lista de equações}.\foot
Foi mesmo?
Não exatamente: mas deixe isso para
depois~(\ref[not_exactly_a_list_of_equations]).
\toof
Estamos procurando entender melhor essa situação:
um cara chega com um um bocado de equações como uma suposta definição
recursiva duma funcção, e a gente da uma olhada nelas, e aceita isso como
definição mesmo;
outro cara chega com \emph{o mesmo tipo de coisa} (um bocado de equações)
e no caso dele a gente falou ``desculpa mas isso não serve como
definição de funcção''.
O que tá acontecendo?

%%}}}

%%{{{ Do you remember school "math"? 
\note Lembra da ``matemática'' na escola?.
%%%{{{ meta 
%%%}}}

Lembra os \emph{sistemas de equações} em um ou mais
\emph{incógnitos} que tu precisava \emph{resolver}
estudando matemática básica?\foot
Presumo aqui que o leitor já teve contato com esse
tipo de exercícios desde criança; mas caso contrário, espero
que a conversa vai continuar fazendo sentido.
\toof
Por exemplo, um exercício pode pedir para o aluno:
\emph{resolva o sistema} seguinte nos reais ($x\in\reals$):
\system
x^2     &= 64 \\
10 + 2x &= 2 + x
\endsystem
O aluno vai responder que
$$
\text{<<o sistema tem uma resolução única: $x = -8$>>}
$$
e vai ganhar um biscoito.
Esses sistemas são mais comuns em espaços de dimenções superiores
($\reals^2$, $\reals^n$, $\complex^n$, etc.).
Mas no final das contas, qual é o objectivo?
O que significa resolver um sistema deles?
Bem, significa dar uma das seguintes respostas:
\elist i:
\li: O sistema é impossível;
\li: O sistema é possível e indeterminado;
\li: O sistema é possível e determinado;
\endelist
e nos dois últimos casos, queremos descrever todas as resoluções
se for indeterminado, ou achar sua única resolução caso que é determinado.
Uns sistemas no $\reals^2$ por exemplo são os:
$$
\xxalignat4
\text{(A)}&
\lsystemed {
x^2 + y^2 &= 1 \\
y         &= 2x
}&
\text{(B)}&
\lsystemed {
y &= x^2 + 8 \\
x &= y + 1
}&
\text{(C)}&
\lsystemed {
x       &= 2y + 1 \\
3x - 6y &= 3
}&
\text{(D)}&
\lsystemed {
x &= y^2 \\
y &= \sin(x).
}&
\endxxalignat
$$
Aqui o aluno deu umas respostas interessantes.
(A) O sistema é possível mas indeterminado: tem duas resoluções:
$\tupp{x,y} = \tupp{\sqrt3/2, 1/2}$
e
$\tupp{x,y} = \tupp{1/2,\sqrt3/2}$.
(B) O sistema é impossível: nenhum par $\tupp{x,y}\in\reals^2$
satisfaz ambas as equações.
(C) O sistema é possível mas indeterminado: todos os membros do
conjunto
$
\setst {\tupp{t, 2t+1} \in\reals^2} {t\in \reals}
$
satisfazem o sistema (e tem pelo menos dois membros nesse conjunto---na
verdade tem uma infinidade deles).
(D) O sistema é possível e determinado: tem resolução única, o
$\tupp{x,y} = \tupp{0,0}$.

%%}}}

%%{{{ remark: infinite_does_not_mean_all_eg_systems 
\remark.
%%%{{{ meta 
\label infinite_does_not_mean_all_eg_systems
%%%}}}

O fato que um sistema tem uma infinidade de resoluções, não quis
dizer que \emph{todos} os possíveis candidatos são resoluções.
Por exemplo o sistema~(3) acima tem uma infinidade de resoluções,
mas não são todos os membros do $\reals^2$ que servem: considere
o $\tupp{x,y} \asseq \tupp{1,1}$ por exemplo.

%%}}}

%%{{{ Recursive definitions as systems to solve 
\note Definições recursivas como sistemas para resolver.
%%%{{{ meta 
%%%}}}

O que isso tem a ver com as definições recursivas?
No primeiro sistema acima estamos procurando \emph{números reais},
ou seja, estamos procurando determinar o \alert{incógnito}
$\alert x\in\reals$ que consegue satisfazer todas as suas equações.
$$
\align
\systemed {
\alert x^2     &= 64 \\
10 + 2\alert x &= 2 + \alert x
}&
\intertext{%
Podemos pensar então que todos os reais são candidatos consideráveis
aqui, e nosso trabalho é achar quem serve para o sistema (se é possível)
e quem não.
Testando então para o $\alert x\asseq 8$ temos:
}
\systemed {
\alert x^2            &= 64 \\
10 + 2\ntimes\alert x &= 2 + \alert x
}&\quad\leadsto\quad
\systemed {
\alert 8^2            &= 64 \\
10 + 2\ntimes\alert 8 &= 2 + \alert 8
}
\endalign
$$
e assim percebemos que o $8$ \emph{não} serve pois tem pelo menos uma
equação que ele não satisfaz.
E a situação é similar resolvendo sistemas com incógnitos membros
de $\reals^2$ ou $\complex^n$, etc., onde procuramos um par de números
reais no primeiro caso, ou $n$ números complexos no segundo, etc.
Testamos então o $(\sqrt 2, 0)$ nos sistemas
$$
\xxalignat4
\text{(A)}&
\lsystemed {
\alert x^2 + \alert y^2 &= 1 \\
\alert y         &= 2\alert x
}&
\text{(B)}&
\lsystemed {
\alert y &= \alert x^2 + 8 \\
\alert x &= \alert y + 1
}&
\text{(C)}&
\lsystemed {
\alert x       &= 2\alert y + 1 \\
3\alert x - 6\alert y &= 3
}&
\text{(D)}&
\lsystemed {
\alert x &= \alert y^2 \\
\alert y &= \sin(\alert x).
}&
\endxxalignat
$$
etc., etc.
\eop
Agora te convido olhar para todas as definições recursivas que a gente
encontrou aqui com uma maneira similar:
\emph{como sistemas}, onde agora \emph{o incógnito não é um número real
mas uma funcção no $(\nats\to\nats)$}.

%%}}}

%%{{{ eg: fibs again 
\example.
%%%{{{ meta 
%%%}}}

Considere o sistema que usamos para definir a funcção $b$
do~\ref[fact_and_fib_recursive_eg].
\system
\alert b(0) &= 0 \\
\alert b(1) &= 1 \\
\alert b(n) &= \alert b(n-1) + \alert b(n-2), \quad\text{para todo $n>1$}.
\endsystem
Agora o incógnito é uma funcção $b : \nats\to\nats$.
Vamos testar uns candidatos consideráveis:
tome $b \asseq \idof \nats$:
$$
\align
\rsystemed {
\alert{\idof \nats}(0) &= 0\\
\alert{\idof \nats}(1) &= 1\\
\alert{\idof \nats}(n) &= \alert{\idof \nats}(n-1) + \alert{\idof \nats}(n-2)
}
&\iff
\lsystemed {
0 &= 0\\
1 &= 1\\
n &= (n-1) + (n-2),\quad\text{para todo $n>1$}.
}
\intertext{%
Legal!  As duas primeiras linhas do sistema são satisfeitas.
Para a terceira, testando com o $n\asseq 3$ dá certo, pois realmente
$3 = 2 + 1$
mas é muito fácil perceber que essa igualdade não é satisfeita em geral.
Tome $n\asseq 4$ e já temos problema, pois
$4 \neq 3 + 2$.
O candidato $\idof \nats$ então não satisfaz o sistema.
Próximo!
Vamos tentar com $b \asseq \succ$, essa vez divulgando a notação
mais econômica, sem parenteses:
}
\rsystemed {
\alert{\succ}\fa 0 &= 0\\
\alert{\succ}\fa 1 &= 1\\
\alert{\succ}\fa n &= \alert{\succ} \fap {n-1} + \alert{\succ} \fap {n-2}
}
&\iff
\lsystemed {
1   &= 0\\
2   &= 1\\
n+1 &= n + (n-1),\quad\text{para todo $n>1$}.
}
\endalign
$$
Fuen-fuen-fuen!
Bem, então nem a $\idof \nats$ nem a $\succ$ satisfazem esse sistema.

%%}}}

%%{{{ remark: not_exactly_a_list_of_equations 
\remark.
%%%{{{ meta 
\label not_exactly_a_list_of_equations
%%%}}}

No~\ref[what_is_going_on_with_recursive_definitions]
afirmei que cada suposta definição de funcção foi ``apenas
uma lista de equações''.
São realmente listas de \emph{equações?}
Umas dessas afirmações não são equações não;
pois em vez de ter a forma ``\,${\lthole} = {\lthole}$\,''
elas têm a forma ``\,$\forall n {\lthole}$\,''.
Ou seja, correspondem em proposições universais
(quantificadas universalmente) e não em proposições
(atômicas) de equações.
Mas não seria errado considerar que essas são listas de
equações sim, com o acordo que\dots são listas infinitas!
Pois sim, podemos ver cada uma dessas como um \emph{esquema}
de equações que fornece uma equação para cada escolha de $n\in\nats$.

%%}}}

%%{{{ When a system serves as a definition.
\note Quando um sistema serve para definir.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Quando um sistema cujos incógnitos são números tem resolução
única isso quis dizer que o sistema \emph{determina}
um certo número.  Ou seja, \emph{podemos usar o próprio sistema
para definir um número real} como a resolução dele.
Por exemplo, escrevemos
<<seja $r\in\reals$ \emph{a} resolução do sistema tal>>, etc.
Observe o artigo definido!
No outro lado, se o sistema tem várias resoluções,
\emph{não pode servir como definição;} mas pelo menos
sabendo que o conjunto das suas resoluções não é vazio
podemos escrever, por exemplo,
<<seja $t\in\reals$ \emph{uma} resolução do sistema tal>>.
E nada muda com sistemas cujos incognitos são funcções!
E por que mudaria?  No final das contas é a existência
e unicidade de algo que nos permite defini-lo!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Voltamos agora para o sistema que usamos para definir
as funcções $a,b$ do~\ref[fact_and_fib_recursive_eg].

%%}}}

%%{{{ Q: Do you know of a solution to a or b's systems ?
\question.
%%%{{{ meta 
%%%}}}

Tu conhece alguma funcção que satisfaz o sistema da $a$?
Alguma que satisfaz o sistema da $b$?

%%}}}

\spoiler

%%{{{ A: Common answer 
\blah Resposta comum.
%%%{{{ meta 
%%%}}}

\emph{Possivelmente} o leitor respondeu
\quote
<<Sim:
o factorial para o primeiro, e a funcção fibonacci para o segundo.>>
\endquote
ou algo similar.
Só que: eu esqueci quais são essas funcções.
Pode lembrar pra mim, por exemplo, qual é essa funcção ``fibonacci''
que tu tá afirmando que é uma resolução do sistema da $b$?
\quote
\wq{Claro.  Vou escrever esse poeminho mágico para dar a sua\dots}
\endquote

%%}}}

%%{{{ df: fibonacci_dangerous_def 
\definition.
%%%{{{ meta 
\label fibonacci_dangerous_def
%%%}}}

Seja $\fib:\nats\to\nats$ definida pelas
$$
\text{(FIB)}\ \lsystemed {
\fib \fa 0 &= 0\\
\fib \fa 1 &= 1\\
\fib \fa n &= \fib\fap {n-1} + \fib\fap {n-2}, \quad\text{para todo $n>1$}.
}
$$
\mistake

%%}}}

%%{{{ Q: Is there a problem? 
\question.
%%%{{{ meta 
%%%}}}

Tem problema?

%%}}}

\spoiler

%%{{{ A: We used fib to justify its own definition!
\blah Resposta.
%%%{{{ meta 
%%%}}}

Usamos a própria coisa que queremos definir (a funcção fibonacci)
para justificar sua própria definição (ou seja, para argumentar
que o sistema (FIB) tem resolução única)!
(E sobre o factorial seria a mesma coisa.)
Como a $\fib$ foi definida pelas equações recursivas do (FIB),
sua definição \emph{depende da existência e unicidade da
resolução do sistema}, então não podemos usá-la antes
de demonstrar isso!

%%}}}

%%{{{ We can't prove existence yet; assume it and prove uniqueness 
\note.
%%%{{{ meta 
\credits
    * Fibonacci : funcção
    ;;
\indexes
    * teorema!de recursão
    ;;
%%%}}}

Infelizmente, caro \sayFibonacci, não estamos prontos neste momento
para demonstrar que esse sistema tem \emph{pelo menos} uma resolução!\foot
Mas calma, daqui uns capítulos estaremos!
\toof
Atrás desse fato fica o poderoso
Teorema de Recursão~\reftag[recursion_theorem].
Mas pelo menos deve ser fácil demonstrar que tem \emph{no máximo}
uma resolução:

%%}}}

%%{{{ x: fib_system_has_at_most_one_solution 
\exercise.
%%%{{{ meta 
\label fib_system_has_at_most_one_solution
%%%}}}

Demonstre que se o sistema (FIB) da~\ref[fibonacci_dangerous_def]
tem resolução, então ela é única.

\hint
Por ``fight club'':
suponha que $f,f'$ são resoluções do sistema (FIB);
demonstre que $f=f'$.

\hint
Ou seja, basta demonstrar que para todo $n\in\nats$, $f n = f'n$.

\hint
Indução!

\hint
Vai precisar de duas bases.

\solution
Sejam $f,f'$ resoluções do sistema (FIB).
Vou demonstrar por indução que:
$$
\lforall {n\in \nats} {f n = f'n}.
$$
Vou demonstrar duas bases, ganhando assim 2 hipoteses indutivas.
\crproofpart{Base 0:}
Calculamos:
\compute
f(0)  &= 1 \by {$f$ resolução de (FIB)} \\
f'(0) &= 1 \by {$f'$ resolução de (FIB)} \\
\endcompute
\crproofpart{Base 1:}
Mesma coisa: $f(1) = 1 = f'(1)$.
\crproofpart{Passo indutivo.}
Seja $k\in \nats$ tal que $f,f'$ concordam nos pontos $k-1$ e $k-2$:
$$
\xxalignat4
\text{(H.I.1)} & & f(k-1) &= f'(k-1) & f(k-2) &= f'(k-2). & & \text{(H.I.2)}
\endxxalignat
$$
Preciso demonstrar que elas concordam no ponto $k$ também:
\compute
f(k)
&= f(k-1) + f(k-2)   \by {$f$ resolução de (FIB)} \\
&= f'(k-1) + f'(k-2) \by {(H.I.1) e (H.I.2)} \\
&= f'(k).            \by {$f'$ resolução de (FIB)} \\
\endcompute
Pronto.

%%}}}

%%{{{ x: why_each_of_the_non_definitions_fails 
\exercise.
%%%{{{ meta 
\label why_each_of_the_non_definitions_fails
%%%}}}

Com esse novo ponto de vista, para cada uma
das supostas definições das funcções $f,g,h:\nats\to\nats$
(dos exemplos~\reftag[dangerous_recursion_f],
\reftag[dangerous_recursion_g], e~\reftag[dangerous_recursion_h])
responda na pergunta: por que não deu certo?
$$
\xalignat3
(1)~&\lsystemed {
f(n) &= f(n)
}&
(2)~&\lsystemed {
g(0) &= 1 \\
g(n) &= g(n)+1
}&
(3)~&\lsystemed {
h(n) &= h(n+1)
}
\endxalignat
$$
Foi porque o sistema não tem resoluções?
Ou porque tem várias?  Tem infinítas?  Tem todas?

\solution
Sobre a $f$:
toda funcção $f : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\eop
Sobre a $g$:
nenhuma funcção $g : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\eop
Sobre a $h$:
mais que uma funcção $h : \nats \to \nats$ satisfaz essa equação,
então não podemos usá-la como definição!

%%}}}

%%{{{ x: which_functions_satisfy_the_equations_of_h 
\exercise.
%%%{{{ meta 
\label which_functions_satisfy_the_equations_of_h
%%%}}}

Quais são exatamente as funcções que satisfazem a ``definição''
da $h$ acima?

\hint
Suponha que uma $h : \nats\to\nats$ satisfaz essa
definição, e suponha que seu valor $h(5) = v$
para algum $v\in\nats$.  O que podes concluir
sobre os valores da $h$ para suas outra entradas?

\solution
Todas as funcções constantes.

%%}}}

%%{{{ x: why_recursive_collatz_does_not_define_a_function 
\exercise.
%%%{{{ meta 
\label why_recursive_collatz_does_not_define_a_function
%%%}}}

Qual o problema com a definição da funcção $c$ do~\ref[collatz_recursive]?

\hint
Por que termina a recursão para toda entrada?

\solution
Não sabemos se ela satisfaz a totalidade de funcção, ou seja,
se ela é realmente definida em todo o seu domínio.
Ate agora, ninguém sabe dizer!
Essa é exatamente a conjectura de
Collatz{\Collatz[conjectura]}~(\ref[collatz_conjecture]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixamos esse assunto por enquanto (até o~\ref[Theory_of_recursive_functions]),
supondo que temos já um entendimento de como definições recursivas
funccionam.

%%}}}

\endsection
%%}}}

%%{{{ Coproduct; disjoint union 
\section Coproduto; união disjunta.
%%%{{{ meta 
\label Coproduct
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos voltar no~\ref[funion].
(Se tu não resolveu ainda, volte a resolver agora, antes de continuar.)
Definimos o $f \union g$ a partir de duas funcções $f$ e $g$ mas a
situação não foi tão agradável como esperamos (cf.~$f \cross g$):
necessitamos restrições adicionais.

%%}}}

%%{{{ Q: Whose fault is it? 
\question.
%%%{{{ meta 
%%%}}}

Quem é o culpado?

%%}}}

\spoiler

%%{{{ A: The union! 
\note Resposta.
%%%{{{ meta 
%%%}}}

A união!
O conjunto que $\union$ construiu, ο $A\union B$, não é útil aqui.
Nem se compara com o $A \cross B$, em questão de
utilidade e elegância.
Além disso---caso que os conjuntos são finitos por enquanto---%
com o produto tivemos a lei bacana
$$
\align
\card{A \cross B} &= \card A \ntimes \card B.
\intertext{%
A união não é tão legal, pois não consegue garantir igualdade
mas apenas
}
\card{A \union B} &\leq \card A + \card B.
\endalign
$$
Decepção de novo!
Será que podemos descobrir um outro operador binário
que comportaria numa maneira tão legal como o~$\cross$?

%%}}}

%%{{{ constructing the coproduct 
\note Contruindo o coproduto.
%%%{{{ meta 
%%%}}}

$$
\tikzpicture
\tikzi disjunion0;
\endtikzpicture
$$
unindo:
$$
\tikzpicture
\tikzi disjunion1;
\endtikzpicture
$$
Em vez disso, vamos criar cópias $A',B'$ dos $A,B$ numa maneira
que garanta que os $A',B'$ são disjuntos.
Por exemplo, pintamos todos os membros de $A$ azuis e de $B$ vermelhos:\foot
Leitores sem acesso nessas cores neste texto vão ficar confusos aqui;
mas paciência pois uma definição formal tá chegando já já; uma que
não necessita telas e impressoras (e olhos?)~chiques.
\toof
$$
\tikzpicture
\tikzi disjunion2;
\endtikzpicture
$$
Os conjuntos agora são disjuntos
(observe que $\aB 4 \neq \aR 4$ e $\aB5 \neq \aR 5$)
então vamos simplesmente uni-los:
$$
\tikzpicture
\tikzi disjunion3;
\endtikzpicture
$$
e nesse caso vamos tomar $A \disjunion B \asseq A' \union B'$.
Observe que esse processo descrito aqui garanta mesmo que
\compute
\card{A \disjunion B}
&= \card{A' \union B'}      \by {def.~$A\disjunion B$} \\
&= \card {A'} + \card {B'}  \by {$A',B'$ disjuntos} \\
&= \card A + \card B.       \by {$\card A = \card A'$ e $\card B = \card B'$} \\
\endcompute
Parece então que conseguimos definir o operador de união disjunta.

%%}}}

%%{{{ the or one? 
\note ``O'' ou ``um''?.
%%%{{{ meta 
%%%}}}

A descripção acima envolve um passo bem ambiguo:
a \emph{contruição das cópias} $A', B'$.
Com certeza existem muitas maneiras diferentes de conseguir essas
cópias e a gente so descreveu uma---inclusive nem formalmente, mas
dá pra fazer (\ref[formal_equivalent_of_painting]).
Precisamos escolher uma pra realmente definir nosso operador.

%%}}}

%%{{{ x: formal_equivalent_of_painting 
\exercise.
%%%{{{ meta 
\label formal_equivalent_of_painting
%%%}}}

Ache algo matematicamente formal que podes usar em vez do informal
<<pintar os membros do $A$ de azul e do $B$ de vermelho>>.

\solution
Em vez de cores, tagamos cada membro de $A$ com um $0$ e cada
membro de $B$ com um $1$:
$$
\alignat2
A' &\asseq \set{0} \cross A = \setst {(0,a)} {a \in A} &
B' &\asseq \set{1} \cross B = \setst {(1,b)} {b \in B}.
\endalignat
$$

%%}}}

%%{{{ df: disjunion_aka_coproduct 
\definition união disjunta ou coproduto.
%%%{{{ meta 
\label disjunion_aka_coproduct
\defines
    * ~A \coprod ~B  -- o coproduto de $A$ e $B$
    * ~A \disjunion ~B  -- a união disjunta de $A$ e $B$
    * coproduto
    * união disjunta
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Definimos o \dterm{coproduto}
$$
A \coprod B \defeq \paren{\set{0} \cross A} \union \paren{\set{1} \cross B}.
$$
Generalizmos para qualquer família indexada $\famil A i {\cal I}$:
$$
\tsize\Coprod_i A_i \defeq \Union_i \paren{\set{i} \cross A_i}.
$$
Também usamos o termo \dterm{união disjunta};
e a notações correspondente $A \dunion B$ para o caso binário;
e a $\Dunion_i A_i$ para famílias.

%%}}}

%%{{{ remark: sum type notation teaser 
\remark.
%%%{{{ meta 
%%%}}}

No contexto de teoria dos tipos (\ref[Type_theory]) o tipo correspondente
é chamado \dterm{sum type} e usamos as notações $A \plus B$ e $\Sum_i A_i$.

%%}}}

%%{{{ choosers_coproduct 
\note Nível coração: escolhedores.
%%%{{{ meta 
\defines
    * escolhedor!coproduto
    ;;
%%%}}}

Seja $\famil A i {\cal I}$ família de conjuntos.
Lembre-se que enxergamos (\reftag[choosers_product]) cada membro
do produto $\Prod_i A_i$ como um escolhedor:
ele escolhe exatamente um membro \emph{de cada $A_i$}.
Podemos enxergar um membro do coproduto como um escolhedor
também.
Mas antes disso, vamos ver se podemos enxergar o arbitrário
membro do $\Union_i A_i$ como escolhedor.
Sim: o $a\in\Union_i A_i$ representa o escolhedor que escolha
o $a$, entre todos os membros que pertencem a qualquer um dos $A_i$'s.
No coproduto a situação é mais informativa e interessante:
o arbitrário membro do $\Coprod_i A_i$ parece assim:
$(j, a)$, onde $j\in\cal I$ e $a \in A_j$.
Ou seja, parece uma escolha rotulada, que selecionou um membro do
conjunto com seu rótulo e nada mais.
Vamos comparar três escolhedores $P,C,U$ então:
$$
\xalignat3
\vphantom{\Coprod_i}
P &\tsize\in \Prod_i A_i &
C &\tsize\in \Coprod_i A_i &
U &\tsize\in \Union_i A_i.
\endxalignat
$$
Podemos perguntar ao $P$:
\dialogue
\say Qual foi tua escolha para o $i\in\cal I$?
\say Do $A_i$ escolhi o $u \in A_i$.
\say E para o $j\in\cal I$?
\say Do $A_j$ escolhi o $v \in A_j$.
\say E para o $k\in\cal I$?
\say Do $A_k$ escolhi o $w \in A_k$.
\enddialogue
etc., e vamos ter uma resposta para cada um dos $i$'s.
Ao $C$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$ por dentro do $w$-esimo: $x \in A_w$.
\enddialogue
E ao $U$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$.
\say Donde?
\say Como assim?
\say Onde tu achou esse $x$, em qual dos $A_i$'s?
\say Sei-lá!  Foi num deles.  Não lembro.  Não quero dizer.
\enddialogue

%%}}}

%%{{{ x: fpair_for_union_and_coprod 
\exercise.
%%%{{{ meta 
\label fpair_for_union_and_coprod
%%%}}}

Imite a idéia da construcção do $\fpair f g$ (\ref[fpair]) que baseamos no
$\cross$ para definir duas novas construcções parecidas:
uma baseada no $\union$,
e outra no $\coprod$.
Qual das duas parece comportar melhor?
(Nossa referência de comportamento aqui é a construcção baseada no $\cross$.)

%%}}}

%%{{{ x: product_vs_coproduct_diagrams 
\exercise.
%%%{{{ meta 
\label product_vs_coproduct_diagrams
%%%}}}

O que tu percebes sobre os diagramas comutativos
do $\cross$ (\ref[fpair]) e do $\coprod$ (que tu desenhou
no~\ref[fpair_for_union_and_coprod])?

\hint
Olha nas setinhas.

\solution
Podemos obter um diagrama a partir do outro simplesmente
trocando a direcção de cada uma das suas setas.

%%}}}

\endsection
%%}}}

%%{{{ From a solution to a problem to a theory 
\section Duma resolução para um problema para uma teoria.
%%%{{{ meta 
%%%}}}

%%{{{ from a solution to a problem 
\note Duma resolução para o problema.
%%%{{{ meta 
\label from_a_solution_to_a_problem_first_uniprop
%%%}}}

Aqui o produto cartesiano $A\cross B$ que chega junto com suas projecções
$\outl : A \cross B \to A$ e $\outr : A \cross B \to B$:
$$
\cdopt{sep=1cm}
                                                                          \| A \\
A\cross B \ar[ur, bend left=15, "\outl"] \ar[dr, bend right=15, "\outr"'] \|   \\
                                                                          \| B
\endcd
$$
Esse bicho junto com suas duas setinhas, $\tupp{\outl, A\cross B, \outr}$
tem uma propriedade \emph{muito interessante:}
para cada \dterm{impostor} $\tupp{f_1,F,f_2}$:
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                  \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| A\cross B
                                         \ar[ur, bend left=15, "\outl"]
                                         \ar[dr, bend right=15, "\outr"'] \|   \\
                                   \| \|                                  \| B
\endcd
$$
A partir dessa \emph{resolução}, vamos descobrir um \emph{problema:}
determine os $\aR?$ no
$$
\cdopt{sep=1cm}
                                                                               \| A \\
\aR? \ar[ur, bend left=15, "\aR?"] \ar[dr, bend right=15, "\aR?"'] \|   \\
                                                                               \| B
\endcd
$$
tais que para todo $\tupp{f_1,F,f_2}$,
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                     \| A \\
F
\ar[rr, dotted, "\aB\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| \aR?
                                         \ar[ur, bend left=15, "\aR?"]
                                         \ar[dr, bend right=15, "\aR?"'] \|   \\
                                   \| \|                                     \| B
\endcd
$$
Observe que realmente o $\tupp{\aR\outl, \aR{A\cross B}, \aR\outr}$
é uma resolução desse problema.

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Categories_a_first_taste 
\section Pouco de cats---um primeiro toque de categorias.
%%%{{{ meta 
\label Categories_a_first_taste
%%%}}}

%%{{{ intro 
\secintro
Podemos \emph{finalmente} introduzir pouca da linguagem e das
idéias principais das \emph{categorias} para ter na nossa
disposição antes de chegar no~\ref[Category_theory] onde vamos
fazer mesmo nossos primeiros passos na sua teoria.
Mas o que é uma categoria?
%%}}}

%%{{{ df: category_first_def 
\definition categoria.
%%%{{{ meta 
\label category_first_def
%%%}}}

Uma \dterm{categoria} $\cat C$ é composta por duas colecções de coisas:
\tlist:
\li: $\Obj {\cat C}$: os \dterm{objetos} da $\cat C$, que denotamos por $A,B,C,\dots$;
\li: $\Arr {\cat C}$: as \dterm{setas} da $\cat C$, que denotamos por $f,g,h,\dots$;
\endtlist
tais que:
\elist i:
\li: Para toda seta $f$ do $\Arr {\cat C}$, são determinados dois objetos:
     o \dterm{source} da $f$ e o \dterm{target} da $f$, denotados por
     $\src f$ e $\tgt f$ respectivamente.
     Escrevemos $f : A \to B$ para afirmar que $f$ é uma seta,
     e que $\src f = A$ e $\tgt f = B$.
     Denotamos por $\Hom(A,B)$ a colecção de todas as setas de $A$ para $B$.
\li: Para cada objeto $A$ da $\cat C$ é determinada uma seta $\oneof A : A \to A$
     chamada \dterm{a identidade do $A$}.
\li: Dados objetos $A,B,C$ e setas $A \toby f B \toby g C$ é determinada uma seta
     $g \of f : A \to C$ chamada \dterm{a composição da $g$ com $f$}
     (ou \dterm{``$g$ de $f$''}\/; ou \dterm{``$g$ seguindo $f$''}\/)
     que freqüentemente denotamos por $gf$ ou $f \dcom g$.
     Ou seja, dados quaisquer objetos $A,B,C$ temos um operador de composição
     $$
     \oflab ABC : \Hom(B,C) \times \Hom(A,B) \to \Hom(A,C).
     $$
\endelist
Tudo isso é o que temos numa categoria.
Mas apenas \emph{ter} tudo isso não é suficiente.
Essas coisas todas devem satisfazer as \dterm{leis de categoria:}
\tlist:
\li (C-Ass):cat_ass_law
Para todas as setas $A \toby f B \toby g C \toby h D$ temos:
$$
(hg)f = h(gf).
$$
\li (C-Unit):cat_unit_law
Para toda seta $A \toby f B$ temos:
$$
f \oneof A = f = \oneof B f.
$$
\endtlist

%%}}}

%%{{{ remark: operations from the definition of a category 
\remark.
%%%{{{ meta 
%%%}}}

Observe que a~\ref[category_first_def] está nos dando operações:
$$
\cd
\Arr{\cat C}
\ar[r, shift left, "\src"]
\ar[r, shift right, "\tgt"'] \| \Obj{\cat C}.
\endcd
$$
E também
$$
\cd
\Obj{\cat C} \ar[r, "\id"] \| \Arr{\cat C} \\
A   \ar[r, maps to, "\id"] \| \oneof A
\endcd
\qquad
\cd
\Hom(B,C) \cross \Hom(A,B) \ar[r, "\of"]          \| \Hom(A,C) \\
\tup{g,f}                  \ar[r, maps to, "\of"] \| gf
\endcd
$$

%%}}}

%%{{{ eg: SET 
\example conjuntos.
%%%{{{ meta 
\label SET
\defines
    * \SET  -- a categoria dos conjuntos e suas funcções
    ;;
%%%}}}

A $\SET$ com objetos os conjuntos e setas as funcções entre conjuntos
é uma categoria.

%%}}}

%%{{{ x: SET_is_a_cat 
\exercise.
%%%{{{ meta 
\label SET_is_a_cat
%%%}}}

Verifique.

%%}}}

%%{{{ eg: INTLEQ 
\example inteiros com ordem.
%%%{{{ meta 
\label INTLEQ
%%%}}}

Denotamos por $\INTLEQ$ a categoria cujos objetos são os inteiros
e entre dois objetos $A,B$ existe seta $f$ sse $A \leq B$.
Observe que o que são mesmo as setas não importa, mas caso que
insista para defini-las podemos considerar a única seta de $A$
para $B$ pra ser o par $\tup{A,B}$.

%%}}}

%%{{{ x: INTLEQ_is_a_cat 
\exercise.
%%%{{{ meta 
\label INTLEQ_is_a_cat
%%%}}}

Demonstre que a suposta categoria do \ref[INTLEQ]
realmente é uma categoria mesmo.
Deixe claro o que precisas demonstrar mesmo; e demonstre.

%%}}}

%%{{{ eg: INTDIV 
\example inteiros com divide.
%%%{{{ meta 
\label INTDIV
%%%}}}

Similarmente definimos a $\INTDIV$:
aqui temos seta $f : A \to B$ sse $A \divides B$.

%%}}}

%%{{{ x: INTDIV_is_a_cat 
\exercise.
%%%{{{ meta 
\label INTDIV_is_a_cat
%%%}}}

Demonstre que a suposta categoria do \ref[INTDIV] realmente
é uma categoria.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Queremos trazer o conceito de isomorfismo pra cá, pra ser aplicável
em qualquer categoria.  Observe que não podemos usá-lo mesmo,
pois na $\SET$ definimos o isomorfismo pra ser sinônimo de bijecção.
E não temos como falar ``bijecção'' no contexto abstrato de categorias.

%%}}}

%%{{{ x: why_cannot_use_bijective_in_cat 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\solution
Pois a definição de funcção bijectiva (como injectiva e surjectiva) usou
a natureza dos objetos e das setas e não apenas suas propriedades
categóricas.  (Dependeu dos \emph{pontos} dos domínio e do codomínio.)

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mesmo assim, podemos definir o que significa que uma seta é \emph{iso},
numa maneira que acaba sendo equivalente a ser bijectiva quando aplicada
na $\SET$:

%%}}}

%%{{{ df: iso 
\definition iso.
%%%{{{ meta 
\defines
    * iso
    ;;
%%%}}}

Seja $\cat C$ uma categoria e $f : A \to B$ uma das suas setas.
Chamamos a $f$ de \dterm{iso} sse $f$ é invertível:
$$
\text{$f$ iso}
\defiff
\lexists {f' : B \to A} {f'f = \oneof A \mland ff' = \oneof B}.
$$
Nesse caso chamamos os objetos $A,B$ \dterm{isómorfos}
ou \dterm{isomórficos}, algo que denotamos por $A \iso B$.
Como encontramos na~\ref[isomorphic_sets], às vezes
escrevemos $f : A \isoto B$ ou até $f : A \iso B$
para enfatisar que $f$ é um isomorfismo de $A$ para $B$.

%%}}}

%%{{{ df: initial_terminal_null_objects 
\definition iniciais, terminais.
%%%{{{ meta 
\label initial_terminal_null_objects
%%%}}}

Numa categoria $\cat C$, um objeto $S$ é \dterm{inicial} sse
para todo objeto $X$, existe única seta $S \uto X$.
Similarmente, um objeto $T$ é \dterm{terminal} sse
para todo objeto $X$, existe única seta $X \uto T$.
Sinônimos de terminal: \dterm{universal}, \dterm{final}, \dterm{terminador};
sinônimos de inicial: \dterm{couniversal}, \dterm{coterminal}, \dterm{coterminador}.
Um objeto inicial e terminal é chamado \dterm{nulo}.

%%}}}

%%{{{ x: null_unique_up_to_iso 
\exercise.
%%%{{{ meta 
\label null_unique_up_to_iso
%%%}}}

Todos os objetos nulos duma categoria $\cat C$
são isómorfos.
Em outras palavras, se $\cat C$ tem objeto nulo,
ele é \emph{único a menos de isomorfismos}.

%%}}}

%%{{{ x: zero_arrow 
\exercise seta zero.
%%%{{{ meta 
\label zero_arrow
%%%}}}

Seja $Z$ um objeto nulo duma categoria $\cat C$.
Dados quaisquer objetos $A,B$ existe uma única seta
que \dterm{passa pelo} $Z$:
$$
A \uto Z \uto B
$$
(a composição das setas acima)
onde entendemos que os $!$ nas setas indicam que
essa seta é \emph{a única seta} desse objeto para
aquele objeto.

%%}}}

%%{{{ beware: some use terminal for either term 
\beware.
%%%{{{ meta 
%%%}}}

Na literatura às vezes aparece o termo ``terminal'' para
significar tanto ``inicial'' quanto ``final''.
Se o contexto deixa claro qual dos dois é, procure
a definição.

%%}}}

%%{{{ eg: initial_and_terminal_of_SET 
\example.
%%%{{{ meta 
\label initial_and_terminal_of_SET
%%%}}}

A categoria $\SET$ possui iniciais?  Terminais?  Quais?

\solution.
Sim e sim.
Demonstraste isso no~\ref[first_contact_with_initial_and_terminal_objects]:
$\emptyset$ é seu único objeto inicial; e cada singleton é um final.

%%}}}

%%{{{ x: initial_terminal_of_INTLEQ 
\exercise.
%%%{{{ meta 
\label initial_terminal_of_INTLEQ
%%%}}}

A categoria $\INTLEQ$ tem iniciais?  Terminais?  Se sim, quais são?

%%}}}

%%{{{ x: initial_terminal_of_INTDIV 
\exercise.
%%%{{{ meta 
\label initial_terminal_of_INTDIV
%%%}}}

A $\INTDIV$?

%%}}}

%%{{{ df: product_in_category 
\definition produto.
%%%{{{ meta 
\label product_in_category
%%%}}}

Sejam $A,B$ objetos numa categoria $\cat C$.
Uma tripla $\tupp{p_1,P,p_2}$ é um \dterm{produto} dos $A,B$, sse:
\tlist:
\li: $A \fromby {p_1} P \toby {p_2} B$;
\li: para toda tripla $\tupp{f_1,F,f_2}$ com $A \fromby {f_1} F \toby {f_2} B$,
existe única seta $!$ que faz o diagrama
$$
\cdopt{sep=1cm}
                                  \| \|                                \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']  \| \| P
                                        \ar[ur, bend left=15,  "p_1"]
                                        \ar[dr, bend right=15, "p_2"'] \| \\
                                  \| \|                                \| B
\endcd
$$
comutar.
\endtlist
Quando as setas são óbvias usamos apenas o objeto $P$ para representar
a tripla $\tupp{p_1,P,p_2}$.

%%}}}

%%{{{ x: product_is_a_product 
\exercise o produto é um produto.
%%%{{{ meta 
\label product_is_a_product
%%%}}}

Dados conjuntos $A,B$ na $\SET$, demonstre que $A\cross B$
é um produto.
Entenda que literalmente o produto não é o $A \cross B$,
mas a tripla $\tupp{\outl, A \cross B, \outr}$.

%%}}}

%%{{{ x: products_are_not_unique 
\exercise produtos não são únicos.
%%%{{{ meta 
\label products_are_not_unique
%%%}}}

Dados conjuntos $A,B$ na $\SET$, ache um outro conjunto,
além do $A \cross B$ que também é produto dos $A,B$.
Pode achar mais?

%%}}}

%%{{{ x: products_are_unique_up_to_unique_isomorphism 
\exercise são únicos a menos de isomorfismo.
%%%{{{ meta 
\label products_are_unique_up_to_unique_isomorphism
%%%}}}

Demonstre que em qualquer categoria, dois produtos dos mesmos objetos
são necessariamente isómorfos.

%%}}}

%%{{{ remark: another way to design the diagram 
\remark.
%%%{{{ meta 
%%%}}}

Outras maneira para desenhar o diagrama acima são as seguintes:
$$
\cdopt{sep=1cm}
A \| P
     \ar[l, "p_1"']
     \ar[r, "p_2"]             \| B \\
  \| F
     \ar[ul, "f_1"]
     \ar[ur, "f_2"']
     \ar[u, dotted, "\unique"] \|
\endcd
\qqquad
\cdopt{sep=1cm}
  \| P
     \ar[dl, "p_1"']
     \ar[dr, "p_2"]            \|   \\
A \| F
     \ar[l, "f_1"]
     \ar[r, "f_2"']
     \ar[u, dotted, "\unique"] \| B
\endcd
$$
Obviamente é a mesma coisa.  Use qualquer delas, ou qualquer outra
equivalente.

%%}}}

%%{{{ x: does_INTLEQ_have_products 
\exercise.
%%%{{{ meta 
\label does_INTLEQ_have_products
%%%}}}

A categoria $\INTLEQ$ do~\ref[INTLEQ]
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

%%}}}

%%{{{ x: does_INTDIV_have_products 
\exercise.
%%%{{{ meta 
\label does_INTDIV_have_products
%%%}}}

A categoria $\INTDIV$ do~\ref[INTDIV]
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: cancellable_stereo 
\problem.
%%%{{{ meta 
\label cancellable_stereo
%%%}}}

Sabemos que bijecções tem inversa e logo são canceláveis
pela esquerda, e também canceláveis pela direita.
Mas no~\reftag[let_us_trip_1] da viagem da~\reftag[An_epic_trip]
encontramos mais uma versão de cancelável: ``cancelável stereo'',
que---para motivos óbvios---desconsideramos na discussão.
Então: existe bijecção $f$ e funcções $g,h$ tais que
$$
f \of g = h \of f \nimplies g = h\, ?
$$
Se sim mostre um exemplo;
se não, refute mesmo a afirmação.

%%}}}

%%{{{ prob: implement_partial_functions 
\problem Implementação: funcções parciais.
%%%{{{ meta 
\label implement_partial_functions
\defines
    * funcção!partial
    ;;
%%%}}}

Pense numa maneira de \emph{implementar} o tipo das
\dterm{funcções parciais} (\ref[Partial_functions])
usando conceitos (tipos) que encontramos até agora:
conjuntos, tuplas, seqüências, famílias indexadas, funcções, etc.
\eop
Para implementar um conceito não basta apenas definir o que são os
objetos desse tipo em termos de já conhecidos.
Precisamos implementar também a interface desejada, em termos de
operações e relações que já temos em nossa disposição.

\hint
Cada funcção parcial $f : A \parto B$ pode ser representada
como uma funcção total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Uma idéia seria adicionar no $B$ um objeto ``fresco'' para representar
a falta de valor; outra idéia seria tomar como $B'$ um subconjunto do $\pset B$.
Qual?

\hint
A primeira idéia não precisa de mais dicas.
Sobre a segunda:
$$
B' \asseq \setst {X \subset B} {\card X \leq 1}.
$$

%%}}}

%%{{{ prob: implement_nondeterministic_functions 
\problem Implementação: funcções não-determinísticas.
%%%{{{ meta 
\label implement_nondeterministic_functions
\defines
    * funcção!não-determinística
    ;;
%%%}}}

Na~\ref[Partial_functions] definimos um conceito mais geral de
``funcção'':
as \emph{funcções parciais}, onde apagamos a primeira das
condições~\reftag[functionhood_conditions]:
\tlist: \notags
\li: \strikeout{(1)~totalidade};
\li: (2)~determinabilidade.
\endtlist
Neste problema, encontramos \dterm{funcções não-determinísticas}, ou seja,
``funcções'' que não respeitam necessariamente a determinabilidade;
apenas a totalidade.  Ou seja, agora apagamos a outra condição:
\tlist: \notags
\li: (1)~totalidade;
\li: \strikeout{(2)~determinabilidade}.
\endtlist
O objectivo desse problema é \emph{implementar o tipo de funcção não-determinística}.
\eop
Como definarias a composição $g \cdot f$ de duas funcções não-determinísticas?
Use a notação $f : A \ndeto B$ para <<$f$ é uma funcção não-determinística
de $A$ para $B$>>.
Que mais tu poderias fazer para tua implementação ser uma implementação boa?

\solution
Podemos representar a $f : A \ndeto B$ pela funcção
$\bar f : A \to \pset B\setminus\set{\emptyset}$ definida pela
$$
\bar f(x) = \setst {y\in B} {x\mapstoby f y}.
$$
Sejam~$f : A \ndeto B$ e~$g : B \ndeto C$ funcções não-determinísticas.
Logo temos $\bar f : A \to \pset B\setminus\set{\emptyset}$
e          $\bar g : B \to \pset C\setminus\set{\emptyset}$.
Definimos sua composição
$g\cdot f : A \ndeto C$ pela
$$
(\overline{g\cdot f})(x) = \Union \img {\bar g} {\bar f (x)}.
$$
O que mais seria legal definir e mostrar para nossa implementação?
Bem, seria bom definir pelo menos a identidade não-determinística
$id_A : A \ndeto A$, e investigar se as leis que provamos sobre
o caso de funcções que conectam composição e identidades estão válidas
para nossas funcções não-determinísticas também.

%%}}}

%%{{{ prob: fcom_respects_jections_pointfree 
\problem.
%%%{{{ meta 
\label fcom_respects_jections_pointfree
%%%}}}

Demonstre que a composição respeita injectividade e sobrejectividade
num estilo pointfree (\ref[fcom_respects_jections]).
Ou seja, tu vai ter que usar as ``versões pointfree'' dessas noções.

%%}}}

%%{{{ prob: define_constant_function_pointfree 
\problem.
%%%{{{ meta 
\label define_constant_function_pointfree
%%%}}}

Descreva a afirmação <<$f$ é constante>> numa maneira pointfree.

\hint
Vai precisar de usar um singleton, $\set{\ast}$, não importa
qual é o seu único membro.

%%}}}

%%{{{ prob: flip_definition 
\problem flip.
%%%{{{ meta 
\label flip_definition
%%%}}}

No \ref[powTwo] da~\reftag[Currying] definimos a funcção $\namedfun{powTwo}$
diretamente como aplicação parcial da funcção $\namedfun{exp}$
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2
$$
evitando o uso de pontos ou lambdas:
$$
\xalignat2
\namedfun{powTwo} \fa n &= \namedfun{exp} \fa 2 \fa n; &
\namedfun{powTwo}       &= \lam n {\namedfun{exp} \fa 2 \fa n}.
\endxalignat
$$
Similarmente podemos definir a funcção que corresponde seqüência das potências
de qualquer outro número real.
Mas parece que não podemos criar com a mesma laconicidade (apenas como
aplicação parcial) uma funcção $\namedfun{square}$ ou $\namedfun{cube}$,
pois os argumentos da $\namedfun{exp}$ estão ``na ordem errada''.
O objectivo desse problema é fazer exatamente isso.
\eop
Defina uma funcção de ordem superior $\namedfun{flip}$, que recebe qualquer
funcção binária currificada, e retorna a funcção binária currificada que
comporta no mesmo jeito mas recebendo seus argumentos na ordem oposta.
Por exemplo:
$$
\xalignat2
\namedfun{exp} \fa 2 \fa 3 &= 8; &
\paren{\namedfun{flip} \fa \namedfun{exp}} \fa 2 \fa 3 &= 9
\endxalignat
$$
Começa escrevendo o tipo da $\namedfun{flip}$ e o lendo com as duas
maneiras diferentes que discutimos na~\ref[human_eyes_and_ho_types].

%%}}}

%%{{{ prob: coproduct_in_category 
\problem Definição: coproduto em categoria.
%%%{{{ meta 
\label coproduct_in_category
%%%}}}

Defina formalmente o que significa \dterm{coproduto} numa categoria.

%%}}}

%%{{{ prob: disjunion_is_a_coproduct 
\problem o coproduto é um coproduto ué.
%%%{{{ meta 
\label disjunion_is_a_coproduct
%%%}}}

Demonstre que a \emph{união disjunta} $A \disjunion B$ que encontramos
na~\ref[disjunion_aka_coproduct], conhecida por seus amigos
algebristas e categoristas como \emph{coproduto} e denotado por
$A \coprod B$ e $A \plus B$, merece seu apelido:
``ele'' realmente é um coproduto dos $A,B$ na $\SET$.
Por que o ``ele'' está em aspas?

%%}}}

%%{{{ prob: coproducts_in_INTLEQ_and_INTDIV 
\problem mais coprodutos.
%%%{{{ meta 
\label coproducts_in_INTLEQ_and_INTDIV
%%%}}}

As $\INTLEQ$ e $\INTDIV$ têm coprodutos?
Quais são?

%%}}}

%%{{{ prob: why_pre_collatz_unsafe_diverges_on_6 
\problem.
%%%{{{ meta 
\label why_pre_collatz_unsafe_diverges_on_6
%%%}}}

Calculando para resolver o~\ref[calculate_pre_collatz]
pareceu que o cálculo do $d(6)$ não ia terminar.
Demonstre que realmente não termina.

\hint
Botei esse problema para desenferrujar tuas armas
de teoria dos números (\ref[The_integers]).

\hint
Observe que a seqüência desses valores começa com 6, assim:
$$
6
\leadsto 9
\leadsto 12
\leadsto 15
\leadsto 18
\leadsto 21
\leadsto \dotsb
$$
Mas, somando $+3$ num número par, sabemos já que o próximo
número será ímpar e logo não pode ser potência de $2$,
e logo já sabemos que o próximo passo será somar $+3$ novamente.
Então podemos pular os ímpares acima, e reduzir nosso trabalho
focando nessa seqüência:
$$
6
\leadsto 12
\leadsto 18
\leadsto 24
\leadsto 30
\leadsto 36
\leadsto \dotsb
$$
De $6$ para $12$ ela ``pulou'' a potência (de $2$) $8$.
E de $12$ para $18$ também pulou o $16$.
A próxima potência é o $32$, que nossa seqüência tambem
conseguiu pular ($30\leadsto 36$).
Teu objectivo é \emph{demonstrar} que ela consegue ``pular''
\emph{todas} as potências de $2$.

\hint
Módulo $6$.

\hint
Como parecem \emph{todas} as potências de $2$ ``dentro do módulo~$6$''?

\hint
A seqüência de todas as potências de $2$ é:
$$
1, 2, 4, 8, 16, 32, 64, \dotsc
$$
que, módulo $6$ fica:
$$
1, 2, 4, 2, 4, 2, 4, 2, \dotsc \pmod 6.
$$
Isso é fácil de demonstrar: então demonstre.

\hint
Observe que somando $+6$ num número não o muda ``módulo $6$''.
(Lembre que $6 \cong 0 \pmod 6$.)

\hint
Ou seja: começando com qualquer número $m$ que módulo $6$
é um dos $0,3,5$ sabemos que $d(m)$ \emph{diverge}, ou seja,
o $d(m)$ não é definido.
E se $m$ é $1$ módulo $6$?
A única potência de $2$ que é $1$ módulo $6$ é o próprio $1$,
e logo qualquer outro inteiro que é $1$ módulo $6$ não
pode ser uma potência de $2$.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[velleman: Cap.~5] defina e trata funcções
como casos especiais de relações (veja~\ref[Relations]),
algo que não fazemos nesse texto.
Muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.

Um livro excelente para auto-estudo é o~\cite[babylawvere].
\emph{Não pule seus exercícios e problemas!}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Functional_programming 
\chapter Programação funccional.
%%%{{{ meta 
\label Functional_programming
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: stretch_countdown_take 
\problem.
%%%{{{ meta 
%%%}}}

Defina as funcções com equações (recursivas):
$$
\xalignat3
\stretch    &\eqtype \nats \to [\nats] \to [\nats] &
\countdown  &\eqtype \nats \to [\nats] &
\take       &\eqtype \nats \to [\nats] \to [\nats].\\
\endxalignat
$$
Exemplos de uso:
$$
\align
\stretch \fa 3 \fa [2,8]        &= [2,2,2,8,8,8]    \\
\stretch \fa 2 \fa [1,9,8,3]    &= [1,1,9,9,8,8,3,3]\\
\countdown \fa 3                &= [3,2,1,0]        \\
\countdown \fa 1                &= [1,0]            \\
\take \fa 3 \fa [2,3,5,7,11]    &= [2,3,5]          \\
\take \fa 8 \fa [0,1,2,4]       &= [0,1,2,4]
\endalign
$$

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[huttonhaskell],
\cite[lyah];
\cite[birdthinking],
\cite[thompsonhaskell];
\cite[birdfphaskell].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Relations 
\chapter Relações.
%%%{{{ meta 
\label Relations
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo estudamos então mais um \emph{tipo} importante para matemática:
a \emph{relação}.
Se pensamos em funcções como construtores (ou ``apontadores'') de objetos,
então as relações são \emph{construtores de afirmações}.
Podemos pensar que uma relação é como um \emph{verbo}, ou um \emph{predicado}
duma afirmação.
Como no~\ref[Functions], nosso objectivo é entender \emph{o que são}
as coisas desse tipo (relações) e não como defini-las formalmente como
objetos matemáticos---sobre isso, paciência até o~\ref[Axiomatic_set_theory].
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

%%{{{ eg: leq_geq_lt_gt_example 
\example.
%%%{{{ meta 
\label leq_geq_lt_gt_example
%%%}}}

Nos números, estamos bem acostumados com as relações de ordem
($\leq$, $\geq$, $<$, $>$).
Nos inteiros já estudamos bastante a relação binária de ``divide''
($\dhole \divides\dhole$) e a relação ternária de ``congruência modular''
($\dhole \cong \dhole \pmod \dhole$).

%%}}}

%%{{{ eg: mother_parents_love_example 
\example.
%%%{{{ meta 
\label mother_parents_love_example
%%%}}}

No nossa vida, conhecemos várias relações também:
$$
\align
\Mother (x,y)     &\defiff \text{$x$ é a mãe de $y$}\\
\Parents (x,y,z)  &\defiff \text{$x$ e $y$ são os pais de $z$}\\
\Love (x,y)       &\defiff \text{$x$ ama $y$}.
\endalign
$$

%%}}}

%%{{{ Black boxes 
\note Black boxes.
%%%{{{ meta 
\label blackbox_rel
\indexes
    * relação!como black box    see: black box
    ;;
\defines
    * black box!de relação
    ;;
%%%}}}

Visualizamos uma relação $R$ de aridade $n$ como um black box com $n$ entradas
e uma lâmpada que pisca sim ou não (como o black box dum conjunto), dependendo
de se os objetos-entradas $x_1,\dotsc,x_n$ são relacionados pela $R$.
Nesse caso dizemos que os $x_1,\dotsc,x_n$ \dterm{satisfazem} a $R$
e escrevemos
$$
R(x_1,\dotsc,x_n)
$$
para denotar isso e, quando $R$ é binária, em vez de escrever
$R(x,y)$ preferimos usar o $R$ com notação \emph{infixa}:
$$
x \rel R y \syndefiff R(x,y).
$$
Podemos então visualizar uma relação binária assim:
$$
\tikzpicture
\tikzi blackboxrel;
\endtikzpicture
$$
Como nas funcções, se suas entradas são rotuladas ou não é questão de
religião: para o Conjuntista o black box parece como esse acima,
e para o Categorista como este abaixo:
$$
\tikzpicture
\tikzi blackboxrelcat;
\endtikzpicture
$$
Ele escreveria $R : \reltype{A,B}$ para deixar claro o tipo dessa relação.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Relações podem relacionar tipos diferentes:

%%}}}

%%{{{ eg: born_author_read_example 
\example.
%%%{{{ meta 
\label born_author_read_example
%%%}}}

Considere as relações seguintes, cujos argumentos não têm o mesmo tipo.
$$
\align
\Born (x,w)       &\defiff \text{$x$ nasceu no ano $w$} \\
\Author (x,k)     &\defiff \text{$x$ escreveu o livro $k$} \\
\Read (x,k)       &\defiff \text{$x$ leu o livro $k$}
\endalign
$$
O primeiro argumento da primeira relação é uma pessoa
mas o segundo é um ano; e as relações $\namedrel{Author}$
e $\namedrel{Read}$ são ambas entre pessoas e livros.

%%}}}

%%{{{ eg: equalities 
\example Igualdades.
%%%{{{ meta 
\indexes
    * aplicação!parcial
    ;;
%%%}}}

Para cada tipo, sua igualdade é uma relação, de aridade $2$.
Nos números naturais por exemplo, se $n,m\in\nats$, $n = m$ é uma afirmação:
$$
\align
n = m &\pseudodefiff \text{os $n$ e $m$ denotam o mesmo número natural}.
\intertext{Similarmente nos conjuntos: se $A,B$ são conjuntos, $A = B$ é a afimação seguinte:}
A = B &\pseudodefiff \text{os $A$ e $B$ denotam o mesmo conjunto}.
\endalign
$$
Etc., etc.
Observe que podemos fazer uma \emph{aplicação parcial},
nas relações como fazemos nas funcções.
Fixando um objeto de nosso tipo, por exemplo o natural $0\in\nats$
em qualquer um dos dois lados da igualdade (vamos fixar na direita nesse exemplo),
chegamos numa relação de aridade $1$:
$$
\align
\bhole &= 0
\intertext{%
onde aplicando a relação para qualquer $x\in\nats$ chegamos na afirmação
}
x &= 0.
\endalign
$$

%%}}}

%%{{{ The type of a relation 
\definition O tipo duma relação.
%%%{{{ meta 
\defines
    * ~R : \reltype{~{A_1,\dotsc,A_n}}  -- $R$ é uma relação entre os conjuntos $A_1,\dotsc,A_n$
    * tipo!duma relação
    ;;
%%%}}}

Com cada relação associamos o seu \dterm{tipo} (pedimos emprestada aqui
a terminologia usada em funcções) que é apenas a informação de qual é o tipo
de cada uma das suas entradas.
Escrevemos
$$
R : \reltype{A_1,\dotsc,A_n}
$$
para afirmar que $R$ é uma relação $n$-ária
entre os conjuntos $A_1,\dotsc,A_n$.
As relações dos exemplos~\reftag[mother_parents_love_example]
e~\reftag[born_author_read_example] têm os tipos seguintes:
$$
\xalignat2
\namedrel{Mother}  &: \reltype{\pers, \pers}        & \namedrel{Born}   &: \reltype{\pers, \cal Y} \\
\namedrel{Parents} &: \reltype{\pers, \pers, \pers} & \namedrel{Author} &: \reltype{\pers, \cal B} \\
\namedrel{Love}    &: \reltype{\pers, \pers}        & \namedrel{Read}   &: \reltype{\pers, \cal B}
\endxalignat
$$
onde $\pers, \cal Y, \cal B$ são os conjuntos de pessoas, anos, livros
(respectivamente).

%%}}}

%%{{{ funlike_notation_for_relations 
\notation funcionista.
%%%{{{ meta 
\label funlike_notation_for_relations
%%%}}}

Relações de aridade $2$ são as mais comuns, e usamos certa notação
e terminologia especialmente só para elas.
Nesse caso, podemos ver o conceito de relação como uma generalização de funcção,
onde nos livramos das duas condições do~\reftag[functionhood_conditions].
Por isso, quando temos uma relação no $\relspace{A,B}$
usamos a frase \wq{relação \emph{de} $A$ \emph{para} $B$}.
Vamos criar uma notação parecida com aquala das funcções para dizer que $R$
é uma relação do conjunto $A$ para o conjunto $B$.
Escrevemos, equivalentemente:
$$
R : A \relto B
\qqqquad
R : B \relfrom A
\qqqquad
A \reltoby R B
\qqqquad
B \relfromby R A.
$$
Tudo isso quis dizer apenas que $R$ é uma relação binária entre $A$ e $B$.
Ou seja, tudo isso é sinónimo com o $R : \reltype{A,B}$.

%%}}}

%%{{{ beware: this notation is not standard 
\beware.
%%%{{{ meta 
%%%}}}

A notação ``$\relto$'' definida no~\reftag[funlike_notation_for_relations]
\emph{não} é padrão.

%%}}}

%%{{{ setlike_notation_for_relations 
\notation conjuntista.
%%%{{{ meta 
\label setlike_notation_for_relations
%%%}}}

Vestindo nosso chapéu de conjuntista, abusamos a notação e escrevemos
também $\tupp{x,y} \in R$ para dizer que $R(x,y)$.
E para afirmar que $R : \reltype{A,B}$, escrevemos
até $R \subset A \cross B$.
É importante entender bem neste momento que essas são apenas
\emph{notações}.  Uma relação $R$ \emph{não é} um conjunto,
então nada pertence a ela, e conseqüentemente ela não é
subconjunto de ninguém!
Mesmo assim escrevemos coisas como
$$
\xalignat2
\namedrel{Author}  &\subset \pers \cross \cal B &
\namedrel{Parents} &\subset \pers^3
\intertext{%
\emph{entendendo} como:
}
\namedrel{Author}  &\eqtype \reltype{\pers, \cal B} &
\namedrel{Parents} &\eqtype \reltype{\pers, \pers, \pers}.
\endxalignat
$$
É muito conveniente tratar relações \emph{como se fossem} conjuntos
---mas mais uma vez: relações \emph{não são} conjuntos.

%%}}}

%%{{{ x: repeat_after_me_relations_are_not_sets 
\exercise.
%%%{{{ meta 
\label repeat_after_me_relations_are_not_sets
%%%}}}

Repita!

\hint
Relações \emph{não são}\dots

\solution
Relações \emph{não são} conjuntos!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Cada vez que introduzimos um tipo novo, precisamos definir quando dois
objetos desse tipo são iguais.  Vamos fazer isso agora.
Novamente, vamos optar para identificar relações cujos comportamentos
são indistinguíveis usando apenas as suas interfaces.

%%}}}

%%{{{ df: R_eq_S_bin_on_single_set_case 
\definition igualdade.
%%%{{{ meta 
\label R_eq_S_bin_on_single_set_case
%%%}}}

Sejam $R,S$ relações binárias num conjunto $A$.
Definimos
$$
R=S
\defiff
\lforall {x,y \in A} {x \rel R y \iff x \rel S y}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Principalmente vamos trabalhar com relações binárias definidas
num conjunto só, então a definição de
igualdade~\reftag[R_eq_S_bin_on_single_set_case] que
acabamos de ver nos serve bem.
No~\ref[R_eq_S_bin_on_different_sets_case]
e no~\ref[R_eq_S] tu vai estender essa definição para
os casos mais gerais.

%%}}}

%%{{{ x: R_eq_S_bin_on_different_sets_case 
\exercise igualdade.
%%%{{{ meta 
\label R_eq_S_bin_on_different_sets_case
%%%}}}

Como tu estenderia a~\ref[R_eq_S_bin_on_single_set_case]
para o caso que as $R,S$ não são relações num conjunto só?
Ou seja, tendo relações binárias~$R,S$, a~$R$ de~$A$ para~$B$,
e a~$S$ de~$C$ para~$D$, como tu definirias a igualdade~$R=S$ nesse caso?

\solution
Digamos que $R=S$ sse para todo $x\in A\union C$,
e todo $y \in B\union D$, temos $x \rel R y \iff x \rel S y$.

%%}}}

%%{{{ x: R_eq_S 
\exercise igualdade (agnóstica).
%%%{{{ meta 
\label R_eq_S
%%%}}}

Defina a igualdade para o caso mais geral de relações,
numa maneira ``agnóstica'' como fizemos nas funcções (\ref[f_eq_g]).

%%}}}

%%{{{ Intension vs. Extension 
\note Intensão \vs extensão.
%%%{{{ meta 
%%%}}}

Com nossa experiência com \emph{intensão} e \emph{extensão} de
conjuntos~(\reftag[Intension_vs_extension_in_sets]) e de
funcções~(\reftag[intension_vs_extension_in_functions]
e~\reftag[programs_vs_functions]), não precisamos esclarecer
muita coisa sobre relações, pois a idéia continua a mesma.

%%}}}

%%{{{ eg: R(n) vs T(n) intensionally and extensionally 
\example.
%%%{{{ meta 
%%%}}}

Considere as relações no $\nats$:
$$
\align
R(n) &\defiff \Prime(n) \mland \Even(n) \\
T(n) &\defiff n = 2.
\endalign
$$
As \emph{intensões} das relações $R$ e $T$ são diferentes,
mas a \emph{extensão} é comum:
$$
\lforall {n\in\nats} {R(n) \iff T(n)}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para capturar a extensão duma relação, definimos o seu gráfico,
na mesma forma que definimos no caso de funcções~(\ref[function_graph]).

%%}}}

%%{{{ df: relation_graph 
\definition gráfico.
%%%{{{ meta 
\label relation_graph
\indexes
    * gráfico    see: funcção
    * gráfico    see: relação
    ;;
\defines
    * \graph{~R}  -- o gráfico da relação $R$
    * relação!gráfico
    * truth set
    ;;
%%%}}}

Dado relação $R : \reltype{A_1,\dotsc,A_n}$,
o \dterm{gráfico da $R$} é o conjunto
$$
\graph R \defeq \setst {\vec a \in A_1\cross\dotsb\cross A_n} {R(\vec a)},
$$
também conhecido como \dterm{truth set} da $R$.

%%}}}

%%{{{ remark: graph R = graph T and setlike notation 
\remark.
%%%{{{ meta 
%%%}}}

Agora temos uma maneira formal para afirmar que $R$ e $T$ tem
a mesma extensão: $\graph R = \graph T$.
E agora a notação conjuntista do~\reftag[setlike_notation_for_relations]
vira literalmente até correta se substituir as relações por seus gráficos.

%%}}}

\endsection
%%}}}

%%{{{ Defining relations 
\section Definindo relações.
%%%{{{ meta 
%%%}}}

%%{{{ with holes 
\note Com buracos.
%%%{{{ meta 
%%%}}}

Começando com uma expressão que denota um \emph{objeto}
e botando $n$ buracos em certas subexpressões dela, criamos
uma \emph{funcção} de aridade $n$.
Se fizer a mesma coisa numa expressão que denota uma \emph{afirmação},
então criamos uma \emph{relação} de aridade $n$.

%%}}}

%%{{{ eg: john_loves_mary_holes 
\example.
%%%{{{ meta 
%%%}}}

Considere a frase \trel{João ama Maria}.
Criamos assim as relações:
$$
\align
L &\defeq \mtrel{{\thole} ama {\thole}} \\
J &\defeq \mtrel{João ama {\thole}} \\
M &\defeq \mtrel{{\thole} ama Maria}.
\endalign
$$
A primeira é uma relação binária no $\pers$ e as outras duas unárias.
Usando variáveis em vez de buracos, escrevemos:
$$
\align
L(x,y) &\defiff \mtrel{$x$ ama $y$} \\
J(x)   &\defiff \mtrel{João ama $x$} \\
M(x)   &\defiff \mtrel{$x$ ama Maria}.
\endalign
$$

%%}}}

%%{{{ other ways of defining relations 
\note Outras maneiras de definir relações.
%%%{{{ meta 
%%%}}}

Em vez de explicar todas as maneiras seguintes em detalhe,
eu acho que um exemplo é suficiente para cada caso, pois
todas essas maneiras são já bem conhecidas graças à nossa
experiência com funcções no~\ref[Functions].

%%}}}

%%{{{ eg: with formulas 
\example formulamente.
%%%{{{ meta 
%%%}}}

Considere os conjuntos $\pers$ de todas as pessoas
e $\cal B$ de todos os livros.
Sejam as relações
$$
\xalignat4
P &: \reltype {\ints}, &
R &: \reltype {\ints, \ints}, &
Q &: \reltype {\pers \times \cal B}, &
M &: \reltype {\ints,\ints,\ints},
\endxalignat
$$
definidas pelas fórmulas:
$$
\align
P(n)     &\defiff \lforall {x,y\in\ints} {xy = n \limplies \paren{|x| = 1 \lor |y| = 1}} \\
R(n,m)   &\defiff \lnot\lexists {k \in \ints} {\Prime(k) \land 2^n < k < 3^m}; \\
Q(p,b)   &\defiff \lexists {b' \in \cal B} {b \neq b' \land \namedrel{Read}(p,b') \land \lexists {a \in \pers} {\namedrel{Author}(a,b) \land \namedrel{Author}(a,b')}} \\
C(a,b,m) &\defiff \lexists {k \in \ints} {mk = a-b}
\endalign
$$
Tente expressar cada uma delas em lingua natural.

%%}}}

%%{{{ eg: relations_with_text_example 
\example Com texto.
%%%{{{ meta 
\label relations_with_text_example
%%%}}}

Sejam as relações $\namedrel{Coauthors}$ (binária, entre pessoas)
e $\namedrel{SameCard}$ (unária, nos conjuntos), definidas pelas:
$$
\align
\namedrel{Coauthors}(x,y) &\defiff \text{$x$ e $y$ já escreveram algum livro juntos}; \\
\namedrel{SameCard}(x)    &\defiff \text{todos os membros de $x$ são conjuntos com a mesma cardinalidade}.
\endalign
$$
Por exempo: $\namedrel{Coauthors}(\textrm{Birkhoff}, \textrm{Mac Lane})$
e $\namedrel{SameCard}(\set{ \set{0,1}, \set{\nats,\set{42}}, \set{\emptyset, \set{\emptyset}}})$.

%%}}}

%%{{{ beware: definitive text 
\beware.
%%%{{{ meta 
%%%}}}

Como sempre, tomamos cuidado quando definimos coisas com texto:
tem que ser uma afirmação definitiva, sem ambigüidades, etc.

%%}}}

%%{{{ x: do_nats_ints_rats_reals_have_the_same_cardinality 
\exercise.
%%%{{{ meta 
\label do_nats_ints_rats_reals_have_the_same_cardinality
%%%}}}

Com a definição de $\namedrel{SameCard}$ do~\ref[relations_with_text_example],
$\namedrel{SameCard}(\set{\nats,\ints,\rats,\reals})$?
Responda com ``sim'' ou ``não'', com uma curtíssima explicação (sem prova).

\hint
Lembre a~\ref[naive_cardinality].

\solution
Infelizmente não podemos ainda responder nessa pergunta:
sua resposta é um dos assuntos principais do~\ref[Cantors_paradise].
Paciência!
Se tu respondeste ``sim, pois todos são conjuntos infinitos'',
fizeste bem, pois é uma resposta aceitável \emph{neste momento}.
Só que\dots~não é uma resposta correta!
Aliás, seguindo a~\ref[naive_cardinality] é uma resposta correta sim,
porém vamos ter que redefinir o conceito de cardinalidade logo.

%%}}}

%%{{{ eg: partial_application_in_relations_example 
\example Aplicação parcial.
%%%{{{ meta 
\label partial_application_in_relations_example
\DefRel EqParity
\DefRel Neg
%%%}}}

Sejam as relações $\EqParity$ (binária entre inteiros),
$B$ (unária em pessoas), e $\Neg$ (unária em inteiros), definidas pelas:
$$
\align
\EqParity(a,b) &\defiff a \cong b \pmod 2 \\
B(y)           &\defiff \Coauthors(\mathrm{Birkhoff}, y) \\
\Neg(x)        &\defiff x < 0.
\endalign
$$
Assim temos por exemplo:
$\EqParity(103,11)$ mas não $\EqParity(21,42)$;
$B(\mathrm{Mac~Lane})$ mas não $B(\mathrm{Thanos})$;
$\Neg(-23)$ mas não $\Neg(0)$.

%%}}}

\endsection
%%}}}

%%{{{ Internal diagrams 
\section Diagramas internos.
%%%{{{ meta 
%%%}}}

%%{{{ Relation as a generalization of function 
\note Relação como uma generalização de funcção.
%%%{{{ meta 
%%%}}}

Um jeito de olhar para uma relação é como uma ``funcção'' sem as restricções
de totalidade e de determinabilidade que encontramos no~\reftag[functionhood_conditions].
Então: lembra dos conjuntos $A,B$ que encontramos na~\ref[Images_preimages]?
Aqui são duas relações $R,Q$ de $A$ para $B$, determinadas por seus
diagramas internos:
$$
\xxalignat2
&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-R) at (2.5,4) {$R$};
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-b) -- (elem-2);
\draw[->] (elem-c) -- (elem-2);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-6);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-2);
\endtikzpicture
&&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-Q) at (2.5,4) {$Q$};
\draw[->] (elem-a) -- (elem-1);
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-c) -- (elem-1);
\draw[->] (elem-d) -- (elem-3);
\draw[->] (elem-d) -- (elem-4);
\draw[->] (elem-d) -- (elem-5);
\draw[->] (elem-d) -- (elem-6);
\draw[->] (elem-f) -- (elem-6);
\endtikzpicture
\endxxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A situação sobre relações binárias definidas num conjunto $A$
é mais divertida.

%%}}}

%%{{{ Relation as a directed graph 
\note Relação como grafo direcionado.
%%%{{{ meta 
%%%}}}

Seja $A$ um conjunto e $R$ uma relação binária nele.
Podemos representar a $R$ como um \emph{grafo direcionado},
onde, para todos $x,y\in A$, desenhamos uma setinha
$x\longrightarrow y$ sse $x \rel R y$.

%%}}}

%%{{{ eg: first_internal_diagrams_for_rel 
\example.
%%%{{{ meta 
\label first_internal_diagrams_for_rel
%%%}}}

Seja $A = \set{1, 2, 3, 4, 5, 6, 7, 8}$.
Desenhamos os diagramas de três relações binárias no $A$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-5) to                 (elem-7);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] ([shift={(0,.2)}]elem-4) arc (10:290:0.25);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$R$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to                 (elem-2);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-7) to                 (elem-5);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] (elem-6) to                 (elem-5);
\draw (rellabel) node {$S$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-5) to [bend left=20]  (elem-8);
\draw[->] (elem-8) to [bend left=20]  (elem-5);
\draw[->] (elem-3) to [bend left=20]  (elem-4);
\draw[->] (elem-4) to [bend left=20]  (elem-3);
\draw[->] (elem-7) to [bend left=10]  (elem-6);
\draw[->] (elem-6) to [bend left=10]  (elem-7);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$Q$};
\endtikzpicture
$$
Os gráficos delas então são os
$$
\align
\graph R &= \set{ (1,2), (2,1), (4,4), (5,5), (5,7), (5,8), (8,6) } \\
\graph S &= \set{ (1,2), (5,8), (6,5), (7,5), (8,6) } \\
\graph Q &= \set{ (1,2), (2,1), (3,4), (4,3), (5,5), (5,8), (6,7), (7,6), (8,5) }.
\endalign
$$
Mais uma vez, aviso que é comum identificar uma relação $R$ com seu gráfico
$\graph R$, escrevendo por exemplo $R = \set { (1,2), (2,1), \dotsc }$.
Já fez o~\ref[repeat_after_me_relations_are_not_sets], né?

%%}}}

%%{{{ x: empty_and_true_relation 
\exercise.
%%%{{{ meta 
\label empty_and_true_relation
%%%}}}

No mesmo conjunto $A = \set{1,2,3,4,5,6,7,8}$, como parecem os diagramas
das relações $F,T$ com gráficos $\graph F = \emptyset$ e $\graph T = A^2$?

\solution
O diagrama da $F$ parece assim:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw (0,-3.0) node {$F$};
\endtikzpicture
$$
E o diagrama da $T$ parece uma bagunça.

%%}}}

%%{{{ x: we_cannot_draw_two_parallel_arrows_on_a_rel_diagram 
\exercise.
%%%{{{ meta 
\label we_cannot_draw_two_parallel_arrows_on_a_rel_diagram
%%%}}}

Para quais relações podemos ter \emph{duas} setinhas do objeto $x$
para o objeto $y$?

\solution
Para nenhuma!
Exatamente como um conjunto não tem noção de \emph{quantas vezes}
um certo objeto pertence nele, uma relação também não tem noção
de \emph{quantas vezes} um certo objeto relaciona com um certo outro.

%%}}}

\endsection
%%}}}

%%{{{ Constructions and operations on relations 
\section Construções e operações em relações.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Todas as relações que consideramos nessa secção serão binárias.

%%}}}

%%{{{ df: ropposite 
\definition.
%%%{{{ meta 
\label ropposite
\defines
    * \rop {~R}  -- a relação oposta da $R$
    * relação!dual
    * relação!oposta
    ;;
\indexes
    * relação!inversa  see: oposta
    ;;
%%%}}}

Seja $R$ uma relação de $A$ para $B$.
Definimos a sua \dterm{relação oposta} (ou \dterm{relação dual})
$\rop R$ de $B$ para $A$ pela:
$$
x \rop R y \defiff y \rel R x.
$$
Também é conhecida como a \emph{relação inversa da $R$},
e a galera que a chama assim usa notação $\rinv R$,
\emph{mas não vamos usá-la nesse texto}---explicarei o porquê
no~\ref[rinv_is_not_inverse].

%%}}}

%%{{{ x: rop_is_an_involution 
\exercise.
%%%{{{ meta 
\label rop_is_an_involution
\defines
    * involução
    ;;
%%%}}}

A operação $\rop{\dhole}$ é uma \dterm{involução}:
$$
\text{para toda relação binária $R$, $\ropp {\rop R} = R$}.
$$

\solution
$
x \ropp{\rop R} y
\iff y \rop R x
\iff x \rel R y
$.

%%}}}

%%{{{ eg: opposite_relations_of_common_orders 
\example.
%%%{{{ meta 
%%%}}}

Nos $\reals$, a relação oposta $\rop<$ da $<$ é a $>$,
e a $\rop\leq$ é a $\geq$.

%%}}}

%%{{{ Composition 
\note Composição.
%%%{{{ meta 
%%%}}}

Dadas relações compatíveis, podemos formar sua composição
$R\rcom S$ numa forma natural.  Vamos ver uns exemplos
antes de chegar na definição formal.

%%}}}

%%{{{ eg: persons_books_words 
\example.
%%%{{{ meta 
\label persons_books_words
%%%}}}

Sejam os conjuntos $\pers$ de pessoas, $\cal B$ de livros, e $\cal W$ de palavras.
Considere as relações:
$$
\align
\Author(x,y)    &\defiff \text{$x$ é um escritor do livro $y$}\\
\Read(x,y)      &\defiff \text{$x$ leu o livro $y$}\\
\Contains(x,y)  &\defiff \text{a palavra $y$ aparece no livro $x$}
\endalign
$$
Observe que $\Author$ e $\Read$ são relações de $\pers$ para $\cal B$,
e $\Contains$ de $\cal B$ para $\cal W$.
O que seria a relação $\Author\rcom\Read$, o que a $\Author\rcom\Contains$,
e o que a $\Read\rcom\Contains$?
Antes de defini-las, vamos primeiramente pensar se faz sentido compor essas
relações.
Realmente $\Read$ é componível com $\Contains$
(gráças ao $\cal B$ ``no meio'') e
similarmente sobre a $\Author$ com $\Contains$.
No outro lado, não podemos compor as $\Author$ e $\Read$ em nenhuma
ordem!
Bem, então $\Author\rcom\Contains$ e $\Read\rcom\Contains$ são ambas
relações de $\pers$ para $\cal W$.
Mas quais?
Lembre que para definir uma relação, precisamos determinar
completamente quando dois arbitrários $x,y$ são relacionados pela
relação.
Precisamos então completar as:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{\dots?\dots}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{\dots?\dots}
\endalign
$$
mas como?
\spoiler
Bem, botamos:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{a pessoa $x$ escreveu algum livro que contem a palavra $y$}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{a pessoa $x$ leu algum livro que contem a palavra $y$}
\endalign
$$

%%}}}

%%{{{ x: comparison_of_statements_about_reading_books 
\exercise.
%%%{{{ meta 
\label comparison_of_statements_about_reading_books
%%%}}}

A relação $R$ de $\pers$ para $\cal W$ definida pela
$$
R(p,w) \defiff \text{a pessoa $p$ leu a palavra $w$ num livro}
$$
é a mesma relação com a $\Read\rcom\Contains$?
Em outras palavras:
$$
R \askeq \Read\rcom\Contains
$$

\hint
As afirmações:
$$
\gather
\text{a pessoa $p$ leu a palavra $w$ num livro}\\
\text{a pessoa $p$ leu um livro onde a palavra $w$ aparece}
\endgather
$$
estão afirmando a mesma coisa?

\solution
Não.
Pode ser que a pessoa leu uma palavra $w$ num livro $b$ mas nunca chegou
a ler um livro inteiro que contem a $w$.
Nesse caso temos apenas
$$
p \relp{\Read\rcom\Contains} w \implies p \rel R y
$$
pois se $p$ leu um livro que tem a palavra $w$ com certeza $p$ leu $w$ num livro.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já observamos que não podemos compor as $\Author$ e $\Read$ em nenhuma ordem,
mas podemos aplicar o operador $\rop\dhole$ e compor depois:

%%}}}

%%{{{ x: using_rop_to_compose 
\exercise.
%%%{{{ meta 
\label using_rop_to_compose
%%%}}}

Como definarias as relações $\Author\rcom{\rop\Read}$ e
$\Read\rcom{\rop\Author}$?
São iguais?

\solution
Temos:
$$
\align
x \relp{\Author\rcom{\rop\Read}} y &\iff \text{$x$ escreveu um livro que $y$ leu}\\
x \relp{\Read\rcom{\rop\Author}} y &\iff \text{$x$ leu um livro que $y$ escreveu}.
\endalign
$$
Não são iguais: uma é a oposta da outra.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Segue mais um exemplo, essa vez usando apenas um conjunto---e
logo todas as relações são gratuitamente compatíveis para composição.

%%}}}

%%{{{ x: grandparents_grandchildren_siblings_and_couples_with_children 
\exercise.
%%%{{{ meta 
\label grandparents_grandchildren_siblings_and_couples_with_children
%%%}}}

Considere as relações
$$
\align
\Parent(x,y) &\defiff \text{$x$ é a mãe ou o pai de $y$}\\
\Child(x,y)  &\defiff \text{$x$ é filho ou filha de $y$}.
\endalign
$$
Como tu definirias diretamente as relações seguintes?:
$$
\Parent\rcom\Parent
\qqquad
\Child\rcom\Child
\qqquad
\Parent\rcom\Child
\qqquad
\Child\rcom\Parent
$$

\solution
Temos:
$$
\align
x \relp{\Parent\rcom\Parent} y &\defiff \text{$x$ é um avô ou uma avó de $y$}\\
x \relp{\Child\rcom\Child}   y &\defiff \text{$x$ é um neto ou uma neta de $y$}\\
x \relp{\Parent\rcom\Child}  y &\defiff \text{$x$ e $y$ tem um filho ou uma filha juntos}\\
x \relp{\Child\rcom\Parent}  y &\defiff \text{$x$ e $y$ são irmã(o)s ou a mesma pessoa}
\endalign
$$

%%}}}

%%{{{ Q: How can we define composition of relations? 
\question.
%%%{{{ meta 
%%%}}}

Como tu imaginas o interior desse black box?
$$
\tikzpicture
\tikzi blackboxrelcompb;
\endtikzpicture
$$
E, como tu definarias a composição de relações?

%%}}}

\spoiler

%%{{{ Composition with black boxes 
\note Composição com black boxes.
%%%{{{ meta 
%%%}}}

Talvez as imagens seguintes com black boxes ajudam a pensar numa definição formal.
$$
\tikzpicture
\tikzi blackboxrelcompt;
\endtikzpicture
$$

%%}}}

%%{{{ df: rcompose 
\definition.
%%%{{{ meta 
\label rcompose
\indexes
    * composição!de relações    see: relação
    ;;
\defines
    * relação!composição
    ;;
%%%}}}

Sejam conjuntos $A,B,C$ e as relações~$R$ de~$A$ para~$B$
e~$S$ de~$B$ para~$C$.
Definimos a relação~$R\rcom S$ de~$A$ para~$C$ pela
$$
a\rel{(R \rcom S)}c
\defiff
\text{existe $b \in B$ tal que $a \rel R b$ \& $b \rel S c$}.
$$
Chamamos a $R \rcom S$ a \dterm{composição} da $R$ \emph{com} a $S$.
Quando não existe possibilidade de confusão escrevemos a composição
com várias outras notações.
Todas as expressões seguintes podem ser usadas:
$$
\xalignat5
& R \rcom S &
& R \com  S &
& R \dcom S &
& R \cdot S &
& RS
\endxalignat
$$

%%}}}

%%{{{ beware: RoS_not_SoR 
\beware.
%%%{{{ meta 
\label RoS_not_SoR
%%%}}}

Não existe um consensus para a ordem de escrever os $R,S$
usando o símbolo $\compose$.
Tome cuidado então enquanto lendo a notação $R \com S$,
pois o que um autor escreve como $R \com S$, outro pode escrever
como $S \com R$.
Quando a composição é denotada por $\dcom$ a ordem concorda com nossa:
$$
a\rel{(R \dcom S)}c
\defiff
\text{existe $y \in B$ tal que $a \rel R y$ \& $y \rel S c$}.
$$
Veja também o~\ref[diagrammatic_notation].

%%}}}

%%{{{ prop: associativity_of_rcom 
\property.
%%%{{{ meta 
\label associativity_of_rcom
%%%}}}

Sejam conjuntos $A,B,C,D$ e relações binárias
$R : \reltype{A,B}$,
$S : \reltype{B,C}$, e
$T : \reltype{C,D}$.
Então
$$
(R\rcom S)\rcom T = R \rcom (S\rcom T),
$$
e logo podemos escrever apenas $R\rcom S\rcom T$.

\sketch.
Supomos $a \in A$ e $d\in D$, e mostramos a equivalência
$$
a \relp{(R\rcom S)\rcom T} d
\iff
a \relp{R\rcom (S\rcom T)} d.
$$

\proof.
Demonstrarei em detalhe a
$$
a \relp{(R\rcom S)\rcom T} d
\implies
a \relp{R\rcom (S\rcom T)} d.
$$
A {\rldir} é similar.  Temos:
\stepproof
\proofsteptnb {Suponha $a\in A$ e $d\in D$ tais que $a \rel{(RS)T} d$.}
\proofsteptnb {Logo seja $c \in C$ tal que $a \rel {RS} c\fact1 \mland c \rel T d\fact2$.}
\proofsteptby {Logo Seja $b \in B$ tal que $a \rel R b\fact3 \mland b \rel S c\fact4$.} {pelo~\byfact1}
\proofsteptby {Logo $b \rel {ST} d$\fact5.} {pelos~\byfact4 e~\byfact2}
\proofsteptby {Logo $a \rel {R(ST)} d$.}    {pelos~\byfact3 e~\byfact5}
\endstepproof

%%}}}

%%{{{ x: associativity_of_rcom_nat_lang 
\exercise.
%%%{{{ meta 
\label associativity_of_rcom_nat_lang
%%%}}}

Escreva uma prova em linguagem natural da~\ref[associativity_of_rcom].

\solution
\lrdir:
Suponha $a \in A$ e $d \in D$ tais que
$a \rel{((R\rcom S)\rcom T)} d$.
Logo, para algum $c\in C$, temos $a \rel{(R\rcom S)} c$\fact1\ e
$c \rel{T} d$\fact2,
e usando a \byfact1\ ganhamos um $b\in B$ tal que $a \rel{R} b$\fact3
e $b \rel{S} c$\fact4.
Juntando as \byfact4~e~\byfact2 temos $b \rel{(S \rcom T)} d$, e agora
junto com a \byfact3~chegamos em
$a \rel{((R\rcom S)\rcom T)} d$.
\eop
A direção \rldir\ é similar.

%%}}}

%%{{{ x: only_if_incest 
\exercise.
%%%{{{ meta 
\label only_if_incest
%%%}}}

Demonstre ou refute:
$$
\Child\rcom\Parent
\askeq
\Parent\rcom\Child.
$$

\hint
$\Child\rcom\Parent\neq\Parent\rcom\Child$.
Agora refute!

\solution
Temos $\Child\rcom\Parent\neq\Parent\rcom\Child$:
\eop
Tome $x,y\in \pers$ dois irmãos que não têm filhos (juntos).
Logo
$$
x \relp{\Parent\rcom\Child} y
\qqtext{mas não}
x \relp{\Child\rcom\Parent} y.
$$
Demonstramos assim que as duas relações são diferentes.

%%}}}

%%{{{ x: id_of_rcom 
\exercise.
%%%{{{ meta 
\label id_of_rcom
%%%}}}

Considere a $\rcom$ como uma operação binária nas relações binárias num conjunto $A$.
Ela tem \dterm{identidade}?  Ou seja, existe alguma relação binária $I$ no $A$,
tal que
$$
\text{para toda relação $R$ no $A$,}\quad
I \rcom R = R = R \rcom I\,?
$$
Se sim, defina essa relação $I$ e demonstre que realmente é.
Se não, demonstre que não existe.

\hint
Sem pensar, dois candidatos prováveis para considerar seriam a igualdade no $A$
e a relação trivial $\True$ satisfeita por todos os pares de elementos de $A$:
$$
\text{ou}
\knuthcases {
x \rel I y \defiff \True\cr
x \rel I y \defiff x = y
}
$$

\solution
Existe sim: a $I$ é a igualdade $\eqof A$ no $A$.
Vamos mostrar que para todos $a,b \in A$
$$
a \rel R b \iff a \relp{I \rcom R} b.
$$
Tratamos cada direção separadamente.
\eop
\lrdir.
Suponha que $a \rel R b$.
Precisamos mostrar que
existe $w\in A$ tal que $a \rel I w$ e $w \rel R b$.
Tome $w \asseq a$.  Realmente temos $a \rel I a$ (pois $I$ é a igualdade),
e $a \rel R b$ que é nossa hipótese.
\eop
\rldir.
Suponha que $a \relp{I \rcom R} b$.
Logo, existe $w\in A$ tal que $a \rel I w$\fact1 e $w \rel R b$\fact2.
Mas, como $I$ é a igualdade, o único $w$ que satisfaz a~\reffact1 é o próprio~$a$.
Ou seja, $w = a$.
Substituindo na~\byfact2, ganhamos o desejado $a \rel R b$.
\eop
A outra equivalência,
$$
a \rel R b \iff a \relp{R \rcom I} b,
$$
é similar.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo uma operação binária (composição) e sua identidade (\ref[id_of_rcom])
podemos já definir as suas potências.

%%}}}

%%{{{ x: R_exp_n 
\exercise Potências.
%%%{{{ meta 
\label R_exp_n
%%%}}}

Defina formalmente as ``potências'' $R^n$ duma dada relação binária $R$
num conjunto $A$, informalmente definida por:
$$
x \relp{R^n} y \pseudodefiff
x \rel{\Big(\tubrace{R \rcom\dotsb\rcom R}{$n$ vezes}\Big)} y,
$$
válida \emph{para todo $n\in\nats$}.

\hint
Questão: o que precisa achar para tua definição servir para o caso $n=0$ também?

\hint
Resposta: precisa achar o elemento neutro da operação $\rcompose$.
Já fez o~\ref[id_of_rcom], né?

\solution
Definimos:
$$
\align
x \relp{R^0} y     &\defiff x=y \\
x \relp{R^{n+1}} y &\defiff x \relp{R \rcom {R^n}} y
\endalign
$$
ou, diretamente, em estilo ``point-free'':
$$
\align
R^0     &\defeq \Eq \\
R^{n+1} &\defeq R^n \rcom R,
\endalign
$$
onde escrevemos $\Eq$ para a relação $\eqof A$ de igualdade no $A$.

%%}}}

%%{{{ x: operation_with_opposite_does_not_yield_identity 
\exercise.
%%%{{{ meta 
\label operation_with_opposite_does_not_yield_identity
%%%}}}

Demonstre ou refute:
\emph{para toda relação binária $R$ num conjunto $A$,
$R \rcom {\rop R} = \Eq = {\rop R} \rcom R$}.

\hint
\ref[grandparents_grandchildren_siblings_and_couples_with_children].

\hint
\ref[only_if_incest]

\hint
Temos $\Parent = \rop \Child$ (e logo $\Child = \rop \Parent$ também).

\solution
Não, como o contraexemplo do~\ref[only_if_incest] mostra, pois
$$
{\Parent} = {\rop \Child} \qquad\mland\qquad {\Child} = {\rop \Parent}.
$$

%%}}}

%%{{{ x: describe_coauthors_in_terms_of_author 
\exercise.
%%%{{{ meta 
\label describe_coauthors_in_terms_of_author
%%%}}}

Descreva a $\namedrel{Coauthors}$ do \ref[relations_with_text_example]
em termos da $\namedrel{Author}$.

\solution
Considerando que um escritor é coescritor com ele mesmo,
$$
\namedrel{Coauthors} = \namedrel{Author}\rcom\rop{\namedrel{Author}}.
$$

%%}}}

%%{{{ beware: rinv_is_not_inverse 
\beware A inversa não é inversa.
%%%{{{ meta 
\label rinv_is_not_inverse
%%%}}}

Depois dos exercícios~\reftag[operation_with_opposite_does_not_yield_identity]
e~\reftag[describe_coauthors_in_terms_of_author], deve ser claro porque eu
preferi chamar a $\rop R$ a relação \emph{oposta} da $R$, e usar essa notação
em vez de $\rinv R$ e o nome \emph{inversa}.
(Que também usamos pois são os mais comuns!)
Se usar a notação $\rinv R$, cuidado para não confundir que
$R \rcom {\rinv R} = \Eq = {\rinv R} \rcom R$,
pois em geral isso não é verdade.
Ou seja: a relação ``inversa'' $\rinv R$,
\emph{não é a $\rcom$-inversa} da $R$!

%%}}}

%%{{{ x: rop_of_rcompose 
\exercise Some stuff.
%%%{{{ meta 
\label rop_of_rcompose
%%%}}}

Sejam $R,S$ relações binárias tais que a $R\rcom S$ é definida.
Descreva a $\ropp{R\rcom S}$ em termos das $\rop R$ e $\rop S$
e demonstre tua afirmação.

\hint
${\ropp{R \rcom S}} = {\rop S \rcom \rop R}$.
Demonstre!

\solution
Vou demonstrar que $\ropp{R \rcom S} = \rop S \rcom \rop R$.
Calculo:
\compute
x \ropp{RS} y
&\iff y \rel{RS} x                                              \by {def.~$\ropp{RS}$} \\
&\iff \text{existe $w$ tal que $y \rel R w \mland w \rel S x$}  \by {def.~$RS$} \\
&\iff \text{existe $w$ tal que $w \rop R y \mland x \rop S w$}  \by {def.~$\rop R$ e~$\rop S$} \\
&\iff \text{existe $w$ tal que $x \rop S w \mland w \rop R y$}  \\
&\iff x \rel{{\rop S}{\rop R}} y.                               \by {def.~${\rop S}{\rop R}$} \\
\endcompute

%%}}}

%%{{{ df: union_and_inter_of_rels 
\definition união; intersecção.
%%%{{{ meta 
\label union_and_inter_of_rels
%%%}}}

Sejam $R,S\subset A\times B$ relações binárias.
Definimos as relações $R\union S$ e $R\inter S$ no $\relspace{A,B}$
pelas
$$
\align
x \relp{R \union S} y &\defiff x \rel R y \mlor  x \rel S y \\
x \relp{R \inter S} y &\defiff x \rel R y \mland x \rel S y.
\endalign
$$
Observe que, identificando as relações com seus gráficos,
as $R \union S$ e $R \inter S$ acabam sendo a união
e intersecção deles mesmo:
$$
\align
\graphP {R \union S} &= \graph R \union \graph S \\
\graphP {R \inter S} &= \graph R \inter \graph S.
\endalign
$$
Claramente generalizamos para famílias de relações $\scr R$,
e assim temos as relações
$$
\xalignat2
\tsize \Union \scr R &: \reltype{A,B} &
\tsize x \relp{\Union \scr R} y & \defiff \lexists {R \in \scr R} {x \rel R y} \\
\tsize \Inter \scr R &: \reltype{A,B} &
\tsize x \relp{\Inter \scr R} y & \defiff \lforall {R \in \scr R} {x \rel R y}.
\endxalignat
$$

%%}}}

%%{{{ eg: union_and_inter_of_orders 
\example.
%%%{{{ meta 
%%%}}}

Nos reais, a $\mathop{<}\union\mathop{=}$ é a relação $\leq$,
e a $\mathop{\leq}\inter\mathop{\geq}$ é a relação $=$.
Substituindo o ``é a relação'' com o símbolo \symq{$=$} que usamos
normalmente a gente acabaria escrevendo essas coisas horrorosas:
$$
\xalignat2
\mathord{\mathop{<}\union\mathop{=}} &= \mathord{\leq} &
\mathord{\mathop{\leq}\inter\mathop{\geq}} &= \mathord{=}.
\intertext{%
Isso fica \emph{muito} esquisito no olho para parsear;
botando parenteses ajuda:
}
\paren{\mathord{\paren{\mathop{<}}\union\paren{\mathop{=}}}} &= \paren{\mathord{\leq}} &
\paren{\mathord{\paren{\mathop{\leq}}\inter\paren{\mathop{\geq}}}} &= \paren{\mathord{=}}.
\endxalignat
$$
Tente sempre escrever na maneira mais legível e entendível.

%%}}}

\endsection
%%}}}

%%{{{ Properties of relations 
\section Propriedades de relações.
%%%{{{ meta 
%%%}}}

%%{{{ intro 
\secintro
Aqui aumentamos nossa terminologia, identificando certas propriedades
interessantes que uma relação binária $R$ no $X$ pode ter.
%%}}}

%%{{{ Reflection 
\note Reflexão.
%%%{{{ meta 
\label reflexion_terminology
\defines
    * relação!irreflexiva
    * relação!reflexiva
    ;;
%%%}}}

Olhamos como cada elemento do $X$ relaciona com ele mesmo.
Dois casos notáveis aparecem:
(i) pode ser que para todo $x$ temos $x\rel R x$;
(ii) pode ser que para nenhum $x$ temos $x\rel R x$.
No primeiro caso, chamamos $R$ \dterm{reflexiva}; no segundo, \dterm{irreflexiva}.
Observe que ``irreflexiva'' não significa ``não reflexiva'', etc:
$$
\alignat 2
\text{$R$ é reflexiva}      &\iff \phantom\lnot\forall x R(x,x)        &&\iff \lnot\exists x \lnot R(x,x)\\
\text{$R$ não é reflexiva}  &\iff \lnot\forall x R(x,x)                &&\iff \phantom\lnot\exists x \lnot R(x,x)\\
\text{$R$ é irreflexiva}    &\iff \phantom\lnot\forall x \lnot R(x,x)  &&\iff \lnot\exists x R(x,x)\\
\text{$R$ não é irreflexiva}&\iff \lnot\forall x \lnot R(x,x)          &&\iff \phantom\lnot\exists x R(x,x)
\endalignat
$$
onde os quantificadores quantificam sobre o $X$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

As relações $=$, $\leq$, $\geq$, nos números e $=$, $\subset$, $\supset$ nos conjuntos são todas reflexivas.
Também reflexivas são as relações
\trel{\thole\ nasceu no mesmo pais que \thole},
\trel{\thole\ tem o mesmo primeiro nome com \thole}, etc.,
definidas entre pessoas.
Típicos exemplos de irreflexivas são as $\neq$, $<$, $>$, $\subsetneq$, $\supsetneq$,
\trel{\thole\ é mais baixo que \thole},
\trel{\thole\ e \thole\ nunca estiveram em distância de 2 metros entre si},
etc.

%%}}}

%%{{{ Symmetry 
\note Simetria.
%%%{{{ meta 
\label symmetry_terminology
\defines
    * relação!antissimétrica
    * relação!assimétrica
    * relação!simétrica
    ;;
%%%}}}

Agora examinamos a relação $R$ com respeito à ordem dos seus argumentos.
Novamente, certos casos notáveis aparecem:
(i) $R$ pode comportar sempre no mesmo jeito independente da ordem dos seus argumentos; nesse caso a chamamos \dterm{simétrica}.
(ii) O $R$-relacionamento dum objeto $x$ com outro $y$ pode garantir que o $y$ não esta $R$-relacionado com o $x$; a chamamos \dterm{assimétrica}.
(iii) O único caso onde a $R$ relaciona os mesmos argumentos com as duas possíveis órdens, é quando os dois argumentos são iguais; chamamos a $R$ \dterm{antissimétrica}.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Simétricas:
$=$, $\neq$,
\trel{\thole\ e \thole\ são irmãos},
\trel{\thole\ e \thole\ são cidades do mesmo país},
etc.
\eop\noi
Asimétricas:
$<$, $\subsetneq$, $>$, $\supsetneq$,
\trel{\thole\ deve dinheiro para \thole},
\trel{\thole\ está andando na mesma direção e no lado esquerdo de \thole},
\trel{\thole\ é a mãe de \thole},
etc.
\eop\noi
Antissimétricas:
$\leq$, $\subset$, $\geq$, $\supset$, $=$,
\trel{a palavra \thole\ aparece, mas não depois da palavra \thole\ no dicionário},
etc.

%%}}}

%%{{{ x: not_symmetric_notequiv_asymmetric 
\exercise.
%%%{{{ meta 
\label not_symmetric_notequiv_asymmetric
%%%}}}

Verifique que ``não simétrica'' não significa nem ``assimétrica''
nem ``antissimétrica'', escrevendo todas as fórmulas envolvidas e suas negações,
como no~\reftag[reflexion_terminology].

%%}}}

%%{{{ x: check_reflexion_and_symmetry 
\exercise.
%%%{{{ meta 
\label check_reflexion_and_symmetry
%%%}}}

Decida a ``reflexão'' e a ``simetria'' das relações seguintes:
$$
\align
R(A, B) &\letiff \text{os conjuntos $A$ e $B$ são disjuntos}\\
S(A, B) &\letiff |A\setminus B| > 1\\
T(A, B) &\letiff A\symdiff B \neq \emptyset.
\endalign
$$
Isso quis dizer: para cada uma dessas relações, decida se ela é:
reflexiva, irreflexiva, simétrica, assimétrica, antissimétrica.

%%}}}

%%{{{ x: asymmetric_implies_irreflexive 
\exercise.
%%%{{{ meta 
\label asymmetric_implies_irreflexive
%%%}}}

Mostre que:
$$
\text{$R$ assimétrica} \implies \text{$R$ irreflexiva}.
$$

\hint
Contrapositivo.

\solution
Mostramos o contrapositivo.
Suponha que $R$ não é irreflexiva.
Então existe $s$ com $R(s,s)$,
e logo é impossível que a $R$ seja assimétrica,
pois achamos $x$ e $y$ ($x,y\asseq s$) que satisfazem ambas
$R(x,y)$ e $R(y,x)$.

%%}}}

%%{{{ x: asymetric_implies_antisymmetric 
\exercise.
%%%{{{ meta 
\label asymetric_implies_antisymmetric
%%%}}}

Uma das duas direções abaixo é válida:
$$
\text{$R$ assimétrica} \askiff \text{$R$ antissimétrica}.
$$
Demonstre-a, e mostre que a oposta não é.

\hint
Como uma relação assimétrica poderia não ser antissimétrica?
(O que significa ``não ser antissimétrica''?)

\hint
Procure contraexemplo nos exemplos típicos de relação antissimétrica.

\solution
Para demonstrar a \lrdir, observe que $R$ não é antissimétrica
sse existem $x$ e $y$ tais que:
$$
\underbrace{R(x,y)
\land
R(y,x)}_{\text{impossível por assimetria}}
{}\land\ \ 
{x\neq y}.
$$
Para refutar a \rldir, considere o contraexemplo da antissimétrica $\leq$
no $\nats$, que não é assimétrica, pois é reflexiva.

%%}}}

%%{{{ x: rop_of_symmetric 
\exercise.
%%%{{{ meta 
\label rop_of_symmetric
%%%}}}

Seja $R : \reltype{X,X}$.
Logo
$$
\text{$R$ simétrica}
\iff
R = \rop R.
$$

\solution
\proofpart{\lrdir.}
Suponha $R$ simétrica.
\compute
x \rel R y
&\implies y \rel R x  \by {hipótese} \\
&\implies x \rop R y. \by {def.~$\rop R$} \\
\endcompute
\proofpart{\rldir.}
Suponha $R = \rop R$.
\compute
x \rel R y
&\implies y \rop R x  \by {def.~$\rop R$} \\
&\implies y \rel R x. \by {hipótese} \\
\endcompute

%%}}}

%%{{{ Transitions 
\note Transições.
%%%{{{ meta 
\defines
    * relação!circular
    * relação!left-euclidean
    * relação!right-euclidean
    * relação!transitiva
    ;;
%%%}}}

Às vezes queremos garantir a existência de alguma seta dadas duas ou mais setas.
Suponha que $x\rel R y$ e $y \rel R z$.
Se isso garanta que $x\rel R z$ chamamos a $R$ \dterm{transitiva};
e se isso garanta que $z \rel R x$, \dterm{circular}.
Suponha agora que temos dois objetos cada um relacionado com um terceiro.
Se isso já é suficiente para garantir que eles também são relacionados,
chamamos a relação \dterm{left-euclidean}.
Similarmente, se a relação de um objeto com dois outros garanta que os outros
também relacionam entre si, chamamos a relação \dterm{right-euclidean}.

%%}}}

%%{{{ Why the names -euclidean? 
\note Por que ``euclidean''?.
%%%{{{ meta 
%%%}}}

O primeiro axioma de {\Euclid}Euclides no seu ``Elementos'' é:
\emph{coisas iguais com outra coisa, são iguais entre si também}.
Podemos visualizar isso tanto como
<<$a=c$ e $b=c$ implica $a=b$>>
(left-euclidean pois a conclusão aconteceu no lado esquerdo); 
quanto como
<<$a=b$ e $a=c$ implica $b=c$>>
(right-euclidean pois a conclusão aconteceu no lado direito).

%%}}}

%%{{{ Totalities 
\note Totalidades.
%%%{{{ meta 
\defines
    * relação!total
    * relação!tricotômica
    ;;
%%%}}}

Tem duas noções onde uma relação pode ``dominar'' um conjunto, no sentido
de ``opiniar'' sobre quaisquer $x,y$ nele.
A primeira só usa a relação em questão $R$ mesmo:
dizemos que $R$ é \dterm{total} sse quaisquer $x,y$ são relacionados em pelo
menos uma ordem: $x \rel R y$ ou $y \rel R x$.
A segunda usa a ajuda da igualdade:
dizemos que $R$ é \dterm{tricotômica} sse para quaisquer $x,y$ exatamente
uma das três possibilidades é válida: $x \rel R y$; $y \rel R x$; $x = y$.

%%}}}

%%{{{ Glossary: relations_glossary 
\note Glossário.
%%%{{{ meta 
\label relations_glossary
%%%}}}

Resumimos aqui as propriedades que encontramos.
Seja $X$ conjunto e $R$ uma relação binária nele.
Definimos as seguintes propriedades:
\mathcall
& x \rel R x                                           \called {reflexiva} \\
& x \not\rel R x                                       \called {irreflexiva} \\
& x \rel R y  \implies  y \rel R x                     \called {simétrica} \\
& x \rel R y  \implies  y \not\rel R x                 \called {assimétrica} \\
& x \rel R y  \mland y \rel R x \implies x = y         \called {antissimétrica} \\
& x \rel R y  \mland  y \rel R z \implies x \rel R z   \called {transitiva} \\
& x \rel R y  \mland  y \rel R z \implies z \rel R x   \called {circular} \\
& x \rel R y  \mland  x \rel R z \implies y \rel R z   \called {right-euclidean} \\
& x \rel R z  \mland  y \rel R z \implies x \rel R y   \called {left-euclidean} \\
& x \rel R y  \mlor   y \rel R x                       \called {total} \\
& \text{exatamente uma das:
        $x \rel R y$; $y \rel R x$; $x = y$}           \called {tricotômica} \\
\endmathcall
Para o caso mais geral onde $R$ é uma relação binária de $X$ para $Y$, temos:
\mathcall
&  \pforall {x \in X} \lexists {y \in Y} {x \rel R y}  \called {left-total} \\
&  \pforall {y \in Y} \lexists {x \in X} {x \rel R y}  \called {right-total ou surjectiva} \\
&  y \rel R x  \mland  z \rel R x \implies y = z       \called {left-unique ou injectiva} \\
&  x \rel R y  \mland  x \rel R z \implies y = z       \called {right-unique ou funccional} \\
\endmathcall

%%}}}

%%{{{ x: investigate_rel_properties_of_three_diags 
\exercise.
%%%{{{ meta 
\label investigate_rel_properties_of_three_diags
%%%}}}

Para cada uma das relações $R,S,Q,F,T$ do~\reftag[first_internal_diagrams_for_rel]
e do~\ref[empty_and_true_relation] decida se ela têm ou não, cada uma das
propriedades do glossário no~\reftag[relations_glossary].

\hint
Cuidado: nas propriedades que acabam ser implicações, as variáveis que aparecem
nas suas premissas não denotam obrigatoriamente objetos distintos!

%%}}}

%%{{{ prop: wrong_property_of_sym_and_trans_implies_refl 
\proposition.
%%%{{{ meta 
\label wrong_property_of_sym_and_trans_implies_refl
%%%}}}

Seja $X\neq\emptyset$ e $\sim$ uma relação no $X$.
Se $\sim$ é simétrica e transitiva, então ela é reflexiva.

\wrongproof.
Como ela é simétrica, de $x\sim y$ concluimos que $y\sim x$ também.
E agora usando a transitividade, de $x\sim y$ e $y\sim x$, concluimos a $x\sim x$,
que mostra que $\sim$ é reflexiva também.

%%}}}

%%{{{ x: find the error and prove that the proposition is false 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o erro na demonstração acima e \emph{demonstre} que a proposição é falsa!

%%}}}

%%{{{ remark: conventions_for_internal_diagrams_of_rel 
\remark Convenções para diagramas internos.
%%%{{{ meta 
\label conventions_for_internal_diagrams_of_rel
%%%}}}

Quando queremos desenhar o diagrama duma relação que
sabemos que tem uma certa propriedade, podemos preguiçar
e não desenhar todas as suas setas.
\crtabcase{Reflexiva:}
não precisamos botar nenhuma das setinhas-redemoinhos,
pois graças à reflexividade são todas implicitas.
\crtabcase{Simétrica:}
não precisamos botar cabeças nas setas, pois para
cada seta já é garantida a sua seta-oposta, então
botamos apenas uma linha entre dois objetos e já
entendemos que existem as setas das duas direções
entre si.
\crtabcase{Transitiva:}
não precisamos desenhar setas entre objetos se já
existe um caminho entre eles usando outras setas
já desenhadas.
\crtabcase{Relação de equivalência:}
não precisamos desenhar nem linhas entre os objetos
que relacionam; apenas desenhar regiões por volta
de todos os relacionados, algo que vai virar óbvio
na~\ref[Quotient_set].
\crtabcase{Relação de ordem:}
desenhamos diagramas de~{{\Hasse}}Hasse, que vamos
encontrar depois (pouco
na~\ref[hasse_diagrams_first_encounter] e muito
no~\ref[Posets_Lattices]).

%%}}}

\endsection
%%}}}

%%{{{ Closures 
\section Fechos.
%%%{{{ meta 
\label Closures
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Antes de definir formalmente o conceito importante de fechos,
começamos com uns exemplos ilustrativos para os três fechos mais comuns:
reflexivo, simétrico, transitivo.
A idéia é sempre a mesma, e vamos descrevê-la como um algoritmo.

%%}}}

%%{{{ The idea 
\note A idéia.
%%%{{{ meta 
\label Closure_informal_bottom_up
%%%}}}

Começamos com uma relação $R$, e fixamos uma propriedade
desejada (por exemplo, a transitividade).
Vamos construir uma nova relação $\bar R$, que chamamos o \dterm{fecho}
da $R$ pela propriedade escolhida.
Pense na $R$ como o seu diagrama interno, com suas setinhas.
Primeiramente nós nos perguntamos:
<<a relação já tem essa propriedade?>>
Caso que sim, não precisamos fazer nada, a relação que temos é
o fecho $\bar R$ que queriamos construir.
Caso que não, quis dizer que tem setinhas que
\emph{deveriam estar} no diagrama, mas não estão.
(Essas setinhas são as testemunhas que refutam a nossa propriedade.)
Vamos adicioná-las na nossa relação.
E agora voltamos a perguntar a mesma pergunta,
e continuar no mesmo jeito, até finalmente chegar numa
relação $\bar R$ que realmente satisfaz a propriedade escolhida.
Essa relação $\bar R$ é o fecho da $R$ pelessa propriedade.

%%}}}

%%{{{ eg: reflexive_closure_example 
\example Fecho reflexivo.
%%%{{{ meta 
\label reflexive_closure_example
%%%}}}

Seja $R$ a relação no $A$ com o diagrama seguinte:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Qual é o fecho reflexivo dela?
Bem, primeiramente nós nos perguntamos:
será que a relação já é reflexiva?
Ela não é.
Identificamos então as setinhas-testemunhas desse fato:
são as $(1,1)$, $(3,3)$, $(7,7)$, e $(8,8)$.
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\node[color=blue] (elem-1b) at (elem-1) {$1$};
\node[color=blue] (elem-3b) at (elem-3) {$3$};
\node[color=blue] (elem-7b) at (elem-7) {$7$};
\node[color=blue] (elem-8b) at (elem-8) {$8$};
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
As adicionamos na relação e chegamos em:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
\dots e perguntamos a mesma pergunta:
será que ela é reflexiva?
Agora é sim!
Essa relação então é o \emph{fecho reflexivo} da $R$.

%%}}}

%%{{{ eg: symmetric_closure_example 
\example Fecho simétrico.
%%%{{{ meta 
\label symmetric_closure_example
%%%}}}

Vamos calcular agora o fecho simétrico da mesma relação $R$
do~\ref[reflexive_closure_example]:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Será que ela já é simétrica?
Ela não é por causa das três setinhas seguintes,
onde para cada uma mostro em azul a setinha-razão que obriga
a setinha-faltante (em vermelho) ser adicionada:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to                 (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-6) to [bend left=30]  (elem-8);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-6) to                 (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-7) to [bend left=15]  (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to                 (elem-8);
\draw[->, color=red , ultra thick, dotted] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
\endxxalignat
$$
Então adicionamos todas essas setinhas necessárias:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->            ] (elem-8) to                 (elem-6);
\draw[->            ] (elem-6) to                 (elem-7);
\draw[->            ] (elem-5) to                 (elem-8);
\draw[->            ] (elem-6) to [bend left=30]  (elem-8);
\draw[->            ] (elem-7) to [bend left=15]  (elem-6);
\draw[->            ] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
$$
Agora perguntamos novamente: a relação é simétrica?
Ela é sim, então paramos aqui.
A relação criada é o \emph{fecho simétrico} da $R$.

%%}}}

%%{{{ eg: transitive_closure_example 
\example Fecho transitivo.
%%%{{{ meta 
\label transitive_closure_example
%%%}}}

Para ser original, seja $R$ a mesma relação dos
exemplos~\reftag[reflexive_closure_example]--\reftag[symmetric_closure_example]:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Essa vez vamos calcular o fecho transitivo dela, então começamos com a pergunta:
será que a relação já é transitiva?
Não é!
Então precisamos achar todas as setinhas que deveriam estar nela e não estão
e adicioná-las:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-8) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-1) to [bend left=20] (elem-2);
\draw[->, color=blue, ultra thick        ] (elem-2) to [bend left=20] (elem-1);
\draw[->, color=red , ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\endtikzpicture
\endxxalignat
$$
Adicionando todas essas setas necessárias, chegamos na relação:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\endtikzpicture
$$
E perguntamos: ela é transitiva?
\emph{Ainda não!}
Pois, as novas setinhas que adicionamos criaram novos caminhos que
obrigam mais uma setinha estar na relação (dois caminhos diferentes
explicam a adição dessa mesma setinha nesse caso):
$$
\xalignat2
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
\endxalignat
$$
Adicionamos então a setinha $(5,7)$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->] (elem-5) to (elem-7);
\endtikzpicture
$$
Ela é transitiva agora?  Sim, finalmente!
Então esse é o \emph{fecho transitivo} da $R$.

%%}}}

%%{{{ pseudodf: fecho_pseudodefinition 
\pseudodefinition.
%%%{{{ meta 
\label closure_pseudodefinition
\defines
    * fecho!de relação
    ;;
%%%}}}

Seja $R$ uma relação binária num conjunto $A$,
e fixe uma propriedade \emph{razoável}
daquelas que aparecem no~glossário~\reftag[relations_glossary].
Definimos o fecho da $R$ pela propriedade para ser a relação que criamos se
\emph{adicionar} numa maneira \emph{justa} todas as setinhas \emph{necessárias}
no diagrama da $R$ até ela virar uma relação com a propriedade
desejada.

%%}}}

%%{{{ remark: we may add but never remove 
\remark Podemos botar mas não retirar.
%%%{{{ meta 
%%%}}}

Note então que o fecho $\bar R$ duma relação $R$ tem todas
as setinhas que $R$ tem, e possivelmente mais ainda.
Ou seja, temos
$$
\graph R \subset \graph \bar R
$$
para qualquer fecho escolhido.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na~\ref[closure_pseudodefinition] enfatizei as palavras ``razoável'',
``justa'' e ``necessárias''.
Vamos ver o que cada uma delas quis dizer mesmo.

%%}}}

%%{{{ Necessary arrows 
\note Setinhas necessárias.
%%%{{{ meta 
%%%}}}

``Adicionar apenas as setinhas \emph{necessárias}'' quis dizer que
a falta de cada uma dessas setinhas é uma razão que nossa relação não
satisfaz a propriedade escolhida.
Caso contrário não vamos adiciona-la, \emph{mesmo se sua adição não afeta nada}.

%%}}}

%%{{{ Fair way 
\note Maneira justa.
%%%{{{ meta 
%%%}}}

``Adicionar setinhas numa maneira \emph{justa}'' quis dizer que em
nenhum ponto vamos ter que escolher entre duas ou mais setinhas-testemunhas
\emph{tais que a adição de apenas uma} seria suficiente para satisfazer
a propriedade.
Imagine que nesse caso, nossa escolha não seria justa para a setinha
não-escolhida (ou para a setinha escolhida, dependendo o ponto de vista).
Formar o fecho duma relação deve ser uma operação, e sendo isso deve
ser determinística.
Imagina entao que temos uma propriedade estranha, dizendo que:
$$
x \rel R x \mland y \rel R y \implies x \rel R y \mlor y \rel R x.
$$
(Nem adianta tentar achar um nome razoável para essa propriedade.)
Agora, a relação $R$ no $\nats$ com $\graph R = \set{ (0,0), (1,1) }$
claramente não satisfaz essa propriedade.
Tentando formar o fecho através dessa propriedade, já na primeira etapa,
temos duas ``setinhas-testemunhas'' que podemos escolher para adicionar:
a $(0,1)$ e a $(1,0)$.  Graças à restricção de ``necessárias'', não podemos
adicionar ambas, pois assim que adicionar uma, a propriedade já é satisfeita.
No outro lado, não podemos escolher uma das duas numa maneira justa:
as duas servem igualmente bem.
\emph{Para esse tipo de propriedade então não podemos definir um fecho.}
Espero que isso explica também o que eu quis dizer com a palavra ``razoável''.
O~\ref[unreasonable_properties_for_closures_of_relations] esclarecerá
isso ainda mais.

%%}}}

%%{{{ x: unreasonable_properties_for_closures_of_relations 
\exercise.
%%%{{{ meta 
\label unreasonable_properties_for_closures_of_relations
%%%}}}

Por que não falamos de fecho total, irreflexivo, e assimétrico?

\hint
Seja justo.

\solution
Fechando através da totalidade a gente deveria tomar umas decisões
injustas.
Fechando através da irreflexividade a gente deveria retirar setinhas
quando fechando podemos apenas adicionar.
Fechando através da assimetria, a gente deveria retirar setinhas
também e inclusive isso seria numa maneira injusta:
dadas setinhas $(0,1)$ e $(1,0)$ qual das duas tu vai escolher para retirar?

%%}}}

%%{{{ x: order_of_closures_matters 
\exercise.
%%%{{{ meta 
\label order_of_closures_matters
%%%}}}

Seja $R$ relação num conjunto $A$.
Podemos concluir alguma das afirmações seguintes?:
% TODO: fix reflabs
\tlist:
\li (i):   $t(r(R)) \askeq r(t(R))$
\li (ii):  $t(s(R)) \askeq s(t(R))$
\li (iii): $r(s(R)) \askeq s(r(R))$
\endtlist
Aqui $r, s, t$ são os fechos reflexivo, simétrico, transitivo respectivamente.

\hint
Use diagramas internos.

\hint
Tente achar um contraexemplo para o (ii).
Qual a dificuldade de achar contraexemplo para o (i) e qual para o (iii)?

%%}}}

%%{{{ Q: How would you define the reflexive and symmetric closures of R? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias formalmente o fecho reflexivo e o fecho simétrico duma relação $R$?

%%}}}

\spoiler

%%{{{ df: rclosure 
\definition Fecho reflexivo.
%%%{{{ meta 
\label rclosure
\defines
    * \rclo {~R}  -- o fecho reflexivo da $R$
    * \rclosure {~R}  -- o fecho reflexivo da $R$
    * fecho!reflexivo
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos a relação $\rclosure R$ pela
$$
x \rclosure R y \defiff x \rel R y \mlor x = y
$$
Chamamos a $\rclosure R$ o \dterm{fecho reflexivo} da $R$.
Também usamos a notação $\rel {R^=}$.

%%}}}

%%{{{ x: wrong_sclosure_definition 
\exercise.
%%%{{{ meta 
%%%}}}

Alguém definiu o fecho simétrico assim:
\quotepar
<<Seja $R$ relação binária num conjunto $A$.
Seu fecho simétrico é a relação $\sclosure R$ definida pela
$$
x \sclosure R y \pseudodefiff x \rel R y \mland y \rel R x\;\text{.>>}
$$
\endquote
Ache o erro na definição e mostre que a definição realmente é errada.

\hint
Aplique fielmente essa definição na relação do~\ref[symmetric_closure_example].

\hint
Essa definição pode acabar apagando setas!

\solution
Tome a relação $R$ nos $\nats$ com gráfico $\set{(0,1)}$.
Aplicando essa suposta definição da $\sclosure R$ então temos:
$$
x \sclosure R y \iff x \rel R y \mland y \rel R x \iff \False
$$
ou seja, a $x \sclosure R y$ acaba sendo a relação vazia.
Assim acabamos apagando setinhas, algo contra do nosso conceito de fecho!

%%}}}

%%{{{ df: sclosure 
\definition Fecho simétrico.
%%%{{{ meta 
\label sclosure
\defines
    * \sclo {~R}  -- o fecho simétrico da $R$
    * \sclosure {~R}  -- o fecho simétrico da $R$
    * fecho!simétrico
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos a relação $\sclosure R$ pela
$$
x \sclosure R y \defiff x \rel R y \mlor y \rel R x.
$$
Chamamos a $\sclosure R$ o \dterm{fecho simétrico} da $R$.
Também usamos a notação $\rel {R^\leftrightarrow}$.

%%}}}

%%{{{ x: wrong_tclosure_definition 
\exercise.
%%%{{{ meta 
%%%}}}

Alguém definiu o fecho transitivo assim.
\emph{Seja $R$ relação binária num conjunto $A$.
Seu fecho transitivo é a relação $\tclosure R$ definida pela}
$$
x \tclosure R y \pseudodefiff \text{existe $w\in A$ tal que $x \rel R w \mland w \rel R y$}.
$$
Mas isso não é o fecho transitivo da $R$.  O que é mesmo?

\solution
A relação definida é a $R^2$, ou seja, a $R \rcom R$.

%%}}}

%%{{{ Q: How would you define the transitive closures of R? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias formalmente o fecho transitivo duma relação $R$?

%%}}}

\spoiler

%%{{{ df: tclosure 
\definition Fecho transitivo.
%%%{{{ meta 
\label tclosure
\defines
    * \rtclo {~R}      -- o fecho reflexivo-transitivo da $R$
    * \rtclosure {~R}  -- o fecho reflexivo-transitivo da $R$
    * \tclo {~R}       -- o fecho transitivo da $R$
    * \tclosure {~R}   -- o fecho transitivo da $R$
    * fecho!reflexivo-transitivo
    * fecho!transitivo
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos as relações $\tclosure R$ e $\rtclosure R$ pelas
$$
\xalignat2
x \tclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats_{>0}$}.
&&\text{(\dterm{fecho transitivo} da $R$)}\\
x \rtclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats$}
&&\text{(\dterm{fecho reflexivo-transitivo} da $R$)}\\
\endxalignat
$$
Chamamos a $\tclosure R$ o \dterm{fecho transitivo} da $R$,
e a $\rtclosure R$ o \dterm{fecho reflexivo-transitivo} da $R$.
Também usamos as notações $\tclo R$ para o $\tclosure R$
e $\rtclo R$ para o $\rtclosure R$.

%%}}}

%%{{{ x: find_reflexive_transitive_closure_of_pgoesto 
\exercise.
%%%{{{ meta 
\label find_reflexive_transitive_closure_of_pgoesto
%%%}}}

Definimos no $\nats$ a relação binária $\leadsto$ pela:
$$
a\leadsto b \defiff \text{para algum primo $p$, $ap = b$}.
$$
Qual é o seu fecho reflexivo-transitivo?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixamos as definições de outros fechos para os problemas.

%%}}}

%%{{{ x: isPred 
\exercise.
%%%{{{ meta 
\label isPred
%%%}}}

Considere a relação $\to$ no $\nats$, definida pela:
$$
x\to y \defiff x + 1 = y.
$$
Descreva as relações seguintes:
\item{$\transcl{\to}$}: seu fecho transitivo;
\item{$\rtranscl{\to}$}: seu fecho reflexivo-transitivo;
\item{$\rtranscl{\leftrightarrow}$}: seu fecho reflexivo-transitivo-simétrico.
\eop\noi

%%}}}

%%{{{ x: isPred_in_reals 
\exercise.
%%%{{{ meta 
\label isPred_in_reals
%%%}}}

Considere a relação $\to$ definida pela mesma equação como
no~\ref[isPred], mas essa vez no conjunto $\reals$.
Descreva os mesmos fechos.

%%}}}

%%{{{ remark: and_if_we_never_reach_closure 
\remark E se nunca chegar?.
%%%{{{ meta 
\label and_if_we_never_reach_closure
%%%}}}

Esse processo descrito no~\ref[Closure_informal_bottom_up] pode ser
que nunca termina, ou seja esse \wq{até finalmente chegar} que escrevi
lá pode ser que nunca chega mesmo numa relação com a propriedade
desejada.  Por exemplo, considere a $\to$ do~\ref[isPred].
Se pensar que começamos com ela no dia $1$ e que cada dia que passa
adicionamos todas as cetinhas atualmente sendo testemunhas de
falta de transitividade, em qual dia vamos chegar numa relação
transitiva?
\emph{Nunca!}
\emph{E isso seria verdade para um imortal também!}
Mas a idéia descrita no~\reftag[Closure_informal_bottom_up] funcciona
mesmo assim; é só esquecer essa frase de \wq{finalmente chegar}
e entender que pode ser que nunca chegamos numa relação completa,
mas mesmo assim, o processo determina uma relação sim:
para saber se uma setinha $(x,y)$ está no fecho ou não, é só
perguntar se ela vai ``entrar'' um belo dia ou não.

%%}}}

\endsection
%%}}}

%%{{{ Bottom_up_top_down_closures 
\section Bottom-up \vs top-down.
%%%{{{ meta 
\label Bottom_up_top_down_closures
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos fingir para essa discussão que relações são mesmo
os conjuntos das suas setinhas (ou seja, seus gráficos)
pois vai facilitar a fala informal e uma notação conjuntista
que vou usar.  Espero que tu já fez
o~\ref[repeat_after_me_relations_are_not_sets], e logo
tu entenderás bem a discussão seguinte tanto no nível informal
quanto nos detalhes ``verdadeiros'' por trás.  Vamo lá!

%%}}}

\TODO Adicionar desenhos.

%%{{{ top_down_closure 
\note Top-down.
%%%{{{ meta 
\label top_down_closure
%%%}}}

Imagine que para algum motivo gostamos muito duma propriedade de
relações da forma
\standout
\wq{se \emph{algo}, então tem que ter essas certas setinhas}.
\endstandout
(Pense em transitividade como exemplo ``padrão'' aqui.)
Vamos chamar as relações que tem nossa propriedade de \dterm{legais}.
Começamos com um conjunto $A$ uma relação nele $R$ bugada,
possivelmente ilegal.
(Isso quis dizer que não tem a propriedade escolhida.)
Procuramos \emph{a} relação $\overline R$ para chamar
de fecho ``legal'' da $R$; esse fecho deve satisfazer:
\tlist:
\li (L1): $\overline R \supset R$;
\li (L2): $\overline R$ é legal;
\endtlist
e deve ser ``a melhor'' entre todas as relações $L$ que
satisfazem ambas essas condições.
Mas o que significa \emph{melhor}, e o que nos faz acreditar
que existe \emph{a} melhor?
Aqui melhor quis dizer que a $\overline R$ deve ser \emph{fiel}
na $R$, no sentido de não conter setas desnecessárias, setas
não fornecidas/necessidadas por causa da relação original $R$.
Como vamos descobrir, tal $\overline R$ existe mesmo, e vamos
definí-la numa maneira extremamente elegante e legal!
\eop
A primeira coisa importante para perceber é que
\emph{já sabemos que pelo menos uma relação satisfaz ambas as
condições (L1)--(L2) acima:} a relação cheia, trivial $\True$
do $A$.  Vamos chamá-la de $G$---pense ``Grande''.
Com certeza $G \supset R$, pois como poderia não ser?
$G$ é a relação cheia, ela tem todas as setinhas, então
com certeza as setinhas da $R$ também.
Pelo mesmo motivo e pela natureza da própria propriedade
temos certeza que $G$ também goza da (L2): ela é legal.
\eop
Bem, temos uma candidata; mas estamos procurando a melhor,
pois essa pode ter \dterm{lixo}.  Procuramos uma maneira
de jogar fora todo o lixo da $G$.
\eop
Uma idéia ruim para conseguir isso seria seguinte:
pega uma setinha $\alpha$ do $G\setminus R$ e veja se removendo
essa $\alpha$, tu quebras a ``legaldade''.
Qual o problema com essa abordagem?
Bem: vai que tu pegou uma setinha e que observou
que ela não pode ser jogada fora, pois duas outras setinhas
estão a obrigando ficar mesmo.
Mas, por que confiar nessas outras setinhas?
Talvez elas mesmas também fazem parte do lixo, e deveriam ser jogadas
foras também.  Mas então, como escolher onde começar a investigação?
Hah!  Nem vamos escolher nenhum canto para começar, pois nem vamos
começar investigar nada disso!  Vamos usar uma maneira bem simples
e jogar todo o lixo fora num instante só!
\eop
Vamos definir a colecção de todos os candidatos:
$$
\scr L_R \defeq
\setst {L : \reltype{A,A}} {L \supset R \mland \text{$L$ é legal}}.
$$
Primeiramente observe que sabemos que essa colecção não é vazia,
pois se fosse a gente teria um problema grande---tu vai entender logo qual.
Realmente, a $G$ é uma das candidatas, então $G \in \scr L_R$ e logo
$\scr L_R \neq \emptyset$.
Agora observe que cada candidato $L \in \scr L_R$ satisfaz
$$
G \supset L \supset R.
$$
Ambas são imediates pela definição do $\scr L_R$.
Tem então dois casos extremos (onde $L$ é uma das $G,R$) mas no caso
geral $L$ fica estritamente entre as relações $G$ e $R$.
Estamos finalmente prontos para a definição linda que prometi,
que vai acabar com todo o lixo:
\eop
$$
\overline R \defeq \Inter \scr L_R.
$$
Afirmo que:
% TODO: fix reflabs
\tlist:
\li (1): $\overline R \supset R$;
\li (2): $\overline R$ é legal;
\li (3): $\overline R$ é a melhor: não tem lixo nenhum.
\endtlist
Antes de demonstrar esses pontos, primeiramente quero te preocupar
com uma outra perguta:

%%}}}

%%{{{ Q: How do you know that the arrow you deleted is not needed? 
\question.
%%%{{{ meta 
%%%}}}

Alguém poderia reclamar que certas das setinhas que foram jogadas
fora nesse processo, por exemplo essa aqui abaixo, foram injustamente
tiradas, e talvez eram essenciais, ou seja, necessárias mesmo para
a legaldade da relação.  O que responderias?  Como podemos convencer
essa pessoa que a setinha não foi realmente necessária?

%%}}}

\spoiler

%%{{{ A 
\note Resposta.
%%%{{{ meta 
%%%}}}

Observe que essa setinha pertence a uma das candidatas do $\scr L_R$,
mas tem outras candidatas que não têm essa setinha nelas e mesmo assim
conseguem ser legais!  Ou seja, com certeza essa setinha não pode ser
necessária mesmo para a legaldade da relação que estamos procurando!

%%}}}

%%{{{ What's missing? 
\note O que falta?.
%%%{{{ meta 
%%%}}}

Basta demonstrar as (1)--(3) agora.
A primeira \emph{deve ser óbvia} para o leitor que já passou pelo~\ref[Sets]
(até se ele pulou---foi sem querer né?---o~\ref[Inter_of_supsets_supset],
que é exatamente isso).
As outras duas, tu demonstrarás agora:

%%}}}

%%{{{ x: top_down_closure_prove_2 
\exercise.
%%%{{{ meta 
\label top_down_closure_prove_2
%%%}}}

Demonstre a (2) do~\ref[top_down_closure]

%%}}}

%%{{{ x: top_down_closure_prove_3 
\exercise.
%%%{{{ meta 
\label top_down_closure_prove_3
%%%}}}

Demonstre a (3) do~\ref[top_down_closure]

%%}}}

%%{{{ bottom_up_closure 
\note Bottom-up.
%%%{{{ meta 
%%%}}}

\TODO Descrever como imortal construtor por dia.

%%}}}

%%{{{ Always coincide? 
\note Sempre concordam?.
%%%{{{ meta 
%%%}}}

Tem situações onde a definição bottom-up e definição top-down discordam!
Isso pode acontecer, por exemplo, quando o ``imortal'' construindo na
maneira bottom-up necessitaria uma infinidade
\emph{mais longa que a largura dos naturais}---e se essa frase
não fez nenhum sentido agora, tranqüilo, não era pra fazer:
volte a relê-la depois de ter estudado \emph{aritmética ordinal}
no~\ref[Ordinal_arithmetic].

%%}}}

\endsection
%%}}}

%%{{{ Order relations 
\section Relações de ordem.
%%%{{{ meta 
\label Order_relations
%%%}}}

%%{{{ df: order_relation 
\definition Ordem.
%%%{{{ meta 
\label order_relation
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem parcial} sse ela é reflexiva, transitiva, e antissimétrica.
Se ela também é total, a chamamos de \dterm{ordem total}.

%%}}}

%%{{{ beware: total-partial default, relations vs functions 
\beware.
%%%{{{ meta 
%%%}}}

Quando usamos apenas o termo \emph{ordem}, entendemos como \emph{ordem parcial}.
Observe que esta convenção é a oposta que seguimos nas funcções, onde um pleno
\emph{funcção} quis dizer \emph{funcção total}.

%%}}}

%%{{{ eg: subset and supset are orders 
\example.
%%%{{{ meta 
%%%}}}

Dado qualquer conjunto $X$, seus subconjuntos
são parcialmente ordenados tanto por $\subset$
quanto por $\supset$.

%%}}}

%%{{{ eg: common orders are orders 
\example.
%%%{{{ meta 
%%%}}}

As $\leq$ e $\geq$ comuns são ordens totais nos $\nats,\ints,\rats,\reals$.

%%}}}

%%{{{ divides_is_not_an_order_on_ints 
\exercise.
%%%{{{ meta 
\label divides_is_not_an_order_on_ints
%%%}}}

A relação $\divides$ nos inteiros é uma relação de ordem?

\hint
O que podemos concluir se $a \divides b$ e $b \divides a$?

%%}}}

%%{{{ divides_is_a_partial_order_on_nats 
\example.
%%%{{{ meta 
%%%}}}

A relação $\divides$ no $\nats$ é uma ordem parcial.
(Provaste isso no~\ref[divides_is_almost_a_partial_order].)

%%}}}

%%{{{ df: strict_order 
\definition Ordem estrita.
%%%{{{ meta 
\label strict_order
\defines
    * ordem!estrita
    ;;
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem estrita} sse ela é irreflexiva, transitiva, e assimétrica.
Se ela também é tricotômica, chamamos-la \dterm{ordem estrita total}.

%%}}}

%%{{{ remark: default adjective 
\remark Adjectivo implícito.
%%%{{{ meta 
\defines
    * ordem!fraca
    ;;
%%%}}}

Quando queremos enfatizar que uma relação é uma ordem e não uma ordem estrita,
usamos o termo \dterm{fraca}.  Similarmente com as funcções (totais \vs parciais),
Dependendo do contexto o \emph{adjectivo implícito} pode mudar.
Quando focamos em ordens estritas, ``ordem'' vira sinônimo de ``ordem estrita''
e precisamos o adjectivo ``fraca'' para referir a uma ordem (fraca).

%%}}}

%%{{{ x: weak_fromto_strong_orders 
\exercise De fraca para estrita; ida e volta.
%%%{{{ meta 
\label weak_fromto_strong_orders
%%%}}}

(1)
Seja $\leq$ ordem num conjunto $A$.
Defina a relação $<$ no $A$ pela:
$$
x < y \defiff x \leq y \mland x \neq y.
$$
Demonstre que $<$ é uma ordem estrita.
\eop\noi
(2)
Seja $<$ ordem estrita num conjunto $A$, e
defina a relação $\leq$ no $A$ pela:
$$
x \leq y \defiff x < y \mlor x = y.
$$
Demonstre que $\leq$ é uma ordem.

%%}}}

%%{{{ df: preorder_relation 
\definition Preordem.
%%%{{{ meta 
\label preorder_relation
\indexes
    * quasiordem    see: preordem
    ;;
\defines
    * preordem
    ;;
%%%}}}

Uma relação binária $R$ num conjunto $A$ é chamada \dterm{preordem} (ou \dterm{quasiordem}) sse ela é reflexiva e transitiva.

%%}}}

%%{{{ eg: divides_is_a_preorder_on_ints 
\example.
%%%{{{ meta 
\label divides_is_a_preorder_on_ints
%%%}}}

Como provamos no~\ref[divides_is_almost_a_partial_order],
a relação $\divides$ nos inteiros é uma preordem.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No~\ref[why_called_preorder] tu vai justificar o nome ``preordem'',
mostrando que cada preordem $R$ fornece uma ordem $R'$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Paramos \emph{por enquanto} o estudo de relações de ordem;
pois voltaremos a estudá-las depois (capítulos~\reftag[Posets_Lattices],
\reftag[Wosets_Ordinals], e~\reftag[Denotational_semantics]).

%%}}}

\endsection
%%}}}

%%{{{ Equivalence relations 
\section Relações de equivalência.
%%%{{{ meta 
\label Equivalence_relations
%%%}}}

%%{{{ idea_of_equivalence 
\note Equivalência.
%%%{{{ meta 
\label idea_of_equivalence
%%%}}}

Considere um conjunto $A$, onde queremos ``identificar'' certos elementos deles,
talvez porque ligamos apenas sobre uma propriedade, e queremos ignorar os
detalhes irrelevantes que nos obrigariam distinguir uns deles.
Por exemplo, se $A$ é um conjunto de pessoas, podemos focar apenas na
``nacionalidade''.  Esquecendo todos os outros detalhes então, vamos
considerar todos os copatriotas como se fossem ``iguais'':
o termo certo é \dterm{equivalentes}.
Outra propriedade poderia ter sido o ano que cada pessoa nasceu,
ou o primeiro nome, ou até quem é a mãe de cada pessoa.
Queremos identificar as propriedades que uma relação desse tipo tem que ter:
\item{(i)} Reflexividade: não importa qual foi o critério que escolhemos
para ``equivaler'' os objetos, cada objeto com certeza vai ``concordar''
com ele mesmo nesse critério.
\item{(ii)} Transitividade:
se $a$ e $b$ concordam no assunto escolhido, e $b$ e $c$ também,
com certeza $a$ e $c$ devem concordar também.
\item{(iii)} Simetría: pela natureza da nossa intuição é claro que
para decidir se dois elementos serão equivalentes ou não, não precisamos
considerá-los numa ordem específica.
\eop
\noi Chegamos assim na definição seguinte:

%%}}}

%%{{{ df: equivalence_relation 
\definition.
%%%{{{ meta 
\label equivalence_relation
\defines
    * relação!de equivalência
    ;;
%%%}}}

Seja $A$ conjunto e $\sim$ uma relação binária no $A$.
Chamamos $\sim$ uma \dterm{relação de equivalência} sse ela é
reflexiva, simétrica, e transitiva.
Definimos também o
$$
\eqrelspace A \defeq \setstt {R \in \relspace{A,A}} {$R$ é uma relação de equivalência}.
$$

%%}}}

%%{{{ eg: eqrel_eg_eq 
\example.
%%%{{{ meta 
\label eqrel_eg_eq
%%%}}}

A $=$ é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_parity 
\example.
%%%{{{ meta 
\label eqrel_eg_parity
%%%}}}

A relação $\sim_2$ que relaciona exatamente os inteiros com a mesma paridade
$$
x \sim_2 y \defiff \text{ambos os $x,y$ são pares ou ambos os $x,y$ são ímpares}.
$$
Essa relação de equivalência é um caso especial da próxima.

%%}}}

%%{{{ x: congruence_mod_m_is_an_eqrel_again 
\exercise.
%%%{{{ meta 
\label congruence_mod_m_is_an_eqrel_again
%%%}}}

Seja $m\in\nats$.
Demonstre que a relação binária nos inteiros definida pela
$$
a \congmod m b \defiff a \cong b \pmod m
$$
é uma relação de equivalência.

\solution
Esqueceu o~\ref[congruence_mod_m_is_an_eqrel]?

%%}}}

%%{{{ eg: eqrel_eg_countries 
\example.
%%%{{{ meta 
\label eqrel_eg_countries
%%%}}}

Em qualquer conjunto $P$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_children 
\example.
%%%{{{ meta 
\label eqrel_eg_children
%%%}}}

No conjunto $\pers$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_teams 
\example.
%%%{{{ meta 
\label eqrel_eg_teams
%%%}}}

No conjunto $\cal B$ de jogadores profissionais de basquete,
a relação
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
é uma relação de equivalência.

%%}}}

%%{{{ noneg: eqrel_noneg_food
\nonexample.
%%%{{{ meta 
\label eqrel_noneg_food
%%%}}}

Num conjunto $\pers$ de pessoas, a relação
$$
x \sim y \defiff \text{existe comida que $x$ e $y$ ambos comeram hoje}
$$
não é sempre uma relação de equivalência.

%%}}}

%%{{{ x: why not? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\hint
Não é necessariamente nem reflexiva nem transitiva.
Invente um contraexemplo para cada propriedade.

%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_plane 
\example.
%%%{{{ meta 
\label equivalent_relations_on_euclidean_plane
%%%}}}

No $\reals^2$ considere as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Facilmente todas são relações de equivalência.

%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_space 
\example.
%%%{{{ meta 
\label equivalent_relations_on_euclidean_space
%%%}}}

No $\reals^3$ considere as relações:
$$
\align
\tup{x,y,z} \sim_3 \tup{x',y',z'}
&\iff z = z'\\
\tup{x,y,z} \sim_{1,2} \tup{x',y',z'}
&\iff x = x' \mland y = y' \\
\tup{x,y,z} \sim_{\textrm N} \tup{x',y',z'}
&\iff \norm{ \tup{x,y,z} } = \norm{ \tup{x',y',z'} }
\endalign
$$
Facilmente todas são relações de equivalência.

%%}}}

%%{{{ x: cannot replace and with or 
\exercise.
%%%{{{ meta 
%%%}}}

Mudamos o ``e'' para ``ou'' na segunda relação
do~\ref[equivalent_relations_on_euclidean_space]:
$$
\tup{x,y,z} \sim \tup{x',y',z'} \iff x = x' \mlor y = y'
$$
A $\sim$ é uma relação de equivalência?

\hint
Ache um contraexemplo que refuta sua transitividade.

\solution
Não, pois não é transitiva.
Tome os
$\tup{0,0,0}$,
$\tup{0,1,0}$, e
$\tup{2,1,0}$.
Observe que
$$
\tup{0,0,0}
\sim
\tup{0,1,0}
\mland
\tup{0,1,0}
\sim
\tup{2,1,0}
$$
mas $\tup{0,0,0} \not\sim \tup{2,1,0}$.

%%}}}

%%{{{ x: guaranteed_eqrels 
\exercise.
%%%{{{ meta 
\label guaranteed_eqrels
%%%}}}

Seja $A$ um conjunto qualquer.
Quais relações de equivalência podes já definir nele,
sem saber absolutamente nada sobre seus elementos?

\solution
A identidade $\eqof A$, a trivial $\True$, e a vazia $\False$.

%%}}}

%%{{{ x: how_many_equivalence_relations_on_3 
\exercise.
%%%{{{ meta 
\label how_many_equivalence_relations_on_3
%%%}}}

Seja $A$ conjunto com $\card A = 3$.
Quantas relações de equivalência podemos definir no $A$?

\hint
Deixe para responder junto com o~\ref[how_many_partitions_on_3].

\solution
Encontramos a resposta dessa pergunta no~\ref[how_many_partitions_on_3].

%%}}}

%%{{{ x: equivalent_properties_to_eqrel 
\exercise.
%%%{{{ meta 
\label equivalent_properties_to_eqrel
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
O.s.s.e.:
\item{(i)}   $R$ é uma relação de equivalência;
\item{(ii)}  $R$ é reflexiva e circular;
\item{(iii)} $R$ é reflexiva e left-euclideana;
\item{(iv)}  $R$ é reflexiva e right-euclideana.

%%}}}

%%{{{ x: distance_like_not_transitive 
\exercise.
%%%{{{ meta 
\label distance_like_not_transitive
%%%}}}

Seja real $\epsilon\in(0,1)$, e defina a relação $\approx_\epsilon$:
$$
x \approx_\epsilon y \defiff (x-y)^2 < \epsilon.
$$
A $\approx_\epsilon$ é uma relação de equivalência?

\hint
Primeiramente resolve o mesmo problema mas para a relação:
$$
x \sim_\epsilon y \defiff |x-y| < \epsilon
$$
onde $\epsilon > 0$.

\hint
Reflexividade e simetria das $\sim_\epsilon$ e $\approx_\epsilon$ são imediatas.
Sobre a transitividade, um desenho na linha real ajudaria.

\hint
Como contraexemplo, tome os reais $0$, $\epsilon/2$, e $\epsilon$ e
observe que $0 \sim_\epsilon \epsilon/2$ e $\epsilon/2 \sim_\epsilon \epsilon$
mas mesmo assim não temos $0\sim_\epsilon \epsilon$.

\hint
Como podes usar a não-transitividade da $\sim_\epsilon$
para deduzir a não-transi\-tivi\-dade da $\approx_\epsilon$?

\hint
Para todo $\alpha\in\reals_{\geq 0}$ temos:
$$
\cdots
\iff
\sqrt{\alpha}\in(0,1)
\iff
\alpha\in(0,1)
\iff
\alpha^2\in(0,1)
\iff
\cdots
$$

\solution
Não é.  Uma resolução já foi rescunhada nas dicas.
Para um contraexemplo direto, pode tomar os reais
$0$, $\sqrt \epsilon / 2$, e $\sqrt \epsilon$.
Observe que $0 \approx_\epsilon \sqrt \epsilon / 2$
e $\sqrt \epsilon / 2 \approx_\epsilon \sqrt \epsilon$
mas não temos $0 \approx_\epsilon \sqrt \epsilon$.

%%}}}

%%{{{ df: equivalent_class 
\definition.
%%%{{{ meta 
\label equivalent_class
\defines
    * \eqclass {~a} {~R}  -- a classe de equivalência do $a$ através da $R$
    * \eqclassimp {~a}  -- a classe de equivalência do $a$ (relação implícita pelo contexto)
    * classe de equivalência
    ;;
%%%}}}

Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Para cada $a\in A$, definimos a \dterm{classe de equivalência do} $a$
como o conjunto de todos os membros de $A$ que $\sim$-relacionam com o $a$.
Formalmente definimos
$$
\eqclass a {\sim} \defeq \setst {x\in A} {x\sim a}.
$$
Às vezes aparece também a notação $\eqclassalt a \sim$.
Quando a relação de equivalência é implicita pelo contexto
denotamos a $\eqclass a \sim$ apenas por $\eqclassimp a$.

%%}}}

%%{{{ x: type_of_eqclass_hole 
\exercise.
%%%{{{ meta 
\label type_of_eqclass_hole
%%%}}}

Sejam $A$ conjunto, $a\in A$, e $\sim$ relação de equivalência no $A$.
Considere as funcções seguintes definidas com buracos:
$$
\xalignat3
\eqclass {\dhole} {\sim}   &: \ \askdots &
\eqclass {a} {\dhole}      &: \ \askdots &
\eqclass {\dhole} {\dhole} &: \ \askdots
\endxalignat
$$
Escreva tipos válidos para essas funcções.

\solution
Escrevemos os tipos:
$$
\align
\eqclass {\dhole} {\sim}   &: A \to \pset A \\
\eqclass {a} {\dhole}      &: E \to \pset A \\
\eqclass {\dhole} {\dhole} &: \paren{A \cross \eqreltype A} \to \pset A.
\endalign
$$

%%}}}

%%{{{ x: equivalent_statements_to_x_equiv_y 
\exercise.
%%%{{{ meta 
\label equivalent_statements_to_x_equiv_y
%%%}}}

Sejam $\sim$ uma relação de equivalência num conjunto $X$, e $a,b\in X$.
Mostre que as afirmações seguintes são equivalentes:
\item{(i)} $a\sim b$;
\item{(ii)} $\eqclassimp a = \eqclassimp b$;
\item{(iii)} $\eqclassimp a \inter \eqclassimp b \neq \emptyset$.

\solution
\proofpart{Vamos demonstrar primeiro a {\rm ((i)\tiff(iii))}.}
\crtabproofpart{\lrdir.}
Suponha que $a \sim b$.
Precisamos achar um elemento que pertence nos dois conjuntos
$\eqclassimp a$ e $\eqclassimp b$.
Tome o próprio $a$.
Temos $a\in \eqclassimp a$ pois $a \sim a$ (pela reflexividade da $\sim$).
Também temos $a \in \eqclassimp b$, pois $a \sim b$ (hipótese).
Logo $a \in \eqclassimp a \inter \eqclassimp b\neq\emptyset$.
\crtabproofpart{\rldir.}
Suponha que $\eqclassimp a\inter\eqclassimp b \neq \emptyset$
e tome $w \in \eqclassimp a\inter\eqclassimp b$.
Logo $w \in \eqclassimp a$ e $w \in \eqclassimp b$,
ou seja $w \sim a$ e $w \sim b$ pela definição de classe de equivalência.
Pela simetría da $\sim$ temos $a \sim w$.
Agora como $a\sim w$ e $w \sim b$, pela transitividade da $\sim$ ganhamos
o desejado $a \sim b$.
\crproofpart{Agora vamos demonstrar a {\rm ((i)\tiff(ii))}.}
\crtabproofpart{\lrdir.}
Suponha que $a \sim b$.
Tome $x\in \eqclassimp a$.
Logo $x \sim a$.
Mas $a \sim b$ e logo pela transitividade da $\sim$ temos $x \sim b$,
e logo $x \in \eqclassimp b$.
\crtabproofpart{\rldir.}
Suponha que $\eqclassimp a = \eqclassimp b$.
Pela reflexividade da $\sim$, sabemos que $a\in\eqclassimp a$.
Logo $a\in\eqclassimp b$, e logo $a\sim b$ pela definição de $\eqclassimp b$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: preorders_are_idempotent 
\problem.
%%%{{{ meta 
\label preorders_are_idempotent
%%%}}}

Seja $R$ uma preordem num conjunto $A$.
Demonstre que $R$ é \dterm{idempotente}, ou seja, $R = R \rcom R$.

\solution
\def\R{\rel R}%
\def\RR{\rel {(R \rcom R)}}%
Vamos demonstrar as duas direções separadamente.
\crproofpart{$x \R y \implies x \RR y$:}
Suponha $x \R y$.
Como $\R$ é reflexiva, logo $x \R x$.
Pelas $x \R x$ e $x \R y$ concluimos que $x \RR y$.
\crproofpart{$x \RR y \implies x \R y$:}
Suponha $x \RR y$.
Logo $x \R w$ e $w \R y$ para algum $w \in A$ (pela def.~de $\rcom$),
e logo pela transitividade da $\R$ temos $x \R y$.

%%}}}

%%{{{ prob: when_is_rop_irreflexive 
\problem.
%%%{{{ meta 
\label when_is_rop_irreflexive
%%%}}}

Seja $S$ uma relação binária num conjunto $A$ tal que
$$
\text{$\relp{S \rcom {\rop S}}$ é irreflexiva}.
$$
Qual é o gráfico da $S$?
Demonstre tua resposta.

\hint
Supondo que $x \rel S y$, o que tu consegues concluir?

\solution
$\graph(S) = \emptyset$.
\eop
Pois, supondo que tem membros, tome $(x,y) \in \graph(S)$, e agora:
$x \rel S y$ e logo $y \rop S x$ (pela def.~de $\rop S$).
Logo $x \relp{S \rcom {\rop S}} x$, que contradiza
a irreflexividade da $S \rcom {\rop S}$.

%%}}}

%%{{{ prob: rcom_does_not_respect_transitivity 
\problem.
%%%{{{ meta 
\label rcom_does_not_respect_transitivity
%%%}}}

Sejam $R,S$ relações binárias e transitivas no $A$.
Podemos concluir que $R \rcom S$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.  Para achar um contraexemplo desenha as
setinhas das relações envolvidas para construir
os desejados $x,y,z$.

%%}}}

%%{{{ prob: rop_iter_R_eq_iter_rop_R 
\problem.
%%%{{{ meta 
\label rop_iter_R_eq_iter_rop_R
%%%}}}

Seja $R:\reltype{X,X}$.
Demonstre que para todo $n\in\nats$,
$$
\ropp{R^n} = \paren{\rop R}^n.
$$

\hint
Indução.

\solution
Por indução.
\crproofpart{Base.}
Calculamos:
\compute
\ropp{R^0}
&= \ropp{\eqof X}     \by {def.~$R^0$} \\
&= (\eqof X)          \by {pelo~\ref[rop_of_symmetric]} \\
&= \paren{\rop R}^0.  \by {def.~$\paren{\rop R}^0$} \\
\endcompute
\crproofpart{Passo indutivo.}
Seja $k\in\nats$ tal que $\ropp{R^k} = \paren{\rop R}^k$\fact{HI}.
Calculamos:
\compute
\ropp{R^{k+1}}
&=\ropp{R R^k}              \by {def.~$R^{k+1}$} \\
&=\ropp{R^k R}              \by {Lemma} \\
&=\rop R \ropp{R^k}         \by {\ref[rop_of_rcompose]} \\
&=\rop R \paren{\rop R}^k   \by {HI} \\
&=\paren{\rop R}^{k+1}      \by {def.~$R^{k+1}$} \\
\endcompute
Onde devemos demonstrar o Lemma:
{\proclaimstyle
para todo $t\in\nats$, $R^t R = R R^t$.}
\crproofpart{Demonstração do Lemma.}
Por indução.
\crproofpart{Base: $R^0 R \askeq R R^0$.}
Imediato pois $R^0 = (\eqof X)$ e $\eqof X$ é uma $\rcom$-identidade (\ref[id_of_rcom]).
\crproofpart{Passo indutivo.}
Seja $w \in \nats$ tal que $R^w R = R R^w$\fact{HI}.
Calculamos:
\compute
R^{w+1} R
&= (R^w R) R  \by {def.~$R^{w+1}$} \\
&= (R R^w) R  \by {HI} \\
&= R (R^w R)  \by {assoc.~$\rcom$ (\reftag[associativity_of_rcom])} \\
&= R (R R^w)  \by {HI} \\
&= R R^{w+1}. \by {def.~$R^{w+1}$} \\
\endcompute

%%}}}

%%{{{ prob: condorcet_paradox 
\problem O paradoxo de Condorcet.
%%%{{{ meta 
\label condorcet_paradox
\credits
    * Condorcet : paradoxo
    ;;
\indexes
    * paradoxo!de Condorcet
    ;;
%%%}}}

Seja $P\neq\emptyset$ um conjunto de pessoas e
$C\neq\emptyset$ um conjunto de candidatos.
Seja $\gtrdot$ a relação binária no $C$ definida pela
$$
x \gtrdot y \defiff \text{a maioria da população do $P$ prefere $x$ do que $y$}.
$$
Podemos concluir que $\gtrdot$ é transitiva?
Responde ``sim'' e demonstre; ou ``não'' e mostre um contraexemplo.

\hint
Já jogou ``pedra--papel--tesoura''?

\solution
Não.  Sejam $P = \set{p,q,r}$ e $C = \set{a,b,c}$.
Considere que as pessoas do $P$ em ordem de preferência de melhor para pior têm:
$$
\align
    p:\ & a, b, c \\
    q:\ & c, a, b \\
    r:\ & b, c, a.
\endalign
$$
Assim temos:
$$
\alignat2
a &\gtrdot b, \by {pois os $p,q$ preferem $a$ que $b$} \\
b &\gtrdot c, \by {pois os $p,r$ preferem $b$ que $c$} \\
\endalignat
$$
mas $a \smartnot\gtrdot c$ pois apenas o $p$ prefere $a$ que $c$.
De fato, $c \gtrdot a$, pois os $q,r$ preferem $c$ que $a$.

%%}}}

%%{{{ prob: dom_trans_cod_not_trans 
\problem.
%%%{{{ meta 
\label dom_trans_cod_not_trans
%%%}}}

Sejam $A \toby f B$ e $\leadsto$ uma relação transitiva no $A$.
Definimos a relação $R$ no $B$ pela
$$
b \rel R b'
\defiff
\text{existem $a, a' \in A$ tais que $f(a) = b$, $f(a') = b'$, e $a \leadsto a'$}.
$$
Podemos concluir que $R$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.

\hint
A $f$ não é necessariamente injetora.

\solution
Não, e vamos ver um contraexemplo.
Considere:
$$
\align
A &= \set{1,2,3,4} \\
B &= \set{5,6,7}
\endalign
$$
e a $\leadsto$ relacionando apenas os:
$$
\align
1 &\leadsto 2 \\
3 &\leadsto 4.
\endalign
$$
Defina a $f:A\to B$ pelas
$$
\align
1 &\mapstoby f 5 \\
2 &\mapstoby f 6 \\
3 &\mapstoby f 6 \\
4 &\mapstoby f 7.
\endalign
$$
Primeiramente observe que realmente $\leadsto$ é transitiva.
Vamos verificar que: $5 \rel R 6$ e $6 \rel R 7$ mas mesmo assim
$5 \not\rel R 7$.
Os testemunhos de $5 \rel R 6$ são os $1$ e $2$; e
os testemunhos de $6 \rel R 7$ são os $3$ e $4$.
Mas os únicos candidados para testemunhos de $5 \rel R 7$
são os $1$ e $4$, e $1 \not\leadsto 4$; e logo $5 \not\rel R 7$.

%%}}}

%%{{{ prob: dom_trans_cod_trans_if_inj 
\problem.
%%%{{{ meta 
\label dom_trans_cod_trans_if_inj
%%%}}}

O que muda no~\ref[dom_trans_cod_not_trans] se
adicionar a hipótese que $f$ é injetora?
Demonstre tua afirmação.

%%}}}

%%{{{ prob: explain_succ_rel 
\problem.
%%%{{{ meta 
\label explain_succ_rel
%%%}}}

Seja a relação $\to$ no $\nats$ definida pela
$$
a \to b \defiff a + 1 = b.
$$
Dê uma definição simples da relação $\to^n$ para quem não sabe
nem de iterações nem de composições de relações (e sequer quer aprender essas noções).
Demonstre tua afirmação, que a relação $\to^n$ é igual à relação que tu definiu.

\hint
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Agora demonstre que isso é válido para todo $a,b,n\in\nats$.

\solution
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Sejam $a,b\in\nats$.
Vou demonstrar por indução que para todo $n\in\nats$,
$$
a \ton n b  \iff  a + n = b.
$$
\proofpart{Base.}
Temos
\compute
a \ton 0 b
&\iff a = b \by {pela def.~$\ton 0$} \\
&\iff a + 0 = b.
\intertext{
\proofpart{Passo Indutivo.}
Seja $k\in\nats$ tal que
}
a \ton k b &\ifflabel {HI} a + k = b.
\intertext{Calculamos:}
a \ton {k+1} b
&\iff a \rel{(\ton k\rcom\to)} b              \by {def.~$\ton{k+1}$} \\
&\iff \lexists w {a \ton k w \mland w \to b}  \by {def.~$\rcom$} \\
&\iff \lexists w {a + k = w \mland w + 1 = b} \by {HI; def.~de~$\to$} \\
&\iff {(a + k) + 1 = b} \\
&\iff {a + (k + 1) = b}.
\endcompute

%%}}}

%%{{{ prob: agree_on_at_least_half_relation 
\problem.
%%%{{{ meta 
%%%}}}

Sejam conjunto $A$ com $\card A>2$, e $n$ inteiro par positivo.
No $A^n$ defina:
$$
a \sim b
\defiff
\card{ \setst {i\in\finord n} {a_i = b_i} } \geq n/2,
$$
onde
$a \eqass \tup{ a_0, \dotsc, a_{n-1}}$
e
$b \eqass \tup{ b_0, \dotsc, b_{n-1}}$.
A $\sim$ é uma relação de equivalência?

\solution
Não é.
Sejam $s,t,u\in A$ distintos dois-a-dois.
Tome
$$
\align
a &\leteq \tup{ s,s,\dots,s,t,t,\dotsc,t }\\
b &\leteq \tup{ s,s,\dots,s,u,u,\dotsc,u }\\
c &\leteq \tup{ t,t,\dots,t,u,u,\dotsc,u }
\endalign
$$
como contraexemplo, pois temos
$a \sim b$ e $b \sim c$ mas $a\not\sim c$.

%%}}}

%%{{{ prob: simh_simv_apph_appv 
\problem.
%%%{{{ meta 
\label simh_simv_apph_appv
\pdefs
    \pdef apph {\mathrel{\approx}}
    \pdef appv {\mathrel{\wr\mkern-1mu\wr}}
    \pdef simh {\mathrel{\sim}}
    \pdef simv {\mathrel{\wr}}
    ;;
%%%}}}

Considere as relações seguintes no $(\ints\to\ints)$:
$$
\align
f \simh g &\defiff \pexists {u\in\ints} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \apph g &\defiff \pexists {u\in\nats} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \simv g &\defiff \pexists {u\in\ints} \lforall {x \in\ints} {f(x) = g(x)+u } \\
f \appv g &\defiff \pexists {u\in\nats} \lforall {x \in\ints} {f(x) = g(x)+u }.
\endalign
$$
Para cada uma dessas relações, decida se é:
(ir)reflexiva; transitiva; (a(nti)s)simétrica.

\hint
Primeiramente tente entender (visualizar) essas relações.

\solution
Primeiramente tentamos entender essas relações bem informalmente.
As $\simh$ e $\apph$ envolvem um movimento horizontal,
e as $\simv$ e $\appv$ um movimento vertical.
Especificamente $f \simh g$ [$f \simv g$]
sse $f$ e $g$ são a mesma funcção depois de um ``shift'' horizontal
[vertical] para qualquer direção.
As $\apph$ e $\appv$ são parecidas so que $f \apph g$
[$f \appv g$] sse a $f$ ``coincide'' com a $g$ depois de um
``shift'' da $f$ para a direita [para baixo] $0$ ou mais ``posições''.
\eop\medskip
\crtabproofpart{Reflexividade.}
Todas são reflexivas, algo que mostramos tomando $u \asseq 0$.
Vamos ver em detalhe apenas para a $\simh$.
\crproofpart{Reflexividade da $\apph$.}
\eop\noi
    Seja $f : \ints\to\ints$.
    Temos para todo $x\in \ints$, $f(x) = f(x + 0)$, e como $0\in\nats$,
    logo $f\apph f$.
\eop\medskip
\crtabproofpart{Transitividade.}
Todas são transitivas, e parecida em todas:
usando nossas hipoteses ganhamos dois números $i,j$ e o número que procuramos
acaba sendo o $i + j$.
Vamos ver em detalhe apenas para a $\appv$:
\crproofpart{Transitividade da $\appv$.}
\eop\noi
    Sejam $f,g,h: \ints\to\ints$ tais que $f\simh g$ e $g\simh h$.
    Sejam então $i,j\in\ints$ tais que:
    $$
    \align
    \text{para todo $x\in \ints$, }&f(x) = g(x+i) \tag{1} \\
    \text{para todo $x\in \ints$, }&g(x) = h(x+j).\tag{2}
    \endalign
    $$
    Seja $z\in\ints$ e calcule:
    \compute
    f(z)
    &= g(z+i)       \by {pela (1) com $x \asseq z$} \\
    &= h((z+i)+j)   \by {pela (2) com $x \asseq z+i$} \\
    &= h(z+(i+j)).
    \endcompute
    Ou seja, o inteiro $i+j$ mostra que $f\simh h$.
Já provamos então que todas essas relações são preordens!
Vamos pesquisar sobre as outras propriedades agora.
\eop\medskip
\crtabproofpart{(A(nti)s)simetria.}
As $\simh$ e $\simv$ são simétricas, algo que mostramos para as
duas no mesmo jeito: nossa hipótese fornece um $i\in\ints$
que satisfaz algo, e o inteiro que procuramos acaba sendo o $-i$.
As $\appv$ é antissimétrica, mas a $\apph$ não satisfaz nenhuma
dessas propriedades.
Vamos demonstrar a simetria da $\simh$, a antissimetria da $\appv$,
e refutar a simetria e a antissimetria da $\apph$.
\crproofpart{Simetria da $\simh$.}
\eop\noi
    Sejam $f,g : \ints\to\ints$ tais que $f\simh g$.
    Então seja $i\in\ints$ tal que
    para todo $x\in \ints$, $f(x) = g(x+i)$\fact1.
    Observe que para todo $x\in\ints$, temos:
    \compute
    g(x)
    &= g(x+(i-i)) \\
    &= g((x-i)+i) \\
    &= f(x-i).    \by {pela~\byfact1~com $x\asseq x-i$} \\
    \endcompute
    Ou seja, o $-i\in\ints$ mostra que $g\simh f$.
\crproofpart{Antissimetria da $\appv$.}
\eop\noi
    Sejam $f,g : \ints\to\ints$ tais que $f\appv g$ e $g\appv f$.
    Sejam então $i,j\in\nats$ tais que para todo $x\in \ints$
    $f(x) = g(x)+i$ e $g(x) = f(x)+j$.
    Seja $x\in\ints$ e calcule:
    $$
    f(x) = g(x)+i = f(x) + j + i.
    $$
    Logo $i+j = 0$, e sendo ambos naturais, temos $i=j=0$.
    Ou seja, para todo $x\in\ints$, $f(x) = g(x)$, e logo $f=g$.
\crtabproofpart{A $\appv$ não é nem relação de equivalência nem de ordem.}
\crproofpart{Refutação da simetria da $\apph$.}
    \eop\noi
    Como contraexemplo tome as funcções $f,g : \ints\to\ints$
    definidas pelas:
    $$
    \xalignat2
    f(0) &= 1                   & g(1) &= 1 \\
    f(x) &= 0 \quad (x \neq 0)  & g(x) &= 0 \quad (x \neq 1)
    \endxalignat
    $$
    Observe que realmente $f \apph g$ pois temos
    que para todo $x \in \ints$, $f(x) = g(x+1)$.
    Mas $g\not\apph f$.  Suponha que tem $u\in\nats$
    tal que para todo $x\in\ints$, $g(x) = f(x + u)$.
    Basta ou achar um absurdo.
    Pela nossa hipótese, $g(1) = f(1 + u)$.
    Mas $g(1) = 1$, ou seja $f(1+u) = 1$.
    Pela definição da $f$ então $u+1 = 0$,
    Absurdo, pois o $0$ não é sucessor de nenhum natural.
\crproofpart{Refutação da antissimetria da $\apph$.}
    \eop\noi
    Como contraexemplo tome as funcções $f,g : \ints\to\ints$
    definidas pelas:
    $$
    \xalignat2
    f(x) &=
    \knuthcases {
    0, & se $x$ é par; \cr
    1, & se $x$ é ímpar;
    }
    &
    g(x) &=
    \knuthcases {
    1, & se $x$ é par; \cr
    0, & se $x$ é ímpar;
    }
    \endxalignat
    $$
    Observe que realmente $f \apph g$ (tome $u \asseq 1$)
    e $g \apph f$ (tome $u \asseq 1$ de novo).
    Mesmo assim, $f\neq g$.
    Logo $\apph$ não é uma relação antissimétrica.
\eop\medskip
Concluimos então que:
as $\simh$ e $\simv$ são relações de equivalência,
a $\appv$ é uma relação de ordem,
e a $\apph$ apenas uma preordem.

%%}}}

%%{{{ prob: simz_sime_simo_simi 
\problem.
%%%{{{ meta 
\label simz_sime_simo_simi
\pdefs
    \pdef sime {\rel{\stackrel{{}_{\mathrmsmall e}}=}}
    \pdef simi {\rel{\stackrel{\infty}=}}
    \pdef simo {\rel{\stackrel{{}_{\mathrmsmall o}}=}}
    \pdef simz {\rel{\stackrel{{}_{\mathrmsmall z}}=}}
    ;;
%%%}}}

Defina as relações seguintes no $(\nats\to\nats)$ assim:
$$
\align
f\simz g&\defiff f(0)    = g(0) \\
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$} \\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$} \\
f\simi g&\defiff f(n)    = g(n)   \ \text{para uma infinidade de $n\in\nats$.}
\endalign
$$
% TODO: fix reflabs
\tlist:
\li (i):
Para cada uma da $\simz,\sime,\simo,\simi$, decida se é uma relação de
equivalência ou não.
\li (ii):
Demonstre ou refute a afirmação seguinte:
\emph{a relação $(\sime\rcom\simo)$ é a relação trivial $\mathsf{True}$.}
\endtlist

\hint
Ache um contraexemplo para a $\simi$.  As outras, são.

\solution
\proofpart{(i)}
A $\simi$ não é.  Considere o seguinte contraexemplo.
Sejam as $\alpha, \beta, \gamma : \nats\to\nats$ (como seqüências):
$$
\align
\alpha &= \tup{0,1,0,1,0,1,\dotsc} \\
\beta  &= \tup{0,2,0,2,0,2,\dotsc} \\
\gamma &= \tup{1,2,1,2,1,2,\dotsc}.
\endalign
$$
Trivialmente, $\alpha\simi\beta$ e $\beta\simi\gamma$ mas $\alpha\not\simi\gamma$.
\crproofpart{(ii)}
Correto.
Sejam $f, g \in (\nats\to\nats)$.
Vamos mostrar que $f \relp{\sime\rcom\simo} g$.
Pela definição da $\rcom$ temos:
$$
f \relp{\sime\rcom\simo} g
\iff \text{existe $h \in (\nats\to\nats)$ tal que $f \sime h$ e $h\simo g$}.
$$
A funcção $h : \nats\to\nats$ definida pela
$$
h(n) = \knuthcases {
f(n), &se $n$ par \cr
g(n), &se $n$ ímpar
}
$$
satisfaz as $f \sime h\simo g$ pela sua construção.
Logo, $f \relp{\sime\rcom\simo} g$.

%%}}}

%%{{{ prob: cofinite_cameo_appearance 
\problem.
%%%{{{ meta 
\label cofinite_cameo_appearance
%%%}}}

No conjunto $(\reals\to\reals)$ definimos:
$$
\align
f \approx g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) = g(x)}$ é infinito};\\
f \sim    g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) \neq g(x)}$ é finito}.
\endalign
$$
Demonstre que:
\item{(i)} uma delas é relação de equivalência;
\item{(ii)} a outra não é.

\hint
Se um subconjunto $X\subset\reals$ é infinito, isso não quis dizer
que $\reals\setminus X$ é finito!

\hint
A $\sim$ é a relação de equivalência.
Demonstre.

\hint
A $\approx$ não é transitiva.
Refute!

\solution
A $\sim$ é uma relação de equivalência:
\crproofpart{Reflexiva.}
Seja $f : \reals\to\reals$.
Calculamos:
$$
\setst {x \in \reals} {f(x) \neq f(x)} = \emptyset,
$$
que, sendo finito, mostra que $f\sim f$.
\crproofpart{Simétrica.}
Trivial, pois para quaisquer $f,g : \reals\to\reals$ temos
$$
\setst {x \in \reals} {f(x) \neq g(x)}
=
\setst {x \in \reals} {g(x) \neq f(x)}
$$
e logo um é finito sse o outro é finito.
\crproofpart{Transitiva.}
Sejam $f,g,h:\reals\to\reals$ tais que $f\sim g$ e $g\sim h$.
Logo:
$$
\align
A &\defeq \text{$\setst {x \in \reals} {f(x) \neq g(x)}$ finíto} \tag{1} \\
B &\defeq \text{$\setst {x \in \reals} {g(x) \neq h(x)}$ finíto} \tag{2}.
\endalign
$$
Seja $w \in \reals$.
Vamos demonstrar que
$$
w \notin A \union B \implies f(w) = h(w).
$$
Calculamos:
\compute
f(w) &= g(w)    \by {pois $w \notin A$} \\
     &= h(w).   \by {pois $w \notin B$} \\
\endcompute
Contrapositivamente,
$$
f(w) \neq h(w) \implies w \in A \union B.
$$
Mas $A\union B$ é finito,
(sendo uma união finita de conjuntos finitos)
e mostramos que
$$
\setst {x \in \reals} {f(x) \neq h(x)} \subset A\union B
$$
e logo também finito, ou seja, $f\sim h$.
\crproofpart{A $\approx$ não é uma relação de equivalência.}
Vamos refutar a sua transitividade.
Como contraexemplo, tome as $f,g,h : \reals\to\reals$ definidas pelas:
$$
\xalignat3
    f(x) &= 1 &
    g(x) &= \cos(x) &
    h(x) &= -1.
\endxalignat
$$
Observe que $f \approx g$ pois concordam nos pontos $2k\pi$ para todo $k\in\ints$.
Também $g \approx h$ pois concordam nos pontos $(2k+1)\pi$ para todo $k\in\ints$.
Mesmo assim, $f \not\approx h$ pois não concordam em ponto nenhum.

%%}}}

%%{{{ prob: efle_vs_fele_and_eflt_vs_felt 
\problem.
%%%{{{ meta 
\label efle_vs_fele_and_eflt_vs_felt
\pdefs
    \pdef efle {\rel{\buildrel{{}_{\exists\forall}} \over \leq}}
    \pdef eflt {\rel{\buildrel{{}_{\exists\forall}} \over <}}
    \pdef fele {\rel{\buildrel{{}_{\forall\exists}} \over \leq}}
    \pdef felt {\rel{\buildrel{{}_{\forall\exists}} \over <}}
    ;;
%%%}}}

Defina no $(\reals\to\reals)$ as relações seguintes:
$$
\align
f \efle g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) \leq g(x) } \\
f \fele g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) \leq g(x) } \\
f \eflt g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) < g(x) } \\
f \felt g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) < g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela tem ou não cada uma
das propriedades de uma ordem total, e de uma ordem estrita.

%%}}}

%%{{{ prob: implementing_functions_as_relations_and_vice_versa 
\problem implementando funcções como relações e vice versa.
%%%{{{ meta 
\label implementing_functions_as_relations_and_vice_versa
%%%}}}

Já encontramos a idéia de \emph{implementação} de algum
conceito matemático no~\ref[Functions]
(\reftag[Implementations_seq_fam], \reftag[implement_partial_functions],
\reftag[implement_nondeterministic_functions]).
Como tu definiria funcções como relações, e como relações como funcções?
Dê apenas um esboço da tua idéia, sem entrar em muitos detalhes.

\solution
Seguem umas idéias.
\crproofpart{Funcção como relação.}
Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$
tal que $f$ é \emph{left-total} e \emph{right-unique}
(veja o glossário~\reftag[relations_glossary])
é chamada uma \dterm{funcção de $A$ para $B$}.
Escrevemos $f(x) = y$ em vez de $f(x,y)$ ou de $x \rel f y$
e para todo $a\in A$ denotamos com $f(a)$ o único $b\in B$
tal que $a \rel f b$.
\crproofpart{Relação binária como funcção.}
Sejam $A,B$ conjuntos.
Uma funcção $R : A \to \pset B$ é chamada uma \dterm{relação de $A$ para $B$}.
Escrevemos $a \rel R b$ quando $b \in R(a)$,
e $a \not\rel R b$ quando $b \notin R(a)$.
\crproofpart{Relação geral como funcção.}
Seja $W$ conjunto.
Uma funcção $R : W \to \bools$ é chamada uma \dterm{relação no $W$}.
Escrevemos $R(w)$ como afirmação, quando $R(w) = \True$, e $\lnot R(w)$
ou ``não $R(w)$'' quando $R(w) = \False$.

%%}}}

\endproblems
%%}}}

%%{{{ Partitions 
\section Partições.
%%%{{{ meta 
\label Partitions
%%%}}}

%%{{{ idea_of_partition 
\note Partição.
%%%{{{ meta 
\label idea_of_partition
%%%}}}

Voltamos de novo para nosso conjunto $A$ do~\reftag[idea_of_equivalence],
mas essa vez sem uma predeterminada propriedade para focar.
Essa vez vamos dividir os elementos do $A$ em \dterm{classes},
tais que cada membro do $A$ pertencerá a \emph{exatamente uma delas},
e cada uma delas terá pelo menos um membro do $A$.
E nem vamos justificar essa separação, explicando o como ou o porquê.
Esse tipo de colecção de classes vamos definir agora:

%%}}}

%%{{{ df: partition 
\definition.
%%%{{{ meta 
\label partition
\defines
    * partição
    ;;
%%%}}}

Seja $A$ conjunto e $\scr A \subset \pset A$ uma família de subconjuntos de $A$.
$\scr A$ é uma \dterm{partição} de $A$, sse:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \scr A = A$;
\li (P2): os membros de $\scr A$ são disjuntos dois-a-dois;
\li (P3): $\emptyset \notin \scr A$.
\endtlist
Chamamos de \dterm{classes} os membros da $\scr A$.

%%}}}

%%{{{ x: partitions_of_seven 
\exercise.
%%%{{{ meta 
\label partitions_of_seven
%%%}}}

Seja $A=\set{0,1,2,3,4,5,6}$.
Quais das colecções seguintes são partições do $A$?:
$$
\xalignat 2
\scr A_1 &= \big\{ \set{0,1,3}, \set 2, \set{4,5}, \set 6 \big\}                &\scr A_5 &= \big\{ \set{0,1,2}, \set{2,3,4}, \set{4,5,6} \big\} \\
\scr A_2 &= \big\{ \set{0,1,2,3}, \emptyset, \set{4,5,6} \big\}                 &\scr A_6 &= \big\{ \set{1,2}, \set{0,3}, \set 5, \set 6 \big\}  \\
\scr A_3 &= \big\{ \set{0,1,2,3,4,5,6} \big\}                                   &\scr A_7 &= \big\{ \set{0,1,2}, \set 3, \set{4,5,6,7} \big\}    \\
\scr A_4 &= \big\{ \set 0, \set 1, \set 2, \set 3, \set 4, \set 5, \set 6 \big\}&\scr A_8 &= \big\{ \set 0, \set{1,2}, \set{6,5,4,3} \big\}
\endxalignat
$$

\hint
Quatro delas são, as outras não.

\solution
As $\scr A_1, \scr A_3, \scr A_4, \scr A_8$ são.
As outras não:
\tlist:
\li: a $\scr A_2$ não é: $\emptyset$ é seu membro;
\li: a $\scr A_5$ não é: o $2$ que pertence a dois membros dela;
\li: a $\scr A_6$ não é: $4 \in A$ mas não pertence a nenhum membro dela;
\li: a $\scr A_7$ não é: $7 \notin A$ mas $7 \in \Union \scr A_7$.
\endtlist


%%}}}

%%{{{ x: union_scr_A_subset_already_known 
\exercise.
%%%{{{ meta 
\label union_scr_A_subset_already_known
%%%}}}

Podemos trocar o~(P1) da~\ref[partition] por
$$
\text{(P1$'$)}\quad\Union \scr A \supset A \ ?
$$

\hint
Será que já sabemos a outra ``direção'' da igualdade?

\solution
Sim!
Pois como $\scr A$ é uma família de subconjuntos de $A$,
já sabemos que $\Union \scr A \subset A$.
Logo, afirmar $\Union \scr A = A$ ou afirmar $\Union \scr A \supset A$
nesse caso é a mesma coisa.
Escolhemos o (P1) pois fica mais natural (e porque se retirar a hipótese
que $\scr A \subset \pset A$, o (P1) vira necessário).

%%}}}

%%{{{ x: pairwise_necessary_for_partition 
\exercise.
%%%{{{ meta 
\label pairwise_necessary_for_partition
%%%}}}

Podemos trocar o~(P2) da~\ref[partition] por
$$
\text{(P2$'$)}\quad\Inter \scr A = \emptyset\  ?
$$

\hint
Não: nossa definição vai permitir mais colecções ser chamadas ``partição'' do que deveriam.

\hint
Uma das colecções não-partições do~\ref[partitions_of_seven] vai
acabar sendo partição.

\solution
A $\scr A_5\subset\powerset A$ do~\ref[partitions_of_seven] satisfaz as
$$
\Union \scr A_5 = A,
\qqqquad
\Inter \scr A_5 = \emptyset,
$$
mas não é uma partição: o $2\in A$ por exemplo, pertenceria em duas classes
diferentes, algo contra da nossa idéia de ``partição''.

%%}}}

\endsection
%%}}}

%%{{{ Quotient set 
\section Conjunto quociente.
%%%{{{ meta 
\label Quotient_set
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os dois conceitos de ``relação de equivalência'' e ``partição'',
parecem diferentes mas realmente são apenas duas formas diferentes de
expressar a mesma idéia.
Cada relação de equivalência determina uma partição;
e vice-versa: cada partição determina uma relação de equivalência.
Bora demonstrar isso!

%%}}}

%%{{{ x: wrong_partition_of_eqrel_def 
\exercise Cuidado!.
%%%{{{ meta 
\label wrong_partition_of_eqrel_def
%%%}}}

Tentando investigar isso, começando com uma relação de equivalência $R$,
um aluno tentou definir a partição correspondente $\scr A_R$ assim:
$$
\align
C \in \scr A_R
\defiff
&C \subset A \\
&\mland  C \neq \emptyset \\
&\mland  \lforall {c,d \in C} {c \rel R d}.
\endalign
$$
Qual o erro na definição do aluno?
O que faltou escreverer para virar uma definição correta?

\hint
Considere o conjunto $A$ com a relação de equivalência $R$ como no diagrama
interno seguinte:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\draw (elem-1) -- (elem-2) -- (elem-3) -- (elem-4);
\draw (elem-5) -- (elem-6);
\endtikzpicture
$$
Lembra-se que como já declaramos a~$R$ de ser uma relação de
equivalência, não precisamos botar todas as setinhas, apenas as necessárias
para ``gerar'' a~$R$
(veja~\ref[conventions_for_internal_diagrams_of_rel]).
Agora, seguindo fielmente sua definição, qual é o conjunto $\scr A_{R}$?

\hint
\emph{Não} é o conjunto dos seguintes subconjuntos de $A$:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\tikzi eqrel2partitiondesired;
\endtikzpicture
$$
Ache um $C\subset A$ tal que $C \in \scr A_{R}$ mas \emph{não deveria}.

\hint
A definição do aluno garanta que todos os elementos numa classe realmente
relacionam entre si através da $R$;
mas não garanta que cada classe $C$ é feita por \emph{todos} os elementos
de~$A$ que relacionam com os membros da $C$ mesmo.
Por exemplo, ela \emph{corretamente exclue} conjuntos como $\set{2,5}$;
mas ela \emph{incorretamente inclue} conjuntos como o $\set{2,3}$.
$$
\tikzpicture
\draw [rounded corners=3mm, fill=blue!20] (-1.6,0.4)--(-1.6,1.4)--(-0.3,1.4)--(-0.3,0.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
\qqqquad
\tikzpicture
\draw [rounded corners=2mm, fill=red!20] (-1.5,1.4)--(-1.5,-1.0)--(-0.9,-1.0)--(-0.9,1.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
$$

\solution
Seguindo as dicas, faltou escrever a ultima linha:
$$
\align
C \in \scr A_{R}
\defiff
&C \subset A\\
&\mland  C \neq \emptyset\\
&\mland  \lforall {c,d \in C} {c \rel R d}\\
&\mland  \pforall {a \in A} \lforall {c \in C} {a \rel R c \implies a \in C}.
\endalign
$$

%%}}}

%%{{{ x: from_eqrel_to_partition 
\exercise De equivalência para partição.
%%%{{{ meta 
\label from_eqrel_to_partition
%%%}}}

Seja $\sim$ relação de equivalência num conjunto $A$.
Escreva formalmente como definir uma partição
$\scr A_{\sim}$ do $A$ em que suas classes são feitas
por todos os $\sim$-relacionados.
Demonstre que realmente é uma partição.

\hint
Mande os membros de $A$ se separar:
<<se juntem todos os relacionados entre si!>>.

\solution
\proofpart{Definir uma família de subconjuntos de $A$.}
Definimos $\scr A_{\sim}$ para ser a família de todas as
classes de equivalência através da $\sim$.  Formalmente:
$$
\scr A_{\sim}
\defeq
\setst {\eqclassimp a} {a \in A}.
$$
\proofpart{Provar que a família $\scr A_{\sim}$ é uma partição.}
Primeiramente observe que cada membro de $\scr A_{\sim}$
é um subconjunto de $A$.
Agora basta verificar as (P1)--(P3) da~\ref[partition].
\crproofpart{(P1) Mostrar que $A \subset \Union \paren{\scr A_{\sim}}$.}
Tome $a\in A$.
Como $a \sim a$ (reflexividade), então $a \in \eqclassimp a$.
Agora como $\eqclassimp a \in \scr A_{\sim}$,
temos que $a \in \Union \paren{\scr A_{\sim}}$.
\crproofpart{(P2) Os membros de $\scr A_{\sim}$ são disjuntos dois-a-dois.}
Sejam $C,D \in \scr A_{\sim}$.
Logo sejam $c,d \in A$ tais que $C = \eqclassimp c$ e $D = \eqclassimp d$.
Precisamos demonstrar \emph{qualquer uma} das duas implicações (são contrapositivas):
$$
\align
C\neq D                 &\implies C\inter D = \emptyset; \\
C\inter D\neq\emptyset  &\implies C = D.
\endalign
$$
Vamos demonstrar a segunda.
Suponha $C\inter D \neq \emptyset$ e seja logo $w\in C\inter D$.
Ou seja, $w\in C$ e $w \in D$, e logo $w \sim c$ e $w \sim d$.
Queremos demonstrar que $C = D$.
{\lrdirset.}
Tome $x \in C = \eqclassimp c$.
Temos:
$$
x \sim c \sim w \sim d
$$
(simetria e transitividade da $\sim$)
e logo $x \in \eqclassimp d = D$ e $C\subset D$.
A {\rldirset} é similar.
\crproofpart{(P3) $\emptyset \notin \scr A_{\sim}$.}
Basta demonstrar que para cada $a\in A$, $\eqclassimp a \neq \emptyset$.
Isso é uma conseqüência da reflexividade da $\sim$, pois
para todo $a\in A$, $a \in \eqclassimp a$.
\eop
Se escolher a primeira implicação na parte de (P2), a gente continua assim:
Suponha $C\neq D$ e logo sem perda de generalidade, tome $c_0 \in C\setminus D$.
Logo $c_0 \sim c$ e $c_0 \not\sim d$.
Isso já mostra que não pode ter nenhum elemento $w \in C\inter D$, pois
nesse caso usando a simetria e transitividade da $\sim$ teriamos
$c_0 \sim c \sim w \sim d$ que obrigaria $c_0 \sim d$;
impossível.

%%}}}

%%{{{ x: why_all_of_eqrel_properties_are_needed 
\exercise.
%%%{{{ meta 
\label why_all_of_eqrel_properties_are_needed
%%%}}}

Explique onde precisou cada uma das propriedades da~\ref[equivalence_relation]
(reflexividade, transitividade, simetria)
na tua resolução do~\ref[from_eqrel_to_partition].

\solution
Veja a resolução do~\ref[from_eqrel_to_partition].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A partição definida no~\ref[from_eqrel_to_partition] é muito importante
e merece seu próprio nome e sua própria notação.  Definimos agora.

%%}}}

%%{{{ df: quoset 
\definition.
%%%{{{ meta 
\label quoset
\indexes
    * quociente!conjunto    see: conjunto quociente
    ;;
\defines
    * \quoset {~A} {~R}  -- o conjunto quociente do $A$ por $R$
    * conjunto!quociente
    ;;
%%%}}}

Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Definimos o \dterm{conjunto quociente} de $A$ por $\sim$ para ser a colecção
de todas as classes de equivalência através da $\sim$.
Formalmente:
$$
\quoset A {\sim} \defeq \setst {\eqclass a {\sim}} {a \in A}.
$$

%%}}}

%%{{{ x: type_of_holed_quoset 
\exercise.
%%%{{{ meta 
\label type_of_holed_quoset
%%%}}}

Sejam $A$ conjunto e $\sim$ relação de equivalência no $A$.
Considere a funcção seguinte definida com buraco:
$$
\quoset A \dhole : \ \askdots
$$
Escreva um tipo válido para essa funcção.

\solution
$\quoset A \dhole : \eqreltype A \to \pset\pset A$.

%%}}}

%%{{{ seeing_the_quotient_set 
\note Enxergando o conjunto quociente.
%%%{{{ meta 
\label seeing_the_quotient_set
%%%}}}

Tendo um conjunto $A$ e uma relação de equivalência $\sim$,
no conjunto quociente $\quoset A \sim$ a relação de equivalência
$\sim$ se vira igualdade $=$ mesmo.
Numa maneira, $\quoset A \sim$ é o mundo que chegamos se nossa $\sim$
virar para ser a nossa $=$.  O mundo onde não conseguimos enxergar
diferenças entre objetos $\sim$-relaçionados.
Para dar um exemplo, considere o conjunto dos inteiros $\ints$,
e a relação de equivalência $\sim$ definida pela
$$
x \sim y \defiff x \cong y \pmod 2,
$$
ou seja, $\sim$ relaciona os inteiros com a mesma \dterm{paridade}
(\ref[eqrel_eg_parity]).
Vamos olhar para nosso conjunto:
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
Quantos elementos ele tem?
Uma infinidade, correto?
Sim, pois todos os
$$
\dots, -3, -2, -1, 0, 1, 2, 3, \dots
$$
são distintos dois-a-dois.
Vamos lembrar uma propriedade fundamental de conjuntos:
quantos elementos tem o
$$
\set {7, 7, 7, 5, 0, 8, 8}?
$$
Temos escrito $7$ termos para ser exatamente os membros
desse conjunto, mas quantos elementos ele tem mesmo?
$4$, pois num conjunto não existe a noção de
\emph{quantas vezes} um membro pertence a ele;
só a noção de pertencer.
E isso é uma conseqüência imediata da definição de igualdade
de conjuntos.  Lembre se:
$$
A = B \defiff \lforall x {x\in A \iff x \in B}
$$
e logo
$$
\set {7, 7, 7, 5, 0, 8, 8} = \set {0, 8, 7, 5}
$$
pois realmente para todo $x$,
$$
x \in \set {7, 7, 7, 5, 0, 8, 8}
\iff
x \in \set {0, 8, 7, 5}
$$
e, sendo iguais não pode ser que eles têm cardinalidades diferentes!
Voltando para o conjunto de inteiros
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
agora imagina que perguntamos sobre sua cardinalidade uma pessoa
$\sim$-cega.  O que quis dizer $\sim$-cega?  Ela não consegue
enxergar como distintos objetos relacionados pela $\sim$.
O que ela vai responder em nossa pergunta?
<<2>>.
Pois, para essa pessoa os
$$
\dots, -4, -2, 0, 2, 4, \dots
$$
são todos indistingüíveis, e a mesma coisa sobre os
$$
\dots, -5, -3, -1, 1, 3, 5, \dots
$$
O conjunto quociente $\quoset \ints \sim$ então,
é o conjunto que ela enxerga.
Só tem um probleminha agora:
\emph{quais} são esses dois membros do conjunto que ela enxerga?
A resposta correta aqui pode aparecer chocante mas é a seguinte:
\standout
\emph{Não importa!}
\endstandout
Uma escolha natural seria escolher como membros do $\quoset \ints \sim$
os dois conjuntos:
$$
\set{\dots, -4, -2, 0, 2, 4, \dots}
\qqtext{e}
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
$$
chegando assim no
$$
\quoset\ints\sim
= \set {
\set{\dots, -4, -2, 0, 2, 4, \dots},
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
}.
$$
De fato, pela \ref[quoset] do conjunto quociente, $\quoset\ints\sim$
realmente \emph{é} esse conjunto.  E isso faz sentido,
pois uma definição de $\quoset A R$ precisa determinar completamente
um objeto.
Mas uma outra escolha poderia ser, por exemplo, o conjunto
$$
\set{0, 1}
$$
ou qualquer conjunto feito escolhendo outros ``rótulos'' para cada
classe de equivalência:
$$
\set{{\mathbf 0}, {\mathbf 1}}, \quad
\set{\mathrm{even}, \mathrm{odd}}, \quad
\set{\mathrm{E}, \mathrm{O}}, \quad
\set{\emptyset, \set{\emptyset}}, \quad\dotsc
$$
Basta só ter exatamente dois membros.
Toda esta conversa chega no teorema e na definição seguintes:

%%}}}

%%{{{ thm: only_theorem_about_relations 
\theorem.
%%%{{{ meta 
\label only_theorem_about_relations
%%%}}}

Seja $A$ conjunto e $\sim$ uma relação binária nele.
A $\sim$ é uma relação de equivalência se e somente se
existe conjunto $Q$ e surjecção
$$
\pi : A \surto Q
\mtag[quoset_determining_surjection_1=QS1]
$$
tal que $(\sim) = (\frel \pi)$ (\ref[kernel_coimage]), ou seja, tal que
$$
x \sim y \iff \pi(x) = \pi(y).
\mtag[quoset_determining_surjection_2=QS2]
$$

\sketch.
\proofpart{\lrdir.}
O conjunto $Q$ é o $\quoset A \sim$ e a surjecção $\pi$
é a ``projecção canônica'' $\eqclass \dhole \sim$.
\crproofpart{\rldir.}
Demonstrado no~\ref[frel_is_an_eqrel].

%%}}}

%%{{{ df: general_quotient_and_determining_surjection 
\definition.
%%%{{{ meta 
\label general_quotient_and_determining_surjection
%%%}}}

No contexto do~\ref[only_theorem_about_relations],
quando temos $\pi$ e $Q$ que satisfazem
as~\mref[quoset_determining_surjection_1]
 e~\mref[quoset_determining_surjection_2],
dizemos que $Q$ é um \dterm{quociente} de $A$ por $\sim$,
e que $\pi$ é uma \dterm{surjecção determinante} da $\sim$.

%%}}}

%%{{{ remark: choose_your_quotient_wisely 
\remark.
%%%{{{ meta 
\label choose_your_quotient_wisely
%%%}}}

A demonstração do~\ref[only_theorem_about_relations] fornece
o quociente $\quoset A \sim$ e a surjecção determinante
$\lam x {\eqclass x \sim}$
(ou, com buracos, $\eqclass {\dhole} {\sim}$)
que mapeia cada membro de $A$ a sua classe de equivalência.
Vamos dizer que esse será o ``conjunto quociente oficial'',
e a ``surjecção determinante oficial''.
Mas dependendo do uso, pode ser que para uns
casos é melhor utilizar outro quociente
e outra surjecção determinante.
E até pior---ou, na verdade, melhor---pessoas
diferentes podem escolher quocientes diferentes
como \emph{mais iluminantes}.
Vamos ver uns exemplos.
Em cada um, vamos ver o oficial, e comparar com uma
alternativa melhor.
Vamos usar a notação
$$
\quoset A \sim \pseudoeq Q
$$
para afirmar que $Q$ é \emph{um} quociente que possivelmente
parece mais iluminante do que o oficial.

%%}}}

%%{{{ eg: quoset_eg_countries 
\example.
%%%{{{ meta 
\label quoset_eg_countries
%%%}}}

Considere um conjunto de pessoas $P$.
Na relação do~\ref[eqrel_eg_countries]
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
o conjunto quociente oficial é feito por conjuntos
de pessoas copatriotas.  Uma escolha melhor seria
usar os próprios países como quociente, e a
$$
\pi(x) = \text{o país em que $x$ nasceu}.
$$
Para ser sobrejetora mesmo, no quociente não vamos
incluir paises em quais nenhuma pessoa (de $P$) nasceu.
Seja $C$ esse conjunto de paises $c$ onde pelo menos
uma pessoa $p\in P$ nasceu.
Então temos
$$
\quoset {P} {\sim} \pseudoeq C.
$$
Num certo sentido, \emph{dividindo esse conjunto de pessoas
$P$ por a relação $\sim$}, chegamos no conjunto de
paises $C$.

%%}}}

%%{{{ x: quoset_children 
\exercise.
%%%{{{ meta 
\label quoset_children
%%%}}}

Na relação do~\ref[eqrel_eg_children]
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

%%}}}

%%{{{ x: quoset_teams 
\exercise.
%%%{{{ meta 
\label quoset_teams
%%%}}}

Na relação do~\ref[eqrel_eg_teams]
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

%%}}}

%%{{{ eg: some_eqclasses_geometrically_and_algebrically 
\example.
%%%{{{ meta 
\label some_eqclasses_geometrically_and_algebrically
%%%}}}

Vamos descrever geometricamente as classes de equivalência das
relações do~\ref[equivalent_relations_on_euclidean_plane] no $\reals^2$,
ou seja, determinar os conjuntos quocientes correspondentes.
Lembramos as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Em cada classe de equivalência da $\sim_1$ então, estão todos os
pares que concordam na sua primeira coordenada.  Ou seja,
cada classe é uma retas vertical, e o conjunto quociente é
colecção de todas essas linhas.  Olhando ainda mais de longe,
podemos ``identificar'' cada reta com seu representante canônico
que fica no eixo-$x$, ou seja, podemos dizer que
$$
\quoset {\reals^2} {\sim_1} \pseudoeq \reals.
$$
A situação é similar para a $\sim_2$, so que essa vez são todas
as retas horizontais, mas olhando novamente de longe,
identificamos cada reta com seu representante canônico
que agora fica no eixo-$y$, ou seja, novamente temos
$$
\quoset {\reals^2} {\sim_2} \pseudoeq \reals.
$$
Sobe a $\sim_{\textrm N}$, a classes do seu
conjunto quociente são todos os cíclos com centro a origem $(0,0)$,
incluindo o ``ciclo-trivial'' com raio $0$, que acaba sendo apenas
o ponto $(0,0)$ mesmo.
Essa vez, identificando cada cíclo com seu raio, chegamos na
$$
\quoset {\reals^2} {\sim_{\textrm N}} \pseudoeq \reals_{\geq 0}.
$$
Por enquanto, entendemos todas essas $\pseudoeq$ apenas como
um ``modo de falar''.
Cuidado pois nenhuma delas é uma verdadeira $=$!
Os dois lados dessas ``igualdades'' são conjuntos cujos membros
nem são objetos do mesmo tipo!
No lado esquerdo pertencem \emph{conjuntos de pares de números reais},
no lado direito pertencem \emph{números reais}.

%%}}}

%%{{{ x: more_eqclasses_geometrically_and_algebrically 
\exercise.
%%%{{{ meta 
\label more_eqclasses_geometrically_and_algebrically
%%%}}}

Descreva geometricamente e algebricamente os conjuntos quocientes
das relações de equivalência
do~\ref[equivalent_relations_on_euclidean_space].

\hint
Entendeu o~\ref[some_eqclasses_geometrically_and_algebrically]?

\solution
O $\quoset {\reals^3} {\sim_3}$ parece lasanha:
é composto por todos os planos horizontais.
O $\quoset {\reals^3} {\sim_{1,2}}$ é composto pelas todas as retas
verticais (perpendiculares no $xy$-plano).
O $\quoset {\reals^3} {\sim_{\textrm N}}$ é composto pelas todas as
sferas com centro na origem.
Informalmente temos as ``equações'' seguintes:
$$
\xalignat3
\quoset {\reals^3} {\sim_3}             & \pseudoeq \reals &
\quoset {\reals^3} {\sim_{1,2}}         & \pseudoeq {\reals^2} &
\quoset {\reals^3} {\sim_{\textrm N}}   & \pseudoeq \reals_{\geq 0}.
\endxalignat
$$
Na primeira identificamos cada plano com sua altura;
na segunda cada reta com sua sombra no $xy$-plano;
na terceira casa sfera com seu raio.

%%}}}

%%{{{ x: quoset_of_congruence_mod_m 
\exercise.
%%%{{{ meta 
\label quoset_of_congruence_mod_m
%%%}}}

Seja $m\in\nats_{>1}$.
Já provou no~\ref[congruence_mod_m_is_an_eqrel_again] que a relação de
congruência módulo $m$ é uma relação de equivalência.
Vamos denotá-la \symq{$\congmod m$}.
Então: qual é o seu conjunto quociente?
Também: seguindo a idéia do~\ref[some_eqclasses_geometrically_and_algebrically],
com que tu ``identificaria'' o $\quoset \ints {\congmod m}$?

%%}}}

%%{{{ x: cong_0_and_cong_1 
\exercise.
%%%{{{ meta 
%%%}}}

Continuando: quais são as relações $\congmod 0$ e $\congmod 1$?

\hint
Uma é a igualdade e outra é a trivial $\True$.
Qual é qual?  Demonstre.

\solution
Temos:
$$
\align
a \congmod 0 b &\iff 0 \divides a - b \iff a - b = 0 \iff a = b \\
a \congmod 1 b &\iff 1 \divides a - b \iff \True.
\endalign
$$
Ou seja:  $(\congmod 0) = (\eqof \ints)$ e $(\congmod 1) = (\True)$.

%%}}}

%%{{{ x: isPred_quoset 
\exercise.
%%%{{{ meta 
\label isPred_quoset
%%%}}}

Descreva o conjunto quociente
$\quoset{\nats}{\rtranscl{\leftrightarrow}}$ do~\ref[isPred].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já vimos que cada relação de equivalência determina uma partição:
seu conjunto quociente.
Mas parece que a partição é um conceito mais geral, pois nos permite
``separar em classes'' um conjunto numa forma que não é obrigada seguir
nenhuma lógica ou regra: sem nenhuma relação de equivalência
``por trás''.
Ou seja: \emph{talvez tem partições que não são conjuntos quocientes de
nenhuma relação de equivalência.}
Mas essa intuição razoável é enganosa!
Vamos investigar agora o caminho de volta: mostrar que cada
partição $\scr A$ também determina uma relação de equivalência
$\sim_{\scr A}$, e sim, a partição $\scr A$ é um conjunto quociente:
o $\quoset A {\sim_{\scr A}}$!

%%}}}

%%{{{ x: from_partition_to_eqrel 
\exercise de partição para equivalência.
%%%{{{ meta 
\label from_partition_to_eqrel
%%%}}}

Seja $A$ conjunto e $\scr A$ partição dele.
Escreva claramente como definir uma relação de equivalência $\sim_{\scr A}$
no $A$ tal que $\quoset A {\sim_{\scr A}} = \scr A$.

\hint
Defina a relação tal que dois objetos são relacionados sse eles pertencem
no mesmo membro da família $\scr A$.

\hint
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
Demonstre que $\sim_{\scr A}$ é uma relação de equivalência.

\solution
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
\crtabproofpart{A relação $\sim_{\scr A}$ é uma relação de equivalência.}
\crproofpart{Reflexiva.}
Tome $a \in A$.
Precisamos mostrar que existe $C \in \scr A$ tal que $a \in C$.
Mas, como $\scr A$ é uma partição \byfact{P1}, temos que $\Union \scr A = A$.
Seja então $C$ tal que $a \in C \in \scr A$.  Logo $a \sim_{\scr A} a$.
\crproofpart{Simétrica.}
Trivial pois $x,y \in C \iff y,x \in C$.
\crproofpart{Transitiva.}
Suponha $x \sim_{\scr A} y$ e $y \sim_{\scr A} z$.
Logo sejam $C,D \in \scr A$ tais que $x,y \in C$ e $y,z \in D$.
Agora, como $y \in C\inter D$ e $\scr A$ é uma partição \byfact{P2},
temos $C = D$.  Ou seja, $x,z \in C \in \scr A$ e logo $x \sim_{\scr A} z$.
\crtabproofpart{O conjunto quociente $\quoset A {\sim_{\scr A}}$ é a partição $\scr A$.}
\crproofpart{\lrdirset.}
Tome $C \in \quoset A {\sim_{\scr A}}$.
Seja $c \in A$ tal que $C = \eqclassimp c$.
Como $c \in \Union \scr A$ ($\scr A$ partição \byfact{P1}),
seja $C'$ o único ($\scr A$ partição \byfact{P2}) membro da $\scr A$ tal que $c \in C'$.
Basta mostrar que $C = C'$.
Tome $x \in C = \eqclassimp c$.
logo $x \sim_{\scr A} c$, e logo existe $D' \in \scr A$ tal que $x,c \in D'$.
Mas pela escolha do $C'$, temos $D' = C'$, e logo $x \in C'$ e $C \subset C'$.
Conversamente, tome $x' \in C'$.
Logo $x',c \in C'$, logo $x'\sim_{\scr A} c$, e logo $x' \in \eqclassimp c = C$.
Ou seja, $C' \subset C$.
\crproofpart{\rldirset.}
Tome $C' \in \scr A$.
Como $C' \neq \emptyset$ (pois $\scr A$ é partição~\byfact{P3}),
seja $c' \in C'$.
Basta demonstrar que $\eqclassimp {c'} = C'$.
Tome $x \in \eqclassimp {c'}$.
Logo $x \sim_{\scr A} c'$, e logo seja $D' \in \scr A$ tal que $x,c' \in D'$.
Mas, como $c' \in C'\inter D'$, concluimos que $C'=D'$ (pela~\byfact{P2}).
Ou seja, $x \in C'$.
Conversamente, tome $x' \in C'$.
Como $c'\in C'$, logo $x' \sim_{\scr A} c'$ pela definição da $\sim_{\scr A}$,
ou seja $x'\in\eqclassimp {c'}$.

%%}}}

%%{{{ x: why_all_of_partition_properties_are_needed 
\exercise.
%%%{{{ meta 
\label why_all_of_partition_properties_are_needed
%%%}}}

Explique onde precisou cada uma das condições (P1)--(P3) da~\ref[partition]
na tua resolução do~\ref[from_partition_to_eqrel].

\solution
Veja a resolução do~\ref[from_partition_to_eqrel].

%%}}}

%%{{{ df: induced_equivalence_relation_and_partition 
\definition.
%%%{{{ meta 
\label induced_equivalence_relation_and_partition
\defines
    * partição!induzida
    * relação!induzida
    ;;
%%%}}}

Chamamos a $\sim_{\scr A}$ a \dterm{relação de equivalência induzida pela $\scr A$}.
Similarmente chamamos o conjunto quociente $\quoset A {\sim}$
a \dterm{partição induzida pela $\sim$}.

%%}}}

%%{{{ x: how_many_partitions_on_3 
\exercise.
%%%{{{ meta 
\label how_many_partitions_on_3
%%%}}}

Seja $A$ conjunto finito com $\card A = 3$.
Quantas partições de $A$ existem?
Por que isso resolve o~\ref[how_many_equivalence_relations_on_3]?

%%}}}

%%{{{ Summary 
\note Resumo.
%%%{{{ meta 
\label eqrel_quoset_partition_summary
\DefFun eqrelize
\DefFun quotient
\DefOp EqRel
\DefOp Part
%%%}}}

O coração dessa secção fica nos exercícios~\reftag[from_eqrel_to_partition]
e~\reftag[from_partition_to_eqrel].  Vamos resumir o que tá acontecendo.
Para qualquer conjunto $A$ definimos os conjuntos $\EqRel(A)$
de todas as suas relações de equivalência e $\Part(A)$ de
todas as suas partições:
\mathcol
\EqRel(A) &\defeq \setstt {{\sim}} {$\sim$ é uma relação de equivalência no $A$} \\
\Part(A)  &\defeq \setstt {{\scr A}} {$\scr A$ é uma partição do $A$}.
\endmathcol
Dado conjunto $A$ encontramos como definir \emph{funcções}
$$
\cdopt{sep=2cm}
\EqRel(A) \ar[r, shift left, "\quotient"] \|
\Part(A)  \ar[l, shift left, "\eqrelize"]
\endcd
$$
que ``traduzem'' qualquer relação de equivalência para sua partição induzida
e qualquer partição para sua relação de equivalência induzida.
São definidas pelas:
\mathcols 2
\quotient(\sim) &\defeq \quoset A {\sim} &
x \relp{\eqrelize(\scr A)} y &\defiff \lexists {C\in \scr A} {x,y \in C}.
\endmathcols
Essas traduções são fieis, no sentido de:
\mathcols 2
\quotient \of \eqrelize &= \idof {\Part(A)} &
\eqrelize \of \quotient &= \idof {\EqRel(A)}.
\endmathcols
De fato, ambas são bijecções, e cada uma é a inversa da outra.
Com as primeiras notações que usamos e também com palavras, temos:
\mathcall
{\sim_{\scr A_{\sim}}}   &= {\sim}    \called{<<a relação induzida pela partição induzida pela $\sim$ é a própria $\sim$>>}; \\
{\scr A_{\sim_{\scr A}}} &= {\scr A}  \called{<<a partição induzida pela relação induzida pela $\scr A$ é a própria $\scr A$>>}.
\endmathcall
Não se preocupe se o conceito do \emph{conjunto quociente} ainda parece meio
distante ou abstrato demais.  Ataque os problemas e os exercícios, e confie
que estudando teoria dos grupos (\ref[Group_theory]) isso vai mudar!

%%}}}

%%{{{ two_sides_of_the_same_coin_eqrel_partition 
\note Dois lados da mesma moeda.
%%%{{{ meta 
\label two_sides_of_the_same_coin_eqrel_partition
%%%}}}

Vimos aqui que ``partição'' e ``classe de equivalência'' são
\emph{dois lados da mesma moeda}.  Considere um conjunto $A$.
\elist:
\li:
Quando precisamos \emph{definir uma relação de equivalência} no $A$,
podemos \emph{definir uma partição} $\scr A$ de $A$ e usar a $\sim_{\scr A}$.
\li:
Conversamente, quando precisamos \emph{definir uma partição} no $A$,
podemos \emph{definir uma relação de equivalência} $\sim$ no $A$
e usar a $\quoset A {\sim}$.
\li:
Além disso, quando temos uma relação $\sim$ no $A$ e precisamos
\emph{demonstrar que ela é uma relação de equivalência},
podemos definir uma família $\scr A$ de subconjuntos de $A$,
\emph{demonstrar que ela é uma partição}, e mostrar que:
$$
x \sim y \iff \lexists {C\in\scr A} {x,y \in C}.
$$
\li:
Finalmente, quando temos uma família $\scr A$ de subconjuntos de $A$
e precisamos \emph{demonstrar que ela é uma partição}, podemos definir
a relação $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y \iff \lexists {C\in\scr A} {x,y \in C}
$$
e \emph{demonstrar que ela é uma relação de equivalência}.
\endelist
Não esqueça essas dicas!

%%}}}

%%{{{ df: kernel_coimage 
\definition.
%%%{{{ meta 
\label kernel_coimage
\defines
    * \coim {~f}  -- a coimagem da $f$
    * \ker {~f}  -- o kernel da $f$
    * coimagem
    * kernel
    ;;
%%%}}}

Seja $f : X \to Y$ e defina a relação binária $\frel f$ no $X$ pela
$$
x_1 \frel f x_2 \defiff f(x_1)=f(x_2).
$$
Chamamos a $\frel f$ o \dterm{kernel} da $f$, e seu conjunto quociente
a \dterm{coimagem} da $f$.
Usamos também os símbolos $\ker f$ e $\coim f$ respectivamente.

%%}}}

%%{{{ x: frel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label frel_is_an_eqrel
%%%}}}

Com os dados da~\ref[kernel_coimage] mostre que $\frel f$
é uma relação de equivalência e descreva os elementos da coimagem.
O que podemos dizer se $f$ é injetora?
Se ela é sobrejetora?

\solution
\proofpart{$\frel f$ é uma relação de equivalência.}
Cada uma das três propriedades é uma conseqüência direta da
propriedade correspondende da igualdade.  Em detalhe:
\crproofpart{Reflexiva.}
Seja $x\in X$.
Temos $x \frel f x$ pois $f(x) = f(x)$ (reflexividade da $=$).
\crproofpart{Transitiva.}
Sejam $a,b,c \in X$ tais que $a \frel f b$ e $b \frel f c$.
Logo $f(a) = f(b)$ e $f(b) = f(c)$.
Logo $f(a) = f(c)$ (transitividade da $=$), ou seja, $a \frel f c$.
\crproofpart{Simétrica.}
Sejam $a, b \in X$ tais que $a \frel f b$, e logo $f(a) = f(b)$
e logo $f(b) = f(a)$ (simetria da $=$), ou seja, $b \frel f a$.
\crtabproofpart{Descripção do conjunto quociente.}
O conjunto quociente ``é'' a imagem $\ima f$.
Caso que $f$ é injetora a relação acaba sendo a igualdade e logo
o conjunto quociente acaba sendo o próprio $\dom f$.
Caso que $f$ é sobrejetora nada demais muda,
só que agora $\ima f = \cod f$.

%%}}}

%%{{{ x: gen_frel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label gen_frel_is_an_eqrel
%%%}}}

Seja $f : A \to B$ e seja $\sim_B$ uma relação de equivalência no $B$.
Defina a $\frel {f,\sim_B}$ no $A$ pela
$$
x_1 \frel {f,\sim_B} x_2 \defiff f(x_1) \sim_B f(x_2).
$$
A $\frel {f,\sim_B}$ é uma relação de equivalência?

\solution
A $\frel {f,\sim_B}$ é uma relação de equivalência sim.
Isso já foi demonstrado, pois a resolução do~\ref[frel_is_an_eqrel]
usou apenas o fato que a igualdade é uma relação de equivalência.

%%}}}

%%{{{ x: immediate applications 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre que todas as relações dos
exemplos~\reftag[equivalent_relations_on_euclidean_plane]
e~\reftag[equivalent_relations_on_euclidean_space]
são casos especiais do~\ref[frel_is_an_eqrel]
(e logo são relações de equivalência ``gratuitamente'').

\hint
Para cada uma delas, precisa definir completamente a
$f : A \to B$ (esclarecendo também quais são os $A,B$).

%%}}}

\endsection
%%}}}

%%{{{ Recursive definitions 
\section Relações recursivas.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Aqui são exemplos familiares para definir recursivamente relações.

%%}}}

%%{{{ eg: even_and_odd_rels_recursion 
\example.
%%%{{{ meta 
%%%}}}

No $\nats$ definimos:
$$
\xalignat2
\Even(0).      &                       &\lnot\Odd(0).&\\
\Even(n+1)     &\defiff \lnot \Even(n) &\Odd(n+1)&\defiff \lnot \Odd(n)
\intertext{Ou, alternativamente, usando duas bases:}
\Even(0).      &                       &\lnot\Odd(0).&\\
\lnot\Even(1). &                       &\phantom\lnot\Odd(1).&\\
\Even(n+2)     &\defiff \Even(n)       &\Odd(n+2)&\defiff \Odd(n)
\endxalignat
$$

%%}}}

%%{{{ eg: even_and_odd_rels_mutual_recursion 
\example Recursão mutual.
%%%{{{ meta 
%%%}}}

$$
\xalignat2
\Even(0).  &                  &\lnot\Odd(0).&\\
\Even(n+1) &\defiff \Odd(n)   &\Odd(n+1)&\defiff \Even(n)
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Num paradigma de programação, na \emph{programação lógica},
programamos definindo relações nesse jeito.
Deixamos então esse assunto para o~\ref[Logic_programming].

%%}}}

\endsection
%%}}}

%%{{{ Higher-order relations 
\section Relações de ordem superior.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Talvez você já se perguntou o que acontece se numa frase como a
$$
\mtrel{João ama Maria}
$$
em vez de substrituir os objetos ``João'' e ``Maria'' com buracos,
substituir o próprio verbo ``amar'':
$$
\mtrel{João {\thole} Maria}.
$$
Chegamos assim no conceito de relações de ordem superior.
Não vale a pena investigar (ainda) esse conceito pois necessita
mais umas ferramentas (e pouco mais maduridade).
Voltamos depois de estudar programação lógica (\ref[Logic_programming])
e lógicas de ordem superior (\ref[Mathematical_logic]).

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_relations 
\section Pouco de cats---categorias e relações.
%%%{{{ meta 
\label Categories_and_relations
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: rats_via_eqrel_no_ints 
\problem.
%%%{{{ meta 
\label from_ints_to_rats_via_eqrel
%%%}}}

Defina no $\ints\times\ints_{\neq0}$ a relação
$$
\tup{a,b} \approx \tup{c,d}
\defiff
ad = bc
$$
Mostre que $\approx$ é uma relação de equivalência
e descreva suas classes de equivalência:
$\quoset {\ints\times\ints_{\neq0}} {\approx} \pseudoeq ?$

%%}}}

%%{{{ prob: like_vitali_rel 
\problem.
%%%{{{ meta 
\label like_vitali_rel
%%%}}}

Defina no $\rats$ a relação
$$
r \sim s \defiff r-s\in\ints.
$$
Demonstre que $\sim$ é uma relação de equivalência e descreva as
classes do $\quoset {\rats} {\sim}$.

%%}}}

%%{{{ prob: vitali_rel 
\problem.
%%%{{{ meta 
\label vitali_rel
%%%}}}

Defina no $\reals$ a relação
$$
x \sim y \defiff x-y\in\rats.
$$
Demonstre que $\sim$ é uma relação de equivalência e descreva as classes
do $\quoset {\reals} {\sim}$.

%%}}}

%%{{{ prob: epimono_factorization_teaser_now_easy 
\problem Agora é fácil.
%%%{{{ meta 
\label epimono_factorization_teaser_now_easy
%%%}}}

Resolvemos o~\ref[epimono_factorization_teaser].
Seja $f : A\to B$ uma funcção qualquer, e considere a $\frel f$
da~\ref[kernel_coimage].
Então $f$ pode ser ``decomposta'' assim:
$$
\cdopt{sep=1.5cm}
A   \ar[r,two heads, ""]\ar[rrr, bend left, "f"] \|
\quoset A {\frel f} \ar[r,two heads,tail, "\tilde f"'] \|
\ima f              \ar[r,hook, ""] \|
B
\endcd
$$
onde a primeira funcção é a ``projecção'' $\eqclassimp {\dhole}$,
a terceira é a inclusão $\ima f \subset B$, e a bijecção no meio
é a funcção definida pela
$$
\tilde f(\eqclassimp a) = f(a),
$$
que garanta a comutatividade do diagrama acima.
Mesmo assim, falta demonstrar umas coisas.
Ache o que, e prove.

\hint
Precisas mostrar que:
(1) a $\tilde f$ é bem-definida;
(2) a $\tilde f$ é uma bijecção.

\hint
(1)
Para mostrar que $\tilde f$ é bem-definida, precisa mostrar que
a escolha do representante da classe não afeta o valor da funcção.
Ou seja, tome $a, a'\in A$ e mostre que:
$$
\eqclass a = \eqclass {a'} \implies f(a) = f(a').
$$
(2)
A bijectividade da $\tilde f$ não precisa de dicas!

%%}}}

%%{{{ word_on_the_street_for_order_of_limit_depending_quantifiers 
\note Com palavras da rua.
%%%{{{ meta 
\label word_on_the_street_for_order_of_limit_depending_quantifiers
%%%}}}

Já encontramos várias vezes situações onde a troca dos $\forall\exists$
para $\exists\forall$ mudou completamente o significado
(o~\ref[mother_of_all] é o mais ilustrativo).
Vamos focar agora no caso onde o universo é o $\nats$, o primeiro
quantificador quantifica o $n$ sobre todo o $\nats$, mas o segundo
quantifica todos os naturais \emph{começando com esse $n$}.
Tu já fez o~\ref[set_liminf_limsup_problem_heart_level], certo?
Seria bom achar aqui mais uma maneira de entender essa situação,
explicando os dois significados \emph{com palavras de rua}.
A situação aqui é parecida:
$$
\gather
\pexists {n\in\nats} \lforallt {x \geq n} { algo }\phantom.\\
\pforall {n\in\nats} \lexistst {x \geq n} { algo }.
\endgather
$$
Supondo que esse ``algo'' tá dizendo que \wq{$x$ é legal},
as afirmações acima com palavras de rua ficam assim:
$$
\align
\pexists {n\in\nats} \lforallt {x \geq n} { $x$ é legal }
&\quad\textwq{A partir dum ponto, todos são legais.} \\
\pforall {n\in\nats} \lexistst {x \geq n} { $x$ é legal }
&\quad\textwq{Sempre vai ter legais.}
\endalign
$$
Assim, ambas nos permitem concluir que tem uma infinidade de legais.
Mas quantos \emph{ilegais} tem?  A primeira nos permite concluir
que tem apenas uma quantidade finita de ilegais, pois, escolhendo
tal $n_0\in\nats$ cuja existência é afirmada sabemos que todas
as possíveis excessões (os ``possivelmente ilegais'') estão
entre eles: $0,1,\dotsc,n_0-1$.
Note que isso não quis dizer que todos eles são ilegais.
No outro lado, a segunda, não nos permite concluir isso.
O fato que ``sempre vai ter legais'', não exclue a possibilidade
de ``sempre vai ter ilegais'' também!
Por exemplo, sempre vai ter números pares, mas sempre vai ter números
ímpares também, né?
Os problemas seguintes brincam com essas idéias.

%%}}}

%%{{{ prob: efeq_vs_feeq 
\problem.
%%%{{{ meta 
\label efeq_vs_feeq
\pdefs
    \pdef efeq {\rel{\buildrel{{}_{\exists\forall}} \over =}}
    \pdef feeq {\rel{\buildrel{{}_{\forall\exists}} \over =}}
    ;;
%%%}}}

Defina no $(\nats\to\nats)$ as relações seguintes:
$$
\align
f \efeq g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) = g(x) }\\
f \feeq g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) = g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela é relação de equivalência (demonstre ou refute).
Se é, descreva seu conjunto quociente.

%%}}}

%%{{{ why_called_preorder 
\problem Por que preordem?.
%%%{{{ meta 
\label why_called_preorder
%%%}}}

Justifique o nome ``preordem'': mostre como começando com uma preordem
$R$ num conjunto $A$, podemos construir uma relação $R'$ consultando a $R$.
Pode demonstrar essa afirmação em vários jeitos, mas o objectivo é achar
a ordem $R'$ mais natural e a mais \emph{justa}, seguindo a preordem $R$.

\hint
A ordem $R'$ não vai ser uma ordem no $A$, pois não podemos
decidir como ``resolver conflitos'' do tipo $R(a,b)$ e $R(b,a)$.
Não podemos arbitrariamente escolher um dos $a,b$ como ``menor'',
botando assim por exemplo $R'(a,b)$ e $\lnot R'(b,a)$.
Isso não seria justo!
Então, em qual conjunto $A'$ faz sentido definir nossa ordem $R'$?

%%}}}

%%{{{ prob: how_many_partitions 
\problem Números Bell.
%%%{{{ meta 
\label how_many_partitions
\indexes
    * Bell!números see: Bell
    ;;
\credits
    * Bell!números
    ;;
%%%}}}

Seja $A$ conjunto finito.
Quantas partições de $A$ existem?

\hint
Conte ``manualmente'' os casos com $\card A = 0, 1, 2, 3$.

\hint
(Os números que tu achou na dica anterior devem ser: $1$, $1$, $2$, e $5$, respectivamente.)
Chame $B_n$ o número de partições dum conjunto finito com $n$ elementos.
Use recursão para definir o $B_n$.

\hint
Já temos umas bases desde a dica anterior:
$$
\align
B_0 &= 1\\
B_1 &= 1\\
B_2 &= 2\\
B_3 &= 5
\intertext{Para a equação recursiva,}
B_{n+1} &= \dots
\endalign
$$
lembra-se que podes considerar conhecidos \emph{todos} os números
$B_k$ para $k \leq n$.

\hint
Sejam $a_0,\dots,a_n$ os $n+1$ elementos de $A$
e considere uma partição arbitrária $\scr A$ dele.
Sendo partição, existe exatamente um conjunto-classe $A_0$ no $\scr A$
tal que $a_0\in A_0$.
Influenciados por a notação de classes de equivalência, denotamos
o $A_0$ por $\eqclassimp {a_0}$.
Tirando esse conjunto da partição $\scr A$ chegamos no
$$
\scr A \setminus \set {\eqclassimp {a_0}}
$$
que é (certo?)\ uma partição do conjunto
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
Seja $k$ o número de elementos desse conjunto.
Quais são os possíveis valores desse $k$?

\hint
Vamos melhorar nossa notação para nos ajudar raciocinar.
O conjunto 
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
da dica anterior, depende de quê?
Como a gente fixou uma enumeração dos elementos do $A$,
ele depende apenas na partição $\scr A$.
Introduzimos então a notação
$$
R_{\scr A} \asseq
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
E denotamos o $k$ da dica anterior com
$k_{\scr A} \asseq \card {R_{\scr A}}$.
O $k_{\scr A}$ da dica anterior pode ter qualquer um dos valores
$k_{\scr A}=0,\dotsc,n$.
E agora?

\hint
Agora separe todas as partições $\scr A$ de $A$ em grupos dependendo
no valor de $k_{\scr A}$, ache o tamanho de cada grupo separadamente,
e use o princípio da adição para achar a resposta final.

\hint
Todas as partições do $A$ são separadas assim em:
\tlist:
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = 0$;
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = 1$;
\li $\eqvdots$:
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = n$.
\endtlist
Seja
$N_i$
o número das partições $\scr A$ de $A$ tais que $k_{\scr A} = i$.
Graças ao princípio da adição, procura-se o somatório $\Sum_{i=0}^n N_i$.
Ache o valor do arbitrário $N_i$.

\hint
De quantas maneiras pode acontecer que o
$$
R_{\scr A} = \Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}
$$
tem $i$ elementos?

\hint
Sabemos que o $a_0$ não pode ser um deles,
então precisamos escolher $i$ elementos dos $n$ seguintes: $a_1, \dotsc, a_n$.
Ou seja, de $\comb n i$ maneiras.
Cada escolha $A_i$ corresponde numa colecção de partições:
$$
\Big\{
\eqclassimp {a_0}\ 
,
\underbrace{\quad\dots\quad}_{\hbox{partição do $A_i$}}
\Big\}
$$

\hint
Sabemos a quantidade de partições de qualquer conjunto de tamanho $i$
com $i\leq n$: são $B_i$.

\solution
Seguindo todas as dicas, basta definir:
$$
\align
B_0 &= 1\\
B_{n+1}
&= \Sum_{i=0}^n N_i
= \Sum_{i=0}^n \comb n i B_i
\endalign
$$
Essa seqüência de números é conhecida como
\credited[Bell : números]\dterm{números~Bell}.

%%}}}

%%{{{ prob: same_limits_eqrel 
\problem.
%%%{{{ meta 
\label same_limits_eqrel
%%%}}}

No $(\nats\to\reals)$ defina a relação
$$
a\sim b
\defiff
\lim\nolimits_n a_n = \lim\nolimits_n b_n
\mlor
\text{nenhum dos dois limites é definido.}
$$
descreva o $\quoset {(\nats\to\reals)} {\sim}$.

%%}}}

%%{{{ prob: smiles_and_frowns 
\problem.
%%%{{{ meta 
\label smiles_and_frowns
%%%}}}

No conjunto $\reals$ defina as relações:
$$
\align
x \smile y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x \leq n \leq y} \\
x \frown y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x < n < y}
\endalign
$$
Sejam $\Smile$ o fecho reflexivo-simétrico da $\smile$,
e $\Frown$ o fecho simétrico da $\frown$.
\eop
(i) Demonstre que $\Smile$ é uma relação de equivalência;
(ii) Demonstre ou refute a afirmação: \emph{$\Frown$ é uma relação de equivalência}.

\hint
Sobre a (i): veja o~\ref[two_sides_of_the_same_coin_eqrel_partition].
Sobre a (ii): a afirmação é falsa; refute!

\hint
Sobre a (i):
Defina a partição de $\reals$
$$
\scr C \defeq
\mubraceleg {\setst {(n,n+1)} {n\in\ints}} {\dsize \cal I}
\union
\mubraceleg {\setst {\set{n}} {n\in\ints}} {\dsize \cal S}.
$$
Basta demonstrar que $\scr C = \quoset \reals {\Smile}$.
\eop\noi
Sobre a (ii):
mostre com um contraexemplo que $\Frown$ não é transitiva.

\solution
(i)
Defina a partição de $\reals$
$$
\scr C \defeq
\mubrace {\setst {(n,n+1)} {n\in\ints}} {\dsize \cal I}
\union
\mubrace {\setst {\set{n}} {n\in\ints}} {\dsize \cal S}.
$$
Basta demonstrar que
$
\scr C = \quoset \reals {\Smile}
$,
ou seja:
$$
x\Smile y \iff \lexists {C\in \scr C} {x\in C \mland y\in C}.
$$
{\rldir}.
Trivial nos dois casos $C\in\cal I$ e $C\in\cal S$.
\eop\noi
{\lrdir}.
Pela hipótese, $x=y$ ou $x\smile y$ ou $y\smile x$.
Separamos então em casos:
\eop\noi
\case{Caso $x=y$:}
Caso $x\in\ints$ tome $C=\set x\in\cal S$.
Caso $x\notin\ints$ tome $C=(\floor x, \floor x + 1)\in\cal I$.
\eop\noi
\case{Caso $x\smile y$:}
Nesse caso $[x,y] \inter \ints = \emptyset$.
Facilmente, $\floor x < x \leq y < \floor x + 1$.
Tome novamente $C=(\floor x, \floor x + 1)\in\cal I$.
\eop\noi
\case{Caso $y\smile x$:}
Similar.
\eop
(ii) Não é, pois não é transitiva.
Observe que $0 \Frown 1$, pois não existe inteiro no $(0,1)$,
e similarmente $1 \Frown 2$.
Mas $0 \not\Frown 2$, pois $1$ é inteiro e $1\in(0,2)$.

%%}}}

%%{{{ prob: cyclic_and_euclidean_closures 
\problem Fecho cíclico, fechos euclideanos.
%%%{{{ meta 
\label cyclic_and_euclidean_closures
\defines
    * \cclo {~R}  -- o fecho cíclico da $R$
    * \leclo {~R}  -- o fecho left-euclideano da $R$
    * \reclo {~R}  -- o fecho right-euclideano da $R$
    * fecho!cíclico
    * fecho!left-euclideano
    * fecho!right-euclideano
    ;;
%%%}}}

Seja $R$ uma relação num conjunto $A$.
Defina seus fechos: cíclico~($\cclo R$), left-euclideano~($\leclo R$), right-euclideano~($\reclo R$).

%%}}}

%%{{{ prob: tclosure_recursive_def 
\problem.
%%%{{{ meta 
%%%}}}

Seja $R$ relação binária num conjunto $A$.
Dê uma definição recursiva do fecho transitivo $\tclosure R$.

\solution
Definimos:
$$
x \tclosure R y
\defiff
x \rel R y \mlor \lexists {w \in A} {x \rel R w \mland w \tclosure R y}.
$$
Pense para visualizar como isso ``funcciona''.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[velleman: Cap.~4] defina e trata relações
diretamente como conjuntos, algo que não fazemos nesse texto.
De novo: muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.
Nos vamos \emph{implementar} e tratar relações como conjuntos apenas
no~\ref[Axiomatic_set_theory].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Logic_programming 
\chapter Programação lógica.
%%%{{{ meta 
\label Logic_programming
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[lpbook],
\cite[artofprolog],
\cite[holpbook].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Group_theory 
\chapter Teoria dos grupos.
%%%{{{ meta 
\label Group_theory
\pdefs
    \pdef G {{\ssetfont G}}
    \pdef H {{\ssetfont H}}
    ;;
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo vamos ver os ``baby steps'' da teoria dos grupos.
Os grupos têm uma quantidade de leis perfeita que fornecem
uma estrutura ideal para começar nosso estudo de \dterm{algebra abstrata}.
Depois estudamos mais teorias de outras estruturas algébricas.
%%}}}

%%{{{ History 
\history.

A teoria dos grupos é principalmente atribuida no trabalho do gigante
{\Galois}Galois.  Ele morreu muito jovem (20 anos) baleado num duel.
Sua biografia sendo bastante romântica e aventurosa,
naturalmente atrai muita atenção, muitas lendas, umas exageradas, outras não.
Mas seu trabalho matemático não precisa nenhum toque de exagero.
Ele introduziu o conceito de grupo e começou estudar sua teoria.
Ele conseguiu perceber, construir, e abstrair numa maneira tão profunda e
original que o resto da humanidade demorou para entender e apreciar.
O que chamamos hoje de \dterm{teoria dos grupos} e de \dterm{teoria de Galois}
nasceram na cabeça desse menino francês, e os \dterm{corpos finitos} também!
A teoria de Galois conecta as duas teorias, de grupos e de corpos.

{\Abel}Abel, um matemático norueguês que morou na mesma época
(e também morreu jovem: 26 anos) estudou uns assuntos parecidos,
e hoje em dia chamamos uma classe de grupos de
\dterm{abelianos} como homenagem a ele.
Uma das coisas que Abel conseguiu demonstrar foi que não existe uma única fórmula
para ``matar'' todas as equações de quinto grau.  Esse teorema é conhecido como
Abel--Ruffini: {\Ruffini}Ruffini atacou o problema com uma prova complicada
que, mesmo que {\Cauchy}Cauchy a aceitou como convincente, ela realmente tava
incompleta; foi Abel matou o problema no \yearof{1826} numa maneira completa e concisa.
Mas o teorema de Abel deixa a possibilidade de existir, por exemplo,
uma família de fórmulas, ou até uma fórmula diferente para resolver cada
polinómio de quinto grau separadamente.

É a teoria de Galois que ilumina mesmo a situação: graças à ela sabemos
que tem polinómios que não são resolutíveis por nenhuma fórmula.
E bem mais que isso.

Três problemas abertos na epoca desde os gregos antigos eram as
construções de régua e compaço seguintes:
(1) trissecção do ângulo;
(2) quadratura do cíclo;
(3) duplicação do cubo.
No (1) são dadas duas linhas que interesetam num ponto único,
formando assim um ângulo.
O problema pede construir duas linhas que dividem esse ângulo
em $3$ ângulos iguais.
No (2) é dado um cíclo e seu ráio e o objectivo é construir
um quadrado com a mesma área.
No (3) é dado um cubo e queremos construir um cubo com
volume duplo.\foot
Na verdade, é dada a \emph{aresta} dum cubo com volume $V$,
é o problema é construir a aresta dum cubo com volume $2V$.
Ou seja, chamando o tamanho da aresta dada $1$,
construir segmento com tamanho $\cbrt 2$.
\toof

{\Wantzel}Wantzel no \yearof{1837} demonstrou a \emph{impossibilidade}
desses três problemas.  Para os (1) e (2), sua demonstração dependeu
do fato que $\pi$ é \dterm{transcendental}.
Na época a transcendentalidade do $\pi$ era apenas uma conjectura,
proposta por {\Lambert}Lambert no \yearof{1768} (no mesmo artigo onde
\emph{demonstrou} a sua irracionalidade).
A conjectura vira teorema bem depois, no ano \yearof{1882},
por \vonLindemann{}von~Lindemann.
Mesmo que esse trabalho de Wantzel é depois da morte de
Galois, ele não aproveitou a teoria de Galois pois
ela demorou bastante para ser publicada (\yearof{1846}), e ainda mais
para ser entendida e aproveitada!

Novamente, é a teoria de Galois que ilumina a situação:
ela oferece as ferramentas para demonstrar com elegância e clareza
todos esses teoremas difíceis!

\endhistory
%%}}}

%%{{{ Permutations 
\section Permutações.
%%%{{{ meta 
%%%}}}

%%{{{ Introduce \sym 3 
\note.
%%%{{{ meta 
\indexes
    * permutação
    ;;
%%%}}}

Vamos começar considerando o conjunto $\sym n$ de todas as permutações
dum conjunto com $n$ elementos.  Tomamos o $\set{1,2,\dotsc,n}$ como
nosso conjunto mas sua escolha é inessencial.
Logo, temos por exemplo
$$
\sym 3 \defeq (\set{1,2,3}\bijto\set{1,2,3}).
$$
Quantos elementos o $\sym 3$ tem?
Lembramos\foot
Se não lembramos, veja a~\ref[total_permutations]
e a~\reftag[Permutations_and_combinations] em geral.
Depois disso, lembramos!
\toof
que são
$$
\card{\sym 3} = \totperm 3 = 3! = 3\ntimes 2\ntimes 1 = 6.
$$
Nosso primeiro objectivo é achar todos esses $6$ membros de $\sym 3$.
\eop
Primeiramente, a identidade $\idof {\set{1,2,3}} \in \sym 3$ pois é bijetora.
Para continuar, introduzimos aqui uma notação bem práctica para
trabalhar com permutações:

%%}}}

%%{{{ notation: notation_with_cycles 
\notation.
%%%{{{ meta 
\label notation_with_cycles
%%%}}}

Denotamos a bijecção $f \in \sym n$ assim:
$$
f = \permf{
1    & 2    & \dotsb & n\\
f(1) & f(2) & \dotsb & f(n)
}
$$
Por exemplo, a identidade de $\sym 3$,
e a permutação $\phi$ que troca apenas o primeiro com o segundo elemento
são denotadas assim:
$$
\xalignat2
\id
&= \permf{
1 & 2 & 3\\
1 & 2 & 3
}
&
\phi
&\asseq \permf{
1 & 2 & 3\\
2 & 1 & 3
}
\endxalignat
$$
Considere agora uma permutação do $\sym 8$ e uma do $\sym {12}$ por exemplo as
$$
\align
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
2 & 3 & 1 & 4 & 6 & 5 & 7 & 8
}
\quad&\text{e}\quad
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\
2 & 3 & 1 & 4 & 5 & 10 & 6 & 11 & 9 & 12 & 8 & 7
}.
\intertext{Podemos quebrá-las em ``ciclos'' escrevendo}
\permc{1 & 2 & 3}
\permc{5 & 6}
\quad&\text{e}\quad
\permc{1 & 2 & 3}
\permc{6 & 10 & 12 & 7}
\permc{8 & 11}
\endalign
$$
respectivamente.
Entendemos o ciclo $\permc{1 & 2 & 3}$ como
$1 \mapsto 2 \mapsto 3 \mapsto 1$:
$$
(
\cdopt{sep=.666cm}
1 \ar[r,maps to] \| 2 \ar[r,maps to] \| 3 \ar[ll,maps to,bend left=36]
\endcd
)
$$
Observe que, por exemplo,
$$
\permc{1 & 3 & 2} = \permc{3 & 2 & 1} = \permc{2 & 1 & 3}
=
\gathered
\tikzpicture
\node (a) at ( 0,.866) {$1$};
\node (b) at (-.5,0)   {$2$};
\node (c) at ( .5,0)   {$3$};
\draw[|->] (a) to [bend left=30] (c);
\draw[|->] (c) to [bend left=30] (b);
\draw[|->] (b) to [bend left=30] (a);
\endtikzpicture
\endgathered
$$
mas mesmo assim preferimos botar o menor número na primeira posição na escrita;
optariamos para o $\permc{1 & 3 & 2}$ nesse caso.

%%}}}

%%{{{ x: verify cycle notation 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que as duas permutações que escrevemos usando ciclos
realmente correspondem nas permutações anteriores.

%%}}}

%%{{{ beware: beware_notation_with_cycles 
\beware.
%%%{{{ meta 
\label beware_notation_with_cycles
%%%}}}

Para usar a notação com ciclos para denotar os membros de algum
$\sym n$, precisamos esclarecer o $n$---algo que não é necessário
com a notação completa, onde esta informação é dedutível pela
sua forma.  Por exemplo as duas permutações
$$
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5\\
2 & 1 & 3 & 5 & 4
}}_{\permc{1 & 2}\permc{4 & 5}}
\qtext{e}
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7\\
2 & 1 & 3 & 5 & 4 & 6 & 7
}}_{\permc{1 & 2}\permc{4 & 5}}
$$
compartilham a mesma forma usando a notação com ciclos!
Olhando para as formas acima, sabemos que a primeira
é uma permutação do $\sym 5$, e a segunda do $\sym 7$.
\eop
Mais um defeito dessa notação é que não temos como denotar
a identidade numa forma consistente: podemos concordar
denotá-la pelo $\permc {1}$ ou $\permc{}$, mas na práctica
optamos para o $\id$ mesmo.

%%}}}

%%{{{ The members of \sym 3 
\note Os membros de $\sym 3$.
%%%{{{ meta 
%%%}}}

Já achamos $2$ dos $6$ elementos de $\sym 3$:
$$
\xalignat2
\id
&=\permf{
1 & 2 & 3\\
1 & 2 & 3
}
&
\phi
&\leteq\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permc{1 & 2}
\endxalignat
$$
Sabendo
que a composição de bijecções é bijecção (\ref[fcom_respects_jections]),
tentamos a
$$
\phi^2 = \phi\com\phi
=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
1 & 2 & 3
}
=\id
$$
e voltamos para a própria $\id$!
Uma outra permutação no $\sym 3$ é a
$$
\psi\leteq\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permc{1 & 2 & 3}.
$$
Vamos agora ver quais diferentes permutações ganhamos combinando essas:
$$
\align
\psi^2
= \psi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
3 & 1 & 2
}
=\permc{1 & 3 & 2}
\\
\phi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
1 & 3 & 2
}
=\permc{2 & 3}\\
\psi\com\phi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
3 & 2 & 1
}
=\permc{1 & 3}
\endalign
$$
E achamos $6$ membros distintos do $\sym 3$.\foot
Por que são distintos?
Veja~\ref[why_phipsi_neq_psiphi] por exemplo.
\toof
Mas $\card{\sym 3} = 6$, e logo achamos \emph{todos} os membros de
$\sym 3 = \set{\id, \phi, \psi, \psi^2, \phi\psi,\psi\phi}$:
$$
\xalignat3
\id  &= \permc {1}         &\psi         &= \permc {1 & 2 & 3}  & \phi\com\psi &= \permc {2 & 3}\\
\phi &= \permc {1 & 2}     &\psi^2       &= \permc {1 & 3 & 2}  & \psi\com\phi &= \permc {1 & 3}.
\endxalignat
$$

%%}}}

%%{{{ remark: is_it_needed_to_compute_last_value_of_perm 
\remark.
%%%{{{ meta 
\label is_it_needed_to_compute_last_value_of_perm
%%%}}}

Preciso mesmo calcular os últimos números das permutações?
Vamos voltar no momento que estamos calculando o $\phi\fcom\psi$;
acabamos de calcular as imagens de $1$ e $2$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| \\
 \aB1                 \| \aB3         \| \aR?
\endcd
$$
Estamos então aqui:
$$
\phi\fcom\psi
=\permf{
1 & 2 & 3\\
\aB1 & \aB3 & \aR?
}
$$
Agora podemos continuar no mesmo jeito, para calcular a imagem de $3$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \ar[d,maps to] \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| 1 \ar[d,maps to] \\
 1                        \| 3                \| 2
\endcd
$$
e assim chegar no
$$
\phi\fcom\psi
=\permf{
1 & 2 & 3\\
1 & 3 & 2
}
$$
Mas, $\phi\fcom\psi$ é uma bijecção (pois $\phi,\psi$ são,
e~\ref[fcom_respects_jections]), e logo podemos concluir desde o penúltimo
passo que $(\phi\fcom\psi)(3) = 2$.
Mesmo assim, sendo humanos, faz sentido achar esse último valor
\emph{com as duas maneiras}.
Assim, caso que elas chegam em resultados diferentes, teriamos um aviso sobre
um erro nos nossos cálculos anteriores!

%%}}}

%%{{{ x: inj_or_surj_needed_to_compute_last_value_of_perm 
\exercise.
%%%{{{ meta 
\label inj_or_surj_needed_to_compute_last_value_of_perm
%%%}}}

Qual das duas propriedades de bijecção estamos usando
na~\ref[is_it_needed_to_compute_last_value_of_perm] para
concluir que $(\phi\psi)\fa 3 = 2$ sem calculá-lo
explicitamente?

\solution
Qualquer uma das duas seria suficiente nesse caso!

%%}}}

%%{{{ x: calculate psi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule a $\psi\com\psi^2$ e justifique que ela é igual à $\psi^2\com\psi$.

\solution
Calculamos:
$$
\align
1 &\mapstoby {\psi^2} 3 \mapstoby \psi 1\\
2 &\mapstoby {\psi^2} 1 \mapstoby \psi 2\\
3 &\mapstoby {\psi^2} 2 \mapstoby \psi 3
\endalign
$$
ou seja, $\psi\com\psi^2 = \id$.
A igualdade é imediata pela associatividade da $\fcom$.
(E ambas são iguais à $\psi^3$.)

%%}}}

%%{{{ x: calculate phi psi^2 and psi^2 phi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule as $\phi\com\psi^2$ e $\psi^2\com\phi$.

%%}}}

%%{{{ note: abstracting_the_notion_of_group 
\note Abstraindo.
%%%{{{ meta 
\label abstracting_the_notion_of_group
%%%}}}

Temos um conjunto cujos elementos podemos ``combinar'' através duma operação binária.
As seguintes propriedades são satisfeitas nesse caso:
\tlist:
\li (G0):
O conjunto é fechado sobre a operação.\foot
Aplicando a operação em quaisquer membros do nosso conjunto,
o resultado pertence ao conjunto.
\toof
\li (G1):
A operação é associatíva.
\li (G2):
A operação tem identidade no conjunto.
\li (G3):
Cada elemento do conjunto possui inverso no conjunto.
\endtlist
Conjuntos onde é definida uma operação que satisfaz essas propriedades
aparecem com freqüência, e vamos ver que são suficientes para construir
uma teoria rica baseada neles.

%%}}}

\endsection
%%}}}

%%{{{ What is a group? 
\section O que é um grupo?.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Seguindo a abstracção do~\reftag[abstracting_the_notion_of_group],
chegamos numa primeira definição:

%%}}}

%%{{{ df: group_def_wordy 
\definition Grupo.
%%%{{{ meta 
\label group_def_wordy
\defines
    * grupo
    ;;
%%%}}}

Um conjunto $G$ com uma operação binária $\ast$ é um \dterm{grupo}
sse:
o $G$ é $\ast$-\emph{fechado};
a $\ast$ é \emph{associativa};
a $\ast$ tem \emph{identidade} no $G$;
cada elemento de $G$ possui $\ast$-\emph{inverso}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Anticipando o dicionário relevante (\ref[dictionary_of_operation_properties])
vamos esclarecer pouco essa definição:

%%}}}

%%{{{ pseudodf: group_def_2_classic 
\pseudodefinition Grupo.
%%%{{{ meta 
\label group_def_2_classic
\defines
    * grupo
    ;;
%%%}}}

Um conjunto $G$ com uma operação binária $\ast$ no $G$ é um \dterm{grupo}
sse as leis seguintes
$$
\gather
a,b \in G \implies a\ast b \in G                                             \tag{G0} \\
a\ast(b\ast c) = (a\ast b)\ast c                                             \tag{G1} \\
\text{existe $e\in G$ tal que para todo $a\in G$, $e\ast a = a = a\ast e$}   \tag{G2} \\
\text{para todo $a\in G$, existe $y\in G$, tal que $y\ast a = e = a \ast y$} \tag{G3}
\endgather
$$
são satisfeitas.
\mistake

%%}}}

%%{{{ Laws vs. axioms 
\note Leis \vs axiomas.
%%%{{{ meta 
\label laws_vs_axioms
\indexes
    * axioma!\vs lei
    ;;
\defines
    * leis de grupo
    * lei
    ;;
%%%}}}

As (G0)--(G3) são conhecidas como \dterm{as leis de grupos},
ou \dterm{os axiomas de grupos}.
Tentarei evitar---mas não sempre!---usar a palavra \emph{axioma}
com esse sentido, optando para a palavra \emph{lei} mesmo,
pois chamamos de ``axioma'' algo que aceitamos como verdade em
nosso univérso (mais sobre isso no~\ref[Axiomatic_set_theory]),
mas nesse caso não estamos afirmando a veracidade das (G0)--(G3).
Faz apenas parte do que significa ``ser grupo''.
Se um conjunto estruturado satisfaz todas as leis,
bem, ele ganha o direito de ser chamado um ``grupo''.
Se não, beleza, ele não é um grupo.

%%}}}

%%{{{ warning: notational_abuse_groups 
\warning abuso notacional.
%%%{{{ meta 
\label notational_abuse_groups
%%%}}}

Lembra-se o abuso notacional que introduzímos
no~\reftag[notational_abuse_structured_sets]:
usamos $a,b\in\ssetfont G$, $G=\sset G {\bullet}$, etc.

%%}}}

%%{{{ Multiplicative and additive groups 
\note Grupos multiplicativos e aditivos.
%%%{{{ meta 
\defines
    * grupo!aditivo
    * grupo!multiplicativo
    ;;
%%%}}}

Dependendo da situação, podemos adoptar um ``jeito multiplicativo''
para a notação dum grupo, ou um ``jeito additivo''---ou ficar
realmente com um jeito neutro.
Num \dterm{grupo multiplicativo} usamos $\cdot$ para denotar a operação do grupo,
aproveitamos a convenção de omitir o símbolo totalmente, usando apenas
juxtaposição: $a(bc)$ significa $a\cdot(b\cdot c)$ por exemplo.
A identidade parecerá com $e$ ou $1$, e $a^{-1}$ será o inverso de~$a$.
Num \dterm{grupo aditivo} usamos $+$ para denotar a operação do grupo,
a identidade parecerá com $e$ ou $0$; e $-a$ será o inverso de~$a$.
Naturalmente usamos $\ast$, $\bullet$, etc.~para denotar operação
de grupo, $e$ para sua identidade, e $a^{-1}$ para denotar o inverso de~$a$.
É importante entender que os termos ``grupo multiplicativo'' e ``grupo aditivo''
usados assim não carregam nenhum significado matemático mesmo: apenas mostram
uma preferência notacional.
Mas quando um conjunto já tem adição e/ou multiplicação definida
(como por exemplo os reais), então usamos frases como
``o grupo aditivo dos reais'' para referir ao $\sset \reals +$,
(como por exemplo os reais), então usamos frases como
``o grupo aditivo dos reais'' para referir ao $\sset \reals +$,
e até ``o grupo multiplicativo dos reais'' para referir ao
$\sset {\reals_{\neq0}} \ntimes$, considerando óbvio o ``sem o zero'',
pois \emph{com} o zero nem é grupo (\ref[numeric_noneg_of_groups_are_really_noneg]).

%%}}}

%%{{{
\blah.
%%%{{{ meta 
%%%}}}

Para entender melhor as quatro leis de grupo, as escrevemos novamente,
essa vez sem deixar nenhum quantificador como implícito,
e começando com um \emph{conjunto estruturado} com uma operação binária:

%%}}}

%%{{{ pseudodf: group_def_2 
\pseudodefinition Grupo (2).
%%%{{{ meta 
\label group_def_2
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast}$ é um \dterm{grupo} sse
$$
\alignat2
\pforall {a,b\in G}                 &\quantified{a\ast b \in G}                   &\tag{G0} \\
\pforall {a,b,c\in G}               &\quantified{a\ast(b\ast c) = (a\ast b)\ast c}&\tag{G1} \\
\pexists {e\in G} \pforall {a \in G}&\quantified{e\ast a = a = a\ast e}           &\tag{G2} \\
\pforall {a\in G} \pexists {y\in G} &\quantified{y\ast a = e = a \ast y}          &\tag{G3} 
\endalignat
$$
Chamamos o elemento garantido pela~(G2) a \dterm{identidade} do grupo,
chamamos o~$y$ da~(G3) o \dterm{inverso} de~$a$.
\mistake

%%}}}

%%{{{ x: check_group_def_classic_and_group_def_2 
\exercise.
%%%{{{ meta 
\label check_group_def_classic_and_group_def_2
%%%}}}

Tá tudo certo com as definições~\reftag[group_def_2_classic]
e~\reftag[group_def_2]?

\hint
Quem é esse $e$ que aparece no (G3)?

\hint
Como assim \emph{o} inverso?

%%}}}

%%{{{ Galois, Abel, Cayley.
\note Galois, Abel, Cayley.
%%%{{{ meta 
%%%}}}

Como vimos, na mesma época o {\Galois}Galois e o {\Abel}Abel chegaram na
idéia abstrata de grupo.  Galois mesmo escolheu a palavra ``group'' para
esse conceito.
A definição ``moderna'' de grupo como conjunto com operação que satisfaz
as leis~(G0)--(G3) é de~{\Cayley}Cayley.
Como Abel focou em grupos cuja operação é comutativa, chamamos esses
grupos de abelianos:

%%}}}

%%{{{ df: abelian group 
\definition Grupo abeliano.
%%%{{{ meta 
\label abelian_group
\defines
    * grupo!abeliano
    ;;
%%%}}}

Um grupo é \dterm{abeliano}
(também: \dterm{comutativo})
sse sua operação é comutativa:
$$
\alignat2
\pforall {a,b\in G}    &\quantified{a\ast b = b\ast a}.   &\tag{GA}
\endalignat
$$

%%}}}

%%{{{ note: groups_and_abelian_groups_schematically 
\note.
%%%{{{ meta 
\label groups_and_abelian_groups_schematically
%%%}}}

Esquematicamente:
$$
\gathered
\text{(fechado)}\\
\text{(associatividade)}\\
\text{(identidade)}\\
\text{(inversos)}\\
\text{(comutatividade)}
\endgathered
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3
\endgathered
}
\text{grupo}\\
\vphantom4\\
\endgathered
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3\\
\vphantom4
\endgathered
}
\text{grupo abeliano}
\endgathered
$$

%%}}}

%%{{{ eg: S3_is_a_non_abelian_group 
\example.
%%%{{{ meta 
\label S3_is_a_non_abelian_group
%%%}}}

Verifique que $\sym 3$ é um grupo.
Ele é abeliano?

\solution.
Precisamos verificar as leis de grupo.
\eop\noi
{(G0).}
Para demonstrar que $\sym 3$ é fechado pela $\fcom$, precisamos verificar
que para todo $a,b\in \sym 3$, $a \fcom b \in \sym 3$.
Pela definição do $\sym 3$, isso segue pelo~\ref[fcom_respects_jections]~(3).
\eop\noi
{(G1).}
Já provamos a associatividade da $\fcom$ na~\ref[fcom_associativity_law].
\eop\noi
{(G2).}
Facilmente verificamos que a $\idof {\set{1,2,3}}$ é a identidade do
$\sset {\sym 3} {\fcom}$, pela sua definição.
\eop\noi
{(G3).}
Cada bijecção tem uma funcção-inversa, que satisfaz as equações dessa lei
pela definição de funcção-inversa.
(Veja~\ref[finverse] e~\ref[finv_is_bij].)
\eop\noi
{(GA).}
Basta mostrar pelo menos um contraexemplo, ou seja, duas permutações
$a,b$ do $\sym 3$ tais que $a\fcom b \neq b\fcom a$.
Agora preciso saber o que significa igualdade entre \emph{funcções}
(\ref[f_eq_g]).
Escolho os $\phi,\psi$.
Já calculamos as $\phi\fcom\psi$ e $\psi\fcom\phi$ e são diferentes.
\eop
Logo, $\sym 3$ é um grupo não abeliano.

%%}}}

%%{{{ x: why_phipsi_neq_psiphi 
\exercise.
%%%{{{ meta 
\label why_phipsi_neq_psiphi
%%%}}}

E por que $\phi\fcom\psi \neq \psi\fcom\phi$?

\solution
Pois elas discordam em pelo menos um valor: tome o $1$.
Agora
$$
(\phi\fcom\psi)(1)
= \phi(\psi(1))
= \phi(2)
= 1
\neq
3
= \psi(2)
= \psi(\phi(1))
= (\psi\fcom\phi)(1).
$$
Logo $\phi\fcom\psi \neq \psi\fcom\phi$.

%%}}}

%%{{{ And why 1 ≠ 3? 
\note E por que 1 ≠ 3?.
%%%{{{ meta 
%%%}}}

Na resolução do~\ref[why_phipsi_neq_psiphi] nosso argumento reduziu
o que queriamos demonstrar à afirmação $1 \neq 3$.
\emph{E por que $1 \neq 3$?}
Bem, precisamos saber o que significa igualdade no $\nats$!
Mas podemos já considerar o $1 \neq 3$ como um fato conhecido sobre os números
naturais.  Depois, no~\ref[Axiomatic_set_theory], vamos \emph{fundamentar}
o~$\nats$ na teoria de conjuntos, e logo vamos ter como realmente demonstrar essa
afirmação para nosso $\nats$, por exemplo.

%%}}}

%%{{{ x: find_all_inverses_on_S3 
\exercise.
%%%{{{ meta 
\label find_all_inverses_on_S3
%%%}}}

Ache o inverso de cada elemento de $\sym 3$.\foot
Se tu já fez isso para resolver o~\ref[S3_is_a_non_abelian_group],
não foi necessário.  Por quê?
Veja a resolução do~\reftag[S3_is_a_non_abelian_group] mesmo.
\toof

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora vamos dar mais uma definição de grupo, essa vez usando um conjunto
estruturado de tipo diferente: além de ter uma operação binária,
tem uma constante também:

%%}}}

%%{{{ df: group_def_20 
\definition Grupo (2,0).
%%%{{{ meta 
\label group_def_20
\defines
    * grupo
    ;;
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast, e}$ é um grupo sse
$$
\alignat2
\pforall {a,b\in G}                 &\quantified{a\ast b \in G}                   &\tag{G0} \\
\pforall {a,b,c\in G}               &\quantified{a\ast(b\ast c) = (a\ast b)\ast c}&\tag{G1} \\
\pforall {a \in G}                  &\quantified{e\ast a = a = a\ast e}           &\tag{G2} \\
\pforall {a\in G} \pexists {y\in G} &\quantified{y\ast a = e = a \ast y}          &\tag{G3}
\endalignat
$$

%%}}}

%%{{{ x: check_group_def_20 
\exercise.
%%%{{{ meta 
\label check_group_def_20
%%%}}}

Tá tudo certo com a~\ref[group_def_20]?

\solution
Sim!
Veja também a~\ref[a_vs_the_identity_of_a_group].

%%}}}

%%{{{ remark: a_vs_the_identity_of_a_group 
\remark.
%%%{{{ meta 
\label a_vs_the_identity_of_a_group
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

O $e$ que aparece na~(G3) não é ``\emph{a} identidade do $\cal G$''.
É sim \emph{a} constante que aparece na estrutura do $\sset G {\ast,e}$,
que---graças à~(G2)---é \emph{uma} identidade do $\cal G$.
No~\ref[uniqueness_of_identity_in_group] vamos demonstrar que cada grupo tem identidade única,
e a partir dessa prova, vamos ganhar o direito de usar o artigo definido ``a''.

%%}}}

%%{{{ Q: can you define group (2,1,0)? 
\question.
%%%{{{ meta 
%%%}}}

Já encontramos definições de grupo como conjunto estruturado com assinaturas
de aridades $(2)$ e $(2,0)$.
Como definarias com assinatura de aridades $(2,1,0)$?

%%}}}

\spoiler

%%{{{ df: group_def_210 
\definition Grupo (2,1,0).
%%%{{{ meta 
\label group_def_210
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast, {}^{-1}, e}$
onde $\ast$ é uma operação binária, ${}^{-1}$ unária, e $e$ uma constante
é um \dterm{grupo} sse:
\tlist:
\li (G0): $G$ é $\ast$-fechado;
\li (G1): $\ast$ é associativa;
\li (G2): $e$ é uma $\ast$-identidade;
\li (G3): para todo $a \in G$, $\ginv a$ é um $\ast$-inverso do $a$.
\endtlist
Formulamente:
$$
\alignat2
\pforall {a,b \in G}   &\quantified{a\ast b \in G}                    &\tag{G0} \\
\pforall {a,b,c \in G} &\quantified{a\ast(b\ast c) = (a\ast b)\ast c} &\tag{G1} \\
\pforall {a \in G}     &\quantified{e\ast a = a = a\ast e}            &\tag{G2} \\
\pforall {a \in G}     &\quantified{a^{-1}\ast a = e = a \ast a^{-1}} &\tag{G3} 
\endalignat
$$

%%}}}

%%{{{ df: order of group 
\definition Ordem de grupo.
%%%{{{ meta 
\label order_of_group
\defines
    * \gord {~G}  -- a ordem do grupo $G$
    * ordem!de grupo
    ;;
%%%}}}

O número de elementos de um grupo $G$ é sua \dterm{ordem}.
Denotamos a ordem de $G$ com:
$\gord G$, $\tord G$, ou até $\bord G$ quando não existe ambigüidade.
Se o carrier set do grupo é infinito, escrevemos
$\gord G = \infty$.

%%}}}

%%{{{ x: group_of_any_finite_order 
\exercise.
%%%{{{ meta 
\label group_of_any_finite_order
%%%}}}

Já conhecemos um grupo finito bem, o $\sym 3$,
com $\gord {\sym 3} = 6$.
No~\ref[Sn_is_a_group] demonstrarás que para todo $n\in\nats$,
o $\sym n$ é um grupo.
Seja $m\in\nats$.
Tem como achar um grupo com ordem $m$?
Observe que como sabemos que $\gord {\sym n} = n!$, podemos já achar
um grupo com ordem $m$ para qualquer $m$ que fosse um fatorial.
Por exemplo, se $m=120$ já temos o grupo $\sym 5$,
pois $\gord {\sym 5} = 5! = 120$.
Mas para um $m$ arbitrário, existe grupo de ordem $m$?

\hint
\ref[The_integers].

%%}}}

%%{{{ remark: G0_is_redundant 
\remark Uma lei que não é lei.
%%%{{{ meta 
%%%}}}

Talvez resolvendo os exercícios~\reftag[check_group_def_classic_and_group_def_2]
e~\reftag[check_group_def_20],
tu já percebeste algo redundante na~\ref[group_def_2]:
\emph{pra que essa (G0)?}
O $\sset G \ast$ é um conjunto estruturado cuja estrutura tem uma
\emph{operação binária}, ou seja uma \emph{funcção}
$$
\ast : G \cross G \to G.
$$
Logo, a (G0) não tem absolutamente nada pra oferecer:
\emph{necessariamente}
$$
\lforall {a,b \in G} {a \ast b \in G}
$$
pois $\ast : G \cross G \to G$.
Observe que se relaxar a definição de conjunto estruturado
para permitir operações \emph{parciais} (\ref[partial_function])
o (G0) vira lei necessária mesmo e afirma simplesmente
que $\ast$ é total.
Mas nosso padrão de operação foi operação total mesmo,
e, nesse sentido, \emph{as leis de grupo} são as (G1)--(G3).\foot
E por isso denotei a primeira com \symq{0}, não foi questão
de começar a conta com o primeiro Nat.
\toof
\emph{Mesmo assim}, é comum encontrar a (G0) como axioma
de grupo, e se tirá-la não ganhamos nada mesmo.
Suponha que tu trabalhas com a (G0) como lei que faz parte
da tua definição de grupo; e teu amigo trabalha apenas com
as (G1)--(G3).
Inicialmente parece que teu amigo vai ter menos trabalho
pra fazer quando precisar demonstrar que um $\sset G \ast$
é um grupo.
Mas não é assim: a definição começa com um
\emph{conjunto estruturado} cuja estrutura inclui a operação
binária $\ast$.
Ou seja, para demonstrar que $\sset G \ast$ é um grupo
ele vai precisar demonstrar que $\ast$ realmente é uma operação
$$
\ast : G \cross G \to G
$$
ou seja, (G0), ou seja, ele não vai ter menos trabalho;
se preocupe não!

%%}}}

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.
%%%{{{ meta 
%%%}}}

%%{{{ eg: with numbers 
\example Com números.
%%%{{{ meta 
%%%}}}

Todos os seguintes conjuntos estruturados são grupos:
\tlist:
\li: $\sset A {+,0}$, onde $A \asseq \ints, \rats, \reals, \complex$;
\li: $\sset B {\ntimes,1}$, onde $B \asseq \rats_{\neq0}, \reals_{\neq0}$;
\li: $\sset C {\ntimes,1}$, onde $C \asseq \set{1,-1}, \set{1,i,-1,-i} \subset\complex$.
\endtlist

%%}}}

%%{{{ noneg: with numbers 
\nonexample Com números.
%%%{{{ meta 
%%%}}}

E \emph{nenhum} dos seguintes é um grupo:
$\sset \nats {+}$;
$\sset \reals {\ntimes,1}$;
$\sset {\ints_{\neq 0}} {\ntimes,1}$;
$\sset \reals {+,1}$.

%%}}}

%%{{{ x: why? : numeric_noneg_of_groups_are_really_noneg 
\exercise.
%%%{{{ meta 
\label numeric_noneg_of_groups_are_really_noneg
%%%}}}

Por quê?

%%}}}

%%{{{ noneg: strings_with_concat_is_not_a_group 
\nonexample Strings.
%%%{{{ meta 
\label strings_with_concat_is_not_a_group
%%%}}}

Sejam $\Sigma\neq\emptyset$ um alfabeto finíto,
e $S$ o conjunto de todos os strings finitos formados por símbolos do $\Sigma$.
O $\sset S +$ onde $+$ é a \emph{concatenação} de strings \emph{não} é um grupo.

%%}}}

%%{{{ x: verify_all_group_laws_for_strings 
\exercise.
%%%{{{ meta 
\label verify_all_group_laws_for_strings
%%%}}}

Para cada uma das leis~(G0)--(GA), decida se é
satisfeita pelo $\sset S +$ do~\ref[strings_with_concat_is_not_a_group].
Se é, demonstre; se não é, refute!

%%}}}

%%{{{ x: shared_carrierset_group_notgroup 
\exercise.
%%%{{{ meta 
\label shared_carrierset_group_notgroup
%%%}}}

Sejam $B = \setst {2^m} {m \in \ints}$ e $B_0 = B \union \set{0}$.
Considere os conjuntos estruturados
$$
\xalignat4
&\sset B {+}
&&\sset B {\ntimes}
&&\sset {B_0} {+}
&&\sset {B_0} {\ntimes}.
\endxalignat
$$
Para cada um deles decida se satisfaz cada uma das leis (G0)--(GA).

%%}}}

%%{{{ x: more number-based groups 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre mais grupos formados de números dos
$\nats$, $\ints$, $\rats$, $\reals$, $\complex$,
e uma operação não-padrão da sua escolha.

%%}}}

%%{{{ eg: matrix_group_examples 
\example Matrizes.
%%%{{{ meta 
\label matrix_group_examples
%%%}}}

Considere os conjuntos seguintes:
$$
\xalignat2
A &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {a,b,c,d \in \reals } &
M &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }.
\endxalignat
$$
O $A$ com a adição de matrízes vira um grupo $\sset A +$,
mas com a multiplicação não: não todos os seus membros tem inverso.
No outro lado, graças à condição no filtro na definição do conjunto $M$,
todos os seus membros são matrízes invertíveis,
e $\sset M {\cdot}$ realmente é um grupo.

%%}}}

%%{{{ x: (M;+) is not a group 
\exercise matrizes.
%%%{{{ meta 
%%%}}}

O $\sset M +$ é?

\hint
Não: tem como adicionar dois matrizes invertíveis e resultar
numa matriz que não é.

\solution
Não é, pois quebra a (G0):
$$
\mubrace {\matrixp{1 & 0\\0 & 1}} {\in \sset M +} +
\mubrace {\matrixp{0 & 1\\1 & 0}} {\in \sset M +} =
\mubrace {\matrixp{1 & 1\\1 & 1}} {\notin \sset M +}.
$$

%%}}}

%%{{{ eg: modular_addition_group_eg 
\example Adição modular.
%%%{{{ meta 
\label modular_addition_group_eg
%%%}}}

O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $+_n$
da adição módulo $n$.
Qual é o inverso de um elemento $a$ nesse caso?
É o $n-a$, pois $a +_n (n-a) = 0 = (n-a) +_n a$.

%%}}}

%%{{{ df: modular addition group 
\definition.
%%%{{{ meta 
\defines
    * \ints_{~n}  -- o grupo aditivo dos inteiros módulo
    ;;
%%%}}}

Denotamos o grupo do~\ref[modular_addition_group_eg] por $\ints_n$.

%%}}}

%%{{{ noneg: modular_multiplication_group_noneg
\nonexample Multiplicação modular.
%%%{{{ meta 
\label modular_arithmetic_group_eg
%%%}}}

O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $\ntimes_n$
da multiplicação módulo $n$, não é um grupo, pois o $0$ não tem inverso.
E se jogar fora o problemático $0$?  Talvez vira um grupo.
Mas não: o $\sset {\set{1,\dotsc,5}} {\ntimes_6}$ também não é um grupo,
pois não é fechado: $2 \ntimes_6 3 = 0$.

%%}}}

%%{{{ df: symmetric_group 
\definition.
%%%{{{ meta 
\label symmetric_group
\defines
    * \sym {~n}  -- o grupo simétrico $\sym n$
    * grupo!simétrico
    ;;
%%%}}}

Usamos $\sym n$ para denotar o conjunto de todas as permutações
dum conjunto de tamanho $n\in\nats$.
Para definir mesmo o $\sym n$ escolhemos o conjunto canônico:
$$
\sym n \pseudodefeq (\set{1,\dotsc,n}\bijto\set{1,\dotsc,n}).
$$
Para qualquer $n\in\nats$, chamamos o $\sset {\sym n} {\fcom}$
o \dterm{grupo simétrico} de tamanho $n$.

%%}}}

%%{{{ x: Sn_is_a_group 
\exercise.
%%%{{{ meta 
\label Sn_is_a_group
%%%}}}

Justifique a~\ref[symmetric_group]: demonstre que o grupo simétrico $\sym n$
realmente é um grupo.
Ele é abeliano?

%%}}}

%%{{{ x: pset_with_setops_group 
\exercise Conjuntos.
%%%{{{ meta 
\label pset_with_setops_group
%%%}}}

Seja $A$ conjunto.
Com quais das operações $\union$, $\inter$, $\symdiff$, e $\setminus$,
o $\pset A$ é um grupo?

%%}}}

%%{{{ x: real_functions_pointwise_plus_group 
\exercise Funcções reais: adição pointwise.
%%%{{{ meta 
\label real_functions_pointwise_plus_group
%%%}}}

O $(\reals \to \reals)$ com operação a pointwise $+$, é um grupo?\foot
Qual operação é a pointwise $+$?  Veja a~\ref[pointwise_operation].
\toof
Ele é abeliano?

%%}}}

%%{{{ x: real_functions_pointwise_times_nongroup 
\exercise Funcções reais: multiplicação pointwise.
%%%{{{ meta 
\label real_functions_pointwise_times_nongroup
%%%}}}

O $(\reals \to \reals) \setminus \set{ \lam x 0 }$ com operação a
pointwise~$\ntimes$, é um grupo?
Ele é abeliano?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Lembre que já usamos $\times$ entre \emph{conjuntos} $A,B$ para formar seu
produto cartesiano $A \times B$; e também entre \emph{funcções} $f : A \to B$,
$g : C \to D$ para formar seu produto
$f \times g : (A\times C) \to (B \times D)$.
Vamos agora sobrecarregar ainda mais esse $\times$:

%%}}}

%%{{{ df: direct_product_of_groups 
\definition Produtos diretos.
%%%{{{ meta 
\label direct_product_of_groups
%%%}}}

Sejam $\cal G_1 = \sset {G_1} {\ast_1}$ e $\cal G_2 = \sset {G_2} {\ast_2}$ grupos.
Definimos o grupo
$$
\cal G_1 \times \cal G_2 = \sset {G_1 \times G_2} {\ast},
$$
onde $\ast$ é a operação definida pela
$$
\tup{x_1, x_2} \ast \tup{y_1, y_2} = \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2}.
$$

%%}}}

%%{{{ x: direct_product_of_groups_is_a_group 
\exercise.
%%%{{{ meta 
\label direct_product_of_groups_is_a_group
%%%}}}

Demonstre que realmente é um grupo.

\solution
\def\xx{\tup{x_1,x_2}}%
\def\yy{\tup{y_1,y_2}}%
\def\zz{\tup{z_1,z_2}}%
Precisamos verificar as leis (G0)--(G3).
\crproofpart{(G0).}
Tome $\xx, \yy \in G_1\times G_2$.
Calculamos
\compute
\xx \ast \yy
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \by {def.~$\ast$} \\
&\in G_1 \times G_2.                    \by {$G_1$ e $G_2$ fechados pelas suas operações} \\
\endcompute
e logo $G_1\times G_2$ é $\ast$-fechado.
\crproofpart{(G1).}
Tome $\xx, \yy, \zz \in G_1\times G_2$.
Calculamos:
$$
\align
\paren{\xx \ast \yy} \ast \zz
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \ast \zz \\
&= \tup{\paren{x_1 \ast_1 y_1} \ast_1 z_1, \paren{x_2 \ast_2 y_2} \ast_2 z_2} \\
&= \tup{x_1 \ast_1 \paren{y_1 \ast_1 z_1}, x_2 \ast_2 \paren{y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\tup{y_1 \ast_1 z_1, y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\yy \ast \zz}.
\endalign
$$
\proofpart{(G2).}
Afirmação: o $\tup{e_1,e_2}\in G_1\times G_2$ é a $\ast$-identidade.
Prova da afirmação: tome $\xx \in G_1\times G_2$ e calcule:
$$
\tup{e_1, e_2} \ast \xx
= \tup{e_1 \ast_1 x_1, e_2 \ast_2 x_2}
= \xx
= \tup{x_1 \ast_1 e_1, x_2 \ast_2 e_2}
= \xx \ast \tup{e_1, e_2}.
$$
\proofpart{(G3).}
Seja $\xx \in G_1 \times G_2$.
Afirmação: o $\tup{\ginv{x_1}, \ginv{x_2}}$ é o $\ast$-inverso dele.
Realmente temos:
$$
\align
\xx \ast \tup{\ginv{x_1}, \ginv{x_2}}
&= \tup{x_1 \ast_1 \ginv{x_1}, x_2 \ast_2 \ginv{x_2}}
 = \tup{e_1, e_2} \\
\tup{\ginv{x_1}, \ginv{x_2}} \ast \xx
&= \tup{\ginv{x_1} \ast_1 x_1, \ginv{x_2} \ast_2 x_2}
 = \tup{e_1, e_2}
\endalign
$$
Assim concluimos nossa prova.

%%}}}

%%{{{ df: gop 
\definition grupo oposto.
%%%{{{ meta 
\label gop
%%%}}}

Seja $\G = \sset G {\ast, \ginv{}, \gid}$ grupo.
Definimos no $\carrier\G$ a operação binária $\ast'$ pela:
$$
x \ast' y = y \ast x.
$$
Chamamos o $\sset G {\ast'}$ de \dterm{grupo oposto do $\G$},
e o denotamos por $\gop\G$.

%%}}}

%%{{{ x: gop_is_a_group 
\exercise.
%%%{{{ meta 
\label gop_is_a_group
%%%}}}

Justifique o nome escolhido na~\ref[gop]:
demonstre que o $\gop\G$ é um grupo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Chegam os exemplos por enquanto.
Vamos começar ver a \emph{teoria} de grupos, investigando propriedades que
todos os grupos necessariamente têm.
Ou seja, procuramos as \emph{conseqüências das leis} (G0)--(G3).

%%}}}

\endsection
%%}}}

%%{{{ First consequences 
\section Primeiras conseqüências.
%%%{{{ meta 
\label First_consequences_of_group_laws
%%%}}}

%%{{{ lm: uniqueness_of_identity_in_group 
\lemma unicidade da identidade.
%%%{{{ meta 
\label uniqueness_of_identity_in_group
\indexes
    * unicidade!da identidade
    ;;
%%%}}}

Em todo grupo $G$ existe único elemento $e$ que satisfaz a (G2).

\sketch.
Seja $G$ grupo.
Sabemos que existe pelo menos uma identidade no $G$ pela (G2),
então precisamos mostrar que existe no máximo uma (unicidade).
Vamos supor que $e_1, e_2$ são identidades do $G$, e usando
as leis~(G0)--(G2) mostrar que $e_1 = e_2$.

\proof.
Seja $G$ grupo.
Sabemos que $G$ tem pelo menos uma identidade graças à (G2),
então o que precisamos mostrar é sua unicidade mesmo.
Suponha que $e_1,e_2\in G$ tais que $e_1,e_2$ são identidades do $G$;
em outras palavras:
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1   \tag{1}\\
\text{para todo $b\in G$},\quad & e_2\ast b \eqlabel L b \eqlabel R b\ast e_2.  \tag{2}
\endalign
$$
Agora exatamente a mesma prova pode ser escrita em dois caminhos
meio diferentes:
\crtabproofalt{Caminho 1:}
Temos
\compute
e_1
&= e_1 \ast e_2  \by {pela (2R), com $b\asseq e_1$} \\
&= e_2           \by {pela (1L), com $a\asseq e_2$} \\
\endcompute
e provamos o que queremos: $e_1 = e_2$, ou seja,
em cada grupo existe única identidade.
\crtabproofalt{Caminho 2.}
Temos
\compute
e_1 \ast e_2 &= e_1  \by {pois $e_2$ é uma R-identidade (2R)} \\
e_1 \ast e_2 &= e_2  \by {pois $e_1$ é uma L-identidade (1L)} \\
\endcompute
e concluimos o desejado $e_1 = e_2$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Uma prova errada desse lemma aparece
no~\ref[bust_proof_of_uniqueness_of_identity_in_group],
onde peço identificar seus erros.

%%}}}

%%{{{ Q: What have we just won? 
\question.
%%%{{{ meta 
%%%}}}

O que acabamos de ganhar?

%%}}}

%%{{{ A: The right to use the definite article 
\note Resposta.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Ganhamos o direito de usar o artigo definido:
para cada grupo~$\cal G$ falar \emph{da}~identidade do~$\cal G$,
em vez \emph{duma}~identidade do~$\cal G$.
Observe que dado algum $a\in \cal G$ ainda não podemos falar sobre
\emph{o}~inverso de~$a$, mas apenas sobre \emph{um}~inverso de~$a$,
pois por enquanto a~(G3) garanta que pelo menos um inverso existe.
Vamos resolver isso agora.

%%}}}

%%{{{ beware: bound_variables_in_proof_of_uniqueness_of_identity_in_group 
\beware.
%%%{{{ meta 
\label bound_variables_in_proof_of_uniqueness_of_identity_in_group
\indexes
    * variável!ligada
    ;;
%%%}}}

Os $a$ e $b$ que aparecem nas~(1)--(2) na demonstração do~\ref[uniqueness_of_identity_in_group]
são \emph{variáveis ligadas} aos correspondentes <<para todo ${\thole} \in G$>>
e logo, ``nascem'' com essa frase e ``morrem'' no fim da mesma linha!\foot
Veja~a~\ref[Variables] também.
\toof
Daí, não faz sentido afirmar logo após das~(1)--(2) algo do tipo $e = a \ast e$, pois o $a$ não foi declarado!
Podemos escrever as duas afirmações sem usar o nome $a$:
\emph{para cada elemento do $G$, operando com o~$e_1$ ao qualquer lado (direito ou esquerdo), o resultado é o próprio elemento}.
E para enfatizar ainda mais a independência do~$a$ que aparece na~(1) com o~$b$ que aparece na~(2) escolhemos variáveis diferentes.
Mas isso é \emph{desnecessário}, em geral vamos reusar variáveis ligadas quando não gera confusão---e aqui não geraria nenhuma.

%%}}}

%%{{{ x: rewrite_proof_with_same_bound_var 
\exercise.
%%%{{{ meta 
\label rewrite_proof_of_uniqueness_of_identity_in_group_with_same_bound_var
%%%}}}

O que muda na demonstração do~\ref[uniqueness_of_identity_in_group] se usar a mesma
variável ligada nas afirmações~(1) e~(2)?

\solution
É apenas escrever
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1 \tag{1}\\
\text{para todo $a\in G$},\quad & e_2\ast a \eqlabel L a \eqlabel R a\ast e_2 \tag{2}
\endalign
$$
e depois
\compute
e_1
&= e_1 \ast e_2     \by {pela (2R), com $a\asseq e_1$} \\
&= e_2.             \by {pela (1L), com $a\asseq e_2$} \\
\endcompute
Observe que os $a$ que aparecem nas instanciações $a \asseq \dots$ são completemante independentes.
Ou seja, nada muda mesmo!

%%}}}

%%{{{ lm: uniqueness_of_inverses_in_group 
\lemma unicidade dos inversos.
%%%{{{ meta 
\label uniqueness_of_inverses_in_group
\indexes
    * unicidade!dos inversos
    ;;
%%%}}}

Em todo grupo $G$, cada $a\in G$ tem
exatamente um inverso $\ginv a$ que satisfaz a (G3).

\sketch.
Supondo que existe um certo $a \in G$ que possui inversos
$a_1,a_2\in G$, mostramos que necessariamente $a_1 = a_2$.
Ganhamos isso como corolário do~\ref[cancellation_laws_in_group].
(Como?)

\proof.
Seja $\sset G {\ast, e}$ grupo, e suponha que existem $a,a_1,a_2\in G$
tais que $a_1,a_2$ são inversos de $a$, ou seja,
\compute
a_1 \ast a &\eqlabel L e \eqlabel R a \ast a_1  \by {$a_1$ é um inverso de $a$} \tag 1 \\
a_2 \ast a &\eqlabel L e \eqlabel R a \ast a_2. \by {$a_2$ é um inverso de $a$} \tag 2 \\
\endcompute
Vamos mostrar que $a_1 = a_2$.
Temos:
\compute
a_1 \ast a &= a_2 \ast a \by {pelas (1L), (2L)} \\
a_1        &= a_2        \by {pelo~\reftag[cancellation_laws_in_group]~(GCR)} \\
\endcompute
e \emph{ficamos devendo} demonstrar a (GCR) do~\ref[cancellation_laws_in_group].

%%}}}

%%{{{ beware: Proof dependencies 
\beware Dependências de demonstrações.
%%%{{{ meta 
%%%}}}

Até realmente demonstrar as leis
de can\-ce\-la\-men\-to~(\reftag[cancellation_laws_in_group]) não temos
a unicidade dos inversos~(\reftag[uniqueness_of_inverses_in_group]).
Dado um elemento $a$ dum grupo $G$ não podemos ainda falar \emph{do}
inverso do $a$, nem usar a notação $\ginv a$ (seria mal-definida), etc.\foot
Na verdade, se a gente usa como definição de grupo a \reftag[group_def_210],
temos como usar a notação $\ginv a$ sim, mas ainda não podemos afirmar que
$\ginv a$ é \emph{a} inversa do $a$.  \emph{Uma}, sim.
\toof
Crucialmente, não podemos usar nada disso em nossa prova
do~\reftag[cancellation_laws_in_group];
caso contrário criamos uma loope de dependências.
``Forward dependencies'' são perigosos exatamente por causa disso,
e nós as evitamos mesmo.\foot
Aqui escolhi essa abordagem para enfatizar a importância de ficar
alertos para identificar chances de afirmar e demonstrar lemmas separadamente,
os usando em nossa prova e para demonstrar outros teoremas depois à vontade.
Fazemos isso exatamente no mesmo jeito que um bom programador
percebe padrões nos seus programas e suas funcções e separa certas partes para
outras funcções, as chamando depois à vontade.
\toof

%%}}}

%%{{{ lm: cancellation_laws_in_group 
\lemma Leis de cancelamento.
%%%{{{ meta 
\label cancellation_laws_in_group
%%%}}}

Seja $\ssetfont G = \sset G {\ast, \gid}$ grupo.
Então as leis de cancelamento pela esquerda e pela direita
$$
\alignat2
\pforall {a,x,y\in G}  &\quantified{a\ast x = a\ast y \implies x=y}  &\tag{GCL} \\
\pforall {a,x,y\in G}  &\quantified{x\ast a = y\ast a \implies x=y}  &\tag{GCR}
\endalignat
$$
são válidas em $G$.

\sketch.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Queremos demonstrar $x=y$.
Tome a~(1) então, e usando umas das leis de grupo---comece com a~(G3)---chegue no desejado $x=y$, demonstrando assim a~(GCL).
A~(GCR) é similar.

\proof.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Pela (G3) o $a$ possui inverso no $G$;
daí, seja $a_0$ \emph{um} inverso de $a$, ou seja,
$$
a_0 \ast a \eqlabel L e  \eqlabel R a \ast a_0.  \tag{2}
$$
Agora temos:
\compute
a_0 \ast (a \ast x) &= a_0 \ast (a \ast y)  \by {pela (1)} \\
(a_0 \ast a) \ast x &= (a_0 \ast a) \ast y  \by {pela (G1): $\ast$ é associativa} \\
e \ast x            &= e \ast y             \by {pela escolha do $a_0$: (2L)} \\
x                   &= y                    \by {pela definição do $e$} \\
\endcompute
Provamos assim a~(GCL).
A~(GCR) é completamente simétrica (e vamos precisar a~(2R) em vez da~(2L)).

%%}}}

%%{{{ x: converses_of_cancellation_laws 
\exercise.
%%%{{{ meta 
\label converses_of_cancellation_laws
%%%}}}

Os conversos das leis de cancelamento~(GCL)~\&~(GCR) são válidos?

\hint
Sim; mas por quê?

\hint
Não precisamos nem saber que $G$ é um grupo nem nada sobre $\ast$, etc.

\solution
Se $x=y$ isso quis dizer que podemos substituir à vontade em cada
\emph{expressão} que envolve $x$ e $y$, uns $x$'s por $y$'s, e vice versa.
Nesse caso, começa com o
$$
a \ast x
$$
e troca a única instância de $x$ nessa expressão por $y$, e já chegamos no
$$
a \ast y
$$
ou seja, $a \ast x = a \ast y$.

%%}}}

%%{{{ x: refute_the_diffside_cancellation_law 
\exercise.
%%%{{{ meta 
\label refute_the_diffside_cancellation_law
%%%}}}

Refuta: para todo grupo $\sset G {\ast, e}$ e $a,x,y\in G$
$$
a\ast x = y\ast a \implies x=y
$$

\hint
Não tem como achar um contraexemplo em grupos abelianos.

\hint
Tem contraexemplo no $\sym 3$.

\hint
Procuramos $a,x,y$ num grupo tais que
$$
ax = ya \nimplies x = y,
$$
ou seja, tais que $ax = ya$ e $x \neq y$.
Mas, o que podemos concluir se $ax = ya$?
$$
ax = ya \implies x = \ginv a y a.
$$
Então nossos $a,x,y$ tem que ser tais que
$x = \ginv a y a$ e mesmo assim $x \neq y$.
Pensando nesses membros como processos e na operação como
``seguindo'' (exatamente a intuição da composição de funcções),
para conseguir um contraexemplo, precisamos achar $a$ e $y$
tais que:
fazendo o $a$, depois o $y$, e depois desfazendo o $a$, não
vai ter o mesmo efeito com o processo de fazer apenas o $y$.

\solution
No $\sym 3$, temos
$$
\phi (\psi\phi) = (\phi\psi) \phi
$$
e mesmo assim
$$
\psi\phi \neq \phi\psi.
$$

%%}}}

%%{{{ x: why_is_this_not_a_counterexample_of_the_diffside_cancellation_law
\exercise.
%%%{{{ meta 
\label why_is_this_not_a_counterexample_of_the_diffside_cancellation_law
%%%}}}

Um aluno achou o seguinte contraexemplo para refutar a lei
no~\reftag[refute_the_diffside_cancellation_law]:
$$
\text{nos reais com multiplicação, temos $0\ntimes 1 = 2\ntimes 0$ mas $1\neq 2$.}
$$
Por que sua resposta é errada?

\hint
O que exatamente é um contraexemplo nesse caso?

%%}}}

%%{{{ x: uniqueness_of_inverses_in_group_proof_without_cancellation 
\exercise.
%%%{{{ meta 
\label uniqueness_of_inverses_in_group_proof_without_cancellation
%%%}}}

Ache uma prova do~\ref[uniqueness_of_inverses_in_group]
que não precisa das leis de cancelamento.

%%}}}

%%{{{ remark: what is your group structure? 
\remark Qual a estrutura dos teus grupos?.
%%%{{{ meta 
%%%}}}

Suponha que na nossa estrutura não temos a operação unária de ${}^{-1}$.
Provando finalmente a unicidade dos inversos
(\reftag[uniqueness_of_inverses_in_group]) ganhamos então em cada
grupo $G$ uma \emph{funcção} (unária) de inverso
$$
\ginvt : G \to G.
$$
Sua \emph{totalidade} já era garantida pela~(G3), que nesse caso é a:
$$
\alignat2
\pforall {a\in G} \pexists {y\in G} &\quantified{y\ast a = e = a \ast y}          &\tag{G3}\\
\intertext{%
e agora acabamos de ganhar sua \emph{determinabilidade} com
o~\ref[uniqueness_of_inverses_in_group].
Ou seja: \emph{funcção!}
Podemos finalmente definir uma notação para denotar o inverso
de qualquer $a\in G$.
Similarmente, se na nossa estrutura não temos a constante $e$,
então demonstrando a unicidade da identidade ganhamos o direito de
definir uma notação para \emph{a} identidade dum grupo $G$.
Cuidado, pois agora a (G2) tá apenas afirmando a existência
\emph{duma} identidade:
}
\pexists {e\in G} \pforall {a \in G}&\quantified{e\ast a = a = a\ast e}           &\tag{G2}
\endalignat
$$
mas graças ao \ref[uniqueness_of_identity_in_group] sabemos
que é única então podemos definir uma notação pra ela.
Vamos fazer essas duas coisas agora:

%%}}}

%%{{{ df: gid 
\definition identidade para estruturas incompletas.
%%%{{{ meta 
\label gid
\defines
    * \gidof {~G}  -- a identidade do grupo $G$
    * \gid  -- a identidade dum grupo implicito pelo contexto
    ;;
%%%}}}

Seja $\sset G \ast$ grupo.
Denotamos a única identidade de $G$ por
$\gidof G$, ou simplesmente $\gid$ se o grupo $G$ já é
implícito pelo contexto.

%%}}}

%%{{{ df: ginv ; gid 
\definition inversos para estruturas incompletas.
%%%{{{ meta 
\label ginv
\defines
    * \ginv {~a}  -- o inverso de $a$ num grupo
    ;;
%%%}}}

Seja $\sset G \ast$ ou $\sset G {\ast,e}$ grupo.
Para qualquer $a\in G$, definimos o
$$
\ginv a \defeq \text{o único inverso de $a$ no $G$}.
$$

%%}}}

%%{{{ beware: choice_of_group_structure_justifications 
\beware a escolha de estrutura: escrevendo justificativas.
%%%{{{ meta 
\label choice_of_group_structure_justifications
%%%}}}

Um matemático tá trabalhando com grupos $\sset G \ast$,
e ta querendo justificar que
$$
a \ast \gidof G = a.
$$
Qual seria a justificativa que ele vai escrever?
Ele não pode dizer <<pela (G2)>>, pois a (G2)
ta afirmando apenas a existência duma identidade;
ela não ta afirmando nada sobre esse $\gidof G$ ali.
A justificativa dele seria:
\standout
\wq{pela definição do $\gidof G$}.
\endstandout
No outro lado, um matemático que trabalha com grupos
cuja estrutura já tem a constante $e$ nela, ou seja,
com grupos $\sset G {\ast, e}$ ou $\sset G {\ast, {}^{-1}, e}$,
justificaria o mesmo passo assim:
\standout
\wq{pela (G2R)}.
\endstandout
Similarmente sobre a justificativa de uma igualdade como a
$$
\ginv a \ast a = \gidof G.
$$
Um matemático que trabalha com $\sset G {\ast, {}^{-1}, e}$
justificaria com um simples
\standout
\wq{pela (G3L)}.
\endstandout
Mas para os matemáticos que não tem a operação de inverso
na sua estrutura, a justificativa seria
\standout
\wq{pela definição do $\ginv a$}.
\endstandout
Nesse texto vou usar ambas as abordagens.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo ganhado unicidade da identidade e dos inversos,
vamos responder agora em duas perguntas.

%%}}}

%%{{{ Q1: When is y the inv(a)? 
\question 1.
%%%{{{ meta 
%%%}}}

Num grupo $G$, dado $a\in G$,
o que precisamos mostrar para demonstrar que um certo $y\in G$ é o inverso de $a$?

%%}}}

%%{{{ wrong answer 
\note Resposta errada.
%%%{{{ meta 
%%%}}}

Basta mostrar que $a \ast y = e$
(ou, alternativamente, que $y \ast a = e$)
pois, \emph{graças à unicidade dos inversos},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $y = \ginv a$.

%%}}}

%%{{{ Q2: When is u the identity? 
\question 2.
%%%{{{ meta 
%%%}}}

Num grupo $G$, o que precisamos mostrar para demonstrar que um certo $u\in G$ é a identidade do grupo?

%%}}}

%%{{{ wrong answer 
\note Resposta errada.
%%%{{{ meta 
%%%}}}

Basta achar um $a\in G$ tal que $a \ast u = a$
(ou, alternativamente, tal que $u \ast a = a$),
pois, \emph{graças à unicidade da identidade},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $u = e$.

%%}}}

%%{{{ Where's the mistake? 
\note Cadê o erro?.
%%%{{{ meta 
%%%}}}

O \emph{raciocínio} nas duas respostas é errado numa maneira parecida:
\eop
Na (1), pode ser que $y$ satisfaz a $a\ast y = e$ sem $y$ ser o inverso do $a$.
\emph{E isso não violaria a unicidade do inverso $\ginv a$},
pois pela definição de \emph{inverso do $a$}, ambas equações $a \ast y = e = y \ast a$
precisam ser satisfeitas, e talvez $y \ast a \neq e$.
\eop
Na (2), pode ser que $u$ satisfaz $a \ast u = a$ para algum membro $a \in G$ sem $u$ ser a identidade do grupo.
\emph{E isso não violaria a unicidade da identidade $e$},
pois pela definição de \emph{identidade do $G$}, o $u$ precisa satisfazer ambas as $a \ast u = e = u \ast e$ e mesmo se satisfaria ambas isso não seria sufiziente: ele tem que as satisfazer não apenas \emph{para algum} $a\in G$ que deu certo, mas \emph{para todo} $a\in G$!
Ou seja: o fato que achamos \emph{algum} $a \in G$ tal que $a \ast u = a (= u \ast a)$
não quis dizer que esse $u$ merece ser chamado \emph{a identidade do $G$} ainda,
pois talvez tem membros $c \in G$ tais que $c \ast u \neq c$ ou $u \ast c \neq c$.

%%}}}

%%{{{ warning: wrong_reasoning_nimplies_wrong_claim_group_eg 
\warning.
%%%{{{ meta 
\label wrong_reasoning_nimplies_wrong_claim_group_eg
%%%}}}

Os raciocínios acima sendo errados não quis dizer que as afirmações também são!
Na verdade, nos dois casos podemos realmente ganhar o que queremos:
identidades e inversos \emph{mais baratos}, sem pagar todo o preço das definições.
Ambos resultados seguem como corolários diretos do~\ref[group_latin_square]
que vamos demonstrar daqui a pouco.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por enquanto, vamos continuar pesquisando o que mais podemos concluir assim
que tivermos um grupo~$G$, e voltaremos logo nessas duas questões.

%%}}}

%%{{{ Q: Can we conclude something about these? 
\question.
%%%{{{ meta 
%%%}}}

Se $a,b$ são membros de algum grupo $\sset G {\ast,e}$, podemos concluir algo sobre os\dots
$$
\align
\ginv {e}           &\askeq \dots?\\
\ginvp{\ginv a}     &\askeq \dots?\\
\ginvp{a \ast b}    &\askeq \dots?
\endalign
$$

%%}}}

\spoiler

%%{{{ A: yes, but we need to prove them 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Sim:
$$
\align
\ginv  e            &\askeq e\\
\ginvp{\ginv a}     &\askeq a\\
\ginvp{a \ast b}    &\askeq \ginv b \ast \ginv a.
\endalign
$$
Mas precisamos demonstrar cada uma delas.

%%}}}

%%{{{ different_interpretations_of_same_eq 
\note Interpretações diferentes.
%%%{{{ meta 
\label different_interpretations_of_same_eq
%%%}}}

Considere a primeira afirmação acima:
$$
\ginv e = e.
$$
De quantas maneiras podemos ler (entender) essa equação,
e o que seria uma prova de cada uma dessas maneiras?
$$
\xxalignat3
\text{\crcase{Maneira 1:}}&&
\tubrace {\ginv \gid} {isso}
&\tubrace {=} {é}
\tubrace {\gid} {a identidade do grupo.}&&\\\\
\text{\case{Maneira 2:}}&&
\tubrace {\aR \gid} {\aR {isso}}
&\tubrace {=} {é}
\tubrace {\ginv {\aB \gid}} {o inverso de $\aB \gid$.}&&\\\\
\text{\case{Maneira 3:}}&&
\tubrace {\ginv \gid} {isso}
&\tubrace {=} {é}
\tubrace {\gid} {isso.}&&\text{\phantom{\case{Maneira 0:}}}
\endxxalignat
$$
Com a primeira, o que precisamos mostrar é que o objeto $\ginv \gid$
satisfaz a definição de ser a identidade do grupo, ou seja:
$$
\text{para todo $a \in G$, $\ginv \gid \ast a = a = a \ast \ginv \gid$}.
$$
Com a segunda, precisamos mostrar que a \aR{coisa vermelha}
é o inverso da \aB{coisa azul}.
Mas o que significa ser inverso de algo?
Precisamos mostrar que:
$$
\align
\aR \gid \ast \aB \gid &= \gid\\
\aB \gid \ast \aR \gid &= \gid.
\endalign
$$
Com a terceira, a única coisa que podemos fazer é começar calcular
até finalmente chegar nessa igualdade.

%%}}}

%%{{{ advice: read_the_same_equation_in_different_ways 
\advice.
%%%{{{ meta 
\label read_the_same_equation_in_different_ways
%%%}}}

Cada vez que tu queres demonstrar uma igualdade que envolve certas
noções, tente ``ler'' o que a igualdade realmente afirma em
várias maneiras diferentes.  Cada uma é uma chance para te dar
uma idéia de como prová-la!

%%}}}

%%{{{ lemma: inverse_of_identity_in_group 
\lemma inverso da identidade.
%%%{{{ meta 
\label inverse_of_identity_in_group
%%%}}}

Em todo grupo $G$, $\ginv e = e$.

\proof.
Basta mostrar que $e$ é o inverso de $e$, ou seja,
que ele satisfaz $ee = e$, algo imediato pela definição da identidade $e$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Das três maneiras analizadas acima, escolhi a segunda.
Investigue as outras duas:

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

Ache uma demonstração alternativa do~\ref[inverse_of_identity_in_group],
baseada na primeira maneira do~\reftag[different_interpretations_of_same_eq].

\solution
Precisamos mosrar que
$$
\text{para todo $a \in G$, $\ginv e \ast a = e = a \ast \ginv e$}.
$$
Seja $a \in G$.
Vamos mostrar que o $\ginv e$ ``deixa o $a$ em paz'' pelos dois lados.
Calculamos:
\compute
\ginv e \ast a
&= \ginv e \ast (e \ast a)  \by {$a = e\ast a$} \\
&= (\ginv e \ast e) \ast a  \by {G1} \\
&= e \ast a                 \by {def.~de $\ginv e$} \\
&= a                        \by {def.~de $e$} \\
\endcompute
Ou outro lado é similar.

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

E uma baseada na terceira.

\solution
Calculamos:
\compute
\ginv e
&= \ginv e \ast e   \by {def.~$e$} \\
&= e                \by {def.~$\ginv e$} \\
\endcompute

%%}}}

%%{{{ lm: inverse_of_inverse_in_group 
\lemma inverso de inverso.
%%%{{{ meta 
\label inverse_of_inverse_in_group
%%%}}}

Em todo grupo $G$, $\ginvp {\ginv a} = a$ para todo $a\in G$.

\sketch.
Uma maneira de ler a afirmação: {\proclaimstyle <<$a$ é o inverso de $\ginv a$>>}.
Usando o que significa ser inverso de alguém chegamos no resultado.
Alternativamente, usamos as definições dos inversos envolvidos para ganhar duas equações.
Com elas, chegamos na equação desejada.

\proof.
Vamos ver duas maneiras de demonstrar isso:
\crproofalt{Maneira 1:}
Basta demonstrar que $a$ satisfaz a propriedade de
ser inverso do $\ginv a$:
$$
a \ginv a \eqlabel L e \eqlabel R \ginv a a
$$
e ambas são imediatas: a (L) pela (G3R), e a (R) pela (G3L).
\crproofalt{Maneira 2:}
Pelas definições de $\ginvp{\ginv a}$ e $\ginv a$ ganhamos
as equações:
\compute
\ginvp{\ginv a} \ast \ginv a &= e   \by {def.~$\ginvp{\ginv a}$} \\
a               \ast \ginv a &= e.  \by {def.~$\ginv a$} \\
\intertext{Logo}
\ginvp{\ginv a} \ast \ginv a &= a \ast \ginv a
\endcompute
e cancelando agora pela direita (GCR), chegamos na desejada
$\ginvp{\ginv a} = a$.

%%}}}

%%{{{ x: cd 
\exercise.
%%%{{{ meta 
%%%}}}

Desenha um diagrama cuja comutatividade é a lei que tu acabou de demonstrar.

\solution
$$
\cdopt{sep=2cm}
A   \ar[r, "\ginvt"]\ar[dr, "\id"'] \| A \ar[d, "\ginvt"] \\
                                    \| A
\endcd
$$

%%}}}

%%{{{ remark: where did the inversion come from 
\remark.
%%%{{{ meta 
%%%}}}

É comum adivinhar erroneamente que em geral
$\ginvp{a \ast b} = \ginv a \ast \ginv b$.
O erro é feito pois, acostumados com certos grupos \emph{bem especiais}
como o $\sset {\reals_{\neq0}} {\ntimes}$ (onde essa lei realmente é válida),
generalizamos para o caso geral de grupos, sem perceber algo estranho e
esquisito que acontece nessa equação.  Repensanso em nosso exemplo-guia de
grupos, o~$\sym 3$, o que significa~$a \ast b$?
<<Faça a~$b$, depois a~$a$.>>
E o que signfica $\ginvp{a \ast b}$ então?
<<Desfaça a~$\paren{a \ast b}$.>>
E se aplicar uma transformação~$b$, e depois mais uma~$a$, qual seria o jeito
para desfazer tudo isso e voltar na configuração inicial?
<<Desfaça a~$a$, e depois desfaça a $b$.>>
Ou seja,~$\ginv b \ast \ginv a$.
Isso é bem natural sim: para desfazer uma seqüência de ações, começamos
desfazenso a última, depois a penúltima, etc., até finalmente desfazer
a primeira.
Sendo o inverso então, faz sentido que \emph{a ordem é a inversa também!}
E nos reais, por que não foi a inversa?
Foi sim!
É apenas que o~$\sset {\reals_{\neq0}} {\ntimes}$ é um grupo abeliano;
em outras palavras a ``ordem que acontecem os membros'' não importa.
Mas tudo isso é apenas uma \emph{intuição correta} para adivinhar essa lei.
Precisamos demonstrá-la.  Bora!

%%}}}

%%{{{ lm: inverse_of_product_in_group 
\lemma inverso de produto.
%%%{{{ meta 
\label inverse_of_product_in_group
%%%}}}

Em todo grupo $G$, $\ginvp{a\ast b} = \ginv b \ast \ginv a$
para todo $a,b\in G$.

\sketch.
Queremos mostrar que $\ginv b \ast \ginv a$ é o inverso do $a \ast b$.
Mas o que <<ser o inverso do $a \ast b$>> significa?
Precisamos verificar que o $\ginv b \ast \ginv a$ satisfaz a definição:
$$
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b} = e = \paren{a \ast b} \ast \paren{\ginv b \ast \ginv a}.
$$
Agora só basta fazer esse cálculo mesmo.

\proof.
Calculamos
\compute
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b}
&= \paren{\paren{\ginv b \ast \ginv a} \ast a} \ast b   \by {assoc.} \\
&= \paren{\ginv b \ast \paren{\ginv a \ast a}} \ast b   \by {assoc.} \\
&= \paren{\ginv b \ast e} \ast b                        \by {def.~$\ginv a$} \\
&= \paren{\ginv b} \ast b                               \by {def.~$e$} \\
&= e                                                    \by {def.~$\ginv b$} \\
\endcompute
A $\paren{a \ast b} \ast \paren{\ginv b \ast \ginv a} = e$ é similar.

%%}}}

%%{{{ x: cd 
\exercise.
%%%{{{ meta 
%%%}}}

Desenha um diagrama cuja comutatividade é a lei que tu acabou de demonstrar.

\hint
A idéia é descrever cada lado da
$$
\ginvp{a\ast b} = \ginv b \ast \ginv a
$$
como um caminho.
Pense em duas listas de instruções para ser aplicadas no $\tup{a,b}$,
tais que:
seguindo uma das listas acabamos no $\ginv b \ast \ginv a$,
e seguindo a outra no $\ginvp{a\ast b}$.
Para o lado $\ginvp{a\ast b}$ existe apenas uma maneira razoável
de ``quebrá-lo'' em sub-passos.
Para o lado $\ginv b \ast \ginv a$ existem duas equivalentes.
Escolha uma, ou desenha as duas no mesmo diagrama.

\hint
Podes começar com os conjuntos seguintes:
$$
\cdopt{column sep=1cm, row sep=1cm}
            \| G\times G\ar[d]\ar[rrrr] \|           \| \| \| G\ar[dd] \\
            \| G\times G\ar[d]          \|           \| \| \|   \\
            \| G\times G\ar[rrrr]       \|           \| \| \| G
\endcd
$$
A coluna esquerda corresponde num caminho do $\tup{a,b}$
para o $\tup{\ginv b, \ginv a}$.

\hint
Substitui a coluna esquerda por dois caminhos formando o rombo
na esquerda (ele comuta):
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W]
\ar[from=N,to=E]
\ar[from=W,to=S]
\ar[from=E,to=S]
\ar[from=N,to=NE]
\ar[from=NE,to=SE]
\ar[from=S,to=SE]
\endcd
$$
Agora só basta botar nomes nas setas.

\solution
Uma tal diagrama é o seguinte:
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W,"\swap"']
\ar[from=N,to=E,"\ginvt\times\ginvt"]
\ar[from=W,to=S,"\ginvt\times\ginvt"']
\ar[from=E,to=S,"\swap"]
\ar[from=N,to=NE,"\ast"]
\ar[from=NE,to=SE,"\ginvt"]
\ar[from=S,to=SE,"\ast"]
\endcd
$$
onde $\swap(x,y) = \tup{y,x}$.

%%}}}

%%{{{ lemma: group_latin_square 
\lemma resolução de equações: Latin square.
%%%{{{ meta 
\label group_latin_square
%%%}}}

Seja $G$ grupo.
Para quaisquer $a,b,x,y\in G$,
cada uma das equações abaixo tem resolução única para $x$ e $y$:
$$
\xalignat2
a\ast x &= b
&
y\ast a &= b
\endxalignat
$$

\sketch.
Aplicando o inverso de $a$ em cada equação pelo lado certo,
achamos que as soluções necessariamente são
$x = \ginv a \ast b$ e $y = b \ast \ginv a$.

\proof.
Aplicando $(a^{-1}\ast)$ nos dois lados da primeira
e $(\ast a^{-1})$ nos dois lados da segunda temos:
$$
\xalignat2
  a\ast x = b &\impliesbecause{$\ginv a\ast$} \ginv a\ast \paren{a\ast x} = a^{-1} \ast b 
& y\ast a = b &\impliesbecause{$\ast\ginv a$} \paren{x\ast a}\ast \ginv a = b \ast \ginv a
\\
&\implies\paren{\ginv a\ast a}\ast x = \ginv a \ast b
&&\implies y\ast \paren{a\ast \ginv a} = b \ast \ginv a
\\
&\implies e \ast x = \ginv a \ast b
&&\implies y\ast e = b \ast \ginv a
\\
&\implies x = \ginv a \ast b
&&\implies y = b \ast \ginv a
\endxalignat
$$

%%}}}

%%{{{ remark: ab_eq_c_each_determined_by_other_two 
\remark.
%%%{{{ meta 
\label ab_eq_c_each_determined_by_other_two
%%%}}}

Isso quis dizer que dada uma equação $a \ast b = c$,
cada um dos $a,b,c$ é determinado pelos outros dois!
Assim, podemos \emph{definir} por exemplo o objeto $x$
como \emph{a única solução da} $a\ast x = b$, etc.

%%}}}

%%{{{ cor: cheaper_ginv 
\corollary inversos mais baratos.
%%%{{{ meta 
\label cheaper_ginv
%%%}}}

Seja $G$ grupo e $a,y \in G$
tais que $a\ast y = e$ ou $y \ast a = e$.
Logo $y = \ginv a$.

%%}}}

%%{{{ cor: cheaper_gid 
\corollary identidade mais barata.
%%%{{{ meta 
\label cheaper_gid
%%%}}}

Seja $G$ grupo $u\in G$.
Se para algum $a\in G$, $au = a$ ou $ua = a$, então $u$ é a identidade do grupo:
$u = e$.

%%}}}

%%{{{ x: cheaper_ginv_and_gid_by_cancellation 
\exercise.
%%%{{{ meta 
\label cheaper_ginv_and_gid_by_cancellation
%%%}}}

Ganhamos esses resultados (\ref[cheaper_ginv] e~\reftag[cheaper_gid])
como corolários do~\ref[group_latin_square].
Mostre como ganhá-los como corolários das leis de cancelamento.

%%}}}

%%{{{ x: abelian_iff_inv_of_prod_sameorder 
\exercise.
%%%{{{ meta 
\label abelian_iff_inv_of_prod_sameorder
%%%}}}

Seja $G$ grupo.
Demonstre a equivalência:
$$
\text{$G$ abeliano} \iff \text{para todo $a,b\in G$, $\ginvp{ab} = \ginv a \ginv b$}.
$$

\solution
\lrdir.
Calculamos:
\compute
\ginvp{ab}
&= \ginv b \ginv a      \by {pelo~\ref[inverse_of_product_in_group]} \\
&= \ginv a \ginv b.     \by {$G$ abeliano} \\
\endcompute
\rldir.
Calculamos:
\compute
ab
&= \ginvp{\ginvp{ab}}               \by {pelo~\ref[inverse_of_inverse_in_group]} \\
&= \ginvp{\ginv b \ginv a}          \by {pelo~\ref[inverse_of_product_in_group]} \\
&= \ginvp{\ginv b} \ginvp{\ginv a}  \by {pela hipótese} \\
&= b a.                             \by {pelo~\ref[inverse_of_inverse_in_group]~($\times2$)} \\
\endcompute

%%}}}

%%{{{ criterion: cancellation_based_group_def 
\criterion Definição de grupo com cancelamento.
%%%{{{ meta 
\label cancellation_based_group_def
%%%}}}

Seja $\ssetfont G = \sset G \ast$ um conjunto \emph{finito} estruturado
que satisfaz:
$$
\align
\pforall {a,b\in G}    &\quantified{a\ast b \in G}                    \tag{G0} \\
\pforall {a,b,c\in G}  &\quantified{a\ast(b\ast c) = (a\ast b)\ast c} \tag{G1} \\
\pforall {a,x,y\in G}  &\quantified{a\ast x = a\ast y \implies x=y}   \tag{GCL}\\
\pforall {a,x,y\in G}  &\quantified{x\ast a = y\ast a \implies x=y}   \tag{GCR}
\endalign
$$
Então $\ssetfont G$ é um grupo.

\proof.
\ref[cancellation_based_group_def_proof]

%%}}}

%%{{{ x: cancellation_based_group_def_only_valid_for_finite_G 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre que não podemos apagar o ``finito'' das nossas hipoteses.

\hint
Procure contraexemplo!

\solution
Veja~\ref[how_come_the_cancellation_laws_hold_in_nongroup_without_inverses].

%%}}}

%%{{{ criterion: onesided_group_def 
\criterion Definição unilateral ``one-sided'' de grupo.
%%%{{{ meta 
\label onesided_group_def
%%%}}}

Seja $\ssetfont G = \sset G {\ast,e}$ um conjunto estruturado que satisfaz:
$$
\align
\pforall {a,b\in G}                 &\quantified{a \ast b \in G}                    \tag{G0}  \\
\pforall {a,b,c\in G}               &\quantified{a \ast (b \ast c) = (a \ast b) \ast c} \tag{G1}  \\
\pforall {a \in G}                  &\quantified{a \ast e = a}                      \tag{G2R} \\
\pforall {a\in G} \pexists {y\in G} &\quantified{a \ast y = e}                     \tag{G3R} \\
\intertext{%
Então $\ssetfont G$ é um grupo.
Similarmente se adicionar as
}
\pforall {a \in G}                  &\quantified{e \ast a = a}                      \tag{G2L} \\
\pforall {a\in G} \pexists {y\in G} &\quantified{y \ast a = e}                      \tag{G3L}
\endalign
$$

\proof.
\ref[onesided_group_def_proof].

%%}}}

%%{{{ x: onesided_group_def_catch 
\exercise.
%%%{{{ meta 
\label onesided_group_def_catch
%%%}}}

Verifique que mesmo se conseguir demonstrar as
$$
\align
\pforall {a \in G}                    &\quantified{e \ast a = a}   \tag{G2L} \\
\pforall {a \in G} \pexists {y \in G} &\quantified{y \ast a = e}   \tag{G3L}
\endalign
$$
isso não nos permite deduzir trivialmente as (G2) e (G3)!
Explique o porquê.

%%}}}

%%{{{ x: splitsided_group_notdef 
\exercise.
%%%{{{ meta 
\label splitsided_group_notdef
%%%}}}

Podemos substituir a (G3R) do~\ref[onesided_group_def] por
$$
\align
\pforall {a \in G} \pexists {y \in G} &\quantified{y \ast a = e}   \tag{G3L}
\endalign
$$
e ainda concluir que $\ssetfont G$ é grupo?
Ou seja, se a operação possui R-identidade,
e se cada membro tem L-inverso, o $\ssetfont G$
é necessariamente um grupo?
(Obviamente a resposta na pergunta simétrica deve ser a mesma.)

\hint
Não!

\hint
Procure um contraexemplo.
(Claramente, a operação não pode ser comutativa.)

\hint
Dá pra construir contraxemplo com apenas $2$ membros.

\hint
Considere como operação binária a $\outl$.

\solution
Seja $A = \set{\idr,a}$ um conjunto com dois membros.
Definimos a operação $\ast$ pela:
$$
x \ast y = x.
$$
Confirmamos que $\sset A \ast$ satisfaz todas as
(G0),(G1),(G2R),(G3L), mas mesmo assim não é um
grupo: não tem identidade, pois a $\idr$ não serve
como L-identidade:
$$
\idr \ast a = \idr \neq a.
$$

%%}}}

\endsection
%%}}}

%%{{{ Cayley tables 
\section Tabelas Cayley.
%%%{{{ meta 
\label Cayley_tables
%%%}}}

%%{{{ Q: In how many ways can we define an operation to create a finite group? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos definir uma operação binária $\ast$
num conjunto finito $G$, tal que $\sset G \ast$ é um grupo?

%%}}}

\spoiler

%%{{{ What determines an operation 
\note O que determina uma operação.
%%%{{{ meta 
%%%}}}

O que significa \emph{definir uma operação} (binária)?
Seguindo nossa definição de igualdade (extensional) entre funcções,
precisamos deixar claro para qualquer $\tup{x,y}\in G\times G$,
seu único valor $x \ast y \in G$.
Vamos brincar com os casos mais simples.
Se $\card G = 0$, não tem como virar um grupo,
pois todo grupo tem pelo menos um membro: sua identidade.
Se $\card G = 1$, só tem uma operação possível, pois não existe
nenhuma opção para o valor $e \ast e$: necessariamente $e \ast e = e$.
E essa opção realmente vira-se o $\sset G \ast$ um grupo (trivial).

%%}}}

%%{{{ 234_groups 
\note Os casos 2,3,4.
%%%{{{ meta 
%%%}}}

Vamos dizer que temos um conjunto $G$ com $\card G = 4$.
Não sabemos nada sobre seus membros, podem ser números, letras, pessoas,
funcções, conjuntos, sapos, sei-lá:
$$
G = \set{ \bullet, \bullet, \bullet, \bullet }.
$$
Então faz sentido começar nossa investigação dando uns nomes para
esses membros, por exemplo $a,b,c,d$, onde não vamos supor nada mais
sobre eles exceto que são distintos dois-a-dois.
$$
\text{<<Sejam $G\eqass\set{a,b,c,d}$.>>}
$$
Sera que podemos fazer algo melhor?
Querendo tornar o $G$ em grupo, sabemos que ele vai ter exatamente uma
identidade, então melhor denotá-la com $e$,
e escolher nomes para os outros três membros do $G$:
$$
G = \set {e, a, b, c}.
$$
Similarmente, caso que $\card G = 2$ ou $3$, teremos
$G = \set {e, a}$
ou
$G = \set {e, a, b}$
respectivamente.

%%}}}

%%{{{ Cayley tables 
\note Tabelas Cayley.
%%%{{{ meta 
\defines
    * tabela!Cayley
    ;;
%%%}}}

{\Cayley[tabela]}%
Temos então que ver o que podemos botar nos $\faded?$ para completar
as \dterm{tabelas Cayley} abaixo:
$$
\xalignat3
\matrix
\ast& e & a \\
e   & \faded? & \faded? \\
a   & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & \faded? & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded? & \faded? \\
c   & \faded? & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$
Mas, não todos os $\faded?$ realmente representam uma escolha,
pois certos deles são determinados; e cada vez que fazemos uma escolha
para um deles, possivelmente nossas opções próximas deminuiam.
Para começar, como $e\ast x = x = x \ast e$ para qualquer $x$ do grupo,
a primeira linha e a primeira coluna da tabela já são determinadas:\foot
De fato, foi por isso que Cayley realmente nem escreveu a coluna
e a linha ``exterior'', tomando a convenção que o elemento que aparece
primeiro é a sua identidade.
Para um grupo de três elementos então, ele começaria assim:
$$
\matrix
a & b       & c       \\
b & \faded? & \faded? \\
c & \faded? & \faded?
\endmatrix
\qquad
\text{que, seguindo nossa convenção com \symq{$e$}, escreveríamos}
\qquad
\matrix
e & a       & b       \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
$$
\toof
$$
\xalignat3
\matrix
\ast& e & a \\
e   & e & a \\
a   & a & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & e & a & b \\
a   & a & \faded? & \faded? \\
b   & b & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & e & a & b & c \\
a   & a & \faded? & \faded? & \faded? \\
b   & b & \faded? & \faded? & \faded? \\
c   & c & \faded? & \faded? & \faded?
\endmatrix
&
\intertext{Exatamente por causa dessa observação, em geral omitimos a
primeira coluna e a primeira linha dessas tabelas, escrevendo as três
tabelas acima nesse jeito:}
\matrix
e & a \\
a & \faded?
\endmatrix
&&
\matrix
e & a & b \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
&&
\matrix
e & a & b & c \\
a & \faded? & \faded? & \faded? \\
b & \faded? & \faded? & \faded? \\
c & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$

%%}}}

%%{{{ Q: how can we replace the blanks? 
\question.
%%%{{{ meta 
%%%}}}

O que tu podes botar nos\/ $\faded?$ para chegar num grupo?
O que muda se tu queres construir um grupo abeliano?

%%}}}

\spoiler

%%{{{ 2 members 
\note 2 membros.
%%%{{{ meta 
%%%}}}

Vamos começar no caso mais simples, onde temos apenas um $\faded?$ para preencher.
Em teoria temos duas opções: $e,a$.  Mas precisamos verificar se o conjunto
realmente torna-se um grupo ou não.  Escolha $a$:
$$
\matrix
e & a \\
a & \alert a
\endmatrix
$$
Qual seria o inverso do $a$?
Nenhum!
Assim o~(G3) será violado, ou seja, não podemos escolher o $a$.
Se escolher nossa única outra opção ($e$) temos:
$$
\matrix
e & a \\
a & \alert e
\endmatrix
$$
Que realmente é um grupo.

%%}}}

%%{{{ x: Verify! 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique!


%%}}}

%%{{{ x: find_all_groups_of_order_3 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_3
%%%}}}

Ache todas as operações possíveis que tornam um conjunto com $3$ membros um grupo.

\hint
Só tem uma maneira.  Qual?  Por quê?

\solution
Só tem uma maneira:
$$
\matrix
e & a & b\\
a & b & e\\
b & e & a
\endmatrix
$$
Realmente não temos nenhuma opção em nenhum dos $\faded?$.
O~\ref[find_the_rules_of_grupoku] investiga o porquê.

%%}}}

%%{{{ Playing ``grupoku'' 
\note Jogando ``Grupoku''.
%%%{{{ meta 
\defines
    * Grupoku
    ;;
%%%}}}

Investigar todas as possíveis escolhas para os~$\faded?$ parece como um jogo
de Sudoku, só que nossa restricção não é com a soma dos números de cada linha e
cada coluna como no Sudoku---nem poderia ser isso: nossos membros possivelmente
nem são números---mas as leis~(G0)--(G3) que tem que ser satisfeitas.
E caso que queremos criar um grupo abeliano, a~(GA) também.

%%}}}

%%{{{ x: find_the_rules_of_grupoku 
\exercise.
%%%{{{ meta 
\label find_the_rules_of_grupoku
%%%}}}

Que restricções pode afirmar que temos nesse jogo de ``Grupoku'',
graças todos os resultados que temos provado até agora sobre grupos?
E se queremos um grupo abeliano, muda o quê?

%%}}}

%%{{{ x: find_all_groups_of_order_4 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_4
%%%}}}

Ache todas as operações possíveis que tornam um conjunto com $4$
membros um grupo.

\hint
\emph{Essencialmente} são apenas $2$.
Se achar mais, verifique que renomeando seus membros umas viram iguais,
e só tem dois que realmente não tem como identificá-las,
mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\reftag[Group_morphisms]).

\solution
\emph{Essencialmente} são apenas $2$:
$$
\xalignat2
\matrix
e & a & b & c \\
a & b & c & e \\
b & c & e & a \\
c & e & a & b
\endmatrix
&&
\matrix
e & a & b & c \\
a & e & c & b \\
b & c & e & a \\
c & b & a & e
\endmatrix
&
\endxalignat
$$
O primeiro é conhecido como o grupo cíclico de ordem $4$;
o segundo como {\Klein[four-group]}Klein four-group.
Se tu achaste mais, verifique que renomeando seus membros
umas viram iguais, e só tem dois que realmente não tem como
identificá-las, mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\reftag[Group_morphisms]).

%%}}}

%%{{{ x: find_all_groups_of_order_0_and_1 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_0_and_1
%%%}}}

Tem grupos de ordem 1?  De 0?

\solution
De ordem $1$ sim.  Cada um tem a mesma forma: seu único elemento é sua identidade.
De ordem $0$, não: a lei (G2) \emph{manda a existência} de um certo membro do grupo (a sua identidade).

%%}}}

\endsection
%%}}}

%%{{{ Powers_and_orders 
\section Potências e ordens.
%%%{{{ meta 
\label Powers_and_orders
%%%}}}

%%{{{ df: powers_in_group 
\definition.
%%%{{{ meta 
\label powers_in_group
\defines
    * ~a^{~m}  -- $a \ast \dotsb \ast a$ ($m$ vezes)
    ;;
%%%}}}

Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos suas potências $a^{\ast n}$ onde $n\in\nats$ recursivamente:
$$
\align
a^{\ast 0}     &\defeq e\\
a^{\ast {n+1}} &\defeq a \ast a^{\ast n}
\endalign
$$
Quando a operação $\ast$ é entendida pelo contexto
escrevemos apenas $a^n$ em vez de $a^{\ast n}$.

%%}}}

%%{{{ x: powers_in_group_altdef 
\exercise.
%%%{{{ meta 
\label powers_in_group_altdef
%%%}}}

Demonstre que a definição alternativa de exponenciação ao natural
$$
\align
a^{\ast 0}     &= e\\
a^{\ast {n+1}} &= a^{\ast n} \ast a
\endalign
$$
é equivalente.

\hint
Como o próprio ``operador'' de exponenciar fica escondido na notação
comum $a^b$, melhor escrever temporariamente as duas definições como:
$$
\xalignat2
a \uparrow_1 0 &= e &
a \uparrow_2 0 &= e \\
a \uparrow_1 (n+1) &= a \ast (a \uparrow_1 n) &
a \uparrow_2 (n+1) &= (a \uparrow_2 n) \ast a.
\endxalignat
$$
Agora tem uma notação melhor para demonstrar o que queremos: ${\uparrow_1} = {\uparrow_2}$.
O que significa que duas operações (funcções) são iguais?

\hint
Precisamos mostrar que:
$$
\text{para todo $a\in G$ e todo $n\in\nats$,}\quad
a \uparrow_1 n = a \uparrow_2 n
$$
ou, simbolicamente:
$$
\align
\pforall {a \in G}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\intertext{\emph{Seja $a\in G$.}  Agora queremos demonstrar:}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\endalign
$$
Como demonstrar isso?

\hint
As definições envolvidas são recursivas.

\hint
Ou seja: indução.

\hint
\proofpart{Base:} demonstrar que $a \uparrow_1 0 = a \uparrow_2 0$:

\hint
Seja $k\in\nats$ tal que $a \uparrow_1 k = a \uparrow_2 k$ (hipótese indutiva).
Queremos mostrar que
$$
a \uparrow_1 (k+1) = a \uparrow_2 (k+1).
$$

\hint
Seguindo as dicas anteriores, provavelmente tu chegou aqui:
\compute
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$} \\
&= a \ast (a \uparrow_2 k)   \by {HI} \\
\intertext{\dots e agora?
\emph{Se} $\ast$ fosse comutativa (ou seja, se o grupo fosse abeliano),
a gente \emph{poderia} continuar assim:}
&= (a \uparrow_2 k) \ast a   \by {comutatividade~(GA)} \\
&= a \uparrow_2 (k+1).       \by {def.~$\uparrow_2$} \\
\intertext{\emph{Só que não!}
Sobre o $G$ sabemos apenas que é um grupo, então não podemos contar na
comutatividade da sua operação $\ast$.
(Inclusive, se a $\ast$ fosse comutativa o resultado seria
trivial e nem precisaria prova por indução.)
Voltando no passo que tivemos colado}
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$} \\
&= a \ast (a \uparrow_2 k)   \by {HI} \\
\endcompute
percebemos que precisamos ``abrir mais'' a expressão $(a \uparrow_2 k)$,
aplicando a definição de $\uparrow_2$, mas não podemos, pois não sabemos se $k=0$ ou não.
Neste momento então percebemos que saber a veracidade dessa equação apenas para o valor $n=k$ não é suficiente.
Tu vai precisar o $n=k-1$ também.
\eop
Ou seja, tu vai precisar \emph{duas} bases ($n=0,1$),
e supor que tem um $k \geq 2$ tal que ambos os $k-1$ e $k-2$ satisfazem a
$a \uparrow_1 n = a \uparrow_2 n$.
Ou seja, tu ganharás as \emph{duas} hipoteses indutivas:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2) \tag{HI2}
\endalign
$$
e só bastará demonstrar que $a \uparrow_1 k = a \uparrow_2 k$.

\solution
Seja $a \in G$.
Vamos demonstrar que para todo $n\in\nats$, $a \uparrow_1 n = a \uparrow_2 n$
por indução no $n$.
\crproofpart{Bases $n\asseq 0,1$:}
Temos
$$
\computed {
a \uparrow_1 0
&= e               \by {def.~$\uparrow_1$} \\
&= a \uparrow_2 0  \by {def.~$\uparrow_2$} \\
}
\qqqquad
\computed {
a \uparrow_1 1
&= a \ast (a \uparrow_1 0)  \by {def.~$\uparrow_1$} \\
&= a \ast e                 \by {def.~$\uparrow_1$} \\
&= a                        \by {def.~$e$} \\
&= e \ast a                 \by {def.~$e$} \\
&= (a \uparrow_2 0) \ast a  \by {def.~$\uparrow_2$} \\
&= a \uparrow_2 1           \by {def.~$\uparrow_2$} \\
}
$$
\proofpart{Passo indutivo:}
Seja $k\in\nats$, tal que $k\geq 2$ e:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2).\tag{HI2}
\endalign
$$
Precisamos demonstrar que $a \uparrow_1 k = a \uparrow_2 k$.
Calculamos:
\compute
a \uparrow_1 k
&= a \ast \paren{a \uparrow_1 (k-1)}                \by {def.~$\uparrow_1$} \\
&= a \ast \paren{a \uparrow_2 (k-1)}                \by {HI1} \\
&= a \ast \paren{\paren{a \uparrow_2 (k-2)} \ast a} \by {def.~$\uparrow_2$} \\
&= a \ast \paren{\paren{a \uparrow_1 (k-2)} \ast a} \by {HI2} \\
&= \paren{a \ast \paren{a \uparrow_1 (k-2)}} \ast a \by {associatividade~(G1)} \\
&= \paren{a \uparrow_1 (k-1)} \ast a                \by {def.~$\uparrow_1$} \\
&= \paren{a \uparrow_2 (k-1)} \ast a                \by {HI1} \\
&= a \uparrow_2 k.                                  \by {def.~$\uparrow_2$} \\
\endcompute
Pelo principio da indução segue que para todo $n\in\nats$,
$a \uparrow_1 n = a \uparrow_2 n$.
Como $a$ foi arbitrário membro de $G$, isso termina nossa prova que
${\uparrow_1} = {\uparrow_2}$.

%%}}}

\TODO connect this with \ref[concat_iterations_equivalent].

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Acabaste de demonstrar um teorema bem mais geral do que parece
no enunciado do~\ref[powers_in_group_altdef]!
É o seguinte:

%%}}}

%%{{{ thm: associative_with_identity_exp_defs_equiv 
\theorem.
%%%{{{ meta 
\label associative_with_identity_exp_defs_equiv
%%%}}}

Seja $A$ um conjunto estruturado e~$\ast$~uma operação
binária e associativa no~$A$, com identidade $u$.
As duas definições de potências
$$
\xalignat2
a^{\ast0}     &= u &
a^{\ast0}     &= u \\
a^{\ast{n+1}} &= a \ast a^n &
a^{\ast{n+1}} &= a^n \ast a
\endxalignat
$$
são equivalentes, ou seja, as duas operações
definidas são iguais.

\proof Provado.
No~\ref[powers_in_group_altdef], pois as únicas coisas que
precisamos na sua prova foram exatamente as hipoteses
desse teorema.

%%}}}

%%{{{ thm: properties_of_exp_in_general 
\theorem.
%%%{{{ meta 
\label properties_of_exp_in_general
%%%}}}

A operação de exponenciação definida
no~\ref[associative_with_identity_exp_defs_equiv]
satisfaz as leis:
% TODO: fix reflabs
\tlist:
\li (1): $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m+n}        = a^m \ast a^n}$;
\li (2): $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m\ntimes n} = (a^m)^n}$;
\li (3): $\lforall {n\in\nats}   {\gid^n = \gid}$.
\endtlist

\proof Já demonstrado.
Como observamos no~\ref[properties_of_function_iterations] também,
quando provamos por indução as leis nos exercícios~\reftag[law_of_natexp_1],
\reftag[law_of_natexp_2], e~\reftag[law_of_natexp_3],
usamos apenas a \emph{associatividade} e a \emph{identidade} da
multiplicação e \emph{não usamos sua definição}.
Logo a mesma demonstração serve aqui, trocando a multiplicação por nossa $\ast$.

%%}}}

\TODO Teaser/remark about \ref[Algebraic_structures].

%%{{{ x: sq_of_prod_not_prod_of_sq 
\exercise.
%%%{{{ meta 
\label sq_of_prod_not_prod_of_sq
%%%}}}

Mostre que, \emph{em geral}, $(a \ast b)^2 \neq a^2 \ast b^2$.

%%}}}

\TODO check the following exercise for dups and position.

%%{{{ x: in_finite_groups_all_members_have_finite_orders 
\exercise.
%%%{{{ meta 
\label in_finite_groups_all_members_have_finite_orders
%%%}}}

Seja $G$ grupo finito.
Para todo $a \in G$, existe $n \in \nats_{>0}$
tal que $a^n = e$.
Demonstre:
(i) diretamente;
(ii) usando a contrapositiva;
(iii) usando reductio ad absurdum.

%%}}}

%%{{{ beware: for which values of w have we defined a^w? 
\beware.
%%%{{{ meta 
%%%}}}

Neste momento então, para qualquer grupo $G$ e qualquer $a\in G$,
o símbolo $a^w$ é definido \emph{apenas} para $w \asseq -1, 0, 1, 2, \dots$
e nada mais!
Vamos agora estender para os valores $w \asseq -2, -3, -4, \dots$
num jeito razoável.

%%}}}

%%{{{ Q: what do you think a^{-2} should mean? 
\question.
%%%{{{ meta 
%%%}}}

O que você acha que deveria ser denotado por $a^{-2}$?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Bem, tem duas interpretações, ambas razoáveis:
$$
a^{-2} \askeq
\paths{
\paren{\ginv a}^2 & (o quadrado do inverso do $a$) \cr
\pathween {\dots\orword\dots}
\ginvp{a^2}       & (o inverso do quadrado do $a$)
}
$$
Demonstre que as duas interpretações são equivalentes, ou seja:

%%}}}

%%{{{ x: inv_of_square_eq_square_of_inv 
\exercise.
%%%{{{ meta 
\label inv_of_square_eq_square_of_inv
%%%}}}

Seja $G$ grupo.  Para todo $a\in G$,
$\paren{a^{-1}}^2 = \paren{a^2}^{-1}$.
Ou seja, o diagrama
$$
\cdopt{sep=2cm}
G \ar[r, "\ginv\bhole"] \ar[d, "\bhole^2"] \| G \ar[d, "\bhole^2"]\\
G \ar[r, "\ginv\bhole"]                    \| G
\endcd
$$
comuta.

\hint
\ref[different_interpretations_of_same_eq]
e~\ref[read_the_same_equation_in_different_ways].

\hint
Tem como demonstrar isso numa linha só!
Se não enxergar como, seja $a\in G$.
O que tu precisas mostrar, é que $\paren{\ginv a}^2$ é o inverso do $a^2$.
O que significa <<ser o inverso do $a^2$>>?

\hint
$
\paren{\ginv a}^2 \ast {a^2}
\askeq e
\askeq {a^2} \ast \paren{\ginv a}^2
$.

\solution
Graças ao~\ref[cheaper_ginv], basta demonstrar que para todo $a\in G$,
$\paren{\ginv a}^2 \ast a^2 = e$.
Seja $a\in G$ então.  Calculamos:
\compute
\paren{a^{-1}}^2 \ast {a^2}
&= (\ginv a \ast \ginv a) \ast {a^2}             \by {def.~$\paren{\ginv a}^2$} \\
&= (\ginv a \ast \ginv a) \ast \paren{a\ast a}   \by {def.~$a^2$} \\
&= \paren{(\ginv a \ast \ginv a) \ast a}\ast a   \by {ass.} \\
&= \paren{\ginv a \ast (\ginv a \ast a)}\ast a   \by {ass.} \\
&= \paren{\ginv a \ast e}\ast a                  \by {def.~$\ginv a$} \\
&= \ginv a \ast a                                \by {def.~$e$} \\
&= e                                             \by {def.~$\ginv a$} \\
\endcompute
Logo $\paren{\ginv a}^2$ é o inverso de $a^2$.
\eop
Mas, um segundo!
Nessa maneira fizemos bem mais trabalho do que precisamos.
Observe que praticamente repetimos aqui a prova
do~\ref[inverse_of_product_in_group]!
Seria melhor simplesmente usá-lo,
chegando assim nessa prova bem mais simples:
\compute
\ginvp{a^2}
&= \ginvp{aa}           \by {def.~$a^2$} \\
&= \ginv a \ginv a      \by {inv.~prod.~(\ref[inverse_of_product_in_group])} \\
&= \paren{\ginv a}^2.   \by {def.~$\paren{\ginv a}^2$} \\
\endcompute

%%}}}

%%{{{ x: inv_of_npow_eq_npow_of_inv 
\exercise.
%%%{{{ meta 
\label inv_of_npow_eq_npow_of_inv
%%%}}}

Generalize o~\ref[inv_of_square_eq_square_of_inv] para $n\in\nats$:
\emph{para todo grupo $G$ e todo $n\in\nats$, se $a\in G$ então
$\paren{\ginv a}^n = \ginvp{a^n}$}.

\hint
As potências de elementos de grupo foram definidas
\emph{recursivamente}.

\hint
Indução.

%%}}}

%%{{{ df: negpowers_in_group 
\definition.
%%%{{{ meta 
\label negpowers_in_group
%%%}}}

Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos para todo $n\in\nats_{>0}$.
$$
a^{-n} \defeq \paren{\ginv a}^n
$$
Note que graças ao \ref[inv_of_npow_eq_npow_of_inv]
a definição alternativa de exponenciação ao inteiro negativo
$
a^{-n} \defeq \ginvp {a^n}
$
é equivalente.

%%}}}

%%{{{ property: properties_of_powers_in_groups 
\property Potências.
%%%{{{ meta 
\label properties_of_powers_in_groups
%%%}}}

Sejam $G$ grupo, $a \in G$, e $m,n\in\ints$.
Temos:
\item{\rm (1)} $a^m \ast a^n = a^{m+n}$;
\item{\rm (2)} $(a^m)^n = a^{m\ntimes n}$;
\item{\rm (3)} $\gid^n = \gid$;
\item{\rm (4)} $\ginvp {a^n} = \paren{\ginv a}^n$.

\sketch.
Demonstramos a (4) primeiro para $m,n\in\nats$ por
indução---as (1)--(3) já provamos~(\ref[properties_of_exp_in_general]).
Depois consideramos os casos de inteiros negativos para as quatro leis.

%%}}}

%%{{{ x: square_of_product_abelian_criterion
\exercise.
%%%{{{ meta 
\label square_of_product_abelian_criterion
%%%}}}

Seja $G$ grupo tal que para todo $a,b \in G$, $(ab)^2 = a^2 b^2$.
Logo, $G$ é abeliano.

\hint
Sejam $x,y\in G$.
Calcule o $(xy)^2$ em dois jeitos.

\solution
Sejam $x,y\in G$.
Pela hipótese temos:
$$
\align
(xy)^2 &= x^2y^2 = xxyy;
\intertext{e pela definição de $(xy)^2$ temos}
(xy)^2 &= xyxy.
\endalign
$$
Ou seja
$$
\align
xxyy &= xyxy
\intertext{e cancelando os $x$ pela esquerda
e os $y$ pela direita, chegamos no desejado:}
xy &= yx.
\endalign
$$

%%}}}

%%{{{ df: order_of_member_in_group 
\definition Ordem de membro em grupo.
%%%{{{ meta 
\label order_of_member_in_group
\defines
    * \gord {~a}  -- a ordem do elemento $a$ num grupo
    * ordem!de membro em grupo
    ;;
%%%}}}

Seja $\sset G {\ast,e}$ grupo e $a\in G$.
Chamamos \dterm{ordem} de $a$ o menor positivo $n\in\nats$ tal que
$a^n = e$, se tal $n$ existe; caso contrário, dizemos que o $a$ tem ordem infinita.
Usamos a mesma notação como no caso de ordem de grupos:
$\gord a$, $\tord a$, ou $\bord a$, com os mesmos cuidados.
Logo:
$$
\gord a =
\knuthcases {
\min \setst {n\in\nats_{>0}} {a^n = e}, & se $\setst {n\in\nats_{>0}} {a^n = e} \neq \emptyset$\cr
\infty,                                 & caso contrário.
}
$$

%%}}}

%%{{{ eg: orders_of_members_of_S3 
\example.
%%%{{{ meta 
\label orders_of_members_of_S3
%%%}}}

No $\sym 3$, temos
$$
\xalignat3
\gord {\id} &= 1 & \gord {\phi}         &= 2  &  \gord {\psi}   &= 3\\
            &    & \gord {\phi\com\psi} &= 2  &  \gord {\psi^2} &= 3.\\
            &    & \gord {\psi\com\phi} &= 2  &  
\endxalignat
$$

%%}}}

%%{{{ x: verify the numbers of orders_of_members_of_S3 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique os números do~\ref[orders_of_members_of_S3].

%%}}}

%%{{{ x: nonzero_power_is_gid_implies_finite_order 
\exercise.
%%%{{{ meta 
\label nonzero_power_is_gid_implies_finite_order
%%%}}}

Seja $G$ grupo e $a\in G$.
Se existe $m\in\ints_{\neq 0}$ tal que $a^m = e$, então $\gord a < \infty$.

\hint
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.

\hint
Se $m>0$, tome $n\leteq m$.  Se não?

\solution
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.
Se $m>0$, o conjunto $N \leteq \setst {n\in\nats_{>0}} {a^n = e}$ não é vazio,
então pelo princípio da boa ordem~\indexed[princípio!da boa ordem](PBO)
possui elemento mínimo e logo
$\gord a = \min N < \infty$.
Se $m<0$, observe que $-m > 0$, e calcule:
$$
a^{-m} = \ginvp{a^m} = \ginv e = e,
$$
e novamente
$N\neq\emptyset$ e $\gord a < \infty$.

%%}}}

%%{{{ lm: a_has_exactly_gord_a_powers 
\lemma.
%%%{{{ meta 
\label a_has_exactly_gord_a_powers
%%%}}}

Sejam $G$ grupo e $a\in G$, e suponha $\gord a = n\in\nats$.
Existem exatamente $n$ distintas potências de $a$.

\sketch.
As potências de $a$ são as:
$$
\dotsc, a^{-2}, a^{-1}, a^0, a^1, a^2, \dotsc, a^{n-1}, a^n, a^{n+1}, a^{n+2}, \dotsc
$$
Queremos demonstrar que, no final das contas, nesta lista aparecem exatemente $n$
distintos membros de $G$.  Ou seja,
$$
\card{\setst {a^k} {k\in\ints}} = n.
$$
Consideramos os
$$
a^0, a^1, \dotsc, a^{n-1}
$$
e usando a definição de $\gord a$ provamos:
\crtabproofpart{Existência:} os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
\eop\noi
Ou seja: para todo $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$, temos $a^i \neq a^j$.
\crtabproofpart{Unicidade:} para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\eop\noi
Sabemos diretamente pela sua definição que $a^0 = e$, e que $a^n = e$, pois $\gord a = n$.
Com pouca imaginação chegamos na idéia que a cadeia de membros
$$
\alignat{12}
&\dotsc,\ && a^{-2},\ && a^{-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^n,\ && a^{n+1},\ && a^{n+2},\ && \dotsc\\
\intertext{é feita por uma copia de $a^0, \dotsc, a^{n-1}$ se repetindo infinitamente para as duas direções:}
&\dotsc,\ && a^{n-2},\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc
\endalignat
$$
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref[euclidean_division])
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$.

\proof.
\proofpart{Existência:}
existem $n$ potências de $a$.
\eop\noi
Provamos isso demonstrando que os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
Sejam $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$.
\emph{Sem perda de generalidade}, suponha que $i<j$, ou seja:
$$
0 \leq i < j < n.
$$
Para chegar num absurdo, suponha que $a^i = a^j$.
Assim temos:
$$
\align
\mubrace{aa\dotsb a} i &= \mubrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i<j$, quebramos o lado direito assim:}
\mubrace{aa\dotsb a} i &= \mubrace{\mobrace{aa\dotsb a} i \mobrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref[cheaper_gid].
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.  Como $0 < j-i < n$, isso contradiza a definição
de $n$ como a ordem de $a$:
$n = \gord a$.
Logo $a^i \neq a^j$, que foi o que queremos demonstrar.
\eop\noi
\proofpart{Unicidade:}
os $a^0,\dotsc,a^{n-1}$ são as \emph{únicas} potências de $a$.
Ou seja, para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\eop\noi
Tome $M\in \ints$.
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref[euclidean_division])
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$:
$$
a^M
= a^{q\ntimes n + r}
= a^{q\ntimes n} a^r
= \paren{a^n}^q a^r
= e^q a^r
= e a^r
= a^r
$$
e como $0\leq r < n$, provamos o que queriamos demonstrar.

%%}}}

%%{{{ x: a_has_exactly_gord_a_powers_without_reductio 
\exercise.
%%%{{{ meta 
\label a_has_exactly_gord_a_powers_without_reductio
%%%}}}

Leia a demonstração do~\ref[a_has_exactly_gord_a_powers]
e escreva uma que não usa \emph{reductio ad absurdum}.

\solution
Sejam $i,j \in \set{0,\dotsc,n-1}$ tais que $a^i = a^j$.
Preciso mostrar que $i=j$.
Sem perda de generalidade suponha que $i \leq j$, ou seja:
$$
0 \leq i \leq j < n.
$$
Agora temos
$$
\align
\mubrace{aa\dotsb a} i &= \mubrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i \leq j$, quebramos o lado direito assim:}
\mubrace{aa\dotsb a} i &= \mubrace{\mobrace{aa\dotsb a} i \mobrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref[cheaper_gid].
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.
Logo $j-i \geq n$ ou $j-i = 0$, pela definição da $\gord a$.
A primeira alternativa é impossível pela escolha dos $i,j$,
e logo concluimos que $j-i=0$, ou seja, $i=j$.

%%}}}

%%{{{ Q: a^m = e => ? ; o(a) = infty => ? 
\question.
%%%{{{ meta 
%%%}}}

Se $a^m = e$ para algum $m\in\ints$, o que podemos concluir sobre o $m$ e a $\gord a$?
Se $\gord a = \infty$, o que podemos concluir sobre todas as potências de $a$?

%%}}}

\spoiler

%%{{{ lm: a_exp_m_is_e_iff_gord_a_divides_m 
\lemma.
%%%{{{ meta 
\label a_exp_m_is_e_iff_gord_a_divides_m
%%%}}}

Sejam $\sset G \ast$ grupo, $a\in G$, e $m\in\ints$.
Logo
$$
a^m = e \iff \gord a \divides m.
$$

\proof.
\proofpart{\rldir:}
Como $\gord a \divides m$,
temos $m = k\gord a$ para algum $k\in\ints$.
Calculamos:
$$
a^m
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= \gid^k
= \gid.
$$
\proofpart{\lrdir:}
Para demonstrar que $\gord a \divides m$,
aplicamos o~\ref[euclidean_division] da divisão de Euclides\Euclid[lemma da divisão],
dividindo o $m$ por $\gord a$, e ganhando assim inteiros $q$ e $r$ tais que
$$
m = \gord a q + r
\qquad
0\leq r < \gord a.
$$
Vamos demonstrar que o resto $r=0$.
Calculamos:
$$
e
= a^m
= a^{\gord a q + r}
= a^{\gord a q} \ast a^r
= \paren{a^{\gord a}}^q \ast a^r
= \gid^q \ast a^r
= \gid \ast a^r
= a^r.
$$
Ou seja, $a^r = \gid$ com $0\leq r < \gord a$,
então pela definição de $\gord a$
como o mínimo inteiro positivo $n$ que satisfaz a $a^n = \gid$,
o $r$ não pode ser positivo.
Logo $r=0$ e $\gord a \divides m$.

%%}}}

%%{{{ lm: infinite_order_of_a_guarantees_all_powers_distinct 
\lemma.
%%%{{{ meta 
\label infinite_order_of_a_guarantees_all_powers_distinct
%%%}}}

Sejam $G$ grupo e $a\in G$.  Se $\gord a = \infty$,
então as potências de $a$ são distintas dois-a-dois.

\sketch.
Precisamos demonstrar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
chegamos em $a^{r-s} = e$; e como a ordem de $a$ é infinita,
temos $r-s=0$ e logo $r=s$.

\proof.
Precisamos demonstrar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
temos
$$
a^sa^{r-s} = a^s
$$
e logo $a^{r-s} = e$ (\ref[cheaper_gid]).
Agora, como $\gord a = \infty$, usando o contrapositivo
do~\ref[nonzero_power_is_gid_implies_finite_order] obtemos que não existe
nenhum inteiro $m\neq 0$ tal que $a^m=e$.  Logo $r-s = 0$, ou seja $r = s$.

%%}}}

\endsection
%%}}}

%%{{{ Choosing_the_laws 
\section Escolhendo as leis.
%%%{{{ meta 
\label Choosing_the_laws
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Como escolhemos as leis~(G0)--(G3)?
Por que essas?
Por que não botamos a~(GA)?
Por que botamos a~(G3)?
Vamos discutir pouco sobre essas perguntas.

%%}}}

%%{{{ More theorems or more models? 
\note Mais teoremas ou mais modelos?.
%%%{{{ meta 
%%%}}}

Óbvio que adicionando mais leis na definição de grupo,
a gente poderia demonstrar mais teoremas.
Mas o que ganhamos em teoremas, perdemos em generalidade
da nossa teoria: menos coisas vão acabar sendo \dterm{modelos}
dos nossos axiomas, e logo esse bocado de teoremas que
vamos conseguir demonstrar não poderá ser aproveitado
em muitos contextos diferentes.
Adicionando a~(GA) nos axiomas de grupo por exemplo,
os $\sym n$ iam parar de ser grupos, e não teriamos
nenhum teorema ``de graça'' pra eles.
Como eu afirmei na introdução desse capítulo,
a escolha~(G0)--(G3) tem um equilibrio muito bom entre
riquesa da teoria e diversidade de modelos.
Faz sentido tirar o~(G3)?
Claro que sim; chegamos numa estrutura com mais modelos
(e menos teoremas), que com certeza vale a pena estudar.
O nome dessa estrutura é \dterm{monóide}, que estudamos
no~\reftag[Algebraic_structures].

%%}}}

%%{{{ Avoid redundancies 
\note Evite redundâncias.
%%%{{{ meta 
%%%}}}

Vamos dizer que estamos escolhendo as leis para a definição de grupo.
Já escolhemos as~(G0)--(G3), mas queremos que em cada grupo seja
possível cancelar pela esquerda~(GCL) e pela direita~(GCR).
Mesmo assim, não faz sentido adiconar as~(GCL)--(GCR) como leis,
pois como a gente descobriu no~\ref[cancellation_laws_in_group],
ambas são \emph{teoremas} da teoria dos~(G0)--(G3).
Similarmente, escolhemos os axiomas~(G2) e~(G3) que garantam
a existência \emph{duma} identidade e para cada membro \emph{dum}
inverso, em vez de botar como leis as proposições mais fortes
que afirmam as \emph{unicidades} deles também.
Por quê?
A resposta é parecida: se for possível, preferimos limitar
nossos axiomas nas versões mais fracas possíveis para elaborar
nossa teoria.
Nesse caso, a gente também descobriu que mesmo com os~(G2)--(G3)
as unicidades são garantidas na nossa teoria, agora como
\emph{teoremas}~(\reftag[uniqueness_of_identity_in_group]
e~\reftag[uniqueness_of_inverses_in_group]).

%%}}}

%%{{{ Clarity and intuitiveness 
\note Clareza e intuitividade \vs mão-de-vaca.
%%%{{{ meta 
\label clarity_and_intuitiveness
%%%}}}

No outro lado, optamos para botar as leis~(G2)--(G3),
em vez do par mais fraco~(G2L)--(G3L),
ou do~(G2R)--(G3R), que como tu sabes---ou como tu
vai descobrir quando finalmente resolver
o~\ref[onesided_group_def_proof]---qualquer
um par poderia substituir o par~(G2)--(G3), sem
afetar a teoria pois os~(G2)--(G3) viram teoremas
nesse caso~(\ref[onesided_group_def]).
Por que não escolher como axiomas dos grupos os
(G0),(G1),(G2L),(G3L) então?
Aqui é mais difícil justificar essa escolha.
Queremos achar um \emph{equilíbrio} entre a
economia, fraqueza, e quantidade dos axiomas num
lado; e a clareza e intuitividade no outro.
Não queremos exagerar nem no lado de clareza
(sendo redundantes), nem no lado de economia
(sendo mão-de-vaca).
Escolhendo as~(G2L)--(G3L) como axiomas, daria
um toque assimétrico na definição do que é um grupo.
Pelas leis apareceria (erroneamente) que a operação
dum grupo trata seus dois lados em maneiras diferentes,
prejudicando ou favorecendo um em comparação com o outro.
Botamos então como leis as~(G2)--(G3) e demonstramos
como \emph{critérion}~(\reftag[onesided_group_def]) que
assim que os~(G0),(G1),(G2L),(G3L) são satisfeitos,
temos um grupo (e similarmente para os~(G2R)--(G3R)).
Nossas leis escolhidas ((G0)--(G3)) estão falando
claramente para nosso coração.  Cada um é simples;
descreve uma propriedade simples e significante.
Imagine se alguém definir que o
$\sset G {\ast, \ginv{}, \gid}$ é um \dterm{grupo}
sse
satisfaz uma lei única e bizarra, como a
$$
\lforall
{a,b,c \in G}
{\paren{\ginvp{c \ast \ginvp{a \ast b}} \ast (c \ast \ginv b)} \ast \ginvp{\ginv b \ast b} = a}.
\tag{GKUN}
$$
Dá pra entender no teu coração qualquer coisa sobre
o $G$ e sua alma?
Dá pra entender, olhando par essa lei única,
se sua operação tem identidade?  Se ela é associativa?
Pelo incrível que aparece, eu nem tô brincando sobre
a lei (GKUN).  Realmente, {\Kunen}Kunen construiu o
(GKUN) e demonstrou que a teoria do (GKUN) sozinho
e a mesma da teoria dos (G1)+(G2)+(G3)
(veja~\cite[kunensinglegroup])!
Ou seja:
$$
\text{$\ssetfont G$ satisfaz a (GKUN)}
\wowiff
\text{$\ssetfont G$ é grupo}.
$$
Considerei aqui a (G0) como automaticamente garantida
(e logo redundante) pelo fato de ter uma operação (total)
na minha estrutura.
A volta é muito fácil, e tu demonstrarás agora
no~\ref[group_implies_kunen]; deixo o converso para
o~\ref[kunen_implies_group].

%%}}}

\TODO Clarificar single axioms; elaborar e mostrar mais.

%%{{{ x: group_implies_kunen 
\exercise.
%%%{{{ meta 
\label group_implies_kunen
%%%}}}

Demonstre a {\rldir}.

\hint
Sejam $a,b,c \in G$.
Calcule:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&\eqvdots \\
&= a
\endcompute

\solution
Sejam $a,b,c \in G$.
Calculamos:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \gid \\
&= \ginvp{c \ginvp{a b}} (c \ginv b) \\
&= \paren{\ginvp{\ginvp{a b}} \ginv c} (c \ginv b) \\
&= \paren{(a b) \ginv c} (c \ginv b) \\
&= (a b) (\ginv c c) \ginv b \\
&= (a b) e \ginv b \\
&= (a b) \ginv b \\
&= a (b \ginv b) \\
&= a e \\
&= a.
\endcompute

%%}}}

%%{{{ Modularity 
\note Modularidade.
%%%{{{ meta 
%%%}}}

Também é bom ter \emph{modularidade} entre nossos
axiomas, em tal forma que facilita tirar um, botar
outro, e chegar numa teoria diferente mas
interessante também.
Continuando no mesmo exemplo da definição unilateral
de grupos, suponha que tiramos o~(G3L), que é
nosso axioma de L-inversos.
Onde chegamos?
Numa estrutura verdadeiramente L-lateral---esquisito!

%%}}}

%%{{{ proving_the_unprovability 
\note Demonstrando a indemonstabilidade.
%%%{{{ meta 
\label proving_the_unprovability
%%%}}}

Alguém poderia pensar (ra\-zo\-avel\-mente) que a inclusão
do~(G3) nos axiomas de grupos foi desnecessária.
A gente deveria derivá-lo como conseqüência do resto dos axiomas,
na mesma maneira que demonstramos tantas outras proposições.
Aceitando o desafio começamos pensar para achar uma
demonstração do~(G3) a partir dos~(G0)--(G2).
E o tempo passa, passa, e passa\dots
\eop
E não conseguimos demonstrar.
\emph{Isso não quis dizer que o~(G3) é indemonstrável!}
Talvez amanha a gente terá uma idéia nova e conseguir demonstrá-lo;
ou talvez amanhã um rapaz mais esperto vai achar uma demonstração.
Mas, nesse caso, não vai não.
Pois podemos \emph{demonstrar} que o~(G3) é realmente
\emph{indemonstrável} pelos~(G0)--(G2).

%%}}}

%%{{{ proving_the_unprovability_method 
\exercise.
%%%{{{ meta 
\label proving_the_unprovability_method
%%%}}}

Como?
O que seria um argumento convencente sobre isso?
E em geral, como podemos demonstrar
a indemonstrabilidade duma proposição $\psi$
a partir dumas proposições $\phi_1,\dots,\phi_n$?
Depois de deixar claro tua estratégia demonstre
que realmente:
\tlist:
\li: a (GA) não é uma conseqüência das (G0)--(G3);
\li: a (G3) não é uma conseqüência das (G0)--(G2);
\li: a (G2) não é uma conseqüência das (G0)--(G1);
\li: a (G1) não é uma conseqüência da  (G0).
\endtlist

\hint
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
Qual modelo tu escolheria para cada uma delas?

\hint
Para a~(GA) basta achar um grupo que não
seja abeliano;
para a~(G3) basta achar um \dterm{monóide}
(ou seja, algo que satisfaz as~(G0)--(G2))
que não é um grupo;
para a~(G2) basta achar um \dterm{semigrupo}
(ou seja, algo que satisfaz as~(G0)--(G1))
que não é um monóide;
para a~(G1) basta achar um \dterm{magma}
(ou seja, algo que satisfaz a~(G0))
que não é um semigrupo.

\solution
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
\crproofpart{Para a~(GA)}
tome o $\sym 3$, que é grupo mas não abeliano
($\phi\psi\neq\psi\phi$).
\crproofpart{Para a~(G3)}
tome o $S$ do~\ref[strings_with_concat_is_not_a_group]
que ja verificámos que não satisfaz a~(G3), e que
tu já demonstrou~(\ref[verify_all_group_laws_for_strings])
que ele goza das outras:~(G0)--(G2).
\crproofpart{Para a~(G2)}
considere um conjunto $A = \set{a,b}$ com operação $\ast$
a $\outl$:
$$
x \ast y = x.
$$
Facilmente o $\sset A \ast$ satisfaz as (G0)--(G1) mas
não possui identidade.
\crproofpart{Para a~(G1)}
tome o $\nats$ com a exponenciação: o conjunto obviamente
é fechado, mas a operação não é associativa:
$$
2^(1^2) \neq (2^1)^2.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Não se preocupe demais com essas questões; com mais experiência
e maduridade tu vai reconhecer e apreciar os motivos dessas escolhas,
e tu elaborarás teu próprio gosto, instinto, e talento, para escolher
axiomas.
Mas chega!
Voltamos a estudar a teoria dos grupos agora.

%%}}}

\endsection
%%}}}

%%{{{ Subgroups 
\section Subgrupos.
%%%{{{ meta 
%%%}}}

%%{{{ df: subgroup 
\definition Subgrupo.
%%%{{{ meta 
\label subgroup
\defines
    * ~H \subgroup ~G  -- $H$ é um subgrupo de $G$
    * subgrupo!trivial
    * subgrupo
    ;;
%%%}}}

Seja $\sset G {\ast,e}$ grupo.
Um subconjunto $H\subset G$ é um \dterm{subgrupo} de $G$ sse
$H$ é um grupo com a mesma operação $\ast$.
Escrevemos $H \subgroup G$.
Chamamos os $\set e$ e $G$ \dterm{subgrupos triviais} de $G$.

%%}}}

%%{{{ remark: is it really the same op really? 
\remark A mesma mesmo?.
%%%{{{ meta 
%%%}}}

Na~\ref[subgroup] falamos que $H$ é um grupo com \emph{a mesma operação} $\ast$.
Literalmente as duas operações são diferentes, pois seus domínios são diferentes.
O que entendemos com essa frase aqui é que o conjunto $H$ é um grupo com operação
\emph{a restricção da $\ast$ no $H\times H$}.
Com símbolos, $\sset H {\resfunsub \ast {H\times H}}$ é um grupo.
(Lembre-se a~\ref[fresto].)

%%}}}

%%{{{ x: singleton_e_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label singleton_e_is_a_subgroup
%%%}}}

Verifique que para todo grupo $\sset G {\ast,e}$, temos $\set e \subgroup G$.

%%}}}

%%{{{ eg: Numbers 
\example Números reais.
%%%{{{ meta 
%%%}}}

(1) Considere o grupo $\sset \reals {+}$.
Observe que $\rats$ e $\ints$ são subgrupos dele, mas $\nats$ não é.
\eop\noi
(2) Considere o grupo $\sset {\reals_{\neq0}} {\ntimes}$.
Observe que $\set{1, -1}$, $\rats_{\neq0}$, e para qualquer
$\alpha\in\reals_{\neq0}$ o conjunto $\setst {\alpha^k} {k\in\ints}$ são todos
subgrupos dele, mas $\ints$ e $\setst {\alpha^n} {n\in\nats}$ não são.

%%}}}

%%{{{ x: rationals 
\exercise.
%%%{{{ meta 
%%%}}}

Considere o grupo $\ssetfont Q \leteq \sset {\rats\setminus\set0} {\ntimes}$
e seus subconjuntos:
$$
\align
Q_1 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ e $q$ ímpares} }\\
Q_2 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ ímpar, $q$ par} }\\
Q_3 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ par, $q$ ímpar} }.
\endalign
$$
Para quais dos $i=1,2,3$ temos $Q_i \subgroup \ssetfont Q$?

%%}}}

%%{{{ property: empty_is_never_a_subgroup 
\property.
%%%{{{ meta 
\label empty_is_never_a_subgroup
%%%}}}

$H\subgroup G \implies H \neq\emptyset$.

\proof.
Como $H$ é um grupo, necessariamente $e\in H$.

%%}}}

%%{{{ x: some_subgroups_of_additive_ints 
\exercise.
%%%{{{ meta 
\label some_subgroups_of_additive_ints
\defines
    * ~m \ints  -- o conjunto de todos os múltiplos do $m$
    ;;
%%%}}}

Demonstre que para todo $m\in\ints$, $m\ints \subgroup \sset \ints +$,
onde $m\ints \defeq \setst {km} {k \in \ints}$.

%%}}}

%%{{{ x: some_nontrivial_subgroups_of_multiplicative_reals 
\exercise.
%%%{{{ meta 
\label some_nontrivial_subgroups_of_multiplicative_reals
%%%}}}

Ache uns subgrupos não-triviais do
$\sset {\reals\setminus\set0} {\ntimes}$.

%%}}}

%%{{{ remark: ass_for_free_in_subgroup
\remark Associatividade de graça.
%%%{{{ meta 
\label ass_for_free_in_subgroup
%%%}}}

Seja $\sset G \ast$ grupo, e tome um $H\subset G$.
Para ver se $H \subgroup G$, seguindo a definição,
precisamos verificar as (G0)--(G3) no $\sset H \ast$.
Mas a lei~(G1) da associatividade não tem como ser violada no $\sset H \ast$.
O que significaria violar essa lei?
$$
\text{Teriamos $a,b,c \in H$, tais que $a\ast (b\ast c) \neq (a \ast b) \ast c$.}
$$
Mas como $H \subset G$, nos teriamos o mesmo contraexemplo para a (G1) de $G$,
impossível pois $G$ é um grupo mesmo (e a operação é a mesma).
Logo, jamais precisaramos verificar a~(G1) para um possível subgrupo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E isso não é o único ``desconto'' que temos quando queremos demonstrar
que~$H \subgroup G$.  Vamos ver mais dois critéria agora:

%%}}}

%%{{{ criterion: nonempty_subgroup_criterion 
\criterion Subgrupo.
%%%{{{ meta 
\label nonempty_subgroup_criterion
%%%}}}

Se $H$ é um subconjunto não vazio do grupo $\sset G {\ast,e}$, então:
$$
\rightbrace {
\alignedat3
\textrm{(0)} & \quad &                      & \emptyset \neq H \subset G                 &\qquad &\textrm{($H$ é n\~ao vazio)}\\
\textrm{(1)} & \quad & \pforall {a,b \in G} & \quantified{a, b \in H \implies a\ast b \in H}  &\qquad &\textrm{($H$ é $\ast$-fechado)}\\
\textrm{(2)} & \quad & \pforall {a \in G}   & \quantified{a \in H    \implies \ginv a \in H}  &\qquad &\textrm{($H$ é $^{-1}$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$

\sketch.
Observamos que a associatividade é garantida pelo fato que $G$ é grupo,
então basta demonstrar que $e\in H$.
Por isso, usamos a hipótese $H\neq\emptyset$ para tomar um $a\in H$
e usando nossas (poucas) hipoteses concluimos que $e\in H$ também.

\proof.
Precisamos verificar as leis (G0)--(G3) para o $\sset H {\ast}$.
Os (1) e (2) garantam as (G0) e (G3) respectivamente,
e o fato que $G$ é grupo garanta a (G1) também.
Basta verificar a (G2), ou seja, que $e\in H$:
\stepproof
\proofsteptby {Tome $a\in H$.}              {$H\neq\emptyset$\,}
\proofsteptby {Logo $\ginv a \in H$.}       {pela (ii)}
\proofsteptby {Logo $a\ast \ginv a \in H$.} {pela (i)}
\proofsteptby {Logo $e \in H$.}             {def.~$\ginv a$}
\endstepproof

%%}}}

%%{{{ The skeleton of the proof 
\note O esqueleto dessa demonstração.
%%%{{{ meta 
%%%}}}

Vamos lembrar o tema de arvores, escrevendo a prova
do~\ref[nonempty_subgroup_criterion] assim:
$$
\PROOFm {
\A    {h\in H}
\I1-------------- {\phantom{$H$ $\ginv{}$-fechado}}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {\phantom{$H$ $\ast$-fechado}}
           {\ginv h h \in H}
    \I1-------------------------- {\phantom{def.~$\ginv h$}}
               {e \in H}
}
$$
Quais são as justificações de cada linha de inferência?
$$
\PROOFm {
\A    {h\in H}
\I1-------------- {$H$ $\ginv{}$-fechado}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {$H$ $\ast$-fechado}
           {\ginv h h \in H}
    \I1-------------------------- {def.~$\ginv h$}
               {e \in H}
}
$$

%%}}}

%%{{{ remark: shorter formulas 
\remark.
%%%{{{ meta 
%%%}}}

Observe que como $H\subset G$, a afirmação
$$
\lforall {a,b \in G} {a,b\in H \implies ab \in H}
$$
é equivalente à
$$
\lforall {a,b \in H} {ab \in H}.
$$
No próximo critério vamos escrever nessa forma mais curta.

%%}}}

%%{{{ criterion: finite_subgroup_criterion 
\criterion Subgrupo finito.
%%%{{{ meta 
\label finite_subgroup_criterion
%%%}}}

Se $\sset G {\ast,e}$ é um grupo e $H$ é um subconjunto finito e não vazio do $G$,
fechado sobre a operação $\ast$, então $H$ é um subgrupo de $G$.
Em símbolos:
$$
\rightbrace {
\alignedat2
\textrm{(0)} \quad & \emptyset \neq H \finsubset G        &\qquad &\textrm{($H$ é \emph{finito} e n\~ao vazio)}\\
\textrm{(1)} \quad & \lforall{a, b \in H}{a\ast b \in H}    &\qquad &\textrm{($H$ é $\ast$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$

\sketch.
Basta demonstar o (2) para aplicar o~\ref[nonempty_subgroup_criterion].
Tome um $a\in H$ e considere a seqüência das suas potências
$a, a^2, a^3, \dotsc \in H$.
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ com inteiros $r > s > 0$, e usamos isso
para achar qual dos $a, a^2, a^3, \dotsc$ deve ser o $\ginv a$,
demonstrando assim que $\ginv a\in H$.

\proof.
Graças ao~\ref[nonempty_subgroup_criterion], basta mostrar que todos os membros
de $H$ têm seu inverso dentro do $H$.
Tome um $a\in H$ e considere a seqüência das suas potências positivas:
\compute
a, a^2, a^3, \dotsc &\in H \by {graças à hipótese (1)} \\
\endcompute
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ para alguns distintos positivos $r,s \in \nats$.
Sem perda de generalidade, suponha $r > s$.
Temos
$$
\align
\tobrace{a\ast a \ast \dotsb \ast a}{$r$ vezes}
&=\tobrace{a\ast a \ast \dotsb \ast a}{$s$ vezes}
\intertext{e como $r>s$, reescrevemos assim:}
\tobrace{
\tubrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
\ast
\tubrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}
}{$r$ vezes}
&=\tobrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}.
\intertext{Agora operando nos dois lados pela direita por $\ginvp{a^s}$:}
\tobrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
&=e
\intertext{Ou seja, $e = a^{r-s}$ e acabamos de demonstrar que $e\in H$.
Observe que $r-s>0$, então temos pelo menos um $a$ na esquerda:}
\tobrace{a\ast \tubrace{a \ast \dotsb \ast a}{$r-s-1$ vezes}}{$r-s$ vezes}
&=e
\endalign
$$
e agora \emph{precisamos} considerar dois casos:
\eop\noi
\case{Caso $r-s = 1$:}
Nesse caso então temos $e = a^1 = a$,
e logo $\ginv a = \ginv e = e = a \in H$.
\eop\noi
\case{Caso $r-s > 1$:}
Nesse caso, temos $e = aa^{r-s-1}$, ou seja,
achamos o inverso do $a$: é o $a^{r-s-1}$, e ele pertence no $H$, pois é potência positiva de $a$ (e $H$ é fechado pela operação).
\eop
Em ambos dos casos mostramos que $\ginv a \in H$ e podemos
aplicar o~\ref[nonempty_subgroup_criterion] para concluir o desejado
$H\subgroup G$.

%%}}}

%%{{{ criterion: subgroup_one_test 
\criterion subgrupo: ``one-test''.
%%%{{{ meta 
\label subgroup_one_test
%%%}}}

Se $G$ é um grupo e $\emptyset\neq H \subset G$ tal que
$$\text{para todo $a,b\in H$},\ a\ginv b\in H,$$
então $H\subgroup G$.  Em símbolos:
$$
\rightbrace {
\aligned
\textrm{(0)} \quad & \emptyset \neq H \subset G \\
\textrm{(1)} \quad & \lforall {a, b \in H} {a\ast \ginv b \in H}
\endaligned
}
\implies
H \subgroup G
$$

\proof.
\ref[subgroup_one_test_proof].

%%}}}

%%{{{ remark: the converses of all criteria above are obviously true 
\remark.
%%%{{{ meta 
%%%}}}

Em todos esses critérios, as direções {\rldir} também são válidas
(e suas demonstrações devem ser óbvias).

%%}}}

%%{{{ x: subgroup_one_test_proof 
\exercise.
%%%{{{ meta 
\label subgroup_one_test_proof
%%%}}}

Demonstre o~\ref[subgroup_one_test].

\hint
Demonstre primeiro que $H$ é fechado pelos inversos, tomando um $h\in H$
e demonstrando que $\ginv h \in H$.
Depois basta demonstrar que $H$ é fechado pela operação, tomando
$a,b\in H$ e demostrando que $ab \in H$.

\solution
Como $H\neq\emptyset$, tome $h\in H$.
Pela hipótese, $h\ginv h\in H$, ou seja $e\in H$.
Como $e,h\in H$, de novo pela hipótese temos $e\ginv h \in H$,
ou seja $\ginv h \in H$.
Temos então que o $H$ é fechado pelos inversos.
Basta demonstrar que é fechado pela operação de $G$ também:
tomando $a,b\in H$, ganhamos $a,\ginv b\in H$,
então pela hipótese $a\ginvp{\ginv b} \in H$, ou seja, $ab \in H$.

%%}}}

%%{{{ x: subgroup_is_an_order 
\exercise.
%%%{{{ meta 
\label subgroup_is_an_order
%%%}}}

Mostre que $\subgroup$ é uma relação de ordem:
$$
\gather
G \subgroup G\\
K \subgroup H \mland H \subgroup G \implies K\subgroup G\\
H \subgroup G \mland G \subgroup H \implies H = G.
\endgather
$$

%%}}}

%%{{{ x: Matrices 
\exercise Matrizes.
%%%{{{ meta 
%%%}}}

Verificamos que
$$
G \leteq \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }
$$
com multiplicação é um grupo no~\ref[matrix_group_examples].
Considere seus subconjuntos:
$$
\xalignat2
G_{\rats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\rats^{2\times2}} {ad - bc \neq 0 }&\quad H &\leteq \setlst { \matrixp{a & b\\0 & d}      } { a,b,d \in\reals,\ ad \neq 0 }\\
G_{\ints} &\leteq \setst{ \matrixp{a & b\\c & d}\in\ints^{2\times2}} {ad - bc \neq 0 }&\quad K &\leteq \setlst { \matrixp{1 & b\\0 & 1}      } { b\in\reals }                 \\
G_{\nats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\nats^{2\times2}} {ad - bc \neq 0 }&\quad L &\leteq \setlst { \matrixp{a & 0^{\phantom{-1}}\\0 & a^{-1}} } { a\in\reals,\ a\neq 0 }
\endxalignat
$$
Para cada relação de $\subset$ válida entre 2 dos 7 conjuntos acima,
decida se a correspondente relação~$\subgroup$ também é válida.

%%}}}

%%{{{ eg: Modular arithmetic 
\example Aritmética modular.
%%%{{{ meta 
%%%}}}

Considere o grupo $\sset {\finord 6} {+_6}$ onde $+_6$ é a adição modulo $6$.
Os $\set{0,2,4}$ e $\set{0,3}$ são seus únicos subgrupos não-triviais.

%%}}}

%%{{{ eg: Permutations 
\example Permutações.
%%%{{{ meta 
%%%}}}

O $\set{\id, \phi}$ é um subgrupo de $\sym 3$, onde $\phi = \permc{1 & 2}$.

%%}}}

%%{{{ x: find all subgroups of \sym 3 
\exercise.
%%%{{{ meta 
%%%}}}

Ache todos os subgrupos do $\sym 3$.

\hint
São 6.  Ache todos.

\solution
Os seguintes são todos os subgrupos do $\sym 3$:
$$
\xalignat6
&\set {\id} &
&\set {\id, \phi} &
&\set {\id, \phi\psi} &
&\set {\id, \psi\phi} &
&\set {\id, \psi, \psi^2} &
&\sym 3.
\endxalignat
$$

%%}}}

%%{{{ eg: Real functions 
\example Funcções reais.
%%%{{{ meta 
%%%}}}

Seja $F = (\reals\to\reals_{\neq0})$ com operação a
multiplicação pointwise~(\ref[pointwise_operation]).
Os subconjuntos seguintes de $F$ são todos subgrupos dele:
$$
\xalignat2
&\setstt {f\in F} {$f$ continua} &
&\setst  {f\in F} {f(0) = 1} \\
&\setstt {f\in F} {$f$ constante} &
&\setstt {f\in F} {$f(r) = 1$ para todo $r\in\rats$}
\endxalignat
$$

%%}}}

%%{{{ eg: Sets 
\example Conjuntos.
%%%{{{ meta 
%%%}}}

Sejam $A$ conjunto, e $X\subset A$.
Lembra que $\sset {\pset A} {\symdiff}$ é um
grupo~(\ref[pset_with_setops_group]).
Os $\set{\emptyset, X}$, $\set{\emptyset, X, A\setminus X}$,
e $\set{\emptyset, X, A\setminus X, A}$ são todos subgrupos dele,
mas o $\set{\emptyset, X, A}$ não é.

%%}}}

%%{{{ x: why not? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\hint
(G0).

\solution
O $H = \set{\emptyset, X, A}$ em geral não é um subgrupo, pois pode violar a
lei~(G0) no caso que $A\setminus X \notin H$, pois~$A \symdiff X = A \setminus X$.

%%}}}

%%{{{ x: intersection_of_subgroups_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label intersection_of_subgroups_is_a_subgroup
%%%}}}

Seja $G$ grupo, e $H_1,H_2\subgroup G$.
Então $H_1\inter H_2 \subgroup G$.

\hint
Precisa mostrar que $H_1\inter H_2 \neq \emptyset$ e que é fechado sobre a
operação do grupo e sobre inversos.

\hint
Para mostrar que é fechado sobre a operação do grupo
tome $a,b\in H_1\inter H_2$ e mostre que
$ab\in H_1\inter H_2$.
Similarmente, para mostrar que é fechado sobre os inversos,
tome $a\in H_1\inter H_2$ e mostre que
$\ginv a \in H_1\inter H_2$.

\solution
Temos $H_1\inter H_2 \subset G$.
Observe primeiramente que $H_1\inter H_2\neq \emptyset$,
pois $e\in H_1$ e $e\in H_2$ (os dois sendo subgrupos de $G$).
Agora mostramos que o $H_1\inter H_2$ é fechado pela operação:
\stepproof
\proofsteptnb {Sejam $a,b \in H_1\inter H_2$.}
\proofsteptby {Logo $a,b \in H_1$ e $a,b\in H_2$.} {def.~$\inter$}
\proofsteptby {Logo $ab  \in H_1$ e $ab\in H_2$.}  {$H_1$ e $H_2$ grupos}
\proofsteptby {Logo $ab  \in H_1\inter H_2$.}      {def.~$\inter$}
\intertext{e pelos inversos:}
\proofsteptnb {Seja $a \in H_1\inter H_2$.}
\proofsteptby {Logo $a      \in H_1$ e $a\in H_2$.}      {def.~$\inter$}
\proofsteptby {Logo $a^{-1} \in H_1$ e $a^{-1}\in H_2$.} {$H_1$ e $H_2$ grupos}
\proofsteptby {Logo $a^{-1} \in H_1\inter H_2$.}         {def.~$\inter$}
\endstepproof
e o resultado segue graças ao~\ref[nonempty_subgroup_criterion].

%%}}}

%%{{{ x: union_of_subgroups_is_a_subgroup_wrong 
\exercise.
%%%{{{ meta 
\label union_of_subgroups_is_a_subgroup_wrong
%%%}}}

Trocamos o $\inter$ para $\union$
no~\ref[intersection_of_subgroups_is_a_subgroup].
\item{(i)} Ache o erro na demonstração seguinte:
\quote
<<Como $H \leteq H_1\inter H_2 \subset G$,
precisamos mostrar que $H$ é fechado sobre a operação:
\stepproof
\proofsteptnb {Sejam $a,b \in H_1\union H_2$.}
\proofsteptby {Logo $a,b \in H_1$ ou $a,b\in H_2$.}   {def.~$\union$}
\proofsteptby {Logo $ab \in H_1$ ou $ab\in H_2$.}     {$H_1$ e $H_2$ grupos}
\proofsteptby {Logo $ab \in H_1\union H_2$.}          {def.~$\union$}
\intertext{e sobre os inversos:}
\proofsteptnb {Seja $a \in H_1\union H_2$.}
\proofsteptby {Logo $a \in H_1$ ou $a\in H_2$.}           {def.~$\union$}
\proofsteptby {Logo $a^{-1} \in H_1$ ou $a^{-1}\in H_2$.} {$H_1$ e $H_2$ grupos}
\proofsteptby {Logo $a^{-1} \in H_1\union H_2$.}          {def.~$\union$}
\endstepproof
Portanto, $H_1 \union H_2 \subgroup G$.>>
\endquote
\item{(ii)} Demonstre que a proposição não é válida.

%%}}}

%%{{{ x: arbitrary_intersection_of_subgroups_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label arbitrary_intersection_of_subgroups_is_a_subgroup
%%%}}}

Generalize a~\ref[intersection_of_subgroups_is_a_subgroup] para
intersecções arbitrárias:
se $G$ é um grupo, e $\scr H$ uma família não vazia de subgrupos de $G$,
então $\Inter {\scr H} \subgroup G$.

%%}}}

%%{{{ x: ongruence_mod_H_teaser 
\exercise.
%%%{{{ meta 
\label congruence_mod_H_teaser
\pdefs
    \pdef RH {\rel {R_H}}
    ;;
%%%}}}

Seja $G$ conjunto e $H\subgroup G$.
Defina no $G$ a relação $\RH$ pela
$$
a \RH b \defiff a\ginv b \in H.
$$
Decida se a relação $\RH$ é uma
relação de ordem parcial, de ordem total, de equivalência, ou nada disso.

\hint
É uma relação de equivalência.
Demonstre as 3 propriedades!

\solution
\def\RH{\rel {R_H}}%
\proofpart{Reflexiva:}
Seja $a\in G$.
Calculamos:
$$
\align
a \RH a
&\iff a\ginv a\in H\\
&\iff e\in H
\endalign
$$
que é verdade pois $H\subgroup G$.
\crproofpart{Transitiva:}
Sejam $a,b,c \in G$ tais que $a \RH b$ e $b \RH c$.
Precisamos mostrar que $a \RH c$, ou seja, mostrar que $a\ginv c \in H$.
Temos
\compute
a\ginv b &\in H  \by {$a \RH b$} \tag 1 \\
b\ginv c &\in H  \by {$b \RH c$} \tag 2 \\
(a\ginv b) (b \ginv c) &\in H \by {pelas (1) e (2) pois $H\subgroup G$} \\
\endcompute
Logo $a\ginv b b \ginv c = a \ginv c \in H$.
\crproofpart{Simétrica:}
Sejam $a,b \in G$ tais que $a \RH b$, ou seja, $a\ginv b \in H$\fact1.
Vamos demonstrar que $b \RH a$, ou seja, queremos $b\ginv a \in H$.
Mas como $H$ é fechado pelos inversos, pela~\byfact1~temos que
$\ginvp{a\ginv b}\in H$.
Mas calculando
\compute
\ginvp{a\ginv b}
&= \ginvp{\ginv b} \ginv a      \by {inv.~de~op.} \\
&= b \ginv a                    \by {inv.~de~inv.} \\
\endcompute
ou seja, $b\ginv a \in H$.

%%}}}

\endsection
%%}}}

%%{{{ Generators 
\section Geradores.
%%%{{{ meta 
\label Group_generators
%%%}}}

%%{{{ df: subgroup_generated_by_a 
\definition.
%%%{{{ meta 
\label subgroup_generated_by_a
\defines
    * \generate {~a}  -- o subgrupo gerado por o elemento $a$
    * grupo!subgrupo!gerado por elemento
    ;;
%%%}}}

Sejam $G$ grupo e $a\in G$.
Chamamos o
$$
\align
\generate{a}
&\defeq \setst {a^m} {m\in\ints}\\
&= \set{\dotsc,a^{-2},a^{-1},a^0,a^1,a^2,\dotsc}
\endalign
$$
o \dterm{subgrupo de $G$ gerado por $a$}.

%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generated_by_a 
\exercise.
%%%{{{ meta 
\label justify_subgroup_on_subgroup_generated_by_a
%%%}}}

Justifica a palavra ``subgrupo'' na~\ref[subgroup_generated_by_a].
Ou seja, demonstre que para qualquer grupo $G$ e qualquer $a\in G$,
$\generate a \subgroup G$.

\hint
Use o~\ref[nonempty_subgroup_criterion].

\solution
Graças ao~\ref[nonempty_subgroup_criterion],
precisamos verificar que $\generate a$ é fechado pela operação e pelos inversos.
\eop\noi
\proofpart{Fechado pela operação:}
Sejam $h_1,h_2\in\generate a$.
Logo
$h_1 = a^{k_1}$\fact1
e 
$h_2 = a^{k_2}$\fact2
para alguns $k_1,k_2\in\ints$.
Precisamos mostrar que $h_1h_2\in\generate a$.
Calculamos:
\compute
h_1h_2
&= a^{k_1} a^{k_2}  \by {pelas~\byfact1,\byfact2} \\
&= a^{k_1 + k_2}    \by {pela~\ref[properties_of_powers_in_groups]~(1)} \\
&\in \generate a.   \by {def.~$\generate a$, pois $k_1+k_2\in\ints$} \\
\endcompute
\proofpart{Fechado pelos inversos:}
Seja $h \in \generate a$,
logo $h = a^k$ para algum $k\in\ints$.
Pela~\ref[properties_of_powers_in_groups]~(3),
$$
\ginv h = \ginvp {a^k} = a^{-k} \in \generate a.
$$

%%}}}

%%{{{ x: Cyclic group of e 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $\sset G {\ast,e}$ grupo.
Calcule o $\generate e$.

\solution
$\generate e = \set {e}$.

%%}}}

%%{{{ x: Calculate some sets and subgroups of ints 
\exercise.
%%%{{{ meta 
%%%}}}

Nos inteiros com adição, calcule os
$\generate 4$,
$\generate 4 \inter \generate 6$,
$\generate 4 \inter \generate {15}$,
e
$\generate 4 \union \generate 6$.
\eop\noi
Quais deles são subgrupos do $\ints$?

%%}}}

%%{{{ Q: How would you generalize gen a to gen A? 
\question.
%%%{{{ meta 
%%%}}}

Como tu generalizarias o
<<subgrupo gerado por $a\in G$>>
para
<<subgrupo gerado por $A \subset G$>>?
Ou seja, como definirias o $\generate A$ para qualquer $A \subset G$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Falando de \emph{generalização}, a idéia é que queremos definir o $\gen A$ num jeito
\emph{razoável} e tal que $\gen {\set a} = \gen a$.

%%}}}

\spoiler

%%{{{ A wrong generalization of <a> to <A> 
\note.
%%%{{{ meta 
\label wrong_generalization_of_gord_a_to_gord_A
%%%}}}

Queremos generalizar o conceito de geradores para definir $\generate A$,
onde $A\subset G$.
Seguindo ingenuamente a definição de $\generate a$,
uma primeira abordagem seria botar
$$
\generate A = \setst {a^m} {a \in A,\  m \in\ints}
$$
e chamar $\generate A$ o subgrupo de $G$ gerado por $A$.\mistake

%%}}}

%%{{{ x: find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A 
\exercise.
%%%{{{ meta 
\label find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A
%%%}}}

Qual o problema com a definição de $\generate A$ acima?

\hint
Calcule o $\generate {4,6}$ no $\sset \ints +$.

\hint
Ele é um subgrupo?

%%}}}

%%{{{ x: subgroup_generated_by_two_members 
\exercise.
%%%{{{ meta 
\label subgroup_generated_by_two_members
%%%}}}

Tentando generalizar primeiramente para o caso mais simples de <<subgrupo gerado por dois membros $a,b\in G$>>,
alguém definiu o $\gen {a,b}$ para quaisquer $a,b \in G$ assim:
$$
\generate {a,b} \defeq \setst {a^m b^n} {m,n \in \ints}.
$$
Existe um problema.  Qual?

\hint
Se $G$ fosse abeliano, daria certo.

\solution
O problema é que não podemos chamar isso \emph{subgrupo}, pois não é garantidamente fechado pela operação.
Por exemplo,
sabendo que $a \in \gen{a,b}$ e $a\ast b\in\gen{a,b}$, deveriamos ter
$(ab)a \in \gen{a,b}$, mas o $(ab)a$ \emph{em geral} não pode ser escrito na
forma $a^m b^n$.
Uma outra observação similar que serve também é que o inverso de
$ab \in \gen{a,b}$ é o $\ginv b \ginv a$ que também \emph{em geral} não
pode ser escrito na forma $a^m b^n$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos finalmente definir o $\gen A$.

%%}}}

%%{{{ df: subgroup_generate_A_direct 
\definition direta.
%%%{{{ meta 
\label subgroup_generate_A_direct
\defines
    * \generate {~A}  -- o subgrupo gerado por o conjunto $A$
    * grupo!subgrupo!gerado por subconjunto
    ;;
%%%}}}

Sejam $\sset G \ast$ grupo e $A\subset G$.
Chamamos o
$$
\generate A
\defeq
\setstt {a_0\ast\dotsb\ast a_{k-1}}
        {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
$$
o \dterm{subgrupo de $G$ gerado por $A$}.
Ou seja, os membros de $\generate A$ são os produtos finitos feitos por
membros de $A$ e seus inversos.
Abusando a notação, escrevemos também $\generate {a_1, a_2,\dotsc, a_n}$
para o $\generate {\set{a_1, a_2,\dotsc, a_n}}$.

%%}}}

%%{{{ remark: why_e_is_in_every_generated_subgroup 
\remark.
%%%{{{ meta 
\label why_e_is_in_every_generated_subgroup
%%%}}}

Lembre-se (\ref[operating_on_an_empty_list_of_objects]) que para $k=0$
a expressão acima é a identidade $e$,
e logo $e \in \generate A$ para qualquer $A$.

%%}}}

%%{{{ property: equivalent_formulations_for_generate_A 
\property.
%%%{{{ meta 
\label equivalent_formulations_for_generate_A
%%%}}}

As alternativas definições são equivalentes:
$$
\generate A
=
\leftbrace {
\aligned
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A} \\
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} \\
& \setstt {a_0\ast\dotsb\ast a_{k-1}}
          {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\endaligned
}
$$

%%}}}

%%{{{ x: check_that_a_word_satisfies_all_three_definitions_for_generate_A 
\exercise.
%%%{{{ meta 
\label check_that_a_word_satisfies_all_three_definitions_for_generate_A
%%%}}}

Sejam $G$ grupo e um subconjunto dele $A=\set{a,b,c,d}$.
Mostre que $a^3b^{-2}cb^3d^{-1} \in \generate A$ para todas
as três definições equivalentes da~\ref[equivalent_formulations_for_generate_A].
Ou seja, para cada um desses conjuntos, decida quais são todas as atribuições
necessárias que satisfazem o ``filtro'' de cada conjunto.

\solution
Pela sua forma, já é óbvio que
$$
\align
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A}.
\intertext{Basta tomar $k\asseq 5$ e}
&
\alignedat2
a_0 &\asseq a  & m_0 &\asseq 3  \\
a_1 &\asseq b  & m_1 &\asseq -2 \\
a_2 &\asseq c  & m_2 &\asseq 1  \\
a_3 &\asseq b  & m_3 &\asseq 3  \\
a_4 &\asseq d  & m_4 &\asseq -1
\endalignedat
\intertext{e pronto!  Mas para mostrar que}
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} 
\intertext{não podemos fazer a mesma escolha, pois cada um dos $m_i$
pode ser ou $1$ ou $-1$.  Basta só aumentar o $k$, e tomando $k \asseq 10$ e}
&
\alignedat4
a_0 &\asseq a  & m_0 &\asseq 1  & a_5 &\asseq c  & m_5 &\asseq 1 \\
a_1 &\asseq a  & m_1 &\asseq 1  & a_6 &\asseq b  & m_6 &\asseq 1 \\
a_2 &\asseq a  & m_2 &\asseq 1  & a_7 &\asseq b  & m_7 &\asseq 1 \\
a_3 &\asseq b  & m_3 &\asseq -1 & a_8 &\asseq b  & m_8 &\asseq 1 \\
a_4 &\asseq b  & m_4 &\asseq -1 & a_9 &\asseq d  & m_9 &\asseq -1.
\endalignedat
\intertext{Finalmente para demonstrar que}
a^3b^{-2}cb^3d^{-1}
&\in \setstt {a_0\ast\dotsb\ast a_{k-1}}
             {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\intertext{o $k$ é o mesmo, $k\asseq 10$, e basta escolher nossos $a_i$'s
em tal forma que cada um deles ou é membro de $A$ ou seu inverso é.  Fácil:}
&
\alignedat2
a_0 &\asseq a        & a_5 &\asseq c \\
a_1 &\asseq a        & a_6 &\asseq b \\
a_2 &\asseq a        & a_7 &\asseq b \\
a_3 &\asseq \ginv b  & a_8 &\asseq b \\
a_4 &\asseq \ginv b  & a_9 &\asseq \ginv d.
\endalignedat
\endalign
$$

%%}}}

%%{{{ df: group_word 
\definition Palavra.
%%%{{{ meta 
\label group_word
%%%}}}

Chamamos dum termo feito por membros dum grupo $G$ operados entre si
de \dterm{palavra} de $G$.  Especificando um subconjunto $A\subset G$,
uma $A$-palavra seria uma palavra de $G$ feita usando apenas membros
de $A$ e seus inversos.

%%}}}

%%{{{ eg: some_examples_of_words 
\example.
%%%{{{ meta 
\label some_examples_of_words
%%%}}}

Seja $G$ grupo e $A=\set{w,x,y,z}$ um subconjunto de $G$.
Umas $A$-palavras são as:
$$
\xalignat5
& wxyz  &
& \ginv x &
& wwwwwww &
& wxx\ginv yyyyw\ginv zw &
& \ginv z\ginv z \ginv z y \ginv y z z x \ginv x z
\intertext{Podemos usar exponentes para abreviar essas palavras:}
& wxyz  &
& \ginv x &
& w^7 &
& wx^2\ginv yy^3w\ginv zw &
& z^{-3} y \ginv y z^2 x \ginv x z.
\intertext{e às vezes até usamos um ``overline'' para indicar os inversos:}
& wxyz  &
& \overline x &
& w^7 &
& w\,x^2\,\overline y\,y^3\,w\,\overline z\,w &
& \overline z^3\,y\,\overline y\,z^2\,x\,\overline x\,z.
\endxalignat
$$
Observe que começando com uma palavra podemos \emph{computar} seu valor,
sendo uma palavra onde não aparecem consecutivos objetos canceláveis,
aplicando um passo cada vez: selecionando um tal par e o apagando.

%%}}}

%%{{{ remark: generate_A is the set of all values of A-words 
\remark.
%%%{{{ meta 
%%%}}}

Com essa definição o $\generate A$ é feito por os valores de todas
as $A$-palavras.

%%}}}

%%{{{ x: Calculate <> and <G> 
\exercise.
%%%{{{ meta 
%%%}}}

Dado grupo $G$,
calcule os $\generate \emptyset$ e $\generate G$.

\hint
Considere o ``produto vazio'' igual ao $e\in G$.

\solution
Temos
$$
\align
\generate \emptyset &= \set{e} \\
\generate G         &= G.
\endalign
$$

%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generate_A_direct 
\exercise.
%%%{{{ meta 
\label justify_subgroup_on_subgroup_generate_A_direct
%%%}}}

Demonstre que $\generate A \subgroup G$ para qualquer grupo $G$ e qualquer $A\subset G$.

%%}}}

%%{{{ Q: How would you describe bottom-up and top-down for generate_A? 
\question.
%%%{{{ meta 
%%%}}}

Temos duas mais caracterizações do~$\generate A$ especialmente
importantes: bottom-up e top-down.  A gente já encontrou algo
similar, definindo os fechos de relações (especialmente o fecho
transitivo) no \ref[Relations],~\reftag[Closures].
Como descreverias os dois processos para definir o $\generate A$?

%%}}}

\spoiler

%%{{{ generated_subgroup_bottom_up_informally 
\note Bottom-up, informalmente.
%%%{{{ meta 
\label generated_subgroup_bottom_up_informally
%%%}}}

Começamos com um conjunto~$T$ onde botamos todos os elementos que desejamos
no subgrupo (os elementos de~$A$ nesse caso),
e enquanto isso não forma um grupo, ficamos nos perguntando \emph{por que não}.
A resposta sempre é que (pelo menos) uma lei de grupo ((G0)--(G3)) está sendo
violada.
Vendo as leis, isso sempre quis dizer que um certo elemento tá faltando:
\tlist:
\li: (G0) violada: para alguns~$s,t \in T$, o~$s\ast t \notin T$.
\li: (G1) violada é impossível (veja~\ref[ass_for_free_in_subgroup]).
\li: (G2) violada: a identidade~$e \notin T$.
\li: (G3) violada: para algum~$t \in T$, seu inverso~$\ginv t \notin T$.
\endtlist
E agora?
\tlist:
\li: (G0) violada? Resolução: adicione o $st$: $T\union \set{st}$.
\li: (G2) violada? Resolução: adicione o $e$: $T\union \set{e}$.
\li: (G3) violada? Resolução: adicione o $\ginv t$: $T\union \set{\ginv t}$.
\endtlist
Como resolver cada um desses três possíveis problemas então?
Adicionando os membros culpados!  E depois?  Se o conjunto já virou
um grupo, paramos.  Se não, continuamos.
Ficamos \emph{adicionando} os membros culpados (os faltantes)
e repetindo a mesma pergunta, até chegar num conjunto que não viola
nenhuma das leis, ou seja, um grupo mesmo.
É o conjunto~$T$ que tem todos os elementos de~$A$ e todos os
necessários de~$G$ para formar um grupo.
\eop
Cuidado: é tentoso pensar como resolução \emph{retirar} os $s,t$, no caso da
(G0), ou o $t$ no caso da (G3).  Por exemplo, alguém poderia pensar que o
problema no caso da violada (G0), foi a presença dos $s,t$ no $T$; mas não é!
O problema é a ausência do $st$.  Lembre nossa intuição: queremos começar com o
$A$ e sem perder nenhum dos seus membros, chegar num subgrupo de $G$, adicionando
apenas os necessários.

%%}}}

%%{{{ thm: generated_subgroup_bottom_up_formally 
\theorem Bottom-up, formalmente.
%%%{{{ meta 
\label generated_subgroup_bottom_up_formally
%%%}}}

Sejam $G$ grupo e $A \subset G$.
Definimos a seqüência de conjuntos:
$$
\align
A_0     &= A\\
A_{n+1} &= A_n
\union \tubrace {\setst {ab} {a,b \in A_n}} {(G0)}
\union \tubrace {\set e} {(G2)}
\union \tubrace {\setst {\ginv a} {a \in A_n}} {(G3)}.
\endalign
$$
Logo temos:
$$
\gather
A = A_0 \subset A_1 \subset A_2 \subset A_3 \subset \dotsb\\
\generate A = \Union_{n=0}^{\infty} A_n.
\endgather
$$

\sketch.
Provar $A_n \subset A_{n+1}$ para todo $n\in\nats$ é imediato
por indução.  Para a afirmação principal,
que $\generate A = \Union_{n=0}^{\infty} A_n$,
provamos cada direção separadamente:
para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e ache $w\in\nats$ tal que $\alpha \in A_w$;
para a {\rldirset}, basta demonstrar que cada um dos $A_0, A_1, A_2, \dots$
é subconjunto de $\generate A$.  Podes---alias, deves---usar indução.

%%}}}

%%{{{ eg: tree_for_a_member_of_generate_A 
\example.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A
%%%}}}

Pensando em como demonstrar formalmente o~\ref[generated_subgroup_bottom_up_formally],
talvez ajuda considerar um exemplo específico para entender melhor como funcciona.
Considere então um $A=\set{a,b}\subset G$ e um $a^3b^{-8}\in\generate A$.
Como podemos demonstrar que $a^3b^{-8} \in \Union_n A_n$?
Basta achar um $n\in\nats$ tal que $a^3b^{-8}\in A_n$; mas qual $n$ serve aqui?
Vamos plantar uma árvore abreviada e rascunhosa:
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
               \A {b \in A}
            \I1-------------- {}
                {b \in A_0}
\I2--------------- {}
    {b^2 \in A_1}
               \A {b \in A}
            \I1-------------- {}
                {b \in A_0}
            \I1-------------- {}
                {b \in A_1}
\I2--------------- {}
    {b^3 \in A_2}
               \A {\vdots}
            \I1-------------- {}
                {b \in A_2}
\I2--------------- {}
    {b^4 \in A_3}
\I1--------------- {}
       {\vdots}
\I1--------------- {}
    {b^7 \in A_6}
               \A {\vdots}
            \I1-------------- {}
                {b \in A_6}
\I2--------------- {}
    {b^8 \in A_7}
\I1----------------- {}
    {b^{-8} \in A_8}
                           \A {a \in A}
                      \I1------------------ {}
                            {a \in A_0}
                      \I1------------------ {}
                           {a^2 \in A_1}
                                                  \A {a \in A}
                                              \I1--------------- {}
                                                   {a \in A_0}
                                               \I1-------------- {}
                                                   {a \in A_1}
                      \I2--------------------------------------- {}
                                   {a^3 \in A_2}
                               \I1------------------ {}
                                   {a^3 \in A_8}
\I2-------------------------------------------------- {}
                {a^3 b^{-8} \in A_9}
}
$$
Então já sabemos que o $n\asseq 9$ é suficiente e logo concluimos
que $a^3 b^{-8} \in \Union_n A_n$.

%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_justifications 
\exercise.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A_justifications
%%%}}}

Justifique as linhas de inferência da árvore
do~\ref[tree_for_a_member_of_generate_A].

\solution
\let\rulelabel=\textrmsmallish
A parte esquerda parece assim:
$$
\PROOFmr {
   \A {b \in A}
\I1-------------- {(1)}
    {b \in A_0}
                    \A {b \in A}
                 \I1-------------- {(2)}
                     {b \in A_0}
\I2---------------------------- {(3)}
         {b^2 \in A_1}
                          \A {b \in A}
                       \I1-------------- {(4)}
                           {b \in A_0}
                       \I1-------------- {(5)}
                           {b \in A_1}
   \I2------------------------------- {(6)}
              {b^3 \in A_2}
                                            \A {\vdots}
                                         \I1-------------- {(7)}
                                             {b \in A_2}
\I2------------------------------------------------------ {(8)}
                   {b^4 \in A_3}
              \I1--------------- {*}
                     {\vdots}
              \I1--------------- {*}
                  {b^7 \in A_6}
                                         \A {\vdots}
                                     \I1-------------- {(9)}
                                         {b \in A_6}
              \I2----------------------------------- {(10)}
                            {b^8 \in A_7}
                     \I1--------------------- {(11)}
                           {b^{-8} \in A_8}
}
$$
Onde as justificativas são:
\tlist:
\li (1):  def.~$A_0$;
\li (2):  def.~$A_0$;
\li (3):  def.~$A_1$~(G0);
\li (4):  def.~$A_0$;
\li (5):  $A_0 \subset A_1$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (6):  def.~$A_2$~(G0);
\li (7):  $A \subset A_2$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (8):  def.~$A_3$~(G0);
\li (9):  $A \subset A_6$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (10): def.~$A_7$~(G0);
\li (11): def.~$A_8$~(G3).
\endtlist
Nas (*) usamos a regra inferida:
$$
\PROOFmr {
     \A {x^k \in A_m}
\I1-------------------- {$x\in A$}
   {x^{k+1} \in A_{m+1}}
}
\qquad\leadsto\qquad
\PROOFmr {
\A {x^k \in A_k}
                 \A {x \in A_0}
                \I1------------- {$A_0\subset A_k$}
                    {x \in A_k}
\I2----------------------------- {def.~$A_{k+1}$~(G0)}
        {x^2 \in A_{k+1}}
}
$$
O resto da arvore é justificado numa maneira parecida.

%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_shorter 
\exercise.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A_shorter
%%%}}}

Com uma arvore mais baixa demonstre que $a^3 b^{-8} \in A_5$.

\hint
Tem como mostrar $b^{-8} \in A_4$.

\hint
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {}
    {b^2 \in A_1}
\I1--------------- {}
    {b^4 \in A_2}
\I1--------------- {}
    {b^8 \in A_3}
}
$$
Como justificar cada linha?

\solution
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {*}
    {b^2 \in A_1}
\I1--------------- {*}
    {b^4 \in A_2}
\I1--------------- {*}
    {b^8 \in A_3}
\I1----------------- {}
    {b^{-8} \in A_4}
                               \A {a \in A}
                          \I1------------------ {}
                                {a \in A_0}
                          \I1------------------ {*}
                               {a^2 \in A_1}
                                                          \A {a \in A}
                                                      \I1--------------- {}
                                                           {a \in A_0}
                                                       \I1-------------- {}
                                                           {a \in A_1}
                          \I2-------------------------------------------- {}
                                       {a^3 \in A_2}
                                   \I1------------------ {}
                                       {a^3 \in A_4}
\I2------------------------------------------------------ {}
                {a^3 b^{-8} \in A_5}
}
$$
Onde explicamos a regra inferida (*):
$$
\PROOFm {
\A {x \in A_m}
\I1-------------- {*}
   {x^2 \in A_{m+1}}
}
\qquad\leadsto\qquad
\PROOFm {
\A {x \in A_k}
\A {x \in A_k}
\I2----------------- {}
   {x^2 \in A_{k+1}}
}
$$
A parte esquerda com pouco mais detalhe parece assim:
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
                   \A {b \in A}
                \I1-------------- {}
                    {b \in A_0}
\I2-------------------------------- {}
           {b^2 \in A_1}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^2 \in A_1}
        \I2-------------------------- {}
           {b^4 \in A_2}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^4 \in A_2}
        \I2--------------------------- {}
                {b^8 \in A_3}
}
$$

%%}}}

%%{{{ generated_subgroup_top_down_informally 
\note Top-down, informalmente.
%%%{{{ meta 
\label generated_subgroup_top_down_informally
%%%}}}

Começamos considerando o próprio $G$ como um possível candidato para ser
o subgrupo de $G$ gerado por o conjunto $A$.  No final das contas,
$G \subgroup G$, e também $G \supset A$.
Mas no~$G$ existe possível ``lixo'': membros fora do~$A$ cuja presença não
foi justificada como necessária pelas leis de grupo.
Precisamos filtrar esse lixo, para ficar apenas com os membros ``necessários''.
Quais são esses membros?
Bem, se conseguir formar um subgrupo $H \subgroup G$
tal que $H\supset A$ e que \emph{não} tem alguns dos membros,
isso quis dizer que eles não são realmente necessários; ou seja, é lixo.
Então quem fica mesmo?
Ficam apenas aqueles que pertencem a \emph{todos} os subgrupos de $G$
que contêm o $A$.  Estes membros são exatamente os membros do $\generate A$.

%%}}}

%%{{{ top_down_heart_level 
\note Top-down: nível coração.
%%%{{{ meta 
\label top_down_heart_level
%%%}}}

Vamos pensar em nosso alvo (o $\generate A$) como o \emph{menor} de todos
os subgrupos de $G$ que contêm o $A$.  O que significa esse \wq{menor}?
Menor em qual ordem?  Não ligamos sobre quantidade de elementos aqui.
Menor quis dizer subgrupo---lembra que $\subgroup$ é uma
ordem~(\ref[subgroup_is_an_order]), né?---ou $\subset$-menor,
que \emph{nesse caso} acaba sendo equivalente.
O que tudo isso quis dizer?
Queremos definir o $\generate A$ como
\emph{aquele} conjunto $\overline A$ que satisfaz:
(i) $A \subset \overline A \subgroup G$; e
(ii) para todo $K$ tal que $A \subset K \subgroup G$,
temos $\overline A \subgroup K$.
Observe que nada muda se trocar o $\subgroup$ por $\subset$ na última condição,
pois como $\generate A$ e $K$ são subgrupos de $G$, as afirmações
$\overline A \subset K$ e $\overline A \subgroup K$ são equivalentes.
\eop
Podemos parar nossa definição aqui?  Não, pois esse \wq{aquele} acima
não foi merecido ainda: como sabemos que existe tal conjunto?
Felizmente, graças à (ii), se tal conjunto existe,
ele é único~(\ref[uniqueness_of_minimum_subgroup_containing_A]).
\eop
Começamos com a família~$\scr H$ de \emph{todos} os subgrupos de~$G$
que contêm o~$A$:
$$
\scr H = \setst {H} {A \subset H \subgroup G}.
$$
Afirmamos que o conjunto que procuramos é o $\Inter \scr H$.
Basta verificar que ele satisfaz todas as condições,
algo que tu vai fazer agora nos exercícios abaixo, mas antes disso\dots

%%}}}

%%{{{ x: intersection_of_possibly_empty_family_in_top_down_heart_level 
\exercise.
%%%{{{ meta 
\label intersection_of_possibly_empty_family_in_top_down_heart_level
%%%}}}

Mesmo verificando essas três coisas, ainda falta demonstrar algo!
Temos um erro sutil mas importantíssimo;
\emph{como se fosse} uma possível divisão por zero!
Ache o que é, e demonstre o que precisas demonstrar para corrigi-lo.

\solution
Precisamos verificar que a família $\scr H$ tem pelo menos um membro
antes de intersectar (veja a resolução do~\ref[Inter_emptyset]).
Fato, pois já temos um membro dela: o próprio $G$!
É imediato verificar que $G \in \scr H$, e logo $\scr H \neq \emptyset$.

%%}}}

%%{{{ x: intersection_of_cal_H_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_is_a_subgroup
%%%}}}

$\Inter \scr H \subgroup G$.

\solution
Imediato pelo~\ref[arbitrary_intersection_of_subgroups_is_a_subgroup],
pois $\scr H$ e não vazia e todos os seus membros são subgrupos.

%%}}}

%%{{{ x: intersection_of_cal_H_contains_A 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_contains_A
%%%}}}

$A \subset \Inter \scr H$.

\solution
Pela definição da $\scr H$, para todo $H \in \scr H$ temos $A \subset H$.
Logo $A \subset \Inter \scr H$.
Isso deveria ser óbvio, e resolvido desde~\ref[Inter_of_supsets_supset].

%%}}}

%%{{{ x: intersection_of_cal_H_is_contained_in_every_other_candidate 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_is_contained_in_every_other_candidate
%%%}}}

Para cada candidato $K$ com $A \subset K \subgroup G$, temos
$\Inter \scr H \subgroup K$.

\hint
Como já provamos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta demonstrar $\Inter \scr H \subset K$.

\solution
Seja $K$ tal que $A \subset K \subgroup G$.
Como já provamos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta demonstrar $\Inter \scr H \subset K$.
Mas, pela sua escolha, $K$ é um dos membros da família $\scr H$,
e logo $\Inter \scr H \subset K$.
Se isso não é óbvio, resolva o~\ref[Inter_is_contained_in_every_member].

%%}}}

%%{{{ x: uniqueness_of_minimum_subgroup_containing_A 
\exercise.
%%%{{{ meta 
\label uniqueness_of_minimum_subgroup_containing_A
%%%}}}

Demonstre que realmente a condição (ii) acima garanta que se tal conjunto
existe, ele é único.

\solution
Isso não é nada demais do que unicidade do mínimo, se existe,
algo fácil para demonstrar num contexto geral para qualquer ordem
(\ref[uniqueness_of_min_max]).
Mas vamos ver essa prova nesse contexto especifico aqui.
Suponha que $\overline A, A'$ ambos satisfazem a (i)--(ii).
Vamos demonstrar que $\overline A = A'$.
Como $\overline A$ satisfaz a (ii) e $A'$ satisfaz a (i), temos
$$
\overline A \subgroup A'.
$$
No outro lado, $A'$ satisfaz a (ii) e $\overline A$ satisfaz a (i), logo
$$
A' \subgroup \overline A.
$$
Logo $\overline A = A'$, pois a relação de subgrupo é
antissimétrica~(\ref[subgroup_is_an_order]).

%%}}}

%%{{{ thm: generated_subgroup_top_down_formally 
\theorem Top-down, formalmente.
%%%{{{ meta 
\label generated_subgroup_top_down_formally
%%%}}}

Sejam $G$ grupo e $A\subset G$.
Logo
$$
\generate A = \Inter \setst { H \subgroup G } { A \subset H }.
$$

\sketch.
Seja $\scr H = \setst { H \subgroup G } { A \subset H }$.
Provamos cada direção separadamente:
Para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e um arbitrário $H \subgroup G$ tal que $H \supset A$,
e mostre que $\alpha\in H$.
Para a {\rldirset}, tome um $\alpha$ que pertence a todos
os subgrupos de $G$ que contêm o $A$ e mostre que
ele pode ser escrito na forma desejada (da definição de~$\generate A$).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ou seja, temos três definições equivalentes de \dterm{subgrupo gerado por $A$}.

%%}}}

%%{{{ df: cyclic_group 
\definition Grupo cíclico.
%%%{{{ meta 
\label cyclic_group
\defines
    * Grupo!cíclico
    ;;
%%%}}}

Um grupo $G$ é \dterm{cíclico} sse existe $a\in G$ tal que $\generate a = G$.

%%}}}

%%{{{ x: cyclic_and_noncyclic_groups 
\exercise.
%%%{{{ meta 
\label cyclic_and_noncyclic_groups
%%%}}}

Quais dos seguintes são grupos cíclicos?
$$
\xalignat8
& \sset \reals + &
& \sset \rats +  &
& \sset \ints +  &
& \sset {\reals_{\neq0}} \ntimes &
& \sset {\rats_{\neq0}} \ntimes  &
& \sset {\ints_6} {+_6} &
& \sset {\ints_6\setminus\set0} {\ntimes_6} &
& \sym 3
\endxalignat
$$

\solution
O $\sset \reals +$ não é.
O $\sset \rats +$ também não.
O $\sset \ints +$ é: $\generate 1 = \sset \ints +$.
O $\sset {\reals_{\neq0}} \ntimes$ não é.
O $\sset {\rats_{\neq0}} \ntimes$ também não é.
O $\sset {\ints_6} {+_6}$ é: $\generate 1 = \sset {\ints_6} {+_6}$
O $\sset {\ints_6\setminus\set0} {\ntimes_6}$ nem é grupo!
O $\sym 3$ não é.

%%}}}

%%{{{ x: generators_of_additive_Z6
\exercise.
%%%{{{ meta 
\label generators_of_additive_Z6
%%%}}}

Ache todos os membros geradores de $\sset {\ints_6} {+_6}$.

\hint
Ele tem dois.

\solution
$\generate 1 = \generate 5 = \ints_6$.

%%}}}

%%{{{ x: generators_of_S3 
\exercise.
%%%{{{ meta 
\label generators_of_S3
%%%}}}

Ache todos os geradores $A$ de $\sym 3$ com tamanho $2$.

%%}}}

\endsection
%%}}}

%%{{{ A detour: bottom-up and top-down 
\section Um desvio: bottom-up e top-down.
%%%{{{ meta 
\label Bottom_up_and_top_down
%%%}}}

%%{{{ Thingies and subthingies
\note Bichos e subbichos.
%%%{{{ meta 
%%%}}}

As idéias de bottom-up e top-down são tão fundamentais que vale a pena
desviar um pouco do nosso estudo de grupos para discutir e generalizar
o que acabou de acontecer.
Vamos dizer que temos um tipo de coisas que gostamos e estudamos.
Aqui esse tipo de coisas foi o grupo, mas queremos ver essas
idéias num contexto ainda mais abstrato e geral.
Então não vamos especificar esse tipo.
Vamos chamar esses objetos de \dterm{bichos}.
Suponha agora que cada bicho tem ``por trás'' um associado conjunto.
Por exemplo, os grupos e em geral os conjuntos estruturados tem seus carrier sets.
Então faz sentido de unir, intersectar, etc., bichos.
Suponha também que cada bicho tem algo que faz seu conjunto ser especial:
sua estrutura, umas leis, etc.
Assim, já temos como definir o que significa \dterm{subbicho}:
\emph{$B_0$ é subbicho do bicho $B$ sse $B_0 \subset B$ e $B_0$ também é um bicho}.
Agora comece com um bicho $B$, e considere um subconjunto $S \subset B$,
que não é necessariamente um subbicho.
Queremos definir o \dterm{subbicho gerado por $S$}.
Precisamos:
\elist 1:
\li: saber que a relação de ``subbicho'' é uma ordem;
\li: saber que intersecção arbitrária de bichos é bicho.
\endelist
Agora podemos definir o \dterm{subbicho gerado por $S$} para ser o menor subbicho
de $B$ que contem o $S$, ou seja, a intersecção
$$
\align
\generate S &= \Inter \setstt {C} {$C$ é subbicho de $B$ que contem o $S$}.
\intertext{Curtamente: dados $S \subset B$, temos}
\generate S &= \Inter_{\mathclap{S \subset C \leq B}} C,
\endalign
$$
onde $\leq$ aqui significa ``subbicho''.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas construções aparecem o tempo todo, para vários bichos:
espaços topológicos, $\sigma$-algebras, espaços vetoriais, relações transitivas,
modelos de lógica, etc.
Aqui vamos usar como exemplo para ilustrar o processo os \emph{conjuntos convexos}
do plano euclideano $\reals^2$:

%%}}}

%%{{{ df: convex_set_in_plane 
\definition Conjuntos convexos.
%%%{{{ meta 
\label convex_set_in_plane
%%%}}}

Seja $C \subset \reals^2$.
Chamamos o $C$ \dterm{convexo} sse
para todo $P, Q \in C$, o segmento $\segment {PQ} \subset C$.

%%}}}

\TODO Add figures.

%%{{{ x: which_sets_are_convex 
\exercise.
%%%{{{ meta 
\label which_sets_are_convex
%%%}}}

Desenha os subconjuntos seguintes de $\reals^2$:
% TODO: fix reflabs
\elist a:
\li: $\emptyset$;
\li: $\set{\tup{0,0}}$;
\li: $\set{\tup{0,0},\tup{0,1}}$;
\li: $\set{\tup{0,0},\tup{0,1},\tup{1,0},\tup{1,1}}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 = 1}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 \leq 1}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 < 1}$;
\li: $\setst {\tup{x,0}} {0\leq x < 1}$;
\li: $\setst {\tup{x,y}} {\max\set{\abs x, \abs y} < 1}$.
\li: $\setst {\tup{x,y}} {x + y > 1}$.
\endelist
Quais deles são convexos?

%%}}}

%%{{{ x: find_the_convex_hulls 
\exercise.
%%%{{{ meta 
\label find_the_convex_hulls
%%%}}}

Para cada um dos conjuntos do~\ref[which_sets_are_convex]
que não é convexo, desenha seu fecho convexo.

%%}}}

%%{{{ x: convex_sets_have_the_intersection_property 
\exercise.
%%%{{{ meta 
\label convex_sets_have_the_intersection_property
%%%}}}

Demonstre que os conjuntos convexos têm a propriedade de intersecção:
se $\scr C$ é uma família não vazia de conjuntos convexos, então
$\Inter \scr C$ é um conjunto convexo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Logo, \emph{podemos definir} o \dterm{fecho convexo} (ou \dterm{convex hull})
dum subconjunto $S\subset\reals^2$ usando a abordagem top-down.

%%}}}

%%{{{ df: convex_hull_bottom_up 
\definition.
%%%{{{ meta 
\label convex_hull_bottom_up
%%%}}}

Seja $S\subset\reals^2$.
Definimos a seqüência de conjuntos $\seqn S n$ pela recursão:
$$
\align
S_0     &= S \\
S_{n+1} &= S_n \union \setstt {M \in \reals^2} {existem $P,Q \in S_n$ tais que $M$ é um ponto no segmento $\segment {PQ}$}.
\endalign
$$
Agora definimos o \dterm{fecho convexo} (ou \dterm{convex hull}) $\hull S$ de $S$ pela
$$
\hull S \defeq \Union_{n=0}^\infty S_n.
$$

%%}}}

%%{{{ x: convex_hull_bottom_up_deserves_the_name 
\exercise.
%%%{{{ meta 
\label convex_hull_bottom_up_deserves_the_name
%%%}}}

Demonstre que o convex hull $\hull S$ dum $S \subset \reals^2$ merece seu nome:
(i) $\hull S$ é convexo mesmo e contem o $S$; (ii) qualquer convexo $C$ que contem o $S$, está contido no $\hull S$.

%%}}}

%%{{{ Q: how_can_we_define_the_convex_hull_top_down 
\question.
%%%{{{ meta 
\label how_can_we_define_the_convex_hull_top_down
%%%}}}

Como podemos definir o fecho convexo dum conjunto $S\subset\reals^2$ ``top-down''?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Precisamos ter pelo menos um conjunto convexo que contem o $S$,
verificar que intersecção arbitrária de conjuntos convexos é conjunto convexo,
e que a relação ``subconjunto convexo'' é uma ordem.
A última coisa é trivial.  As outras duas, deixo como exercícios
pra ti~(\reftag[at_least_one_convex_contains_S]
e~\reftag[intersection_of_convex_is_convex]).
Com essas coisas podemos definir o $\convexhull S$ como
$$
\convexhull S = \Inter \setst {C} {S \subset C \leq \reals^2}
$$
onde $\leq$ é a relação de ``subconjunto convexo''.
Assim $\convexhull S$:
(i) é convexo e contem o $S$;
(ii) esta contido em qualquer conjunto que satisfaz a (i).
A argumentação é exatamente a mesma com o caso de grupos
(\ref[top_down_heart_level] e os exercícios o seguindo:
\reftag[intersection_of_cal_H_is_a_subgroup];
\reftag[intersection_of_cal_H_contains_A];
\reftag[intersection_of_cal_H_is_contained_in_every_other_candidate]).

%%}}}

%%{{{ x: intersection_of_convex_is_convex 
\exercise.
%%%{{{ meta 
\label intersection_of_convex_is_convex
%%%}}}

A intersecção de uma família não vazia de conjuntos convexos é um conjunto convexo.

%%}}}

%%{{{ x: at_least_one_convex_contains_S 
\exercise.
%%%{{{ meta 
\label at_least_one_convex_contains_S
%%%}}}

Seja $S$ um subconjunto do plano.
Demonstre que a família de todos os conjuntos convexos que
contêm o $S$ não é vazia.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Chega para agora.
No~\ref[Posets_Lattices] vamos revisitar esse assunto num contexto abstrato.

%%}}}

\endsection
%%}}}

%%{{{ Group_conjugation 
\section Conjugação de grupo.
%%%{{{ meta 
\label Group_conjugation
%%%}}}

%%{{{ df: conjugates_of_group_element 
\definition Conjugados.
%%%{{{ meta 
\label conjugates_of_group_element
\defines
    * conjugado!de elemento de grupo
    ;;
%%%}}}

Seja $G$ grupo e $a\in G$.
Para qualquer $g\in G$, o $ga\ginv g$ é chamado
um \dterm{conjugado} de $a$.

%%}}}

%%{{{ df: conjugation_of_group 
\definition conjugação.
%%%{{{ meta 
\indexes
    * relação!conjugação    see: conjugação
    ;;
\defines
    * ~a \gconjrel ~b  -- conjugação de grupo
    * conjugação!de grupo
    ;;
%%%}}}

Seja $G$ um grupo.
A \dterm{conjugação do $G$}
é a relação ${\gconjrel} : \reltype{G,G}$ definida pela
$$
\align
a \gconjrel b
&\defiff \text{$a$ é um conjugado de $b$}\\
&\intiff \lexists {g\in G} {a = gb\ginv g}.
\endalign
$$

%%}}}

%%{{{ x: gconjrel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label gconjrel_is_an_eqrel
%%%}}}

Seja $G$ grupo.  A conjugação $\gconjrel$ do $G$
é uma relação de equivalência.

\solution
\proofpart{Reflexividade:}
Seja $a \in G$.
Procuramos $g\in G$ tal que $a = ga\ginv g$.
Como $a = e a \ginv e$, temos que realmente $a \gconjrel a$.
\eop
\proofpart{Simetria:}
Sejam $a,b \in G$ tais que $a \gconjrel b$.
Daí, seja $x\in G$ tal que $a = xb\ginv x$.
Operando pela esquerda com $\ginv x$ e pela direita com $x$, temos:
$$
\ginv x a x = \ginv x x b \ginv x x = b.
$$
Mas $x = \ginvp {\ginv x}$, ou seja
$b = \ginv x a \ginvp{\ginv x}$
e logo $b \gconjrel a$.
\eop
\proofpart{Transitividade:}
Sejam $a,b,c \in G$ tais que $a \gconjrel b$ e $b \gconjrel c$.
Daí, sejam $x,y \in G$ tais que:
\compute
a &= x b \ginv x \\
b &= y c \ginv y.
\intertext{Substituindo a segunda na primeira, temos}
a &= x \paren{ y c \ginv y } \ginv x                \\
  &= \paren{ xy } c \paren{ \ginv y \ginv x} \by {ass.} \\
  &= \paren{ xy } c \ginvp{ xy }.            \by {inverso de produto (\reftag[inverse_of_product_in_group])} \\
\endcompute
Ou seja, $a \gconjrel c$.

%%}}}

%%{{{ df: conjugacy_class 
\definition Classe de conjugação.
%%%{{{ meta 
\label conjugacy_class
\defines
    * \gcl {~a}  -- a classe de conjugação de $a$
    * classe de conjugação
    ;;
%%%}}}

Seja $G$ grupo e $a\in G$.
A \dterm{classe de conjugação} de $a$ é o conjunto
$$
\gcl a \defeq \setst {ga\ginv g} {g \in G},
$$
ou seja, $\gcl a$ é a classe de equivalência do $a$
através da relação <<é um conjugado de>>.

%%}}}

%%{{{ x: conjugacy_class_of_e 
\exercise.
%%%{{{ meta 
\label conjugacy_class_of_e
%%%}}}

Seja $G$ grupo.
Calcule a $\gcl e$.

\hint
$\gcl e = \set{e}$.
Por quê?

%%}}}

%%{{{ x: conjugacy_classes_of_S3 
\exercise.
%%%{{{ meta 
\label conjugacy_classes_of_S3
%%%}}}

Ache todas as classes de conjugação de $\sym 3$.

\hint
Já achou uma no \ref[conjugacy_class_of_e].

%%}}}

%%{{{ df: conjugator 
\definition conjugadores.
%%%{{{ meta 
\label conjugator
\defines
    * \gconj {~g}  -- o $g$-conjugador
    * conjugador
    ;;
%%%}}}

Seja $G$ grupo e $g\in G$.
Definimos a funcção $\gconj g : G \to G$ pela
$$
\gconj g x = gx\ginv g.
$$
Chamamos a $\gconj g$ de \dterm{$g$-conjugador}.
Observe que o conjugador $\gconj g$ é um ator:
$\actorS g {\ginv g}$.

%%}}}

%%{{{ x: conjugators_respect_powers 
\exercise.
%%%{{{ meta 
\label conjugators_respect_powers
%%%}}}

Sejam $G$ grupo e $g,a\in G$.
Para todo $n\in\ints$,
$\paren{ga\ginv g}^n = g a^n \ginv g$.
Em outras palavras, a conjugação por membro respeita as potências:
$$
\gconj g (a^n) = \paren{\gconj g a}^n
$$
para todo $n\in\ints$.

\hint
Indução para os inteiros não-negativos.
E os negativos?

\solution
Demonstramos primeiramente por indução que para todo $n \in \nats$,
$\paren{ga\ginv g}^n = g a^n \ginv g$.
Observe que
$$
\align
(ga\ginv g)^0 &= e \\
g a^0 \ginv g &= g e \ginv g = g \ginv g = e.
\endalign
$$
Agora seja $k\in\nats$ tal que
$$
(ga\ginv g)^k = g a^k \ginv g. \tag{H.I.}
$$
Calculamos
\compute
(ga\ginv g)^{k+1}
&= (ga\ginv g)^k (ga\ginv g) \\
&= (ga^k\ginv g) (ga\ginv g) \by {pela H.I.} \\
&= ga^k(\ginv g g)a\ginv g \\
&= ga^ka\ginv g \\
&= ga^{k+1}\ginv g.
\endcompute
Para terminar a demonstração basta observar que para qualquer $n \in \nats$ temos:
\compute
\paren{ga\ginv g}^n = g a^n \ginv g
& \implies \ginvp{\paren{ga\ginv g}^n} = \ginvp{g a^n \ginv g} \\
& \implies \paren{ga\ginv g}^{-n} = \ginvp{\ginv g} \ginvp{a^n} \ginv g \\
& \implies \paren{ga\ginv g}^{-n} = g a^{-n} \ginv g.
\endcompute

%%}}}

%%{{{ x: exponentiation_respects_conjugation 
\exercise.
%%%{{{ meta 
\label exponentiation_respects_conjugation
%%%}}}

Se $x,y$ são conjugados, então para todo $n\in\nats$,
$x^n$ e $y^n$ também são.

\hint
Lembre o~\ref[conjugators_respect_powers].

\solution
Isso é um corolário imediato
do~\ref[conjugators_respect_powers]:
Como $x,y$ conjugados, temos $x = gy\ginv g$ para algum $g\in G$.
E agora calculamos:
\compute
x^n
&= \paren{gy\ginv g}^n \\
&= gy^n\ginv g.  \by {pelo \reftag[conjugators_respect_powers]} \\
\endcompute
e logo $x^n,y^n$ conjugados também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A idéia de conjugação deve aparecer meio aleatória
pra ti neste momento, mas não tanto como logo depois
da definição (agora pelo menos tu já demonstrou
muitas propriedades interessantes).
Logo vamos descobrir que os subgrupos que são
\emph{fechados pela conjugação} (ou \emph{fechados pelos conjugados}\/)
são muito interessantes.  Paciência.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: group_actors_are_bijective_proof 
\problem.
%%%{{{ meta 
\label group_actors_are_bijective_proof
%%%}}}

Sejam $G$ grupo e $a,b\in G$.
Definimos as funcções $f,g,h : G \to G$ pelas
$$
\xalignat3
f(x) &= ax  &
g(x) &= xa  &
h(x) &= axb.
\endxalignat
$$
Demonstre que as $f,g,h$ são bijecções e ache suas inversas.

\solution
\proofpart{Injectividade:}
$$
f(x) = f(y)
\implies ax = ay
\implies x = y.
$$
\proofpart{Sobrejectividade:}
Seja $y \in G$.
Considere o $\ginv a y \in G$.
Observe que
$$
f(\ginv a y)
= a (\ginv a y)
= (a \ginv a) y
= y.
$$
A $\finv f$ é definida pela:
$$
\finv f (y) = \ginv a y
$$
pois, de fato, $f(\ginv a y) = a \ginv a y = y$.
Similar para a $g$.
Sobre a $h$, observe que $h = g\of f$ e logo ela é bijetora
como composição de bijetoras, e sua inversa é dada
pela~\ref[finv_of_fcompose].

%%}}}

%%{{{ prob: how_come_the_cancellation_laws_hold_in_nongroup_without_inverses 
\problem.
%%%{{{ meta 
\label how_come_the_cancellation_laws_hold_in_nongroup_without_inverses
%%%}}}

Na~\ref[First_consequences_of_group_laws] provamos que as leis de cancelamento
implicam a existência de únicos inversos.
Lembre-se que o $\sset {\nats} {+}$ não é um grupo pois não satisfaz a (G3).
Mesmo assim, no $\sset {\nats} {+}$ ambas as leis de cancelamento são válidas.
Então, isso implica a existência de inversos únicos!
Qual o erro aqui?

\hint
O que precisamos na demonstração do fato que as leis de cancelamento implicam
a existência de inversos únicos?

\solution
Na prova do fato que as leis de cancelamento implicam a existência
de inversos únicos, \emph{usamos} a (G3) que garanta a existência,
e provamos a unicidade.  No caso do $\sset {\nats} {+}$ não temos a
(G3) (existência de inversos).  Então nossa prova nesse caso mostra
que cada membro de $\sset {\nats} +$ tem \emph{no máximo} um inverso,
algo que realmente é verdade: o $0$ tem exatamente um, e nenhum dos
outros tem.

%%}}}

%%{{{ prob: bust_proof_of_uniqueness_of_identity_in_group 
\problem.
%%%{{{ meta 
\label bust_proof_of_uniqueness_of_identity_in_group
%%%}}}

Considere essa suposta prova da unicidade da identidade~(\ref[uniqueness_of_identity_in_group]):
\quote
\indent<<Seja $G$ grupo e suponha que temos identidades $e_1,e_2 \in G$.
Seja $a\in G$.
Como $e_1$ é identidade, temos $a \ast \ginv a = e_1$\fact1.
Como $e_2$ é identidade, também temos $a \ast \ginv a = e_2$\fact2.
Pelas \byfact1~e~\byfact2, como os lados esquerdos são iguais,
o lados direitos também são.
Ou seja, $e_1 = e_2$ que foi o que queremos demonstrar.>>
\endquote
Identifique todos os erros nessa tentativa de prova.

%}}}

%%{{{ prob: onesided_group_def_proof 
\problem leis unilaterais de grupo.
%%%{{{ meta 
\label onesided_group_def_proof
%%%}}}

Demonstre o~\ref[onesided_group_def].
Cuidado: lembre-se o~\ref[onesided_group_def_catch].

\hint
Para evitar as chances de ``roubar'' sem querer,
use uma notação adaptada às novas leis:
chame $\idr$ a identidade-direita grantida pela (G2R);
$\invl a$ para os inversos-direitos grantidos pela (G3R); e
$\invr a$ para os inversos-esquerdos garantidos pela (G3L).

\hint
Precisas mostrar as (G2)--(G3).
Ou seja, verificar que o $\idr$ é uma identidade-esquerda,
$$
\align
\pforall {a\in G} & \quantified{\idr a = a}            \tag{G2'}\\
\intertext{e que para todo $a\in G$,
seu inverso direito $\invr a$ é um inverso esquerdo também:}
\pforall {a\in G} &\quantified{\invr a \ast a = \idr}. \tag{G3'}
\endalign
$$

\hint
Para demonstrar a (G2') tome um $a\in G$ e comece com:
\compute
\idr \go a
&= (\idr \go a) \go \idr \\
&= \idr \go (a \go \idr) \\
&= \idr \go (a \go (\; \alert? \go \invr{\alert?}\;)) \by {qual membro de $G$ serve aqui?} \\
&\eqvdots \\
&= a
\endcompute
Para a (G3'), o lemma seguinte pode ajudar:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
Use isso para demonstrar que um inverso direito é esquerdo também.

\hint
Para a (G2'), qual produto podes botar no lugar do $(\;?\;)$ da dica anterior?
Sabendo que (G2R) é válida, faz sentido substituí-lo com um termo
$\paren{x \invr x}$ para algum $x\in G$, mas qual seria esse $x$?
\emph{Não precisamos adivinhar ainda!}
Continue assim com um $x$ não-especificado por enquanto,
e logo tu vai chegar numa expressão que vai te ajudar escolher teu $x$ para
continuar, pois tu vai querer que esse $x$ ``anula'' a coisa que aparecerá
na sua esquerda.
\eop
Para a (G3'), teu objectivo é demonstrar que dado qualquer $a \in G$,
$\invr a a = \idr$; e o Lemma te oferece um critério para
decidir que algo é o $\idr$.  Use!

\solution
Vamos demonstrar em detalhe o critério unilateral direito.
A demonstração do esquerdo é simétricamente análoga.
\proofpart{Demonstração da (G2').}
Preciso demonstrar que a identidade direita $\idr$
é uma identidade esquerda.  Seja $a \in G$.
Basta verificar que $\idr a \askeq a$.
Calculamos:
\compute
\idr a
&= \idr a \idr                       \by {def.~$\idr$} \\
&= \idr a (\invr a \invr {\invr a})  \by {def.~$\invr {\invr a}$} \\
&= \idr (a \invr a) \invr {\invr a}  \\
&= \idr \idr \invr {\invr a}         \by {def.~$\invr a$} \\
&= (\idr \idr) \invr {\invr a}       \\
&= \idr \invr {\invr a}              \by {def.~$\idr$} \\
&= (a \invr a) \invr {\invr a}       \by {def.~$\invr a$} \\
&= a (\invr a \invr {\invr a})       \\
&= a \idr                            \by {def.~$\invr {\invr a}$} \\
&= a.                                \by {def.~$\idr$} \\
\endcompute
onde botei parenteses apenas para ajudar a leitura;
seu uso sendo opcional graças a (G1).
\eop
Para demonstrar o (G3'), eu vou usar o Lemma:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
\proofpart{Demonstração do Lemma.}
Seja $g\in G$.  Temos
\compute
gg = g
&\implies (gg)\invr g = g \invr g  \by {$(\go g)$} \\
&\implies g(g\invr g) = \idr       \by {(G1); def.~$\invr g$} \\
&\implies g \idr = \idr            \by {def.~$\invr g$} \\
&\implies g = \idr                 \by {def.~$\idr$} \\
\endcompute
\proofpart{Demonstração da (G3').}
Vou demonstrar que para todo $a \in G$, o $\invr a$ é um inverso
esquerdo do $a$.  Seja $a \in G$ então; preciso mostrar que
$\invr a a \askeq \invr \gid$.
Verificamos que $(\invr a a)(\invr a a) = (\invr a a)$:
\compute
(\invr a a)(\invr a a)
&= \invr a (a\invr a) a  \by {(G1)} \\
&= \invr a (\idr) a      \by {def.~$\invr a$} \\
&= (\invr a \idr) a      \by {(G1)} \\
&= \invr a a.            \by {def.~$\idr$} \\
\endcompute
e logo pelo Lemma concluimos que $(\invr a a) = \idr$.

%%}}}

%%{{{ prob: cancellation_based_group_def_proof 
\problem.
%%%{{{ meta 
\label cancellation_based_group_def_proof
%%%}}}

Demonstre o~\ref[cancellation_based_group_def].

\hint
Como podemos usar o fato que um conjunto é finito?

\hint
O $G$ é finito, logo sejam $G \eqass \set{a_1, \dotsc, a_n}$.

\hint
Seja $g \in G = \set{a_1, \dotsc, a_n}$.
Considere o $Ga \defeq \setst {ga} {a \in G} = \set{ga_1, \dotsc, ga_n}$.
E agora?

%%}}}

%%{{{ prob: cancellation_based_group_def_both_cancellations 
\problem.
%%%{{{ meta 
\label cancellation_based_group_def_both_cancellations
%%%}}}

Podemos apagar um dos (GCL), (GCR) das hipoteses do~\ref[cancellation_based_group_def]?

\hint
Não.
Como podemos demonstrar isso?

\hint
Basta achar um contraexemplo: um conjunto estruturado $\sset G \ast$
tal que $G$ é finito e satisfaz as (G0),(G1),(GCL) mas mesmo assim
não é um grupo; isso mostraria que não podemos apagar o (GCR).
Similarmente para o (GCL).

%%}}}

%%{{{ prob: Futurama 
\problem Futurama.
%%%{{{ meta 
\label Futurama
\indexes
    * Futurama
    ;;
\defines
    * teorema!Futurama
    ;;
%%%}}}

No episódio <<The prisoner of Benda>> do seriado \emph{Futurama},
a galera resolve seu problema usando teoria dos grupos!
um teorema ficou enunciado e demonstrado por {\Keeler}Keeler,
o escritor desse episódio, e foi a primeira (e provavelmente única)
vez que um teorema matemático foi publicado num seriado!
o teorema ficou conhecido como o \emph{Futurama theorem}.
Assista o episódio, entenda o enunciado do teorema, e demonstre!

%%}}}

%%{{{ df: group_center 
\definition Centro.
%%%{{{ meta 
\label group_center
\defines
    * \gcenter {~G}  -- o centro do grupo $G$
    * grupo!centro
    ;;
%%%}}}

Dado um grupo $G$, definimos seu \dterm{centro} $\gcenter G$
como o conjunto de todos os membros de $G$ que ``comutam'' com todos os membros de $G$:
$$
\gcenter G \defeq \setstt {z \in G} {para todo $g\in G$, $zg = gz$}.
$$

%%}}}

%%{{{ prob: center_G_is_a_subgroup 
\problem.
%%%{{{ meta 
\label center_G_is_a_subgroup
%%%}}}

Mostre que dado um grupo $G$, seu centro $\gcenter G \subgrp G$.

\solution
Primeiramente observe que $\gcenter G\neq\emptyset$:
$e \in \gcenter G$ pois para todo $g\in G$, $eg=e=ge$ pela definição de $e$.
Como $\emptyset \neq \gcenter G \subset G$, precisamos apenas mostrar que:
\eop\noi
\proofpart{Fechado pela operação:}
Sejam $x,y\in \gcenter G$.
Para demonstrar que $xy\in \gcenter G$,
verificamos que o $(xy)$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
(xy)g
&= x(yg)  \by {(G1)} \\
&= x(gy)  \by {$y\in \gcenter G$} \\
&= (xg)y  \by {(G1)} \\
&= (gx)y  \by {$x\in \gcenter G$} \\
&= g(xy). \by {(G1)} \\
\endcompute
\eop\noi
\proofpart{Fechado pelos inversos:}
Seja $x\in \gcenter G$.
Para demonstrar que $\ginv x\in \gcenter G$,
verificamos que o $\ginv x$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
\ginv x g
&= \ginvp{\ginvp{\ginv x g}}         \by {inv.~de~inv.} \\
&= \ginvp{\ginv g {\ginvp{\ginv x}}} \by {inv.~de~prod.} \\
&= \ginvp{\ginv g x}                 \by {inv.~de~inv.} \\
&= \ginvp{x \ginv g}                 \by {$x \in \gcenter G$} \\
&= \ginvp{\ginv g} \ginv x           \by {inv.~de~prod.} \\
&= g \ginv x.                        \by {inv.~de~inv.} \\
\endcompute

%%}}}

%%{{{ prob: identifier_of_all 
\problem.
%%%{{{ meta 
\label identifier_of_all
%%%}}}

Seja $G$ grupo finito.
Existe inteiro $N>0$ tal que para todo $a \in G$, $a^N = e$.

\hint
Tem como construir mesmo esse $N$.

\hint
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n$ membros de $G$.

\hint
Dado $a \in G$ sabemos que $a^{\gord a} = e$.

\solution
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n>0$ membros de $G$.
O inteiro $N$ que procuramos é o
$$
N \asseq \Prod_{i=1}^n \gord {a_i}.
$$
Para confirmar, seja $w \in \set{1,\dotsc,n}$
(assim temos uma arbitrário membro de $G$, o $a_w$).
Basta mostrar que $a_w^N = e$:
\compute
a_w^N
&= a_w^{\gord{a_1}\dotsb\gord{a_n}}
   \by {def.~$N$} \\
&= a_w^{\gord{a_w}\paren{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}}
   \by {ensino fundamental} \\
&= \paren{a_w^{\gord{a_w}}}^{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}
   \by {\ref[properties_of_powers_in_groups]-(2)} \\
&= e^{\text{coisa}}
   \by {def.~$\gord {a_w}$} \\
&= e.
   \by {\ref[properties_of_powers_in_groups]-(3)} \\
\endcompute

%%}}}

%%{{{ prob: all_subgroups_of_additive_ints 
\problem.
%%%{{{ meta 
\label all_subgroups_of_additive_ints
%%%}}}

No~\ref[some_subgroups_of_additive_ints] tu provaste que para todo $m\in\ints$,
$m\ints \subgroup \sset \ints +$.  Demonstre que esses são \emph{todos} os
subgrupos de $\sset \ints +$.  Ou seja: para todo $H \subgroup \sset\ints+$,
existe $t \in \ints$ tal que $H = t\ints$.

%%}}}

%%{{{ prob: weird_convex 
\problem.
%%%{{{ meta 
\label weird_convex
%%%}}}

Seja $Q$ o conjunto de todos os pontos do cíclo com ângulo racional:
$$
Q = \setst {\tup{\cos\theta, \sin\theta}} {\theta\in[0,2\pi)\inter\rats}.
$$
Considere a seqüência
$$
Q = Q_0 \subset Q_1 \subset Q_2 \subset Q_3 \subset \dotsb
$$
obtenida pela bottom-up construção da~\reftag[Bottom_up_and_top_down].
(i) Qual conjunto é o convex hull $\generate Q$ do $Q$?
(ii) Descreva o conjunto $Q_1$.
(iii) Tem $Q_i = Q_{i+1}$ para algum $i\in\nats$?

%%}}}

%%{{{ prob: weird_convex_hard 
\problem.
%%%{{{ meta 
\label weird_convex_hard
%%%}}}

No~\ref[weird_convex], $Q_1 = Q_2$?

\hint
Não!  O $Q_1$ tem ``buracos'' nele, e o $Q_2$ não tem!
Tem com achar um tal buraco no $Q_1$.

\hint
$(0,0) \in Q_2 \setminus Q_2$.  Por quê?

\hint
Para ``passar pelo $(0,0)$'', uma corda obrigatoriamente
tem que ser uma diámetro.

\hint
Por enquanto só podemos responder ``não'' por causa desse
buraco.  Tem outros buracos?
Paciência até o~\ref[Cantors_paradise], onde revisitamos essa
pergunta nos seus problemas.

%%}}}

%%{{{ prob: conjugates_have_the_same_order 
\problem.
%%%{{{ meta 
\label conjugates_have_the_same_order
%%%}}}

Membros da mesma classe de conjugação tem a mesma ordem.

\hint
Separe os casos em $\gord a = n \in\nats$ e $\gord a = \infty$.

\hint
Lembre o~\ref[exponentiation_respects_conjugation]
e o~\ref[conjugacy_class_of_e].

\solution
Sejam $a,b$ conjugados.
\crcase{Caso que $\gord a < \infty$.}
\crproofpart{Resolução 1.}
Preciso mostrar:
(i) $b^n = e$;
(ii) para todo $m$ com $0<m<n$, $b^m \neq e$.
\eop
(i) Pelo~\ref[exponentiation_respects_conjugation],
temos que $a^n$ e $b^n$ são conjugados,
mas $a^n = e$, e a classe de conjugação de $e$ é o singleton $\set{e}$
(\ref[conjugacy_class_of_e]).
Logo $b^n = e$.
\eop
(ii) Pela mesma observação cada suposto $b^m = e$
obrigaria $a^m = e$ também.
Logo $\gord b = n$.
\crproofpart{Resolução 2.}
Pelo~\ref[exponentiation_respects_conjugation]
temos $a^{\gord a}$ conjugado com $b^{\gord a}$.
Logo $b^{\gord a} = e$ e logo $\gord b \divides \gord a$.
Similarmente $\gord a \divides \gord b$ e logo $\gord a = \gord b$
pois ambos são naturais.
\crcase{Caso que $\gord a = \infty$.}
Tenho que para todo $n > 0$, $a^n \neq e$,
e preciso mostrar a mesma coisa sobe os $b^n$.
De novo, de qualquer suposto contraexemplo $m\in \nats$ com $b^m = e$
concluimos $a^m = e$ que é absurdo pois $\gord a = \infty$.
\eop
Para uma resolução mais poderosa e simples,
veja o~\ref[conjugates_look_alike].

%%}}}

%%{{{ prob: G abelian iff something with conjugates 
\problem.
%%%{{{ meta 
%%%}}}

Ache uma propriedade interessante que tem a ver com conjugados,
tal que para todo grupo $G$,
$$
\text{$G$ abeliano} \iff \text{essa propriedade}.
$$
Demonstre tua afirmação!

\hint
Num grupo abeliano, o que podes afirmar se $a \gconjrel b$?
(A próxima dica já tem a resposta, depois disso vai faltar
só demonstrá-la.)

\hint
$$
\text{$G$ abeliano} \iff (\gconjrel) = (\eqof G)
$$
Demonstre!

%%}}}

%%{{{ prob: kunen_implies_group 
\problem.
%%%{{{ meta 
\label kunen_implies_group
%%%}}}

\TODO Escrever.

%%}}}

\endproblems
%%}}}

%%{{{ Congruences and cosets 
\section Congruências e coclasses.
%%%{{{ meta 
\label Group_congruences_and_cosets
%%%}}}

%%{{{ The relation R was actually congruence mod subgroup 
\blah.
%%%{{{ meta 
%%%}}}

A relação de equivalência que definimos no~\ref[congruence_mod_H_teaser]
não é tão desconhecida como talvez apareceu ser.
Vamos investigar.

%%}}}

%%{{{ congruence mod H 
\note Congruência módulo subgrupo.
%%%{{{ meta 
%%%}}}

Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
a \cong b \pmod H \defiff a\ginv b \in H.
$$
Usamos também a notação $a \congR H b$.

%%}}}

%%{{{ x: mod_int_as_a_special_case_of_mod_subgroup 
\exercise.
%%%{{{ meta 
\label mod_int_as_a_special_case_of_mod_subgroup
%%%}}}

Justifique a notação da~\ref[equivalence_mod_subgroup] a comparando com a
congruência módulo algum inteiro da~\ref[congruence_modulo_int].
Ou seja, mostre como a definição nos inteiros é apenas um caso especial da definição nos grupos.

\hint
Tome $G \asseq \sset\ints+$ e $H \asseq \sset{m\ints}+$.
E agora?  O que cada uma das
$$
\xalignat2
a \cong b &\pmod m &
a \cong b &\pmod H
\endxalignat
$$
tá dizendo nesse caso?

%%}}}

%%{{{ Investigating the congruence 
\note Investigando a congruência.
%%%{{{ meta 
\label investigation_of_equivalence_mod_subgroup
%%%}}}

Vamos supor que temos um grupo $G$ e um subgrupo $H\subgroup G$.
Tomamos $a,b\in G$ e queremos ver se $a\cong b\pmod H$.
Separamos em casos:
\tlist:
\li \case{Caso 1:}: os dois elementos $a$ e $b$ estão no $H$;
\li \case{Caso 2:}: um dos elementos está dentro do $H$, o outro fora;
\li \case{Caso 3:}: os dois estão fora do $H$.
\endtlist
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)    (a) {$\bullet$};
\node at (-0.5,-0.5) (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)   (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (0.5,1)    (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
}
\botcaption{}
Os 3 casos da Investigação~\reftag[investigation_of_equivalence_mod_subgroup].
\endcaption
\endinsert
\noi
Para cada caso, queremos decidir se:
\tlist:
\li (i): podemos concluir que $a \cong b \pmod H$;
\li (ii): podemos concluir que $a \ncong b \pmod H$;
\li (iii): nenhum dos (i)--(ii).
\endtlist
Vamos ver qual dos (i)--(iii) aplica no \casestylize{caso 1}.
Temos
$$
a \cong b \pmod H \iff a\ginv b \in H
$$
Como $b\in H$ e $H$ é um grupo ($H\subgroup G$) concluimos que
$\ginv b \in H$.
Agora, como $a, \ginv b \in H$ ganhamos $a\ginv b\in H$, ou seja,
$a \cong b \pmod H$:
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[color=blue,inner sep=1pt] at (-1.5,-0.5)  (binv)  {$\bullet$};
\draw[->,dashed,color=blue] (b)--(binv);
\node[above,  outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[inner sep=1pt] (binv)  at (-1.5,-0.5)  {$\bullet$};
\node[color=blue,inner sep=1pt] (abinv)  at (-0.75,-0.75) {$\bullet$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\draw[|-,color=blue]  (a)    edge[out=240,  in=135] (abinv);
\draw[|->,color=blue] (binv) edge[out=60, in=135] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos do \casestylize{caso 1} do~\reftag[investigation_of_equivalence_mod_subgroup].
\endcaption
\endinsert

%%}}}

%%{{{ x: do case 2 
\exercise.
%%%{{{ meta 
\label investigation_of_equivalence_mod_subgroup_case_2
%%%}}}

Decida qual dos (i)--(iii) aplica no \casestylize{caso 2}
do~\reftag[investigation_of_equivalence_mod_subgroup].

\hint
Sem perda de generalidade, podes supor que $a \in H$ e $b \notin H$.
Comece desenhando como fizermos no \casestylize{caso 1}.

\hint
Mostre que $b^{-1}\notin H$.  (Qual seria o problema se $b^{-1} \in H$?)

\hint
Se $b{-1} \in H$ seu inverso também deveria estar no $H$, pois $H$ é um grupo.

\hint
Suponha que $ab^{-1} \in H$ para chegar num absurdo, mostrando assim que necessariamente,
$a \ncong b \pmod H$.  Cuidado:
$$
xy \in H \nimplies x \in H \mland y \in H.
$$

\hint
Mostre que $a^{-1}\in H$.

\solution
Sem perda de generalidade, suponha $a\in H$ e $b\notin H$.
Primeiramente mostramos que $b^{-1} \notin H$:
$$
b^{-1}\in H \implies \paren{b^{-1}}^{-1} \in H \implies b \in H,
$$
logo $b^{-1}\notin H$.
Para chegar num absurdo, vamos supor que $ab^{-1} \in H$.
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt, color=blue] at (0,1.5) (binv) {$\bullet$};
\draw[->,dashed,color=blue] (b) edge[out=180, in=225] (binv);
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
}
\medskip
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[inner sep=1pt, color=blue] at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\draw[->,dashed,color=blue] (a) to (ainv);
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[|-]  (ainv)  edge[out=60, in=250] (binv);
\draw[|->,color=red] (abinv) edge[out=90, in=250] (binv);
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[inner sep=1pt,color=blue] at (1,1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[-,dashed,color=blue] (a) edge[out=20,  in=160] (abinv);
\draw[->,dashed,color=blue] (b) edge[out=110, in=160] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos da resolução do~\ref[investigation_of_equivalence_mod_subgroup_case_2].
\endcaption
\endinsert
\noi
Vamos deduzir a contradição $b^{-1}\in H$.
Para conseguir isso, observamos que $a^{-1} \in H$ (pois $a\in H$),
e logo
$$
\overbrace{\underbrace{\vphantom{(}a^{-1}}_{\in H}\underbrace{(ab^{-1})}_{\in H}}^{\dsize b^{-1}} \in H.
$$
\noi
Achamos assim nossa contradição:
$$
b^{-1} = eb^{-1} = (a^{-1}a)b^{-1} = a^{-1}(ab^{-1}) \in H.
$$
Concluimos então que $ab^{-1} \notin H$, ou seja $a \ncong b \pmod H$.

%%}}}

%%{{{ x: do case 3 
\exercise.
%%%{{{ meta 
%%%}}}

Decida qual dos (i)--(iii) aplica no \casestylize{caso 3} do~\reftag[investigation_of_equivalence_mod_subgroup].

\hint
Ache dois exemplos com $a,b\notin H$, tais que num
$a \cong b \pmod H$ e no outro $a \ncong b \pmod H$.

\hint
Um exemplo consiste em: um grupo $G$, um subgrupo $H\subgroup G$, e dois elementos $a,b\in G\setminus H$ tais que satisfazem (ou não) a congruência $a\cong b \pmod H$.

\hint
Procure teus exemplos no grupo dos inteiros com adição $\sset \ints +$.

\hint
Tome $G \leteq \sset \ints +$, $H \leteq 2\ints$, $a \leteq 1$, $b \leteq 3$
e observe que $1 \cong 3 \pmod {2\ints}$.

\hint
Não é possível achar o outro exemplo com o mesmo subgrupo $2\ints$,
mas pode sim no $3\ints$.

\solution
No grupo $G\leteq\sset \ints +$ considere seu subgrupo $H\leteq 5\ints$.
Temos:
$$
\xalignat2
\rightbrace {
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 6  
\endaligned
}
&\implies a \cong b \pmod H
&
\rightbrace {
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 3  
\endaligned
}
&\implies a \ncong b \pmod H,
\endxalignat
$$
porque $1 + (-6) = -5 \in 5\ints$ e $1 + (-3) = -2 \notin 5\ints$ respectivamente.

%%}}}

%%{{{ def: cosets 
\definition Coclasses.
%%%{{{ meta 
\label coset
\indexes
    * coset    see: coclasse
    ;;
\defines
    * H~a  -- o right-coset do $H\subgrp G$ através do $a\in G$
    * ~a H  -- o left-coset do $H\subgrp G$ através do $a\in G$
    * coclasse
    ;;
%%%}}}

Seja $G$ grupo e $H\subgrp G$.  Para $a\in G$ definimos
$$
\xalignat2
aH &\defeq \setst {ah} {h\in H}
&
Ha &\defeq \setst {ha} {h\in H}.
\endxalignat
$$
Chamamos o $aH$ a \dterm{coclasse esquerda} do $H$ através de $a$,
e similarmente o $Ha$ sua \dterm{coclasse direita}.
Também usamos os termos
\dterm{coclasse (lateral) à esquerda/direita},
e também chamamos as coclasses de \dterm{cosets}.

%%}}}

%%{{{ Q: What w \in Ha means? 
\question.
%%%{{{ meta 
%%%}}}

O que significa que algum $w \in Ha$?
Como podemos usá-lo se é dado?
Como podemos matá-lo se é alvo?

%%}}}

\spoiler

%%{{{ A: what_belonging_to_Ha_means 
\note Respostas.
%%%{{{ meta 
\label what_belonging_to_Ha_means
%%%}}}

Pela definição do conjunto $Ha$ com a notação set-builder,
$$
w \in Ha \defiff \lexists {h\in H} {w = ha}.
$$
Então ganhando $w \in Ha$ como dado, nos permite ``sejar''
um tal membro de $H$: \emph{seja $h\in H$ tal que $w = ha$}.
E para matar esse alvo precisamos mostrar como escrever
nosso $w$ como produto de algum membro do $H$ e do $a$.
Ou seja, procuramos algo que encaixa no $\holed?$:
$$
w = \mubrace {\holed?} {\in H} a.
$$
Não esqueça: assim que achar um tal objeto que satisfaz
a equação acima, precisa demonstrar que ele pertence ao $H$.

%%}}}

%%{{{ warning: only_declare_variables_group_reminder 
\warning Declare apenas variáveis.
%%%{{{ meta 
\label only_declare_variables_group_reminder
%%%}}}

É comum escrever algo do tipo:
\quote
Seja $ha \in Ha$.
\endquote
Não escreva assim, pois é perigoso roubar sem querer!
Em vez disso, podes escrever:
\quote
Seja $w \in Ha$.  Logo seja $h \in H$ tal que $w = ha$.
\endquote
É provável que esse $w$ tem um papel ``bobo'' aí, e realmente
podemos evitá-lo:
o conjunto $Ha$ é um conjunto \emph{indexado pelo $H$}.
Então tudo que discutimos no~\ref[picking_elements_from_indexed_sets]
aplica, e nesse caso para tomar um arbitrário membro do $Ha$,
basta tomar um arbitrário membro $h\in H$:
\quote
Seja $h \in H$.
\endquote
\dots e já temos um arbitrário membro do $Ha$: o $ha$.

%%}}}

%%{{{ warning: what_does_Ha_eq_Hb_really_mean 
\warning.
%%%{{{ meta 
\label what_does_Ha_eq_Hb_really_mean
%%%}}}

Vamos supor que temos uns $a,b\in G$ e algum $H = \set{h_1,\dotsc,h_n}$.
Logo são definidos os
$$
\matrix
\format
\l &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
H  & =  & \{   & h_1,  & h_2,  & h_3,  & \dotsc, & h_n  & \}; \\
Ha & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \}; \\
Hb & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
\eop
(1) Agora suponha que sabemos que $Ha = Hb$:
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
É um \emph{erro grave} concluir que
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq &    &      & \veq  & \veq  & \veq  &         & \veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
A igualdade desses conjuntos nos permite apenas concluir que
cada $h_ia$ é igual a um dos $h_jb$ e vice versa.  Nada mais!
\eop
(2) E agora suponha que queremos demonstrar que $Ha = Hb$.
Pela definição de igualdade de conjuntos, precisamos demonstrar $Ha \subset Hb$
e $Ha \supset Hb$.  Mas!  Se a gente conseguir demonstrar
que realmente para todo $i$, $h_ia = h_ib$, isso seria
ainda mais forte, e obviamente suficiente para concluir
que $Ha=Hb$, mas \emph{não necessário}.

%%}}}

%%{{{ x: What can we conclude if for some i, h_i a = h_i b?
\exercise.
%%%{{{ meta 
%%%}}}

O que podemos concluir se no (1) acima para \emph{algum} $i$,
$h_ia = h_ib$?

\solution
Que $a = b$ (pela~(GCL))---e logo que \emph{para todo} $i$,
$h_ia = h_ib$.

%%}}}

%%{{{ x: every_coset_is_nonempty 
\exercise.
%%%{{{ meta 
\label every_coset_is_nonempty
%%%}}}

Nenhuma coclasse de $H$ é vazia.

\solution
Qualquer coclasse de $H$ tem a forma $Ha$ ou $aH$ para
algum $a\in G$.  Observe que o proprio $a \in Ha$, pois
$$
a = \mubrace {e} {\in H} a \in Ha,
$$
e similarmente $a\in aH$.

%%}}}

%%{{{ x: Ha_eq_H_iff_a_in_H 
\exercise.
%%%{{{ meta 
\label Ha_eq_H_iff_a_in_H
%%%}}}

Sejam $G$ grupo, $H\subgrp G$, e $a \in G$.
$$
Ha = H \iff a \in H.
$$

\solution
\proofpart{\lrdir.}
Suponha $Ha = H$.
Como $e \in H$, então $ea \in Ha$, mas $ea = a$ e pronto.
Numa linha só:
$$
a = ea \in Ha = H.
$$
\crproofpart{\rldir.}
Suponha $a \in H$.
Para demonstrar $Ha = H$ separamos as duas direcções:
{\lrdirset}.
Seja $x \in Ha$, e logo seja $h \in H$ tal que $x = ha$.
Mas $a \in H$ e logo $ha \in H$ pois $H$ é fechado pela operação do grupo.
Ou seja, $x\in H$.
{\rldirset}.
Seja $h \in H$.
Para mostrar que $h \in Ha$ procuramos $h' \in H$ tal que $h = h'a$.
Tome $h' \asseq h\ginv a$ e confirma que $h = h \ginv a a$,
e logo $h \in Ha$ pois $h\ginv a \in H$.
Sabemos disso pois $H$ sendo subgrupo de $G$ é fechado pelos inversos
(logo $\ginv a \in H$) e pela operação também, e logo $h\ginv a \in H$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Uma conseqüência imediata do \ref[Ha_eq_H_iff_a_in_H] é que
$$
a \notin H \iff Ha \neq H.
$$
Mas assim que souber que $a\notin H$ podemos concluir
algo bem mais forte que $Ha \neq H$:

%%}}}

%%{{{ x: a_notin_H_implies_H_and_Ha_disjoint 
\exercise.
%%%{{{ meta 
\label a_notin_H_implies_H_and_Ha_disjoint
%%%}}}

O quê?  Como?

\hint
Podemos concluir que:
\emph{se $a \notin H\subgroup G$ então $H$ e $Ha$ são disjuntos.}

\solution
Podemos concluir que:
\emph{se $a \notin H\subgroup G$ então $H$ e $Ha$ são disjuntos:}
Suponha que $H$ e $Ha$ tem algum membro em comum $h$.
Vamos chegar numa contradição, demonstrando assim que
$H\inter Ha=\emptyset$.
Como $h \in Ha$, logo seja $h_1\in H$ tal que $h = h_1a$.
Passando o $h_1$ para o outro lado, temos
$$
\mubrace {\ginvp{h_1} h} {\in H} = \mubrace {a} {\notin H}
$$
que é absurdo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E se escolher um $b\in G$ fora do $H$ e fora do $Ha$?

%%}}}

%%{{{ x: every_coset_disjoint_from_all_others 
\exercise.
%%%{{{ meta 
\label every_coset_disjoint_from_all_others
%%%}}}

Mostre que se $a,b \in G$ tais que $b\notin Ha$
então $Hb$ e $Ha$ são disjuntos.
(Que $Hb$ e $H$ são disjuntos já sabemos graças
ao~\ref[a_notin_H_implies_H_and_Ha_disjoint].)

\solution
Suponha que $Ha$ e $Hb$ tem algum membro em comum $w$.
Logo sejam $h_a,h_b\in H$ tais que $w = h_a a$ e $w = h_b b$.
Logo
$$
h_a a = h_b b
$$
e passando o $h_b$ para o outro lado temos:
$$
\mubrace {\mubrace {\ginvp{h_b} h_a} {\in H} a} {\in Ha} = b
$$
que contradiz que $b \notin Ha$.

%%}}}

%%{{{ Q: How many cosets? 
\question.
%%%{{{ meta 
%%%}}}

\emph{Dados um grupo $G$ e $H\subgroup G$, quantas coclasses tem o $H$?
Ou seja, qual é a cardinalidade do conjunto $\setst {Ha} {a\in G}$?}

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver a resposta daqui a pouco (\ref[index_of_subgroup]
e~\ref[lagrange_theorem]).

%%}}}

%%{{{ df: cosetsL_and_cosetsR 
\definition.
%%%{{{ meta 
\label cosetsL_and_cosetsR
\defines
    * \cosetsL {~H}  -- a família das coclasses esquerdas do subgrupo $H$ (grupo implícito)
    * \cosetsR {~H}  -- a família das coclasses direitas do subgrupo $H$ (grupo implícito)
    ;;
%%%}}}

Vamos denotar a família de todas as coclasses esquerdas
e direitas do $H$ assim:
$$
\xalignat2
\cosetsL H &\defeq \setst {aH} {a \in G}; &
\cosetsR H &\defeq \setst {Ha} {a \in G}.
\endxalignat
$$
Observe que ambos os $\cosetsL H,\cosetsR H$ são indexados
pelo mesmo conjunto $G$.
Como o grupo $G$ é implícito pelo contexto não precisamos especificá-lo
na notação; mas caso que não é, escrevemos $\cosetsLin H G$ e
$\cosetsRin H G$ respectivamente.

%%}}}

%%{{{ lemma: cosets_form_a_partition 
\lemma.
%%%{{{ meta 
\label cosets_form_a_partition
\indexes
    * partição
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
A família de todas as coclasses direitas de $H$
é uma partição de $G$, e a mesma coisa é verdade
sobre a família das suas coclasses esquerdas.
Ou seja, cada uma das famílias $\cosetsL H$
e $\cosetsR H$ é uma partição do $G$.

\sketch.
Para a $\cosetsR H$, por exemplo, precisamos demonstrar:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \cosetsR H \supset G$;
          ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\li (P2): as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\li (P3): nenhuma coclasse é vazia ($\emptyset \notin \cosetsR H$).
\endtlist
Para o (P1) tomamos um arbitrário $x\in G$ e achamos
uma coclasse de $H$ que o $x$ esteja dentro.
O (P3) já provamos no~\ref[every_coset_is_nonempty].
Essencialmente provamos o (P2) também,
no~\ref[every_coset_disjoint_from_all_others].
Mas para variar, demonstramos que para todo $a,b \in G$,
$$
Ha \inter Hb \neq \emptyset \implies Ha=Hb.
$$
Tome um elemento comum $w\in Ha\inter Hb$.  Logo
$$
h_a a = w = h_b b
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Manipulamos a $h_a a = h_b b$ para mostrar que $Ha = Hb$.

\proof.
Vamos demonstrar que $\cosetsR H$ é uma partição do $G$.
A demonstração que $\cosetsL H$ também é, é similar.
Precisamos demonstrar:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \cosetsR H \supset G$;
          ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\li (P2): as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\li (P3): nenhuma coclasse é vazia ($\emptyset \notin \cosetsR H$).
\endtlist
(P1) Como $H$ é um grupo, sabemos que $e\in H$, então para qualquer $x\in G$,
temos que $x = ex \in Hx$, ou seja todos os elementos de $G$ pertencem
àlguma coclasse.
(P3) Toda coclasse direita de $H$, tem a forma $Ha$ para algum $a\in G$,
e tem pelo menos um elemento: esse mesmo $a$ (a gente provou
isso no~\ref[every_coset_is_nonempty]).
Para o (P2) suponha que $Ha\inter Hb\neq \emptyset$ e tome $w\in Ha\inter Hb$.
Logo
$$
h_aa = w = h_bb
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Para demonstrar que $Ha = Hb$, mostramos que $Ha\subset Hb$ e $Hb\subset Ha$.
Suponha então que $x \in Ha$, logo $x = ha$ para algum $h\in H$.
Precisamos mostrar que $x \in Hb$.
Calculamos:
$$
\align
x= ha
&= h\paren{\ginv {h_a} h_a}a\\
&= h\ginv {h_a} \paren{h_a a}\\
&= h\ginv {h_a} \paren{h_b b}\\
&= \paren{h \ginv {h_a} h_b}b\\
&\in Hb.
\endalign
$$
A outra direção ($Ha \supset Hb$) é similar.

%%}}}

%%{{{ thm: cosets_of_H_eq_quoset_G_congmodR 
\theorem.
%%%{{{ meta 
\label cosets_of_H_eq_quoset_G_congmodR
\indexes
    * partição
    * relação!de equivalência
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
A família $\cosetsR H = \setst {Ha} {a\in G}$ é uma partição do $G$
e sua correspondente relação de equivalência é a congruência $\congR H$
módulo-direito $H$.  Equivalentemente:
$$
\quoset G {\congR H} \;=\; \cosetsR H
$$

\proof.
Vamos denotar por $\eqclassimp a$ a classe de equivalência de
$a\in G$ (através da relação $\congR H$).
Queremos demonstrar que
$\quoset G {\congR H} = \cosetsR H$, ou seja
$$
\setst { \eqclassimp a } {a \in G}
=
\setst { Ha } {a \in G}.
$$
Esses conjuntos são indexados pelo mesmo conjunto (o $G$),
logo basta demonstrar que para todo $a\in G$, $\eqclassimp a = Ha$.
(Veja o~\ref[indexed_sets_equality].)
\crproofpart{\lrdirset:}
Suponha $x \in \eqclassimp a$.
Logo $x \cong a \pmod H$, ou seja, $x\ginv a \in H$.
Pela definição de $Ha$ então temos
$$
Ha\ni
\mubrace {\paren{x\ginv a}} {\in H} a
= x\paren{\ginv a a}
= x.
$$
\proofpart{\rldirset:}
Suponha que $x\in Ha$.
Logo $x=ha$ para algum $h\in H$ e queremos mostrar que $ha\in\eqclassimp a$,
ou seja $ha \cong a \pmod H$.
Confirmamos:
$$
\paren{ha} \ginv a
= h \paren{a\ginv a}
= h
\in H
$$
e pronto.

%%}}}

%%{{{ Q: Why the RIGHT cosets? 
\question.
%%%{{{ meta 
%%%}}}

Por que as coclasses \emph{direitas?}
Tudo até agora na nossa teoria foi justo e simétrico.
Nenhuma lei de grupo e nenhum resultado que provamos
favoreceu um lado ou o outro.
Imagine se a gente tivesse conseguido, por exemplo, demonstrar a lei
de cancelamento para um lado e não para o outro.  Seria bizarro,
pois todos os nossos dados trataram os dois lados na mesma maneira.
E, até pior, nossa relação de congruência já provamos que é simétrica!
Como pode ser então que ela favoreceu a família das coclasses direitas?
Por que o $\quoset G {\congR H}$ acabou sendo a partição $\cosetsR H$
e não a $\cosetsL H$?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Na questão acima tem uma mentira!
Tem uma coisa que usamos aqui que não tratou os dois lados em maneira igual!
É a relação de congruência módulo $H$!
No seu lado \emph{direito} aparece o inverso dum membro do grupo.
Por isso não seria justo usar a notação que temos usado!
Começando agora, vamos usar a notação justa e própria
$$
a \cong b \pmodR H \iff a\ginv b \in H \iff b\ginv a \in H.
$$

%%}}}

%%{{{ Q: How would you define pmodL ?
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias (diretamente) a relação de equivalência que corresponde
à partição das coclasses esquerdas?

%%}}}

\spoiler

%%{{{ df: equivalence_mod_subgroup 
\definition Equivalência módulo subgrupo.
%%%{{{ meta 
\label equivalence_mod_subgroup
\defines
    * ~a \cong {~b} \pmodL {~H}  -- $a,b$ são equivalentes módulo-esquerdo $H \subgroup G$
    * ~a \cong {~b} \pmodR {~H}  -- $a,b$ são equivalentes módulo-direito $H \subgroup G$
    * ~a \congL {~H} {~b}  -- $a \cong b \pmodL H$
    * ~a \congR {~H} {~b}  -- $a \cong b \pmodR H$
    * equivalência!módulo subgrupo
    * módulo!subgrupo
    ;;
%%%}}}

Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
\xalignat2
a \cong b \pmodL H &\defiff \ginv a b \in H; &
a \cong b \pmodR H &\defiff a \ginv b \in H.
\endxalignat
$$
Usamos também as notações $a \congL H b$ e $a \congR H b$.

%%}}}

%%{{{ remark: same is true for left cosets 
\remark.
%%%{{{ meta 
%%%}}}

Voltando ao~\ref[cosets_of_H_eq_quoset_G_congmodR],
simetricamente temos
$\quoset G {\congL H} = \cosetsL H$,
onde $\cosetsL H = \setst {aH} {a\in G}$.

%%}}}

%%{{{ x: a_ginvb_smells_like_division 
\exercise.
%%%{{{ meta 
\label a_ginvb_smells_like_division
%%%}}}

A operação $\tup{a,b} \mapsto a\ginv b$ tá aparecendo mais e mais.
Como tu chamaria essa operação binária?

\solution
Um nome que faz sentido pensar aqui seria \emph{divisão}, se pensar
multiplicativamente; e \emph{subtraição}, se pensar aditivamente.
Mas pra ser mais específicos ainda deveriamos mudar incluir como
adjectivo o lado: \emph{divisão direita} ou \emph{subtraição direita}.
Como assim divisão/subtraição ``direita''?  Nunca escutamos isso
antes, mas isso é porque nossa operação (multiplicação de números
ou adição de números) foi comutativa, então $a\ginv b$ e $\ginv b a$
eram sempre o mesmo número.  Mas aqui no contexto geral de grupo
podem ser diferentes, então faz sentido incluir os lados mesmo!

%%}}}

%%{{{ Does it still seem weird? 
\note.
%%%{{{ meta 
%%%}}}

Talvez ainda parece estranho:
o que a afirmação <<$a\ginv b \in H$>> tem a ver com a
<<os $a,b$ pertencem à mesma coclasse direita de $H$>>?
Observe que, se $a,b$ pertencem à mesma coclasse direita de $H$,
então para algum $c \in G$ temos $a,b \in Hc$, e logo
$a = h_a c$ e $b = h_b c$ para alguns $h_a, h_b \in H$.
Vamo lá:
$$
a \ginv b \in H
\iff
h_a c \ginvp{h_b c} \in H
\iff
h_a c \ginv c \ginv {h_b} \in H
\iff
h_a \ginv {h_b} \in H
\quad\text{que é verdade.}
$$
Conversamente,
$$
a\ginv b \in H
\implies
\paren{a \ginv b} b \in Hb
\implies
a \paren{\ginv b b} \in Hb
\implies
a \in Hb
$$
e logo $a,b$ pertencem à mesma coclasse de $H$: $a,b \in Hb$.
Espero que ficou mais claro agora.

%%}}}

%%{{{ Actors 
\note Atores.
%%%{{{ meta 
%%%}}}

Fixe um $a \in G$.  Como tu provaste
no~\ref[group_actors_are_bijective_proof], isso determina duas
funcções $G \to G$, que no problema chamei de $f,g$.
Vamos relembrá-las e dar um nome e notação especial:

%%}}}

%%{{{ df: group_actors
\definition Atores.
%%%{{{ meta 
\label group_actors
%%%}}}

Sejam $G$ grupo e $a\in G$.  Considere as operações de
``operar com $a$ pela esquerda'' e pela direita
$$
\xalignat2
&\lam x {ax} & &\lam x {xa}.
\intertext{que vamos chamar de $a$-\dterm{ator} esquerdo e direito respectivamente.
As notações que vamos usar para essas funcções são:}
\actorL a     & \eqtype G \to G & \actorR a     & \eqtype G \to G \\
\actorL a (x) & = ax            & \actorR a (x) & = xa. \\
\endxalignat
$$
Ainda mais, para todo par de membros $a,b\in G$ temos um ator definido pela
$$
\align
\actorS a b     &\eqtype G \to G \\
\actorS a b (x) &= axb.
\endalign
$$

%%}}}

%%{{{ x: actorS_as_composition_of_L_and_R 
\exercise.
%%%{{{ meta 
\label actorS_as_composition_of_L_and_R
%%%}}}

$\actorS a b = \actorL a \fcom \actorR b = \actorR b \fcom \actorL a$.

\solution
Sejam $a,b \in G$.
Calculamos:
\compute
\actorS a b x
&= axb                                    \by {def.~$\actorS a b$} \\
&= a(xb)                                  \by {assoc.} \\
&= a\paren{ \actorR b x }                 \by {def.~$\actorR b$} \\
&= \actorL a {\paren{ \actorR b x }}      \by {def.~$\actorL a$} \\
&= \paren{\actorL a \fcom \actorR b} (x). \by {def.~$\fcom$} \\
\endcompute
Provamos a outra igualdade similarmente.

%%}}}

%%{{{ lemma: group_actors_are_bijective 
\lemma.
%%%{{{ meta 
\label group_actors_are_bijective
%%%}}}

Todos as funcções-atores são bijecções.

\proof \proofname~já feita no~\ref[group_actors_are_bijective_proof].

%}}}

%%{{{ lemma: cosets_are_equinumerous_finite_case 
\lemma.
%%%{{{ meta 
\label cosets_are_equinumerous_finite_case
%%%}}}

Todas as coclasses dum finito $H\subgrp G$ têm a mesma
quantidade de elementos com o próprio $H$ (e logo entre si também).

\sketch.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos demonstrar que a quantidade dos dois conjuntos acima
é a mesma.  Primeiramente, como poderia ser diferente?
Ambos parecem ter $n$ elementos, mas isso não garanta
cardinalidade $n$ pois pode ter repetições no $Ha$.
No $H$ não pode, pois definimos o $n$ para ser a cardinalidade de $H$.
Basta demonstrar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.

\proof.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos demonstrar que o $Ha$ também tem $n$ elementos.
Basta demonstrar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.
Mas isso é imediato:
\compute
h_ua = h_va
&\implies h_u = h_v \by {(GCR)} \\
&\implies u = v     \by {pois os $h_i$'s são distintos dois-a-dois} \\
\endcompute
A demonstração sobre as coclasses esquerdas é similar.

%%}}}

%%{{{ remark: cosets are equinumerous even when infinite 
\remark.
%%%{{{ meta 
%%%}}}

O~\ref[cosets_are_equinumerous_finite_case] é
válido até no caso que $H$ é infinito!
Mas não se preocupe agora com isso,
deixe para o~\ref[cosets_are_equinumerous].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos agora generalizar a notação que usamos as coclasses de
``multiplicação de subgrupo por elemento'' para
``multiplicação de subgrupo por subgrupo''.

%%}}}

%%{{{ df: HK_of_groups 
\definition.
%%%{{{ meta 
\label HK_of_groups
%%%}}}

Seja $G$ grupo e $H,K\subgroup G$.  Definimos
$$
HK \defeq \setst {hk} {h\in H,\ k\in K}.
$$

%%}}}

%%{{{ x: group_juxtaposition_is_associative 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que a operação denotada por juxtaposição
no~\ref[HK_of_groups] é associativa.

%%}}}

%%{{{ Q: are HK and KH subgroups of G? 
\question.
%%%{{{ meta 
%%%}}}

$HK = KH$?
$HK \subgroup G$?
$KH \subgroup G$?

%%}}}

%%{{{ eg: calculate_HK_KH_S3 
\example.
%%%{{{ meta 
\label calculate_HK_KH_S3
%%%}}}

No grupo $\sym 3$, sejam seus subgrupos
$$
\xalignat2
H &\leteq \set{ \id, \phi }
&
K &\leteq \set{ \id, \psi\phi }.
\endxalignat
$$
Calcule os $HK$ e $KH$ e decida se $HK=KH$ e se $HK$ e $KH$ são subgrupos de $\sym 3$.

\solution.
Pela definição
$$
\xalignat2
HK &= \setst {hk} {h\in H,\ k\in K}
& 
KH &= \setst {kh} {h\in H,\ k\in K}
\\
&= \set{
\id\compose\id,
\id\compose(\psi\compose\phi),
\phi\compose\id,
\phi\compose(\psi\compose\phi)
}
&
&= \set{
\id\compose\id,
\id\compose\phi,
(\psi\compose\phi)\compose\id,
(\psi\compose\phi)\compose\phi)
}
\\
&= \set{ \id, \psi\phi, \phi, \phi\psi\phi }
&
&= \set{ \id, \phi, \psi\phi, \psi\phi^2 }
\\
&= \set{ \id, \psi\phi, \phi, \psi^2}
&
&= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
Observamos que $HK\neq KH$ (pois, por exemplo, $\psi \in KH$ mas $\psi \notin HK$).
E nenhum deles é subgrupo de $\sym 3$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então descobrimos que, em geral, nem $HK=KH$, nem $HK\subgroup G$,
nem $KH\subgroup G$ são garantidos.
Pode acontecer que $HK \subgroup G$ mas $KH \not\subgroup G$?
E o que a igualdade $HK=KH$ tem a ver com a ``subgrupidade'' dos $HK$ e $KH$?
Vamos responder em todas essas perguntas com o teorema seguinte:

%%}}}

%%{{{ thm: HK = KH <=> HK subgrp G 
\theorem.
%%%{{{ meta 
\label HK_equals_KH_iff_HK_subgroup
%%%}}}

Seja $G$ grupo e subgrupos $H,K \subgrp G$.  Então:
$$
HK = KH
\iff
HK \subgrp G
$$

\sketch.
Para a direção \lrdir, precisamos mostrar que $HK$ é fechado
sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e aplicando as propriedades
de grupo e nossa hipótese, mostramos que $(h_1k_1)(h_2k_2) \in HK$.
Similarmente para os inversos:
consideramos um arbitrário elemento $hk\in HK$ e mostramos que seu
inverso $\ginvp{hk} \in HK$.
Aqui, além da hipótese precisamos o~\ref[inverse_of_product_in_group].
Para a direção \rldir, mostramos as ``$\subset$'' e ``$\supset$''
separadamente, usando idéias parecidas.

\proof.
\lrdir:
Precisamos mostrar que $HK$ é fechado sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e calculamos:
\compute
(h_1k_1)(h_2k_2)
&= h_1(k_1h_2)k_2 \by {ass.} \\
&= h_1(h_3k_3)k_2\quad\text{para alguns $h_3\in H$ e $k_3 \in K$} \by {$k_1h_2\in KH = HK$} \\
&= (h_1h_3)(k_3k_2)\by {ass.} \\
&\in HK
\endcompute
Para os inversos temos:
$$
\ginvp {h_1k_1} = \ginv{k_1} \ginv{h_1} \in KH = HK.
$$
\eop
\rldir:
Mostramos as ``$\subset$'' e ``$\supset$'' separadamente.
``$\subset$'':
Tome $x \in HK$, logo $x^{-1} \in HK$ e $x^{-1} = hk$ \emph{para alguns}
$h\in H$ e $k\in K$.  Como $H$ e $K$ são sub\emph{grupos} de $G$ seus inversos
também estão em $H$ e $K$ respectivamente.
Mas
$$
x = \ginvp{\ginv x} = \ginvp{hk} \ginv k \ginv h \in KH.
$$
``$\supset$'':
Tome $x \in KH$, logo $x = kh$ \emph{para alguns} $k\in K$, $h\in H$.
Logo $\ginv k \in K$ e $\ginv h \in H$.
Como $HK\subgrp G$, basta apenas demonstrar que $\ginv x \in HK$ pois isso
garantará que $x \in HK$ também.
Realmente, $\ginv x = \ginvp{kh} = \ginv h \ginv k \in HK$.

%%}}}

\endsection
%%}}}

%%{{{ Lagrange theorem 
\section O teorema de Lagrange.
%%%{{{ meta 
\label Lagrange_theorem
\credits
    * Lagrange : teorema
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Talvez não é tão óbvio que temos já descoberto um teorema interessante!
Ele é conhecido como \emph{teorema de \Lagrange[teorema]Lagrange},
mesmo que não foi {\Lagrange}Lagrange que o provou na sua generalidade,
mas apenas num caso especifico---mais detalhes nas notas históricas.
Vamos formular e demonstrar o teorema, mas primeiro uma definição simples
e relevante.

%%}}}

%%{{{ df: index_of_subgroup 
\definition Índice.
%%%{{{ meta 
\label index_of_subgroup
\defines
    * \altgroupind {~G} {~H}  -- $\groupind G H$ (notação alternativa)
    * \groupind {~G} {~H}  -- o índice do subgrupo $H$ no grupo $G$
    * grupo!índice de subgrupo
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
O \dterm{índice} de $H$ no $G$ é o número de coclasses direitas de $H$ no $G$.
O denotamos com os símbolos $\groupind G H$ ou $\altgroupind G H$.

%%}}}

%%{{{ remark: it doesn't matter if you choose cosetsL or cosetsR 
\remark.
%%%{{{ meta 
%%%}}}

Escolhemos acima as coclasses direitas, mas isso não é essencial:
escolhendo as esquerdas o número ia sempre ser o mesmo,
como tu demonstrarás agora:

%%}}}

%%{{{ x: number_of_cosets_independend_of_side 
\exercise.
%%%{{{ meta 
\label number_of_cosets_independend_of_side
%%%}}}

Sejam $G$ grupo, $H\subgrp G$.
Demonstre que o número de coclasses à esquerda de $H$ é o mesmo
com o número de coclasses à direita de $H$:
$$
\card{\cosetsL H} = \card{\cosetsR H}.
$$

%%}}}

%%{{{ thm: lagrange_theorem 
\theorem Lagrange.
%%%{{{ meta 
\label lagrange_theorem
\credits
    * Lagrange : teorema
    ;;
\indexes
    * teorema!Lagrange
    ;;
%%%}}}

Seja $G$ grupo finito e $H\subgroup G$.
Então $\groupord H \divides \groupord G$.

\proof.
Sabemos que o $G$ pode ser particionado pelos right cosets de $H$,
e que cada um deles tem a mesma cardinalidade $o(H)$ com o próprio $H$.
Logo,
$$
\gord G = \groupind G H \gord H,
$$
e temos o que queremos demonstrar.

%%}}}

%%{{{ remark: lagrange_reformulated 
\remark.
%%%{{{ meta 
\label lagrange_reformulated
%%%}}}

O teorema de Lagrange então afirma que
$$
\groupind G H  =  \card G / \card H.
$$

%%}}}

%%{{{ eg: HK and KH had no chances of being subgroups 
\example eles não tinham nenhuma chance de ser subgrupos.
%%%{{{ meta 
%%%}}}

No~\ref[calculate_HK_KH_S3] achamos que
$$
\xalignat2
HK &= \set{ \id, \psi\phi, \phi, \psi^2} &
KH &= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
E afirmamos que nenhum dos dois é subgrupo do $G$.
Por quê?
Em vez de fazer o trabalho tedioso e verificar se cada um
dos $HK,KH$ é um subgrupo do $\sym 3$, observamos que cada
um tem $4$ elementos---verifique que são \emph{realmente} $4$.
Mas, graças ao Lagrange~(\reftag[lagrange_theorem]) $\sym 3$ não
tem subgrupos de ordem $4$, pois $4$ não divide o $6$.  Pronto.

%%}}}

%%{{{ Corollaries as exercises 
\note Corolários.
%%%{{{ meta 
%%%}}}

{\Lagrange[teorema!corolário]}%
Graças ao teorema de Lagrange~\reftag[lagrange_theorem]
ganhamos muitos corolários diretamente,
como tu vai verificar agora resolvendo os exercícios seguintes:

%%}}}

%%{{{ x: subgroups_of_group_with_prime_order_proof 
\exercise.
%%%{{{ meta 
\label subgroups_of_group_with_prime_order_proof
%%%}}}

Seja $G$ grupo com $\gord G = p$, onde $p$ primo.
Quais são todos os subgrupos de $G$?

\hint
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G$.  Quais são os divisores de $\gord G$?

\solution
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G = p$, logo $\gord H = 1$ ou $p$.
No primeiro caso $H = \set e$, no segundo, $H = G$.
Ou seja:
\emph{um grupo com ordem primo não tem subgrupos não-triviais}.

%%}}}

%%{{{ corollary: subgroups_of_group_with_prime_order 
\corollary.
%%%{{{ meta 
\label subgroups_of_group_with_prime_order
%%%}}}

Um grupo com ordem primo não tem subgrupos não-triviais.

\proof Demonstrado no~\ref[subgroups_of_group_with_prime_order_proof].

%%}}}

%%{{{ corollary: order_of_a_divides_order_of_G 
\corollary.
%%%{{{ meta 
\label order_of_a_divides_order_of_G
%%%}}}

Seja $G$ grupo finito e $a\in G$.  Então $\gord a \divides \gord G$.

\proof Demonstrarás no~\ref[order_of_a_divides_order_of_G_proof].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já resolveste o~\ref[identifier_of_all]?
O próximo corolário oferece uma resolução mais elegante:

%%}}}

%%{{{ corollary: a_to_the_order_of_G_is_e 
\corollary.
%%%{{{ meta 
\label a_to_the_order_of_G_is_e
%%%}}}

Seja $G$ grupo finito e $a\in G$.
Então $a^{\gord G} = e$.

\proof Demonstrarás no~\ref[a_to_the_order_of_G_is_e_proof].

%%}}}

%%{{{ x: order_of_a_divides_order_of_G_proof 
\exercise.
%%%{{{ meta 
\label order_of_a_divides_order_of_G_proof
%%%}}}

Demonstre o~\ref[order_of_a_divides_order_of_G].

\hint
Se achar um subgrupo $H\subgroup G$ com $\gord H = \gord a$,
acabou (graças ao Lagrange).

\hint
Lembra que $\generate a$ é um subgrupo do $G$\dots?

\hint
\dots e que sua ordem é $\gord {\generate a} = \gord a$?

\solution
Sabemos que $\generate a$ é um subgrupo de $G$, com ordem
$\gord {\generate a} = \gord a$,
e pelo teorema de Lagrange, como $\generate a \subgroup G$
e $G$ é finito temos
$$
\gord a = \gord {\generate a} \divides \gord G.
$$

%%}}}

%%{{{ x: a_to_the_order_of_G_is_e 
\exercise.
%%%{{{ meta 
\label a_to_the_order_of_G_is_e_proof
%%%}}}

Demonstre o~\ref[a_to_the_order_of_G_is_e].

\hint
\ref[order_of_a_divides_order_of_G].

\solution
Graças ao~\ref[order_of_a_divides_order_of_G] temos que
$\gord a \divides \gord G$, ou seja, $\gord G = k\gord a$ para algum
$k\in\ints$.
Agora calculamos:
$$
a^{\gord G}
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= e^k
= e.
$$

%%}}}

%%{{{ The idea behind Lagrange 
\note A idéia atrás do teorema de Lagrange.
%%%{{{ meta 
%%%}}}

Temos um grupo finito $G$, e um subgrupo $H \subgrp G$.
Vamos conseguir arrumar \emph{todos os membros de $G$}
numa tabela:
$$
\matrix
\format
& \quad\c\quad & \quad\c\quad & \quad\c\quad & \ \ \c\ \  & \quad\c\quad \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \phantom\bullet \\
& \vdots   & \vdots   & \vdots   & \ddots  & \vdots \\
& \phantom\bullet \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet
\endmatrix
$$
Sua primeira linha será feita por todos os membros de $H$.
Sabendo que $G$ é finito, temos que $H$ também é, e
logo essa primeira linha será finita também.
Vamos chamar $n$ a $\gord H$, e logo $h_1,\dots,h_n$
os $n$ membros de $H$.
Então a primeira linha tem tamanho $n$, e é a seguinte:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
\endmatrix
$$
Vamos mostrar como botar o resto dos membros de $G$ nessa tabela.
Na verdade, tem uma chance que não tem mais elementos para
botar: isso acontece se $H = G$.  Nesse caso não temos
mais nada pra fazer, já conseguimos o que queriamos.
Mas, no caso geral, existem membros de $G$ fora do $H$.
Seja $a\in G$ um deles, ou seja, $a \notin H$.
Agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
\endmatrix
$$
Agora \emph{afirmamos} sobre os elementos novos que:
\tlist:
\li: eles são realmente $n$, ou seja, distintos dois-a-dois;
\li: eles são realmente novos, ou seja, nenhum deles é igual àlgum
     dos membros que já estava na tabela.
\endtlist
Se demonstrar essas afirmações, saberemos que temos exatamente $2n$
membros de $G$ já arrumados na nossa tabela.
E depois?
Caso que $G$ não tenha mais elementos, não temos nada mais pra fazer,
pois já conseguimos o que queriamos.
Caso que tenha membros de $G$ fora deles, seja $a'\in G$ um deles,
ou seja, $a'$ não é nenhum dos membros já listados.
E agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'
\endmatrix
$$
Novamente, \emph{afirmamos} sobre os elementos novos que:
\tlist:
\li: eles são realmente $n$;
\li: eles são realmente novos.
\endtlist
\emph{E por aí vai.}
Sabemos que o processo vai terminar depois duma quantidade finita
de passos, pois o $G$ é finito.
Quando terminar então, teriamos conseguido arrumar todos os seus
membros numa tabela de largura $n$ e altura igual à quantidade
de coclasses direitas do $H$ no $G$, ou seja,
altura $m \asseq \groupind G H$.
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H    &:         & h_1     & h_2     & h_3     & \dots   & h_n   \\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'\\
& \phantom\bullet \\
\phantom h\vdots&\phantom:& \phantom h\vdots& \phantom h\vdots & \phantom h\vdots & \ddots  & \phantom h\vdots\\
& \phantom\bullet \\
Ha'' &:         & h_1 a'' & h_2 a'' & h_3 a'' & \dots   & h_n a''
\endmatrix
$$
\eop
A única coisa que basta fazer então, é demonstrar todas as afirmações que
deixamos sem prova acima.
Mudando os nomes dos $a, a', \dots, a''$ para $a_2, a_3, \dots, a_m$,
queremos demonstrar para quaisquer $i,j\in\set{2,\dotsc,m}$ as seguintes:\foot
Talvez aparece estranha a escolha de índices que começa com ${}_2$,
mas é muito conveniente aqui, pois o índice final ${}_m$ já seria a
própria altura da tabela.
Se ficou triste por a falta do $a_1$, tome $a_1\asseq e$ e vai dar certo:
a primeira coclasse de $H$ (o próprio $H$), seria o $Ha_1$ nesse caso.
Mas nada disso é necessário!
\toof
% TODO: fix reflabs
\tlist:
\li (1): $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente $n$, ou seja,
         distintos dois-a-dois;
\li (2): $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente novos, ou seja:
         \tlist:
         \li (2.a): nenhum deles é igual àlgum dos $h_1,h_2,\dotsc,h_n$;
         \li (2.b): nenhum deles é igual àlgum dos $h_1a_j, h_2a_j, \dotsc, h_na_j$
                    para $j < i$.
         \endtlist
\endtlist
Nenhuma delas é difícil pra demonstrar---na verdade, \emph{nos já demonstramos} todas.\foot
A~(1) é o~\ref[cosets_are_equinumerous_finite_case];
a~(2) é o~(ii) do~\reftag[cosets_form_a_partition].
\toof
Mesmo assim, bora prová-las novamente aqui com uns ``one-liners'':
$$
\gather
h_ua_i = h_va_i \implies h_u = h_v \implies u=v;\tag{1}\\
h_ua_i = h_v    \implies a_i = \ginv{h_u}h_v \implies \text{$a_i \in H$, que é absurdo};\tag{2a}\\
h_ua_i = h_va_j \implies a_i = \ginv{h_u}h_va_j \implies \text{$a_i \in Ha_j$, que é absurdo}.\tag{2b}
\endgather
$$
Pronto!

%%}}}

%%{{{ warning: converse_of_lagrange_is_invalid 
\warning.
%%%{{{ meta 
\label converse_of_lagrange_is_invalid
%%%}}}

Não seja tentado para aplicar o ``converso''.
Sabendo que $d \divides \gord G$, \emph{não podemos concluir}
que o $G$ possui subgrupos de ordem $d$ (\ref[converse_of_lagrange_is_invalid_proof])

%%}}}

%%{{{ x: dividing_the_additive_group_of_ints 
\exercise dividindo o grupo aditivo dos inteiros.
%%%{{{ meta 
\label dividing_the_additive_group_of_ints
%%%}}}

Qual é o índice do $\sset {4\ints} + \subgrp \sset \ints +$?  Generalize para o $m\ints$.

%%}}}

%%{{{ x: dividing_the_additive_group_of_reals 
\exercise dividindo o grupo aditivo dos reais.
%%%{{{ meta 
\label dividing_the_additive_group_of_reals
%%%}}}

Qual o $\groupind {\sset \ints +} {\sset \reals +}$?

%%}}}

\endsection
%%}}}

%%{{{ Number_theory_revisited 
\section Teoria dos números revisitada.
%%%{{{ meta 
\label Number_theory_revisited
%%%}}}

%%{{{ x: the_multiplicative_group_Zp 
\exercise.
%%%{{{ meta 
\label the_multiplicative_group_Zp
%%%}}}

Seja $p$ primo e defina
$\cal Z_p = \sset {\finord p \setminus \set0} {\ntimes}$
onde $\ntimes$ é a multiplicação módulo~$p$.
Mostre que $\cal Z_p$ é um grupo e ache sua ordem.

%%}}}

%%{{{ x: the_multiplicative_group_Zn 
\exercise.
%%%{{{ meta 
\label the_multiplicative_group_Zn
%%%}}}

Seja $n\in\nats$ com $n>1$ e defina
$\cal Z_n = \sset {\setst {a \in \finord n} {\gcd a n = 1}} {\ntimes}$
onde $\ntimes$ é a multiplicação módulo~$n$.
Mostre que $\cal Z_n$ é um grupo e ache sua ordem.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já estamos em posição de ganhar o ``teorema pequeno de Fermat''
e sua generalização, o teorema de congruências
de~{\Euler}Euler~\reftag[euler_congruence_theorem]
como um corolário{\Lagrange[teorema!corolário]} fácil
das nossas novas ferramentas grupoteóricas.

%%}}}

%%{{{ cor: euler_congruence_theorem_as_corollary_of_lagrange 
\corollary Teorema de Euler.
%%%{{{ meta 
\label euler_congruence_theorem_as_corollary_of_lagrange
%%%}}}

Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$

\sketch.
Conseqüência do teorema de~{\Lagrange}Lagrange~\reftag[lagrange_theorem]
graças ao~\ref[the_multiplicative_group_Zn].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ainda mais resultados podem ser derivados como
corolários{\Lagrange[teorema!corolário]} do
teorema de Lagrange:
no~\ref[euclids_theorem_as_corollary_of_lagrange]
por exemplo tu ganhas o fato que tem uma
infinidade de primos
(teorema de~\sayEuclid, \reftag[primes_is_infinite]).

%%}}}

\endsection
%%}}}

%%{{{ The_quotient_group 
\section O grupo quociente.
%%%{{{ meta 
\label The_quotient_group
%%%}}}

%%{{{ As soon as you've got a subgroup…
\note Assim que tiver um subgrupo….
%%%{{{ meta 
%%%}}}

Vamos começar com um certo grupo $G$, bagunçado assim:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Identificamos nele um subgrupo $H \subgroup G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$H$};
\endtikzpicture
$$
Assim que fizermos isso, o grupo toda se arruma em
dua maneiras, uma a partir das coclasses esquerdas
e uma a partir das direitas:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitionedmistake;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$

%%}}}

%%{{{ Q: what is wrong with the picture above? 
\question.
%%%{{{ meta 
%%%}}}

Tem algo errado na figura acima.
O que é?

%%}}}

\spoiler

%%{{{ A: we should have used different names 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não sabemos que cada um dos representantes que desenhamos
na partição $\cosetsL H$ vai acabar sendo um representante
da correspodente coclasse direita.  Pode ser, por exemplo
que o $q \in Hp$, e logo $Hp = Hq$.  Para formar a partição
escolhemos cada vez um membro fora das coclasses que já
formamos, mas ninguém garanta que andando pelas coclasses
esquerdas e esclohendo os $p,q,r,s,t,u,v$, vamos conseguir
escolher os mesmos como representantes das coclasses
direitas.
Em geral então, a imagem deve ser alterada para usar
nomes diferentes nos representantes, por exemplo:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitioned;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$

%%}}}

%%{{{ eg: cosets_of_K_subgroup_S3 
\example.
%%%{{{ meta 
\label cosets_of_K_subgroup_S3
%%%}}}

Considere o subgrupo $K \subgroup \sym 3$:
$$
K \leteq \set{ \id, \psi\phi }.
$$
Calcule todos os left e right cosets de $K$ no $\sym 3$,
e decida se as duas colecções são iguais.

\solution.
Queremos calcular primeiramente todas as coclasses de $K$.
Como $\gord K = 2$, e o $G$ tem $6$ membros em total,
sabemos que o $K$ tem $3$ coclasses esquerdas, e $3$ coclasses direitas:
$$
\xalignat4
\text{esquerdas:} &  & K &= \set {\id, \psi\phi }  &   \holed? K &= \set{\holed?,\holed?}  &  \holed? K &= \set{ \holed?, \holed? }   \\
\text{direitas:}  &  & K &= \set {\id, \psi\phi }  &   K\holed?  &= \set{\holed?,\holed?}  &  K\holed?  &= \set{ \holed?, \holed? }
\endxalignat
$$
Vamos escolher o primeiro representante para escrever a primeira coclasse esquerda ``própria'' de $K$.
Temos $4$ opções, pois se escolher qualquer um dos dois membros do $K$, vamos ``cair'' na mesma coclasse $K$.
Escolhemos o $\psi$.  Calculamos:
$$
\psi K = \set { \psi, \psi\psi\phi } = \set { \psi, \psi^2\phi } = \set { \psi, \phi\psi }.
$$
Observe que seria a mesma coclasse esquerda, se tivemos escolhido o $\phi\psi$.
Vamos calcular a última.  Qual seria o represetante agora?
Precisamos evitar todos os membros de $K$ e de $\psi K$.
Vamos escolher o $\phi$, e bora calular o $\phi K$.  Ou não?
Não precisamos fazer nenhum cálculo, pois so sobraram $2$ membros de $\sym 3$, então esses $2$ formam a última coclasse esquerda:
$$
\phi K = \set { \phi, \psi^2 }.
$$
Basta calcular as coclasses direitas agora.  Para a primeira, escolhemos de novo o $\psi$, já que observamos que $\psi\notin K$.  Calculamos:
$$
K \psi = \set { \psi, \psi\phi\psi } = \set { \psi, \phi }.
$$
Qual seria o representante ta próxima?  Aqui não pode ser novamente o $\phi$, pois o $\phi$ apareceu no $K\psi$.
Escolhemos um dos dois restantes então, vamos tomar o $\psi^2$, e junto com o último restante ele forma a última coclasse direita:
$$
K \psi^2 = \set { \psi^2, \phi\psi }.
$$
Finalmente achamos todas:
$$
\xalignat2
\cosetsL K &= \set {
\aligned
     K &= \set {\id, \psi\phi}, \\
\psi K &= \set {\psi, \phi\psi}, \\
\phi K &= \set {\phi, \psi^2}
\endaligned
} & 
\cosetsR K &= \set {
\aligned
K       &= \set {\id, \psi\phi}, \\
K\psi   &= \set {\phi, \psi}, \\
K\psi^2 &= \set {\psi^2, \phi\psi}
\endaligned
}.
\endxalignat
$$
Para responder na pergunta, precisamos comparar as duas
\emph{colecções}, ou seja a pergunta é:
$$
\set{ K, \psi K, \phi K }
\askeq
\set{ K, K\psi, K\psi^2 }
$$
e facilmente observamos que não são iguais, pois, por exemplo,
$\psi K$ não é igual a nenhuma das coclasses direitas,
algo que verificamos comparando o conjunto $\psi K$
com cada um dos conjuntos $K, K\psi, K\psi^2$.

%%}}}

%%{{{ x: cosets_of_H_N_subgroup_S3 
\exercise.
%%%{{{ meta 
\label cosets_of_H_N_subgroup_S3
%%%}}}

Calcule todas as coclasses esquerdas e direitas dos
$$
\xalignat3
H &\leteq \set{ \id, \phi }&
N &\leteq \set{ \id, \psi, \psi^2 }
\endxalignat
$$
Quantas coclasses direitas diferentes cada um deles tem?
Quantas esquerdas?  Explique sua resposta.
A família $\cosetsR H$ de todas as coclasses direitas de $H$ é igual
à família $\cosetsL H$ de todas as esquerdas?
Similarmente para as $K$ e $N$.

%%}}}

%%{{{ notation 
\notation.
%%%{{{ meta 
%%%}}}

Observe que definimos os $aH$, $Ha$, e $HK$, num grupo $G$
para \emph{subgrupos} $H,K\subgroup G$.
Mas não usamos nenhuma propriedade de subgrupo mesmo.
Podemos realmente estender essa notação para arbitrários
\emph{subconjuntos} de $G$, e, por que não,
até usar notação como a seguinte abominação:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
\defeq
\setst {g_1abg_2b'\ginv{g_3}a'g_1cb''}
{
a, a' \in A,\ 
b, b', b'' \in B,\ 
c \in C
}
$$
dados $g_1,g_2,g_3\in G$ e $A,B,C\subset G$.
Observe primeiramente que \emph{precisamos} usar variáveis diferentes
para cada instância de elemento de $A$, etc.
Observe também que todos esses objetos que escrevemos juxtaposicionando
elementos e subconjuntos de $G$ são subconjuntos de $G$ se usamos
pelo menos um subconjunto de $G$ na expressão:
$$
\xalignat2
g_1abg_5ab' &\in G &
g_1aBg_5ab' &\subset G.
\endxalignat
$$
Finalmente, \emph{confira} que graças à associatividade da operação do grupo $G$,
não precisamos botar parenteses:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
= g_1A(Bg_2B)\ginv{g_3}(Ag_1CB)
= (g_1A)(Bg_2)(B\ginv{g_3})(Ag_1)(CB)
= \dotsb
$$
etc.

%%}}}

%%{{{ df: normal_subgroup 
\definition Subgrupo normal.
%%%{{{ meta 
\label normal_subgroup
\indexes
    * normal    see: subgrupo normal
    ;;
\defines
    * ~N \normal ~G  -- $N$ é um subgrupo normal de $G$
    * subgrupo!normal
    ;;
%%%}}}

Seja $G$ grupo e $N\subgroup G$.
O $N$ é um \dterm{subgrupo normal} de $G$
sse a família das suas coclasses esquerdas
e a das suas coclasses direitas são iguais.
Em símbolos,
$$
N \normal G \defiff \cosetsL N = \cosetsR N.
$$

%%}}}

%%{{{ x: subgroup_of_abelian_is_normal 
\exercise.
%%%{{{ meta 
\label subgroup_of_abelian_is_normal
%%%}}}

Se $H \subgroup G$ num $G$ abeliano, então $H \normal G$.

%%}}}

%%{{{ x: cosets_of_subgroup_of_index_2 
\exercise.
%%%{{{ meta 
\label cosets_of_subgroup_of_index_2
%%%}}}

Se $H\subgroup G$ de índice $2$, então $H \normal G$.

\solution
Suponha $H\subgroup G$ com 
Precisamos mostrar que $aH = Ha$ para todo $a\in G$.
Como o índice de $H$ é 2, só tem 2 cosets, logo, fora do próprio $H$, seu
complemento $G\setminus H$ tem que ser um coset.
Agora para qualquer $aH$ com $a \notin H$, temos
$$
aH = G\setminus H = Ha.
$$

%%}}}

%%{{{ The quotient group 
\note.
%%%{{{ meta 
%%%}}}

Acabamos de identificar certos subgrupos dum grupo $G$---que chamamos
\dterm{normais}---com uma propriedade legal:
a colecção de todas as suas coclasses esquerdas é a mesma com
a colecção de todas as suas coclasses direitas.
(Na verdade a situação é bem mais legal que isso---continue lendo.)
Começando então com um $N\normal G$, podemos falar \emph{da} partição
correspodente de $G$, sem especificar se estamos considerando a colecção
das coclasses esquerdas ou das direitas.
Ou seja, nesse caso, as relações de equivalência
$$
\dhole \cong \dhole \pmodL N
\qqqqtext{e}
\dhole \cong \dhole \pmodR N
$$
são a \emph{mesma} relação:

%%}}}

%%{{{ df: congruence_mod_N 
\definition congruência módulo subgrupo.
%%%{{{ meta 
\label congruence_mod_N
\defines
    * ~a \cong ~b \pmod ~N  -- $a,b$ são congruentes módulo o subgrupo normal $N$
    * congruência!módulo subgrupo
    * módulo!subgrupo
    ;;
%%%}}}

Sejam $G$ grupo e $N \normal G$.
Definimos a relação binária
$$
\dhole \cong \dhole \pmod N
$$
que chamamos de \dterm{congruência módulo $N$}.

%%}}}

%%{{{ As soon as we have a normal subgroup… 
\note Assim que tiver um subgrupo normal….
%%%{{{ meta 
\indexes
    * conjunto!quociente
    ;;
%%%}}}

Vamos começar com um certo grupo $G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Agora identificamos nele um subgrupo \emph{normal} $N\normal G$.
Assim que fizermos isso, todo o $G$ se arruma
graças à partição de todas as coclasses de $N$:
$$
\gathered
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$N$};
\endtikzpicture
\endgathered
\qquad\leadsto\qquad
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned;
\endtikzpicture
\endgathered
$$
E agora comece se afastar mais e mais, até não dá mais pra ver
os pontinhos \emph{dentro} dessas classes, e até as próprias
classes viram pontinhos:
$$
\tikzpicture
\tikzi quogrpzoomout;
\endtikzpicture
$$
Denotamos esse conjunto por $\quogrp G N$:
$$
\quogrp G N = \setst {Ng} {g \in G}
$$
Observe que esse conjunto é o
\emph{conjunto quociente} de $G$
através da relação de congruência módulo $N$.\foot
Lembra-se que dada qualquer relação de equivalência
num conjunto, definimos seu conjunto quociente?
Não?!  Corra para a~\ref[quoset].
\toof

%%}}}

%%{{{ So what? 
\note E daí?.
%%%{{{ meta 
%%%}}}

Isso é verdade mesmo se o $N$ não fosse normal:
podemos definir os (dois) conjuntos quocientes
$\quoset G {\congL N}$ e $\quoset G {\congR N}$.
Mas assim estamos esquecendo \emph{a alma} do $G$:
o $G$ é um \emph{grupo}.
Desde o~\ref[Relations] (\reftag[quoset]) sabemos que podemos
dividir um \emph{conjunto} (por uma relação de equivalência)
e o resultado (quociente) é novamente o mesmo tipo de coisa:
\emph{conjunto}.
Aqui dividimos um \emph{grupo} e o quociente foi o quê?
A melhor coisa que podemos dizer é\dots~\emph{conjunto!}
Péssimo!  O resultado perdeu seu alma!
Por isso os subgrupos normais são \emph{muito} legais:
o quociente retenha a alma do grupo original!

%%}}}

%%{{{ What is stopping us, exactly? 
\note O que exatamente é o problema?.
%%%{{{ meta 
%%%}}}

Suponha então que temos um $H \subgrp G$.
Gostariamos de definir a operação $\ast$ no
$\quoset G {\congL H}$ em tal forma que
$$
aH \ast bH \pseudodefeq (a \ast_G b)H.
$$
O problema é que a operação $\ast$ que estamos
tentando definir não tem acesso nos $a,b$ das suas entradas $aH,bH$
respectivamente, e logo o seu valor $aH \ast bH$ não pode depender
das escolhas desses representantes.
Ou seja, \emph{não temos como demonstrar que $\ast$ é bem-definida},
e logo \emph{não podemos usar a igualdade acima como definição 
de operação}---por isso o $\pseudodefeq$.
Voltando no desenho anterior a situação ficará mais clara;
vou pintar todos os membros da $aH$ de vermelho e todos os
membros da $bH$ de azul:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\endtikzpicture
$$
Querendo usar a ``definição'' da operação $\ast$ acima
escolhemos o $a \in aH$ e o $b \in bH$ e procuramos
o $a \ast_G b$; vamos dizer que achamos aqui no $gH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node[text=magenta] at (ab) {$\bullet$};
\node at (ab) {\pointL {ab}};
\endtikzpicture
$$
agora escolhendo \emph{outros representantes} $a',b'$ das
$aH,bH$
(onde pelo menos uma das $a'\neq a$ e $b'\neq b$ é válida)
procuramos o $a' \ast_G b'$.  O que acontece se ele
não pertence à mesma coclasse $gH$?
Talvez caiu na $cH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node[text=magenta] at (ab)  {$\bullet$};
\node[text=magenta] at (ab0) {$\bullet$};
\node at (ab)  {\pointL {ab}};
\node at (ab0) {\pointL {a'b'}};
\endtikzpicture
$$
Assim a $\ast$ \emph{não é bem-definida} (e logo
o $\quoset G {\congL H}$ não tem nenhuma chance de
virar grupo com ela.
É exatamente isso que aproveitamos nos subgrupos \emph{normais:}
eles não deixam isso acontecer, pois garantam que
o produto de quaisquer representantes das $aH,bH$ vai sempre
cair dentro da mesma coclasse, e logo apenas a $gH$ será pintada
roxa aqui no nosso desenho
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned3colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node at (ab2) {\pointL {a'b'}};
\node at (ab)  {\pointL {ab}};
\endtikzpicture
$$
e logo aqui teriamos
$$
aH \ast bH = gH \quad \bigparen{= (ab)H}.
$$

%%}}}

%%{{{ beware: not_well_defined_function_danger_quogrp 
\beware.
%%%{{{ meta 
\label not_well_defined_function_danger_quogrp
\indexes
    * funcção!bem-definida
    ;;
%%%}}}

Caso que o problema de não ser bem-definida não é óbvio,
primeiramente volte a re-estudar os:
\ref[not_well_defined_function_danger_argument_name_dependence]
e~\ref[not_well_defined_function_danger_choice_dependence].
Agora observe que o $aH$ é na verdade um membro $a$ de $G$
\emph{operado} com um subgrupo $H$ de $G$; e isso resulta
num certo subconjunto de $G$: uma coclasse (esquerda) de $H$.
\eop
Então: as entradas da $\ast$ são coclasses esquerdas de $H$,
por exemplo podem ser as
$$
\xalignat2
aH &\eqass \set{a,a_1,a_2,a_3,a_4,a_5} &
bH &\eqass \set{b,b_1,b_2,b_3,b_4,b_5}
\endxalignat
$$
e agora
$$
\set{a,a_1,a_2,a_3,a_4,a_5}
\ast
\set{b,b_1,b_2,b_3,b_4,b_5}
= ?
$$
Observe que aqui temos
$$
\xalignat2
aH &= a_1H = \dotsb = a_5H &
bH &= b_1H = \dotsb = b_5H.
\endxalignat
$$
Parece então que tentamos definir a $\ast$ pela
$$
A \ast B = (ab)H,\quad
\text{onde $a$ é algum membro de $A$ e $b$ de $B$}
$$
mas para essa ser uma definição de funcção mesmo
temos uma tarefa para fazer:
\emph{precisamos demonstrar que seu valor $A \ast B$
não depende das escolhas desses ``representantes'' $a$ e $b$}
(\ref[not_well_defined_function_danger_choice_dependence]).
Até conseguir demonstrar isso, não podemos considerar a
$\ast$ uma funcção \emph{bem-definida}.
Vamos voltar se preocupar com o mesmo tipo de coisa logo
no~\ref[not_well_defined_function_danger_firstiso].

%%}}}

%%{{{ Q: How can we turn the quotient set into a group? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir uma operação interessante $\ast$
nos elementos de $\quogrp G N$, tal que o
$\sset {\quogrp G N} \ast$ vira um grupo?
Qual seria sua identidade?
Para cada um dos seus membros, qual seria o seu inverso?
Para cada dois dos seus membros, qual seria o seu produto?

%%}}}

\spoiler

%%{{{ df: quogrp 
\definition Grupo quociente.
%%%{{{ meta 
\label quogrp
\defines
    * \quogrp {~G} {~N}  -- o grupo quociente de $G$ módulo $N$
    * grupo!quociente
    ;;
%%%}}}

Sejam $G$ grupo e $N \normal G$.
O conjunto
$$
\quoset G {\congmod N}
\quad
\bigparen{ =
\mubrace {\setst { aN } { a \in G }} {\cosetsL N}
=
\mubrace {\setst { Na } { a \in G }} {\cosetsR N}
}
$$
com operação a $\ast$ definida pela
$$
Na \ast Nb \defeq N(ab)
$$
é chamado o \dterm{grupo quociente de $G$ módulo $N$},
e é denotado por $\quogrp G N$.
\mistake

%%}}}

%%{{{ Q: Everything alright with quogrp ? 
\question.
%%%{{{ meta 
%%%}}}

Tá tudo bem com a~\ref[quogrp]?

%%}}}

\spoiler

%%{{{ A: No: you must prove that it is well-defined: 
\blah Resposta.
%%%{{{ meta 
%%%}}}

A operação $\ast$ não é automaticamente ``bem-definida''
(como discutimos no \ref[not_well_defined_function_danger_quogrp]):
precisamos demonstrar que realmente seu valor não
depende da escolha dos representantes $a$ e $b$.
Falei ``precisamos''?  Quis dizer \emph{precisas}.
Agora:

%%}}}

%%{{{ x: nop_is_well_defined 
\exercise.
%%%{{{ meta 
\label nop_is_well_defined
%%%}}}

Demonstre que a $\ast$ definida acima é bem-definida.

\hint
Basta demonstrar que qualquer escolha de representante envolvida
não afetará o resultado.

\hint
Basta demonstrar que para quaisquer $a,a',b,b'\in G$ temos:
$$
\rightbrace {
\mathcoled {
aN &= a'N \\
bN &= b'N
}
}
\implies
(ab)N = (a'b')N
$$

\hint
Temos que $N \normal G$ e logo $a'N = Na'$ e $b'N = Nb'$.

\solution
Sejam $a,a',b,b'$ tais que $aN = a'N$ e $bN = b'N$,
e como $N \normal G$ temos
$aN = a'N = Na'$ e
$bN = b'N = Nb'$.
Basta demonstrar que $(ab)N = (a'b')N$.
Demonstramos apenas a direção \lrdirset (a outra é similar).
\eop
\lrdirset:
Precisamos mostrar que um arbitrario membro do $(ab)N$ pertence ao $(a'b')N$.
Seja $n \in N$.  O $abn$ então já é um arbitrário membro do $(ab)N$.
Basta demonstrar que $abn \in (a'b')N$, ou seja escrevê-lo na forma:
$$
abn = a'b'\mubrace {\askbox} {\in N}.
$$
Calculamos:
\compute
abn
&= an'b'    \by {onde $n'   \in N$ tal que $bn  = n'b'$     (pela $bN=Nb'$)} \\
&= a'n''b'  \by {onde $n''  \in N$ tal que $an' = a'n''$    (pela $aN=a'N$)} \\
&= a'b'n''' \by {onde $n''' \in N$ tal que $n''b' = b'n'''$ (pela $Nb'=b'N$)}
\endcompute

%%}}}

\TODO Sobre bem-definido por argumento.

%%{{{ lemma: operation_for_cosets_of_normal 
\lemma.
%%%{{{ meta 
\label operation_for_cosets_of_normal
%%%}}}

Sejam $G$ grupo, $N \normal G$, e $a,b \in G$.
$$
(Na)\ast(Nb) = (Na)(Nb) \quad \Bigparen{= \setst {uv} {u \in Na, v \in Nb}}
$$

\sketch.
Como $(Na)\ast(Nb) = N(ab)$, mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
Sem detalhes, temos
$$
\xalignat2
&
\aligned
g \in (Na)(Nb)
&\implies g = (n_a a) (n_b b) \\
&\implies g = n_a (a n_b) b \\
&\impliesbecause{$^{(\normal)}$} g = n_a (n_b' a) b \\
&\implies g = \mubrace {\mubrace{(n_a n_b')} {\in N} (a b)} {\in N (ab)}
\endaligned
&&
\aligned
g \in N(ab)
&\implies g = n(ab)\\
&\implies g = \mubrace{\mubrace{(na)} {\in Na} \mubrace{\vphantom(b\vphantom)} {\in Nb}} {\in (Na)(Nb)}
\endaligned
\endxalignat
$$
onde os nomes das variáveis introduzidas devem indicar uns
dos detalhes omitidos.

\proof.
Mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
\crproofpart{\lrdir}.
Suponha $g \in (Na)(Nb)$.
Logo sejam $a'\in Na$ e $b' \in Nb$ tais que $g = a'b'$.
Pelas definições dos $Na$ e $Nb$, sejam $n_a,n_b \in N$
tais que $a' = n_a a$ e $b' = n_b b$.
Logo temos
$$
g = (n_a a) (n_b b) = n_a (a n_b) b
$$
Mas como $a n_b \in aN$ e $aN = Na$ (pois $N\normal G$),
temos que $a n_b$ = $n_b' a$ para algum $n_b' \in N$.
Logo
$$
g = n_a (n_b' a) b = (n_a n_b') (a b) \in N (ab)
$$
pois $n_a n_b' \in N$.
\crproofpart{\rldir}.
Suponha $g \in N(ab)$.
Logo seja $n\in N$ tal que $g = n(ab)$.
Logo temos
$$
g = n(ab) = (na)b \in (Na)(Nb)
$$
pois $na \in Na$ e $b \in Nb$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para merecer esse nome, o $\quogrp G N$ deve ser um grupo mesmo.
Vamos demonstrar isso agora.

%%}}}

%%{{{ thm: quogrp_is_a_group 
\theorem.
%%%{{{ meta 
\label quogrp_is_a_group
%%%}}}

Sejam $G$ grupo e $N\normal G$.
O $\quogrp G N$ é um grupo.

\sketch.
Graças ao~\ref[onesided_group_def], basta verificar que
$\quogrp G N$ com sua operação (\ref[quogrp]) satisfaz uma
definição unilateral de grupo: (G0), (G1), (G2L), (G3L).
Observe que o $\quogrp G N$ é indexado pelo $N$,
e logo para solicitar um membro arbitrário do $\quogrp G N$,
basta tomar um arbitrário membro $a \in N$.
\crproofpart{(G0):}
Sejam $a,b \in N$.
Realmente $(Na)(Nb) = N(ab) \in \quogrp G N$.
\crproofpart{(G1):}
Sejam $a,b,c \in N$.
Calculando verificamos que $((Na)(Nb))(Nc) = (Na)((Nb)(Nc))$.
\crproofpart{(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
O candidato óbvio é o próprio $N = Ne$.
Basta confirmar essa afirmação, ou seja, mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
\crproofpart{(G3L):}
Para mostrar que cada um dos membros de $\quogrp G N$ tem um inverso esquerdo,
seje $a \in N$ e mostre como achar um inverso esquerdo de $Na \in \quogrp G N$.
Aqui o candidato que faz sentido considerar é o $N(\ginv a)$.

\proof.
Graças ao~\ref[onesided_group_def], basta verificar que
$\quogrp G N$ com sua operação (\ref[quogrp]) satisfaz uma
definição unilateral de grupo: (G0), (G1), (G2L), (G3L).
\proofpart{(G1):}
Sejam $a,b,c \in N$.
Calculamos:
$$
\bigparen{(Na)(Nb)}(Nc)
= \bigparen{N(ab)}(Nc)
= N\paren{(ab)c}
= N\paren{a(bc)}
= (Na)\bigparen{N(bc)}
= (Na)\bigparen{(Nb)(Nc)}.
$$
\proofpart{(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
Afirmação: o $N \in \quogrp G N$ é uma identidade esquerda do $\quogrp G N$.
Para demonstrar essa afirmação precisamos mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
Realmente, seja $a \in N$.
Calculamos:
$$
N(Na) = (Ne)(Na) = N(ea) = Na.
$$
\proofpart{(G3L):}
Seja $a \in N$.
Afirmação: o $N(\ginv a)$ é um inverso esquerdo de $Na$.
Para demonstrar essa afirmação precisamos verificar que:
$$
(N(\ginv a)) (Na) = N.
$$
Calculamos:
$$
\paren{N(\ginv a)}(Na)
= N(\ginv a a)
= Ne
= N
$$
e pronto.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Seria importante se convencer que essa coisa legal realmente não
é compartilhada por subgrupos não-normais.
Faça agora o:

%%}}}

%%{{{ x: not_normal_subgroup_makes_soulless_quoset 
\exercise.
%%%{{{ meta 
\label not_normal_subgroup_makes_soulless_quoset
%%%}}}

Mostre que para qualquer $H \not\normal G$ as $\congL H$ e
$\congR H$ não são congruências e logo nenhum dos
$\quoset G {\congL H}$ $\quoset G {\congR H}$ pode virar
um grupo com a alma do $G$.

%%}}}

%%{{{ Congruences 
\note Congruências.
%%%{{{ meta 
\label congruences
%%%}}}

Teve mais algo dessatisfatório com as relações $\congL H$
e $\congR H$ baseadas num $H \subgroup G$, mesmo que ambas
são relações de equivalência sim!  Eles não são garantidas
pra ser\dots~\emph{congruências:}

%%}}}

%%{{{ df: congruence_in_group 
\definition congruência (em grupo).
%%%{{{ meta 
\label congruence_in_group
%%%}}}

Uma relação de equivalência $\sim$ num grupo $\ssetfont G = \sset G {\ast, \ginv{}, \gid}$
é uma \dterm{congruência} de $G$ sse $\sim$ é \dterm{compatível com a estrutura} do $\ssetfont G$:
$$
\align
\pforall {a,b,a',b' \in G} & \quantified {a \sim b \mland a' \sim b' \implies a \ast a' \sim b \ast b'} \\
\pforall {a,b \in G}       & \quantified {a \sim b \implies \ginv a \sim \ginv b} \\
                           & \gid \sim \gid.
\endalign
$$

%%}}}

%%{{{ remark: automaticly compatible with gid 
\remark.
%%%{{{ meta 
%%%}}}

Observe que a última linha não oferece absolutamente nada na definição
de \emph{congruência} pois a $\sim$ sendo relação de equivalência é reflexiva.

%%}}}

%%{{{ corollary: congmod_N_is_a_congruence 
\corollary.
%%%{{{ meta 
%%%}}}

Se $N \normal G$ então $\congmod N$ é uma congruência.

\proof Demonstrado no \ref[nop_is_well_defined].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No \ref[Universal_algebra] estudamos mais congruências num
contexto mais geral, não apenas para grupos.

%%}}}

%%{{{ x: congL_and_congR_not_congruences_counterexample 
\exercise.
%%%{{{ meta 
\label congL_and_congR_not_congruences_counterexample
%%%}}}

Mostre grupo $G$ e $H \subgroup G$ tais que $\congL H$ e $\congR H$
não são congruências.

%%}}}

\endsection
%%}}}

%%{{{ Normal_subgroups 
\section Subgrupos normais.
%%%{{{ meta 
\label Normal_subgroups
%%%}}}

%%{{{ intro 
\secintro
Na~\ref[The_quotient_group] definimos os
\emph{subgrupos normais} como aqueles cujas coclasses
esquerdas e direitas formam a mesma partição.
Aqui encontramos umas definições equivalentes que
superficialmente parecem bastante diferentes.
%%}}}

%%{{{ df: normal_equivalent_definitions 
\definition definições de normal.
%%%{{{ meta 
\label normal_equivalent_definitions
\defines
    * subgrupo!normal
    ;;
%%%}}}

As afirmações seguintes são equivalentes (e logo cada
uma pode servir como definição de $N \normal G$):
$$
N \normal G
\defiff
N \subgrp G
\mland
\text{qualquer uma das:}\ \ 
\leftbrace {
\aligned
\text{(i)}~   & \cosetsL N = \cosetsR N \\
\text{(ii)}~  & \congL N \;=\; \congR N \\
\text{(iii)}~ & \text{$N$ é fechado pelos conjugados} \\
\text{(iv)}~  & \lforall {g\in G} {gN\ginv g \subset N} \\
\text{(v)}~   & \lforall {g\in G} {gN\ginv g = N} \\
\text{(vi)}~  & \lforall {g\in G} {gN = Ng},
\endaligned
}
$$
lembrando que $\cosetsL N$ e $\cosetsR N$ são as colecções de left
e right cosets de $N$ respectivamente (\ref[cosetsL_and_cosetsR]),
e $\congL N$ e $\congR N$ as equivalências módulo-esquerdo e
módulo-direito $N$ respectivamente (\ref[equivalence_mod_subgroup]).
Se demonstrar tudo isso---algo que vamos fazer junto logo---seria
massa pois:
cada vez que vamos ter como dado que $N \normal G$, a gente
vai ganhar \emph{toda} essa afirmação de graça; e dualmente,
cada vez que vamos querer demonstrar que $N \normal G$, a gente
vai ter a liberdade de escolher qualquer uma dessas e pronto!

%%}}}

%%{{{ x: which_normal_altdef_will_never_be_our_goal 
\exercise.
%%%{{{ meta 
\label which_normal_altdef_will_never_be_our_goal
%%%}}}

Qual dessas não faria sentido escolher nunca querendo demonstrar
que $N \normal G$?

\hint
A $\lforall {g\in G} {gN\ginv g = N}$.  Por quê?

\solution
A $\lforall {g\in G} {gN\ginv g = N}$, pois escolhendo
a $\lforall {g\in G} {gN\ginv g \subset N}$, a gente teria
menos trabalho pra fazer.

%%}}}

%%{{{ closed_under_conj_meaning 
\note Fechado pelos quê?.
%%%{{{ meta 
\defines
    * fechado!pelos conjugados
    ;;
%%%}}}

O que significa \emph{fechado pelos conjugados?}
Significa \emph{fechado pela relação de conjugação};
em símbolos:
$$
\align
\pforall {n \in N} & \quantifiedt{todos os conjugados do $n$ pertencem ao $N$} \\
\intertext{ou seja,}
\pforall {n \in N} &
\lforall {g \in G}
{ gn\ginv g \in N }.
\endalign
$$

%%}}}

%%{{{ remark: closed_under_conjugation_swap_quantifiers 
\remark trocando a ordem dos quantificadores.
%%%{{{ meta 
\label closed_under_conjugation_swap_quantifiers
%%%}}}

Observe que podemos trocar a ordem dos quantificadores
pois são do mesmo tipo:
$$
\pforall {n\in N}
\lforall {g\in G}
{ gn\ginv g \in N }
\iff
\pforall {g\in G}
\mubrace {
\lforall{n\in N}
{ gn\ginv g \in N }
}
{ gN\ginv g \subset N }.
$$
Vamos dar uma olhada detalhada agora,
caso que a parte sublinhada acima pareceu estranha.
Lembre-se como tomamos membros arbitrários dum conjunto
indexado (\ref[picking_elements_from_indexed_sets]
e~\ref[only_declare_variables_group_reminder]).
Provando a afirmação
$$
\align
\pforall {n\in N} &\quantifiedt{algo sobre o $gn\ginv g$}
\intertext{ganhamos que todos os membros do $gN\ginv g$ satisfazem
esse algo, pois o conjunto $gN\ginv g$ é indexado por o $N$.
Aqui o algo é o <<pertencer ao $N$>>.
Ou seja:}
\pforall {n\in N} &\quantified{gn\ginv g \in N}
\endalign
$$
afirma que todos os membros de $gN\ginv g$ pertencem ao $N$,
ou seja, $gN\ginv g \subset N$.

%%}}}

%%{{{ thm: normal_equivalent_definitions_are_equivalent 
\theorem.
%%%{{{ meta 
\label normal_equivalent_definitions_are_equivalent
\indexes
    * subgrupo!normal
    ;;
%%%}}}

Sejam $G$ grupo, e $N\subgroup G$.
Os (i)--(vi) da~\ref[normal_equivalent_definitions] são
equivalentes.

\proof.
\proofpart{(i)\tiff(ii).}
Demonstrado no~\ref[Relations] (veja \ref[eqrel_quoset_partition_summary]).
\crproofpart{(iii)\tiff(iv).}
Demonstrado no~\ref[closed_under_conjugation_swap_quantifiers].
\crproofpart{(iv)\tiff(v).}
A {\rldir} é trivial, pois o que precisamos demonstrar
($N \normal G$) é obviamente uma afirmação mais fraca da nossa hipótese.
Para a {\lrdir}, suponha $N \normal G$ e seja $g\in G$.
Já temos a inclusão $gN\ginv g \subset N$, então só basta demonstrar
a $N \subset gN\ginv g$.  Seja $n \in N$.
Como $n \in N$ e $N$ normal, temos $\ginv g n \ginvp{\ginv g} \in N$.
Logo
$$
\mubrace {g \paren{\ginv g n \ginvp{\ginv g}} \ginv g} {=n} \in gN\ginv g.
$$
\crproofpart{(iii)\timplies(vi)}
Tome $n \in N$; assim $gn\ginv g$ é
um arbitrário membro do $gN\ginv g$.
Basta mostrar que $gn\ginv g \in N$.
Mas $gn \in gN = Ng$ e logo $gn = n'g$ para algum
$n' \in N$.
Calculamos:
$$
gn\ginv g = n'g \ginv g = n' \in N.
$$
\crproofpart{As outras implicações são pra ti:}
\ref[normal_equivalent_definitions_are_equivalent_rest_of_proof].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um corolário bem útil da (vi) é o seguinte:

%%}}}

%%{{{ cor: normal_commutes_with_every_subset_via_subset_product 
\corollary.
%%%{{{ meta 
\label normal_commutes_with_every_subset_via_subset_product
%%%}}}

Sejam $G$ grupo, $N \normal G$.
Para todo $A \subset G$, $AN = NA$.

\proof.
Numa linha só:
$$
AN = \Union_{a \in A} aN = \Union_{a \in A} Na = NA.
$$

%%}}}

%%{{{ beware: g n g^{-1} \neq n 
\beware.
%%%{{{ meta 
%%%}}}

Se tivemos $N \normal G$ temos sim que $gn\ginv g \in N$ para todo $n\in N$,
mas isso \emph{não garanta} que $gn\ginv g = n$ não!
Sabemos que para todo $n\in N$, temos $gn\ginv g = n'$ \emph{para algum}
$n' \in N$, mas nada nos permite concluir que esse $n'$ é nosso $n$.
Isso quis dizer que em geral não podemos demonstrar que
$$
\align
\famst {gn\ginv g} {n\in N} &= \famst {n} {n\in N}
\intertext{como famílias indexadas por o mesmo conjunto $N$, mas mesmo
assim conseguimos demonstrar que os \emph{conjuntos} são iguais sim:}
\setst {gn\ginv g} {n\in N} &= \setst {n} {n\in N},
\intertext{ou seja,}
gN\ginv g &= N.
\endalign
$$
Parecidamente, sabendo que $gN=Ng$ e tendo um $n\in N$, \emph{não}
podemos concluir que $gn=ng$, mas pelo menos sabemos que
$$
gn = n'g,
\quad\text{para algum $n' \in N$}.
$$

%%}}}

%%{{{ x: gnginvg_neq_n 
\exercise.
%%%{{{ meta 
\label gnginvg_neq_n
%%%}}}

Ache um contraexemplo que mostra que não necessariamente
$gn\ginv g = n$, mesmo com $n\in N \normal G$.

%%}}}

%%{{{ x: normal_equivalent_definitions_are_equivalent_rest_of_proof 
\exercise.
%%%{{{ meta 
\label normal_equivalent_definitions_are_equivalent_rest_of_proof
%%%}}}

Demonstre o que falta para estabelecer que todas
as (i)--(vi) do~\ref[normal_equivalent_definitions_are_equivalent]
são equivalentes.

%%}}}

%%{{{ x: subset_product_of_subgroup_and_normal_is_subgroup 
\exercise.
%%%{{{ meta 
\label subset_product_of_subgroup_and_normal_is_subgroup
%%%}}}

Se $S \subgroup G$ e $N\normal G$, então $SN \subgroup S$.

\hint
\proofalt{Maneira 1:}
imediato pelos:
\ref[HK_equals_KH_iff_HK_subgroup] e~\ref[normal_commutes_with_every_subset_via_subset_product].
\crproofalt{Maneira 2:}
Use o ``one-test''~\ref[subgroup_one_test].
Observe que
$SN$ é indexado pelo conjuto $S\times N$ e logo basta tomar
um arbitrário par $\tup{s,n} \in S \times N$ para ganhar
um arbitrário membro do $SN$: o $sn$.

\hint
Se escolheste investigar a segunda maneira da dica anterior:
\eop
Tome $s_1,s_2 \in S$ e $n_1,n_2 \in N$; assim o $s_1n_1$
e $s_2n_2$ são dois arbitrários membros do $SN$.
Basta demonstrar que $(s_1n_1)\ginvp{s_2n_2} \in SN$.

%%}}}

%%{{{ x: inter_of_subgroup_and_normal_is_normal_in_subgroup 
\exercise.
%%%{{{ meta 
\label inter_of_subgroup_and_normal_is_normal_in_subgroup
%%%}}}

Se $S \subgroup G$ e $N\normal G$, então $S \inter N \normal S$.

\hint
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\reftag[intersection_of_subgroups_is_a_subgroup]
e~\reftag[subgroup_is_an_order]).
Para mostrar que $S \inter N \normal S$,
tente demonstrar que $S\inter N$ é fechado pelos conjugados no $S$.

\solution
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\reftag[intersection_of_subgroups_is_a_subgroup]
e~\reftag[subgroup_is_an_order]).
Basta mostrar que $S \inter N \normal S$,
ou seja, que $S\inter N$ é fechado pelos conjugados no $S$.
Tome $x \in S\inter N$ e $h\in S$.
Temos:
\compute
h x \ginv h &\in S  \by {$S \subgroup G$} \\
h x \ginv h &\in N  \by {$N \normal G$} \\
\endcompute
Logo $hx\ginv h \in S \inter N$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: converse_of_lagrange_is_invalid_proof 
\problem.
%%%{{{ meta 
\label converse_of_lagrange_is_invalid_proof
%%%}}}

Justifique o~\ref[converse_of_lagrange_is_invalid]:
mostre grupo $G$ e um divisor $d \divides \gord G$
tal que $G$ não possui nenhum grupo de ordem $d$.

%%}}}

%%{{{ prob: euclids_theorem_as_corollary_of_lagrange 
\problem Teorema de Euclides.
%%%{{{ meta 
\label euclids_theorem_as_corollary_of_lagrange
%%%}}}

Mostre como demonstrar o teorema de Euclides~\reftag[primes_is_infinite]
como um corolário de {\Lagrange[teorema!corolário]}Lagrange.

\hint
Para chegar num absurdo, suponha que $P$ é o maior primo.
Considere o número $2^P - 1$.

\hint
Como o $2^P - 1$ não é primo,
seja $q$ um fator primo do $2^P - 1$.
Então
$$
2^P - 1 \cong 0 \pmod q.
$$

\hint
Temos
$$
2^P \cong 1 \pmod q.
$$
O que podemos concluir sobre a ordem de $2$ no grupo\dots
Em qual grupo mesmo?

%%}}}

%%{{{ prob: wilsons_theorem_proof_using_groups 
\problem Teorema de Wilson.
%%%{{{ meta 
\label wilsons_theorem_proof_using_groups
\credits
    * Wilson : teorema
    ;;
%%%}}}

Demonstre o teorema de Wilson
$$
\text{$n$ é primo} \iff \facp{n-1} \cong -1 \pmod n
$$
usando o conhecimento da teoria dos grupos até agora.

%%}}}

%%{{{ prob: cosets_are_equinumerous 
\problem.
%%%{{{ meta 
\label cosets_are_equinumerous
%%%}}}

Demonstre o~\ref[cosets_are_equinumerous_finite_case]
mesmo quando $H$ é infinito.

\hint
Sendo o $H$ infinito, basta demonstrar que o $Ha$ também é?

\hint
Deixe a pergunta da dica anterior para o~\ref[Cantors_paradise].
Por enquanto, demonstre uma bijecção entre $H$ e $Ha$.

\hint
A restricção (\ref[fresto]) no $H$ do $a$-ator direito (\ref[group_actors]).

\hint
Já sabemos que é injetora (\ref[group_actors_are_bijective]).
Basta demonstrar que é sobre o $Ha$.

\solution
Seja $a\in G$.
Basta demonstrar que $Ha$ e $H$ têm a mesma quantidade de elementos
(a demonstração sobre as coclasses esquerdas é similar).
Vamos fazer isso mostrando uma bijecção entre os dois conjuntos.
Primeiramente observe que a funcção $\actorR a : G \to G$
é injetora (\ref[group_actors_are_bijective])
e logo sua restricção $\actorR a \resto {H}$ também é.
Basta mostrar que ela é sobrejetora no $Ha$.
Seja $d \in Ha$, e logo pela definição de $Ha$ seja $h \in H$
tal que $d = ha$.
Temos então $\actorR a \resto {H} (h) = d$,
e logo $\actorR a \resto {H}$ é sobrejetora no $Ha$.

%%}}}

%%{{{ prob: one_congruence_implies_normal 
\problem.
%%%{{{ meta 
\label one_congruence_implies_normal
%%%}}}

Seja $G$ grupo e $N \subgrp G$ tal que $\congL N$ ou $\congR N$
é uma congruência (\ref[congruence_in_group]).
A afirmação $N \normal G$ é correta?
Responda <<sim>> e demonstre; ou <<não>> e refuta;
ou <<talvez>> e mostre um exemplo e um contraexemplo.

%%}}}

%%{{{ prob: subgroup_product_of_normal_is_normal 
\problem.
%%%{{{ meta 
\label group_subset_product_of_normal_is_normal
%%%}}}

Sejam $G$ grupo e $N,M \normal G$.
Afirmação:
$$
NM \normal G.
$$
Se a afirmação é demonstrável demonstre; se é refutável refuta;
caso contrário mostre que não é nem demonstrável nem refutável.

\hint
A afirmação é válida;
demonstre.

\hint
Mostre que $NM$ é fechado pelos conjugados.

%%}}}

\endproblems
%%}}}

%%{{{ Symmetries 
\section Simetrias.
%%%{{{ meta 
\label Symmetries
%%%}}}

%%{{{ eg: [symmetry_eg] flip around a bisector 
\example.
%%%{{{ meta 
\label symmetry_eg
%%%}}}

A transformação $T$ que gira o triangulo por volta do
eixo mostrado por um ângulo $\pi$, é uma simetria
do triangulo.
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=red] (-.5,0.866) -- (B) -- (C);
\draw[color=blue] (-.5,0.866) -- (A) -- (C);
\node[color=blue,xshift=-3mm] at (A) {$A$};
\node[color=red,xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=blue] (-.5,0.866) -- (B) -- (C);
\draw[color=red] (-.5,0.866) -- (A) -- (C);
\node[color=red,xshift=-3mm] at (A) {$B$};
\node[color=blue,xshift=-2mm,yshift=1mm] at (B) {$A$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm);
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
$$

%%}}}

%%{{{ What is a symmetry? (1) 
\note O que é uma simetria (1).
%%%{{{ meta 
%%%}}}

Ok, então <<simetria>> é uma \emph{transformação} que leva uma forma
geométrica para outra, tal que o resultado fica exatamente em cima
da forma original: se desenhar a forma-depois em cima da forma-antes,
cada ponto da forma-depois vai cair em cima dum ponto da forma-antes.
Isso é bem informal, mas nosso objectivo não é estudar simetrias
geométricas neste momento, apenas dar uma intuição com
``palavras da rua'' então essa descripção deve servir para nos guiar.
Mas isso \emph{não é suficiente} para chamar uma transformação de
simetria.

%%}}}

%%{{{ noneg: [symmetry_noneg] flip just the base 
\nonexample.
%%%{{{ meta 
\label symmetry_noneg
%%%}}}

Considere a transformação $T'$
que deixa todos os pontos dos lados $AB$ e $AC$ em paz,
mas vira todos os pontos do interior do $BC$ para a outra direção:
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=red] (-.5,0.866) -- (B);
\draw[color=blue] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.2) node [pos=.666] {\rotator{150}};
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T'$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=blue] (-.5,0.866) -- (B);
\draw[color=red] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.0);
\endtikzpicture
\endgathered
$$

%%}}}

%%{{{ Q: What would you add to exclude symmetry_noneg ?
\question.
%%%{{{ meta 
%%%}}}

O que tu adicionaria na ``definição'' de simetria acima
para excluir transformações como essa do~\ref[symmetry_noneg]?

%%}}}

\spoiler

%%{{{ What is a symmetry? (2) 
\note O que é uma simetria (2).
%%%{{{ meta 
\defines
    * isometria
    ;;
%%%}}}

Observe que existe uma diferença importante entre a transformação
do~\ref[symmetry_eg] e aquela do~\ref[symmetry_noneg]:
a primeira \emph{preserva as distâncias}, a segunda não.
Vamos chamar as transformações $T$ e $T'$ respectivamente.
Tome quaisquer dois pontos $x,y$ no triângulo, e meça sua
distância $d(x,y)$.
A transformação $T$ garanta que
$$
d(x,y) = d(Tx, Ty)
$$
para todos os $x,y$, mas a $T'$ não:
existem $x,y$ tais que $d(x,y) \neq d(T'x, T'y)$.
Isso é o que faltou da nossa primeira tentativa de dizer
o que é uma simetria:
ela tem que \emph{preservar as distâncias},
ou seja, ser uma \dterm{isometria}.

%%}}}

%%{{{ x: Show that symmetry_noneg is not a symmetry 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre (informalmente no desenho) que a transformação $T'$
do~\ref[symmetry_noneg] não é uma simetria.

\hint
Ela não é uma isometria.
Demonstre!

\hint
Precisa achar dois pontos $p,q$ no triângulo tal que
a distância $d(p,q) \neq d(T'p, T'q)$.

%%}}}

%%{{{ Q: Which are all the symmetries of an equilateral triangle? 
\question.
%%%{{{ meta 
%%%}}}

Quais são todas as simetrias dum triângulo equilátero?

%%}}}

\spoiler

%%{{{ dih3_symmetries 
\note As simetrias dum triângulo equilátero.
%%%{{{ meta 
\label dih3_symmetries
%%%}}}

Fixa um triângulo equilátero.
Aqui todas as suas simetrias:
$$
\xalignat3
&\tikzpicture
\tikzi dih3base;
\draw[dashed] (0,1.732) -- +(270:2.5cm) node [pos=0.83] {\rotator{90}};
\draw[dashed] (0,1.732) -- +(90:5mm);
\node (label) at (-.5, -.5) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (-1,0) -- +(30:2.5cm) node [pos=0.83] {\rotator{30}};
\draw[dashed] (-1,0) -- +(210:5mm);
\node (label) at (1.1, 1.5) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\node (label) at (-1.0, 1.5) {$\Delta_3$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:210:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{2\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:330:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{4\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3base;
\node (label) at (-1.1, 1.1) {$I$};
\endtikzpicture
\endxalignat
$$
Tem $6$ simetrias então
$$
\Delta_1, \Delta_2, \Delta_3, R, R', I
$$
onde escrevemos $R$ e $R'$ para as $R_{\frac{2\pi}3}$
e $R_{\frac{4\pi}3}$ respectivamente.

%%}}}

%%{{{ Q: How can we turn dih3 into a group? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir uma operação no conjunto de todas as simetrias
dum triângulo equilateral, tal que ele vira um grupo?

%%}}}

\spoiler

%%{{{ df: dih_n 
\definition Os grupos dihedrais.
%%%{{{ meta 
\label dih_n
\indexes
    * dihedral    see: grupo dihedral
    ;;
\defines
    * grupo!dihedral
    ;;
%%%}}}

O \dterm{grupo dihedral} $\dih n$ (também $\dihalt n$)
é o grupo das simetrias dum $n$-gono regular, com operação
a composição $\fcom$ (vendo as simetrias como
transformações---ou seja, funcções):
$B \fcom A$ é a simetria que criamos aplicando primeiramente
a $A$ e depois a $B$.\foot
Alternativamente escrevemos isso como
$A \dcom B$ (notação diagramática,~\reftag[diagrammatic_notation]).
Tendo esclarecido qual das~$\fcom$ e~$\dcom$ usamos---e com
a mesma preguiça notacional que temos elaborado
em vários outros casos até agora---escrevemos simplesmente $AB$,
denotando assim a operação do grupo com juxtaposição.
\toof

%%}}}

%%{{{ x: dih_n is indeed a group 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que o $\dih n$ realmente é um grupo.

%%}}}

%%{{{ x: dih_4 
\exercise.
%%%{{{ meta 
\label dih_4
%%%}}}

Ache todas as simetrias dum quadrado.

\hint
São $8$.

\solution
Aqui todas as simetrias dum quadrado:
$$
\xalignat4
&\tikzpicture
\tikzi dih4base;
\node at (label) {$I$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:90:.4);
\node at (label) {$R$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:180:.4);
\node at (label) {$R'$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:270:.4);
\node at (label) {$R''$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,-1.07) -- (1.07,1.07) node [pos=0.5] {\rotator{45}};
\node at (label) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,1.07) -- (1.07,-1.07) node [pos=0.5] {\rotator{-45}};
\node at (label) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.2,0) -- (1.2,0) node [pos=0.5] {\rotator{0}};
\node at (label) {$H$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (0,-1.2) -- (0,1.2) node [pos=0.5] {\rotator{90}};
\node at (label) {$V$};
\endtikzpicture
\endxalignat
$$

%%}}}

%%{{{ x: gord_dih_n 
\exercise.
%%%{{{ meta 
\label gord_dih_n
%%%}}}

Qual a $\gord{\dih n}$?

%%}}}

%%{{{ Dih n notation warning 
\warning.
%%%{{{ meta 
%%%}}}

O que simbolizamos aqui por $\dih n$ em certos textos aparece
como $\dih {2n}$.  A gente botou a quantidade $n$ de ângulos do
$n$-gono no índice do símbolo, mas tem gente que bota a quantidade
de simetrias do $n$-gono como índice, e como tu acabou de ver
no~\ref[gord_dih_n], essa quantidade é $2n$.
De qualquer forma, nenhuma dessas notações é standard.\foot
Mesmo assim, a nossa notação faz mais sentido, pois:
(i) quando definimos o grupo dihedral $\dih n$ já sabemos a quantidade
de ângulos ($n$) mas por enquanto não sabemos quantos membros esse
grupo tem (até resolver o~\ref[gord_dih_n]);
(ii) já temos uma notação para a ordem dum grupo,
então não perdemos acesso nela optando para o nosso $\dih n$.
\toof
Então tome cuidado quando tu encontra em outros textos
o símbolo $\dih m$.\foot
Se o $m$ é ímpar, não existe ambigüidade.  Óbvio?
\toof

%%}}}

%%{{{ What a discovery!  Or is it? 
\note Que descoberta!  Ou não?.
%%%{{{ meta 
%%%}}}

Então, nosso amigo chegou feliz com sua descoberta
desse grupo interessante.
Mas, mais cedo ou mais tarde, a gente com certeza vai perceber algo:
esse grupo $\dih 3$ \emph{parece ser} o $\sym 3$!
Nosso amigo não achou um grupo realmente novo e original,
mas apenas re-descobriu o grupo $\sym 3$ que conhecemos
desde o início desse capítulo!
Em qual sentido os dois grupos ``são praticamente a mesma coisa''?
Esse é o assunto da~\ref[Group_morphisms],
mas podemos já dar uma primeira resposta informal:
\emph{como grupos, eles comportam no mesmo jeito}.

%%}}}

%%{{{ Are they equal then? 
\note Então são iguais?.
%%%{{{ meta 
%%%}}}

Não!
A palavra certa para esse caso é \dterm{isómorfos} ou
\dterm{isomórficos}, que já encontramos no contexto de
conjuntos~(\ref[isomorphic_sets]).
Lembre-se que isómorfos são aqueles que têm a mesma forma
(\ref[etymology_of_isomorphic]), mas também que o que significa
``forma'' depende do contexto.
Aqui seria \emph{a estrutura de grupos}.
Grupos isómorfos têm exatamente as mesmas \emph{propriedades grupoteóricas}.

%%}}}

%%{{{ Group-theoretic properties 
\note Propriedades grupoteóricas.
%%%{{{ meta 
\label grouptheoretic_properties
\defines
    * propriedade!grupoteórica
    ;;
%%%}}}

Essas são propriedades que o grupista consegue enxergar com
seus olhos grupoteóricos.
Uns exemplos:
\tlist:
\li: \wq{ele tem membro cuja ordem é $2$};
\li: \wq{ele é cíclico};
\li: \wq{ele tem dois membros que são seus próprios inversos};
\li: \wq{ele possui $3$ subgrupos normais};
\li: \wq{ele tem exatamente $4$ membros}.
\endtlist
A última talvez não parece ser muito grupoteórica, mas de fato
o grupista entende essa afirmação---talvez se reformulá-la como
\wq{ele tem ordem $4$} não vai parecer estranho.
Uns nãœxemplos:
\tlist:
\li: \wq{seus membros são conjuntos};
\li: \wq{seus membros são números};
\li: \wq{ele tem membro que é singleton};
\endtlist
Por outro lado, o conjuntista, com seus olhos conjuntoteóricos
consegue enxergar todas as diferenças entre o $\dih 3$ e $\sym 3$:
de fato, ele vai responder que são diferentes---e ainda mais:
disjuntos!
Os membros do $\dih 3$ são transformações dos pontos dum plano;
os membros do $\sym 3$ são permutações, ou seja,
bijecções de $\set{1,2,3}$ para $\set{1,2,3}$.
\eop
E para o grupista?
\emph{O que são} e \emph{quais são} os membros de grupo é irrelevante.
Ele não tá nem aí sobre a natureza dos membros, ou seus nomes,
ou sua aparência!
O que importa pra ele são suas propriedades grupoteóricas e nada mais:
o inverso desse é aquele; o produto desses é aquilo;
a identidade é essa; este aqui é um gerador; estes aqui são conjugados;
tem tantos com ordem $n$;
etc.

%%}}}

%%{{{ eg: why dih 4 is not isomorphic with sym 4
\example.
%%%{{{ meta 
%%%}}}

O $\dih 4$ não é isómorfo com o $\sym 4$.

\solution.
Como $\gord{\dih 4} = 8 \neq 24 = \gord{\sym 4}$,
já sabemos que os dois grupos não são isomórficos.

%%}}}

%%{{{ x: why dih 4 is not isomorphic with Z/8Z 
\exercise.
%%%{{{ meta 
%%%}}}

Explique porque o $\dih 4$ não é isómorfo com o grupo aditivo
$\ints_8$ dos inteiros com adição módulo $8$.

\solution
Basta achar uma propriedade grupoteórica que um dos dois grupos tem
e o outro não.  Uns exemplos:
\tlist:
\li: \wq{{\thole} é abeliano}:
     satisfeita por $\ints_8$ mas não por $\dih 4$;
\li: \wq{{\thole} é cíclico}:
     satisfeita por $\ints_8$ mas não por $\dih 4$;
\li: \wq{{\thole} tem $3$ membros de ordem $2$}:
     satisfeita por $\dih 4$ mas não por $\ints_8$;
\endtlist
etc.

%%}}}

%%{{{ eg: is dih 4 cyclic? 
\example.
%%%{{{ meta 
%%%}}}

O $\dih 4$ é um grupo cíclico?

\solution.
Para ver se $\dih 4$ é um grupo cíclico ou não, conferimos
para cada membro $a$ dele, se $a$ pode gerar o grupo inteiro
ou não.
Calculamos:
$$
\xalignat2
\gen I     &= \set {I}          & \gen {\Delta_1} &= \set {I, \Delta_1} \\
\gen R     &= \set {I,R,R',R''} & \gen {\Delta_2} &= \set {I, \Delta_2} \\
\gen {R'}  &= \set {I,R'}       & \gen H          &= \set {I, H} \\
\gen {R''} &= \gen R            & \gen V          &= \set {I, V}
\endxalignat
$$
Nenhum desses subgrupos gerados é o próprio $\dih 4$,
e logo $\dih 4$ não é um grupo cíclico.

%%}}}

%%{{{ hasse_diagrams_first_encounter 
\note Diagramas Hasse.
%%%{{{ meta 
\label hasse_diagrams_first_encounter
\defines
    * Hasse!diagrama
    ;;
%%%}}}

Quando temos uma ordem parcial $\leq$ definida num conjunto,
podemos desenhar os membros do conjunto num diagrama
chamado \dterm{diagrama Hasse}{\Hasse}.
Desenhamos os membros do conjunto e botamos uma linha
\emph{subindo} dum membro $x$ para outro $y$ sse $x\leq y$ e,
ainda mais, não tem nenhum $w$ entre os dois ($x \leq w \leq y$).
(Fique lendo até os exemplos e vai fazer sentido.)
No~\ref[Posets_Lattices] vamos trabalhar demais com esses diagramas;
agora é uma boa oportunidade introduzi-los nesse contexto.
Qual contexto exatamente?  Qual o conjunto e qual a ordem?
Lembre-se que $\subgrp$ é uma ordem parcial entre grupos
(\ref[subgroup_is_an_order]), ou seja, o conjunto de todos
os subgrupos dum dado grupo é ordenado pela $\subgrp$.
Bora desenhar então!

%%}}}

%%{{{ hasse_dih_3 
\example O Hasse das simetrias do triângulo.
%%%{{{ meta 
\label hasse_dih_3
%%%}}}

$$
\tikzpicture
\node (top)     at (0,  0 ) {$\mobrace{\set{I,R,R',\Delta_1,\Delta_2,\Delta_3}}{\dih 3}$};
\node (ir1r2)   at (-3, -2) {$\set{I,R,R'}$};
\node (id1)     at (-1, -2) {$\set{I,\Delta_1}$};
\node (id2)     at (1,  -2) {$\set{I,\Delta_2}$};
\node (id3)     at (3,  -2) {$\set{I,\Delta_3}$};
\node (bot)     at (0,  -4) {$\set{I}$};
\draw (top) -- (ir1r2);
\draw (top) -- (id1);
\draw (top) -- (id2);
\draw (top) -- (id3);
\draw (bot) -- (ir1r2);
\draw (bot) -- (id1);
\draw (bot) -- (id2);
\draw (bot) -- (id3);
\endtikzpicture
$$

%%}}}

%%{{{ hasse_dih_4 
\exercise O Hasse das simetrias do quadrado.
%%%{{{ meta 
\label hasse_dih_4
%%%}}}

Fiz do $\dih 3$; faça do $\dih 4$.

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$?$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$?$};
\endtikzpicture
$$

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

\solution
$$
\tikzpicture
\tikzi hassedih4nodes;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$\set{I,\Delta_1,\Delta_2,R'}$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$\set{I,H,V,R'}$};
\node (id2)     at (id2)     {$\set{I,\Delta_2}$};
\node (id1)     at (id1)     {$\set{I,\Delta_1}$};
\node (ir2)     at (ir2)     {$\set{I,R'}$};
\node (ih)      at (ih)      {$\set{I,H}$};
\node (iv)      at (iv)      {$\set{I,V}$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

%%}}}

%%{{{ x: dih_4_isomorphic_to_what 
\exercise.
%%%{{{ meta 
\label dih_4_isomorphic_to_what
%%%}}}

Consegues achar um grupo diferente,
que é isomórfico com o $\dih 4$?

\hint
Não pode ser o $\sym 4$ obviamente, por questão de tamanho!

\hint
Mas olhe dentro do $\sym 4$: no seus subgrupos!

\hint
Renomeia teus $A,B,C,D$ para $1,2,3,4$.
Agora veja cada uma das simetrias do $\dih 4$, para onde ela
leva cada número, e escreva sua permutação correspondente do $\sym 4$.
Basta demonstrar que esse conjunto realmente é um subgrupo de $\sym 4$.

%%}}}

%%{{{ x: minimal_generator_for_dih_3 
\exercise.
%%%{{{ meta 
\label minimal_generator_for_dih_3
%%%}}}

Qual é o menor tamanho de gerador $A \subset \dih 3$,
com $\gen{A} = \dih 3$?
Mostre um tal gerador.

%%}}}

%%{{{ x: minimal_generator_for_dih_4 
\exercise.
%%%{{{ meta 
\label minimal_generator_for_dih_4
%%%}}}

E sobre o $\dih 4$?

%%}}}

%%{{{ x: rectangle_symmetries 
\exercise Simetrias de rectângulo.
%%%{{{ meta 
\label rectangle_symmetries
%%%}}}

Ache todas as simetrias do rectângulo.

%%}}}

%%{{{ x: circle_symmetries 
\exercise As simetrias do cíclo.
%%%{{{ meta 
%%%}}}

Ache todas as simetrias do cíclo.

%%}}}

\endsection
%%}}}

%%{{{ Morphisms 
\section Morfismos.
%%%{{{ meta 
\label Group_morphisms
%%%}}}

%%{{{ Idea 
\note Idéia.
%%%{{{ meta 
%%%}}}

Queremos formalizar a idéia de <<o grupo $\dih 3$ \emph{parece com} o $\sym 3$>>.
O que precisa ser satisfeito (ou mostrado) para convencer alguém que,
no final das contas, trabalhar com um grupo $\cal A$ é
\emph{essencialmente a mesma coisa} de trabalhar com um grupo $\cal B$?

%%}}}

%%{{{ pseudodf: group_homomorphism_first_attempt 
\pseudodefinition homomorfismo.
%%%{{{ meta 
\label group_homomorphism_first_attempt
%%%}}}

Sejam $\cal A, \cal B$ grupos.
A funcção $\phi : A \to B$ é um \dterm{homomorfismo} de $\cal A$ para $\cal B$
sse ela \emph{preserva a estrutura de $\cal A$ no $\cal B$}.

%%}}}

%%{{{ Preserving the structure 
\note Preservando a estrutura.
%%%{{{ meta 
\defines
    * preservar!estrutura
    * respeitar!estrutura
    ;;
%%%}}}

Antes de entender o que significa <<preservar uma estrutura>>, vamos
lembrar: o que é a estrutura dum grupo?
É sua alma: num grupo temos a sua operação (binária), podemos pegar inversos (operação unária),
e temos também em cada grupo um membro especial chamado identidade do grupo (constante).
Ou seja, \dterm{preservar a estrutura} faz sentido significar as três coisas seguintes:
$$
\xalignat2
&\text{preservar a operação:}   & \phi(x \ast_A y)    &= \phi(x) \ast_B \phi(y)   \tag{i}   \\
&\text{preservar os inversos:}  & \phi(\ginvt_A (x))  &= \ginvt_B\paren{\phi(x)}  \tag{ii}  \\
&\text{preservar a identidade:} & \phi(e_A)           &= e_B.                     \tag{iii}
\endxalignat
$$
Também usamos o termo \dterm{respeitar}, muitas vezes como sinônimo de
preservar mas não sempre---então tome cuidado com as definições,
especialmente se a estrutura envolve relações.

%%}}}

%%{{{ Two paths 
\note Dois caminhos.
%%%{{{ meta 
%%%}}}

Considere que temos uma \emph{funcção} $\phi$ de $\cal A$ para $\cal B$.
Comece no grupo $\cal A$ (o domínio de $\phi$) e tome uns membros
$a_1,\dots,a_n$ do seu carrier set $A$.
Faça quaisquer coisas aí que a estrutura de grupo te permite fazer:
tome inversos, combine eles com a operação do grupo, etc.
Assim tu chega num certo membro $x$ do grupo $\cal A$.
Agora use a $\phi$ nesse resultado $x$, passando assim
para um certo membro $y$ do grupo $\cal B$.
Alternativamente, \emph{começando com os mesmos membros}
$a_1,\dots,a_n$ do~$\cal A$,
use a~$\phi$~logo no início em cada um deles para passar ao grupo $\cal B$,
chegando assim nuns membros $b_1,\dots,b_n$ do~$\cal B$.
Sendo num grupo agora, podes performar exatamente as mesmas operações, na mesma
ordem, nos correspondentes membros que tu fez antes (no grupo $\cal A$),
e assim tu chegarás num certo resultado $b$ no $\cal B$.
Vamos chamar a funcção $\phi$ um homomorfismo exatamente quando ela garanta que
em qualquer situação como essa, os dois caminhos de $\cal A$ para $\cal B$,
chegam no mesmo membro, ou seja, $b = y$.

%%}}}

%%{{{ note: Diagramas comutativos 
\note Diagramas comutativos.
%%%{{{ meta 
%%%}}}

Essa idéia é bem melhor desenhada do que escrita, usando diagramas comutativos.
Por exemplo, a lei (ii) é equivalente à comutatividade do diagrama seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "\phi"]\ar[d, "\ginvt_A"'] \| B\ar[d, "\ginvt_B"]\ \\
A   \ar[r, "\phi"]                    \| B
\endcd
$$

%%}}}

%%{{{ x: cd_for_respects_operation 
\exercise.
%%%{{{ meta 
\label cd_for_respects_operation
%%%}}}

Desenha um diagrama cuja comutatividade é a lei (i).

\solution
$$
\cdopt{sep=2cm}
A\times A   \ar[r, "\phi \times \phi"]\ar[d, "\ast_A"'] \| B\times B \ar[d, "\ast_B"]\ \\
A           \ar[r, "\phi"]                              \| B
\endcd
$$

%%}}}

%%{{{ Different structures for groups 
\note Diferentes estruturas para grupos.
%%%{{{ meta 
%%%}}}

Já viermos como definir ``grupo'' como conjunto estruturado usando três
estruturas diferentes:
$$
\xalignat3
\sset A {\ast_A} &
&\sset A {\ast_A, e_A} &
&\sset A {\ast_A, \ginvt_A, e_A}. &
\endxalignat
$$
Então, dependendo na estrutura que escolhemos para nossa definição
de grupo, precisamos definir ``morfismo'' em forma diferente:
No caso de estrutura $\sset A {\ast_A}$ o morfismo deve satisfazer
o~(i); no caso de $\sset A {\ast_A, e_A}$, os~(i)~e~(iii), e no caso
de $\sset A {\ast_A, \ginvt_A, e_A}$ todos os~(i)--(iii).
\emph{Parece então que chegamos no primeiro ponto onde a estrutura
escolhida na definição de grupo será crucial.}
Felizmente, como nós vamos demonstrar logo após, as leis de grupo
são suficientes para garantir que qualquer funcção $\phi$ que
satisfaz apenas o~(i)~acima, obrigatoriamente satisfaz
os~(ii)~e~(iii) também!
Mesmo assim, vamos botar em nossa definição todos os~(i)--(iii),
pois isso captura melhor a idéia geral de ``homomorfismo''.
E assim que demonstrar nossa afirmação ganhamos um critérion forte
para decidir se alguma funcção é um homomorfismo.

%%}}}

%%{{{ df: group_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label group_homomorphism
\defines
    * \phi : {~A} \homto {~B}  -- $\phi$ é um homomorfismo do $A$ para o $B$
    * \phi : {~{\cal A}} \to {~{\cal B}}  -- $\phi$ é um homomorfismo do $\cal A$ para o $\cal B$
    * homomorfismo!de grupos
    ;;
%%%}}}

Sejam
\mathcols2
\cal A &= \sset A {\ast_A,\ginvtof A,\gidof A}, &
\cal B &= \sset B {\ast_B,\ginvtof B,\gidof B}
\endmathcols
grupos.
A funcção $\phi : A \to B$ é um \dterm{homomorfismo} do
$\cal A$ para o $\cal B$ sse ela respeita a operação,
os inversos, e a identidade:
$$
\alignat2
&\text{para todo $x,y\in A$},\quad & \phi(x \ast_A y)   &= (\phi x) \ast_B (\phi y); \\
&\text{para todo $x\in A$},\quad   & \phi(\ginvtof A x) &= \ginvtof B \funparen{\phi x}; \\
&&\phi e_A       &= e_B.
\endalignat
$$
Às vezes escrevemos $\phi : \cal A \to \cal B$ (em vez de $\phi:A\to B$)
para enfatizar que o $\phi$ nos leva do \emph{grupo} $\cal A$ para o
\emph{grupo} $\cal B$; ou também $\phi : A \homto B$.

%%}}}

%%{{{ note: safe juxtaposition 
\note.
%%%{{{ meta 
%%%}}}

Quando pelo contexto podemos inferir qual é a operação envolvida,
optamos para denotá-la com juxtaposição como produto mesmo.
Por exemplo, escrevemos
$$
\phi(xy) = \phi(x)\phi(y)
$$
sem ambigüidade nenhuma:
o $xy$ que aparece no lado esquerdo,
só pode denotar o $x \ast_A y$, pois $x,y \in A$.
No outro lado, o $(\phi x) (\phi y)$ só pode denotar o $\phi(x) \ast_B \phi(y)$,
pois $\phi(x),\phi(y) \in B$.
A mesma coisa acontece com os inversos:
$\phi(\ginv x)$ só pode denotar ``a imagem do inverso (no $A$) de $x$'',
e $\ginvp{\phi(x)}$ só pode denotar ``o inverso (no $B$) de $\phi(x)$'',
pois, no primeiro caso o $\ginv{}$ é aplicado num membro de $A$,
e no segundo caso num membro de $B$.

%%}}}

%%{{{ criterion: criterion_for_morphism_in_groups
\criterion de homomorfismo.
%%%{{{ meta 
\label criterion_for_morphism_in_groups
%%%}}}

Sejam grupos $\cal A = \sset A {\ast_A,\ginvtof A,\gidof A}$
e $\cal B = \sset B {\ast_B,\ginvtof B,\gidof B}$
e funcção $\phi : A \to B$ que preserva a operação, ou seja,
tal que
$$
\quad\text{para todo $x,y\in A$},\quad
\phi(x \ast_A y) = (\phi x) \ast_B (\phi y).
$$
Então $\phi$ é um homomorfismo.

\sketch.
Precisamos demonstrar o que falta:
$$
\alignat2
&&\phi e_A       &= e_B              \tag{iii}  \\
&\text{para todo $x\in A$},\quad &
\phi(\ginv x)    &= \ginvp{\phi x}.  \tag{ii}
\endalignat
$$
Para o~(iii), calculamos $\phi(e_A) = \phi(e_A) \phi(e_A)$
para concluir que $e_B = \phi(e_A)$;
para o~(ii), mostramos que o $\phi(\ginv x)$ satisfaz a
propriedade característica de ser inverso de $\phi x$:
$$
\phi(\ginv x) \phi(x) \askeq e_B.
$$

%%}}}

%%{{{ df: group_morphisms 
\definition -morfismos.
%%%{{{ meta 
\label group_morphisms
\defines
    * automorfismo!(grupo)
    * endomorfismo!(grupo)
    * epimorfismo!(grupo)
    * epimorfismo!split (grupo)
    * homomorfismo!(grupo)
    * isomorfismo!(grupo)
    * monomorfismo!(grupo)
    * monomorfismo!split (grupo)
    * morfismo!grupo
    ;;
%%%}}}

Sejam grupos $\cal A$ e $\cal B$, e $\phi : \cal A \to \cal B$ um homomorfismo.
Usamos os termos:
$$
\align
\text{$\phi$ monomorfismo}       &\defiff \text{$\phi$ L-cancelável}\\
\text{$\phi$ epimorfismo}        &\defiff \text{$\phi$ R-cancelável}\\
\text{$\phi$ split monomorfismo} &\defiff \text{$\phi$ L-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A}\\
\text{$\phi$ split epimorfismo}  &\defiff \text{$\phi$ R-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi\phi' = \idof B}\\
\text{$\phi$ isomorfismo}        &\defiff \text{$\phi$ é invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A \mland \phi\phi' = \idof B}\\
\text{$\phi$ endomorfismo}       &\defiff \text{$\dom\phi = \cod\phi$}\\
\text{$\phi$ automorfismo}       &\defiff \text{$\phi$ endomorfismo~\&~isomorfismo}
\endalign
$$
onde ``cancelável'' e ``invertível'' significam com respeito a
operação da composição $\fcom$.

%%}}}

%%{{{ x: mono_splitmono_inj_in_Group 
\exercise.
%%%{{{ meta 
\label mono_splitmono_inj_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ mono}
\askiff \text{$\phi$ split mono}
\askiff \text{$\phi$ injectiva}
$$
Como a situação compara com os resultados de funcções entre conjuntos
(veja~\reftag[An_epic_trip])?

%%}}}

%%{{{ x: epi_splitepi_surj_in_Group 
\exercise.
%%%{{{ meta 
\label epi_splitepi_surj_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ epí}
\askiff \text{$\phi$ split epí}
\askiff \text{$\phi$ sobrejectiva}
$$
Como a situação compara com os resultados de funcções entre conjuntos?

%%}}}

%%{{{ x: iso_bim_bij_in_Group 
\exercise.
%%%{{{ meta 
\label iso_bim_bij_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ iso}
\askiff \text{$\phi$ mono} + \text{$\phi$ epí}
\askiff \text{$\phi$ bijectiva}
$$
Como a situação compara com os resultados de funcções entre conjuntos?

%%}}}

%%{{{ sketch_of_morphism_adjectives_in_Group 
\note Rascunho de morfismos de grupos.
%%%{{{ meta 
\label sketch_of_morphism_adjectives_in_Group
%%%}}}

Temos então:
$$
\align
\text{mono} &\iff \text{injecção} \\
\text{epí}  &\iff \text{sobrejecção} \\
\text{iso}  &\iff \text{bijecção}.
\endalign
$$

%%}}}

%%{{{ x: id_is_an_auto 
\exercise.
%%%{{{ meta 
\label id_is_an_auto
%%%}}}

Seja $G$ grupo.  Mostre que a $\id : G \to G$
é um homomorfismo (e logo automorfismo).

\solution
Sejam $x,y\in G$.
Calculamos
$$
\id(xy) = xy = \id(x)\id(y)
$$
e logo $\id$ é um homomorfismo,
e como $\id$ é bijetora e endomapa, $\id$ é um automorfismo.

%%}}}

%%{{{ x: conj_is_an_auto 
\exercise.
%%%{{{ meta 
\label conj_is_an_auto
%%%}}}

Seja $G$ grupo.  Para todo $g\in G$, o $g$-conjugador
(\ref[conjugator]) é um automorfismo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Finalmente podemos definir o que significa que dois grupos são isómorfos!

%%}}}

%%{{{ df: isomorphic_groups 
\definition Grupos isomórficos.
%%%{{{ meta 
\label isomorphic_groups
\defines
    * grupo!isomórficos
    ;;
%%%}}}

Sejam grupos $G$ e $G'$.
Chamamos o $G$ \dterm{isomórfico} (ou \dterm{isómorfo}) ao $G'$ sse
existe isomorfismo $\phi : G \to G'$.
Nesse caso chamamos o $\phi$ \dterm{isomorfismo de grupos}.
Como introduzimos na~\ref[isomorphic_sets]
escrevemos $G \iso G'$ para dizer que <<os $G,G'$ são isómorfos>>,
e também $\phi : G \isoto G'$ ou até $\phi : G \iso G'$ para
<<$\phi$~é um isomorfismo de $G$ para $G'$>>.

%%}}}

%%{{{ x: isomorphic_is_an_equivalence_relation 
\exercise.
%%%{{{ meta 
\label isomorphic_is_an_equivalence_relation
%%%}}}

Mostre que $\isomorphic$ é uma relação de equivalência.

%%}}}

%%{{{ x: additive_ints_and_rats_are_not_isomorphic 
\exercise.
%%%{{{ meta 
\label additive_ints_and_rats_are_not_isomorphic
%%%}}}

Mostre que os $\sset \ints +$ e $\sset \rats +$ não são
isómorfos.

\hint
Procure uma propriedade grupoteórica que um dos dois tem e o outro não.

\solution
Considere a propriedade seguinte:
$$
\text{Para todo $w$, existe $u$ tal que $u+u = w$.}
$$
Ela é uma propriedade grupoteórica, válida no $\sset \rats +$
e inválida no $\sset \ints +$.
Em outras palavras, suponha para chegar num absurdo que temos
um isomorfismo desses grupos $\phi : \ints \to \rats$.
Olhe para o $w \asseq \phi(1)$ (qualquer número ímpar serveria em vez do $1$).
Sendo racional, o $u \asseq \phi(1)/2$ também é racional e temos:
$$
w = u + u.
$$
Qual inteiro é o $\finv\phi$?
Deve ser um inteiro que satisfaz
$$
\finv\phi(u) + \finv\phi(u)
= \finv\phi(u+u)
= \finv\phi(w)
= 1
$$
mas tal inteiro não existe.
Logo, não pode existir nenhum isomorfismo entre os
$\sset \ints +$ e $\sset \rats +$.
\eop
Usando uma outra propriedade grupoteórica para diferenciar
os dois grupos seria observar que um é cíclico, mas o outro não é.

%%}}}

\endsection
%%}}}

%%{{{ Kernel, Image 
\section Kernel, Image.
%%%{{{ meta 
\label Kernel_Image
%%%}}}

%%{{{ df: kernel 
\definition kernel, image.
%%%{{{ meta 
\label kernel
\defines
    * \ima{~\phi}  -- a image do homomorfismo $\phi$
    * \ker{~\phi}  -- o kernel do homomorfismo $\phi$
    * image de homomorfismo
    * kernel de homomorfismo
    ;;
%%%}}}

Sejam $A,B$ grupos e $\phi:A\to B$ um homomorfismo.
Definimos
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{e_B}} &
\quad\big(&= \setst {a \in A} {\phi(a) = e_B} \ \big)\\
\ima\phi
&\defeq \img \phi A &
\quad\big(&= \setst {b \in B} {\lexists {x\in A} {\phi(x) = b}} \ \big)
\endalignat
$$
Chamamos o $\ker \phi$ o \dterm{kernel} do $\phi$
e o $\ima \phi$ o \dterm{image} do $\phi$.

%%}}}

%%{{{ thm: group_homo_mono_iff_ker_singleton 
\theorem.
%%%{{{ meta 
\label group_homo_mono_iff_ker_singleton
%%%}}}

Sejam $A,B$ grupos e $\phi : A \to B$ homomorfismo.
$$
\text{$\phi$ injetora}
\iff
\ker\phi = \set{e_A}.
$$

\sketch.
\proofpart{\lrdir}:
Como $e_A \in \ker\phi$,
basta demonstrar que todos os membros de $\ker\phi$ são iguais:
suponha $x,y\in\ker\phi$ e mostre que $x = y$.
\crproofpart{\rldir}.
Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.
Operando nessa igualdade e usando o fato que $\phi$ é homomorfismo,
chegamos no $x=y$, ou seja, $\phi$ é injetora.

\proof.
\proofpart{\lrdir}:
Como $e_A \in \ker\phi$,
basta demonstrar que todos os membros de $\ker\phi$ são iguais.
Sejam $x,y\in\ker\phi$ então.
Logo $\phi(x) = e_B = \phi(y)$,
e como $\phi$ é injetora, concluimos o desejado $x=y$.
\crproofpart{\rldir}.
\stepproof
\proofsteptnb {Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.}
\proofsteptby {Logo $\phi(x) \ginv{\phi(y)} = e_B$.}          {$(\ast \ginv{\phi(y)})$}
\proofsteptby {Logo $\phi(x) \phi\funparen{\ginv y} = e_B$.}  {$\phi$ homo (inv.)}
\proofsteptby {Logo $\phi(x \ginv y) = e_B$.}                 {$\phi$ homo (op.)}
\proofsteptby {Logo $x\ginv y \in \ker\phi$.}                 {def.~$\ker\phi$}
\proofsteptby {Logo $x\ginv y \in \set{e_A}$.}                {hipótese}
\proofsteptby {Logo $x\ginv y = e_A$.}                        {$\set{e_A}$ singleton}
\proofsteptby {Logo $x = y$.}                                 {$(\ast y)$}
\endstepproof

%%}}}

%%{{{ x: kernel_subgroup 
\exercise.
%%%{{{ meta 
\label kernel_subgroup
%%%}}}

Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Demonstre que $\ker\phi\subgrp A$.

\hint
Primeiramente verifique que $\ker\phi\neq\emptyset$.
Agora, graças ao~\ref[nonempty_subgroup_criterion], precisas demonstrar:
(i)~$\ker\phi$ é~$\ast$-fechado;
(ii)~$\ker\phi$ é~$\ginv{}$-fechado.

\hint
Para o (i), tome $x,y\in\ker\phi$ e mostre que $xy\in\ker\phi$,
ou seja, que $\phi(xy) = e_B$.

\hint
Para o (ii), tome $x\in\ker\phi$ e mostre que $\ginv x\in\ker\phi$,
ou seja, que $\phi\funparen{\ginv x} = e_B$.

\solution
Primeiramente observamos que $\ker\phi\neq\emptyset$:
$e_A \in \ker\phi$, pois $\phi$ é um homomorfismo
e logo leva a $e_A$ para a $e_B$.
Então graças ao~\ref[nonempty_subgroup_criterion], basta demonstrar:
\crproofpart{$\ker\phi$ é fechado pela operação:}
Sejam $x,y\in\ker\phi$.
Precisamos mostrar que $xy\in\ker\phi$, ou seja, que $\phi(xy) = e_B$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)} \\
&= e_B e_B          \by {$x,y\in\ker\phi$} \\
&= e_B.             \by {def.~$e_B$} \\
\endcompute
\proofpart{$\ker\phi$ é fechado pelos inversos:}
Seja $x\in\ker\phi$.
Precisamos mostrar que $\ginv x\in\ker\phi$, ou seja, que $\phi\funparen{\ginv x} = e_B$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi(x)}  \by {$\phi$ homo (inv.)} \\
&= \ginv{e_B}       \by {$x\in\ker\phi$} \\
&= e_B.             \by {inverso da identidade~(\ref[inverse_of_identity_in_group])} \\
\endcompute

%%}}}

%%{{{ x: kernel_is_normal 
\exercise.
%%%{{{ meta 
\label kernel_is_normal
%%%}}}

Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Demonstre que $\ker\phi\normal A$.

\hint
Acabamos de demonstrar que $\ker\phi\subgrp \cal A$ no~\ref[kernel_subgroup].
Basta demonstrar que $\ker\phi$ é fechado pelos conjugados.
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos demonstrar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Ou seja, basta verificar que realmente $\phi(ak\ginv a) = e_B$.

\solution
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos demonstrar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo} \\
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$n\in\ker\phi$} \\
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$} \\
&= \phi(a) \ginvp{\phi(a)}                  \by {$\phi$ homo} \\
&= e_B                                      \by {def.~$\ginvp{\phi(a)}$} \\
\endcompute
Logo $ak\ginv a\in\ker\phi$ como queremos demonstrar.

%%}}}

%%{{{ x: kernel_is_normal_altproof 
\exercise.
%%%{{{ meta 
\label kernel_is_normal_altproof
%%%}}}

Veja a prova completa do~\ref[kernel_is_normal].
No seu cálculo, mostre como continuar num caminho diferente depois da terceira
igualdade para chegar no mesmo resultado desejado: $e_B$.

\hint
Aplicamos a propriedade que homomorfismos preservam os inversos.
Aplique outra propriedade de homomorfismos.

\solution
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo (oper.)} \\
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$k\in\ker\phi$} \\
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$} \\
&= \phi(a \ginv a)                          \by {$\phi$ homo (oper.)} \\
&= \phi(e_A)                                \by {def.~$\ginv a$} \\
&= e_B                                      \by {$\phi$ homo (iden.)} \\
\endcompute

%%}}}

%%{{{ x: image_subgroup 
\exercise.
%%%{{{ meta 
\label image_subgroup
%%%}}}

Sejam $A$ e $B$ grupos e $\phi$ um homomorfismo de $A$ para $B$.
Demonstre que $\ima\phi\subgrp B$.

\hint
Precisas mostrar que $\ima\phi$ é fechado pela operação e pelos conjuntos.

\hint
\proofpart{$\ima\phi$ fechado pela operação:}
Tome $x', y' \in \ima\phi$ e ache um $w\in A$ tal que que $\phi(w) = x'y'$.
\crproofpart{$\ima\phi$ fechado pelos conjuntos:}
Tome $x' \in \ima\phi$ e ache um $x\in A$ tal que $\phi(x) = \ginvp{x'}$.

\solution
\proofpart{$\ima\phi$ fechado pela operação:}
Sejam $x', y' \in \ima\phi$.
Logo, sejam $x,y\in A$ tais que $\phi x = x'$, e $\phi y = y'$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)} \\
&= x' y'.           \by {pela escolha dos $x,y$} \\
\endcompute
Ou seja, $x'y' \in \ima\phi$.
\crproofpart{$\ima\phi$ fechado pelos conjuntos:}
Seja $x' \in \ima\phi$.
Logo, seja $x\in A$ tal que $\phi x = x'$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi x}   \by {$\phi$ homo (inv.)} \\
&= \ginvp{x'}.      \by {pela escolha do $x$} \\
\endcompute
Ou seja, $x'\in\ima\phi$.

%%}}}

%%{{{ thm: first_isomorphism_theorem_groups 
\theorem Primeiro teorema de isomorfismo.
%%%{{{ meta 
\label first_isomorphism_theorem_groups
\indexes
    * isomorfismo    seealso: teorema de isomorfismo
    * grupo!teorema de isomorfismo    see: teorema de isomorfismo
    * teorema de isomorfismo!primeiro (de grupos)
    ;;
%%%}}}

Sejam $G$ e $G'$ grupos
e $\phi : G \to G'$ homomorfismo.
\tlist:
\li (i):   $\ker\phi\normal G$;
\li (ii):  $\ima\phi\subgrp G'$;
\li (iii): $\quogrp G {\ker\phi} \iso \ima\phi$.
\endtlist

\sketch.
Acabamos de demonstrar as (i)~\&~(ii) nos~\reftag[kernel_is_normal]~\&~\reftag[image_subgroup].
Para a (iii) precisamos definir uma funcção
$$
\Phi : \quogrp G {\ker\phi} \to \ima\phi
$$
tal que $\Phi$ é um isomorfismo.
Seja $K \asseq \ker\phi$.
Queremos definir a $\Phi$ pela
$$
\Phi(Kx) = \phi(x)
$$
para qualquer coclasse $Kx$ do $K$ (essas são as suas entradas).
\eop
O problema é que $\Phi$ não parece \emph{bem-definida}, pois seu valor
pode depender na escolha do representante $x$ da coclasse---veja
o~\ref[not_well_defined_function_danger_firstiso] caso que o problema
com essa definição não é claro.
Precisamos melhorar essa definição e demonstrar que:
(a) realmente defina uma \emph{funcção} $\Phi$;
(b) $\Phi$ é bijetora;
(c) $\Phi$ é um homomorfismo (e logo isomorfismo).

%%}}}

%%{{{ beware: not_well_defined_function_danger_firstiso 
\beware.
%%%{{{ meta 
\label not_well_defined_function_danger_firstiso
\indexes
    * funcção!bem-definida
    ;;
%%%}}}

Caso que o perigo descrito no esboço acima não é óbvio,
primeiramente volte re-estudar os
\ref[not_well_defined_function_danger_quogrp],
\ref[not_well_defined_function_danger_argument_name_dependence],
e~%
\ref[not_well_defined_function_danger_choice_dependence].
\eop
Agora vamos pensar como um programador querendo definir essa
funcção $\Phi$.
Sua funcção, quando chamada, recebe uma coclasse, ou seja,
um conjunto com certos elementos membros.
Ela não sabe qual foi o nome que o chamador escolheu para essa coclasse
(\ref[not_well_defined_function_danger_argument_name_dependence]).
Até pior, e para corresponder ainda melhor com nosso caso, observe
que o $Kx$ é na verdade uma operação entre um subgrupo $K$ e um membro
$x$ que resulta num subconjunto de $G$.
Mas a $\Phi$ \emph{não tem acesso nesse $x$}
(\ref[not_well_defined_function_danger_choice_dependence]).
\eop
Mesmo se defini-la pela
$$
\Phi(C) = \phi(c),\quad
\text{onde $c$ é algum membro de $C$}
$$
temos uma tarefa para fazer:
\emph{precisamos demonstrar que seu valor $\Phi(C)$ não depende da escolha de $c$}.
Até conseguir demonstrar isso, não podemos considerar a $\Phi$ uma funcção
\emph{bem-definida}.
Veja bem a prova do~\ref[first_isomorphism_theorem_groups].

%%}}}

%%{{{ kernel <==> normal 
\note Dois lados da mesma moeda.
%%%{{{ meta 
%%%}}}

Já provamos algo (\ref[kernel_is_normal]) que,
informalmente falando, podemos escrever assim:
$$
\text{kernel} \implies \text{normal}.
$$
E o converso?
Será que também é verdade?
O que exatamente é esse converso?
Como formalizar?  Podemos demonstrar?
\eop
Realmente o converso da implicação-informal também é válido:
$$
\text{normal} \implies \text{kernel}.
$$
Temos então o slogan
$$
\text{normal} \iff \text{kernel}.
$$
Ou seja, em teoria dos grupos os conceitos de ``kernel''
e de ``subgrupo normal'' são apenas dois lados da mesma moeda.
Deixo os \emph{detalhes importantes} pra ti,
no~\ref[normal_is_kernel]---não pule!

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_groups 
\section Pouco de cats---categorias e grupos.
%%%{{{ meta 
\label Categories_and_groups
%%%}}}

%%{{{ intro 
\secintro
Temos uns objetos que nos interessam: os grupos.
Temos umas setas interessantes entre esses objetos: os morfimos.
Será que temos uma categoria (\ref[category_first_def])?
%%}}}

%%{{{ df: GROUP 
\definition.
%%%{{{ meta 
\label GROUP
\defines
    * \GROUP  -- a categoria dos grupos e seus homomorfismos
    ;;
%%%}}}

Denotamos por $\GROUP$ a categoria dos grupos:
\tlist:
\li: $\Obj \GROUP$: todos os grupos;
\li: $\Arr \GROUP$: todos os homomorsfismos de grupos;
\endtlist
onde obviamente os $\src\phi$ e $\tgt\phi$ denotam os $\dom\phi$ e $\cod\phi$ respectivamente.

%%}}}

%%{{{ x: GROUP_is_a_cat 
\exercise.
%%%{{{ meta 
\label GROUP_is_a_cat
%%%}}}

Demonstre que $\GROUP$ realmente é uma categoria.

%%}}}

%%{{{ eg: products_of_Group 
\example.
%%%{{{ meta 
\label products_of_Group
%%%}}}

A categoria $\GROUP$ possui produtos?  (\ref[product_in_category].)

\solution.
Sim.
Dados dois objetos $G,H$ o
$\tupp{\outl, G \cross H, \outr}$ (\reftag[direct_product_of_groups]) é um produto
dos $G,H$.
Primeiramente precisamos demonstrar que $G \cross H$ realmente é um objeto
da $\GROUP$, ou seja, um grupo;
tu demonstraste isso no~\ref[direct_product_of_groups_is_a_group].
Agora falta verificar que dados $\tupp{f_1, F, f_2}$,\foot
Sim, isso é uma frase completa, com seu verbo e tudo mais:
\wq{\dots dados $\tupp{f_1,F,f_2}$,
existe única seta $! : F \to G \cross H$
que faz o diagrama seguinte comutar: \dots}
Mais uma vez que percebemos a veracidade do ditado
$$
\text{1 diagrama comutativo} = \text{1{,}000 palavras}.
$$
\toof
$$
\cdopt{sep=1cm}
                                 \| \|                                  \| G \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"'] \| \| G \cross H
                                       \ar[ur, bend left=15, "\outl"]
                                       \ar[dr, bend right=15, "\outr"'] \| \\
                                 \| \|                                  \| H
\endcd
$$
Defina a $!$ pela
$$
! = \fpair {f_1} {f_2}.
$$
Isso realmente é o único que faz o diagrama comutar---tu
já verificaste isso no~\ref[product_is_a_product],
certo?---então só basta demonstrar uma coisa pra terminar.

%%}}}

%%{{{ x: what more is needed to prove? 
\exercise.
%%%{{{ meta 
%%%}}}

Qual?
Enuncie e demonstre!

\hint
Basta demonstrar que $! : F \to G \cross H$ é um homomorfismo mesmo.
Demonstre!

%%}}}

%%{{{ x: initial_and_terminal_of_Group 
\exercise.
%%%{{{ meta 
\label initial_and_terminal_of_Group
%%%}}}

A categoria $\GROUP$ possui objetos iniciais?  Terminais?  Quais?
(\ref[initial_terminal_null_objects].)
E, esqueci: a $\SET$ tem?

%%}}}

%%{{{ df: ABEL 
\definition.
%%%{{{ meta 
\label ABEL
\defines
    * \ABEL  -- a categoria dos grupos abelianos e seus homomorfismos
    ;;
%%%}}}

Denotamos por $\ABEL$ a categoria dos grupos abelianos:
\tlist:
\li: $\Obj \ABEL$: todos os grupos abelianos;
\li: $\Arr \ABEL$: todos os homomorsfismos de grupos abelianos;
\endtlist
onde novamente os $\src\phi$ e $\tgt\phi$ são as coisas óbvias.

%%}}}

%%{{{ x: ABEL_is_a_cat 
\exercise.
%%%{{{ meta 
\label ABEL_is_a_cat
%%%}}}

Verifique que $\ABEL$ realmente é uma categoria.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

É fácil verificar que a $\ABEL$ também possui produtos:
essencialmente o mesmo argumento da $\GROUP$ passa aqui também.
Mas a situação é bastante diferente olhando para os \emph{coprodutos}
(\ref[coproduct_in_category]).

%%}}}

%%{{{ products_and_coproducts_in_Group_complicated
\note Coprodutos de grupos.
%%%{{{ meta 
\label products_and_coproducts_in_Group_complicated
%%%}}}

Os coprodutos na~$\GROUP$\dots~meio complicado.
Vamos voltar nesse assunto no~\ref[Category_theory];
mas por enquanto observe que o conjunto $G \disjunion H$
que usamos para o coproduto $G \coprod H$ na $\SET$ não
possui uma estrutura de grupo óbvia para servir como coproduto
dos $G,H$.  Qual seria sua identidade, por exemplo, e, antes
de chegar em conseguir perguntar isso, qual seria sua operação?
No outro lado é fácil demonstrar que $\ABEL$ possui
coprodutos---e tu nem imagina quais são!

%%}}}

%%{{{ x: coproducts_in_Abel 
\exercise.
%%%{{{ meta 
\label coproducts_in_Abel
%%%}}}

Dados objetos (grupos abelianos) $G,H$, ache um coproduto deles.
Tu ficarás surpreso.

\hint
Que tipo de coisa é o coproduto literalmente?

\hint
Na $\ABEL$, o $G\cross H$ serve como objeto tanto de produto,
quanto de coproduto!
Demonstre!

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: conjugates_look_alike 
\problem.
%%%{{{ meta 
\label conjugates_look_alike
%%%}}}

Pode achar alguma propriedade grupoteórica tal que num grupo $G$,
dentro duma das suas classes de conjugação vai ter membros que
satisfazem e membros que não?

%%}}}

%%{{{ prob: hom_abel_with_pointwise_plus 
\problem.
%%%{{{ meta 
\label hom_abel_with_pointwise_plus
%%%}}}

Sejam $G,G'$ grupos abelianos.
Demonstre que
$$
\Hom(G,G') \defeq \setstt {\phi : G \to G'} {$\phi$ homomorfismo}
$$
é um grupo abeliano com operação a $+$ definida pointwise (\ref[pointwise_operation]):
$$
(\phi + \psi)(x) = \phi(x) + \psi(x).
$$
com operação a $+$ pointwise é um grupo abeliano.
Precisas realmente saber que ambos os $G,G'$ são abelianos?

\solution
Primeiramente precisamos demonstrar que $\Hom(G,G')$ é $+$-fechado.
Então sejam $\phi,\psi\in\Hom(G,G')$ e $x,y \in G$.
Calculamos:
\compute
(\phi + \psi)(x + y)
&= \phi(x + y) + \psi(x + y)                \by {pointwise~$+$} \\
&= \phi(x) + \phi(y) + \psi(x) + \psi(y)    \by {$\phi,\psi$ homo} \\
&= \phi(x) + \psi(x) + \phi(y) + \psi(y)    \by {$G'$ abeliano} \\
&= (\phi + \psi)(x) + (\phi+\psi)(y).       \by {def.~$\phi+\psi$} \\
\endcompute
Agora basta só confirmar que realmente é abeliano.
Fácil:
$$
(\phi + \psi)(x)
= \phi(x) + \psi(x)
= \psi(x) + \phi(x)
= (\psi + \phi)(x).
$$
Observe que precisamos a comutatividade apenas no $G'$,
ou seja, $\sset {\Hom(G,G')} +$ é abeliano se $G'$ é.

%%}}}

%%{{{ prob: aut_G_is_a_group 
\problem.
%%%{{{ meta 
\label aut_G_is_a_group
\defines
    * \Aut({~G})  -- o grupo de automorfismos no $G$
    ;;
%%%}}}

Mostre que dado um grupo $G$, o conjunto de todos os seus automorfismos
$$
\Aut G
\defeq
\set{
\phi : G\bijto G
\st
\text{$\phi$ é um automorfismo}
}
$$
com operação $\compose$ é um grupo.

%%}}}

%%{{{ prob: bij_G_subgrp_aut_G 
\problem.
%%%{{{ meta 
\label aut_G_subgrp_bij_G
%%%}}}

Sabendo que $\namedop{Bij} G \defeq \sset {(G \bijto G)} {\compose}$ é um grupo,
mostre que
$$
\Aut G \subgroup \namedop{Bij} G.
$$

\hint
Se $F$ é injetora, então: $x=y \impliedby F(x) = F(y)$.

\solution
Como $\Aut G \subset \namedop{Bij} G$ precisamos verificar
apenas que $\Aut G$ é:
\crproofpart{Não vazio:}
$\id : G \to G$ é um automorfismo (\ref[id_is_an_auto])
e logo $\Aut G\neq\emptyset$.
\crproofpart{Fechado pela operação:}
Tome $\phi,\psi\in\Aut G$, e $x,y\in G$.  Calculamos:
\compute
(\phi\compose\psi)(x\cdot y)
&=\phi\paren{\psi(x\cdot y)}                                     \by {def.~$\compose$} \\
&=\phi\paren{\psi(x) \cdot \psi(y)}                              \by {$\psi$ homo} \\
&=\phi\paren{\psi(x)} \cdot \phi\paren{\psi(y)}                  \by {$\phi$ homo} \\
&=\paren{\phi\compose\psi}(x) \cdot \paren{\phi\compose\psi}(y). \by {def.~$\compose$} \\
\endcompute
\proofpart{Fechado pelos inversos:}
Tome $\phi\in\Aut G$.
Precisamos verificar que a bijecção $\finv\phi$
é realmente um homomorfismo.
Ou seja, precisamos mostrar que
$$
\phi^{-1}(x\cdot y) = \phi^{-1}(x)\cdot \phi^{-1}(y)
$$
para todos os $x,y\in G$.
Seguindo a dica, basta demonstrar que
$$
\phi\paren{\phi^{-1}(x\cdot y)} = \phi\paren{\phi^{-1}(x)\cdot \phi^{-1}(y)}
$$
O lado esquerdo é igual ao $x\cdot y$.
Calculamos o lado direito:
\compute
\phi\paren{\phi^{-1}(x) \cdot \phi^{-1}(y)}
&=\phi\paren{\phi^{-1}(x)} \cdot \phi\paren{\phi^{-1}(y)}   \by {$\phi$ homo} \\
&=x\cdot y.  \by {def.~$\phi^{-1}$} \\
\endcompute

%%}}}

%%{{{ df: inner_auto 
\definition Inner autos.
%%%{{{ meta 
\label inner_auto
\indexes
    * inner automorfismo    see: automorfismo
    ;;
\defines
    * \Inn({~G})  -- os inner automorfismos de $G$
    * automorfismo!inner
    ;;
%%%}}}

Seja $G$ grupo.
Definimos o conjunto dos seus \dterm{inner automorfismos}
$$
\Inn(G) \defeq \setst {\gconj g} {g \in G}
$$
onde $\gconj g$ é o $g$-conjugador (\ref[conjugator]).

%%}}}

%%{{{ prob: inn_normal_aut 
\problem.
%%%{{{ meta 
\label inn_normal_aut
%%%}}}

$\Inn G \normal \Aut G$.

\hint
Enxergue bem todos os seus alvos:
(i) $\Inn G \subset \Aut G$;
(ii) $\Inn G \subgroup \Aut G$;
(iii) $\Inn G \normal \Aut G$.
O que precisas demonstrar para matar cada um deles?

\solution
Precisamos demonstrar:
$\Inn G \subset \Aut G$;
$\Inn G \subgroup \Aut G$;
$\Inn G \normal \Aut G$.
\crtabproofpart{$\Inn G \subset \Aut G$}.
Seja $f \in \Inn G$.
Logo seja $g \in G$ tal que $f = \actorS g {\ginv g}$.
Precisamos mostrar que $f$ é um automorfismo.
Já demonstramos que é bijetora (\ref[group_actors_are_bijective])
então basta demonstrar que é um homomorfismo.
Pelo~\ref[criterion_for_morphism_in_groups], é suficiente
mostrar que $f$ respeita a operação.
Calculamos:
$$
\align
f(x)f(y)
&= \paren{\actorS g {\ginv g} x}
   \paren{\actorS g {\ginv g} y} \\
&= \paren{gx\ginv g}
   \paren{gy\ginv g} \\
&= gx\ginv g g y \ginv g \\
&= gxey \ginv g \\
&= g(xy) \ginv g \\
&= f(xy).
\endalign
$$
\crtabproofpart{$\Inn G \subgroup \Aut G$}.
Vamos usar o~\ref[nonempty_subgroup_criterion].
Primeiramente mostramos que $\Inn G \neq \emptyset$:
de fato, $\idof G \in \Inn G$, pois $\idof G$ é um inner:
$$
\idof G = \actorS e {\ginv e}.
$$
\crproofpart{$\Inn G$ $\fcom$-fechado}.
Agora sejam $f_1,f_2 \in \Inn G$.
Vou demonstrar que
$f_1\fcom f_2$ é um inner.
Como $f_1,f_2$ são inners, sejam $g_1,g_2$ tais que
$$
\xalignat2
f_1 & = \actorS {g_1} {\ginv {g_1}} &
f_2 & = \actorS {g_2} {\ginv {g_2}}.
\endxalignat
$$
Para um arbitrário $x \in G$ temos:
$$
\align
(f_1 \fcom f_2) x
&= f_1 ( f_2 x ) \\
&= f_1 ( g_2 x \ginv {g_2} ) \\
&= g_1 ( g_2 x \ginv {g_2} ) \ginv {g_1} \\
&= (g_1 g_2) x \paren{\ginv {g_2} \ginv {g_1}} \\
&= (g_1 g_2) x \ginvp{g_1 g_2}.
\endalign
$$
Ou seja, $f_1\fcom f_2\in\Inn G$.
\crproofpart{$\Inn G$ $\ginv{}$-fechado}.
Seja $f \in \Inn G$, e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Observe que $\actorS {\ginv g} g$ é a inversa da $f$,
e que realmente é um inner, pois
$$
\actorS {\ginv g} g = \actorS {\ginv g} {\ginvp {\ginv g}},
$$
ou seja, $\ginv f \in \Inn G$.
\crtabproofpart{$\Inn G$ fechado pelos conjugados}.
Seja $f \in \Inn G$ e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Vou mostrar que todos os conjugados de $f$ são inners.
Seja então $\alpha \in \Aut G$.
Basta demonstrar que $\alpha f \ginv{\alpha} \in \Inn G$.
Ou seja, basta resolver o
$$
\alpha f \ginv{\alpha} = \actorS {\askbox} {\ginv{\askbox}}.
$$
Para um arbitrário $x \in G$ temos:
\compute
\paren{\alpha \fcom f \fcom \ginv{\alpha}} x
&= \alpha \funparen{ f \funparen { \finv{\alpha} x } }                               \by {def.~$\fcom$} \\
&= \alpha \funparen{ g \ast \paren { \finv \alpha x } \ast \ginv g }                 \by {pela escolha de $g$} \\
&= \alpha g \ast \alpha \funparen { \finv \alpha x } \ast \alpha \funparen {\ginv g} \by {$\alpha$ homo: resp.~op.} \\
&= \alpha g \ast \paren{\alpha \fcom \finv \alpha} x \ast \alpha \funparen {\ginv g} \by {def.~$\fcom$} \\
&= \alpha g \ast x \ast \alpha \funparen {\ginv g}                                   \by {def.~$\finv \alpha$} \\
&= \alpha g \ast x \ast \ginvp {\alpha g}                                            \by {$\alpha$ homo: resp.~inv.} \\
\endcompute
e logo $\alpha f \ginv{\alpha} \in \Inn G$.

%%}}}

%%{{{ prob: normal_is_not_an_order 
\problem.
%%%{{{ meta 
\label normal_is_not_an_order
%%%}}}

A relação $\normal$ é uma ordem?

\hint
Não é!
Ela não é transitiva.
Demonstre!

\hint
Basta achar contraexemplo: grupo $G$ e subgrupos $A,B \subgrp G$
tais que $A \normal B \normal G$ mas $A \nnormal G$.

\hint
Procure teu contraexemplo no $G \asseq \sym 4$ e seus subgrupos
(considere o $A \asseq \gen{\permc{1 & 2}\permc{3 & 4}}$.
Alternativamente, procure no $\dih 4$ e seus subgrupos;
talvez olhando para o diagrama Hasse do $\dih 4$ ajuda.

%%}}}

%%{{{ prob: normal_is_kernel 
\problem kernel = normal.
%%%{{{ meta 
\label normal_is_kernel
%%%}}}

Já provamos algo que informalmente falando podemos escrever assim:
$$
\text{kernel} \implies \text{normal}
$$
Formalize e demonstre o converso.

\hint
Formalização:
{\proclaimstyle
Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}

\hint
O $G'$ é o $\quogrp G N$.

\solution
Formalização:
{\proclaimstyle Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}
\crproofpart{\proofname.}
Considere o grupo $\quogrp G N$ e
defina a $\phi : G \to \quogrp G N$
pela
$$
\phi(x) = Nx.
$$
Basta demonstrar que:
\tlist:
\li (i):  $\phi$ é um homomorfismo;
\li (ii): $\ker\phi = N$.
\endtlist
(i) Basta verificar que $\phi$ respeita a operação.
Sejam $x,y \in G$.
Calculamos
$$
\phi (xy) = N(xy) = (Nx)(Ny) = \phi(x) \phi(y).
$$
(ii) Temos
\compute
x\in \ker\phi
&\iff \phi(x) = e_{\quogrp G N} \by {def.~$\ker\phi$} \\
&\iff \phi(x) = N    \by {$N$ é a identidade do $\quogrp G N$} \\
&\iff Nx = N         \by {def.~$\phi$} \\
&\iff x \in N.       \by {\ref[Ha_eq_H_iff_a_in_H]} \\
\endcompute
Ou seja, $\ker\phi = N$.
\eop
Com isso concluimos que na teoria dos grupos,
``subgrupo normal'' e ``kernel'' são dois lados da mesma moeda.

%%}}}

%%{{{ prob: cayley_theorem 
\problem Teorema de Cayley.
%%%{{{ meta 
\label cayley_theorem
%%%}}}

\TODO Outline Cayley's theorem.

%%}}}

%%{{{ prob: cauchy_theorem 
\problem Teorema de Cauchy.
%%%{{{ meta 
\label cauchy_theorem_groups
%%%}}}

\TODO Outline Cauchy's theorem.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Para practicar com propriedades de operações vale a pena
resolver os primeiros 15 problemas do~\cite[halmoslapb].

Livros introdutórios de álgebra abstrata tratam em geral
a teoria dos grupos mais profundamente ou extensamente do que
podemos tratá-la aqui.
\cite[pinteralgebra] é um desses livros, bastante acessível,
com exemplos de diversas áreas, mostrando várias aplicações.
Uma \emph{excelente} introdução em vários tópicos de álgebra é
o~\cite[hersteintopics], famoso para sua exposição e didáctica.

O assunto da álgebra abstrata foi composto e tratado numa maneira organizada
no \emph{Moderne Algebra}
de van~der~Waerden{\vanderWaerden}
(dois volúmes: \yearof{1930}, \yearof{1931};
modernas edições traduzidas: \cite[vanderWaerden1], \cite[vanderWaerden2]).
Ele foi baseado principalmente em aulas dadas por Artin{\Artin} e Noether{\Noether}.
e é um dos livros mais influenciadores e importantes em matemática.

Birkhoff{\Birkhoff} e Mac~Lane{\MacLane} trazeram o assunto para os currículos
de graduação com o clássico~\cite[babybm].
Os mesmos autores, no~\cite[papamb], apresentam álgebra mais profundamente e
com um cheiro categórico (veja~\ref[Category_theory]),
algo expectado já que Mac~Lane é um dos fundadores da teoria das categorias
(o outro é o Eilenberg{\Eilenberg}).

Infelizmente, muitos livros (e professores) consideram a teoria das categorias
como algo avançado ou difícil para ser introduzido neste nível
(e geralmente o primeiro contato com categorias chega bem depois
dos primeiros contatos com álgebra abstrata).
Felizmente, o bem-legível \cite[aluffialgebra] é uma excessão brilhante dessa
tradição: começa já introduzindo a linguagem
e as idéias das categorias e trata assim todos os assuntos principais
de álgebra abstrata.
(Essa seria minha maior recomendação para o meu leitor que ficou
animado com o conteudo deste capítulo e do próximo.)

Depois de se acostumar com as idéias algébricas em geral,
dois livros focados especialmente em teoria dos grupos
são os~\cite[rosegroups] e~\cite[rotmangroups].

O convex hull que encontramos \emph{en passant} neste capítulo
gera um problema algorítmico muito interessante:
\emph{dado um conjunto $A$ de pontos dum espaço euclideano
calcule um óptimo $C \subset A$ tal que seus pontos
são as vértices do convex hull do $A$}.
Para mais sobre isso, veja por exemplo o~\cite[clrs: \S33.3].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Algebraic_structures 
\chapter Estruturas algébricas.
%%%{{{ meta 
\label Algebraic_structures
%%%}}}

%%{{{ Monoids 
\section Monóides.
%%%{{{ meta 
\label Monoids
%%%}}}

%%{{{ df: monoid 
\definition Monóide.
%%%{{{ meta 
\label monoid
\defines
    * monóide
    ;;
%%%}}}

Um conjunto estruturado $\cal M = \sset M {\cdot,\epsilon}$
é um \dterm{monóide} sse:
$$
\alignat2
\pforall {a,b\in M}    &\quantified{a\cdot b \in G}                       &\tag{G0}\\
\pforall {a,b,c\in M}  &\quantified{a\cdot(b\cdot c) = (a\cdot b)\cdot c} &\tag{G1}\\
\pforall {a\in M}      &\quantified{\epsilon\cdot a = a = a\cdot\epsilon} &\tag{G2}
\endalignat
$$
Naturalmente, se a $\cdot$ é comutativa chamamos $M$ de \dterm{monóide comutativo}.

%%}}}

%%{{{ eg: any group is a monoid 
\example.
%%%{{{ meta 
%%%}}}

A partir de qualquer exemplo de grupo
$\cal G = \sset G {\ast_G, \ginv{}, \gidof G}$
temos um exemplo de monóide também:
o~$\sset G {\ast_G, \gidof G}$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mais interessantes agora seriam exemplos de monóides
que não são grupos:

%%}}}

%%{{{ eg: nats with addition 
\example.
%%%{{{ meta 
%%%}}}

Os naturais com adição formam um monóide.

%%}}}

%%{{{ eg: positive nats with multiplication 
\example.
%%%{{{ meta 
%%%}}}

O $\sset {\nats_{\neq0}} {\ntimes}$ é um monóide.

%%}}}

%%{{{ eg: strings 
\example Strings.
%%%{{{ meta 
%%%}}}

Considere um alfabeto finito $\Sigma$ e seja $\kstar\Sigma$
o conjunto de todos os strings formados por letras do $\Sigma$.
O $\kstar \Sigma$ com a operação a concatenação de strings,
é um monóide.  Sua identidade é o string vazio.

%%}}}

%%{{{ Q: How would you define the submonoid relation? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias a relação de submonóide?

%%}}}

\spoiler

%%{{{ df: submonoid 
\definition submonóide.
%%%{{{ meta 
\label submonoid
\defines
    * submonóide
    ;;
%%%}}}

Seja $\cal M = \sset M {\cdot_M,\epsilon_M}$ monóide
e $H \subset M$.
O $H$ é um submonóide de $M$ sse $\epsilon_M \in H$
e $H$ é $\cdot_M$-fechado.

%%}}}

%%{{{ remark: same abuses as always 
\remark abusamos como sempre.
%%%{{{ meta 
%%%}}}

Literalmente não é o conjunto $H$ que é submonóide,
mas o conjunto estruturado
$$
\cal H \asseq \text{$\sset H {{{\cdot_M} \restosub {N \times N}}, \epsilon_M}$}.
$$
Eu presumo que tu és acostumado com esses abusos depois que
os discutimos nos itens~\reftag[notational_abuse_structured_sets]
e~\reftag[notational_abuse_groups].

%%}}}

%%{{{ Q: How would you define homomorphism between monoids? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias o homomorfismo entre monóides?

%%}}}

\spoiler

%%{{{ df: monoid_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label monoid_homomorphism
\defines
    * homomorfismo!de monóide
    ;;
%%%}}}

Sejam $\cal M = \sset M {\cdot_M,\epsilon_M}$
e $\cal N = \sset N {\cdot_N,\epsilon_N}$ monóides.
Uma funcção $\phi : M \to N$ é um \dterm{homomorfismo} sse:
% TODO: fix reflabs
\elist i:
\li: para todo $x,y\in M$,\quad $\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)$.
\li: $\phi(\epsilon_M) = \epsilon_N$;
\endelist

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Considere os monóides $\cal N = \sset \nats {0, +}$ e
$\cal B = \sset B {\concat,\epsilon}$, onde:
$B$ é o conjunto de todos os strings (finitos) binários,
ou seja, $B=\kstar{\set{\digit 0,\digit 1}}$;
$\epsilon$ é o string vazio ``$\,$'';
$\concat$ a concatenação.
A $\phi : \cal N \to \cal B$ definida recursivamente pelas
$$
\align
\phi(0)     &= \epsilon\\
\phi(n+1)   &= \phi(n) \concat \digit0
\endalign
$$
é um homomorfismo.
A $\namedfun{length} : \cal B \to \cal N$ que retorna o tamanho da sua entrada é um homomorfismo.

%%}}}

%%{{{ noneg 
\nonexample.
%%%{{{ meta 
%%%}}}

Com o contexto do exemplo anterior, a $\psi : \cal N \to \cal B$
definida recursivamente pelas:
$$
\align
\psi(0)     &= \epsilon\\
\psi(n+1)   &=
\knuthcases {
\psi(n) \concat \digit0, & se $\psi(n)$ não termina com $\digit0$\cr
\psi(n) \concat \digit1, & caso contrário
}
\endalign
$$
não é um homomorfismo.

%%}}}

%%{{{ x: why? 
\exercise.
%%%{{{ meta 
%%%}}}

Por quê?

\solution
Temos:
$$
\psi(1+1)
= \digit0\digit1
\neq \digit0\digit0
= \psi(1)\concat\psi(1).
$$

%%}}}

%%{{{ beware: not everything comes for free 
\beware.
%%%{{{ meta 
%%%}}}

No~\ref[Group_theory] assim que definimos o que significa homomorfismo
de grupos~(\reftag[group_homomorphism]) demonstramos
o~\ref[criterion_for_morphism_in_groups] que nos permite concluir
que uma funcção entre grupos é homomorfismo assim que
souber que ela respeita a operação.
Isso quer dizer que temos esse critério nos monóides também?
Primeiramente olhamos para a demonstração
do~\ref[criterion_for_morphism_in_groups] para ver se
ela ``passa'' nos monóides também:
se ela usou apenas os (G0)--(G2), então passa.
Não é o caso: \emph{essa} demonstração necessitou o (G3)
pois usou os inversos.
Então isso quer dizer que perdemos esse critério nos monóides?
\emph{Não!}
O que perdemos foi a demonstração; mas talvez existe
outra que segura o mesmo teorema, e que não necessita os inversos.
Será?

%%}}}

%%{{{ x: in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity 
\exercise.
%%%{{{ meta 
\label in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity
%%%}}}

Podemos demonstrar um critérion parecido com
o~\ref[criterion_for_morphism_in_groups] para os monóides?
Ou seja, se $\phi$ preserva a operação do monóide,
ela necessariamente preserva a identidade também?

\hint
Não!
Mas como podemos demonstrar que não tem como demonstrar isso?

\hint
Procure um contraexemplo:
monóides $\cal M, \cal N$ e funcção $\phi : M \to N$ tais que
$\phi$ preserva a operação do monóide mas não a identidade.

%%}}}

%%{{{ criterion: monoid_morphism_criterion 
\criterion.
%%%{{{ meta 
\label monoid_morphism_criterion
%%%}}}

Uma funcção sobrejetora $\phi : M \surto N$ tal que
$$
\text{para todo $x,y\in M$},\quad
\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)
$$
é um homomorfismo.

\proof Demonstrarás agora no~\ref[monoid_morphism_criterion_proof].

%%}}}

%%{{{ x: monoid_morphism_criterion_proof 
\exercise Critérion.
%%%{{{ meta 
\label monoid_morphism_criterion_proof
%%%}}}

Demonstre o~\ref[monoid_morphism_criterion].

\hint
Precisamos demonstrar que $\phi(\epsilon_M) = \epsilon_N$.
Como podemos ler essa igualdade em lingua (mais) natural?

\hint
Queremos: \wq{o $\phi(\epsilon_M)$ é a identidade do $\cal N$}.
O que significa \wq{ser a identidade dum monóide}?
Ou seja, o que precisamos demonstrar sobre esse objeto, $\phi(\epsilon_M)$
para mostrar que realmente ele é a identidade?

\hint
Precisamos demonstrar que:
$$
\lforall {n \in N} {n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n}.
$$
Como começaria essa prova?

\hint
\wq{Seja $n \in N$.}
Depois dessa frase, queremos demonstrar que
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n.
$$

\hint
Já provamos no~\ref[in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity] que não tem como ganhar a preservação da identidade como conseqüência da preservação da operação tendo uma funcção $\phi : M \to N$ qualquer.  Então com certeza precisamos usar nossa hipótese nova aqui, que a $\phi$ é sobrejetora.

\hint
Seja $n \in N$.
Como $\phi$ é sobrejetora, tome $m \in M$ tal que $\phi(m) = n$.

\solution
Vamos demonstrar que $\phi(\epsilon_M) = \epsilon_N$, ou seja, que para todo $n\in N$, 
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) \cdot_N n.
$$
Seja $n \in N$.
Logo $n = \phi(m)$ para algum $m \in M$ (pois $\phi$ sobre $N$).
Calculamos:
\compute
n\cdot_N \phi(\epsilon_M)
&= \phi(m) \cdot_N \phi(\epsilon_M) \by {pela escolha do $m$} \\
&= \phi(m \cdot_M \epsilon_M)       \by {$\phi$ homo: resp.~op.} \\
&= \phi(m)                          \by {pela (G2)} \\
&= n                                \by {pela escolha do $m$} \\
\endcompute
Similarmente, $n = \phi(\epsilon_M) \cdot_N n$.
\eop
Alternativamente, podemos começar assim:
seja $m \in M$ tal que $\phi(m) = e_N$; e agora
\compute
\phi(e_M)
&= \phi(e_M) e_N        \by {def.~$e_N$} \\
&= \phi(e_M) \phi(m)    \by {pela escolha de $m$} \\
&= \phi(e_M m)          \by {$\phi$ homo: resp.~op.} \\
&= \phi(m)              \by {def.~$e_M$} \\
&= e_N.                 \by {pela escolha de $m$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Rings 
\section Aneis.
%%%{{{ meta 
\label Rings
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos estudar pouco a estrutura de \emph{anel},
cuja definição foi dada primeiramente por {\Fraenkel}Fraenkel.
Nossa inspiração e guia para os grupos, foram os mapeamentos e as permutações.
Para os anéis, nossa guia são os inteiros.

%%}}}

%%{{{ df: ring 
\definition Anel.
%%%{{{ meta 
\label ring
\defines
    * anel
    * anel!comutativo
    ;;
%%%}}}

Seja $\cal R = \sset R {\plus,\,\ntimes,0,1}$ um conjunto estruturado,
onde $\plus,\ntimes$ são operações binárias
e $0,1$ são constantes.
$\cal R$ é um \dterm{anel} ou \dterm{ring} sse
$$
\alignat2
\pforall {a,b\in R}                 &\quantified{a\plus b \in R}                              &\tag{RA0} \\
\pforall {a,b,c\in R}               &\quantified{a\plus(b\plus c) = (a\plus b)\plus c}        &\tag{RA1} \\
\pforall {a \in R}                  &\quantified{0\plus a = a = a\plus 0}                     &\tag{RA2} \\
\pforall {a\in R} \pexists {y\in R} &\quantified{y\plus a = 0 = a \plus y}                    &\tag{RA3} \\
\pforall {a,b\in R}                 &\quantified{a\plus b = b \plus a}                        &\tag{RA4} \\
\pforall {a,b\in R}                 &\quantified{a\ntimes b \in R}                            &\tag{RM0} \\
\pforall {a,b,c\in R}               &\quantified{a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}&\tag{RM1} \\
\pforall {a \in R}                  &\quantified{1\ntimes a = a = a\ntimes 1}                 &\tag{RM2} \\
\pforall {a,b,c \in R}              &\quantified{a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)}  &\tag{RDL}\\
\pforall {a,b,c \in R}              &\quantified{(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)}  &\tag{RDR}\\
\intertext{Caso que também é satisfeitquantified}
\pforall {a,b\in R}                 &\quantified{a\ntimes b = b \ntimes a}                    &\tag{RM4}
\endalignat
$$
chamamos o $\cal R$ \dterm{anel comutativo}.

%%}}}

%%{{{ x: rings_with_different_structures 
\exercise.
%%%{{{ meta 
\label rings_with_different_structures
%%%}}}

Acima escolhemos a maneira ``intermediaria'' de estrutura.
Qual seria uma estrutura ``mais completa'' para definir o conceito de anel, e qual uma estrutura mais pobre?
Descreva as aridades dos símbolos usados (a assinatura da estrutura algébrica).

\solution
A estrutura mais completa:
$$
\sset R {+,\ntimes,-,0,1}
$$
onde seus símbolos têm as aridades $(2,2,1,0,0)$ respectivamente.
A estrutura mais pobre:
$$
\sset R {+,\ntimes}
$$
com assinatura $(2,2)$.

%%}}}

%%{{{ x: ring_definition_using_groups 
\exercise.
%%%{{{ meta 
\label ring_definition_using_groups
%%%}}}

Como podemos definir o que é um anel usando definições de estruturas algébricas que já conhecemos?

\solution
Seja $\cal R = \sset R {\plus, \ntimes, -, 0, 1}$ um conjunto estruturado,
onde $0,1$ são constantes, $\plus,\ntimes$ são operações binárias, e $-$ unária.
O $\cal R$ é um \dterm{anel} sse:
\item{(i)} $\sset R {\plus, -, 0}$ é um grupo abeliano;
\item{(ii)} $\sset R {\ntimes, 1}$ é um monóide;
\item{(iii)} as seguintes leis são satisfeitas:
$$
\alignat2
\pforall {a,b,c \in R} &\quantified{a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)}  &\tag{RDL}\\
\pforall {a,b,c \in R} &\quantified{(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)}  &\tag{RDR}
\endalignat
$$

%%}}}

%%{{{ beware: ring_or_rng
\beware Ring ou Rng?.
%%%{{{ meta 
\label ring_or_rng
\defines
    * rng
    ;;
%%%}}}

Na definição de \dterm{ring} que usamos aqui necessitamos ter
$\ntimes$\,-identidade (unidade).  Infelizmente isso não é padrão:
especialmente em textos antigos (mas também dependendo do objetivo de cada
texto) aneis podem necessitar ou não esse axioma, e logo vendo a palavra
``anel'' num texto, precisamos confirmar qual é a definição usada.
Para a gente aqui, quando queremos referir à estrutura que não necessita
identidades chamamos de \dterm{rng}, a idéia sendo que é como um ``ring''
sem $i$\,(dentidade).\foot
Tentando traduzir ``rng'' para português, tanto ``ael'' quanto ``anl''
funcionam mas não muito bem: na primeira opção perdemos o elemento \emph{n}eutro
da $\ntimes$ e na segunda perdemos o $e$ do monóide multiplicativo, mas nenhuma
das opções fica boa, então melhor esquecer esses termos e usar \emph{rng} o  mesmo.
\toof
No outro lado, quem não considera esse axioma como parte de \emph{ser um ring},
refere aos nossos rings como ``ring com unidade'', ``ring com $1$'', ``ring unital'' etc.
Às vezes o termo \dterm{pseudoring} é usado mas este é um termo ainda mais
sobrecarregado, então melhor usar ``rng'' que sempre tem o mesmo significado.
No \cite[poonenrings] encontrarás mais sobre a escolha da nossa \ref[ring]
mas sugiro não consultá-lo antes de pensar sobre o exercício seguinte primeiro:

%}}}

%%{{{ x: justify_unit_in_ring_def 
\exercise.
%%%{{{ meta 
\label justify_unit_in_ring_def 
%%%}}}

Tu escolherias incluir o $1$ na definição de ring?  Por quê?

%%}}}

%%{{{ df: defined_ops_in_rings 
\definition.
%%%{{{ meta 
\label defined_ops_in_rings
%%%}}}

Dado $x\in R$, denotamos com $(-x)$ o objeto garantido pela~(RA3).
Seguindo nossa experiência com adição e multiplicação de números,
adoptamos as mesmas convenções para os anéis: denotamos pela juxtaposição
a ``multiplicação'' do anel, e consideramos que ela tem precedência contra a ``adição''.
Note também que como não temos alguma operação binária $-$ de subtraição,
a expressão $x-y$ num anel não é definida.
Definimos a operação \emph{binária} $-$ num anel $R$ pela
$$
x - y \sugareq x + (-y).
$$
Pelo contexto sempre dará pra inferir a aridade do símbolo \symq{$-$};
então não tem como criar ambigüidade com a operação \emph{unária} $-$,
mesmo compartilhando o mesmo símbolo.
Continuando, se $n\in\nats$, usamos:
$$
\xalignat2
nx   &\sugareq \tubrace{x + x + \dotsb + x} {$n$ vezes} &
x^n  &\sugareq \tubrace{x x \dotsb x} {$n$ vezes}.
\intertext{Ou seja, lembrando da notação do~\ref[powers_in_group]:}
nx   &\sugareq x^{+n} &
x^n  &\sugareq x^{\ntimes n}.
\endxalignat
$$

%%}}}

%%{{{ eg: first_ring_examples 
\example.
%%%{{{ meta 
\label first_ring_examples
%%%}}}

Todos os seguintes conjuntos são exemplos de anéis:
$$
\xalignat7
&\sset \ints                {+,\ntimes}&
&\sset \rats                {+,\ntimes}&
&\sset \reals               {+,\ntimes}&
&\sset \complex             {+,\ntimes}&
&\sset {\polys\reals x}     {+,\ntimes}&
&\sset {C[a,b]}             {+,\ntimes}&
&\sset {\reals^{n\times n}} {+,\ntimes}
\endxalignat
$$
onde lembramos que
$\polys\reals x$ é o conjunto de todos os polinómios numa variável $x$ com coeficientes
reais,
e $\reals^{n\times n}$ é o conjunto de todas as matrices reais $n\times n$.
Temos também
$$
C[a,b]
\defeq
\setstt {f : [a,b]\to\reals} {$f$ é contínua}
$$
para quaisquer $a,b\in\reals$ com $a\leq b$.
A adição e multiplicação no $C[a,b]$ são as
\emph{operações pointwise}\indexed[pointwise!operação],
definidas pelas:
$$
\xalignat2
f + g       &= \lam x {f(x) + g(x)}         &
f \ntimes g &= \lam x {f(x) \ntimes g(x)}.
\endxalignat
$$
(Veja a~\ref[pointwise_operation].)

%%}}}

%%{{{ eg: End_G_is_a_ring_claim 
\example.
%%%{{{ meta 
%%%}}}

Fez o~\ref[hom_abel_with_pointwise_plus]?\foot
Não?  Vá lá fazer agora e volte assim que resolver.
\toof
Quem fez, sabe que se $G'$ é abeliano, então o
$\sset {\Hom(G,G)} +$ onde $+$ é a operação pointwise
baseada no $+_{G'}$.
Em particular, para qualquer grupo abeliano $G$ o conjunto
$$
\End(G) \defeq \Hom(G,G)
$$
vira um grupo abeliano $\sset {\End(G)} +$.
Mas no mesmo conjunto uma outra operação interessante é a composição.
O $\sset {\End(G)} {+,\com}$ é um anel.

%%}}}

%%{{{ x: End_G_is_a_ring_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre!

%%}}}

%%{{{ df: zero_ring 
\definition.
%%%{{{ meta 
\label zero_ring
%%%}}}

Se num anel $R$ temos $0_R = 1_R$ chamamos o $R$ de \dterm{anel zero}.
Caso contrário \dterm{anel não-zero}.

%%}}}

%%{{{ lemma: ring_zero_absorbs 
\lemma Zero absorve.
%%%{{{ meta 
\label ring_zero_absorbs
%%%}}}

Seja $R$ um anel.
Então:
$$
\text{para todo $x\in R$,}\quad
0x = 0 = x0.
$$

\proof.
Seja $x\in R$.
Calculamos:
\compute
0x
&= (0 + 0)x  \by {def.~$0$} \\
&= 0x + 0x   \by {pela~(RDR)} \\
\endcompute
Achamos então que $0x$ é uma resolução da $0x + \askbox = 0x$.
E como o $\sset R +$ é um grupo sabemos então que $0x = 0$
(\ref[cheaper_gid]) que foi o que queremos demonstrar.

%%}}}

%%{{{ corollary: a zero ring is a singleton 
\corollary.
%%%{{{ meta 
%%%}}}

Se $R$ é um anel zero, $R$ é um singleton.

\proof.
Seja $r \in R$.  Calculamos:
$$
r = r1_R = r0_R = 0_R.
$$

%%}}}

%%{{{ x: ring_negation_of_difference 
\exercise.
%%%{{{ meta 
\label ring_negation_of_difference
%%%}}}

Para todo $a,b\in R$,
$$
-(a - b) = b - a.
$$

%%}}}

%%{{{ lemma: ring_negation_of_product 
\lemma Negação de produto.
%%%{{{ meta 
\label ring_negation_of_product
%%%}}}

Seja $R$ um anel.  Logo,
$$
\text{para todo $a,b\in R$,}\quad
(-a)b = -(ab) = a(-b).
$$

\sketch.
Para demonstrar a primeira igualdade, basta enxergá-la como a afirmação seguinte:
\emph{o $(-a)b$ é o $+$-inverso do $ab$}.
Verificamos então que $ab + (-a)b = 0$.
A outra igualdade é similar.

\proof.
Verificamos que $(-a)b$ realmente é o inverso de $ab$:
\compute
ab + (-a)b
&= (a + (-a))b  \by {pela (RDR)} \\
&= 0b           \by {def.~$(-a)$} \\
&= 0            \by {\ref[ring_zero_absorbs] com $x\asseq b$} \\
\endcompute
e como a equação $ab + \askbox$ tem resolução única
(pois o $\sset R +$ é um grupo)
e o $-(ab)$ também a resolve,
concluimos que $(-a)b = -(ab)$.
A outra igualdade é similar.

%%}}}

%%{{{ corollary 
\corollary.
%%%{{{ meta 
%%%}}}

Em qualquer anel $\cal R$, para todos $x,y\in\cal R$ temos:
\item{\rm (i)}   $(-x)(-y) = xy$;
\item{\rm (ii)}  $(-1)x = -x$;
\item{\rm (iii)} $(-1)(-1) = 1$;
\item{\rm (iv)}  $-(x+y) = (-x) + (-y)$.

%%}}}

%%{{{ x: pset_with_setops_ring 
\exercise.
%%%{{{ meta 
\label pset_with_setops_ring
%%%}}}

Seja $X$ conjunto.
Defina no $\pset X$ duas operações tais que $\pset X$ vira um anel.
Identifique quas são seus $0,1$ e demonstre que realmente é um anel.

\hint
Lembre o~\ref[pset_with_setops_group]?

\hint
Graças ao~\ref[pset_with_setops_group], a adição do anel deve ser a $\symdiff$.

\hint
$\sset {\pset X} {\symdiff, \inter}$.

%%}}}

%%{{{ Q: How would you define subring and ring homomorphism? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias o conceito de subanel?
Pode definir algum critérion parecido com os critéria~\reftag[nonempty_subgroup_criterion]
ou~\reftag[finite_subgroup_criterion] para decidir se algo é subanel dum dado anel?
E o homomorfismo de anel?  Como definirias isso?  E pode definir algum critérion
parecido com o~\reftag[criterion_for_morphism_in_groups]?

%%}}}

\spoiler

%%{{{ df: subring 
\definition subanel.
%%%{{{ meta 
\label subring
\defines
    * subanel
    ;;
%%%}}}

Seja $\cal R$ um anel.
O $S\subset R$ é um \dterm{subanel} de $\cal R$ sse
$\sset S {+_R, \cdot_R,0_R, 1_R}$ é um anel.

%%}}}

%%{{{ criterion: subring_criterion 
\criterion de subanel.
%%%{{{ meta 
\label subring_criterion
%%%}}}

Sejam $R$ anel e $S \subset R$.
O $S$ é um subanel de $R$ sse:
\item{\rm (i)}  $S$ tem a identidade do $R$: $1_R \in S$;
\item{\rm (ii)} $S$ é fechado pela adição: para todo $a,b \in S$, $a+b \in S$;
\item{\rm (iii)}$S$ é fechado pela multiplicação: para todo $a,b \in S$, $ab \in S$;
\item{\rm (iv)} $S$ é fechado pelos negativos: para todo $a \in S$, $-a\in S$.

%%}}}

%%{{{ df: ring_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label ring_homomorphism
\defines
    * homomorfismo!de anel
    ;;
%%%}}}

Sejam os anéis
$\cal R = \sset R {+_R, \cdot_R, 0_R, 1_R}$ e
$\cal S = \sset S {+_S, \cdot_S, 0_S, 1_S}$.
A~funcção $\phi : R \to S$ é um homomorfismo sse:
\item{\rm (i)}   $\phi(0_R) = 0_S$;
\item{\rm (ii)}  $\phi(1_R) = 1_R$;
\item{\rm (iii)} para todo $x,y\in R$, $\phi(x+_R y) = \phi(x) +_S \phi(y)$;
\item{\rm (iv)}  para todo $x,y\in R$, $\phi(x\cdot_R y) = \phi(x) \cdot_S \phi(y)$;
\item{\rm (v)}   para todo $x\in R$, $\phi(-x) = -(\phi(x))$.

%%}}}

%%{{{ criterion: ring_homomorphism_criterion 
\criterion de homomorfismo.
%%%{{{ meta 
\label ring_homomorphism_criterion
%%%}}}

Se a funcção $\phi : \cal R \to \cal S$ satisfaz:
$$
\align
\phi(1_R)           &= 1_S\\
\phi(x +_R y)       &= \phi(x) +_S \phi(y)\quad\text{para todo $x,y\in R$}\\
\phi(x \cdot_R y)   &= \phi(x) \cdot_S \phi(y)\quad\text{para todo $x,y \in R$}
\endalign
$$
então ela é um homomorfismo.
(Ou seja, podemos apagar os itens (i) e (v) na~\ref[ring_homomorphism].)

\proof.
Como $\sset R {+_R}$ e $\sset S {+_S}$ são grupos,
sabemos que se $\phi$ respeita a operação aditiva então
ela necessariamente respeita sua identidade e seus inversos
também~(\ref[criterion_for_morphism_in_groups]).

%%}}}

%%{{{ x: multiplicative_part_of_a_ring_not_a_group 
\exercise.
%%%{{{ meta 
\label multiplicative_part_of_a_ring_not_a_group
%%%}}}

As leis de anel exigem que sua ``parte aditiva'' é um grupo abeliano,
e sobre sua ``parte multiplicative'' exigem apenas ser um monóide.
Pode ter anel $\cal R = \sset R {+,\ntimes,0,1}$ cuja parte multiplicative
realmente forma um grupo?
Ou seja, tal que $\sset R {\ntimes, 1}$ é um grupo?
Se sim, mostre um exemplo de tal anel;
se não, demonstre que não existe tal anel.

\hint
\ref[ring_zero_absorbs].

\hint
Não pode.  Exceto se\dots

\solution
Se é pra ter tal anel $R$, qual seria o inverso de $0$?
Pelo~\ref[ring_zero_absorbs] temos que
$$
0 x = 0
$$
para todo $x\in R$, e logo para $x \asseq \ginv 0$ também:
$$
0 \ginv 0 = 0
$$
Mas $0 \ginv 0 = 1$ pela definição de $\ginv 0$, e logo
$$
0 = 0 \ginv 0 = 1.
$$
Necessariamente então, em tal ring temos $0=1$.
Pode ter mais membros além do $0$?
Não!
Seja $r\in R$.
Temos então
\compute
r
&= 1r \by {def.~$1$} \\
&= 0r \by {pois 0=1} \\
&= 0  \by {pelo~\ref[ring_zero_absorbs]} \\
\endcompute
e logo $R = \set {0_R}$.

%%}}}

%%{{{ df: kernel_image_in_rings 
\definition kernel, image.
%%%{{{ meta 
\label kernel_image_in_rings
%%%}}}

Seja $\phi : R \to S$ homomorfismo de anéis.
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{0_S}} &
\quad\big(&= \setst {r \in R} {\phi(r) = 0_S} \ \big)\\
\ima\phi
&\defeq \img \phi R &
\quad\big(&= \setst {s \in S} {\lexists {r\in R} {\phi(r) = s}} \ \big)
\endalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos já demonstrar o equivalente do~\ref[image_subgroup] que encontramos
nos grupos, para os anéis:

%%}}}

%%{{{ lemma: image_subring 
\lemma.
%%%{{{ meta 
\label image_subring
%%%}}}

Seja $\phi : R \to S$ um homomorfismo de anéis.
Sua imagem $\ima\phi$ é um subanel de $S$.

\sketch.
Usamos o~\ref[subring_criterion] e a definição de $\ima\phi$.

\proof.
Tome $a,b\in \ima\phi$.  Logo
$$
\alignat2
a &= \phi(a') &\quad&\text{para algum $a' \in R$}\\
b &= \phi(b') &\quad&\text{para algum $b' \in R$}.
\endalignat
$$
Calculamos:
\compute
1_S
&= \phi(1_R);           \by {$\phi$ homo ($1$)} \\
a + b
&= \phi(a') + \phi(b')  \by {pela escolha dos $a',b'$} \\
&= \phi(a'+b');         \by {$\phi$ homo ($+$)} \\
-a
&= -\phi(a')            \by {pela escolha do $a'$} \\
&= \phi(-a');           \by {$\phi$ homo ($-$)} \\
ab
&= \phi(a')\phi(b')     \by {pela escolha dos $a',b'$} \\
&= \phi(a'b').          \by {$\phi$ homo ($\cdot$)} \\
\endcompute
Ou seja:  $1_S, a+b, -a, ab \in \ima\phi$ e podemos usar
o~\ref[subring_criterion].

%%}}}

%%{{{ Q: Is the kernel cooler than just a subring? 
\question.
%%%{{{ meta 
%%%}}}

Será que o kernel é algo mais-legal-que-subanel na mesma
forma que aconteceu nos grupos?

%%}}}

\spoiler

%%{{{ x: 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $\phi : R \homto S$.
O que consegues demonstrar entre o $\ker\phi$ e o $R$?

%%}}}

\endsection
%%}}}

%%{{{ Boolean rings 
\section Aneis booleanos.
%%%{{{ meta 
\label Boolean_rings
%%%}}}

%%{{{ df: boolean_ring 
\definition Anel booleano.
%%%{{{ meta 
\label boolean_ring
\defines
    * anel!booleano
    ;;
%%%}}}

Chamamos o anel $\cal R$ um \dterm{anel booleano} sse
sua multiplicação é \indexed[idempotência]\emph{idempotente}, ou seja:
$$
\text{para todo $a\in \cal R$},\quad
a^2 = a.
$$

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Dado conjunto $X$, o $\sset {\pset X} {\symdiff, \inter}$
é um anel booleano.

%%}}}

%%{{{ x: boolean_rings_are_idempotent 
\exercise.
%%%{{{ meta 
\label boolean_rings_are_idempotent
%%%}}}

Seja $\cal R$ um anel booleano.
Demonstre que:
$$
\text{para todo $p\in \cal R$},\quad
p = -p.
$$

\hint
$p + p = (p+p)^2 = \dotsc$

\solution
Seja $p \in R$.
Calculamos:
\compute
p + p
&= (p+p)^2               \by {$R$ booleano} \\
&= (p+p)(p+p)            \\
&= (p+p)p + (p+p)q       \\
&= pp + pp + pp + pp     \\
&= p^2 + p^2 + p^2 + p^2 \\
&= p + p + p + p         \by {$R$ booleano} \\
&= p + p + (p + p)
\endcompute
e logo $p + p = 0$, ou seja, $p = -p$.

%%}}}

%%{{{ x: boolean_rings_negative_of_product 
\exercise.
%%%{{{ meta 
\label boolean_rings_negative_of_product
%%%}}}

Seja $\cal R$ um anel booleano.
Demonstre que:
$$
\text{para todo $p,q\in \cal R$},\quad
pq = -qp
$$
e mostre como isso gera mais uma prova
do~\ref[boolean_rings_are_idempotent].

\hint
Calcule o $(p+q)^2$.

\solution
Sejam $p,q \in R$.
Calculamos:
\compute
(p+q)^2
&= (p+q)(p+q)           \\
&= (p+q)p + (p+q)q      \\
&= pp + qp + pq + qq    \\
&= p^2 + qp + pq + q^2  \\
&= p + qp + pq + q.     \by {$B$ booleano} \\
\endcompute
Mas como $B$ é booleano temos também $(p+q)^2 = p+q$.
Ou seja
\compute
p + q &= p + qp + pq + q \\
      &= p + q + (qp + pq) \\
\intertext{e logo (\ref[cheaper_gid])}
0     &= qp + pq    \tag{1}
\endcompute
ou seja, $pq = -qp$.
\eop
Para ganhar o~\ref[boolean_rings_are_idempotent] como
corolário, é so tomar $q \asseq 1$.

%%}}}

%%{{{ x: boolean_rings_are_commutative 
\exercise.
%%%{{{ meta 
\label boolean_rings_are_commutative
%%%}}}

Todo anel booleano é comutativo.

\hint
Use os \ref[boolean_rings_are_idempotent]
e~\reftag[boolean_rings_negative_of_product].

\solution
Sejam $p,q$ membros dum anel booleano.
Temos
\compute
pq
&= -qp  \by {\ref[boolean_rings_negative_of_product], com $p \asseq p$ e $q \asseq q$} \\
&= qp.  \by {\ref[boolean_rings_are_idempotent], com $p \asseq qp$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Integral domains 
\section Domínios de integridade.
%%%{{{ meta 
\label Integral_domains
%%%}}}

%%{{{ df: zerodivisors 
\definition Divisores de zero.
%%%{{{ meta 
\label zerodivisors
\indexes
    * divisor de zero    see: zerodivisor
    ;;
\defines
    * zerodivisor
    ;;
%%%}}}

Seja $R$ um anel, e $x,y\in R$.
Se $xy = 0_R$ e nem $x=0_R$ nem $y=0_R$, chamamos os $x,y$
\dterm{divisores de zero} (ou \dterm{zerodivisores}) no $R$.

%%}}}

%%{{{ eg: ints_6 
\example.
%%%{{{ meta 
%%%}}}

No anel $\ints_6$, temos $2\ntimes 3 = 0$.
Logo ambos os $2,3$ são divisores de zero nesse anel.
O $4$ também é, pois $3\ntimes 4 = 0$ também.

%%}}}

%%{{{ eg: real_continuous_functions_zerodivisors 
\example.
%%%{{{ meta 
\label real_continuous_functions_zerodivisors
%%%}}}

Considere o anel $C[-1,1]$ com as operações~\indexed[pointwise!operação]pointwise
(veja~\ref[first_ring_examples]).
Tome as funcções $f,g$ definidas pelas
$$
\xalignat2
f(x) &= \knuthcases {
-x, & se $x\leq 0$\cr
0,  & se $x > 0$
}&
g(x) &= \knuthcases {
0,  & se $x\leq 0$\cr
x,  & se $x > 0$.
}
\endxalignat
$$
Calculando, achamos
$$
f\ntimes g = \lam x 0_{C[-1,1]}
$$
e logo os $f,g$ são divisores de zero no $C[-1,1]$.

%%}}}

%%{{{ x: design_graphs_of_zerodevisor_real_continuous_functions 
\exercise.
%%%{{{ meta 
\label design_graphs_of_zerodevisor_real_continuous_functions
%%%}}}

Desenhe os gráficos das funcções $f,g$
do~\ref[real_continuous_functions_zerodivisors],
e com um cálculo explique porque $f\ntimes g = 0$.

%%}}}

%%{{{ df: integral_domain_cancellation_domain 
\definition Domínio de integridade e de cancelamento.
%%%{{{ meta 
\label integral_domain_cancellation_domain
\defines
    * domínio de cancelamento
    * domínio de integridade
    ;;
%%%}}}

Seja $\cal D$ um anel comutativo.
Chamamos o $\cal D$ \dterm{domínio de integridade}
sse ele não tem zerodivisores, ou seja, sse:
$$
\text{para todo $x,y \in D$,}\quad
\text{se $xy=0$ então $x=0$ ou $y=0$}.
\tag{NZD}
$$
Chamamos o $\cal D$ \dterm{domínio de cancelamento}
sse
$$
\text{para todo $a,x,y \in D$,}\quad
ax = ay \mland a \neq 0 \implies x=y.
\tag{RCL}
$$
que é equivalente à
$$
\text{para todo $a,x,y \in D$,}\quad
xa = ya \mland a \neq 0 \implies x=y.
\tag{RCR}
$$
pois esse anel é comutativo.

%%}}}

%%{{{ criterion: integral_domain_equiv_cancellation_domain 
\criterion.
%%%{{{ meta 
\label integral_domain_equiv_cancellation_domain
%%%}}}

Os termos ``domínio de integridade'' e ``domínio de cancelamento''
são sinônimos, ou seja:
$$
\text{$D$ é um domínio de integridade} \iff \text{$D$ é um domínio de cancelamento}.
$$

\proof.
\proofpart{\lrdir:}
Sejam $a,x,y \in D$ tais que $a \neq 0$ e $ax = ay$.
Logo $ax - ay = 0$.
Logo $a(x-y) = 0$.
Pela hipótese (NZD) então $x-y = 0$, ou seja $x = y$.
\crproofpart{\rldir:}
Sejam $x,y \in D$ tais que $xy = 0$ e $x \neq 0$.
Queremos $y = 0$.
Temos $xy = 0 = x0$ (pois $0 = 0x$ em todo anel).
Ou seja $xy = x0$, e como $x\neq 0$, usando a (RCL) concluimos $y=0$.

%%}}}

\endsection
%%}}}

%%{{{ Fields 
\section Corpos.
%%%{{{ meta 
\label Fields
%%%}}}

%%{{{ df: field 
\definition Corpo.
%%%{{{ meta 
\label field
\defines
    * corpo
    ;;
%%%}}}

Seja $\cal K$ um anel não-zero e comutativo.
Chamamos o $\cal K$ um \dterm{corpo} (ou \dterm{field})
sse todos os seus membros diferentes de $0$ são invertíveis,
ou seja sse:
$$
\text{para todo $a\in K_{\neq0}$,
existe $y \in K$, tal que $ay = 1 = ya$.}
\tag{FM3*}
$$

%%}}}

%%{{{ eg: rats and reals and complex 
\example.
%%%{{{ meta 
%%%}}}

Os racionais, os reais, e os complexos, com suas operações canônicas de adição
e multiplicação são todos corpos.

%%}}}

%%{{{ noneg: ints and nats 
\nonexample.
%%%{{{ meta 
%%%}}}

Os inteiros e os naturais não!

%%}}}

%%{{{ eg: integers_modulo_p_field_example 
\example.
%%%{{{ meta 
\label integers_modulo_p_field_example
%%%}}}

O $\cal Z_p = \sset {\quogrp \ints {p\ints}} {+_p, \ntimes_p}$ onde $p$ primo é um corpo.

%%}}}

%%{{{ noneg: integers_modulo_n_field_nonexample 
\nonexample.
%%%{{{ meta 
\label integers_modulo_n_field_nonexample
%%%}}}

O $\cal Z_n$ onde $n>1$ e não primo, não é um corpo.

%%}}}

%%{{{ criterion: finite_integral_domain_implies_field 
\criterion.
%%%{{{ meta 
%%%}}}

Se $D$ é um domínio de integridade finito então $D$ é um corpo.

\proof.
Suponha que $D$ é um domínio de integridade finito.
Precisamos mostrar que cada $d \neq 0$ no $D$ tem inverso.
Seja $d\in D$, $d\neq 0$.
Procuro $d' \in D$ tal que $dd' = 1$.
Sejam
$$
d_1, d_2, \dotsc, d_n
$$
todos os elementos distintos de $D\setminus\set{0}$.
Considere os
$$
dd_1, dd_2, \dotsc, dd_n.
$$
Observe que:
$$
dd_i = dd_j \impliesbecause{(RCL)} d_i = d_j \implies i = j.
$$
Ou seja,
$$
D\setminus\set{0} = \set{dd_1, dd_2, \dotsc, dd_n}.
$$
Ou seja, como $1\in D\setminus\set{0}$,
$$
1 = dd_u \quad\text{para algum $u\in\set{1,\dotsc,n}$}
$$
que é o que queremos demonstrar.

%%}}}

%%{{{ x: integers_modulo_p_field_iff_p_prime
\exercise.
%%%{{{ meta 
\label integers_modulo_p_field_iff_p_prime
%%%}}}

Demonstre que o~\ref[integers_modulo_p_field_example]
realmente é um exemplo de corpo
e que o~\ref[integers_modulo_n_field_nonexample]
realmente não é.

%%}}}

\endsection
%%}}}

%%{{{ Galois_theory 
\section Teoria de Galois.
%%%{{{ meta 
\label Galois_theory
%%%}}}

\TODO Escrever.

%TODO Fixed field, maybe mention fixpoint subring earlier 

\endsection
%%}}}

%%{{{ Lattices 
\section Reticulados.
%%%{{{ meta 
\label Lattices_as_algebras
%%%}}}

%%{{{ Lattice laws 
\note Leis de reticulado.
%%%{{{ meta 
%%%}}}

Num reticulado temos duas operações binárias que chamamos
de \dterm{join} ($\join$) e \dterm{meet} ($\meet$).
Elas satisfazem as leis de reticulado:
$$
\xalignat2
\text{associatividade} &\ \leftbrace {
\aligned
a \join (b \join c) &= (a \join b) \join c \\
a \meet (b \meet c) &= (a \meet b) \meet c
\endaligned
} &
\rightbrace {
\aligned
a \join b &= b \join a \\
a \meet b &= b \meet a
\endaligned
}\ & \text{comutatividade}
\\
\text{idempotência} &\ \leftbrace {
\aligned
a \join a &= a \\
a \meet a &= a
\endaligned
} &
\rightbrace {
\aligned
a \join (a \meet b) &= a \\
a \meet (a \join b) &= a
\endaligned
}\ & \text{absorpção}
\endxalignat
$$
Observe que sem as leis de absorpção não temos uma estrutura interessante.
Essas leis nos dizem como as duas operações interagem e oferecem à teoria
de reticulados sua alma.
Formalmente, temos:

%%}}}

%%{{{ df: lattice_as_algebra 
\definition.
%%%{{{ meta 
\label lattice_as_algebra
\defines
    * reticulado!como álgebra
    * reticulado!limitado, como álgebra
    ;;
%%%}}}

Seja $\cal L = \sset L {\join,\meet}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias que chamamos de \dterm{join}
e \dterm{meet} respectivamente.
$\cal L$ é um \dterm{reticulado} (ou \dterm{láttice}) sse:
$$
\alignat2
\pforall {a,b\in L}   &\quantified{a\join b \in L}                         &\tag{LJ0} \\
\pforall {a,b,c\in L} &\quantified{a\join(b\join c) = (a\join b)\join c}   &\tag{LJ1} \\
\pforall {a,b\in L}   &\quantified{a\join b = b \join a}                   &\tag{LJ2} \\
\pforall {a\in L}     &\quantified{a\join a = a}                           &\tag{LJ3} \\
\pforall {a,b\in L}   &\quantified{a\meet b \in L}                         &\tag{LM0} \\
\pforall {a,b,c\in L} &\quantified{a\meet(b\meet c) = (a\meet b)\meet c}   &\tag{LM1} \\
\pforall {a,b\in L}   &\quantified{a\meet b = b \meet a}                   &\tag{LM2} \\
\pforall {a\in L}     &\quantified{a\meet a = a}                           &\tag{LM3} \\
\pforall {a,b \in L}  &\quantified{a\join (a \meet b) = a}                 &\tag{LAJ} \\
\pforall {a,b \in L}  &\quantified{a\meet (a \join b) = a}.                &\tag{LAM} \\
\intertext{%
Seja $\cal L = \sset L {\join,\meet,0,1}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias e $0,1$ constantes, e tal que
$\cal L$ é um \dterm{reticulado limitado} (ou \dterm{bounded láttice}) sse
$\sset L {\join,\meet}$ é um reticulado e
}
\pforall {a \in L}    &\quantified{a\join 0 = a}                           &\tag{LJB} \\
\pforall {a \in L}    &\quantified{a\meet 1 = a}.                          &\tag{LJB}
\endalignat
$$

%%}}}

%%{{{ criterion: lattice_without_idem_criterion 
\criterion.
%%%{{{ meta 
\label lattice_without_idem_criterion
%%%}}}

Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join$ e $\meet$ satisfazem as leis de:
associatividade, comutatividade, absorção.
Então $\cal L$ é um reticulado.

\proof.
\ref[abs_and_com_imply_idem].

%%}}}

%%{{{ x: abs_and_com_imply_idem 
\exercise.
%%%{{{ meta 
\label abs_and_com_imply_idem
%%%}}}

Demonstre o~\ref[lattice_without_idem_criterion].

\hint
$a\join(a\meet(a\join a))$.

\solution
Seja $a \in L$.
Calculamos
\compute
a \join ( (a \join a) \meet a )
&= a \join a                         \by {$\meet$-abs.} \\
\intertext{e também}
a \join ( (a \join a) \meet a)
&=  ( (a \join a) \meet a) \join a   \by {$\join$-com.} \\
&=  ( a \meet (a \join a) ) \join a  \by {$\meet$-com.} \\
&=  a                                \by {$\join$-abs.} \\
\endcompute
Logo $a\join a = a$.

%%}}}

%%{{{ x: two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser 
\exercise.
%%%{{{ meta 
\label two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser
%%%}}}

Seja $\cal L = \sset L {\join,\meet}$ um reticulado pela~\ref[lattice_as_algebra].
Demonstre que:
$$
a\join b = b \iff a\meet b = a.
$$

\solution
\proofpart{\lrdir}:
Suponha $b = a \join b$.
Calculamos
\compute
a \meet b
&= a \meet (a \join b)  \by {hipótese} \\
&= (a \join b) \meet a  \by {$\meet$-com.} \\
&= a.                   \by {$\meet$-abs.} \\
\endcompute
\proofpart{\rldir:}
Similar.

%%}}}

%%{{{ df: semilattice 
\definition.
%%%{{{ meta 
\label semilattice
\defines
    * semirreticulado
    * semirreticulado!limitado
    ;;
%%%}}}

Seja $\cal S = \sset S {\dmnd}$ um conjunto estruturado onde
$\dmnd$ é uma operação binária.
$\cal S$ é um \dterm{semirreticulado} (ou \dterm{semiláttice}) sse
sua operação é associativa, comutativa, e idempotente:
$$
\alignat2
\pforall {a,b\in S}   &\quantified{a\dmnd b \in S}                        &\tag{SL0} \\
\pforall {a,b,c\in S} &\quantified{a\dmnd(b\dmnd c) = (a\dmnd b)\dmnd c}  &\tag{SL1} \\
\pforall {a,b\in S}   &\quantified{a\dmnd b = b \dmnd a}                  &\tag{SL2} \\
\pforall {a\in S}     &\quantified{a\dmnd a = a}                          &\tag{SL3} \\
\intertext{%
Seja $\cal S = \sset S {\dmnd,\ell}$ um conjunto estruturado tal que
$\sset S {\dmnd}$ é um semirreticulado e $\ell$ é uma constante.
$\cal S$ é um \dterm{semirreticulado limitado} (ou \dterm{bounded semiláttice}) sse:
}
\pforall {a\in S}     &\quantified{a\dmnd \ell = a}                       &\tag{SLB}
\endalignat
$$

%%}}}

%%{{{ remark: shorter (bounded) lattice definitions using (bounded) semilattices
\remark Definições mais curtas.
%%%{{{ meta 
%%%}}}

Com as definições de semirreticulados podemos definir numa maneira mais simples
o que é um reticulado:

%%}}}

%%{{{ x: from_semilattice_to_lattice 
\exercise Definições mais curtas.
%%%{{{ meta 
\label from_semilattice_to_lattice
\defines
    * lattice
    ;;
%%%}}}

Defina os conceitos ``reticulado'' e ``reticulado limitado''
usando os conceitos ``semirreticulado'' e ``semirreticulado limitado''.

\solution
O conjunto estruturado $\cal L = \sset L {\join,\meet}$ é um
\dterm{lattice} sse os conjuntos estruturados
$\sset L {\join}$ e $\sset L {\meet}$ são semilattices,
e as leis de absorção são satisfeitas.
$\cal L = \sset L {\join,\meet}$ é um \dterm{reticulado} sse
$\sset L \join$ e $\sset L \meet$ são semirreticulados.
Similarmente $\sset L {\join,\meet,0,1}$ é um reticulado limitado sse
$\sset L {\join,0}$ e $\sset L {\meet,1}$ são semirreticulados limitados.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nosso objectivo aqui é brincar com várias estruturas algébricas, e não
aprofundar em nenhuma.
Mas se preocupe não: voltamos a estudar reticulados no~\ref[Posets_Lattices].

%%}}}

\endsection
%%}}}

%%{{{ Vector_spaces 
\section Espaços vetoriais.
%%%{{{ meta 
\label Vector_spaces
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os espaços vetoriais é o exemplo mais conhecido de estrutura
algébrica que envolve \emph{dois} conjuntos como carrier sets.

%%}}}

%%{{{ df: vector_space 
\definition.
%%%{{{ meta 
\label vector_space
%%%}}}

Sejam $F = \sset F {+,\ntimes,-,0,1}$ um corpo
e $V = \sset V {\oplus, \ominus, \vecb 0}$ um grupo abeliano.
Chamamos o $\sset {V,F} {\ast}$ com $\ast : F \cross V \to V$
dum \dterm{espaço vetorial sobre o $F$} sse as leis abaixo
são satisfeitas.
Chamamos os membros de $F$ de \dterm{escalares},
e os membros de $V$ de \dterm{vetores}.
Se $F = \reals$, temos um \dterm{espaço vetorial real};
se $F = \complex$, um \dterm{espaço vetorial complexo}.
Usarei $a,b,c,\dotsc$ ou letras gregas como metavariáveis para denotar escalares;
e para denotar vetores userei $\vecb u, \vecb v, \vecb w, \dotsc$ e também
$\veca u, \veca v, \veca w, \dotsc$.
A operação $\ast$ é chamada \dterm{multiplicação escalar}
e é sempre denotada por juxtaposição.
Mesmo que denotamos a multiplicação do corpo $\ntimes$
também por juxtaposição, isso não gera confusão.
Para diferenciar entre a multiplicação escalar e a multiplicação do corpo
chamarei de \dterm{scalaplicação} a primeira e \dterm{multiplicação} a segunda.
Finalmente, as leis:
% TODO: fix reflabs
\tlist:
\li (VS1): compatibilidade da scalaplicação com a multiplicação;
\li (VS2): identidade da scalaplicação;
\li (VS3): distributividade da scalaplicação com a adição dos vetores;
\li (VS4): distributividade da scalaplicação com a adição dos escalares.
\endtlist
Formulamente:
$$
\align
&a(b\vecb v) = (ab)\vecb v                              \tag{VS1} \\
&1\vecb v = \vecb v                                     \tag{VS2} \\
&a(\vecb u \oplus \vecb v) = a\vecb u \oplus a\vecb v   \tag{VS3} \\
&(a + b)\vecb v = a\vecb v \oplus b\vecb v.             \tag{VS4}
\endalign
$$
Escrevemos $+,-$ em vez dos $\oplus, \ominus$ quando é
claro quais são as operações.

%%}}}

%%{{{ eg: vector_space_eg_reals 
\example.
%%%{{{ meta 
%%%}}}

O $\reals$ é um espaço vetorial sobre o $\reals$.

%%}}}

%%{{{ eg: vector_space_eg_plane 
\example.
%%%{{{ meta 
%%%}}}

O $\reals^2$ com
$$
\align
(x,y) \oplus (x',y') &= (x + x', y + y') \\
\ominus (x,y) &= (-x, -y) \\
\vecb 0 &= (0,0)
\endalign
$$
é um espaço vetorial real.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
\defines
    * algebra!linear
    ;;
%%%}}}

O estudo de espações vetorias e seus morfismos
(\dterm{transformações lineares}) é chamado
\dterm{algebra linear}.

%%}}}

\endsection
%%}}}

%%{{{ Modules 
\section Modules.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: N_00 
\problem.
%%%{{{ meta 
\indexes
    * pointwise!operação
    ;;
%%%}}}

Considere o conjunto $\cal N_{00}$ das seqüências infinitas de naturais
``eventualmente zero'', ou seja
$$
\cal N_{00}
\defeq
\setst {f : \nats\to\nats} {\pexists {N\in\nats} \lforall {n \geq N} {f(n) = 0}}.
$$
Consideramos a operação de \emph{adição pointwise} definida pela:
$$
(f + g)(x) = f(x) + g(x).
$$
Demonstre que $\cal N_{00}$ com essa operação forma um monóide
isómorfo com o monóide $\sset {\nats_{>0}} {\ntimes}$
(com operação a multiplicação usual).

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[pinteralgebra],
\cite[hersteintopics],
\cite[babybm],
\cite[papamb].
\cite[sharperings].

Sugiro novamente o~\cite[aluffialgebra] como uma introdução
completa em algebra.

Dois livros excelentes para uma introdução em algebra linear
especificamente são os~\cite[halmosfdvs] e~\cite[halmoslapb]
(para ser estudados em paralelo).
Um primeiro toque dá pra pegar também pelos~\cite[apostol1]
e~\cite[apostol2].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The_reals 
\chapter Os reais.
%%%{{{ meta 
\label The_reals
%%%}}}

%%{{{ intro 
\chapintro
O $\sset \reals {+,\ntimes,0,1}$ é um \emph{corpo ordenado completo}.
Neste capítulo vamos estudar o que isso significa e investigar as
primeiras conseqüências dos axiomas dos reais.
Além disso, vamos definir e estudar os conceitos fundamentais
de limites e séries.
%%}}}

%%{{{ Ordered fields 
\section Corpos ordenados.
%%%{{{ meta 
\label Ordered_fields
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nessa secção, $F$ vai denotar um arbitrário corpo ordenado:

%%}}}

%%{{{ df: ordered_field 
\definition Corpo ordenado.
%%%{{{ meta 
\label ordered_field
\defines
    * corpo!ordenado
    ;;
%%%}}}

Seja $F$ um conjunto, $0,1\in F$, $+$ e $\ntimes$ duas operações
binárias no $F$, e $-$ uma operação unária.
Seja também $P$ uma relação unária no $F$, que identificamos com
seu gráfico: $P \subset F$.
Seu papel é representar os membros \emph{positivos}.
Chamamos o $\cal F = \sset F {+, \,\ntimes\,, -, 0, 1, P}$
um \dterm{corpo ordenado} sse as seguintes leis são satisfeitas:
$$
\align
                        &{0 \neq 1}                                  \tag{FNZ}\\
\\
\pforall {a,b\in F}     &\quantified{a + b \in F}                  \tag{FA0}\\
\pforall {a,b,c\in F}   &\quantified{a + (b + c) = (a + b) + c}    \tag{FA1}\\
\pforall {a \in F}      &\quantified{a + 0 = a}                    \tag{FA2}\\
\pforall {a\in F}       &\quantified{a + (-a) = 0}                 \tag{FA3}\\
\pforall {a,b\in F}     &\quantified{a + b = b + a}                \tag{FA4}\\
\\
\pforall {a,b\in F}     &\quantified{a\ntimes b \in F}                                     \tag{FM0}\\
\pforall {a,b,c\in F}   &\quantified{a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}         \tag{FM1}\\
\pforall {a \in F}      &\quantified{a\ntimes 1 = a}                                       \tag{FM2}\\
\pforall {a\in F}       &\quantified{a\neq 0 \implies \lexists {y\in F} {a \ntimes y = 1}} \tag{FM3*}\\
\pforall {a,b\in F}     &\quantified{a\ntimes b = b \ntimes a}                             \tag{FM4}\\
\\
\pforall {a,b,c \in F}  &\quantified{a\ntimes (b+c) = (a\ntimes b) + (a \ntimes c)}        \tag{FD}\\
\\
\pforall {a \in F}      &\quantifiedt{exatamente uma: $-a \in P$; $a = 0$; $a \in P$}  \tag{FP3}\\
\pforall {a,b\in P}     &\quantified{a + b \in P}                  \tag{FPA}\\
\pforall {a,b\in P}     &\quantified{a\ntimes b \in P}             \tag{FPM}
\endalign
$$

%%}}}

%%{{{ eg: rats_and_reals_are_ordered_fields 
\example.
%%%{{{ meta 
%%%}}}

Os $\rats,\reals$ onde $P_\rats \asseq \rats_{>0}$ e $P_\reals \asseq \reals_{>0}$,
e as operações e os constantes são os usuais.

%%}}}

%%{{{ noneg: compex_order_field_noneg 
\nonexample.
%%%{{{ meta 
\label complex_cannot_by_ordered
%%%}}}

Os complexos não são (\ref[complex_cannot_by_ordered]).

%%}}}

%%{{{ df: gt_in_ordered_fields 
\definition.
%%%{{{ meta 
\label gt_in_ordered_fields
%%%}}}

Definimos a relação binária $<$ num corpo ordenado $F$ pela
$$
x < y \defiff y - x \in P.
$$
Naturalmente definimos as $>, \leq, \geq$ em termos das $<$ e $=$.
Lembre-se a definição da $-$ binária em qualquer anel (\ref[subtraction_in_rings]).

%%}}}

%%{{{ alternative_formalization_of_ordered_fields 
\note Formalização alternativa.
%%%{{{ meta 
\label alternative_formalization_of_ordered_fields
%%%}}}

Em vez de adicionar a relação unária $P$ em nossa estrutura
para representar os membros positivos, podemos considerar a
$$
\cal F = \sset F {+, \,\ntimes\,, -, 0, 1, <}
$$
onde $<$ é uma relação \emph{binária}, cujo papel é representar
a ordem.
Nesse caso vamos precisar substituir as leis (FP$\_$) sobre
o $P$ com leis que afirmam que: $<$ é uma ordem estrita e total:
$$
\align
\pforall {x,y,z \in F}  &\quantified{x<y \mland y<z \implies x<z}  \tag {FOT}\\
\pforall {x,y \in F}    &\quantifiedt{exatamente uma: $x < y$; $x = y$; $x > y$}  \tag {FO3}\\
\intertext{e que comporta bem com as operações:}
\pforall {a,b,c\in F}   &\quantified{a<b \implies a+c < b+c}  \tag{FOA}\\
\pforall {a,b\in F}     &\quantified{0<a \mland 0<b \implies 0 < a\ntimes b}.  \tag{FOM}
\endalign
$$
E podemos definir o conjunto $P$ (ou a relação unária $P$, dependente do ponto
de visto) em termos da ordem $<$, e vice versa, definir a $<$ em termos de $P$:
$$
\xalignat 2
&\gathered
\sset F {+, \,\ntimes\,, -, 0, 1, P} \\
x < y \defiff y-x \in P
\endgathered
&
&\gathered
\sset F {+, \,\ntimes\,, -, 0, 1, <} \\
x \in P \defiff 0 < x.
\endgathered
\endxalignat
$$
As duas abordagens são equivalentes.

%%}}}

%%{{{ remark: rats is an ordered field too 
\remark.
%%%{{{ meta 
%%%}}}

Os números racionais também formam um corpo ordenado.
Ou seja, todas essas leis que listamos até agora,
não são suficientes para determinar os reais, pois
nem conseguem diferencia-los dos racionais.
Falta só um axioma, o axioma da completude,
que realmente vai determinar o conjunto $\reals$.
Mas para entender esse axioma, precisamos primeiro
entender um outro conceito: o \emph{supremum},
e seu conceito dual, o \emph{infimum}.
Faremos essas coisas
nas~\reftag[Infimum_and_supremum_on_reals]--\reftag[Completeness_of_reals].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos agora investigar umas conseqüências dessas leis de corpo ordenado.
Pronto para \emph{descobrir a teoria de corpos ordenados?}

%%}}}

%%{{{ x: ordered_field_trichotomy 
\exercise Tricotomia.
%%%{{{ meta 
\label ordered_field_trichotomy
%%%}}}

Para todo $a,b\in F$, exatamente uma das
$$
a < b;\qquad
a = b;\qquad
a > b;
$$
é válida.

%%}}}

%%{{{ x: ordered_field_transitivity 
\exercise Transitividade.
%%%{{{ meta 
\label ordered_field_transitivity
%%%}}}

A $<$ é uma relação transitiva:
$a < b \mland b < c \implies a < c$.

%%}}}

%%{{{ x: ordered_field_plus_c_monotone 
\exercise.
%%%{{{ meta 
\label ordered_field_plus_c_monotone
%%%}}}

Se $a < b$ então $a + c < b + c$.

%%}}}

%%{{{ x: ordered_field_times_positive_c_monotone 
\exercise.
%%%{{{ meta 
\label ordered_field_times_positive_c_monotone
%%%}}}

Se $a < b \mland c > 0$ então $ac < bc$.

%%}}}

%%{{{ x: ordered_field_product_of_negatives_is_positive 
\exercise.
%%%{{{ meta 
\label ordered_field_product_of_negatives_is_positive
%%%}}}

Se $a,b < 0$ então $ab > 0$.

%%}}}

%%{{{ x: ordered_field_square_of_nonzero_is_positive 
\exercise.
%%%{{{ meta 
\label ordered_field_square_of_nonzero_is_positive
%%%}}}

Se $a\neq 0$ então $a^2 > 0$.

%%}}}

%%{{{ x: ordered_field_one_is_greater_than_zero 
\exercise.
%%%{{{ meta 
\label ordered_field_one_is_greater_than_zero
%%%}}}

$1 > 0$.

%%}}}

%%{{{ x: ordered_field_times_negative_c_antimonotone 
\exercise.
%%%{{{ meta 
\label ordered_field_times_negative_c_antimonotone
%%%}}}

Se $a < b \mland c < 0$ então $ac > bc$.

%%}}}

%%{{{ x: ordered_field_negate_is_antimonotone 
\exercise.
%%%{{{ meta 
\label ordered_field_negate_is_antimonotone
%%%}}}

Se $a < b$ então $-a > -b$.

%%}}}

%%{{{ x: ordered_field_negate_of_negative_is_positive 
\exercise.
%%%{{{ meta 
\label ordered_field_negate_of_negative_is_positive
%%%}}}

Se $a < 0$ então $-a > 0$.

%%}}}

%%{{{ x: ordered_field_product_positive_means_samesign 
\exercise.
%%%{{{ meta 
\label ordered_field_product_positive_means_samesign
%%%}}}

Se $ab > 0$ então $a,b$ são ou ambos positivos ou ambos negativos.

%%}}}

%%{{{ x: ordered_field_add_side_by_side 
\exercise.
%%%{{{ meta 
\label ordered_field_add_side_by_side
%%%}}}

Se $a < c \mland b < d$ então $a + b < c + d$.

%%}}}

%%{{{ x: complex_cannot_be_ordered_in_disguise 
\exercise.
%%%{{{ meta 
\label complex_cannot_be_ordered_in_disguise
%%%}}}

Não existe $x\in F$ com $x^2 + 1 = 0$.

%%}}}

%%{{{ x: sum_of_squares_in_ordered_field 
\exercise.
%%%{{{ meta 
\label sum_of_squares_in_ordered_field
%%%}}}

Para todo $a,b\in F$, temos $a^2 + b^2 \geq 0$.
Ainda mais: $a^2 + b^2 = 0$ sse $a = b = 0$.

%%}}}

%%{{{ x: order_fields_are_unbounded 
\exercise.
%%%{{{ meta 
\label order_fields_are_unbounded
%%%}}}

O $F$ não tem nem mínimo, nem máximo.

%%}}}

%%{{{ x: only_zero_is_leq_than_all_positives 
\exercise.
%%%{{{ meta 
\label only_zero_is_leq_than_all_positives
%%%}}}

Se $x$ tem a propriedade que $0 \leq x < \epsilon$
para todo $\epsilon > 0$, então $x = 0$.

%%}}}

%%{{{ df: abs_in_ordered_fields 
\definition.
%%%{{{ meta 
\label abs_in_ordered_fields
%%%}}}

Definimos a operação $\abs{\dhole} : F \to F$ num corpo ordenado $F$ pela
$$
\abs x \defeq
\knuthcases {
x,  & se $x\geq 0$ \cr
-x, & se não.
}
$$

%%}}}

%%{{{ x: ordered_field_abs_lemma 
\exercise.
%%%{{{ meta 
\label ordered_field_abs_lemma
%%%}}}

Sejam $x,w\in F$.  Logo
$$
\abs x \leq w
\iff
-w \leq x \leq w.
$$

%%}}}

%%{{{ x: ordered_field_triangular_inequality 
\exercise Desigualdade triangular.
%%%{{{ meta 
\label ordered_field_triangular_inequality
%%%}}}

Sejam $x,y,z\in F$.  Logo:
$$
\gather
\abs{x + y} \leq \abs x + \abs y \\
\bigabs{\abs x - \abs y} \leq \abs{x - y} \\
\abs{x - z} \leq \abs{x - y} + \abs{y - z}.
\endgather
$$

%%}}}

\TODO Corpos arquimedeanos.

%%{{{ Models 
\note Modelos.
%%%{{{ meta 
\defines
    * modelo
    ;;
%%%}}}

Temos dois exemplos principais de corpos ordenados,
viz.~os reais e os racionais:
ámbos têm toda a estrutura exigida, e satisfazem todos os axiomas.
Em palavras mais formais, eles são o que a gente chama
de \dterm{modelos} de corpos ordenados.

%%}}}

%%{{{ Q: how_can_we_separate_reals_from_rats
\question.
%%%{{{ meta 
\label how_can_we_separate_reals_from_rats
%%%}}}

Podemos adicionar alguma lei capaz de separar os reais dos racionais?
Ou seja, chegar numa estrutura com leis mais exigentes, tais que
os reais vão ser um modelo, mas os racionais não.

%%}}}

\spoiler

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Responder nessa pergunta neste momento é um grande desafio.\foot
Vai desistir de pensar em alguma resposta por causa disso?
\toof
Mas já estamos prontos para encontrar o que falta para
a pergunta virar mais fácil~(\reftag[Infimum_and_supremum_on_reals])
e finalmente chegar numa resposta (\reftag[Completeness_of_reals]).

%%}}}

\endsection
%%}}}

%%{{{ Infimum and supremum 
\section Infimum e supremum.
%%%{{{ meta 
\label Infimum_and_supremum_on_reals
%%%}}}

%%{{{ df: lower_and_upper_bounds_reals 
\definition Lower e upper bounds.
%%%{{{ meta 
\label lower_and_upper_bounds_reals
\defines
    * \lbs {~A}  -- o conjunto de todos os lower bounds de $A$
    * ~A \leq ~x  -- $x$ é um upper bound de $A$
    * ~x \leq ~A  -- $x$ é um lower bound de $A$
    * \ubs {~A}  -- o conjunto de todos os upper bounds de $A$
    * bounded!above
    * bounded!below
    * bound!lower
    * bound!upper
    * limitado!por baixo
    * limitado!por cima
    * limitante!por baixo
    * limitante!por cima
    ;;
%%%}}}

Seja $A\subset \reals$.
Chamamos o $x$ um \dterm{lower bound} de $A$ sse $x \leq a$ para todo $a \in A$,
e \emph{dualmente} $x$ é um \dterm{upper bound} de $A$ sse $x \geq a$ para todo $a \in A$:
$$
\align
\text{$x$ é um lower bound de $A$} &\defiff \lforall {a\in A} {x \leq a} \\
\text{$x$ é um upper bound de $A$} &\defiff \lforall {a\in A} {a \leq x}.
\endalign
$$
Abusando a notação escrevemos $x \leq A$ e $A \leq x$:
$$
\align
x \leq A &\defiff \lforall {a \in A} {x \leq a} \\
A \leq x &\defiff \lforall {a \in A} {a \leq x}.
\endalign
$$
Denotamos o conjunto de todos os lower bounds de $A$ por $\lbs A$,
e dualmente usamos $\ubs A$ para o conjunto de todos os seus upper bounds:
$$
\align
\lbs A &\defeq \setst {x \in \reals} {x \leq A} \\
\ubs A &\defeq \setst {x \in \reals} {A \leq x}.
\endalign
$$
Se um $A$ tem pelo menos um limitante por cima, dizemos que $A$
é \dterm{limitado por cima} (ou, \dterm{bounded above});
e se tem pelo menos um limitante por baixo, \dterm{limitado por baixo}
(ou, \dterm{bounded below}).

%%}}}

%%{{{ df: inf_sup_reals 
\definition infimum; supremum.
%%%{{{ meta 
\label inf_sup_reals
\defines
    * \glb {~A}  -- o greatest lower bound de $A\subset\reals$
    * \inf {~A}  -- o infimum de $A\subset\reals$
    * \lub {~A}  -- o least upper bound de $A\subset\reals$
    * \overline{\reals}  -- os reais estendidos: $\reals\union\set{\minfty,\pinfty}$
    * \sup {~A}  -- o supremum de $A\subset\reals$
    * greatest lower bound!reais
    * infimum!reais
    * least upper bound!reais
    * reais!estendidos
    * supremum!reais
    ;;
%%%}}}

Definimos os $\inf A$ e $\sup A$ pelas:
$$
\align
\text{$x$ é um infimum  de $A$} &\defiff x \leq A \mland \lforall {w \leq A} {w \leq x} \\
\text{$x$ é um supremum de $A$} &\defiff x \geq A \mland \lforall {w \geq A} {x \leq w}.
\endalign
$$
Mais curtamente:
$$
\xalignat 2
\inf A &\defeq \max {\lbs A} &
\sup A &\defeq \min {\ubs A}.
\intertext{Outros nomes (e notações correspondentes) desses dois conceitos
são muito comuns e vamos ficar os usando também:
o infimum é chamado também de \dterm{greatest lower bound} e o supremum
de \dterm{least upper bound}, e denotados por $\glb$ e $\lub$ respectivamente:}
\glb A &\defeq \inf A & 
\lub A &\defeq \sup A.
\endxalignat
$$

%%}}}

%%{{{ warning: later on we'll meet even more names and notations 
\warning.
%%%{{{ meta 
%%%}}}

No~\ref[Posets_Lattices] encontramos ainda mais nomes e notações!

%%}}}

%%{{{ remark: inf and sup are partial 
\remark.
%%%{{{ meta 
%%%}}}

Observe que assim, $\inf$ e $\sup$ não são operações totais nos reais,
mas \emph{parciais:}
$$
\inf,\sup \eqtype \pset \reals \parto \reals.
$$
Ou seja, ninguém garanta que para qualquer
$A\subset\reals$ existe mesmo um real $x$ que satisfaz as
condições das definições acima.
Mas se existem, são únicos~(\ref[inf_and_sup_are_unique]):

%%}}}

%%{{{ thm: inf_and_sup_are_unique 
\theorem.
%%%{{{ meta 
\label inf_and_sup_are_unique
%%%}}}

Seja $A \subset \reals$.
Se $A$ tem infimum, ele é único.
Dualmente, se $A$ tem supremum, ele é único.

\proof.
Por fight club: suponha $\ell, \ell'$ são infima, logo $\ell \leq \ell'$
pois $\ell'$ é maior que qualquer lower bound, e $\ell$ é um lower bound.
No outro lado $\ell' \leq \ell$ pois $\ell$ é maior que qualquer lowe bound,
e $\ell'$ é um lower bound.  Logo $\ell \leq \ell'$ e $\ell' \leq \ell$
e pela antissimetria da $\leq$ temos $\ell = \ell'$.

%%}}}

%%{{{ The extended reals 
\note Os reais estendidos.
%%%{{{ meta 
\label extended_reals
%%%}}}

Agora, se $A$ não é bounded below e se $A$ não é bounded above escrevemos
$$
\xalignat 2
\inf A &= \minfty &
\sup A &= \pinfty
\endxalignat
$$
respectivamente.
Isso é bem justificável se pensar no $\reals$ apenas como um conjunto
(parcialmente) ordenado enriquecido por dois novos objetos:
o $\minfty$ e o $\pinfty$ chegando assim no conjunto
$$
\set{\minfty}\union\reals\union\set{\pinfty}
$$
que ordenamos assim:
$$
\minfty < x < \pinfty, \quad\text{para todo $x\in\reals$}.
$$
Chamamos os membros do $\reals\union\set{\minfty,\pinfty}$
de \dterm{reais estendidos} e denotamos esse conjunto por
$\overline{\reals}$ e $[\minfty,\pinfty]$ também.
Podemos considerar ambas as operações então como
$$
\inf,\sup \eqtype \pset \reals \parto [\minfty,\pinfty].
$$

%%}}}

%%{{{ x: inf_in_set_implies_min 
\exercise.
%%%{{{ meta 
\label inf_in_set_implies_min
%%%}}}

Seja $A \subset \reals$.
Demonstre que:
(i) se $\inf A \in A$ então $\inf A = \min A$;
(ii) a dual da (i).

%%}}}

%%{{{ x: lbs_and_ubs_are_empty_or_infinite 
\exercise.
%%%{{{ meta 
\label lbs_and_ubs_are_empty_or_infinite
%%%}}}

Seja $A \subset \reals$.
Demonstre que $\lbs A$ é vazio ou infinito, e a mesma coisa sobre o $\ubs A$.

%%}}}

%%{{{ x: a_set_with_nats_as_limit_points 
\exercise.
%%%{{{ meta 
\label a_set_with_nats_as_limit_points
%%%}}}

Considere o conjunto
$$
A = \setlst {m + \frac 1 {2^n}} {m \in \nats, n \in \nats_{>0}}.
$$
(i) Visualize o $A$ na linha dos reais, e rascunhe seu desenho.
(ii) Ache o $\inf A$ e $\sup A$ se são definidos.

%%}}}

%%{{{ x: inf_sup_reals_extreme_cases 
\exercise.
%%%{{{ meta 
\label inf_sup_reals_extreme_cases
%%%}}}

Pode acontecer que para algum $A\subset\reals$ temos\dots
\tlist:
\li (i):  $\inf A = \sup A$?
\li (ii): $\inf A > \sup A$?
\endtlist
Se sim, quando?
Se não, por que não?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E agora\dots
Será que podes pensar numa resposta para
a~\ref[how_can_we_separate_reals_from_rats]?

%%}}}

\spoiler

\endsection
%%}}}

%%{{{ Completude 
\section Completude.
%%%{{{ meta 
\label Completeness_of_reals
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora temos tudo que precisamos para responder
a~\ref[how_can_we_separate_reals_from_rats].
Nossa resposta com palavras de rua é
\standout
\emph{os reais não têm ``buracos''}
\endstandout
mas precisamos formalizar essa afirmação.\foot
No~\ref[Cantors_paradise] encontramos uma outra
resposta a~\ref[how_can_we_separate_reals_from_rats],
de natureza completamente diferente.  Paciência!
\toof
A idéia é exigir que \emph{não falta nenhum supremum}---ou, dualmente,
nenhum infimum, pois é a mesma coisa:
uma afirmação acaba implicando a outra.
Mas o que quis dizer que não falta nenhum supremum?
E, nenhum mesmo?  Não.
Um conjunto que nem é bounded above não tem chances de ter supremum.
Vamos exigir suprema de todos os outros então:

%%}}}

%%{{{ df: complete_ordered_field 
\definition Corpo ordenado completo.
%%%{{{ meta 
\label complete_ordered_field
\defines
    * corpo!ordenado, completo
    ;;
%%%}}}

Um corpo ordenado $R$ é \dterm{completo} sse
todos os seus subconjuntos bounded above possuem supremum no $R$
$$
\align
\pforall {A\subset R} &\quantified{\text{$A\neq\emptyset$} \mland \text{$A$ bounded above} \implies \text{$A$ tem supremum no $R$}}. \tag{FC}
\endalign
$$

%%}}}

%%{{{ eg: reals_is_a_complete_ordered_field 
\example.
%%%{{{ meta 
\label reals_is_a_complete_ordered_field
%%%}}}

Os reais $\sset \reals {+, \,\ntimes\,, -, 0, 1, <}$.

%%}}}

%%{{{ x: can_we_prove_that_reals_is_a_complete_ordered_field 
\exercise.
%%%{{{ meta 
\label can_we_prove_that_reals_is_a_complete_ordered_field
%%%}}}

Tem como demonstrar isso?
Se sim, o que seria uma prova disso?
Se não, por que não?

%%}}}

%%{{{ noneg: rats_is_not_a_complete_ordered_field 
\nonexample.
%%%{{{ meta 
\label rats_is_not_a_complete_ordered_field
%%%}}}

Os racionais!

%%}}}

%%{{{ x: rats_is_not_a_complete_ordered_field_proof 
\exercise.
%%%{{{ meta 
\label rats_is_not_a_complete_ordered_field_proof
%%%}}}

Demonstre!
Ou seja, ache um $A$ bounded above sem supremum
no $\rats$.

%%}}}

%%{{{ remark: now inf and sup are total operations on extended reals 
\remark.
%%%{{{ meta 
%%%}}}

Assim as operações $\inf$ e $\sup$ virar totais nos reais estendidos:
$$
\inf,\sup \eqtype \pset\reals \to \reals\union\set{\minfty,\pinfty}.
$$

%%}}}

%%{{{ thm: bounded_below_subsets_have_infima 
\theorem.
%%%{{{ meta 
\label bounded_below_subsets_have_infima
%%%}}}

Sejam $R$ um corpo ordenado completo e $A \subset R$
bounded below.  Logo $A$ possui infimum no $R$.

\proof Demontrado no~\ref[bounded_below_subsets_have_infima_proof].

%%}}}

%%{{{ x: bounded_below_subsets_have_infima_proof 
\exercise.
%%%{{{ meta 
\label bounded_below_subsets_have_infima_proof
%%%}}}

Demonstre o~\ref[bounded_below_subsets_have_infima].

\hint
Tu vai precisar usar a lei de completude.

\hint
Procure definir um subconjunto de $\reals$
que será garantido ter um supremum, e use
esse supremum para definir o infimum de $A$.

%%}}}

%%{{{ Enough! 
\note Chega!.
%%%{{{ meta 
%%%}}}

Vamos revisar pouco a situação com as estruturas que estudamos até agora.
Como a gente escolha os axiomas (leis) que botamos nas nossas definições?
As mais leis que eu boto, as mais ferramentas que ganho para matar mais
teoremas.  Minha teoria vai acabar sendo capaz de demonstrar mais coisas,
mas o preço que pago para isso são modelos!
\eop
Quantos monóides encontramos?  Demais!  Todos os grupos são monóides,
e a gente já encontrou ainda mais monóides que não são grupos (lembra?).
E grupos?
``Menos'', mas muitos também!
E grupos abelianos?
Provamos mais teoremas, mas temos menos exemplos de grupos abelianos.
E anéis?  E anéis comutativos?  E domínios de integridade?
Cada vez que adicionamos restricções (leis), a teoria correspondente
cresce, e a colecção de models diminui.
E corpos?
Ainda encontramos vários modelos: racionais, reais, complexos, inteiros
módulo primo $p$, \dots
\eop
E corpos ordenados?
Aqui ganhamos muita teoria graças a ordem, mas perdemos os complexos e os
inteiros módulo $p$, mas ainda temos os reais e os racionais e mais
uns modelos, mas já estamos percebendo que fica mais e mais difícil
achar modelos \emph{realmente} diferentes que satisfazem todas as leis!
\eop
E agora?
Adicionamos mais uma lei: o axioma da completude; e assim chegamos nos
\emph{corpos ordenados completos}.  E agora \emph{chega!}
Estamos num ponto onde adicionamos tantos axiomas que nosso conceito
foi tão exigente que perdemos todos os modelos exeto um: os reais!
Realmente não encontramos outro exemplo, mas isso não quis dizer que
não existem outros modelos.  Certo?  Certo, mas acontece que nessa
situação não é o caso: \emph{essencialmente existe apenas um
único corpo ordenado completo: os reais!}

%%}}}

%%{{{ Q: what does "essentially" mean above? 
\question.
%%%{{{ meta 
%%%}}}

O que significa a palavra \wq{essencialmente} acima?

%%}}}

\spoiler

%%{{{ thm: uniqueness_of_complete_ordered_field 
\theorem Unicidade.
%%%{{{ meta 
\label uniqueness_of_complete_ordered_field
%%%}}}

Se $R,R'$ são corpos ordenados completos então $R,R'$ são isómorfos.

\sketch.
Sejam
$\sset R    {+, \;\ntimes\;, -, 0, 1, <}$ e
$\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}$
corpos ordenados completos.
Precisamos definir um isomorfismo
$$
\phi
\eqtype
\sset R    {+, \;\ntimes\;, -, 0, 1, <}
\longtoby{\iso}
\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}.
$$
Obviamente botamos
$$
\align
\phi0 &= 0' \\
\phi1 &= 1'
\intertext{Isso já determina a $\phi$ no resto dos
``naturais'' $N\subset R$:}
\phi2 &= \phi(1 + 1) = \phi1 + \phi1 = 1' + 1' = 2' \\
\phi3 &= \phi(2 + 1) = \phi2 + \phi1 = 2' + 1' = 3' \\
&\eqvdots \\
\phi(n+1) &= \phi n + \phi1 = n' + 1' \\
&\eqvdots
\endalign
$$
ou seja, a $\phi$ (restrita no $N$) necessariamente embute
isomorficamente o $N\subset R$ no $\img \phi N = N' \subset R'$:
$$
\phi \restosub N : N \isoto N'.
$$
Agora, como $\phi$ é homomorfismo, temos
$$
\phi(-x) = \mathord{-'}(\phi x)
\quad\text{para todo $x\in R$},
$$
e logo a $\phi$ necessariamente embute os ``inteiros''
$Z\subset R$ nos ``inteiros'' $Z' \subset R'$:
$$
\phi \restosub Z : Z \isoto Z'.
$$
Definimos a $\phi$ nos ``racionais'' $Q\subset R$ assim:
$$
\phi(m/n)
= \phi(m \ntimes \ginv n)
= \phi m \ntimes' \ginvp{\phi n}
= \phi m \ntimes' \phi (\ginv n)
= \phi m \mathbin{/'} \phi n
$$
e logo
$$
\phi \restosub Q : Q \isoto Q'.
$$
Estamos perto!
Basta só definir a $\phi$ nos ``buracos'' (nos ``irracionais'')
de $R$ e pronto!

%}}}

%%{{{ remark: we cannot finish this proof right now 
\remark.
%%%{{{ meta 
%%%}}}

Infelizmente, por enquanto não temos todo o armamento para matar
os detalhes e o que falta no esboço, mas é importante entender
pelo menos tudo que tá lá.  Voltamos nesse assunto
no~\ref[Axiomatic_set_theory]~(\reftag[Constructing_more_numbers]).

%%}}}

%%{{{ warning: does_a_complete_ordered_field_exist_warning 
\warning.
%%%{{{ meta 
\label does_a_complete_ordered_field_exist_warning
%%%}}}

Mesmo se aceitar que quaisquer corpos ordenados completos são
isomorfos (o~\ref[uniqueness_of_complete_ordered_field]), ainda
temos um ponto que roubamos: para existir único, precisamos duas
coisas: \emph{pelo menos} um; \emph{no máximo} um.
O~\reftag[uniqueness_of_complete_ordered_field] realmente ofereceu
a segunda coisa; mas a primeira?
Qual foi tua resolução
do~\ref[can_we_prove_that_reals_is_a_complete_ordered_field]
mesmo?
Voltamos nesse assunto
no~\ref[Axiomatic_set_theory]~(\reftag[Constructing_more_numbers]).

%%}}}

\endsection
%%}}}

%%{{{ The reals 
\section Os reais.
%%%{{{ meta 
\label The_reals_axioms
%%%}}}

%%{{{ Calculus, the real deal 
\note Calculus, real e oficial.
%%%{{{ meta 
\defines
    * calculus
    * análise!real
    ;;
%%%}}}

Como começamos a teoria dos grupos no~\ref[Group_theory]?
Apresentamos os axiomas dos grupos e continumos investigando
suas conseqüências.  A colecção dessas conseqüências (teoremas)
é exatamente o que chamamos de \dterm{teoria}.
E a \emph{teoria dos anéis} é feita por todos os teoremas
que seguem pelos axiomas de anéis; etc.~etc.
E a \emph{teoria dos corpos ordenados completos?}
Ela não é muito famosa por esse nome, mas com certeza
tu já ouviste falar dela por uns dos seus apelidos:
\dterm{calculus},
ou \dterm{análise real}, etc.
Na abordagem axiomática, não nos importa \emph{definir}\/ ou
\emph{construir} os objetos que vamos chamar de \dterm{números reais}.
Começamos aceitando a existência dum certo conjunto que denotamos
por $\reals$, suas operações binárias de adição e multiplicação,
seu zero $0$ e seu um $1$, e seu subconjunto $P$ cujos membros
chamamos de \dterm{positivos}.
Estipulamos os axiomas seguintes.

%%}}}

%%{{{ ax: closedness 
\axiom Fechado.
%%%{{{ meta 
%%%}}}

O $\reals$ é fechado sobre $+$ e $\,\ntimes\,$.

%%}}}

%%{{{ ax: associativity 
\axiom Associatividade.
%%%{{{ meta 
%%%}}}

As $+$ e $\ntimes$ são associativas.

%%}}}

%%{{{ ax: identities 
\axiom Identidades.
%%%{{{ meta 
%%%}}}

As $+$ e $\ntimes$ têm os distintos $0$ e $1$ como
identidades respectivamente.

%%}}}

%%{{{ ax: inverses 
\axiom Inversos.
%%%{{{ meta 
%%%}}}

Todo $a\in \reals$ tem $+$-inverso (denotado por $-a$)
e todo $a\neq 0$ tem $\,\ntimes\,$-inverso (denotado por $a^{-1}$).

%%}}}

%%{{{ ax: commutativity 
\axiom Comutatividade.
%%%{{{ meta 
%%%}}}

As $+$ e $\ntimes$ são comutativas.

%%}}}

%%{{{ ax: distributivity 
\axiom Distributividade.
%%%{{{ meta 
%%%}}}

A $\ntimes$ é distributiva sobre a $+$.

%%}}}

%%{{{ ax: positive closedness 
\axiom Positivamente fechado.
%%%{{{ meta 
%%%}}}

O $P$ é fechado sobre $+$ e $\,\ntimes\,$.

%%}}}

%%{{{ ax: trichotomy 
\axiom Tricotomia.
%%%{{{ meta 
%%%}}}

Para todo $x \in \reals$ exatamente uma das afirmações seguintes é válida:
$-x$ é positivo; $x=0$; $x$ é positivo.

%%}}}

%%{{{ ax: completeness 
\axiom Completude.
%%%{{{ meta 
%%%}}}

Todo conjunto $A\neq\emptyset$ de reais que é limitado por cima,
tem um supremum, ou seja, existe real $b\in\reals$ tal que $b = \sup A$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ou seja, estipulamos o seguinte:
\standout
\proclaimstyle $\reals$ é um corpo ordenado completo.
\endstandout

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

As conseqüências desses axiomas é o que estudamos em
\dterm{calculus} e \dterm{análise real}.
O resto desse capítulo é um teaserzinho dessa teoria linda demais;
e, como sempre, no fim tenho ponteiros na literatura para mergulhar mais.
No~\ref[Metric_spaces] voltamos nessa investigação de análise real,
pois estudamos a teoria dos \emph{espaços métricos}:
conjuntos equipados com uma noção de distância, ou seja,
uma funcção binária \emph{com valores reais}, satisfazendo certas leis.

%%}}}

%%{{{ thm: reals_is_archimedean 
\theorem.
%%%{{{ meta 
\label reals_is_archimedean
%%%}}}

O $\reals$ é um corpo arquimedeano, ou seja:
para todo $x,y\in\reals$,
$$
x \neq 0
\implies
\lexists {n \in \nats} {xn > y}.
$$

%%}}}

\TODO sketch.

%%{{{ thm: rats_dense_in_reals 
\theorem.
%%%{{{ meta 
%%%}}}

Os racionais são densos nos reais, ou seja:
para todo $x,y\in \reals$,
$$
x < y
\implies
\lexists {q \in \rats} {x < q < y}.
$$

%%}}}

\TODO sketch.

\endsection
%%}}}

%%{{{ Limits_of_reals 
\section Limites.
%%%{{{ meta 
\label Limits_of_reals
%%%}}}

%%{{{ df: epsilon_close_ball_hood 
\definition ε-perto, ε-bola, ε-vizinhança.
%%%{{{ meta 
\label epsilon_close_ball_hood
\defines
    * \ball {~\epsilon} {~{x_0}}  -- a $\epsilon$-bola do $x_0$
    * bola!de real
    * perto!de real
    * vizinhança!de real
    ;;
%%%}}}

A distância entre dois $x,y\in\reals$ é calculada por $\abs{x-y}$.
Sejam $x,y\in\reals$ e $\epsilon > 0$.
Dizemos que
$$
\text{$x$ é $\epsilon$-perto do $y$}
\defiff
\abs{x-y} < \epsilon.
$$
Observe que a relação é simétrica (\ref[epsilon_close_is_symmetric])
e logo podemos escrever também:
$$
\text{$x,y$ são $\epsilon$-perto}.
$$
Dado um ponto $x_0\in\reals$, o conjunto de todos os pontos que
são $\epsilon$-perto do $x_0$ é chamada \dterm{$\epsilon$-bola}
ou \dterm{$\epsilon$-vizinhança} do $x_0$:
$$
\ball \epsilon {x_0}
\defeq
\setstt {x \in \reals} {$x,x_0$ são $\epsilon$-perto}.
$$
Também chamamos de \dterm{bola com centro $x_0$ e raio $\epsilon$}.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Os $1$ e $2/3$ são $1/2$-perto;
a $1/3$-bola do $\sqrt 2$ é o intervalo $(\sqrt2 - 1/3, \sqrt2 + 1/3)$.

%%}}}

%%{{{ x: epsilon_close_is_reflexive 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_reflexive
%%%}}}

Dado $\epsilon > 0$, seja $\sim_\epsilon$ a relação definida pela
$$
x \sim_\epsilon y
\defiff
\text{$x$ é $\epsilon$-perto do $y$}.
$$
Demonstre que $\sim_\epsilon$ é reflexiva.

\hint
$$
\abs{x - x} = 0
$$

%%}}}

%%{{{ x: epsilon_close_is_symmetric 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_symmetric
%%%}}}

Dado $\epsilon > 0$, a $\sim_\epsilon$
do~\ref[epsilon_close_is_reflexive] é simétrica,
e logo podemos escrever frases como
$$
\text{<<os $x,y$ são $\epsilon$-perto>>}.
$$

\hint
Olha:
$$
\abs{x - y}
= \abs{-(y - x)}
= \abs{y - x}
$$
Dá pra justificar ambas as $=$?

%%}}}

%%{{{ x: epsilon_close_is_not_an_equivalence_relation 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_not_an_equivalence_relation
%%%}}}

A $\sim_\epsilon$ do~\ref[epsilon_close_is_reflexive]
é uma relação de equivalência para qualquer $\epsilon$?

\hint
Não!
Já fez o~\ref[distance_like_not_transitive]?

%%}}}

%%{{{ df: for_sufficiently_large_values_of 
\definition <<para valores suficientemente grandes de>>.
%%%{{{ meta 
\label for_sufficiently_large_values_of
%%%}}}

Seja $R(n)$ uma afirmação sobre um natural $n$.
Dizemos que $R(n)$ \dterm{para valores suficientemente grandes de} $n$
sse a partir dum natural $n_0$ todos os naturais satisfazem a $R$,
ou seja, sse
$$
\pexists {n_0\in\nats}
\lforall {i \geq n_0}
{R(i)}.
$$

%%}}}

%%{{{ df: limit_of_sequence_of_reals 
\definition limite.
%%%{{{ meta 
\label limit_of_sequence_of_reals
\defines
    * ~{\seqn a n} \limto ~\ell  -- a seqüência $\seqn a n$ tende ao $\ell$
    * limite!reais
    ;;
%%%}}}

Seja $\seqn a n$ uma seqüência de reais e seja $\ell\in\reals$.
Dizemos que $\seqn a n$ \dterm{tende ao limite} $\ell$
sse a partir dum membro $a_N$, todos os seus membros
ficam $\epsilon$-perto do $\ell$.
Ou seja:
$$
\seqn a n \limto \ell
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i \geq N}
{$a_i$ é $\epsilon$-perto de $\ell$}.
$$
Escrevemos
$$
\liml_n a_n = \ell
$$
como sinônimo de $\seqn a n \limto \ell$.
\mistake

%%}}}

%%{{{ remark: n nought 
\remark.
%%%{{{ meta 
%%%}}}

É muito comum usar o nome \symq{$n_0$}
onde usei o \symq{$N$} na~\ref[limit_of_sequence_of_reals].
O \symq{$n_0$} é freqüêntemente lido ``$n$ nought'' em inglês.

%%}}}

%%{{{ Alternating quantifiers
\note Quantificadores alternantes.
%%%{{{ meta 
%%%}}}

Provavelmente essa foi a primeira definição que tu encontraste
que necessitou três alternações de quantificadores:
$$
\forall\dots\exists\dots\forall\dots
$$
Para cada alteração de quantificação que seja adicionada
numa afirmação, o processo de digeri-la naturalmente fica
mais complicado para nossa mente!
Com experiência, \dterm{matemalhando}, essas definições
com três quantificadores ficarão mais e mais digeríveis.
Mesmo com essa experiência, num momento vamos encontrar
uma afirmação com \emph{quatro} quantificações alternantes,
e a dificuldade vai voltar e te lembrar dessa dificuldade
que sentes agora.
Felizmente, temos as ferramentas formais de lógica matemática
que nos permitem trabalhar com proposições sem digeri-las
completamente!

%%}}}

%%{{{ x: limit_of_sequence_of_reals_uniqueness_needed 
\exercise.
%%%{{{ meta 
\label limit_of_sequence_of_reals_uniqueness_needed
%%%}}}

Qual o problema com a~\ref[limit_of_sequence_of_reals]?

\hint
O problema fica na
$$
\liml_n a_n = \ell.
$$
Qual é?

\solution
Precisamos demonstrar a unicidade dos limites para usar
o símbolo \symq{$=$} da \emph{igualdade}.  Pois, se uma
seqüência tende a dois limites
$$
\xalignat2
\seqn a n &\limto \ell &
\seqn a n &\limto \ell'
\endxalignat
$$
com $\ell = \ell'$, então escrevendo
$$
\xalignat2
\liml_n a_n &= \ell &
\liml_n a_n &= \ell'
\endxalignat
$$
teriamos (pela simetria e transitividade da igualdade)
$\ell = \ell'$, contradizendo nossa hipótese.

%%}}}

%%{{{ eg: ones tends to one 
\example.
%%%{{{ meta 
%%%}}}

A seqüência $1, 1, 1, \dotsc$ tende ao limite $1$.

\solution.
Seja $\epsilon>0$.
O desafio é achar $N \in \nats$ tal que a partir de $N$,
todos os membros da seqüência são $\epsilon$-perto de $1$.
Tome $N \asseq 0$, e seja $n \geq N$.
Obviamente o $n$-ésimo termo da seqüência é $\epsilon$-perto
do $1$ pois, ele é igual ao $1$ mesmo e logo a distância
deles é $0$, e logo menor que $\epsilon$.
Observe que qualquer escolha de $N$ aqui seria correta!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Como tu já resolveste
o~\ref[limit_of_sequence_of_reals_uniqueness_needed] (né?)
tu sabes que precisamos demonstrar a unicidade dos limites.
E a existência?
A existência não é garantida (vamos descobrir isso agora
no~\ref[alternating_zero_one_does_not_have_a_limit]),
então precisamos tomar cuidado com o símbolo $\lim$:
é um operador \emph{parcial}.

%%}}}

%%{{{ x: alternating_zero_one_does_not_have_a_limit 
\exercise.
%%%{{{ meta 
\label alternating_zero_one_does_not_have_a_limit
%%%}}}

A seqüência $0,1,0,1,\dotsc$, formalmente definida pela
$$
a_n = \knuthcases {
0, & se $n$ par \cr
1, & caso contrário.
}
$$
tende àlgum limite?
Se sim, ache e demonstre; se não, refute.

\hint
Não tende a limite nenhum!
Como podemos demonstrar isso?

\hint
Demonstre que para qualquer possível limite $\ell \in \reals$,
$$
\seqn a n \ntendsto \ell.
$$

%%}}}

%%{{{ thm: uniqueness_of_limits_of_reals 
\theorem unicidade de limites.
%%%{{{ meta 
\label uniqueness_of_limits_of_reals
%%%}}}

Uma seqüência não pode ter mais que um limite.
Formalmente, seja $\seqn a n$ seqüência de reais tal que
$$
\xalignat 2
\seqn a n &\limto \ell_1 &
\seqn a n &\limto \ell_2.
\endxalignat
$$
Então $\ell_1 = \ell_2$.

\proof.
Graças ao~\ref[only_zero_is_leq_than_all_positives] basta demonstrar
que $\abs{\ell_1 - \ell_2} < \epsilon$ para todo $\epsilon > 0$.
Seja $\epsilon > 0$ então, e agora observe que para quaisquer
$\epsilon_1,\epsilon_2>0$ podemos escolher $N_1,N_2$ tais que:
$$
\xalignat 2
\pforall {i \geq N_1} &\quantified{\abs{a_i - \ell_1} < \epsilon_1} &
\pforall {j \geq N_2} &\quantified{\abs{a_j - \ell_2} < \epsilon_2}.
\endxalignat
$$
Tome $N \asseq \max\set{N_1, N_2}$.
Logo
$$
\xalignat 2
\abs{a_N - \ell_1} &< \epsilon_1 &
\abs{a_N - \ell_2} &< \epsilon_2.
\endxalignat
$$
Observando que $\abs{a_N - \ell_1} = \abs{\ell_1 - a_N}$
e somando as desigualdades por lados temos
$$
\abs{\ell_1 - a_N} + \abs{a_N - \ell_2} < \epsilon_1 + \epsilon_2.
$$
Mas
$$
\mubrace {\abs{\ell_1 - a_N + a_N - \ell_2}} {\abs{\ell_1 - \ell_2}}
\leq \abs{\ell_1 - a_N} + \abs{a_N - \ell_2}
< \epsilon_1 + \epsilon_2.
$$
Lembre-se que isso é válido para quaisquer $\epsilon_1,\epsilon_2>0$, então
basta selecioná-los para satisfazer $\epsilon_1+\epsilon_2\leq\epsilon$
(tome pore exemplo ambos (menores ou) iguais ao $\epsilon/2$).
Assim provamos que para todo $\epsilon > 0$,
$$
0 \leq \abs{\ell_1 - \ell_2} < \epsilon,
$$
ou seja, $\abs{\ell_1 - \ell_2} = 0$, e logo $\ell_1 - \ell_2 = 0$,
e logo $\ell_1 = \ell_2$, que é o que queremos demonstrar!

%%}}}

%%{{{ x: exp_over_factorial_limit 
\exercise.
%%%{{{ meta 
\label exp_over_factorial_limit
%%%}}}

Demonstre que
$$
\lim_n \frac {2^n} {\fac n} = 0.
$$

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\dotsc
$$

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac 4 3
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
\leq
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 4 \ntimes 4 \ntimes 4 \ntimes \dotsb}
$$
e agora?

%%}}}

%%{{{ x: exp_over_factorial_limit_gen 
\exercise.
%%%{{{ meta 
\label exp_over_factorial_limit_gen
%%%}}}

No~\ref[exp_over_factorial_limit], podemos trocar o $2$
por quais números?

%%}}}

%%{{{ thm: convergent_implies_bounded_in_reals 
\theorem.
%%%{{{ meta 
\label convergent_implies_bounded_in_reals
%%%}}}

Toda seqüência convergente $\seqn a n$ é bounded.

\sketch.
Seja $\seqn a n$ tal que $\seqn a n \limto \ell$.
Logo, usando $\epsilon \asseq 1$ seja $N\in\nats$
tal que a partir do $a_N$, todos os $a_n$'s são
$1$-perto de $\ell$.
Observe que o conjunto $\set{a_0, \dotsc, a_{N-1}}$
é finito, e logo possui mínimo $m$ e máximo $M$:
$$
m \leq a_0, \dotsc, a_{N-1} \leq M.
$$
Agora, observe que a seqüência é bounded below pelo
$\min \set{ m , \ell - 1 }$ e similarmente bounded above pelo
$\max \set{ M , \ell + 1 }$.

%%}}}

%%{{{ thm: monotone_and_bounded_implies_convergent 
\theorem.
%%%{{{ meta 
\label monotone_and_bounded_implies_convergent
%%%}}}

Uma seqüência monótona e bounded é convergente.

%%}}}

\TODO sketch.

%%{{{ thm: nested_interval_theorem 
\theorem intervalos aninhados.
%%%{{{ meta 
\label nested_interval_theorem
%%%}}}

Seja $\seqn I n$ uma seqüência de intervalos não vazios, fechados e bounded,
que forma uma $\supset$-chain:
$$
I_0 \supset I_1 \supset I_2 \supset \dotsb.
$$
Logo $\Inter_n I_n \neq \emptyset$.
E se $\length(I_n) \limto 0$, 
então $\Inter_n I_n$ é um singleton.

%%}}}

\TODO sketch.

%%{{{ x: closed_and_bounded_important_in_nested_interval_theorem 
\exercise.
%%%{{{ meta 
\label closed_and_bounded_important_in_nested_interval_theorem
%%%}}}

Demonstre que as hipoteses do~\ref[nested_interval_theorem] sobre os
intervalos ser fechados e bounded são \emph{necessárias}.

%%}}}

%%{{{ df: liminf_and_limsup_in_reals 
\definition.
%%%{{{ meta 
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Definimos
$$
\xalignat2
\liminf_n &\defeq \sup_n\inf_{k\geq } a_k &
\limsup_n &\defeq \inf_n\sup_{k\geq } a_k.
\endxalignat
$$
Usamos também $\ulim_n$ para o $\liminf_n$ e
similarmente $\olim_n$ para o $\limsup_n$.

%%}}}

\TODO elaborar e adicionar desenhos sobre os $\limsup$ e $\liminf$.

%%{{{ remark 
\remark.
%%%{{{ meta 
%%%}}}

Seja $\seqn a n$ seqüência bounded e seja
$$
M \asseq \limsup_n a_n = \lim_n \sup \setst {a_k} {k \geq n}.
$$
Logo
$$
\pforall {\epsilon > 0}
\pexists {N \in \nats}
\lforall {n \geq N}
  {M - \epsilon < \sup\setst{a_k}{k \geq n} < M + \epsilon}.
$$

%%}}}

%%{{{ criterion: limsup_liminf_criteria 
\criterion.
%%%{{{ meta 
\label limsup_liminf_criteria
%%%}}}

Seja $\seqn a n$ bounded.
Logo
$$
\align
M = \limsup_n a_n
&\iff
\pforall {\epsilon > 0}
\bracket{
\aligned
&\text{$a_n < M + \epsilon$ para eventualmente todos os $n$'s} \\
&\text{$a_n > M - \epsilon$ para uma quantidade infinita de $n$'s}
\endaligned
}; \\
m = \liminf_n a_n
&\iff
\pforall {\epsilon > 0}
\bracket{
\aligned
&\text{$a_n > m - \epsilon$ para eventualmente todos os $n$'s} \\
&\text{$a_n < m + \epsilon$ para uma quantidade infinita de $n$'s}
\endaligned
}.
\endalign
$$

%%}}}

\TODO demonstrar.

\TODO elaborar e conectar com os equivalentes operadores em conjuntos.

%%{{{ df: Cauchy_sequence_of_reals 
\definition seqüência Cauchy.
%%%{{{ meta 
\label Cauchy_sequence_of_reals
\defines
    * Cauchy!reais
    ;;
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Dizemos que $\seqn a n$ é \Cauchy[seqüência]\dterm{Cauchy}
sse para qualquer $\epsilon > 0$ existe um membro da
seqüência tal que a partir dele, todos os seus membros
são $\epsilon$-perto entre si (dois a dois).
Formalmente:
$$
\text{$\seqn a n$ é Cauchy}
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i,j \geq N}
{$a_i,a_j$ são $\epsilon$-perto}.
$$

%%}}}

%%{{{ thm: convergent_implies_Cauchy_in_reals 
\theorem.
%%%{{{ meta 
\label convergent_implies_Cauchy_in_reals
%%%}}}

Se uma seqüência de reais é convergente, então ela é Cauchy.

%%}}}

\TODO sketch.

%%{{{ thm: Cauchy_implies_bounded_in_reals 
\theorem.
%%%{{{ meta 
\label Cauchy_implies_bounded_in_reals
%%%}}}

Se uma seqüência de reais é Cauchy, então é bounded.

%%}}}

\TODO sketch.

%%{{{ thm: Cauchy_with_conv_subseq_implies_convergent_in_reals 
\theorem.
%%%{{{ meta 
\label Cauchy_with_conv_subseq_implies_convergent_in_reals
%%%}}}

Se uma seqüência de reais é Cauchy e possui subseqüência
convergente, então é convergente.

%%}}}

\TODO sketch.

%%{{{ x: every_sequence_has_a_monotone_subsequence_in_reals 
\exercise.
%%%{{{ meta 
\label every_sequence_has_a_monotone_subsequence_in_reals
%%%}}}

Toda seqüência de reais tem uma subseqüência monótona.

%%}}}

%%{{{ thm: Bolzano_Weierstrass_theorem 
\theorem Bolzano--Weierstrass.
%%%{{{ meta 
\label Bolzano_Weierstrass_theorem
%%%}}}

Toda seqüência bounded de reais possui subseqüência convergente.

%%}}}

\TODO sketch.

%%{{{ cor: Cauchy_implies_convergent_in_reals 
\corollary.
%%%{{{ meta 
\label Cauchy_implies_convergent_in_reals
%%%}}}

Uma seqüência de reais é Cauchy sse é convergente.

%%}}}

\TODO sketch.

%%{{{ cor: bounded_implies_Cauchy_subseq_in_reals.
\corollary.
%%%{{{ meta 
\label bounded_implies_Cauchy_subseq_in_reals
%%%}}}

Toda seqüência bounded possui subseqüência Cauchy.

%%}}}

\TODO sketch.

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.
%%%{{{ meta 
%%%}}}

\TODO Elaborar.

%%{{{ df: continuous_real_function 
\definition funcção real contínua.
%%%{{{ meta 
\label continuous_real_function
%%%}}}

Sejam $X,Y\subset \reals$, $f : X \to Y$, e $x_0 \in X$.
Chamamos
$$
\multline
\text{$f$ contínua no $x_0$}
\defiff
\pforall {\epsilon > 0}
\pexists {\delta > 0} \\
\lforall {x \in X}
{
\text{$x,x_0$ são $\delta$-perto}
\implies
\text{$f x, f x_0$ são $\epsilon$-perto}
}.
\endmultline
$$
Dizemos que $f$ é \dterm{contínua} sse ela é contínua em
cada ponto do seu domínio.

%%}}}

%%{{{ Continuity as a game 
\note Continuidade como jogo.
%%%{{{ meta 
\label continuity_game
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ lemma: continuous_functions_preserve_sign 
\lemma preservação de sinal.
%%%{{{ meta 
\label continuous_functions_preserve_sign
%%%}}}

Seja $f : A \to \reals$ contínua no $a$ com $fa \neq 0$.
Logo existe $\ball \delta a$ tal que f não muda sinal nela.

\sketch.
\proofpart{Caso $fa > 0$.}
Usamos a continuidade da $f$ no $a$ com $\epsilon \asseq fa$,
assim ganhando um $\delta > 0$ tal que
todos os $\delta$-perto de $a$ são mapeados $\epsilon$-perto
de $fa$.  Logo todos são positivos.
\crproofpart{Caso $fa < 0$:} similar.

%%}}}

%%{{{ thm: Bolzano_theorem 
\theorem Bolzano.
%%%{{{ meta 
\label Bolzano_theorem
%%%}}}

{\Bolzano[teorema]}%
Seja $f : A \to \reals$ contínua em todo ponto dum intervalo
$[a,b]$ tal que $(fa),(fb)$ têm sinais opostos.
Logo existe $w \in (a,b)$ tal que $fw = 0$.

\sketch.
\proofpart{Caso $fa < 0 < fb$.}
Observe que podem exisir vários $w \in (a,b)$ com $fw = 0$;
a gente precisa achar um tal $w$.
Seja
$$
L = \setst {x \in [a,b]} {f x \leq 0}.
$$
Observe $L \neq \emptyset$ (pois $a \in L$) e ele é
bounded above (por $b$), e logo possui supremum:
seja $w \asseq \sup L$.
Basta demonstrar que (i) $fw = 0$; (ii) $a < w < b$.
(i) Pela tricotomía da ordem basta eliminar as possibilidades
$fw > 0$ e $fw < 0$.
Fazemos isso usando a continuidade da $f$ e
o~\ref[continuous_functions_preserve_sign].
supondo a primeira chegamos na contradição de achar um
upper bound de $L$ menor que $w$;
supondo a segunda chegamos na contradição que o $w$
não é um upper bound.
(ii) Temos $w \in [a,b]$, basta eliminar as possibilidades
de $w = a$ e $w = b$: imediato pois $fw = 0$ e $fa,fb\neq 0$.
\crproofpart{Caso $fb < 0 < fa$:} similar.

%%}}}

%%{{{ df: preserves_limits_in_reals 
\definition preserva limites.
%%%{{{ meta 
\label preserves_limits_in_reals
%%%}}}

Seja $f : A \to \reals$.
Dizemos que \dterm{$f$ preserva os límites} sse
para toda seqüência convergente $\seqn a n$
$$
f\funparen{ \liml_n a_n } = \liml_n (f a_n).
$$

%%}}}

%%{{{ criterion: continuous_iff_preserves_limits_in_reals 
\criterion.
%%%{{{ meta 
\label continuous_iff_preserves_limits_in_reals
%%%}}}

Seja $f : A \to \reals$.
$$
\text{$f$ contínua}
\iff
\text{$f$ preserva os limítes}.
$$

%%}}}

\TODO Demonstrar.

\endsection
%%}}}

%%{{{ Series 
\section Séries.
%%%{{{ meta 
%%%}}}

%%{{{ df: series_of_reals 
\definition.
%%%{{{ meta 
\label series_of_reals
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Considere os números
$$
\align
s_0 &= 0 \\
s_1 &= a_0 \\
s_2 &= a_0 + a_1 \\
s_3 &= a_0 + a_1 + a_2 \\
    &\eqvdots \\
s_n &= \Sum_{i=0}^{n-1} a_i \\
    &\eqvdots
\endalign
$$
dos \dterm{somatórios parciais} (ou \dterm{iniciais})
da $\seqn a n$.
Escrevemos
$$
\Sum_{n=0}^{\infty} a_n
\qqtext{como sinônimo de}
\mubrace
  {\liml_n \paren{\Sum_{i=0}^{n-1} a_i}}
  {\liml_n s_n}
$$
e naturalmente usamos frases como
<<a \dterm{série $\Sum a_n$ converge}>>, etc.
Dizemos que a série $\Sum a_n$ \dterm{diverge} sse
$\seqn s n \limto \pinfty$ ou se a $\seqn s n$ não possui limite.

%%}}}

\endsection
%%}}}

%%{{{ Pointwise convergence 
\section Convergência pointwise (ponto a ponto).
%%%{{{ meta 
%%%}}}

%%{{{ pointwise_limit_in_real_functions 
\definition.
%%%{{{ meta 
\label pointwise_limit_in_real_functions
%%%}}}

Seja $\seqn f n$ uma seqüência \emph{de funcções}
no $(A\to\reals)$.
Observe que para cada $x \in A$, é determinada uma
seqüência \emph{de reais} pelos valores das
$f_n$'s nesse ponto: $\sequence {f_nx} n$.
Se cada uma delas converge àlgum real definimos
o \dterm{limite pointwise} da $\seqn f n$ para
ser a funcção $f : A \to \reals$ definida pela
$$
f x = \liml_n {(f_n x)}.
$$
Dizemos que $\seqn f n$ \dterm{converge pointwise}
(ou \dterm{ponto a ponto}) à $f$.

%%}}}

%%{{{ x: pointwise_limit_eg_monomials 
\exercise.
%%%{{{ meta 
\label pointwise_limits_eg_monomials
%%%}}}

Seja $\seqn f n \subset ([0,1] \to \reals)$ a seqüência
definida pelas
$$
\align
f_n   &\eqtype [0,1] \to \reals \\
f_n x &= x^n.
\endalign
$$
A $\seqn f n$ converge àlguma funcção pointwise?

%%}}}

\endsection
%%}}}

%%{{{ Geometric_representation_of_reals 
\section Representação geométrica e digital.
%%%{{{ meta 
\label Geometric_representation_of_reals
%%%}}}

\TODO Expansão como instruções.

\endsection
%%}}}

%%{{{ The_surreals 
\section Os surreais.
%%%{{{ meta 
\label The_surreals
%%%}}}

\TODO elaborar.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: alternative_formalization_of_ordered_fields_is_equivalent 
\problem.
%%%{{{ meta 
\label alternative_formalization_of_ordered_fields_is_equivalent
%%%}}}

Na~\ref[alternative_formalization_of_ordered_fields] afirmei que
as duas formalizações são equivalentes.
O que isso significa mesmo?  Enuncie e demonstre.

%%}}}

%%{{{ prob: complex_cannot_by_ordered 
\problem.
%%%{{{ meta 
\label complex_cannot_by_ordered
%%%}}}

Demonstre que não tem como definir uma ordem no corpo dos
complexos em tal forma que ele vira um corpo ordenado.

%%}}}

%%{{{ prob: weird_convex_modulized 
\problem.
%%%{{{ meta 
\label weird_convex_modulized
%%%}}}

O que muda no~\ref[weird_convex] se definir o $Q$ como
$Q = \Union_n \set{\tup{\cos n, \sin n}}$?

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[spivakcalculus],
\cite[apostol1],
\cite[hardypuremath],
\cite[loomissternberg].
\cite[knuthsurreals].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Cantors_paradise 
\chapter O paraíso de Cantor.
%%%{{{ meta 
\label Cantors_paradise
%%%}}}

%%{{{ A bit of historical context 
\history Um pouco de contexto histórico.

\TODO Terminar as duas histórias.

%%{{{ Wild_numbers 
\note Números selvágens.
%%%{{{ meta 
\label Wild_numbers
\indexes
    * funcção!algébrica
    ;;
%%%}}}

\yearof{1682}:
{\Leibniz}Leibniz demonstra que $\sin$ não é uma
\dterm{funcção algébrica}.
\yearof{1700}:
{\Euler}Euler define os números \dterm{transcendentais};
mas não consegue demonstrar se existem ou não.
\yearof{1768}:
{\Lambert}Lambert
prova que $\pi$ é \emph{irracional} e os $e^q$ também, para qualquer $q\in\rats_{\neq0}$.
\yearof{1844}:
{\Liouville}Liouville demonstra que existem números transcendentais.
Definiu o que hoje chamamos de \dterm{números Liouville},
mostrou que todos eles são transcendentais, e no 1851 construiu
um número Liouville específico, a \dterm{constante Liouville}
$$
\Sum_{n=1}^\infty 10^{-n!}
= 0.11000100000000000000000100\dots
$$
que foi (finalmente) um exemplo simples e concreto de um
número transcendental.
\yearof{1870}--\yearof{1872}:
{\Cantor}Cantor;
\yearof{1873}:
{\Hermite}Hermite provou que $e$ é transcendental.
Esse foi o primeiro número transcendental que conhecemos cujo
objectivo (cuja definição) não foi feita para ser um tal número.
Liouville \emph{definiu} seus números com objectivo de achar
transcendentais.  O $e$ já era definido e estudado muito,
e sua \emph{raison d'être} não tinha nada a ver com os
números transcendentais.
\yearof{1882}:
\vonLindemann{}von~Lindemann prova a transcendentalidade
dos $e^\alpha$ para $\alpha\neq0$ algébrico---e logo
do $\pi$ também (\ref[pi_is_transcendental])---e
{\Weierstrass}Weierstrass generaliza no \yearof{1885} para o
teorema conhecido como Lindemann--Weierstrass na teoria de
números transcendentais.

%%}}}

%%{{{ From Fourier series to the study of sets 
\note De séries Fourier para o estudo de conjuntos.
%%%{{{ meta 
%%%}}}

\yearof{1870}:
{\Cantor}Cantor se interessou nas séries \Fourier{séries}Fourier.
O que são as \dterm{séries Fourier} não é importante nesse
momento;\foot
Uma série Fourier tem a forma
$$
f(x)
= a_0
+ \Sum_{n=1}^{\infty} a_n \cos(nx)
+ \Sum_{n=1}^{\infty} b_n \sin(nx).
$$
Os $a_n$'s e $b_n$'s são seus coeficientes.
\toof
basta saber que são determinadas por seus
\emph{coeficientes} que são duas seqüências de números reais
$$
\xalignat2
&a_1,a_2,a_3,\dotsc &
&b_1,b_2,b_3,\dotsc
\endxalignat
$$
Cantor demonstrou um teorema impressionante:

%%}}}

%%{{{ thm: Cantor_theorem_1870 
\theorem Cantor, 1870.
%%%{{{ meta 
\label Cantor_theorem_1870
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
numa funcção no $[0,2\pi]$.
Então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mas Cantor se perguntou:
<<E se elas convergem na mesma funcção em todo o $[0,2\pi]$
\emph{exceto um conjunto de possíveis excessões}
$E \subset [0,2\pi]$?  Será que se o $E$ não é grande
demais eu ainda consigo demonstrar o mesmo resultado,
que os coeficientes são iguais?>>
E realmente conseguiu, já no próximo ano:

%%}}}

%%{{{ thm: Cantor_theorem_1871 
\theorem Cantor, 1871.
%%%{{{ meta 
\label Cantor_theorem_1871
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
na mesma funcção no $[0,2\pi] \setminus E$.
Se $E$ é finito, então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observe que o teorema de 1870 é um caso especial do
teorema de 1871, tomando $E \asseq \emptyset$.
No próximo ano, Cantor conseguiu melhorar ainda mais seu
teorema:

%%}}}

%%{{{ thm: Cantor_theorem_1872 
\theorem Cantor, 1872.
%%%{{{ meta 
\label Cantor_theorem_1872
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
na mesma funcção no $[0,2\pi] \setminus E$.
Se $E$ é \dterm{derivável até $\emptyset$},
então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O que significa \dterm{derivável até $\emptyset$} vamos
encontrar no~\ref[Metric_spaces];
por enquanto basta saber que essa condição é satisfeita
por muitos conjuntos \emph{infinitos}, e por todos os
conjuntos finitos, e logo o teorema de 1871 é um caso
especial do teorema de 1872.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas aventuras fizeram Cantor se preocupar sobre os
conjuntos como objetos matemáticos próprios, como
``first-class cítizens'' e se preocupar sobre seus
tamanhos também.
E assim nasceu a \dterm{teoria (ingênua) dos conjuntos}.
Neste capítulo estudamos as idéias de Cantor sobre conjuntos e
sobre infinidade(s); descobertas importantíssimas em matemática,
tanto que faz sentido de falar sobre matemática a.C.~e~d.C.~(antes
Cantor e depois Cantor).

%%}}}

\endhistory
%%}}}

%%{{{ What is counting and comparing of quantities? 
\section O que é contar e comparar quantidades?.
%%%{{{ meta 
%%%}}}

%%{{{ How we count 
\note.
%%%{{{ meta 
%%%}}}

Quando queremos \dterm{contar} a quantidade de membros
dum conjunto $A$, começamos apontando a cada um deles
e, usando \emph{números}, atribuimos um para cada membro.
No final das contas---ahem---acabamos com um certo número $n$
e digamos que $A$ tem $n$ membros.  A \dterm{cardinalidade}
de $A$, é o $n$.
Em símbolos,
$$
\card A = n.
$$
Essa análise tem varios pontos hipersimplificados e talvez
controversiais.
\eop
Primeiramente note que, se o conjunto $A$ é infinito, esse
processo nunca vai parar, e a gente não vai conseguir atribuir
um $n\in\nats$ para representar a cardinalidade $\card A$.
Além disso, precisamos \emph{ter} os números.
Isso talvez parece um ponto bobo, mas vale a pena se perguntar
se os humanos sabiam sobre o conceito de \dterm{quantidade},
e equivalentemente de \dterm{cardinalidade de conjunto},
antes de \emph{ter} os números ou não!

%%}}}

%%{{{ Do we really need numbers? 
\note Precisamos mesmo de números?.
%%%{{{ meta 
%%%}}}

Sabemos como contar conjuntos finitos então.
E usamos o $\nats$ para representar as quantidades possíveis.
Agora não queremos contar, mas \emph{comparar} dois conjuntos
\emph{com relação à quantidade de elementos}.
A discussão sobre contagem acima presuponha a existência
dos números que usamos para contar:  1, 2, 3, etc.,
e dependende da época talvez o 0 também faz parte desses números.
Mas, bem antes de ter números para contar, os humanos poderiam
comparar quantidades.
Talvez um humano prehistórico sabia dizer que ele tem a mesma
quantidade de filhos que seu vizinho, sem saber dizer que
cada um tem \emph{cinqo} filhos.
Como ele sabia então comprarar essas cardinalidades?

%%}}}

\endsection
%%}}}

%%{{{ Equinumerosity 
\section Equinumerosidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: finord 
\definition.
%%%{{{ meta 
\label finord
\defines
    * \finord {~n}  -- o conjunto $\set {0,\dotsc,n-1}$
    ;;
%%%}}}

Como usamos bastante o conjunto $\set{0,1,\dotsc,n-1}$,
vale a pena introduzir uma notação para denotá-lo:
$$
\finord n \pseudodefeq \set{0,\dotsc,n-1}.
$$

%%}}}

%%{{{ x: define \finord using set-builder 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o $\finord n$ usando a notação set-builder.

\hint
Começa com o $\nats$ e filtre seus elementos usando suas relações de ordem.

\solution
Definimos
$$
\finord n \defeq \setst {i \in \nats} { 0 \leq i < n }.
$$

%%}}}

%%{{{ x: define \finord using recursion 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o operador $\finord{\hole} : \nats \to \pset\nats$ recursivamente.

\hint
Cuidado com as operações e os ``tipos'' dos seus argumentos.

\solution
Qualquer uma das definições abaixo serve:
$$
\xalignat 2
\finord 0 &\defeq \emptyset                                     & \finord 0    &\defeq \emptyset\\
\finord n &\defeq \finord {n-1} \union \set{n-1}\qquad(n > 0)   & \finord {Sn} &\defeq \finord n \union \set n.
\endxalignat
$$

%%}}}

%%{{{ df: equinumerous 
\definition Equinúmeros.
%%%{{{ meta 
\label equinumerous
\defines
    * ~A \eqc ~B  -- os $A$ e $B$ são equinúmeros
    * equinúmeros
    ;;
%%%}}}

Chamamos os conjuntos $A$ e $B$ \dterm{equinúmeros} sse
existe bijecção $f : A \bijto B$.
Escrevemos:
$$
A \eqc B \defiff \lexists f {f : A \bijto B}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Continuamos em definir mais relações para comparar os tamanhos de conjuntos:

%%}}}

%%{{{ df: leqc_and_ltc 
\definition.
%%%{{{ meta 
\label leqc_and_ltc
\defines
    * ~A \leqc ~B  -- o $A$ é menor-ou-igual em cardinalidade que o $B$
    * ~A \ltc ~B   -- o $A$ é menor em cardinalidade que o $B$
    ;;
%%%}}}

Sejam $A$ e $B$ conjuntos.
Definimos
$$
\align
A \leqc B &\defiff \lexists {B_0\subset B} {A \eqc B_0}\\
A \ltc B  &\defiff A\leqc B \mland A\neqc B
\endalign
$$
Seguindo nossa práctica comum, usamos também $A\gtc B$ como sinónimo de $B\ltc A$,
$A \not\geqc B$ para significar que não é o caso que $B \leqc A$, etc.

%%}}}

%%{{{ x: A_subset_B_implies_A_leqc_B 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que
$$
A \subset B \implies A \leqc B.
$$
Mostre que, em geral,
$$
A \subsetneq B \nimplies A \ltc B.
$$

%%}}}

%%{{{ x: wrong_ltc_def 
\exercise.
%%%{{{ meta 
\label wrong_ltc_def
%%%}}}

Demonstre ou disprove a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \ltc B \askiff \lexists {B_0\subsetneq B} {A \eqc B_0}.
$$

\hint
$\nats\ltc\ints$?

%%}}}

%%{{{ x: fun_leqc_def_injto 
\exercise.
%%%{{{ meta 
\label fun_leqc_def_injto
%%%}}}

Demonstre ou disprove a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \leqc B \askiff \lexists f {f : A \injto B}.
$$

\hint
Realmente
$$
A \leqc B \iff \lexists f {f : A \injto B}.
$$
Demonstre!

%%}}}

%%{{{ x: fun_leqc_def_surto 
\exercise.
%%%{{{ meta 
\label fun_leqc_def_surto
%%%}}}

Podemos usar a seguinte definição como alternativa?:
$$
A \leqc B \askiff \lexists f {f : B \surto A}.
$$

%%}}}

%%{{{ x: eqc_is_eqrel 
\exercise.
%%%{{{ meta 
%%%}}}

A $\eqc$ é uma relação de equivalência.  Ou seja:
$$
\align
\text{reflexiva:}\quad&  \text{para todo conjunto $A$,     $A \eqc A$};\\
\text{transitiva:}\quad& \text{para todo conjunto $A,B,C$, $A \eqc B \mland B \eqc C \implies A \eqc C$};\\
\text{simétrica:}\quad&  \text{para todo conjunto $A,B$,   $A \eqc B \implies B \eqc A$}.
\endalign
$$

\solution
Usamos as bijecções seguintes: identidade, composição, inversa.

%%}}}

%%{{{ lemma: leqc_is_equiorder 
\lemma.
%%%{{{ meta 
\label leqc_is_equiorder
%%%}}}

A $\leqc$ é:
$$
\align
\text{reflexiva:}              \quad &A \leqc A;\\
\text{transitiva:}             \quad &A \leqc B \mland B \leqc C \implies A \leqc C;\\
\text{não antissimétrica:}     \quad &A \leqc B \mland B \leqc A \nimplies A = B;\\
\text{``equiantissimétrica'':} \quad &A \leqc B \mland B \leqc A \implies A \eqc B.
\endalign
$$

\sketch.
Para as duas primeiras usamos a identidade e a composição respectivamente.
Para a próxima tomando $A\asseq \nats$ e $B\asseq \ints$ serve.
Para ver que não é antissimétrica basta achar um contraexemplo: tente os $\set 0$ e $\set 1$.
A última é realmente difícil para demonstrar:
é um corolário direto
do teorema Schröder--Bernstein (\ref[schroder_bernstein]).

%%}}}

%%{{{ x: times_respects_eqc 
\exercise.
%%%{{{ meta 
\label times_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies A\times B \eqc A'\times B'$.

\solution
Defina $F: A\times B \to A' \times B'$ pela
$
F(a,b) = (f(a), g(b)).
$
Ou seja, $F = f \cross g$.
\proofpart{Injectividade.}
Tome $\tup{a_1,b_1} \neq \tup{a_2,b_2}$ no $A\times B$.
Logo $a_1\neq a_2$ ou $b_1\neq b_2$ (pela definição de $=$ nas tuplas).
Logo
$$
F(a_1,b_2) = \tup{f(a_1), g(b_1)} \neq \tup{f(a_2), g(b_2)} = F(a_2,b_2).
$$
onde a $\neq$ segue pelas injectividades das $f,g$:
pois se $a_1\neq a_2$ então $f(a_1)\neq f(a_2)$,
e se $b_1\neq b_2$ então $g(b_1) \neq g(b_2)$.
\proofpart{Sobrejectividade.}
Tome $\tup{a',b'}\in A'\times B'$.
Logo $a'\in A'$ e $b'\in B'$, e como $f$ e $g$ são sobrejetoras,
sejam $a \in A$ e $b\in B$ tais que $f(a) = a'$ e $g(b) = b'$.
Observe que $F(a,b) = \tup{f(a), g(b)} = \tup{a',b'}$.

%%}}}

%%{{{ x: pset_respects_eqc 
\exercise.
%%%{{{ meta 
\label pset_respects_eqc
%%%}}}

$A \eqc A' \implies \pset A \eqc \pset A'$.

\solution
Defina $F : \pset A \to \pset A'$ pela
$
F(X) = \img f X.
$
\proofpart{Injectividade.}
Tome $X,Y \in \pset A$ tais que $X\neq Y$.
Ou seja, existe $z\in X\symdiff Y$.
Tome tal $z$ e considere os $F(X)$ e $F(Y)$.
Como $f$ é injetora, o $f(z) \in F(X) \symdiff F(Y)$.
Ou seja: $F(X) \neq F(Y)$.
\proofpart{Sobrejectividade.}
Tome $X' \in \pset A'$.
Observe que o $\pre f {X'}$ é mapeado no $X'$ através da $F$,
graças ao~\ref[jection_iff_composition_with_inverse].

%%}}}

%%{{{ x: to_respects_eqc 
\exercise.
%%%{{{ meta 
\label to_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies (A\to B) \eqc (A'\to B')$.

\solution
Defina $F : (A\to B) \to (A' \to B')$ pela
$F(t) = g \compose t \compose f^{-1}$.
\proofpart{Injectividade.}
Sejam $s,t \in (A\to B)$ com $s\neq t$.
Logo existe $a_0 \in A$ tal que $s(a_0) \neq t(a_0)$.
Calcule:
\compute
(F(s))(f(a_0))
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s)(a_0)\\
&= g(s(a_0))\\
&\neq g(t(a_0)) \by {$g$ injetora e $s(a_0) \neq t(a_0)$} \\
&= (g \compose t)(a_0)\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (F(t))(f(a_0)).
\endcompute
\proofpart{Sobrejectividade.}
Seja $t' \in (A'\to B')$.
Defina a $t \in (A\to B)$ pela
$$
    t = \finv g \compose t' \compose f
$$
e observe que $F(t) = t'$.

%%}}}

%%{{{ x: disjunion_respects_eqc 
\exercise.
%%%{{{ meta 
\label disjunion_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies A \dunion B \eqc A' \dunion B'$.

%%}}}

%%{{{ x: which_setops_respect_cardinalities 
\exercise.
%%%{{{ meta 
\label which_setops_respect_cardinalities
%%%}}}

Quais das operações $\Union$, $\Inter$, respeitam a equinumerosidade?

\hint
Nenhuma.
Ache contraexemplos.

\solution
Nenhuma!
Como contraexemplo, tome os
$$
A \asseq \set{ \set{0}, \set{1} }
\eqc
B \asseq \set{ \set{0,1}, \set{1,2} }
$$
e calcule
$$
\xalignat2
\Union \set{ \set{0}, \set{1} }     &= \set{0,1} &
\Inter\set{ \set{0}, \set{1} }      &= \emptyset \\
\Union \set{ \set{0,1}, \set{1,2} } &= \set{0,1,2} &
\Inter\set{ \set{0,1}, \set{1,2} }  &= \set{1}.
\endxalignat
$$
Ou seja, $\Union A \neqc \Union B$ e $\Inter A \neqc \Inter B$.

%%}}}

%%{{{ x: currying_eqc 
\exercise.
%%%{{{ meta 
\label currying_eqc
%%%}}}

$((A \times B) \to C) \eqc (A \to (B\to C))$.

\hint
Curry!

\hint
Use lambdas (veja~\ref[A_touch_of_lambda]).

\solution
Defina $F : ((A\times B) \to C) \to (A \to (B\to C))$, pela
$$
F(t) = \lam a {\lam b {t(a,b)}}.
$$
\proofpart{Injectividade.}
Tome $s,t \in ((A\times B) \to C)$ tais que $s\neq t$.
Ou seja, para alguma entrada $\tup{a_0,b_0} \in (A\times B)$,
as saídas são diferentes elementos de $C$:
$$
s(a_0,b_0) \neq t(a_0,b_0).
$$
Observe então que $F(s) \neq F(t)$,
pois para a entrada $a_0$, elas retornam valores diferentes:
a $F(s)$ retorna a funcção
$\lam b {s(a_0, b)}$,
e a $F(t)$ retorna a funcção $\lam b {t(a_0, b)}$.
Para confirmar que realmente
$$
\lam b {s(a_0, b)}
\neq
\lam b {t(a_0, b)}
$$
basta observar que seus valores para a entrada $b\asseq b_0$
são diferentes.
\proofpart{Sobrejectividade.}
Toma um $f\in (A\to (B\to C))$.
Defina a $t : (A\times B) \to C$
pela
$$
t(a,b) = (f(a))(b)
$$
e observe que realmente $F(t) = f$.

%%}}}

\endsection
%%}}}

%%{{{ What is cardinality? 
\section O que é cardinalidade?.
%%%{{{ meta 
%%%}}}

%%{{{ The double abstraction of Cantor 
\note A dupla abstracção de Cantor.
%%%{{{ meta 
%%%}}}

{\Cantor}Cantor definiu a cardinalidade numa maneira informal,
mas sua descripção é bastante indicativa e serve como uma guia
para chegar numa definição formal.
A cardinalidade dum conjunto $A$ é o que fica, se
a gente mentalmente esquecer a ordem que pensamos os membros de $A$
e também os seus nómes.  Assim o $A$ parece uma colecção de pontinhos
abstratos e distintos.  Cantor denotou a cardinalidade de $A$
$$
\cantorcard A
$$
usando as duas barras para indicar essa ``dupla abstracção''.

%%}}}

%%{{{ But what is a cardinal number? 
\note Mas o que é um número cardinal?.
%%%{{{ meta 
\credits
    * vonNeumann
    * Hausdorff
    ;;
%%%}}}

Vamos voltar pouco ao passado, e seguindo os passos do livro
clássico de Hausdorff (\cite[hausdorffsettheory])
não vamos preocupar com a \emph{natureza} dos cardinais.
Vamos deixar isso ``para os filósofos'' como ele disse,
pois na época que ele escreveu seu texto ninguém tinha conseguido
dar uma definição satisfatória de \dterm{número cardinal}.
Uns anos depois, von~Neumann conseguiu definir
formalmente os números cardinais, algo que vamos encontrar
no~\ref[Wosets_Ordinals].  Mas sem saber o que são,
já podemos usá-los deixando claro quais são as propriedades
que exigimos que eles satisfaçam.
Um operador de cardinalidade $\card{\dhole}$ deve satisfazer
pelo menos a:
$$
A \eqc B \iff \card{A} = \card{B}
$$
e possivelmente mais condições ainda.
Vamos voltar para estudar os detalhes no~\ref[Axiomatic_set_theory].

%%}}}

\endsection
%%}}}

%%{{{ Finite and infinite; countable and uncountable 
\section Finitos e infinitos; contáveis e incontáveis; jogos para imortais.
%%%{{{ meta 
%%%}}}

%%{{{ df: finite_set 
\definition.
%%%{{{ meta 
\label finite_set
\defines
    * finito
    * infinito
    ;;
%%%}}}

O conjunto $A$ é \dterm{finito} sse existe $n\in\nats$ tal que $A \eqc \finord n$.
O conjunto $A$ é \dterm{infinito} sse $A$ não é finito.

%%}}}

%%{{{ df: countable_set 
\definition.
%%%{{{ meta 
\label countable_set
\defines
    * conjunto!contável
    * conjunto!incontável
    ;;
%%%}}}

O conjunto $A$ é \dterm{contável} sse $A$ é finito ou $\nats\eqc A$.
Usamos os termos \dterm{enumerável} e \dterm{denumerável} como sinónimos
de contável.
O conjunto $A$ é \dterm{incontável} sse $A$ não é contável.

%%}}}

%%{{{ countable vs enumerable 
\warning.
%%%{{{ meta 
%%%}}}

Em muitos textos as palavras ``contável'' e ``(d)enumerável'' não
são exatamente sinónimas: uma delas pode insistir que o conjunto seja
infinito, e a outra relaxar essa restricção para permitir os finitos
também.  As duas palavras, etimologicamente e semanticamente falando,
parecem ser sinônimos no mundo matemático, e por isso nesse texto
eu vou usar as duas como sinônimos mesmo.  Mas cuidado lendo
textos diferentes, pois podem significar coisas diferentes
no caso que o conjunto em questão é finito.
(Sobre conjuntos infinitos os dois termos sempre concordam.)

%%}}}

%%{{{ df: enumeration 
\definition.
%%%{{{ meta 
\label enumeração
\defines
    * enumeração
    ;;
%%%}}}

Uma \dterm{enumeração} dum conjunto $A$ é qualquer surjecção
$\pi : \nats\surjto A$.
Assim temos:
$$
A = \img \pi {\nats} = \set{\pi(0), \pi(1), \pi(2), \dotsc}
$$

%%}}}

%%{{{ The enumeration game of Smullyan 
\note O jogo de enumeração de Smullyan.
%%%{{{ meta 
\label Smullyan_game
\indexes
    * estratégia!vencedora
    ;;
\credits
    * Smullyan : jogo
    ;;
%%%}}}

Smullyan criou o seguinte jogo que ajuda em entender o conceito
de conjunto enumerável.  Seja $S$ um conjunto que chamaremos de
\dterm{conjunto-segredo}.  Tu, o jogador, e eu, o inimigo, começamos
o jogo e nos dois sabemos qual é o conjunto $S$ desse jogo.
Eu jogo primeiro, escolhendo um membro $w\in S$.
Teu objectivo é adivinhar o $w$.
Todo dia tu tens um palpite, e eu vou responder ``sim'' ou ``não''.
No dia $i$ então, tu escolhe um membro $s_i \in S$ como um
palpite fazer exatamente um palpite na forma equacional:
$$
w = s_i?
$$
onde $s_i$ é teu $i$-ésimo palpite, ou seja, o palpite do dia $i$.
Tu ganhas se um belo dia tu conseguir adivinhar a minha escolha:
o $w$ que selecionei no inicio do jogo.
Um exemplo de jogo então com $S=\nats$ parece assim:
\dialogue
\say Eu escolhi meu membro $w \in \nats$.
\say (Dia 0:) É o 42?
\say Não.
\say (Dia 1:) É o 28?
\say Não.
\say (Dia 2:) É o 8?
\say Não.
\say (Dia 3:) É o 1024?
\say Não.
\say (Dia 4:) É o 1024?
\say Não!
\say (Dia 5:) É o 12?
\say Sim.
\enddialogue
Quantas tentativas tu tens?
Um para cada dia, pra sempre!
Pois é, um detalhe pequeno: vamos supor que nós dois somos imortais.
E o inimigo não tem o direito de mudar seu palpite!
O jogo então é baseado no conjunto-segredo $S$.
O teu objectivo como jogador é adivinhar o $w$ que eu, teu inimigo, escolhi.
\eop
O teu objectivo como matemático é achar uma
\dterm{estratégia vencedora},
ou seja, \emph{uma estratégia que garanta vitória} para o jogador.
Se tal estratégia existe para esse jogo, chamamos o $S$ \dterm{enumerável}.
Observe que uma estratégia nesse jogo não é nada mais que uma
\emph{seqüência}
$$
s_0, s_1, s_2, s_3, s_4, \dotsc
$$
de membros de $S$, que o jogador vai seguir, jogando $s_i$ no $i$-ésimo dia.
Ela é vencedora sse
$$
\pforall {w \in S}
\lexists {i \in \nats}
{s_i = w}.
$$
Pensando em seqüências do $S$ como funcções $s : \nats\to S$ isso quis
dizer que $s$ é sobrejetora.

%%}}}

%%{{{ Secret set
\note Conjunto-segredo: de easy para nightmare.
%%%{{{ meta 
%%%}}}

Vamos ver se (e como!) tu jogaria nesse jogo com uns $S$
variando em dificuldade:
$$
S = \set {12, -2, 0}.
$$
Espero que é óbvio como garantir vitória aqui:
$$
0, 12, -2;
$$
ou seja, no primeiro dia jogue o $0$; se não foi o escolhido,
jogue o $12$; se nem isso foi o escolhido, jogue o $-2$ que com
certeza será o certo pois não tem outros membros o~$S$.
$$
S = \nats.
$$
Aqui a situação é pouco mais complicada, mais ainda múito fácil:
$$
0, 1, 2, 3, 4, \dotsc;
$$
ou seja: no dia $i$, escolha o $i$!
Não importa quão grande foi o número segredo $w$ que escolhi,
um belo dia (no $w$-ésimo dia mesmo) tu acertás!
Próximo!
$$
S = \ints.
$$
Aqui eu vou adivinhar qualquer inteiro.  O que farás?
Observe que a última estratégia não funcciona mais.
Se eu escolher qualquer número negativo, tu nunca adivinharás,
pois tu ``ficarás preso'' para a eternidade adicinhando apenas
os inteiros não-negativos.
\emph{O fato que uma estratégia não é vencedora, não quis dizer
que não existem vencedoras!}
Aqui realmente existe!

%%}}}

%%{{{ Q: Can we guarantee victory with S = ints ?
\question.
%%%{{{ meta 
%%%}}}

Tem como garantir vitória nesse jogo com $S = \ints$?

%%}}}

\spoiler

%%{{{ x: binary_union_of_countable_is_countable 
\exercise.
%%%{{{ meta 
\label binary_union_of_countable_is_countable
%%%}}}

A união $C\union D$ de dois conjuntos contáveis $C,D$ é contável.

%%}}}

%%{{{ Q: uncountable_or_uncountable_guess 
\question.
%%%{{{ meta 
\label countable_or_uncountable_guess
%%%}}}

Para cada um dos conjuntos seguintes, tu jogaria nesse jogo?
Ou seja, tem estratégia vencedora?
$$
\rm
\align
I   &= \setst {x\in\reals}   {\text{$x$ é irracional}}\\
A   &= \setst {x\in\reals}   {\text{$x$ é algébrico}}\\
T   &= \setst {x\in\reals}   {\text{$x$ é transcendental}}\\
C   &= \setst {z\in\complex} {\modulus z = 1}\\
P_L &= \setstt {p} {$p$ é um programa da linguagem de programação $L$}\\
G   &= \graph(f), \quad \text{onde $f : \reals\to\reals$ definida pela $f(x) = x^2$}\\
D   &= (\nats \to \set{0,2})\\
S   &= (\nats \to \nats)\\
P   &= (\nats \bijto \nats)\\
Z   &= \setst {f:\nats\to\nats} {\pexists {n_0\in\nats} \lforall {n\geq n_0} {f(n)=0}}
\endalign
$$

%%}}}

%%{{{ And the answers? 
\blah E as respostas?.
%%%{{{ meta 
%%%}}}

Pense nisso agora, meio-adivinhando, e até o fim desse capítulo tu vai
saber a resposta para cada um deles!

%%}}}

%%{{{ lemma: A_is_countable_equiv_statements 
\lemma.
%%%{{{ meta 
\label A_is_countable_equiv_statements
%%%}}}

Seja $A$ conjunto.
O.s.s.e.:
\item{\rm (1)} $A$ é contável
\item{\rm (2)} $A \leqc \nats$
\item{\rm (3)} $A=\emptyset$ ou $A$ possui enumeração.

\sketch.
As direcões $(1)\Rightarrow(2)\Rightarrow(3)$ são conseqüências fáceis
das definições.  Para ``fechar o round-robin'' ($(3)\Rightarrow(1)$),
precisamos definir uma \emph{bijecção} $f : \nats\bijto A$
ou $f : \finord n\bijto A$, dados uma \emph{surjecção} $\pi:\nats\surjto A$.
Usamos recursão e o princípio da boa ordem.

\proof.
Vamos demonstrar o lemma na maneira ``round-robin'', demonstrando as implicações
$(1)\Rightarrow(2)\Rightarrow(3)\Rightarrow(1)$.
As duas primeiras são conseqüências imediatas das definições---nada
interessante---mas para a $(3)\Rightarrow(1)$ precisamos mais cuidado.
\crproofpart{$(1)\Rightarrow(2)$.}
Caso $A$ finito, para algum $n\in\nats$ temos $A\eqc \finord n \subset \nats$
e logo $A \leqc \nats$.
Caso que $A$ infinito, temos $A\eqc\nats\subset\nats$ e logo $A \leqc \nats$.
\crproofpart{$(2)\Rightarrow(3)$.}
Suponha que $A\neq\emptyset$.
Vamos construir uma enumeração do $A$, ou seja, uma $\pi : \nats \surjto A$.
Pela hipótese, seja $N_0 \subset \nats$ tal que $A \eqc N_0$.
E logo temos uma bijecção $f : N_0 \bijto A$.
Seja $a_0 \in A$ ($A\neq\emptyset$) e defina a funcção $\pi : \nats \to A$ pela
$$
\pi(x) =
\knuthcases {
f(x), & se $x \in N_0$ \cr
a_0,  & se não.
}
$$
Basta verificar que $\pi$ é realmente sobrejetora, mas isso é fácil:
para cada $a\in A$, temos
$$
\pi(\finv{f}(a)) = a.
$$
\proofpart{$(3)\Rightarrow(1)$.}
Caso $A$ finito, $A$ é contável.
Suponha que $A$ infinito, e seja $\pi : \nats \surjto A$
uma enumeração de $A$.
Precisamos definir uma bijecção $f : \nats\bijto A$ ou $f : \finord n\bijto A$.
Defina a $f$ pela recursão
$$
\align
f(0)   &= \pi(0) \\
\text{e para $n>0$ defina}\qquad
f(n) &= \pi(m_n)
\phantom{\text{e para $n>0$ defina}\qquad}
\endalign
$$
onde $m_n$ é o menor natural $m$ tal que $\pi(m) \notin \set{f(0),\dotsc,f(n-1)}$.
Observe que tal $m_n$ existe graças ao \indexed[PBO]Principio da boa ordem \reftag[nats_WOP].

%%}}}

%%{{{ What do we gain? 
\note O que ganhamos?.
%%%{{{ meta 
%%%}}}

Suponha que um conjunto $A$ é contável.
O que ganhamos realmente com essa informação?
Como podemos usar essa hipótese?
Já sabemos, por exemplo, que o fato ``$C \neq \emptyset$'' nos permite escrever ``Seja $c\in C$.''.
O que o fato ``$A$ é contável'' nos permite fazer?
Bem, podemos escrever: ``seja $a_n$ uma \emph{enumeração} de $A$'', ou, escrever:
``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''.

%%}}}

%%{{{ beware 
\beware.
%%%{{{ meta 
%%%}}}

É um erro comum escrever ``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''~mesmo quando
não sabemos que $A$ é contável.  Talvez $A$ é \emph{grande demais} para poder ser
escrito nessa forma.  Como o $\reals$, por exemplo, que sabemos que não pode ser escrito
como $\reals = \set{r_0, r_1, r_2, \dotsc}$, pois é um conjunto incontável!%

%}}}

\endsection
%%}}}

%%{{{ Cantor's first diagonal argument 
\section O primeiro argumento diagonal de Cantor.
%%%{{{ meta 
\label Cantor_first_diagonal_argument
%%%}}}

%%{{{ And the rationals? 
\note E os racionais?.
%%%{{{ meta 
%%%}}}

O fato que $\ints$ é contável não deixou ninguém muito surpreso.
Mas na maneira que contamos os membros do $\ints$, existe essa
idéia de ``próximo número'' meio incorporada no próprio conjunto
pela sua ordem.
\emph{<<Primeiramente tome o $0$.
Depois tome o próximo positívo,
e depois o próximo negativo, e por aí vai.>>}
Mas o $\rats$ com sua ordem padrão é um conjunto \dterm{denso}:
entre quaisquer racionais $x,y$ com $x<y$, existe racional $w$
tal que $x < w < y$.  Vamos dizer que começou no $0$.
Quem vai depois?  Não existe ``próximo'' para nenhuma direção!
Em vez de contar os membros de $\rats$, vamos contar
os membros de $\nats^2$.  E isso já vai resolver o problema
de enumerar o $\rats$ facilmente.

%%}}}

%%{{{ Counting the pairs of nats 
\note Contando os pares de naturais.
%%%{{{ meta 
%%%}}}

Naturalmente pensamos no $\nats^2$ numa forma bidimensional
(até pronunciando o conjunto usamos a palavra ``quadrado'').
Vamos arrumar então os naturais numa tabela bidimensional
e infinita assim:
$$
\tikzpicture
\tikzi pairs5x5nats;
\endtikzpicture
$$
Naturalmente, influenciados por nossos hábitos talvez gostariamos
de contar os membros linha por linha, ou coluna por coluna---só
que\dots
\eop\bigskip\noi
\centerline{Expectativa:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
    \draw[->] (-.5,-\y) -- (4.666,-\y);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
    \draw[->] (\x,.5) -- (\x,-4.5);
}
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
\eop\bigskip\noi
\centerline{Realidade:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
}
\draw[->] (-.5,0) -- (4.666,0);
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
}
\draw[->] (0,.5) -- (0,-4.5);
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
O que aconteceu?
Stratificando nosso espaço nessa maneira, \emph{ficaremos presos}
no $S_0$ pra sempre!  Se o inimigo no jogo escolher qualquer um dos
membros fora do $S_0$ a gente nunca vai ganhar!

%%}}}

%%{{{ Finite strata 
\note Strata finita.
%%%{{{ meta 
%%%}}}

Stratificando nosso espaço precisamos tomar cuidado para qualquer
stratum ser um conjunto \emph{finito}.  Usando a analogia do jogo
isso garanta vitória, pois ficaremos no primeiro stratum para uma
quantidade finita de dias, e um belo momento depois de ter contado
todos os membros do primeiro stratum vamos começar o segundo,
que (sendo também finito) sabemos que um belo dia já vamos começar
contar o terceiro; etc., etc.

%%}}}

%%{{{ Cantor's first diagonal argument 
\note O primeiro argumento diagonal de Cantor.
%%%{{{ meta 
\label Cantor_stratification_of_pairs
\credits
    * Cantor : diagonalização
    ;;
%%%}}}

Cantor conseguiu stratificar esse
espaço apenas virando sua cabeça num ângulo $\pi/4$:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node[rotate=45] at (-.8,-\y-.8) {$S_{\y}$};
    \draw[->] (-.5,-\y-.5) -- (\y+.5,.5);
}
\node at (-.8, -5.666) {$\vdots$};
\endtikzpicture
$$
Observe que na stratificação de Cantor, \emph{cada stratum é finito}.
Com sua método de diagonalização Cantor conseguiu algo maravilhoso:
contou todos dos \emph{racionais}, algo muito chocante, pois a maneira
que visualizamos esse conjunto é \emph{muito} mais populosa daquela
dos inteiros ou dos naturais.  Mas chega Cantor e nos ilumina:
\emph{o $\rats$ parece tão mais populoso porque tu não tá fazendo
essa dupla abstração, deixando a natureza e ordem te confundir!}

%%}}}

%%{{{ Gödel's stratification 
\note A stratificação de Gödel.
%%%{{{ meta 
\label Godel_stratification_of_pairs
%%%}}}

\Godel[diagonalização]Gödel muitos anos depois preferiu uma
stratificação diferente:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \i in {0,...,4} {
    \node at (-1,-\i) {$S_{\i}$};
    \draw[rounded corners=2ex,->] (-.5,-\i) -- (\i,-\i) -- (\i,.5);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
$$
Observe que aqui também cada stratum é finito, e logo serve para
contar todos os membros do conjunto.

%%}}}

%%{{{ x: define_both_stratifications_of_pairs 
\exercise.
%%%{{{ meta 
\label define_both_stratifications_of_pairs
%%%}}}

Defina formalmante as stratificações de
Cantor~(\reftag[Cantor_stratification_of_pairs]) e de
Gödel~(\reftag[Godel_stratification_of_pairs]).
Observe que cada stratum, sendo finito, pode ser representado por um
conjunto (e não uma tupla) sem problema nenhum.
Defina curtamente então, usando a notação set-builder,
os $S_n$'s de ambas as stratificações.

\hint
$S_n = \setst {(x,y)} {\asklhole}$.

%%}}}

%%{{{ no_repetitions_implies_bijection 
\remark.
%%%{{{ meta 
\label no_repetitions_implies_bijection
%%%}}}

Para corresponder numa bijecção mesmo, o jogo do~\reftag[Smullyan_game]
tem que ser modificado, para proibir repetições do mesmo palpite.
Observamos que se o jogador tem uma estratégia para ganhar num jogo que
permite repetições de palpites, ele já pode adaptá-la para ganhar no
jogo com a restricção: ele apenas segue a estratégia do jogo ``livre''
e quando aparecem palpites que ele já adivinhou, ele pula para o próximo,
até chegar num palpite que ele não tentou ainda, para tentá-lo.
Por exemplo, para enumerar os racionais sabendo uma enumeração dos pares
de inteiros, copiamos a estratégia do $\ints^2$, pulando pares que ou não
correspondem em racionais (como o $(0,0)$ por exemplo), ou que são iguais
com palpites anteriores (como o $(2,4)$ que pulamos por causa do $(1,2)$
que já adivinhamos).

%%}}}

%%{{{ thm: countable_union_of_countables_is_countable 
\theorem.
%%%{{{ meta 
%%%}}}

Seja $\cal C$ uma colecção contável de conjuntos contáveis.
Logo $\Union \cal C$ é contável.
Em outras palavras: união contável de contáveis é contável.

\sketch.
Seja $\seqn C n$ uma enumeração dos membros do $\cal C$:
$$
\align
\cal C &= \set{ C_0, C_1, C_2, \dotsc }.
\intertext{Sabemos que todos os $C_n$'s são contáveis; logo seja
$\sequence {c_n^i} i$ uma enumeração do $C_n$:}
C_0 &= \set {c_0^0, c_0^1, c_0^2, c_0^3, \dotsc } \\
C_1 &= \set {c_1^0, c_1^1, c_1^2, c_1^3, \dotsc } \\
C_2 &= \set {c_2^0, c_2^1, c_2^2, c_2^3, \dotsc } \\
    &\eqvdots 
\endalign
$$
e agora é óbvio como usar o primeiro argumento diagonal de Cantor
e obtenir uma enumeração do $\Union \cal C = \Union_{n=0}^{\infty} C_n$.

%%}}}

%%{{{ Are there uncountable sets? 
\note Tem incontáveis?.
%%%{{{ meta 
%%%}}}

Até este momento podemos sentir uns dos sentimentos de {\Cantor}Cantor
investigando essas infinidades.  Até talvez uma frustração, pois,
por enquanto, todos os conjuntos infinitos que testamos acabaram sendo
contáveis.  Será que todos são?  Os reais estão resistindo ainda,
mas antes de pensar no primeiro argumento diagonal, os racionais
também estavam!
Agora tu demonstraras que muitos mais conjuntos são realmente contáveis.

%%}}}

%%{{{ x: strings_from_finite_alphabet_countable 
\exercise.
%%%{{{ meta 
\label strings_from_finite_alphabet_countable
%%%}}}

Demonstre ou refute:
o conjunto de todos os strings feitos por qualquer alfabeto finito é contável.

%%}}}

\endsection
%%}}}

%%{{{ Hacking intermission 
\problems Intervalo para hackear.
%%%{{{ meta 
%%%}}}

%%{{{ codeit: EnumPairs 
\codeit EnumPairs.
%%%{{{ meta 
\label program_enumpairs
%%%}}}

Implemente uma estratégia para ganhar no jogo sem repetições com
conjunto-segredos o $\nats^2$.
Ou seja, escreva um programa que imprime (pra sempre) os palpites
do jogador na sua ordem.

%%}}}

%%{{{ codeit: EnumRatsReps 
\codeit EnumRatsReps.
%%%{{{ meta 
\label program_enumrats
%%%}}}

Modifique o EnumPairs para o caso com conjunto-segredos
o conjunto de racionais não-negativos, mas permitindo repetições.
Represente cada palpite como fracção,
imprimindo por exemplo o racional $\frac 1 3$ como o string
``{\tt 1/3}''.

%%}}}

%%{{{ codeit: EnumRats 
\codeit EnumRats.
%%%{{{ meta 
\label program_enumratsnoreps
%%%}}}

Modifique o EnumRats para o caso que o jogo proibe
repetições (mas para o mesmo conjunto $\rats_{\geq0}$).
Use teu código para responder na pergunta:
\emph{dada a escolha do inimigo, em qual dia o jogador vai adivinhá-la?}

%%}}}

%%{{{ x: amnesiac_player 
\exercise Jogador amnésico.
%%%{{{ meta 
\label amnesiac_player
%%%}}}

Ache uma estratégia para ganhar no jogo com conjunto-segredos o
conjunto dos racionais não-negativos, se o jogador tem memória que o
permite lembrar apenas seu último palpite!

%%}}}

%%{{{ x: nextPair 
\exercise.
%%%{{{ meta 
\label nextPair
%%%}}}

Defina uma funcção 
$\namedop{nextPair} : \nats^2 \to \nats^2$
tal que para cada entrada $(n,m)$ ela retorna o próximo palpite do jogador
que acabou de tentar o $(n,m)$, no jogo com conjunto-segredos o $\nats^2$.
Considera que sua estratégia começa com o palpite $(0,0)$.
Assim, a enumeração representada por a estratégia do jogador seria a:
$$
(0,0), f(0,0), f^2(0,0), f^3(0,0), \dotsc,
$$
ou seja, a seqüência $\set{ f^n (0,0) }_{n}$.

%%}}}

%%{{{ codeit: NextPair 
\codeit NextPair.
%%%{{{ meta 
\label NextPair
%%%}}}

Implemente funcção do~\ref[nextPair].

%%}}}

\endproblems
%%}}}

%%{{{ Cantor's second diagonal argument 
\section O segundo argumento diagonal de Cantor.
%%%{{{ meta 
\pdefs
    \pdef a {\alert}
    \pdef b {\phantom0}
    \pdef n {}
    \pdef f {\faded}
    \pdef u {\underline}
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos finalmente atacar a cardinalidade dos reais, começando com seu
subconjunto $[0,1]\subset\reals$.
Vamos ver que realmente isso é um conjunto \dterm{incontável}.
Não tem como enumerar seus membros!
Como podemos demonstrar isso?
Lembrando a definição, basta demonstrar que não existe enumeração
$$
[0,1] = \set{a_0, a_1, a_2, \dots}.
$$
Vamos começar com um esboço que tem um erro para entender a idéia
básica---e para ver se tu perceberás o erro, claro.

%%}}}

%%{{{ A slightly wrong sketch 
\note Um esboço pouco errado.
%%%{{{ meta 
%%%}}}

Suponha que alguém chegou feliz pra ti, afirmando que conseguiu enumerar
todos os reais no $[0,1]$, a apresenta sua enumeração pra ti:
$$
a_0, a_1, a_2, a_3, \dots
$$
Tu pega sua lista e escreva a expansão decimal de cada número,
um número por linha; por exemplo:
$$
\matrix
\format
\r  &~~\c~~&     &\c    &\c     &\c     &\c     &\c     &\c     &\c   &\c \\
a_0 &=     &0\b. &\b 3  &\b 6   &\b 4   &\b 8   &\b 8   &\b 5   &\b 0 &\b \dots \\
a_1 &=     &0\b. &\b 2  &\b 1   &\b 8   &\b 9   &\b 8   &\b 0   &\b 5 &\b \dots \\
a_2 &=     &0\b. &\b 0  &\b 8   &\b 9   &\b 8   &\b 5   &\b 8   &\b 8 &\b \dots \\
a_3 &=     &0\b. &\b 9  &\b 2   &\b 6   &\b 6   &\b 8   &\b 6   &\b 6 &\b \dots \\
a_4 &=     &0\b. &\b 2  &\b 3   &\b 4   &\b 6   &\b 0   &\b 5   &\b 7 &\b \dots \\
    &\eqvdots&
\endmatrix
$$
Nosso objectivo é mostrar um certo número $w \in [0,1]$ que não está nessa lista.
Vamos definir esse $w$ construindo sua expansão decimal:
$$
\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots
\endmatrix
$$
E a idéia é a seguinte:
traversa a tabela acima diagonalmente, mudando o dígito,
construindo assim um novo número.
Os primeiros três passos aqui podem ser os seguintes:
$$
\xalignat3
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\a4 &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\a3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\a2 &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\a1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\n2 &\b\a0 &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\a9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
\endxalignat
$$
onde para mudar cada dígito, eu fui para o ``próximo''.
Foi construido assim o
$$
\matrix
\format
\r  &~~\c~~ &     &\c  &\c  &\c  &\c  &\c  &\c \\
  w &\defeq &0\b. &\b4 &\b2 &\b0 &\b7 &\b9 &\b\dots
\endmatrix
$$
que não está na lista $a_0, a_1, a_2, \dots$.
\mistake

%%}}}

%%{{{ Q: why is w not in the list? 
\question.
%%%{{{ meta 
%%%}}}

Por que $w$ não está na lista?

%%}}}

\spoiler

%%{{{ A 
\blah.
%%%{{{ meta 
%%%}}}

Pois pela sua construção, o $w$ discorda com todos os
membros da lista em pelo menos uma posição:
ele discorda com o $a_0$ na primeira posição, com o $a_1$
na segunda, etc.
É fácil demonstrar que
$$
\text{para todo $n\in\nats$,}\quad
w \neq a_n.
$$
Seja $n\in \nats$.
Agora observe que o $w \neq a_n$ pois pela sua construção,
ele discorda com o $a_n$ no $n$-ésimo dígito.
\mistake

%%}}}

%%{{{ Q: why wrong? 
\question.
%%%{{{ meta 
%%%}}}

Qual o problema com essa argumentação?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

O argumento é baseado numa hipótese falsa para concluir que o
número $w$ construido é diferente de todos os números da lista:
que duas expansões de números reais que discordam no dígito duma
certa posição representão reais distintos, que tá simplesmente errado:
$$
0.4999\dots = \frac 1 2 = 0.5000\dots
$$
as expansões são distintas, não temos reais distintos aqui!

%%}}}

%%{{{ blah: Now what? 
\blah E agora?.
%%%{{{ meta 
%%%}}}

Em vez de desistir e jogar a idéia brilhante fora, podemos
(i) perceber que já temos nas nossas mãos uma demonstração da incontabilidade
dum certo conjunto, só que não é o conjunto $[0,1]$
e (ii) proceder para concertar o probleminha da argumentação para virar
uma demonstração correta da incontabilidade do $[0,1]$ mesmo!
Faça ambos agora.

%%}}}

%%{{{ x: wrong_sketch_is_correct_for_another_set 
\exercise (i).
%%%{{{ meta 
%%%}}}

Sobre qual conjunto podemos já afirmar que é incontável, usando
a argumentação bugada que não deu certo para o $[0,1]$?

\hint
As expansões são distintas sim; os números que representão não.

\solution
Vendo as expansões como strings (infinitos) feitos pelo alfabeto
${0,\dotsc,9}$ já temos que o conjunto de todos eles não é contável.

%%}}}

%%{{{ thm: binary_sequences_uncountable 
\theorem Cantor.
%%%{{{ meta 
\label binary_sequences_uncountable
\credits
    * Cantor
    ;;
\pdefs
    \pdef m   {{\rm m}}
    \pdef w   {{\rm w}}
    \pdef two {{\mathbf 2}}
    ;;
%%%}}}

O conjunto de todas as seqüências feitas por dois símbolos distintos
é incontável.

\proof.
Cantor escolheu os \symq{$\m$} e \symq{$\w$} como símbolos distintos,
vamos seguir seu gosto então.  Denotamos $\two = \set{\m,\w}$.
Seja $\seqnset f n \subset \funspace \nats \to \two$.
Basta construir um membro de $\funspace \nats \to \two$ que não
é nenhum dos membros de $\seqnset f n$.
Definimos a $g : \nats \to \two$ então pela
$$
g(x) =
\knuthcases {
\w,   & se $f(x) = \m$;\cr
\m,   & se $f(x) = \w$.
}
$$
Basta verificar que para todo $n \in \nats$, $g \neq f_n$.
Seja $n \in \nats$ então.
Pela definição da $g$ temos que $g,f_n$ discordam no ponto $n$
e logo $g \neq f_n$.

%%}}}

%%{{{ x: fix_the_problem_of_wrong_sketch 
\exercise (ii).
%%%{{{ meta 
%%%}}}

Conserta o problema.

\hint
Os únicos conflitos de expansões envolvem reais com exatamente duas expansões:
uma que a partir duma posição só tem $0$'s, e uma que a partir duma posição só
tem $9$'s.

\hint
Basta determinar uma maneira de trocar os digitais da diagonal que garanta que
cada dígito mudou mesmo e que o número criado não termina nem em $0$'s nem em
$9$'s.

\solution
Os únicos conflitos de expansões envolvem reais com exatamente duas expansões:
uma que a partir duma posição só tem $0$'s, e uma que a partir duma posição só
tem $9$'s.
Logo basta determinar uma maneira de trocar os digitais da diagonal que garanta
que cada dígito mudou mesmo e que o número criado não termina nem em $0$'s nem
em $9$'s:
Mandamos todos os dígitos diferentes de $5$ para o $4$ e o $4$ para o $5$.

%%}}}

%%{{{ x: Why does this proof (1891) fail for rationals? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que
o $\setst{q \in \rats}{0\leq q\leq 1}$ também é incontável?

\hint
Como tu vai demonstrar que o número construido pela método
diagonal de Cantor realmente é um elemento de $\rats\inter[0,1]$?

%%}}}

\endsection
%%}}}

%%{{{ Cantor set 
\section O conjunto de Cantor.
%%%{{{ meta 
\label Cantor_set
\credits
    * Cantor : conjunto de Cantor
    ;;
%%%}}}

%%{{{ Cantor set 
\note O conjunto de Cantor.
%%%{{{ meta 
\defines
    * Cantor!conjunto de
    ;;
\indexes
    * conjunto!de Cantor    see: Cantor
    ;;
%%%}}}

$$
\tikzpicture
\tikzi cantorset;
\endtikzpicture
$$

%%}}}

\TODO Terminar.

\endsection
%%}}}

%%{{{ Some important applications 
\section Umas aplicações importantes da teoria de Cantor.
%%%{{{ meta 
%%%}}}

%%{{{ corollary: irrats_uncountable 
\corollary.
%%%{{{ meta 
\label irrats_uncountable
%%%}}}

Os irracionais são incontáveis.

\proof.
Os racionais são contáveis.  Os reais incontáveis.
Logo, os irracionais são incontáveis, pois
$\reals = \rats \union \paren{\reals\setminus\rats}$
e logo se $\reals\setminus\rats$ fosse contável teriamos
a contradição do $\reals$ ser contável também
(\ref[binary_union_of_countable_is_countable]).

%%}}}

%%{{{ And the transcendentals? 
\note E os transcendentais?.
%%%{{{ meta 
%%%}}}

Os transcendentais parecem ainda mais selvagens que os irracionais.
E neste momento temos poquíssimos exemplos: os números de {\Liouville}Liouville
que foram contruidos exatamente com esse propósito;
o $e$ que {\Hermite}Hermite acabou de demonstrar que é
transcendental~(\yearof{1873}) e a transcendentalidade do $\pi$ demorou uns anos.
Como encontramos transcendentais tão raramente em comparação com os algébricos
faz sentido pensar que eles são contáveis.\foot
Na verdade, a única razão que temos nesse momento de acreditar
que o conjunto de transcendentais é infinito são os números Liouville:
ele realmente conseguiu contruir uma infinidade (incontável) de transcendentais.
\toof

%%}}}

%%{{{ lemma: algebraics_are_countable 
\lemma Dedekind.
%%%{{{ meta 
\label algebraics_are_countable
\credits
    * Dedekind
    ;;
%%%}}}

Os algébricos são contáveis.

\sketch.
Basta observar que $\polys\rats x \eqc \kstar\rats$, com a correspondência
$$
a_0 + a_1 x + a_2 x^2 + \dotsb + a_{n-1} x^{n-1} + a_n x^n
\leftrightarrow
\tupp{a_0, a_1, a_2, \dotsc, a_{n-1}, a_n}.
$$
Seja $f_0, f_1, f_2, \dotsc$ uma enumeração do $\polys\rats x$.
Stratificamos então os números algébricos onde o $i$-ésimo stratum é o
conjunto de todas as raízes reais de $f_i$:
$$
S_i = \setst {\alpha\in\reals} {f_i(\alpha) = 0}.
$$
Pelo teorema fundamental da Álgebra agora, sabemos que cada $f_i$
tem no máximo $\deg(f_i)$ raízes, ou seja, todos os strata
são finitos e pronto!

%%}}}

%%{{{ corollary: transcends_uncountable 
\corollary Cantor.
%%%{{{ meta 
\label transcends_uncountable
\credits
    * Cantor
    ;;
%%%}}}

Os transcendentais são incontáveis.

\proof.
Como os algébricos são contáveis (\ref[algebraics_are_countable]),
os transcendentais são incontáveis com o mesmo argumento da demonstração
do~\ref[irrats_uncountable].

%%}}}

%%{{{ Sky and stars 
\note Céu de estrelas.
%%%{{{ meta 
%%%}}}

Sem as descobertas de Cantor, alguém pensaria que isso
é uma coincidência muito grande e bizarra:
como aconteceu que a gente definiu um número bem importante
como o $\pi$ ou o $e$ e aconteceu que ele tem essa propriedade
estranha de ser transcendental?
Mas, graças ao Cantor, sabemos melhor:
\emph{de fato, seria bizarro se fosse o contrário!}
Pois sabemos agora que, na verdade, as excessões são os
algébricos e não os transcendentais.
O estranho seria descobrir que $e$ aconteceu que é racional!
Como piada considere o princípio seguinte:

%%}}}

%%{{{ joke: transcendentality_principle 
\joke Princípio de transcendentalidade.
%%%{{{ meta 
\label transcendentality_principle
%%%}}}

Seja $x\in\reals$ com $x\neq0,1$.
Se $x$ é profundamente interessante em matemática,
então $x$ é transcendental.

%%}}}

%%{{{ Liouville vs Cantor 
\note Liouville vs Cantor.
%%%{{{ meta 
\label Liouville_vs_Cantor
%%%}}}

É comum encontrar argumentos favorecendo o teorema de Liouville
contra o teorema de Cantor, sobre a existência de transcendentais.
Normalmente escutamos algo do tipo <<Liouville construiu e mostrou
transcendentais, Cantor apenas demonstrou que existem sem constriur
ou mostrar nenhum>>.
Essa afirmação é completamente errada!

%%}}}

%%{{{ x: cantor_proof_is_constructive 
\exercise.
%%%{{{ meta 
\label cantor_proof_is_constructive
%%%}}}

Explique o porquê.

%%}}}

%%{{{ codeit: CantorCon 
\codeit CantorCon.
%%%{{{ meta 
\label CantorCon
%%%}}}

Escreva um programa que compute irracionais e transcendentais.
Considere que teu usuário vai querer determinar quantos
números construir, e também até que precisão (quantos dígitos).

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas: Cantor \vs Reais.
%%%{{{ meta 
%%%}}}

%%{{{ blah: Cantor, Cantor, Cantor 
\blah O conjunto dos reais é incontável.
%%%{{{ meta 
%%%}}}

{\Cantor}Cantor não deu apenas uma demonstração para esse teorema seu.
A demonstração que já encontramos aqui, que envolve seu argumento
diagonal, é a mais importante e elegante (exatamente por causa da
diagonalização e suas diversas aplicações).\foot
Cantor terminou seu artigo \cite[cantor1891] onde publicou sua demonstração
com a frase profética
\emph{\dq{Die weitere Erschließung dieses Feldes ist Aufgabe der Zukunft.}}
que significa:
\emph{desenvolver essa área mais é a tarefa do futuro}.
\toof
Mas essa foi nem a primeira, nem a segunda, mas sim a terceira demonstração dele!
As outras duas foram bem diferentes.
{\Cantor}Cantor que o $\reals$ é incontável
foi bem diferente.  Dado quaisquer reais $a,b$ com $a < b$
e qualquer seqüência de reais no $[a,b]$
ele mostrou um certo membro do $[a,b]$ que a seqüência ``esqueceu de contar''.
Redescobrir essa demonstração é o objetivo do \ref[reals_uncountable_first_proof].

%%}}}

%%{{{ prob: reals_uncountable_first_proof 
\problem Cantor \vs Reais: 1874.
%%%{{{ meta 
\label reals_uncountable_first_proof
\credits
    * Cantor
    ;;
%%%}}}

Sejam $a,b\in\reals$ com $a < b$ e $\seqn x n$ seqüência de reais no $[a,b]$.
Demonstre que existe $w \in [a,b]$ tal que $w \notin \seqnset x n$,
seguindo o esboço seguinte.
O plano é construir uma cadeia de intervalos fechados
$$
[a,b] = I_0 \supset I_1 \supset I_2 \supset \dotsb
$$
e escolher o $w$ na sua intersecção.
Para conseguir isso, vamos definir duas subseqüências $\seqn a n$ e $\seqn b n$ da
seqüência $\seqn x n$ tais que
a primeira começa no $a$ e é ascendente e a segunda no $b$ e é descendente
tais que os intervalos $[a_n,b_n]$ vão assumir o papel dos $I_n$.

%%}}}

%%{{{ prob: Why does this proof (1874) fail for rationals? 
\problem.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que o
$\setst{q \in \rats}{a \leq q\leq b}$ também é incontável?

%%}}}

\endproblems
%%}}}

%%{{{ Looking for bijections 
\section Procurando bijecções.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver como as transformações de esticar/encolher
(stretch/shrink) e de deslocar (shift) nos intervalos de reais,
sendo bijecções levam suas entradas para saídas equinúmeras.

%%}}}

%%{{{ x: stretch and shrink intervals 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre as seguintes equinumerosidades entre os seguintes intervalos de reais:
\elist a:
\li: $(0,1) \eqc (0,2)$;
\li: $(0,2) \eqc (3,5)$;
\li: $[0,1) \eqc (0,1]$;
\li: $(a,b) \eqc (c,d)$;
\li: $[a,b) \eqc (c,d]$;
\li: $[a,b) \eqc (c,d]$;
\endelist
(onde $a < b$ e $c < d$).

\hint
Tente aproveitar que composição de bijecções é bijecção, quebrando assim cada
tarefa em tarefas menores e mais fáceis para resolver, tais que a composição
das resoluções delas, resultará na resolução da tua tarefa inicial.

%%}}}

%%{{{ x: infinite stretches 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre as seguintes equinumerosidades entre os seguintes intervalos de reais,
$$
(\alpha,\beta) \eqc (0,1)
$$
onde $\alpha,\beta \in \reals\union\set{\minfty,\pinfty}$ com $\alpha < \beta$.

%%}}}

%%{{{ x: (α,β) =c (0,1) 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre as seguintes equinumerosidades entre os seguintes intervalos de reais,
$$
(\alpha,\beta) \eqc (0,1)
$$
onde $\alpha,\beta \in \reals\union\set{\minfty,\pinfty}$ com $\alpha < \beta$.

\hint
Esticar um intervalo dum comprimento finito para outro maior
é bem facil visualizar.  Mas como esticamos um intervalo de comprimento
finito para a reta dos reais cujo comprimento é infinito?

\hint
Uma maneira geometrica para resolver o $(a,b) \eqc (\minfty,\pinfty)$ é
pegar o $(a,b)$, curvá-lo para parecer um semicírculo, e posicioná-lo
em cima da reta real como parece na figura seguinte:
\math
\tikzpicture
\tikzi infinitestretch_hint;
\endtikzpicture
\endmath
E agora?

\hint
Agora estabelecemos uma correspondência (bijecção) entre os pontos da reta
e os pontos do nosso semicírculo juntando cada ponto $x \in \reals$
com um segmento reto até o centro do semicírculo e mapeando o $x$
para o ponto que o segmento intersecta o semicírculo:
\math
\tikzpicture
\tikzi infinitestretch;
\endtikzpicture
\endmath

%%}}}

\endsection
%%}}}

%%{{{ The Cantor--Schröder--Bernstein theorem 
\section O teorema Cantor--Schröder--Bernstein.
%%%{{{ meta 
\label The_CSB_theorem
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Esse teorema que provamos aqui é conhecido como
``{\Cantor}Cantor--{\Schroder}Schröder--{\Bernstein}Bernstein''
ou ``Schröder--Bernstein'', mas vamos referir a ele nessas notas
apenas com o nome de Bernstein, pois foi o primeiro que demonstrou
sua veracidade numa forma correta.\foot
E sua prova não precisou o
\emph{axioma da escolha}~(\reftag[Axioms_of_choice]),
algo que vamos apreciar mais no~\ref[Axiomatic_set_theory].
\toof
Vamos começar atacando esse problema com uma abordagem amorosa,
de {\Smullyan}Smullyan (veja~\cite[smullyanbeginners]).

%%}}}

%%{{{ x: schroder_bernstein_by_smullyan 
\exercise Abordagem amorosa.
%%%{{{ meta 
\label schroder_bernstein_by_smullyan
%%%}}}

Suponha que num universo seus habitantes são divididos em dois conjuntos \emph{infinitos}:
o conjunto $A$ de homens e $B$ de mulheres.
Suponha também que os seguintes são fatos sobre esse universo:
\elist 1:
\li: Cada homem ama exatamente uma mulher.
\li: Nenhuma mulher é amada por dois homens.
\li: Cada mulher ama exatamente um homem.
\li: Nenhum homem é amado por duas mulheres.
\endelist
(Essas condições já deixam esse universo bem bizarro.)
Mostre que tem como casar todos os habitantes desse universo
em casamentos monogâmicos e heterosexuais,
em tal modo que em cada casal é garantido amor
(mas não necessariamente reciprocal), ou seja:
se $a\in A$ é casado com $b\in B$, \emph{pelo menos uma} das duas condições acontece:
$a$~ama~$b$; $b$~ama~$a$.

\hint
Escolhe uma pessoa $x \in A \union B$.  Independente se ela é homem ou mulher,
podemos a perguntar: \emph{<<quem te ama?>>}.
Duas possibilidades existem: ou ela é amada por algum $x_1 \in A \union B$,
ou ninguém ama $x$.  No primeiro caso perguntamos $x_1$ a mesma pergunta,
definindo assim o $x_2$, se $x_1$ é uma pessoa amada, etc.
Observerve que cada $x \in A \union B$ defina assim um \dterm{caminho amoroso}
$x, x_1, x_2, \dots$.  Esse caminho ou é infinito, ou termina num certo membro $x_n \in A\union B$.
Vamos agora separar todas as pessoas do $A\union B$ em três grupos:
$$
\align
G_A         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $A$}\\
G_B         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $B$}\\
G_\infty    &= \setstt {x \in A\union B} {o caminho amoroso de $x$ é infinito}
\endalign
$$
Tente casar todos os membros de cada um desse grupo entre si!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Voltando dessa versão antropomórfica do problema, observe que
a condição (1) garanta a existência duma funcção $f : A \to B$,
que graças à (2) é injetora.
Similarmente, a condição (3) garanta a existência duma funcção
$g : B \to A$, que graças à (4) é injetora também.
Essas são as hipotéses do~\ref[schroder_bernstein].
Observe também que se resolver o problema amoroso do~\ref[schroder_bernstein_by_smullyan]
tu já forneceu uma funcção \emph{bijetora} $F : A \to B$, definida pela
$$
F(x) = \text{a pessoa casada com $x$}.
$$
Vamos ver isso agora sem amor.

%%}}}

%%{{{ thm: schroder_bernstein 
\theorem Bernstein.
%%%{{{ meta 
\label schroder_bernstein
\indexes
    * teorema!Schröder--Bernstein
    ;;
%%%}}}

{\Bernstein}%
Sejam conjuntos $A$ e $B$ e funcções injetoras
$f : A \injto B$ e $g : B \injto A$.
Então existe bijecção $\phi : A \bijto B$.

%%}}}

\endsection
%%}}}

%%{{{ Looking for injections 
\section Procurando injecções.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora é \emph{bem} mais fácil demonstrar o seguinte
e ganhar o corolário embaixo.
Sem {\Bernstein}Bernstein, precisamos resolver o~\ref[change_of_ends_of_intervals_without_bernstein].

%%}}}

%%{{{ x: (a,b) \eqc (a,b] with Bernstein
\exercise.
%%%{{{ meta 
\label change_of_ends_of_intervals_with_bernstein
%%%}}}

Usando o teorema de Schröder--Bernstein~\reftag[schroder_bernstein]
prove que $(a,b) \eqc (a,b] \eqc [a,b]$.

%%}}}

%%{{{ cor: 
\corollary.
%%%{{{ meta 
%%%}}}

Qualquer intervalo não-trivial (vazio ou singleton) de reais,
tem a mesma cardinalidade com o próprio $\reals$.

%%}}}

%%{{{ x: \reals \eqc \pset\nats with Bernstein
\exercise.
%%%{{{ meta 
%%%}}}

Usando o teorema de Schröder--Bernstein~\reftag[schroder_bernstein]
prove que $\reals \eqc \pset\nats$.

%%}}}

\endsection
%%}}}

%%{{{ Encodings 
\section Codificações.
%%%{{{ meta 
\label Encodings
%%%}}}

%%{{{ Encodings 
\note Encodings.
%%%{{{ meta 
%%%}}}

Uma maneira de pensamento para construir injecções seria através
de codificações (ou \dterm{encodings}).
Uma \dterm{codificação} de $A$ no $B$ é qualquer injecção
de $A$ para $B$.

%%}}}

%%{{{ eg: rats_leqc_nats_encoding 
\example.
%%%{{{ meta 
\label rats_leqc_nats_encoding
%%%}}}

Para demonstrar que $\rats\leqc\nats$ basta achar uma maneira de
codificar cada racional como um natural.  Aqui um jeito fácil:
dado um racional $q\in \rats$ sejam $m,n$ tais que $q = m/n$
e $m/n$ irredutível; codificamos
$$
\align
m/n  &\mapsto 1\tubrace{00\cdots0}{$m$ vezes}1\tubrace{00\cdots0}{$n$ vezes}1.
\intertext{Assim,}
1/2  &\mapsto 101001 \\
10/6 = 5/3 &\mapsto 10000010001 \\
22/7 &\mapsto 10000000000000000000000100000001
\endalign
$$
etc.
Observe que para qualquer $n\in\nats$, existem dois casos:
ou ele serve como codificação para algum $q\in\rats$
(como o $101001$ acima) ou não (como o $1$, o $2$, o $1011$, etc.).
Caso que sim, podemos facilmente extrair a informação codificada
no $n$, voltando para o racional $q$:
$$
10001001 \leadsto 3/2.
$$
A mesma idéia serve para codificar o $\kstar\nats$:

%%}}}

%%{{{ x: kstar_nats_leqc_nats_encoding 
\exercise.
%%%{{{ meta 
\label kstar_nats_leqc_nats_encoding
%%%}}}

Demonstre usando codificação que $\kstar\nats \leqc \nats$.

%%}}}

%%{{{ x: pset_nats_leqc_zeroone_encoding 
\exercise.
%%%{{{ meta 
\label pset_nats_leqc_zeroone_encoding
%%%}}}

Demonstre usando codificação que $\pset\nats \leqc [0,1)$.

%%}}}

%%{{{ x: zeroone_eqc_nats_to_nats_encoding 
\exercise.
%%%{{{ meta 
\label zeroone_eqc_nats_to_nats_encoding
%%%}}}

Demonstre demonstrando duas codificações que $[0,1) \eqc (\nats\to\nats)$.

%%}}}

\endsection
%%}}}

%%{{{ Cantor's theorem and its consequences 
\section O teorema de Cantor e suas conseqüências.
%%%{{{ meta 
\label Cantors_theorem_and_its_consequences
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Até agora temos encontrado apenas duas quantidades infinitas diferentes:
aquela do $\nats$, e aquela do $\reals$.
Essa situação está prestes a mudar drasticamente..

%%}}}

%%{{{ Cantor's theorem: what it says and first steps 
\note O teorema de Cantor.
%%%{{{ meta 
%%%}}}

Cantor provou que para todo conjunto $A$, seu powerset $\pset A$
tem cardinalidade estritamente maior que do $A$:
$$
A \ltc \pset A.
$$
Primeiramente observe que para conjuntos finitos já sabemos disso,
e é fácil demonstrar:
$$
\card {\pset A} = 2^{\card A} > \card A
$$
pois para todo $n\in\nats$, realmente temos $2^n > n$.
Cantor conseguiu demonstrar que $A \ltc \pset A$ para qualquer $A$.
Lembrando a definição de $\ltc$, precisamos demonstrar duas coisas:
$$
A \leqc \pset A
\qqqquad
A \neqc \pset A.
$$
A primeira é fácil: faça agora!

%%}}}

%%{{{ x: A_leqc_pset_A 
\exercise.
%%%{{{ meta 
\label A_leqc_pset_A
%%%}}}

Para todo conjunto $A$, $A \leqc \pset A$.

\hint
Seja $A$ conjunto e defina a $f : A \to \pset A$ pela
$$
f(x) = \set x.
$$
Demonstre que é injetora.

\solution
Seja $A$ conjunto.
Definimos a $f : a \injto \pset a$ pela
$$
f(x) = \set x.
$$
Facilmente ela é injetora (\ref[the_singletonizer_is_injective]).

%%}}}

%%{{{ proof idea with depressive members 
\note A linda idéia da sua prova.
%%%{{{ meta 
%%%}}}

Suponha que temos um conjunto $A$, e uma funcção $A \toby \pi \pset A$.
Vamos demonstrar que a $\pi$ não pode ser sobrejetora---e logo, nem bijetora.
Para entender a idéia melhor, vamos desenhar um exemplo.
Imagina então que o $A$ parece como no desenho abaixo,
e seu powerset tá no seu lado, onde eu desenhei apenas uns dos
seus membros, pois o desenho ficaria bagunçado demais se eu tivesse
desenhado todos.  Mas todos estão lá mesmo: o $\pset A$, pela sua definição,
é o conjunto de \emph{todos} os subconjuntos de $A$.
$$
\tikzpicture
\draw (0,0) to[out=180,in=90] (-1,-1) to[out=270,in=270] (1,-1) to[out=90,in=0] cycle;
\node at (0,-.2) {$\bullet$};
\node at (-.9,-.9) {$\ast$};
\node at (.9,-.9) {$\star$};
\endtikzpicture
$$
A $\pi$ então mapeia cada membro de $A$ com um membro de $\pset A$.
Por exemplo, pode ser assim:
$$
\mathrm{desenho com $\pi$ aqui}
$$
Vamos dar um toque antropomórfico agora:
vamos considerar os membros de $A$ como pessoas, e a $\pi$
como uma funcção de \emph{amor}, que mapeia cada $x\in A$
para o conjunto de todas as pessoas que $x$ ama:
$$
\pi (x) = \setstt {y \in A} {$x$ ama $y$}.
$$
Lembre-se que nosso objectivo é achar um membro de $\pset A$
que não pertence na imagem da $\pi$.
Chame \dterm{depressivo} um $x \in A$ sse $x$ não se ama.
Ou seja,
$$
\text{$x$ é depressivo}
\defiff
x \notin \pi(x)
$$
pois $\pi(x)$ são todas as pessoas que $x$ ama.\foot
Outros exemplos de definições razoáveis nessa interpretação
seriam chamar o $x$ \dterm{misántropo} se $\pi(x) = \emptyset$,
\dterm{egoista} se $\pi(x) = \set x$, etc.,
mas aqui só vamos precisar dos depressivos mesmo.
\toof
Assim, cada $x\in A$ ou é depressivo, ou não.
Condiseramos o conjunto $D$ de todos os depressivos membros de $A$:
$$
D
\defeq \setstt {x \in A} {$x$ é depressivo}
= \setst {x \in A} {x \notin \pi(x)}.
$$
Observe que $D \subset A$, ou seja, $D$ é um membro do $\pset A$.
Esse $D$ é o testemunha que estamos procurando:
um membro do codomínio da $\pi$, garantido para não pertencer
na imagem $\img \pi A$.
Por quê?
Para chegar num abdurdo, suponha o contrário:
que para algum $d \in A$, temos $\pi(d) = D$.
Faz sentido agora perguntar:
\emph{esse $d$ é depressivo?}
Dois casos existem, e os dois chegam em absurdo:
\compute
\text{$d$ depressivo}
&\implies d \notin \pi(d)           \by {def.~depressivo} \\
&\implies d \notin D                \by {pela escolha de $d$} \\
&\implies \text{$d$ não depressivo} \by {def.~$D$} \\
&\implies \text{absurdo!}
\intertext{e no outro lado,}
\text{$d$ não depressivo}
&\implies d \in \pi(d)              \by {def.~depressivo} \\
&\implies d \in D                   \by {pela escolha de $d$} \\
&\implies \text{$d$ depressivo}     \by {def.~$D$} \\
&\implies \text{absurdo!}
\endcompute
Logo, para nenhum $d \in A$ temos $\pi(d) = D$,
ou seja, $D \notin \img \pi A$ e logo $\pi$ não é sobrejetora.
Em palavras antropomórficas, com essas definições
ninguém pode amar \emph{somente todos} os depressivos.
Note bem que em lugar nenhum usamos os desenhos do $A$
e da $\pi$ nessa prova.  Desenhei apenas para ilustrar.
Podemos então demonstrar formalmente o teorema de Cantor,
sem nada depressivo!

%%}}}

%%{{{ thm: cantor_theorem 
\theorem Cantor.
%%%{{{ meta 
\label cantor_theorem
\credits
    * Cantor : teorema de powerset
    ;;
\indexes
    * teorema!Cantor
    ;;
%%%}}}

Seja $A$ conjunto.
Então $A\ltc \pset A$.

\proof.
Seguindo a definição de $\ltc$, precisamos demonstrar duas coisas:
\crproofpart{{\proofname} de $A\leqc \pset A$:}
feita no \ref[A_leqc_pset_A]; um testemunha é a $\lam x {\set{x}}$,
que ``obviamente''~(\ref[the_singletonizer_is_injective]) é injetiva.
\crproofpart{{\proofname} de $A\neqc \pset A$.}
Basta demonstrar que não existe funcção sobrejetora de $A$ para $\pset A$.
Seja $\pi : A \to \pset A$.
Queremos demonstrar que a $\pi$ não pode ser sobrejetora, ou seja,
mostrar um elemento $C$ do seu codomínio que não pertence na imagem da $\pi$
(ou seja: tal que $C \notin \img \pi A$).
Observe que para qualquer $x\in A$, temos $\pi(x)\in\pset A$,
ou seja $\pi(x) \subset A$.
Considere o conjunto
$$
D = \setst {x\in A} {x \notin \pi(x)}.
$$
Pela definição de $D$, temos $D \subset A$.
Ou seja, $D \in \pset A$, que é o codomínio da $\pi$.
Precisamos demonstrar que para todo $x \in A$, $\pi(x) \neq D$.
Para chegar num absurdo, seja $d\in A$ tal que $\pi(d) = D$.
Agora nos perguntamos: $d\in\pi(d)$?
Como $\pi(d)=D$, a pergunta reduza em: $d\in D$?
Ambas as alternativas (\emph{sim} e \emph{não}) são impossíveis:
$$
d \in D
\iff
d \notin D
$$
pela definição de $D$ e pela escolha de $d$.
Absurdo!
Logo $\pi$ não mapeia nenhum membro de $A$ para o $D\in\pset A$,
ou seja, $\pi$ não é sobrejetora.

%%}}}

%%{{{ x: the_singletonizer_is_injective 
\exercise.
%%%{{{ meta 
\label the_singletonizer_is_injective
%%%}}}

Demonstre em detalhe que a funcção $\mapsio x {\set{x}}$ na prova
de~\ref[cantor_theorem] realmente é injetora.

\hint
O que significa que dois conjuntos são iguais?

%%}}}

%%{{{ cor: infinitely_many_infinities 
\corollary.
%%%{{{ meta 
\label infinitely_many_infinities
%%%}}}

Existe uma infinidade (contável) de cardinalidades infinitas:
$$
\nats
\ltc \pset\nats
\ltc \pset\pset\nats
\ltc \pset\pset\pset\nats
\ltc \pset\pset\pset\pset\nats
\ltc \dotsc
$$

%%}}}

%%{{{ cor: no_maximum_cardinality 
\corollary.
%%%{{{ meta 
%%%}}}

Não existe cardinalidade máxima:
para qualquer conjunto $M$, o conjunto $\pset M$ tem cardinalidade maior.

%%}}}

%%{{{ df: aleph_and_continuum 
\definition.
%%%{{{ meta 
\label aleph_and_continuum
\defines
    * \aleph_0  -- a cardinalidade do $\nats$
    * \continuum  -- a cardinalidade do $\pset\nats$ e do $\reals$
    * aleph 0
    * continuum
    ;;
%%%}}}

Denotamos a cardinalidade de $\nats$ por $\aleph_0$ (\dterm{aleph 0}),
e a cardinalidade de $\pset\nats\eqc\reals$ por $\continuum$.
Chamamos o $\continuum$ o \dterm{continuum}.

%%}}}

%%{{{ note: holes in the chain of cardinalities of powersets 
\note.
%%%{{{ meta 
%%%}}}

Considere os conjuntos
$$
\emptyset
\ltc \pset\emptyset
\ltc \pset\pset\emptyset
\ltc \pset\pset\pset\emptyset
\ltc \pset\pset\pset\pset\emptyset
\ltc \dotsb
$$
Observe que cada conjunto nessa seqüência (infinita) de conjuntos é finito.
Mas, quais são suas cardinalidades?
Calculamos:
$$
\align
\card{\emptyset}                     &= 0\\
\card{\pset\emptyset}                &= 1\\
\card{\pset\pset\emptyset}           &= 2\\
\card{\pset\pset\pset\emptyset}      &= 4\\
\card{\pset\pset\pset\pset\emptyset} &= 16\\
                                     &\eqvdots\\
\endalign
$$
Observamos que a seqüência dessas cardinalidades ``tem burácos''.
Por exemplo, nenhum desses conjuntos tem cardinalidade $3$,
mesmo que realmente tem conjuntos com essa cardinalidade
(por exemplo o $\finord 3=\set{0,1,2}$).
Ou seja, existe conjunto $C$ com
$$
\pset\pset\emptyset\ltc C\ltc \pset\pset\pset\emptyset.
$$
Similarmente achamos conjuntos ``estritamente entre'' os conjuntos que aparecem
depois nessa seqüência.

%%}}}

%%{{{ note: some questions arise 
\note.
%%%{{{ meta 
%%%}}}

Umas questões aparecem imediatamente:
% TODO: fix reflabs
\elist 1:
\li: Será que tem conjuntos ``estritamente entre'' alguns dos conjuntos
infinitos da seqüência anterior?
\li: Será que tem algum conjunto com cardinalidade maior que qualquer uma dessas
cardinalidades?
\li: Será que tem algum conjunto incomparável com todos eles?
\li: Até pior: tem conjuntos incomparáveis em cardinalidade?)
\endelist

%%}}}

\endsection
%%}}}

%%{{{ The smallest infinities 
\section As menores infinidades.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então.  Já sabemos que tem uma quantidade infinita de infinidades
diferentes graças ao teorema de Cantor.
Já encontramos as cardinalidades dos primeiros beths
$$
\beth_0 < \beth_1 < \beth_2 < \beth_3 < \dotsb
$$
que são os nomes das cardinalidades dos conjuntos
$$
\nats \ltc \pset\nats \ltc \pset\pset\nats \ltc \pset\pset\pset\nats \ltc \dotsb
$$

%%}}}

%%{{{ The equinumerosities so far 
\note As equinumerosidades até agora.
%%%{{{ meta 
%%%}}}

Temos então provado as:
$$
\nats 
\eqc \ints
\eqc \rats
\eqc \algs
\eqc C\union C'
\eqc \Union_{n=0}^\infty {C_n}
\eqc C^n
\eqc \kstar C
$$
onde $C,C'$, etc.~denotam conjuntos contáveis.
E tambem temos:
$$
\gather
\Delta \eqc \cantorset \eqc \pset\nats \\
(\alpha,\beta) \eqc [\alpha,\beta) \eqc (\alpha,\beta] \eqc [\alpha,\beta] \eqc \reals.
\endgather
$$
onde $\alpha,\beta\in\reals\union\set{\minfty,\pinfty}$ tais que $\alpha<\beta$.
Como $\cantorset \subset [0,1]$ concluimos que
$$
\Delta \eqc \cantorset \eqc \pset\nats \leqc
(a,b) \eqc [a,b) \eqc (a,b] \eqc [a,b] \eqc (0,1) \eqc \reals.
$$

%%}}}

\endsection
%%}}}

%%{{{ Two big hypotheses 
\section Duas grandes hipoteses.
%%%{{{ meta 
\label Two_big_hypotheses
%%%}}}

%%{{{ Cardinal comparability hypothesis 
\note A hipótese da comparabilidade de cardinais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ CCH 
\hypothesis.
%%%{{{ meta 
\label CCH
%%%}}}

Para todo conjunto $A,B$, $A \leqc B$ ou $B \leqc A$.

%%}}}

%%{{{ The continuum hypothesis 
\note A hipótese do continuum.
%%%{{{ meta 
\credits
    * Godel : CH
    * Cohen : CH
    * Cantor : CH
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ CH 
\hypothesis CH.
%%%{{{ meta 
\label CH
%%%}}}

Não existe subconjunto de reais com cardinalidade estritamente
entre as cardinalidades de $\nats$ e de $\reals$:
$$
\lforall {X \subset \reals} {X \leqc \nats \lor X \eqc \reals}.
$$

%%}}}

%%{{{ GCH 
\hypothesis GCH.
%%%{{{ meta 
\label GHC
%%%}}}

Para todo conjunto infinito $A$, não existe conjunto com cardinalidade
estritamente entre as cardinalidades de $A$ e de $\pset A$.
$$
\lforall {A} {\text{$A$ infinite} \implies \lforall {X \subset \pset A} {X \leqc A \lor X \eqc \pset A}}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Transfinite_numbers 
\section Os números transfinitos.
%%%{{{ meta 
\label Transfinite_numbers
%%%}}}

%%{{{ ordinals_vs_cardinals 
\note Ordinais \vs cardinais.
%%%{{{ meta 
\label ordinals_vs_cardinals
%%%}}}

Na língua natural temos os números \dterm{cardinais}
\quotepar
um, dois, três, quatro, cinco, \dots
\endquote
e os números \dterm{ordinais}
\quotepar
primeiro, segundo, terceiro, quarto, quinto, \dots
\endquote
{\Cantor}Cantor generalizou esses números finitos para os casos finitos,
que chamou de \dterm{números transfinitos} (veja \cite[cantortransfinite]).
Os cardinais representam \emph{quantidades} e os ordinais \emph{ordens}.
Abusando pouco a lingua, podemos dizer que o cardinal dum conjuno $A$
mostra \emph{quantos membros ele tem}, e o ordinal dum conjunto ordenado
$\ssetfont B$ \emph{mostra quão longo ele é}.

%%}}}

%%{{{ Transfinite arithmetic 
\note Aritmética transfinita.
%%%{{{ meta 
\credits
    * Cantor : aritmética transfinita
    ;;
%%%}}}

Bem mais que isso, Cantor conseguiu definir e elaborar uma
\dterm{aritmética transfinita:}
definiu operações de adição, multiplicação, e exponenciação
nesses números e sua aritmética realmente---além de ser
linda---é muito útil e interessante.
Neste capítulo não vamos nos preocupar com isso---paciência até
o~\reffull[Axiomatic_set_theory] (\reftag[Cardinal_arithmetic])
e o~\reffull[Ordinal_arithmetic] (todo!).

%%}}}

\endsection
%%}}}

%%{{{ A taste of measure theory 
\section Um toque de teoria da medida.
%%%{{{ meta 
%%%}}}

%%{{{ from sets to new theories 
\note.
%%%{{{ meta 
%%%}}}

Assim que {\Cantor}Cantor, {\Dedekind}Dedekind, e seus seguidores
desenvolveram essa primeira teoria de conjuntos, os matemáticos
da época ganharam uma ferramenta poderosa e útil que nos liberou
e guiou para desenvolvemento de bem mais teorias interessantes, como:
\emph{teoria de espaços métricos}, \emph{topologia geral},
e \emph{teoria da medida}.
Nesse texto vamos dedicar um capítulo para a primeira (\ref[Metric_spaces])
e um para a segunda (\ref[General_topology]),
e apenas uma secção (esta!)~para a terceira.

%%}}}

%%{{{ measure theory 
\note.
%%%{{{ meta 
%%%}}}

Vários matemáticos, principalmente {\Borel}Borel, {\Baire}Baire,
{\Lebesgue}Lebesgue, {\Frechet}Frechét, {\Hausdorff}Hausdorff,
desenvolveram a teoria da medida.
Podemos pensar em medida como uma generalização do comprimento dum intervalo
$(a,b)$ de reais, em tal jeito que podemos atribuir um ``comprimento''
(ou seja, \dterm{medir}) conjuntos bem mais complicados que intervalos,
e equivalentemente para dimensões maiores, generalizando assim as idéias
de área, volume, etc.
Isso nos leva para uma \emph{teoria de integração} bem mais poderosa que
a primeira que encontramos (integral {\Riemann}Riemann), e também serve
como base para fundar a \emph{teoria de probabilidade}, graças ao
{\Kolmogorov}Kolmogorov (\yearof{1933}, \cite[kolmogorovprob]).
Nosso interesse aquí tem a ver com probabilidade mesmo, pois queremos
responder na pergunta seguinte.

%%}}}

%%{{{ Q: pick a random number from [0,1]; what is the probablity that... 
\question.
%%%{{{ meta 
%%%}}}

Escolhemos \emph{aleatoriamente} um número real $r\in[0,1]$.
Qual a probabilidade de $r$ ser\dots
(i) o número $1/2$?
(ii) um número real no $(a,b)$ com $0\leq a<b \leq 1$?
(iii) um número racional?
(iv) um número algébrico?

%%}}}

%%{{{ warning: tends_to_warning 
\warning <<Tende ao>>.
%%%{{{ meta 
\label tends_to_warning
%%%}}}

É um erro comum afirmar certas coisas sobre probabilidades,
números, funcções, limites, etc., especialmente usando frases
como a \emph{<<tende ao>>}, então vou deixar certas coisas claras
aqui antes de começar nosso pequeno estudo.
\eop
{(1)}
A probabilidade dum evento especifico acontecer, se é definida,
é um número real no $[0,1]$.
E números não mexem.
Números não tendem a lugar nenhum.
Números ficam quetinhos nos seus lugares.
\eop
{(2)}
O limite duma funcção também não tende a lugar nenhum.
Se é definido, é apenas um número real;
talvez \emph{estendido} para incluir os $\pminfty$~(\ref[extended_reals]).
Por exemplo, temos
$$
\lim_{x\to\pinfty} 1/x = 0.
$$
Tá vendo essa igualdade aí?
Esse limite \emph{é} o número zero.
O limite \emph{não tende ao} zero.
O limite \emph{é o próprio} zero!
Podemos sim dizer (corretamente) que
\emph{$1/x$ tende ao $0$ quando $x$ tende ao $\pinfty$}.

%%}}}

\endsection
%%}}}

%%{{{ Consequences in computability and definability 
\section Conseqüências em computabilidade e definabilidade.
%%%{{{ meta 
%%%}}}

%%{{{ Aristos vs Blammenos 
\note Áristos vs Blammenos.
%%%{{{ meta 
\label Aristos_vs_Blammenos
%%%}}}

\eop\noi
\centerline{\scshape Cena 1.}
\centerline{\it Segunda-feira, madrugada.}
\centerline{\it Dois amigos, Áristos e Blammenos,}
\centerline{\it estão estudando para a prova de Fundamentos Matemáticos.}
\centerline{\it Eles estão tentando resolver o problema seguinte:}
\standout
\emph{<<O conjunto $P$ de todos os programas de tipo
$\Nat\to\Nat$ é contável?>>}
\endstandout
\dialogue
\who Áristos:
O conjunto $P$ é contável, e aqui minha prova:
o conjunto $S$ de todos os strings feitos por um alfabeto finíto
é contável, e todos os programas possíveis correspondem em apenas
um subconjunto próprio de $S$ (pois todo programa é um string,
mas tem strings que não são programas).
Logo, o $P$ é contável.
\who Blammenos:
Então tu tá afirmando que existe enumeração do $P$?
Eu vou chegar num absurdo com essa hipótese.
Suponha $p_0, p_1, p_2, \dotsc$ uma enumeração de $P$.
Eu defino o programa $p_*$ com o algoritmo bem simples:
$$
p_*(n) = p_n(n) + 1.
$$
Agora temos $p_* \notin P$, pois para todo $n\in\nats$, $p_* \neq p_n$.
\who Á:
Por quê?
\who B:
Seja $n\in\nats$.
Eu vou lhe mostrar que $p_* \neq p_n$.
Calculamos
\compute
p_*(n)
&= p_n(n) + 1   \by {pela def.~$p_*$} \\
&\neq p_n(n)
\endcompute
que mostra que $p_* \neq p_n$.
Ou seja, $p_*$ não é nenhum dos $p_0, p_1, \dotsc$
que a gente supôs que esses são todos os membros do $P$.
Cheguei assim num absurdo, logo $P$ é incontáv---
\who Á:
Peraí, tu tá roubando!
Como teu programa usou essa enumeração $p_0, p_1, \dotsc$?
Se tu tivesse um algoritmo (programa) que gera essa
seqüência, tu teria razão.
\who B:
Hmmm\dots\ \ 
Mas é fácil programar esse algoritmo!
Concordas que podemos gerar facilmente todos os strings no $S$?
\who Á:
Sim, esse programa que gera os strings, a gente já encontrou na aula.
\who B:
Bem, então meu algoritmo é o seguinte:
gere todos os strings $s_0, s_1, s_2, \dotsc \in S$,
mas para cada string que não é um programa, pula para o próximo.
Esse programa gera sim a seqüência $p_0, p_1, p_2, \dotsc$
de todos os programas!
\who Á:
Pqp, faz sentido!
Não consigo achar um erro na tua prova, mas nem na minha!
\who B:
Eu também não consigo achar um erro na tua prova!
\enddialogue

%%}}}

%%{{{ Q: Who is right? 
\question.
%%%{{{ meta 
%%%}}}

Um conjunto não pode ser contável e incontável,
então pelo menos um dos dois alunos tá errado.
Quais são o(s) erro(s)?
Seguindo as suas idéias o que podemos concluir mesmo?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

O Blammenos tá errado.
O problema é que seu programa em algum momento tem que decidir se um string aleatório é um programa válido, e ainda mais, se termina ou não para alguma dada entrada.
Também não podemos chamar a
$$
p_*(n) \neq p_n(n)
$$
verdadeira para todo $n \oftype \Nat$,
pois existe a possibilidade de algum programa não terminar.
Nesse caso os dois lados são $\bot$ (``bottom'').
Podemos então concluir que é impossível criar tal programa!

%%}}}

\TODO Quantos programas?.

\TODO Quantas funcções?.

\TODO Gödel numbers e lista de todos os programas.

\endsection
%%}}}

%%{{{ Problems in Cantor's paradise: Russell's paradox 
\section Problemas no paraíso de Cantor: o paradoxo de Russell.
%%%{{{ meta 
%%%}}}

%%{{{ Russell's paradox 
\note O paradoxo de Russell.
%%%{{{ meta 
\label russells_paradox
\defines
    * paradoxo!de Russell
    ;;
%%%}}}

Russell\Russell[paradoxo], no ano \yearof{1902},
observou que o conjunto
$$
\Univ \defeq \setstt x {$x$ é conjunto}
$$
tem uma peculiaridade, uma propriedade estranha:
\emph{ele pertence nele mesmo}, ou seja, $\Univ\in \Univ$.
Os conjuntos que encontramos em matemática normalmente não têm essa
propriedade: $\aR\nats\notin\aB\nats$,
pois o $\aR\nats$ não é um número natural!
Similarmente $\set{0,1,\set{1,2}}\notin\set{0,1,\set{1,2}}$, pois
$\set{0,1,\set{1,2}} \neq 0$,
$\set{0,1,\set{1,2}} \neq 1$, e
$\set{0,1,\set{1,2}} \neq \set{1,2}$.
Também $\aR\emptyset \notin \aB\emptyset$ pois nada pertence ao $\aB\emptyset$.
Tudo bem, nenhum problema com isso, mas faz sentido definir o conjunto de
todos os conjuntos ``tranqüilos'', ou seja, aqueles que não têm essa
propriedade estranha de pertencer neles mesmo.
Russell definiu então o conjunto seguinte:
$$
\align
R &\defeq \setstt x {$x$ é conjunto~\andword~$x$ é tranqüilo} \\
  &=      \setstt x {$x$ é conjunto~\andword~$x\notin x$}.
\endalign
$$
E se perguntou:
\emph{o conjunto $R$ é tranqüilo, ou tem essa propriedade estranha?}
Consideramos os dois casos:
Se $\aR R\in \aB R$ então pela definição de $\aB R$
temos que $\aR R$ é tranquilo, ou seja, $\aR R \notin \aR R$,
então esse caso é impossível.
Se $\aR R\notin \aB R$ então $\aR R$ não pertence nele mesmo
(ou seja, $\aR R$ é tranqüilo) e logo pela definição de $\aB R$
temos $\aR R \in \aB R$;
e assim esse caso também é impossível!
Sem muitas palavras:
\compute
\aR R\in {\aB R}
&\implies \text{$\aR R$ tranqüilo}     \by {def.~$\aB R$} \\
&\implies \aR R \notin \aR R           \by {def.~$\aR R$ tranqüilo} \\
\aR R\notin \aB R
&\implies \text{$\aR R$ não tranqüilo} \by {def.~$\aB R$} \\
&\implies \aR R \in \aR R              \by {def.~$\aR R$ tranqüilo} \\
\endcompute
Ou seja, concluimos que:
$$
R \in R \iff R \notin R
$$
e naturalmente queremos escrever um grande \emph{``absurdo''} neste momento,
mas\dots{}
De onde chegamos nesse absurdo?
Todas as vezes que chegamos num absurdo até agora, foi tentando demonstrar algo:
\emph{supondo uma hipótese $H$}, chegamos num absurdo, então concluimos que
sua negação $\lnot H$ é verdade, ou vice-versa, usando o ``reductio ad absurdum'',
querendo demonstrar que a $H$ é verdade supomos sua negação $\lnot H$,
achamos um absurdo e concluimos que nossa suposição não pode ser correta,
logo $H$.
Mas aqui não começamos supondo algo aleatoriamente.
Qual vai ser nossa conclusão agora?
Parece que chegamos num absurdo apenas com lógica sem supor nada ``extra''.
Será que lógica ou matemática é quebrada?

%%}}}

%%{{{ General Comprehension Principle 
\principle Comprehensão geral.
%%%{{{ meta 
\label general_comprehension_principle
%%%}}}

Seja $P(\dhole)$ uma condição definitiva.
Existe um conjunto
$$
\setst x {P(x)}
$$
cujos membros são exatamente todos os objetos $x$
que satisfazem a condição: $P(x)$.

%%}}}

%%{{{ cor: The general comprehension principle is invalid 
\corollary Russell.
%%%{{{ meta 
%%%}}}

O princípio da comprehensão geral não é válido.

\proof.
Supondo que é, chegamos no absurdo que achamos no~\reftag[russells_paradox].

%%}}}

%%{{{ the general Russell paradox 
\remark O paradoxo de Russell geral.
%%%{{{ meta 
%%%}}}

O paradoxo de Russell que encontramos fala de conjuntos e de pertencer,
mas facilmente identificamos que seu paradoxo é apenas um caso duma
verdade mais geral.
Considere uma relação $R$.
A fórmula
$$
\lnot
\exists x
\forall y
\paren{ R(x,y) \liff \lnot R(y,y) }
$$
é um tautologia; um teorema da FOL.
Suponha que tal $x$ existe, e o chame de $x_0$.
Como $R(x_0, y) \liff \lnot R(y,y)$ para todos os $y$, então
tomando $y \asseq x_0$ chegamos na contradição
$$
R(x_0,x_0) \liff \lnot R(x_0,x_0).
$$
Observe que tomando como $R$ a relação $\in$ e como universo
o universo matemático comum, chegamos no paradoxo de Russell.

%%}}}

\endsection
%%}}}

%%{{{ Russell's and Zermelo's solutions 
\section As soluções de Russell e de Zermelo.
%%%{{{ meta 
%%%}}}

%%{{{ theory of types 
\note Teoria dos tipos (Russell).
%%%{{{ meta 
\credits
    * Russell : teoria dos tipos
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ axiomatic set theory 
\note Teoria axiomática dos conjuntos (Zermelo).
%%%{{{ meta 
\credits
    * Zermelo : teoria axiomática dos conjuntos
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ credits 
\note Créditos.
%%%{{{ meta 
\credits
    * Zermelo    : teoria dos conjuntos
    * Fraenkel   : teoria dos conjuntos
    * Mirimanoff : teoria dos conjuntos
    * Skolem     : teoria dos conjuntos
    * vonNeumann : teoria dos conjuntos
    ;;
%%%}}}

A teoria axiomática de conjuntos que estudamos neste capítulo é conhecida
como ``Zermelo--Fraenkel set theory''.
Mesmo assim, mais foram envolvidos na sua evolução, sua definição, e seu
amadurecimento, como os Mirimanoff, Skolem,
e von~Neumann, entre outros.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: a_letter_from_cantor_to_dedekind 
\problem Uma carta de Cantor para Dedekind.
%%%{{{ meta 
\label a_letter_from_cantor_to_dedekind
\credits
    * Cantor
    * Dedekind
    ;;
%%%}}}

\emph{Dia 20 de junho, 1877.}
Cantor manda uma carta para Dedekind onde
ele defina a funcção $f : [0,1]^2 \to [0,1]$ pela
$$
f(a, b)
= 0.a_1b_1a_2b_2a_3b_3\dotsc
\qtext{onde}
\leftbrace {
\aligned
a &\eqass 0.a_1a_2a_3\dotsc\\
b &\eqass 0.b_1b_2b_3\dotsc
\endaligned
}
$$
são as expansões decimais \emph{que não terminam em 0's repetidos},
exceto para o proprio $0$ que só tem essa representação mesmo.\foot
Na verdade esta definição é um caso especial da definição
de Cantor; sua funcção foi do ``cubo $n$-dimensional'' para
o $[0,1]$.
\toof
Afirmando que ela é bijetora ele ficou surpreso que 
tinha conseguido demonstrar que $[0,1]^2 \eqc [0,1]$.
Ansioso, está esperando a resposta de Dedekind.
\eop
\emph{Dia 22 de junho, \yearof{1877}.}
Cantor recebe a carta-resposta:\foot
sim, foi tão rapido; e sim, foi pelos correios mesmo!
\toof
Dedekind percebeu um erro na demonstração!
\eop
\emph{Dia hoje.}
Tendo lido tudo isso, tu respondes nas perguntas seguintes:
(1) Por que Cantor botou a restricção <<que não terminam em $0$'s repetidos>>?
(2) Qual o erro de Cantor?\foot
Cantor, corrigiu sua demonstração e mandou numa nova carta-resposta,
onde também incluiu sua demonstração que $(0,1] \eqc [0,1]$
(\ref[change_of_ends_of_intervals_without_bernstein]).
Dedekind essa vez não respondeu tão rápidamente, e Cantor
mandou um lembrete com a frase
\emph{je le vois, mais je ne le crois pas}
referindo à sua descoberta.
Ele escreveu essa frase em francês mesmo, mesmo que
a comunicação entre eles foi em alemão.
Traduzindo: \dq{eu o vejo, mas eu não o acredito}.
\toof

\hint
(1) Precisamos disso para que $f$ seja bem-definida (por quê?).
(2) A $f$ não é bijetora!  (Por quê?)

\solution
(1) Precisamos disso para que $f$ seja bem-definida.
Sem essa restricção, para onde $f$ manda o $\tup{1/2,1/3}$?
O $1/3$ realmente \emph{determina} os $b_j$'s, mas o $1/2$
não determina os $a_i$'s pois:
$$
0.4999\dots = 1/2 = 0.5000\dots
$$
e logo a $f$ não seria bem-definida sem essa restricção,
já que seu valor dependeria (e mudaria) dependendo dessa escolha.
\eop\noi
(2) A $f$ não é bijetora!
Basta só criar um exemplo que sua preimagem precisaria dum
número cuja expansão termina em $000\dots$:
$$
f( ? ) = 0.5303030303\dots
$$
Nenhuma entrada $(a,b)$ pode ser mapeada nesse número, pois pela
definição da $f$ o $b$ só pode ser o $0.333\dots = 1/3$
(e nenhum problema com isso), e agora o $a$ só pode ser ser o $0.5000\dots$,
ou seja, $a=1/2=0.5000\dots=0.4999\dots$.
Calculamos
$$
f(\frac 1 2,\frac 1 3) = 0.43939393 \neq 0.530303\dots
$$
e logo $f$ não é sobrejetora!

%%}}}

%%{{{ prob: change_of_ends_of_intervals_without_bernstein 
\problem Sem Bernstein.
%%%{{{ meta 
\label change_of_ends_of_intervals_without_bernstein
%%%}}}

Mostre pela definição a equinumerosidade
$$
(a,b) \eqc [a,b) \eqc [a,b];
$$
onde $a,b \in \reals$ e tais que os intervalos não são
nem vazios nem singletons.

\hint
Aqui duas maneiras diferentes para o $(a,b) \eqc [a,b)$:
(i) demonstre $[0,\pinfty) \eqc (\minfty,\pinfty)$;
(ii) demonstre $(0,1] \eqc (0,1)$.

\hint
Seguindo a idéia (i) da primeira dica:
lembre como provamos que $\nats\eqc\ints$;
e seguindo a idéia (ii):
faz sentido mandar o $1$ para o $1/2$; e o $1/2$?

\hint
Seguindo a idéia (i):
$\reals = \Union_n [n,n+1)$.
Seguindo a idéia (ii):
defina uma funcção $f : (0,1] \eqc (0,1)$ por casos:
$$
f(x) =
\knuthcases {
\askhole & se \asklhole \cr
\askhole & caso contrário
}
$$
tal que
$$
\align
1    &\mapstoby f 1/2 \\
1/2  &\mapstoby f \askhole \\
     &\eqvdots \\
\askhole  &\mapstoby f \askhole
\endalign
$$

%%}}}

%%{{{ prob: reals_eqc_irrats_without_bernstein 
\problem Ainda sem Bernstein.
%%%{{{ meta 
\label reals_eqc_irrats_without_bernstein
\credits
    * Cantor
    ;;
%%%}}}

Cantor demonstrou direitamente (pela sua definição) que
$$
[0,1] \eqc [0,1]\setminus\rats.
$$
Faça o mesmo.

\hint
Já sabemos que o $\rats$ é contável; logo o $\rats\inter[0,1] \subset \rats$
também é.
Seja $\seqn q n$ uma enumeração dos racionais do $[0,1]$.

\hint
Agora defina uma seqüência $\seqn \eta n$
de irracionais no $[0,1]$ distintos dois a dois.
Tente ser específico, mas não importa qual tu vai escolher.

\hint
Cantor usou a seqüência de irracionais $\seqn \eta n$ definida pela
$\eta_n = \sqrt 2 / 2^{n+1}$.
Outra escolha seria a $\frac 1 {n + \sqrt 2}$.
(Verifique que todos os membros de ambas as seqüências são irracionais.)

\hint
Defina a $f : [0,1] \to [0,1]\setminus\rats$ mandando
cada $x \in [0,1]$ nele mesmo, exceto os membros das
$\seqnset q n$ e $\seqnset \eta n$.
Fazer o que com eles?

%%}}}

%%{{{ prob: sime_simo_eqclass_card 
\problem.
%%%{{{ meta 
\label sime_simo_eqclass_card
\pdefs
    \pdef sime {\rel{\stackrel{{}_{\mathrmsmall e}}=}}
    \pdef simo {\rel{\stackrel{{}_{\mathrmsmall o}}=}}
    ;;
%%%}}}

No $(\nats\to\nats)$ sejam as relações $\sime$ e $\simo$ como no~\ref[simz_sime_simo_simi]:
$$
\align
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$}\\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$}.
\endalign
$$
Qual é a cardinalidade do $\eqclass f {\sime} \inter \eqclass f {\simo}$?

%%}}}

%%{{{ prob: define three eqrels such that quosets have certain cards 
\problem.
%%%{{{ meta 
%%%}}}

No conjunto dos reais $\reals$, defina três relações de equivalência
$\sim_1$, $\sim_2$, $\sim_3$, diferentes da igualdade $\eqof \reals$,
da vazia, e da trivial $\mathsf{True}$, tais que:
$$
\xalignat3
\quoset \reals {\sim_1} &\ltc \nats &
\quoset \reals {\sim_2} &\eqc \nats &
\quoset \reals {\sim_3} &\gtc \nats.
\endxalignat
$$
Para cada uma, descreva seu conjunto quociente.

\hint
Cada relação de equivalência corresponde numa partição e vice-versa,
então basta definir três partições.

\solution
Cada relação de equivalência corresponde numa partição e vice-versa,
então descrevemos as três partições diretamente:
$$
\align
\scr C_1 &= \set   {(\minfty,0), \set{0}, (0,\pinfty)} \\
\scr C_2 &= \setst {[n,n+1)} {n\in\ints} \\
\scr C_3 &= \setst {\set{a}} {a\in\reals\setminus\rats} \union \set{\rats}.
\endalign
$$
Sem usar partições poderiamos definir as relações diretamente assim:
$$
\align
x \sim_1 y &\defiff \text{$x=y$ ou $xy>0$} \\
x \sim_2 y &\defiff \floor x = \floor y \\
x \sim_3 y &\defiff \text{$x = y$ ou $x,y\in\rats$}.
\endalign
$$

%%}}}

%%{{{ codeit: RatApprox 
\codeit RatApprox.
%%%{{{ meta 
\label RatApprox
%%%}}}

Usando uma implementação de enumeração $\set{q_n}_n$ do $\rats$
(com ou sem repetições), implemente uma funcção
$a : \reals\times\reals \to \nats$ que, dados $x\in\reals$ e $\epsilon>0$
retorna o primeiro $n\in\nats$ com a propriedade $\abs{q_n - x} < \epsilon$:
$$
a(x,\epsilon) = \min\setst{n\in\nats}{\abs{q_n-x}<\epsilon}.
$$
\eop
Se tua linguagem de programação suporta funcções de ordem superior,
considere que seu primeiro argumento deve ser a própria enumeração $q$:
$$
\align
\namedfun{ratApprox} &\eqtype (\nats\to\rats) \to \reals \to \reals \to \nats\\
\namedfun{ratApprox}\ q\ x\ \epsilon &= \min\setst{n\in\nats}{\abs{q_n-x}<\epsilon}
\endalign
$$
Alternativamente, pode representar uma enumeração de racionais
como uma lista (infinita) de racionais.  Considere retornar o
primeiro racional suficientemente próximo além de apenas seu
índice.  Improvise e teste sua funcção, vendo quanto ``demora''
uma enumeração para chegar suficientemente perto de um número
pre-determinado, sendo racional ou não.
Por exemplo, use $x=\sqrt 2$ ou $e$ ou $\pi$,
e
$\epsilon=1, 1/2, 1/4, \dotsc$.
Assim, para qualquer real $x$, tu pode
\emph{construir}---mesmo não muito ``eficientemente''---uma
seqüência de racionais que converge em $x$, apenas aplicando a funcção
$\lambda \epsilon. \namedfun{ratApprox}\ q\ x\ \epsilon$
em argumentos que formam qualquer seqüência que convirja no zero!

%%}}}

%%{{{ df: terminating_game 
\definition Jogo terminante.
%%%{{{ meta 
\label terminating_game
\defines
    * jogo!terminante
    ;;
%%%}}}

Consideramos jogos entre 2 jogadores.
Chamamos um jogo \dterm{terminante} sse não tem partidas infinitas.
Ou seja, seguindo suas regras cada partida termina depois um finíto número de turnos.

%%}}}

%%{{{ df: hypergame 
\definition Hypergame (Zwicker).
%%%{{{ meta 
\label hypergame
\defines
    * hypergame
    ;;
%%%}}}

{\Zwicker[hypergame]}%
Considere o jogo seguinte $\cal H$, chamado \dterm{hypergame}:
O $\cal H$ começa com o {\scshape Player~I} que escolha um jogo terminante $G$.
O {\scshape Player~II} começa jogar o jogo $G$ contra o {\scshape Player~I}.
Quem ganha nesse jogo $G$ é o vencedor do jogo $\cal H$.

%%}}}

%%{{{ eg: hypergame_plays 
\example.
%%%{{{ meta 
\label hypergame_plays
%%%}}}

Por exemplo, sendo um bom jogador de ``jogo da velha'' e um pessimo jogador
de xadrez, se eu for o {\scshape Player~I} num hypergame, meu primeiro
movimento seria escolher o jogo terminante ``jogo da velha'' para jogar.
Meu oponente, se for o {\scshape Player~I} duma partida de hypergame,
seu primeiro movimento seria escolher o jogo terminante ``xadrez''.
Depois desse movimento eu viro o {\scshape Player~I} no xadrez.
Quem vai ganhar nesse xadrez, vai ser o vencidor dessa partida de hypergame.

%%}}}

%%{{{ hypergame_paradox 
\note O paradoxo de hypergame.
%%%{{{ meta 
\label hypergame_paradox
\pdefs
    \pdef O {\text{\tt O}}
    \pdef P {\text{\tt P}}
    ;;
%%%}}}

Zwicker{\Zwicker[hypergame]} percebeu o seguinte paradoxo, se perguntando
se o próprio Hypergame é um jogo terminante ou não.
Claramente tem que ser, pois a primeira regra do jogo obriga o {\scshape Player~I}
escolher um jogo terminante.  Logo, depois de $n\in\nats$ turnos, esse jogo
termina, e junto com ele termina a partida do hypergame (em $n+1$ turnos).
Então hypergame é terminante.
Logo, numa partida de hypergame, o {\scshape Player~I} pode escolher o próprio
hypergame.  Assim começamos uma sub-partida de hypergame, onde o
{\scshape Player~II} toma o papel de {\scshape Player~I}.
Se ele escolher, por exemplo, ``jogo de velha'', a partida parece assim:
$$
\def\drawTTTboard{%
\draw (-1, 3)     -- (-1,-3);
\draw ( 1, 3)     -- ( 1,-3);
\draw (-3, 1)     -- ( 3, 1);
\draw (-3,-1)     -- ( 3,-1);
}
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Jogo de velha''}\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- (0.7, 0.7);
\draw (-0.7, 0.7) -- (0.7,-0.7);
\endtikzpicture
\endgathered\\
\phantom{\P}\vdots\quad&\vdots\\
\O:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
\endtikzpicture
\endgathered\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
% X-moves
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw ( 1.3,-0.7) -- ( 2.7, 0.7);
\draw ( 1.3, 0.7) -- ( 2.7,-0.7);
% O-moves
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
% draw winning line
\draw (-2.7, 0.0) -- ( 2.7, 0.0);
\endtikzpicture
\endgathered\\
\endalign
$$
Onde denotamos os dois jogadores com $\P$ e $\O$ (de ``Player'' e ``Opponent'').
Mas, agora a partida seguinte é possível:
$$
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\phantom{\P}\vdots\quad&\vdots
\endalign
$$
e achamos uma partida infinita do hypergame!
Logo o hypergame não é terminante.

%%}}}

%%{{{ prob: from_hypergame_to_cantors_theorem 
\problem.
%%%{{{ meta 
\label from_hypergame_to_cantors_theorem
%%%}}}

Seja conjunto $A$ e suponha que existe injecção $\phi : A \injto \pset A$.
Para todo $x\in A$, denota com $A_x$ o $\phi(x)$, ou seja, $A_x$
é o subconjunto de $A$ associado com o $x$.
Seja $a\in A$.  Chame um \dterm{caminho} de $a$ qualquer seqüência
finita ou infinita $\set{a_i}_i$ de elementos de $A$ que satisfaz:
$$
\align
a_0     &= a\\
a_{n+1} &\in A_{a_n}.
\endalign
$$
Finalmente, chame um $a\in A$ \dterm{terminante} se todos os caminhos
de $a$ são finítos.  Use o paradoxo do Hypergame para demonstrar que
a $\phi$ não pode ser sobrejetora, achando assim uma nova prova
do teorema de Cantor~\reftag[cantor_theorem].

\hint
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta demonstrar que $T\notin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, demonstrando assim que $\phi$ não é bijetora.

\hint
Suponha para chegar num absurdo que $T=A_a$ para algum $a\in A$.

\hint
$T = \emptyset$?

\solution
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta demonstrar que $T\notin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, demonstrando assim que $\phi$ não é bijetora.
Suponha para chegar num absurdo que $T\in \img\phi A$ e logo seja
$a \in A$ tal que $T=A_a$\fact1.
Observe que $T\neq\emptyset$, pois se fosse vazio o $a$ seria terminante
e logo pertenceria ao $T$; absurdo.
Vamos demonstrar que qualquer caminho de $a$ é terminante.
Seja $\alpha$ um caminho de $a$:
$$
\alpha = \paren{\alpha_0, \alpha_1, \alpha_2, \dotsc}
$$
Logo $\alpha_1 \in A_{\alpha_0} = A_a = T$,
ou seja $\alpha_1$ é terminante,
e logo o caminho $\paren{\alpha_1, \alpha_2, \dotsc}$ é finito!
Logo o $\paren{\alpha_0,\alpha_1,\alpha_2,\dotsc}$ também é.
Mostramos então que o arbitrário caminho de $a$ é finito;
ou seja, todos são; ou seja, $a$ é terminante\fact2~e logo
$a \in T$\fact3.
Mas aqui um caminho infinito de $a$:
$$
\align
a_0 &\asseq a \\
a_1 &\asseq a \\
a_2 &\asseq a \\
a_3 &\asseq a \\
    &\eqvdots
\endalign
$$
ou seja, o caminho seguinte:
$$
\paren{a,a,a,\dotsc}
$$
Isso realmente é um caminho de $a$ pois pelos~\byfact1~e~\byfact3,
$a \in A_a$ e logo substituindo iguais por iguais,
$$
\mubrace {a_{n+1}} {a} \in A_{\mubrace {a_n} {a}}.
$$
Concluimos então que $a$ não é terminante, contradizendo o~\byfact2.
Chegamos assim num absurdo, e logo nossa hipótese que
$T \in \img \phi A$ não é válida, ou seja, $T \notin \img \phi A$
e logo $\phi$ não é sobrejetora.

%%}}}

%%{{{ prob: weird_convex_now_easy 
\problem Agora é fácil.
%%%{{{ meta 
\label weird_convex_now_easy
%%%}}}

Para resolver o~\ref[weird_convex_hard] demonstramos um certo
``buraco'' que o $Q_1$ tem: o $(0,0)$.
Tem outro(s)?  Quantos?

\hint
Considere a diámetro horizontal $\setst {(x,0)} {-1 < x < 1}$.

%%}}}

%%{{{ thm: von_Lindemann_theorem 
\theorem von Lindemann.
%%%{{{ meta 
\label von_Lindemann_theorem
\credits
    * vonLindemann
    ;;
%%%}}}

Para todo $\alpha\neq0$ algébrico, $e^\alpha$ é transcendental.

%%}}}

%%{{{ prob: pi_is_transcendental 
\problem.
%%%{{{ meta 
\label pi_is_transcendental
\credits
    * vonLindemann
    ;;
%%%}}}

Dado o teorema de von~Lindemann \reftag[von_Lindemann_theorem]
demonstre que $\pi$ é transcendental.

\hint
Se $\pi$ fosse algébrico, $i\pi$ também seria.

%%}}}

%%{{{ prob: russell_prondo_exam 
\problem.
%%%{{{ meta 
\label russell_prondo_exam
%%%}}}

Responda com `T' ou `F' quando possível:
\elist a:
\li: o conjunto dos números transcendentais é contável:
\li: existe irracional $\alpha$ tal que $\alpha^\alpha$ é racional:
\li: nas questões do~\ref[russell_prondo_exam] tem mais afirmações falsas do que verdadeiras:
\li: o conjunto $(\nats\to\set{0,1})$ é contável:
\li: o segmento $[0,1]$ é equinúmero com o cubo $[0,1]^3$:
\endelist

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

%%{{{ blah 
\blah Sobre a teoria de conjuntos de Cantor.
%%%{{{ meta 
%%%}}}

\cite[kleeneIM], \cite[ynmnst].

Um livro muito divertido que trata bem essas idéias de infinito
que encontramos aqui é o \cite[satancantorinfinity: Part~VI].

No \ref[russell_prondo_exam], a terceira questão caiu numa
prova final de Panos Rondogiannis.

%%}}}

%%{{{ blah: About measure theory 
\blah Sobre teoria da medida.
%%%{{{ meta 
%%%}}}

\cite[bartlemeasure],
\cite[halmosmeasure],
\cite[taylorintegration].

%%}}}

%%{{{ blah: About the steps that lead Cantor to his discoveries 
\blah Sobre os passos que levaram Cantor nas suas descobertas.
%%%{{{ meta 
%%%}}}

\cite[srivastavacantor].
Mais sobre a construtividade e os ataques injustos contra a
demonstração de Cantor no~\cite[grayaboutcantor].
{\Cantor}Cantor conheceu {\Dedekind}Dedekind na Suiça no \yearof{1872}
e desde então e até \yearof{1899} trocaram muitas cartas entre si
comunicando suas idéias que acabaram gerando as teorias que
conhecemos aqui neste capítuo e que vão muito além disso!
A colecção dessas cartas foi publicada no \cite[cantordedekind].
O \cite[gouveacantor] é artigo curto e bem escrito que resuma
a historia entre Cantor e Dedekind, oferecendo também uma análise
na situação, nos posicionamentos, e até nos possíveis sentimentos
envolvidos dos dois homens.
O \cite[ferreiroscantordedekind] é uma análise mais extensa,
defendendo bastante a contribuição de Dedekind nos resultados
que geralmente atribuimos apenas ao Cantor.

%%}}}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Axiomatic_set_theory 
\chapter Teoria axiomática dos conjuntos.
%%%{{{ meta 
\label Axiomatic_set_theory
%%%}}}

%%{{{ intro: sets like assembly 
\chapintro
Quando ``protoencontramos'' conjuntos no~\ref[Sets],
prometi que eles têm um papel importante para a \emph{fundação de matemática}.
Chegou a hora para ver o porquê!
Podemos traduzir todas as definições e relações matemáticas nessa
linguagem.  Nesse sentido, parece como uma ``assembly'', uma linguagem
``low-level'' onde podemos ``compilar'' toda a matemática, em tal modo
que cada definição, cada afirmação, cada teorema que provamos,
no final das contas, todos podem ser traduzidos para definições,
afirmações, teoremas e provas, que envolvem apenas conjuntos
e a relação primitiva de \emph{pertencer}.
E \emph{nada} mais!
%%}}}

%%{{{ The_principle_of_purity 
\section O princípio da puridade.
%%%{{{ meta 
\label The_principle_of_purity
%%%}}}

%%{{{ df: urelement 
\definition urelemento.
%%%{{{ meta 
\label urelement
\indexes
    * átomo    seealso: urelemento
    ;;
\defines
    * urelemento
    ;;
%%%}}}

Chamamos de \dterm{átomos} ou de \dterm{urelementos}, os objetos que não são
conjuntos (mas podem pertencer a conjuntos).  Números, funcções, pessoas,
sapos, planetas, etc.

%%}}}

%%{{{ principle: principle_of_purity 
\principle Puridade.
%%%{{{ meta 
\label principle_of_purity
\indexes
    * puridade    see: princípio da
    ;;
\defines
    * princípio!da puridade
    ;;
%%%}}}

Tudo é conjunto.

%%}}}

%%{{{ seems like a bad idea 
\note Seria ruim assumir o princípio da puridade.
%%%{{{ meta 
%%%}}}

Como assim <<só tem conjuntos>>?
É pra jogar fora os objetos de todos os outros tipos que temos estudado
até agora?
E os números, as funcções, os grupos?  E as pessoas?  Eu com certaza existo,
e meu leitor também, não é assim?  Se nosso universo é para ter apenas conjunto
só vamos conseguir falar de conjuntos.  E em matemática mesmo que os conjuntos
são importantes per se, temos muitas coisas também importantes que não são conjuntos.
Então não faz sentido nos limitar.
Ou talvez faz:

%%}}}

%%{{{ or is it? 
\note Seria bom assumir o princípio da puridade.
%%%{{{ meta 
%%%}}}

Alguém falando sobre computadores e programação falou:
\quote
\wq{Tudo é $0$'s e $1$'s.  Não tem nada mais que isso.}
\endquote
Primeiramente temos que apreciar a simplicidade dum mundo
onde \emph{só tem bits}.
No outro lado, meu computador tem este texto que tô escrevendo
aqui pra ti; e umas músicas, fotos, vídeos---e mais coisas que
não são da tua conta.  Os programas que programamos e que usamos
manipulam números, conexões, documentos, ou até outros programas.
O que o rapaz acima quis dizer com sua afirmação então?
Bem, com certeza esse documento \emph{não é} uma seqüência
de $0$'s e $1$'s, mas \emph{pode ser representado fielmente}
por uma.  E é assim que meu computador o representa mesmo.
Pensando na mesma maneira, quando optamos para assumir
o princípio da puridade parece que vamos perder tudo que
não é conjunto como algo primitivo; mas se conseguirmos
\emph{representá-lo fielmente} dentro do mundo dos conjuntos
não vamos perder nada essencialmente.
Vamos voltar nesse assunto daqui a pouco
na~\reftag[Foundations_of_mathematics].

%%}}}

%%{{{ What would Zermelo do? 
\note O que Zermelo faria?.
%%%{{{ meta 
\label what_would_zermelo_do
%%%}}}

Zermelo não assumiu o princípio da puridade, nem sua negação.
Ou seja, talvez o universo tem urelementos, talvez não.
Como nenhum teorema dependeu na existência deles, então tudo continua válido
mesmo se escolher assumí-lo, \emph{algo que vamos fazer aqui},
comentando às vezes o que teria que mudar caso que não tivemos esse princípio.
Assim não vamos precisar do predicado $\Set(\dhole)$ que teriamos de carregar
em muitas definições e demonstrações.

%%}}}

\endsection
%%}}}

%%{{{ FOL_translations_for_sets 
\section Traduções de e para a FOL de conjuntos.
%%%{{{ meta 
\label FOL_translations_for_sets
%%%}}}

%%{{{ The FOL of set theory 
\note A FOL da teoria de conjuntos.
%%%{{{ meta 
%%%}}}

Nessa linguagem de primeira ordem temos apenas um predicado não-constante:
o $\in$, de aridade 2, cuja interpretação canônica é ``\thole\ pertence ao \thole''.
Nosso universo aqui consiste (apenas) em conjuntos, ou seja
assumimos o princípio da puridade (\reftag[principle_of_purity]).

%%}}}

%%{{{ x: FOL_translations_for_sets_exercise 
\exercise.
%%%{{{ meta 
\label FOL_translations_for_sets_exercise
%%%}}}

Traduza as frases seguintes para a FOL da teoria de conjuntos.
\elist 1:
\li: Existe conjunto sem membros.
\li: O conjunto $x$ não tem membros.
\li: O conjunto $y$ tem membros.
\li: Existe conjunto com membros.
\li: O $x$ é um singleton.
\li: Existe conjunto com exatamente um membro.
\li: Existe conjunto com pelo menos dois membros.
\li: Os $x$ e $y$ têm exatamente um membro em comum.
\li: Todos os conjuntos tem o $x$ como membro.
\li: Existe conjunto que pertence nele mesmo.
\li: O $y$ consiste em todos os subconjuntos de $x$ com exatamente 2 elementos.
\li: Existe conjunto com exatamente dois membros.
\li: Para todos conjuntos $a$ e $b$ sua intersecção é conjunto.
\li: A união de $a$ e $b$ é um conjunto.
\li: O $x$ não pertence em nenhum conjunto.
\li: Existem conjuntos tais que cada um pertence no outro.
\li: Existe conjunto que não é igual com ele mesmo.
\endelist

%%}}}

%%{{{ Merely saying something doesn't make it true 
\note Apenas escrever algo não o torna verdade.
%%%{{{ meta 
%%%}}}

O fato que podemos expressar uma afirmação numa linguagem não quer dizer
que essa afirmação é válida.  Isso não é nada profundo: em português
também podemos escrever a frase ``a lua não é feita de queijo'', mas isso
não quis dizer que realmente não é---todos sabemos que é, certo?
Infelizmente existe um hábito de confundir as duas noções e usar como
``prova de veracidade de algo'' o fato que apenas esse algo foi escrito,
ou dito.\foot
Veja por exemplo argumentações de várias igrejas de várias religiões.
\toof
A afirmação da fórmula que tu achou para a última frase
do~\ref[FOL_translations_for_sets_exercise] por exemplo é falsa em nosso
mundo de conjuntos e ainda mais: é falsa em cada mundo possível, com qualquer
interpretação do símbolo $\in$!

%%}}}

%%{{{ A useful pattern 
\note Um padrão útil.
%%%{{{ meta 
%%%}}}

Muitas vezes queremos dizer que
existe um certo conjunto \emph{determinado por uma propriedade
característica}, ou seja, um conjunto $s$ que consiste em exatamente
todos os objetos que satisfazem um certo critério.
\eop
\emph{Como podemos dizer isso na FOL da teoria de conjuntos?}
Fácil!  Assim:
$$
\phantom{
\forall a
\forall b
\forall c
\dotsb
}
\alert{
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\tubrace{
\text{\vphantom|\xlthole}
}{critério}
}}}.
$$
Na maioria das vezes queremos afirmar a existência dum certo conjunto
dados conjuntos $a,b,c,\dotsc$.
Nesse caso usamos apenas o
$$
\forall a
\forall b
\forall c
\dotsb
\alert{
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\text{\xlthole}
}}}.
$$
Esse padrão vai aparecer em muitos dos axiomas abaixo.

%%}}}

%%{{{ Abbreviations and syntactic sugar 
\note Abreviações e açúcar sintáctico.
%%%{{{ meta 
%%%}}}

Assim que conseguirmos descrever um conceito interessante com uma fórmula,
faz sentido introduzir uma notação, um novo predicado.
Por exemplo, nas (2) e (5) de~\ref[FOL_translations_for_sets_exercise],
tu achou fórmulas que afirmam que $x$ é vazio, e que $x$ é um singleton.
Faz sentido definir como abreviações então os predicados seguintes:
$$
\align
\Empty(x)
&\sugareq
\lnot \exists w \paren{ w \in x }\\
\Singleton(x)
&\sugareq
\exists w \bigparen{
w \in x
\land
\forall u \paren{ u \in x \limplies u = w }
}
\intertext{e os símbolos:}
a \subset b
&\sugareq \forall x \paren{ x \in a \limplies x \in b }\\
a \subsetneq b
&\sugareq a \subset b \land a \neq b.
\intertext{Lembre-se também nossa práctica onde usamos}
x \neq y
&\sugareq \lnot\, x = y,\\
x \notin y
&\sugareq \lnot\, x \in y,
\endalign
$$
etc.

%%}}}

\endsection
%%}}}

%%{{{ Classes vs. Sets (I) 
\section Classes \vs Conjuntos (I).
%%%{{{ meta 
%%%}}}

%%{{{ What is a class? 
\note O que é uma classe?.
%%%{{{ meta 
%%%}}}

Sem dúvida, a notação $\setstt x {\lthole}$
que temos usado até agora é natural e útil.
Ela denota a colecção de todos os objetos $x$ que satisfazem
a condição (ou ``passam o filtro'') que escrevemos no \lthole.
Dada uma condição definitiva $P$ então consideramos a colecção
$$
\setst x {P(x)}
$$
de todos os objetos que a satisfazem.
Provavelmente vocé já percebeu que eu evitei usar a palavra
\emph{conjunto}, pois reservamos essa palavra para
apenas os conjuntos-objetos do nosso universo.

%%}}}

%%{{{ df: class 
\definition Classe.
%%%{{{ meta 
\indexes
    * própria!classe    see: classe própria
    ;;
\defines
    * classe
    * classe!própria
    ;;
%%%}}}

Dada uma condição definitiva $P(\dhole)$ definimos a \dterm{classe}
$$
\classst x {P(x)}
$$
como um sinónimo da própria condição $P$!
Chamamos a classe $P$ \dterm{própria} sse não existe \emph{conjunto}
$S$ que satisfaz a propriedade:
$$
x \in S \iff P(x).
$$

%%}}}

%%{{{ eg: sets and proper classes 
\example.
%%%{{{ meta 
%%%}}}

Dados conjuntos $a$ e $b$,
das classes
$$
\mubrace{\classst x {x = a}} {\set a}
\qqquad
\mubrace{\classst x {x \in a \land x\in b}} {a\inter b}
\qqquad
\mubrace{\classst x {x \neq x}} {\emptyset}
\qqquad
\classst x {x = x}
$$
apenas a última é própria.
As outras são conjuntos mesmo!

%%}}}

%%{{{ warning: notational abuse 
\warning abuso notacional.
%%%{{{ meta 
%%%}}}

É muito comum abusar o símbolo $\in$, escrevendo
$$
x \in C
$$
mesmo quando $C$ é uma classe própria!
Nesse caso consideramos o $x \in C$ apenas como uma
abreviação do $C(x)$.
Em outras palavras, esse $\in$ não é um símbolo de relação da nossa FOL de
teoria de conjuntos, mas sim uma abreviação em nossa \emph{metalinguagem},
no mesmo jeito que $\iff$ também não é, mas o $\liff$ é.
Quando precisamos enfatizar essa diferença vamos usar um símbolo diferente:

%%}}}

%%{{{ notation: inclass 
\notation.
%%%{{{ meta 
\label inclass
\defines
    * ~x\inclass~C  -- o objeto $x$ está na classe $C$
    ;;
%%%}}}

Usamos o símbolo $\inclass$ na metalinguagem como ``pertence''
quando possivelmente o lado direito é uma classe própria.\foot
Seguimos aqui o exemplo dos símbolos de equivalência na metalinguágem
($\Longleftrightarrow$) e na linguagem-objeto de lógica ($\leftrightarrow$).
\toof
Com essa notação:
$$
x\inclass P
\defiff
\knuthcases {
P(x)    & se $P$ é uma classe própria\cr
x\in P  & se $P$ é um conjunto.
}
$$

%%}}}

\endsection
%%}}}

%%{{{ The first axioms of Zermelo 
\section Os primeiros axiomas de Zermelo.
%%%{{{ meta 
%%%}}}

%%{{{ ax: Extensionality 
\axiom Extensionalidade.
%%%{{{ meta 
\label extensionality
\defines
    * axioma!Extensionality
    ;;
%%%}}}

Todo conjunto é determinado por seus membros.
$$
\forall a \forall b
\paren{
\forall x
\paren{
x \in a
\liff
x \in b
}
\limplies
a = b
}
\axtag[extensionality=ZF1]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Qual o efeito disso em nosso mundo?
Ainda nem podemos garantir a existência de nada,
mas pelo menos sabemos dizer se duas coisas são iguais ou não.
Vamos logo garantir a existência dum conjunto familiar:

%%}}}

%%{{{ ax: Emptyset 
\axiom Emptyset.
%%%{{{ meta 
\label emptyset
\defines
    * axioma!Emptyset
    ;;
%%%}}}

Existe conjunto sem membros.
$$
\exists s \forall x
\paren{
x \notin s
}
\axtag[emptyset=ZF2]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E já nosso mundo mudou completamente:
ganhamos nossa primeira peça, uma coisa para brincar:
\emph{um conjunto sem membros!}
E já estamos em posição de demonstrar nosso primeiro teorema,
seguido pela nossa primeira definição:

%%}}}

%%{{{ thm: uniqueness_of_emptyset 
\theorem Unicidade do conjunto vazio.
%%%{{{ meta 
\label uniqueness_of_emptyset
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

O conjunto sem membros garantido pelo axioma~\axref[emptyset] é único.

\proof.
Suponha que $e, o$ são conjuntos ambós satisfazendo a propriedade:
$$
\forall x\paren{x \notin e}
\qqqquad
\forall x\paren{x \notin o}.
$$
Então a equivaléncia
$$
x\in e \iff x \in o
$$
é válida para todo $x$, pois ambos lados são falsos.
Logo, pelo axioma~\axref[extensionality], $e=o$.

%%}}}

%%{{{ df: emptyset_def 
\definition Conjunto vazio.
%%%{{{ meta 
\label emptyset_def
\defines
    * \emptyset  -- o conjunto vazio
    * conjunto!vazio
    ;;
%%%}}}

Denotamos por $\emptyset$ o \dterm{conjunto vazio} com a propriedade característica
$$
\forall x\paren{x\notin \emptyset}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

\dots e agora parece que não podemos fazer muita coisa mais.
Precisamos novos axiomas:

%%}}}

%%{{{ ax: Pairset 
\axiom Pairset.
%%%{{{ meta 
\label pairset
\defines
    * axioma!Pairset
    ;;
%%%}}}

Dado um par de conjuntos, existe conjunto que consiste
em exatamente os conjuntos do par.
$$
\forall a
\forall b
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x = a
\lor
x = b
}
}
\axtag[pairset=ZF3]
$$

%%}}}

%%{{{ df: doubleton 
\definition Doubleton.
%%%{{{ meta 
\defines
    * \set{~a, ~b}  -- o conjunto doubleton de $a$ e $b$
    * doubleton
    ;;
%%%}}}

Dados $a$ e $b$ quaisquer, o conjunto que consiste nos $a$ e $b$
é chamado o \dterm{doubleton} de $a$ e $b$, e denotado por $\set {a, b}$.
Definimos assim o operador $\set{\dhole, \dhole}$.

%%}}}

%%{{{ Effects 
\note Efeitos.
%%%{{{ meta 
%%%}}}

Como isso muda nosso mundo?
Quais novas peças ganhamos em nosso xadrez?
Para ganhar a existência de algo usando o Pairset
precisamos dar a ele dois objetos,
pois começa com dois quantificadores universais ($\forall$)
antes de chegar no seu primeiro existencial ($\exists$):
``$\forall a\forall b \exists \dots$''.
Quais objetos vamos escolher para dá-lo?
Nosso mundo está tão pobre que é fácil responder nessa pergunta:
\emph{vamos usar como $a$ e como $b$ a única peça que temos: o $\emptyset$}.
Ganhamos então que:
$$
\exists s \forall x \bigparen { x \in s \liff \paren{ x = \emptyset \lor x = \emptyset }}
$$
ou seja, $\exists s \forall x \bigparen { x \in s \liff x = \emptyset }$,
ou seja, existe o conjunto
$$
\setst x {x = \emptyset}
$$
que acostumamos a denotá-lo por $\set \emptyset$.
Uma nova peça!\foot
Agora temos duas opções para cada usar nos $\forall$ do Pairset:
$\emptyset$, $\set\emptyset$.
\toof
E teoremas?

%%}}}

%%{{{ thm: singleton_thm 
\theorem Singleton.
%%%{{{ meta 
\label singleton_thm
%%%}}}

Dado conjunto $a$, existe um único conjunto cujo membro único é o $a$.
Formalmente,
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
x = a
}.
$$

\proof.
Bote $a\asseq a$ e $b\asseq a$ no Pairset~(\axref[pairset]):
$$
\phantom{\forall a}
\exists s
\forall x
\bigparen{
x \in s
\liff
x = a
}.
$$
O conjunto cuja existência está sendo afirmada tem como membro único o $a$,
e graças ao~\axref[extensionality], ele é o único conjunto com essa propriedade.

%%}}}

%%{{{ df: singleton 
\definition.
%%%{{{ meta 
\label singleton
\defines
    * \set{~a}  -- o conjunto singleton de $a$, com membro único o $a$
    ;;
%%%}}}

Dado qualquer conjunto $a$, o conjunto cujo único membro é o $a$
é chamado o \dterm{singleton} de $a$, e denotado por $\set a$.
Definimos assim o operador $\set{\dhole}$.

%%}}}

%%{{{ x: infinitely_many_singletons_and_doubletons 
\exercise.
%%%{{{ meta 
\label infinitely_many_singletons_and_doubletons
%%%}}}

Mostre como construir uma infinidade de singletons
e uma infinidade de doubletons usando apenas os axiomas
\axref[extensionality], \axref[emptyset], e \axref[pairset].

\hint
\axref[emptyset]~\&~\ref[singleton_thm].

\hint
Comece com o $\emptyset$ e aplique iterativamente o operador $\set{\dhole}$.

\solution
Graças ao Emptyset~(\axref[emptyset]) temos o $\emptyset$.
Aplicamos iterativamente o operador $\set{\dhole}$ (\ref[singleton_thm])
e assim construimos a seqüência infinita de singletons
$$
\emptyset,
\set{\emptyset},
\set{\set{\emptyset}},
\set{\set{\set{\emptyset}}},
\set{\set{\set{\set{\emptyset}}}},
\dotsc
$$
Para os doubletons, uma abordagem seria aplicar o $\set{\emptyset,\dhole}$
em todos os membros da seqüência acima começando com o segundo.
Construimos assim a seqüência seguinte de doubletons:
$$
\set{\emptyset, \set{\emptyset}},
\set{\emptyset, \set{\set{\emptyset}}},
\set{\emptyset, \set{\set{\set{\emptyset}}}},
\set{\emptyset, \set{\set{\set{\set{\emptyset}}}}},
\dotsc
$$
Outra idéia simples de descrever para criar uma infinidade de doubletons
é a seguinte:
começa com o doubleton dos dois primeiros singletons que construimos acima:
\mathcol
D_0 &\defeq \set { \emptyset, \set{\emptyset} }
\intertext {
e fique aplicando o operador $\set{\dhole}$ em cada um dos membros:
}
D_1 &\defeq \set { \set{\emptyset}, \set{\set{\emptyset}} } \\
D_2 &\defeq \set { \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}} } \\
    &\eqvdots
\endmathcol

%%}}}

%%{{{ x: no_replacement_and_no_infinity_catch 
\exercise.
%%%{{{ meta 
\label no_replacement_and_no_infinity_catch
%%%}}}

Considere a tentativa seguinte de resolver o
\ref[infinitely_many_singletons_and_doubletons].
\eop
<<Para conseguir uma infinidade de doubletons $\cal D$ botamos:
\mathcol
D_0     &\defeq \set {\emptyset, \set{\emptyset}} \\
D_{n+1} &\defeq \setst {\set{s}} {s \in D_n}
\endmathcol
assim construimos o
\mathcol
\cal D
&= \set {D_0, \ D_1, \ D_2, \ \dotsc} \\
&= \set { \set{\emptyset,\set{\emptyset}}
        , \ \set{\set{\emptyset},\set{\set{\emptyset}}}
        , \ \set{\set{\set{\emptyset}},\set{\set{\set{\emptyset}}}}
        , \ \dotsc
        }
\endmathcol
que possui uma infinidade de doubletons como membros.>>
\eop
Ache todos os problemas com essa resolução.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora mesmo que nosso mundo mudou drasticamente---sim,
ganhamos uma infinidade de objetos---ele ainda tá bem limitado.

%%}}}

%%{{{ x: only_sets_with_up_to_two_elements 
\exercise.
%%%{{{ meta 
\label only_sets_with_up_to_two_elements
%%%}}}

Será que podemos garantir a existência de conjuntos com qualquer cardinalidade
finita que desejamos?

\hint
No exercício anterior construimos uns conjuntos com cardinalidade até 2.
Tente construir conjunto com cardinalidade 3.

\hint
Não tem como.  Por quê?

\solution
A construção dum conjunto com cardinalidade finita $n$ só pode ter sido garantida
ou pelo Emptyset, se $n=0$ (nesse caso o conjunto construido é o próprio $\emptyset$),
ou pelo Pairset, se $n>0$.  Mas o Pairset só construe
conjuntos de cardinalidade $1$ ou $2$, dependendo se o aplicamos em conjuntos
iguais ou não (respectivamente).
Para concluir: nossos axiomas não são suficientemente poderosos para garantir
a existência de conjuntos com cardinalidades maiores que $2$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O próximo axioma não vai nos permitir---por enquanto---definir novos conjuntos.
Mas é a versão ``bug-free'' do princípio da comprehensão geral.
Com isso, o paradoxo de Russell se torna teorema!

%%}}}

%%{{{ ax: Separation 
\axiom Separation (schema).
%%%{{{ meta 
\label separation
\defines
    * axioma!Separation (schema)
    ;;
%%%}}}

{\rm Para cada propriedade $\phi(\dhole)$, o seguinte:}
para todo conjunto, a colecção de todos os seus membros que têm a propriedade $\phi$ é um conjunto.
$$
\forall w
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x\in w 
\land
\phi(x)
}
}
\axtag[separation=ZF4]
$$

%%}}}

%%{{{ x: how many axioms? 
\exercise.
%%%{{{ meta 
%%%}}}

Quantos axiomas temos listado até este momento?

\hint
Não são 4.

\hint
Não é um número finito de axiomas!

\solution
Veja a discução no~\reftag[axioms_vs_axiomatic_schemata].

%%}}}

%%{{{ Axioms vs. axiomatic schemata 
\note Axiomas \vs esquemas axiomáticos.
%%%{{{ meta 
\label axioms_vs_axiomatic_schemata
%%%}}}

Usamos o termo ``esquema axiomático'', pois para cada fórmula $\phi(\dhole)$,
ganhamos um novo axioma pelo~\axref[separation].
Para enfatizar isso podemos até citá-lo como~\axref[separation]$_{\phi}$.
Antes de usá-lo então precisamos primeiramente escolher nossa fórmula $\phi$,
assim passando do \emph{esquema}~\axref[separation]
para o \emph{axioma}~\axref[separation]$_{\phi}$.
Agora como o axioma começa com $\forall w \exists \dots$,
precisamos escolher em qual conjunto $w$ nós vamos aplicá-lo,
para ganhar finalmente um novo conjunto.

%%}}}

%%{{{ df: set_builder_separation 
\definition.
%%%{{{ meta 
%%%}}}

Denotamos por
$$
\setst {x \in W} {\phi(x)}
$$
o conjunto único (pelo~\axref[extensionality]) garantido pelo~\axref[separation] quando o aplicamos com uma fórmula $\phi(x)$ para um conjunto $W$.

%%}}}

%%{{{ x: separation_yields_no_new_sets_yet 
\exercise.
%%%{{{ meta 
\label separation_yields_no_new_sets_yet
%%%}}}

Mostre que os conjuntos garantidos pelos~\axref[extensionality]--\axref[pairset]
são os mesmos com os conjuntos garantidos pelos~\axref[extensionality]--\axref[separation].

\hint
Usando o~\axref[separation], criamos subconjunto de um conjunto dado.

\hint
Quais são todas as cardinalidades possíveis para o conjunto em qual
usamos o~\axref[separation]?

%%}}}

%%{{{ How to use the Separation 
\note Como usar o Separation.
%%%{{{ meta 
%%%}}}

Queremos mostrar que uma certa classe $C$ de objetos realmente é um conjunto.
Para conseguir isso com o~\axref[separation],
precisamos construir (pelos axiomas!) um \emph{conjunto}
$W$ que contem todos os objetos da nossa classe $C$.
Em geral o $W$ vai ter mais elementos, um certo ``lixo'', que precisamos nos livrar.
E é exatamente com o~\axref[separation] que jogamos fora esse lixo,
usando uma apropriada fórmula $\phi$ como ``tesoura'' para cortar o $W$ e ficar só com o $C$,
garantido agora de ser conjunto.
Vamos ver uns exemplos desse uso,
enriquecendo nosso mundo com uns operadores conhecidos.

%%}}}

%%{{{ eg: define inters 
\example.
%%%{{{ meta 
%%%}}}

Defina o operador $\dhole\inter\dhole$.

\solution.
Dados conjuntos $a$ e $b$,
precisamos achar um conjunto $W$ que contenha todos os membros
da intersecção desejada.  Assim vamos conseguir definir o $a \inter b$
usando o~\axref[separation] com filtro a fórmula
$$
\phi(x)\asseq {x \in a \land x \in b}
$$
Observe que todos os elementos da $a \inter b$ são elementos tanto de $a$,
quanto de $b$.
Temos então duas opções.  Vamos escolher a primeira e construir o
$$
\setst {x \in a} {x \in a \land x \in b}
$$
Observamos que com essa escolha nem precisamos a parte ``$x \in a$'' em nosso filtro.
Chegamos assim em duas soluções para nosso problema:
$$
\setst {x \in a} {x \in b}
\qqqquad
\setst {x \in b} {x \in a}
$$

%%}}}

%%{{{ df: inters 
\definition Intersecção binária.
%%%{{{ meta 
\label inters_constructed
%%%}}}

Sejam conjuntos $a,b$.
Usando o~\axref[separation] definimos
$$
a\inter b \defeq \setst {x\in a} {x\in b}.
$$

%%}}}

%%{{{ x: define setminus 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o operador $\dhole\setminus\dhole$.

\hint
Começa considerando dados conjuntos $a$ e $b$.
Procure um \emph{conjunto} que contenha todos os membros
da classe $a\setminus a$ que tu queres construir como conjunto.
Cuidado: nesse caso não temos as duas opções que tivemos
na~\ref[inters_constructed].

\solution
Usando o~\axref[separation] definimos:
$$
a\setminus b\defeq \setst {x \in a} {x \notin b}.
$$

%%}}}

%%{{{ x: cannot_define_union_yet 
\exercise.
%%%{{{ meta 
\label cannot_define_union_yet
%%%}}}

Tente definir os operadores $\dhole\union\dhole$ e $\dhole\symdiff\dhole$.

\hint
Dados conjuntos $a$ e $b$,
precisas achar um \emph{conjunto} $W$
que contenha todos os membros de $a\union b$,
para depois filtarar apenas os certos usando
como filtro a fórmula
$$
\phi(x) \asseq
x \in a \lor x \in b
$$
para a operação $\dhole\union\dhole$;
e similarmente para a $\dhole\symdiff\dhole$ só que
para essa o filtro vai ser a fórmula
$$
\phi(x)\asseq
\paren{x \in a \land x \notin b}
\lor
\paren{x \notin a \land x \in b}.
$$

\hint
Não tem como!

\solution
Não tem como!
Os axiomas que temos por enquanto não são suficientemente poderosos para
definir nenhuma dessas operações!

%%}}}

%%{{{ Blammenos_strikes_back 
\note Blammenos strikes back.
%%%{{{ meta 
\label Blammenos_strikes_back
%%%}}}

Estudamos o paradoxo de Russell, e a resolução do problema por Zermelo:
\emph{o princípio de comprehensão geral não é válido;
usando o separation axiom evitamos cair no paradoxo}.
Mas o aluno Blammenos pensou:
\dialogue
\who Blammenos:
Ok, eu vou trabalhar na teoria de Zermelo então.
Seja $A$ um conjunto.
Defino o
$$
r(A) \defeq \setst {x \in A} {x \notin x}
$$
que realmente é um conjunto, graças ao Separation
(que o usei com a fórmula $\phi(x) \asseq x\notin x$).
Mas agora faço a mesma pergunta que Russell fez: $r(A) \in r(A)$?
Assim consigo cair no mesmo paradoxo:
$$
r(A) \in r(A) \iff r(A) \notin r(A).
$$
Então Zermelo não resolveu o problema não!
\enddialogue

%%}}}

%%{{{ x: Blammenos_strikes_back_spot_the_mistake 
\exercise.
%%%{{{ meta 
\label Blammenos_strikes_back_spot_the_mistake
%%%}}}

Qual o erro do Blammenos essa vez?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Com o axioma da separação no lugar do princípio da comprehensão geral,
o paradoxo de {\Russell}\indexed[paradoxo!de Russell!vira teorema]Russell
vira-se um teorema muito útil que nos permite definir o operador
$\russell\dhole$ que
``escolhe definitivamente um objeto fora da sua entrada''.
Vamos?

%%}}}

%%{{{ thm: russells_paradox_to_theorem 
\theorem.
%%%{{{ meta 
\label russells_paradox_to_theorem
%%%}}}

Dado qualquer conjunto existe algo que não pertence nele.
Ainda mais, pelo menos um dos seus subconjuntos não pertence nele.

\sketch.
Tome um conjunto $A$.
Usamos a mesma idéia do paradoxo de Russell\Russell[de paradoxo para teorema],
só que essa vez não consideramos \emph{todos} os conjuntos que não
pertencem neles mesmo, mas apenas aqueles que pertencem ao $A$:
$$
\russell A \defeq \setst {x \in A} {x \notin x}.
$$
Concluimos que $\russell A \notin A$ pois o caso $\russell A \in A$
chega no mesmo absurdo de Russell.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Destacamos agora o operador que definimos
no~\ref[russells_paradox_to_theorem]:

%%}}}

%%{{{ df: russell_operator 
\definition.
%%%{{{ meta 
\label russell_operator
%%%}}}

Seja $a$ conjunto.  Definimos o operador $\russell\dhole$ pela
$$
\russell a \defeq \setst {x \in a} {x \notin x}.
$$
Chamamos o $\russell\dhole$ de \dterm{operador Russell}{\Russell[operador]}.

%%}}}

%%{{{ property: russell_operator_property 
\property.
%%%{{{ meta 
\label russell_operator_property
%%%}}}

O operador Russell retorna um objeto (um conjunto)
que não pertence à sua entrada:
$$
\lforall a {\russell a \notin a}.
$$

\proof Demonstrado no~\ref[russells_paradox_to_theorem].

%%}}}

%%{{{ Univ is not a set 
\corollary.
%%%{{{ meta 
\label Univ_is_not_a_set
%%%}}}

O universo $\Univ$ não é um conjunto.

\proof.
Se $\Univ$ fosse um conjunto, aplicando o teorema teriamos um conjunto $\russell \Univ$
com $\russell\Univ \notin \Univ$, absurdo pela definição do $\Univ$.

%%}}}

%%{{{ ax: Powerset 
\axiom Powerset.
%%%{{{ meta 
\label powerset
\defines
    * axioma!Powerset
    ;;
%%%}}}

Para cada conjunto a colecção de todos os seus subconjuntos é um conjunto.
$$
\forall a
\exists s
\forall x
\paren{
x\in s
\liff
x \subset a
}
\axtag[powerset=ZF5]
$$

%%}}}

%%{{{ df: pset 
\definition.
%%%{{{ meta 
\indexes
    * conjunto!de partes    see: powerset
    * conjunto!potência    see: powerset
    ;;
\defines
    * \pset {~a}  -- o conjunto de partes (powerset) de $a$
    * powerset
    ;;
%%%}}}

Dado conjunto $a$, escrevemos
$\pset a$
para o conjunto garantido pelo Powerset~(\axref[powerset]),
que é único graças ao~Extensionality(\axref[extensionality]).
Definimos assim o operador $\pset\dhole$.

%%}}}

%%{{{ x: powersingleton 
\exercise.
%%%{{{ meta 
\label powersingleton
%%%}}}

Seja $a$ conjunto.  Mostre que a classe
$$
\classst { \set x } { x \in a }
$$
de todos os singletons de elementos de $a$ é conjunto.

\solution
Queremos mostrar que dado conjunto $a$, a classe
$$
\classst { \set x } { x \in a }
$$
é conjunto.
Basta só achar um conjunto $W$ tal que todos os $\set x \in W$.
Botamos apenas o $W\asseq\pset a$ que sabemos que é conjunto
pelo~Powerset~(\axref[powerset]), assim ganhando o conjunto
$$
\setst { z\in \pset a } { \lexists {x \in a} {z = \set x} }.
$$
pelo~Separation~(\axref[separation]).

%%}}}

%%{{{ x: arbitrarily_large_finite_sets 
\exercise.
%%%{{{ meta 
\label arbitrarily_large_finite_sets
%%%}}}

Usando
os~\axref[extensionality]+\axref[emptyset]+\axref[pairset]+\axref[powerset],
podemos construir conjunto com cardinalidade finita, arbitrariamente grande?

\solution
Sim.
Seja $n\in\nats$.
Precisamos construir um conjunto $A$ com $\card A \geq n$.
Se $n=0$, graças ao Emptyset~(\axref[emptyset]) tomamos $A\asseq\emptyset$.
Se $n>0$, iteramos o operador $\pset\dhole$ até chegar num conjunto
cuja cardinalidade supera o $n$.

%%}}}

%%{{{ x: still_missing_some_finite_cardinalities 
\exercise.
%%%{{{ meta 
\label still_missing_some_finite_cardinalities
%%%}}}

Usando os~\axref[extensionality]+\axref[emptyset]+\axref[pairset]+\axref[powerset], podemos construir conjunto com cardinalidade finita qualquer?

\hint
Não.  Por quê?

\hint
Como vimos no~\ref[only_sets_with_up_to_two_elements],
usando os \axref[extensionality]+\axref[emptyset]+\axref[pairset]
podemos consturir apenas conjuntos com cardinalidades $0$, $1$, e $2$.
Se aplicar o Powerset~(\axref[powerset]) num conjunto $A$ com cardinalidade
finita $n$, qual será a cardinalidade do $\pset A$?

\solution
Não.
Por exemplo, não temos como construir conjunto com cardinalidade $3$,
pois uma tal construção deveria ``terminar'' com uma aplicação do Powerset
(o Emptyset construe conjuntos com cardinalidade $0$, e o Pairset com $1$ ou $2$).
Mas aplicando o Powerset para conjunto com cardinalidade finita $n$,
construimos conjunto com cardinalidade $2^n$, e $3$ não é uma potência de $2$.

%%}}}

%%{{{ Games 
\note Jogos.
%%%{{{ meta 
%%%}}}

Como descobrimos no~\ref[still_missing_some_finite_cardinalities]
não existe estratégia\indexed[estratégia!vencedora]\ vencedora num jogo
onde nosso oponente joga primeiro escolhendo um número $n\in\nats$,
e nosso objectivo é construir pelos axiomas um conjunto
com cardinalidade $n$.
Se ele escolher como $n$ um dos
$$
0, 1, 2, 2^2, 2^{2^2}, 2^{2^{2^2}}, \dotsc
$$
temos como ganhar, mas caso contrário, não.
\eop
No outro lado, num jogo onde  nosso objectivo é construir pelos
axiomas um conjunto com cardinalidade \emph{pelo menos} $n$,
como vimos no~\ref[arbitrarily_large_finite_sets],
temos uma estratégia vencedora sim:
comece com uma aplicação do Emptyset~(\axref[emptyset])
para ganhar o $\emptyset$ e aplique iterativamente o
Powerset~(\axref[powerset]) construindo assim conjuntos de
cardinalidades $0$ (do próprio $\emptyset$),
$1$, $2$, $2^2$, $2^{2^2}$, etc.,
até chegar num conjunto com cardinalidade maior-ou-igual
ao~$n$ escolhido por nosso oponente.

%%}}}

%%{{{ x: how many iterations of powerset do we need to win? 
\exercise.
%%%{{{ meta 
%%%}}}

Quantas iterações precisamos para conseguir conjunto com cardinalidade $n\in\nats$?

%%}}}

%%{{{ x: all_finite_cardinalities 
\exercise.
%%%{{{ meta 
\label all_finite_cardinalities
%%%}}}

Usando os~\axref[extensionality]+\axref[emptyset]+\axref[separation]+\axref[powerset], podemos construir conjunto com cardinalidade finita qualquer?

\hint
Dado $n\in\nats$ construa primeiramente um conjunto com cardinalidade
maior-ou-igual, e aplica o Separation~(\axref[separation]) para
ficar com apenas $n$ elementos.
Formalmente, use indução!

%%}}}

%%{{{ ax: Unionset 
\axiom Unionset.
%%%{{{ meta 
\label unionset
\defines
    * axioma!Unionset
    ;;
%%%}}}

Para cada conjunto, sua união (a colecção de todos os membros dos seus membros) é um conjunto.
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
\exists w
\paren{
x \in w
\land
w \in a
}
}
\axtag[unionset=ZF6]
$$

%%}}}

%%{{{ df: unionset 
\definition.
%%%{{{ meta 
\defines
    * \Union {~a}  -- a união de $a$ (operação unária)
    * unionset
    ;;
%%%}}}

Dado conjunto $a$, escrevemos
$\Union a$
para o conjunto garantido pelo Unionset~(\axref[unionset]),
que é único graças ao~Extensionality~(\axref[extensionality]).
Definimos assim o operador da \dterm{união arbitrária} $\Union\dhole$.

%%}}}

%%{{{ x: union_and_symdiff_constructed 
\exercise.
%%%{{{ meta 
\label union_and_symdiff_constructed
%%%}}}

Defina os operadores binários $\union$ e $\symdiff$.

\hint
(Sobre o operador $\union$.)
Combine os operadores $\Union\dhole$ e $\set{\dhole,\dhole}$!

\hint
(Sobre o operador $\symdiff$.)
Suponha $a,b$ conjuntos.  Temos
$a\symdiff b\subset a\union b$.

\solution
Sejam conjuntos $a,b$.
Definimos:
$$
\align
a \union b   &\defeq \Union\set{a,b}\\
a \symdiff b &\defeq \setst {x \in a\union b} {x \notin a\inter b}
\endalign
$$

%%}}}

%%{{{ x: complement_impossible 
\exercise.
%%%{{{ meta 
\label complement_impossible
%%%}}}

Como podemos definir o operador unitário $\complement{\cdot}$ de \emph{complemento},
tal que $\complement a$ é o conjunto de todos os objetos que não pertencem ao $a$?

\hint
De jeito nenhum!  Por quê?

\solution
Não podemos.
Dado conjunto $a$, se seu complemento $\complement a$ também fosse conjunto,
poderiamos aplicar o $\union$ para construir o $a\union\complement a$.
Mas pela definição dos $\union$ e $\complement a$, temos agora
$$
x\in a\union \complement a
\iff
x\in a \lor x \notin a
$$
ou seja, todos os objetos $x$ satisfazem a condição na direita!
Em outras palavras $a \union \complement a$ seria o próprio universo $\Univ$
que sabemos que não é um conjunto.

%%}}}

%%{{{ x: Inter_constructed 
\exercise.
%%%{{{ meta 
\label Inter_constructed
%%%}}}

Defina o operador unário $\Inter$,
aplicável em qualquer conjunto não vazio.
Precisamos o Unionset~(\axref[unionset])?

\solution
Dado conjunto $A\neq\emptyset$, definimos
$$
\Inter A
\defeq
\setst {x \in \Union A} {\lforall {a \in A} {x \in a}}.
$$

%%}}}

%%{{{ thm: finite_set_constructor 
\theorem.
%%%{{{ meta 
\label finite_set_constructor
%%%}}}

Dados $a_1, a_2, \dotsc, a_n$ (onde $n\in\nats$) existe conjunto único
cujos membros são exatamente os $a_1$, $a_2$, \dots, $a_n$.

\proof Demonstrarás no~\ref[finite_set_constructor_proof].

%%}}}

%%{{{ remark: finite_set_constructor_notation 
\remark.
%%%{{{ meta 
%%%}}}

Pelo~\ref[finite_set_constructor] ganhamos para qualquer $n\in\nats$
o operador $n$-ário
$$
\set{\dhole,\dhole,\dotsc,\dhole}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Construction trees 
\section Arvores de construção.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um jeito bem econômico e claro para descrever uma construção
e usando árvores.
Os exemplos seguintes servem para explicar essa idéia.

%%}}}

%%{{{ eg: Tree explanation 
\example.
%%%{{{ meta 
%%%}}}

Queremos demonstrar que $\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$
é um conjunto, ou seja, construí-lo.
Escrevemos:
{Pelo Emptyset~(\axref[emptyset]), $\emptyset$ é um conjunto.
Pelo Pairset~(\axref[pairset]) aplicado com $a,b\asseq\emptyset$ temos
que $\set{\emptyset,\emptyset}$ também é conjunto.
Mas, pelo Extensionality~(\axref[extensionality]),
$\set{\emptyset,\emptyset}=\set{\emptyset}$.
Agora, novamente pelo Pairset~(\axref[pairset]) essa vez
aplicado com $a\asseq\emptyset$ e $b\asseq\set{\emptyset}$
temos que $\set{\emptyset, \set{\emptyset}}$ é um conjunto.
Aplicando uma última vez o Pairset~(\axref[pairset]) com
$a\asseq\emptyset$ e $b\asseq \set{\emptyset, \set{\emptyset}}$,
conseguimos construir o conjunto
$\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$.
}
Podemos representar essa construção em forma de árvore:
$$
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\doubleLine
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset}$}
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset, \set{\emptyset, \set{\emptyset}}}$}
\DisplayProof
$$
onde a dupla linha indica que pulamos alguns passos implícitios,
como o uso de Extensionality~(\axref[extensionality]) nesse caso.
Usamos agora essa construção para construir um conjunto de cardinalidade $3$:
$$
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\AxiomC{}
\RightLabel{\axref[emptyset]}
\UnaryInfC{$\emptyset$}
\doubleLine
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset}$}
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{\axref[pairset]}
\BinaryInfC{$\set{\emptyset, \set{\emptyset, \set{\emptyset}}}$}
\RightLabel{\axref[powerset]}
\UnaryInfC{$\set{\emptyset, \set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}}, \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}$}
\RightLabel{\axref[separation],\ $\phi(x)\asseq \exists w(w\in x)$}
\UnaryInfC{$\set{\set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}}, \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}$}
\DisplayProof
$$
Observe que para usar o \axref[separation] precisamos especificar qual é a fórmula--filtro.

%%}}}

%%{{{ eg: tree_construction_with_open_leaves 
\example.
%%%{{{ meta 
\label tree_construction_with_open_leaves
%%%}}}

Seja $a,b$ conjuntos.
Mostre que $\set{b, \set{\emptyset, \set{a}}}$ é conjunto.

\solution.
$$
\AxiomC{$b$}
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\AxiomC{$a$}
\doubleLine
\RightLabel{Singleton}
\UnaryInfC{$\set{a}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\emptyset, \set{a}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{b, \set{\emptyset, \set{a}}}$}
\DisplayProof
$$
Onde deixamos as ``folhas'' da árvore $a,b$ ``sem fechar'', pois
correspondem realmente em nossas hipotéses: os conjuntos $a,b$ são dados!
Observe também que ``Singleton'' se-refere no~\ref[singleton_thm].

%%}}}

%%{{{ x: tree_construction_practice 
\exercise.
%%%{{{ meta 
\label tree_construction_practice
%%%}}}

Sejam $a,b,c,d$ conjuntos.
Mostre pelos axiomas que os seguintes também são:
\mathcol
A &= \set{a,b,c,d} \\
B &= \set{a,b, \set{c,d}} \\
C &= \setst x {x \subset a\union b\union c\union d \mland \text{$x$ tem exatamente 2 membros}}
\endmathcol
Use a método de árvores para umas construções e outras faça escrevendo em texto mesmo.
É bom practicar os dois jeitos.

\solution
Como $a,b$ são conjuntos, pelo Pairset o $\set{a,b}$ também é.
Similarmente o $\set{c,d}$ é conjunto, e aplicando mais uma vez o Pairset neles
temos que o $\set{\set{a,b},\set{c,d}}$ é conjunto.
Agora aplicando o Union nele o ganhamos o $A$.
\eop
\bigskip
\noi
Aqui uma construção do $B$ pelos axiomas, em forma de árvore:
$$
\AxiomC{$a$}
\AxiomC{$b$}
\RightLabel{Pair}
\BinaryInfC{$\set{a,b}$}
\AxiomC{$c$}
\AxiomC{$d$}
\RightLabel{Pair}
\BinaryInfC{$\set{c,d}$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{\set{c,d}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\set{a,b},\set{\set{c,d}}}$}
\RightLabel{Union}
\UnaryInfC{$\set{a,b,\set{c,d}}$}
\DisplayProof
$$
\eop
\bigskip
\noi
Para o $C$, usamos o Separation~(\axref[separation])
no $\pset \paren{\Union A}$, que é conjunto graças aos Union (\axref[unionset])
\& Powerset (\axref[powerset]):
$$
\AxiomC{$A$}
\RightLabel{ZF6}
\UnaryInfC{$\Union A$}
\RightLabel{ZF5}
\UnaryInfC{$\pset\Union A$}
\RightLabel{ZF4}
\UnaryInfC{$C$}
\DisplayProof
$$
onde na aplicação de ZF4 usamos a fórmula
$
\exists u \exists v
\paren{ u \neq v \land \forall w(w \in x \liff w = u \lor w = v ) }
$.

%%}}}

\endsection
%%}}}

%%{{{ Foundations_of_mathematics 
\section Fundações de matemática.
%%%{{{ meta 
\label Foundations_of_mathematics
%%%}}}

%%{{{ A low-level language for mathematics 
\note Uma linguagem ``low-level'' para matemática.
%%%{{{ meta 
\indexes
    * açúcar!sintáctico
    ;;
%%%}}}

Fazendo uma analogia entre matemática e programação,
dizemos que a teoria de conjuntos pode servir como uma certa low-level linguagem
em qual podemos ``compilar'' (traduzir, representar, \dots)~todos os high-level
conceitos que nos interessam em matemática!
As ``definições'' (assim entre aspas) que temos usado até agora para os vários
tipos e conceitos que encontramos não foram formais.
Nossa tarefa então aqui é tirar essas aspas.
Dar uma definição formal dum conceito significa defini-lo dentro da
teoria de conjuntos.
No final das contas, tudo vai ser representado dentro da FOL da teoria de conjuntos,
pegando como noções primitívas \emph{apenas} os ``$\Set(\dhole)$'' de ``ser conjunto''
e o ``$\dhole\in\dhole$'' de ``pertencer''.
Já temos uma primeira biblioteca construida até agora,
um certo \emph{açúcar sintáctico}.
E cada vez que conseguimos compilar algo dentro da teoria de conjuntos,
ganhamos não apenas o próprio algo para seus usos e suas aplicações,
mas também algo mais para usar para nossas próximas compilações.

%%}}}

%%{{{ Our inventory so far 
\note Nosso inventório até agora.
%%%{{{ meta 
%%%}}}

Vamos resumir todos os operadores e predicados que temos já definido
dentro da teoria de conjuntos, usando apenas os axiomas que encontramos
até agora.
Temos:
$$
\gather
\emptyset \;;\\
\set \dhole \;;\quad
\set{\dhole,\dhole} \;;\quad
\set{\dhole,\dotsc,\dhole} \;;\quad
\setst {x \in \dhole} {\phi(x)} \;;\\
\dhole \inter \dhole \;;\quad
\dhole \union \dhole \;;\quad
\dhole \setminus \dhole \;;\quad
\dhole\symdiff \dhole \;;\quad
\Union \dhole \;;\quad
\pset \dhole
\endgather
$$
{e com o proviso de $a$ conjunto com $a\neq\emptyset$ também o}
$$
\dsize\Inter a\,.
$$
Observe-se então que de todos esses operadores, o $\Inter\dhole$ é
o único operador \emph{parcial}.
Mas isso não é nada novo como conceito:
no final das contas, estamos usando operadores parciais o tempo todo
trabalhando com números reais: o $\dhole / \dhole$ por exemplo
não é definido quando seu segundo argumento é o $0$, e a mesma coisa
sobre a operação (unária) de inverso: o $0^{-1}$ também não é definido.

%%}}}

%%{{{ From specification to implementation 
\note De especificação para implementação.
%%%{{{ meta 
%%%}}}

Quando queremos representar algum \emph{tipo} de coisa
dentro do nosso mundo de conjuntos,
precisamos esclarecer qual é a \emph{especificação} desse tipo.
Quais propriedades desejamos dos objetos desse tipo?
O que precisamos para construir um objeto desse tipo?
Quando identificamos dois objetos desse tipo e os consideramos iguais?
Como podemos usar os objetos desse tipo?
Qual é a ``interface'' deles?
Talvez ajuda pensar que nossa tarefa é similhante de um ``vendedor
de implementações matemáticas''.
Nossos ``clientes'' são os próprios matemáticos que desejam usar certos
tipos de objetos matemáticos, e nos seus pedidos eles estão esclarecendo
quais são as propriedades que eles precisam.
Nosso trabalho então será:
\emph{implementar} essa especificação, ou seja,
\emph{representar fielmente} esses tipos e conceitos como conjuntos.
Para conseguir isto:
(1) \emph{definimos} os conceitos e objetos como conjuntos;
(2) \emph{demonstramos} que nossa implementação realmente atende as especificações.
Muitas vezes vamos até oferecer uma \emph{garantia de unicidade}
para mostrar para nosso cliente-matemático que ele não precisa
procurar outras implementações alternativas da nossa concorrência,
pois \emph{essencialmente} nem tem!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nosso próximo trabalho será representar as tuplas,
e por isso vamos analizar em muito detalhe essa especificação.
Depois relaxamos um pouco deixando uns detalhes tediosos como
``óbvios''.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_tuples 
\section Construindo as tuplas.
%%%{{{ meta 
\label Constructing_the_tuples
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
\label tup_specification
%%%}}}

Vamos começar com o trabalho de implementar tuplas de tamanho 2,
ou seja \emph{pares ordenados}.
Precisamos então definir \emph{um} operador
$\tup{\dhole,\dhole}$ que atende as especificações.
Primeiramente:
$$
\tup{x, y} = \tup{x', y'} \implies x = x' \mland y=y'.
\mtag[spec_tup1=TUP1]
$$
Mas precisamos mais que isso.
Dados conjuntos $A$ e $B$ queremos que
$$
\text{a \emph{classe}}
\quad
A\times B = \classst z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
\quad
\text{é um \emph{conjunto}}.
\mtag[spec_tup2=TUP2]
$$
Lembrando a idéia de tupla como black\indexed[black box!de tupla]\ box,
a interface que desejamos consiste em duas operações,
as \emph{projecções}
$\outl$ e $\outr$ tais que
$$
\outl \tup{x,y} = x
\qqqquad
\text e
\qqqquad
\outr \tup{x,y} = y.
$$
Queremos definir também um predicado $\Pair(\dhole)$
para afirmar que um certo objeto representa um par ordenado.
Isso é facil:
$$
\Pair(z) \defiff
\exists x
\exists y
\paren{
z = \tup {x,y}
}
$$
Finalmente, precisamos e confirmamos:
$$
\Pair(z) \iff z = \tup{ \outl(z), \outr(z) }.
$$
Anotamos também que assim que definir \emph{funcções} dentro
da teoria de conjuntos, vamos mostrar a existência das funcções
$$
\xalignat2
\outl &\eqtype A\times B \to A &  \outr&\eqtype A\times B \to B\\
\outl\tup{x,y} &= x            &  \outr\tup{x,y} &= y
\endxalignat
$$
para todos os conjuntos $A$ e $B$.

%%}}}

%%{{{ x: op1_converse_direction_by_logic 
\exercise.
%%%{{{ meta 
\label op1_converse_direction_by_logic
%%%}}}

No \mref[spec_tup1] botamos \sq{$\Longrightarrow$} em vez de \sq{$\Longleftrightarrow$}.
Por quê?  O que acontece com a \sq{$\Longleftarrow$}?

\hint
Como a direção \sq{$\Longleftarrow$} poderia ser inválida?

\solution
A direção \sq{$\Longleftarrow$} é garantida pela nossa lógica:
podemos substituir iguais por iguais em qualquer expressão.

%%}}}

%%{{{ x: first_attempt_pair 
\exercise.
%%%{{{ meta 
\label first_attempt_pair
%%%}}}

Demonstre que a operação
$$
\tup{x,y} \defeq \set{x,y}
$$
satisfaz uma das \mref[spec_tup1]~\&~\mref[spec_tup2]
mas não a outra, então essa
\emph{não} é uma implementação de par ordenado

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nossa primeira tentativa não deu certo.
Mesmo assim é realmente possível implementar pares ordenados
como conjuntos!  Como?

%%}}}

\spoiler

%%{{{ df: kuratowski_pair 
\definition par de Kuratowski.
%%%{{{ meta 
\label kuratowski_pair
\credits
    * Kuratowski : par
    ;;
\indexes
    * par!de Kuratowski
    ;;
%%%}}}

Sejam $x,y$ objetos.
Definimos
$$
\tup{x,y} \defeq \kurpair x y.
$$

%%}}}

%%{{{ x: kurpair_satisfies_tup0 
\exercise.
%%%{{{ meta 
\label kurpair_satisfies_tup0
%%%}}}

Mostre pelos axiomas que o operador $\tup{\dhole, \dhole}$ de Kuratowski
é bem-definido, ou seja: dados objetos $x,y$, o $\tup{x,y}$ é conjunto.

%%}}}

%%{{{ ppty: kurpair_satisfies_tup1 
\property.
%%%{{{ meta 
\label kurpair_satisfies_tup1
%%%}}}

O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\mref[spec_tup1].

\sketch.
Suponha $\tup{x,y} = \tup{x',y'}$.
Logo
$$
\kurpair x y = \kurpair {x'} {y'}.
$$
Precisamos deduzir que $x=x'$ e $y=y'$ mas ainda não é claro.
O que temos é apenas igualdade desses dois conjuntos, que não
garanta o que queremos imediatamente.
Não podemos concluir nem que
$$
\alignat3
\set {x} &= \set {x'}
&\qquad&\mland\qquad&
\set {x,y} &= \set {x',y'},\\
\intertext{%
pois pela definição de igualdade de conjuntos (\axref[extensionality])
sabemos apenas que cada membro do conjunto no lado esquerdo
é algum membro do conjunto no lado direito e vice-versa.
Então, talvez
}
\set {x} &= \set { x',y'}
&\qquad&\mland\qquad &
\set {x,y} &= \set {x'}.
\endalignat
$$
Precisamos então separar em casos:
$x = y$ ou não.
Em cada caso argumentamos usando o (\axref[extensionality]) e a
cardinalidade dos conjuntos para progressar até chegar nos desejados
$x=x'$ e $y=y'$.

%%}}}

%%{{{ ppty: kurpair_satisfies_tup2 
\property.
%%%{{{ meta 
\label kurpair_satisfies_tup2
%%%}}}

O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\mref[spec_tup2].

\proof.
Sejam $A,B$ conjuntos.
Precisamos mosrar que a classe
$$
A\times B = \classst z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
$$
é um conjunto.
Como já temos escrita a classe nessa forma, basta achar um conjunto $W$
que contem todos os pares que queremos, e aplicar esse mesmo filtro
para ficar apenas com eles mesmo.
Como parece o aleatório $\tup{a,b} \in A\times B$?
$$
a\in A
\mland
b\in B
\implies
\tup{a,b} = \kurpair a b \in \mathord{?}
$$
Vamos ver:
\stepproof
\proofsteptnb {Suponha $a\in A$ e $b\in B$.}
\proofsteptby {Logo $a,b \in A\union B$.}                               {def.~$\union$}
\proofsteptby {Logo $\set {a}, \set{a,b} \subset A \union B$.}          {def.~$\subset$}
\proofsteptby {Logo $\set {a}, \set{a,b} \in \pset\paren{A \union B}$.} {def.~$\pset$}
\proofsteptby {Logo $\kurpair a b \subset \pset\paren{A \union B}$.}    {def.~$\subset$}
\proofsteptby {Logo $\kurpair a b \in \pset\pset\paren{A \union B}$.}   {def.~$\pset$}
\proofsteptby {Logo $\tup {a, b} \in \pset\pset\paren{A \union B}$.}    {def.~$\tup{a,b}$}
\endstepproof
Tome então $W\asseq \pset\pset\paren{A \union B}$
e defina
$$
A \times B \defeq \setst { z \in \pset\pset\paren{A\union B} } {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
$$
que é conjunto graças ao Separation~(\axref[separation]).

%%}}}

%%{{{ Being agnostic 
\note Sendo agnósticos.
%%%{{{ meta 
\defines
    * agnóstico
    ;;
%%%}}}

Acabamos de encontrar \emph{um} operador de par ordenado:
do Kuratowski{\Kuratowski}.
Ele não é o único possível, mas para continuar com nossa teoria,
precisamos apenas mostrar que existe um.
Vamos usar o símbolo $\tup{\dhole,\dhole}$ sem esclarecer se realmente é
a implementação de Kuratowski que usamos, ou alguma outra implementação.
Tomando cuidado, sobre esse operador nos permitimos usar
\emph{apenas as propriedades da sua especificação e nada mais}:
as \mref[spec_tup1]~\&~\mref[spec_tup2] da \reftag[tup_specification].
Falamos então que estamos sendo $\tup{\,}$-\dterm{agnósticos}.
Por exemplo, não podemos afirmar que $\set {x} \in \tup {x,y}$.
Sim, isso é válido com a implementação de Kuratowski, mas é uma
\emph{coincidência} e não uma \emph{conseqüência} da especificação
de par ordenado.
Talvez outra implementação não tem essa propriedade,
como tu vai descobrir agora demonstrando que o $\tup{\dhole,\dhole}$
do~Wiener{\Wiener} também é uma implementação de par ordenado.

%%}}}

%%{{{ x: wiener_pair 
\exercise par de Wiener.
%%%{{{ meta 
\label wiener_pair
\credits
    * Wiener : par
    ;;
\indexes
    * par!de Wiener
    ;;
%%%}}}

Mostre pelos axiomas que a operação $\tup{\dhole,\dhole}$ definida pela
$$
\tup{x,y} \defeq \bigset{ \set{ \emptyset, \set{x} }, \set{ \set{ y } } }
$$
é uma implementação bem-definida de par ordenado
(ou seja, dados $x,y$ o $\tup{x,y}$ é um conjunto sim)
que satisfaz as~\mref[spec_tup1]~\&~\mref[spec_tup2].\foot
Wiener definiu essa operação uns anos
\emph{antes} da definição de Kuratowski.
\toof

\hint
Trabalhe como fizemos para o par ordenado de Kuratowski
no~\ref[kurpair_satisfies_tup0] e nas
proposições~\reftag[kurpair_satisfies_tup1]--\reftag[kurpair_satisfies_tup2].

\solution
Primeiramente verificamos que dados objetos $x,y$, o $\tup{x,y}$
realmente é um conjunto:
$$
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\AxiomC{$x$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{x}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\emptyset, \set{x}}$}
\AxiomC{$y$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{y}$}
\RightLabel{Singleton}
\doubleLine
\UnaryInfC{$\set{\set{y}}$}
\RightLabel{Pair}
\BinaryInfC{$\set{\set{\emptyset,\set{x}}, \set{\set{y}}}$}
\DisplayProof
$$
\proofpart{\mref[spec_tup2]:}
Sejam $A,B$ conjuntos.
Queremos mosrar que a classe
$$
A\times B = \classst {\tup{x,y}} {
x\in A
\mland
y\in B
}
$$
é um conjunto.
Como na demonstração da~\ref[kurpair_satisfies_tup2],
Basta achar um conjunto $W$ que contem o arbitrário $\tup{a,b}\in A\times B$,
pois depois aplicamos o Separation~(\axref[separation]) com a mesma
fórmula da~\ref[kurpair_satisfies_tup2] para ganhar o $A\times B$.
Um conjunto que serve como $W$ é o $\pset\pset\pset(A\union B)$,
como verificamos aqui, escrevendo a derivação em forma de árvore:
$$
\AxiomC{}
\UnaryInfC{$\emptyset\in\pset(A\union B)$}
\AxiomC{$a \in A$}
\UnaryInfC{$a \in A\union B$}
\UnaryInfC{$\set{a} \in \psetp{A\union B}$}
\BinaryInfC{$\set{\emptyset,\set{a}} \in \pset\psetp{A\union B}$}
\AxiomC{$b \in B$}
\UnaryInfC{$b \in A\union B$}
\UnaryInfC{$\set{b} \in \psetp{A\union B}$}
\UnaryInfC{$\set{\set{b}} \in \pset\psetp{A\union B}$}
\BinaryInfC{$\set{\set{\emptyset,\set{a}}, \set{\set{b}}}\in\pset\pset\psetp{A\union B}$}
\DisplayProof
$$

%%}}}

%%{{{ x: hausdorff_pair 
\exercise par de Hausdorff.
%%%{{{ meta 
\label hausdorff_pair
\credits
    * Hausdorff : par
    ;;
\indexes
    * par!de Hausdorff
    ;;
%%%}}}

Considere $0$ e $1$ dois objetos distintos (algo que nossos axiomas garantam).
Para ser especifico, tome $0\asseq\emptyset$ e $1\asseq\set\emptyset$.
Demonstre que a operação
$$
\tup{x,y} \defeq \bigset{ \set{0, x}, \set{1, y} }
$$
também é uma implementação de par ordenado.

\hint
Calcule os $\tup {0,0}$, $\tup {0,1}$, $\tup {1,0}$, $\tup {1,1}$.

\hint
Separe em casos: $x=y$ ou não.

%%}}}

%%{{{ x: bad_pair 
\exercise Bad pair.
%%%{{{ meta 
\label bad_pair
%%%}}}

Demonstre que não podemos usar a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{y} }
$$
como uma implementação de par ordenado.

\hint
O $\tup{x,y}$ não satisfaz a~\mref[spec_tup1].
Mostre um contraexemplo, ou seja, ache objetos $x,y,x',y'$ tais que:
$$
\tup{x,y} = \tup{x',y'}
$$
e mesmo assim não temos $x=x'$ e $y=y'$.

\solution
Seja $o$ qualquer conjunto (tome $o \asseq \emptyset$ por exemplo).
Considere o $\set{\set{o}, \set{\set{o}}}$.
Ele representa algum par ordenado?
Calculamos:
$$
\align
\tup{ \set{o}, \set{o} } &= \set{\set{o}, \set{\set{o}}} \\
\tup{ \set{\set{o}}, o } &= \set{\set{\set{o}}, \set{o}}
\endalign
$$
Observe que os conjuntos nos lados direitos são iguais:
$$
\set{\set{o}, \set{\set{o}}}
=
\set{\set{\set{o}}, \set{o}}
$$
e logo
$$
\tup{ \set{o}, \set{o} }
=
\tup{ \set{\set{o}}, o }.
$$
Isso já mostra que a~\mref[spec_tup1] não é satisfeita, pois
$\set{o} \neq \set{\set{o}}$.
(E nem $\set{o}=o$ mas só precisamos uma das duas ser falsa
para concluir que a propriedade não é satisfeita.)
\mistake
\eop
A prova que acabamos de escrever tem um roubo sutil,
que é muito fácil corrigir, mas difícil identificar!
Para corrigi-lo, basta tomar o conjunto $\emptyset$
onde tomamos um arbitrário conjunto $o$, e a prova
vira correta!
O \ref[find_the_crime_of_foundation] pede identificar
o problema.

%%}}}

%%{{{ x: spooky_pair 
\exercise Spooky pair.
%%%{{{ meta 
\label spooky_pair
%%%}}}

Considere a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
como uma implementação de par ordenado.
Demonstre que ela satisfaz a~\mref[spec_tup2].
Sobre a~\mref[spec_tup1], a situação é mais complicada.
Nesse momento não podemos demonstrar que ela é satisfeita,
mas nem construir um contraexemplo!
Mesmo assim, vale a pena pensar:
que conjunto (spooky!) serviria?
Deixo isso para o~\ref[spooky_pair_problem].

\hint
Para demonstrar a~\mref[spec_tup2], dados conjuntos $a,b$,
tome $x\in a$ e $y \in b$ e ache um conjunto $w$ tal que
$\tup{x,y} \in w$.
(Exatamente como a gente fez no~\ref[kurpair_satisfies_tup2].)

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_disjoint_union 
\section Construindo a união disjunta.
%%%{{{ meta 
\label Constructing_the_disjoint_union
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
\label disjunion_specification
\indexes
    * união!disjunta
    ;;
%%%}}}

Queremos definir a operação binária da \emph{união disjunta}.

%%}}}

\TODO Especificação: mention coproduct.

%%{{{ df: disjoint_union 
\definition União disjunta.
%%%{{{ meta 
\label disjoint_union
\defines
    * ~A \disjunion ~B  -- a união disjunta de $A$ com $B$
    * união!disjunta
    ;;
%%%}}}

Fixamos dois objetos distintos como os $\mathrm L\asseq \emptyset$ e $\mathrm R\asseq \set\emptyset$
e definimos:
$$
A \disjunion B
\defeq
\paren{\set{\mathrm L} \times A}
\union
\paren{\set{\mathrm R} \times B}.
$$

%%}}}

%%{{{ x: why_not_use_A_and_B_as_tags 
\exercise.
%%%{{{ meta 
\label why_not_use_A_and_B_as_tags
%%%}}}

Uma escolha de ``tags'' para os membros dos conjuntos $A$ e $B$ seria
os próprios conjuntos $A$ e $B$ em vez dos $\emptyset$ e $\set\emptyset$
que usamos.  Qual é o problema com essa idéia?

%%}}}

%%{{{ x: generalize_disjunion_to_indexed_Disjunion 
\exercise.
%%%{{{ meta 
\label generalize_disjunion_to_indexed_Disjunion
%%%}}}

Generalize a construção de união disjunta binária para
o operador ``grande'' de união disjunta indexada por algum conjunto
de índices $I$.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_relations 
\section Construindo as relações.
%%%{{{ meta 
\label Constructing_the_relations
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

O que precisamos de algum objeto $R$ que merece o nome de
\emph{implementação de relação de $A$ para $B$}?
Bem, primeiramente, dados $a\in A$ e $b\in B$ queremos ter
como ``perguntar'' esse objeto $R$ se o $a$ está relacionado
com o $b$.
Dados quaisquer conjuntos $c$ e $d$ queremos também que
a classe de todas as relações de $c$ para $d$ seja um conjunto.
Nossa definição tem que ser feita em tal jeito que facilita
as demais definições de operações em relações, por exemplo
a composição, os vários fechos que encontramos, etc.
\eop
Praticamente, \emph{nossa especificação é o~\ref[Relations]!}

%%}}}

%%{{{ df: relation_formal_def 
\definition Relação.
%%%{{{ meta 
\label relation_formal_def
%%%}}}

Sejam $A,B$ conjuntos.
Qualquer subconjunto $R \subset A \times B$
é uma relação de $A$ para $B$.
Em outras palavras:
$$
\text{$R$ relação de $A$ para $B$}
\defiff
R \subset A \times B.
$$
Introduzimos as notações
$$
\align
x \rel R y
&\sugiff \tup{x,y} \in R\\
R(x,y)
&\sugiff \tup{x,y} \in R.
\endalign
$$
Formalmente definimos o predicado
$$
\Relation(r,a,b)
\sugiff
r \subset (a \times b).
$$

%%}}}

%%{{{ remark: remember the graph of a relation? 
\remark.
%%%{{{ meta 
%%%}}}

No final das contas, já tivemos definido esse conceito.
Seu nome foi \emph{o gráfico da $R$}.  Lembra?
Se não, veja o~\ref[relation_graph].
Em outras palavras, dentro da teoria de conjuntos,
com nossa~\ref[relation_formal_def],
\emph{identificamos as relações com seus gráficos: $R = \graph R$.}

%%}}}

%%{{{ warning: faithful representation 
\warning.
%%%{{{ meta 
%%%}}}

Enfatisamos mais uma vez que isso não quis dizer que
uma relação \emph{é} o seu gráfico (que é um conjunto)!
Mas que isso é apenas um jeito de \emph{representar fielmente}
o conceito de \emph{relação} dentro da teoria de conjuntos, ou seja:
``\emph{como se fosse} conjunto''.

%%}}}

%%{{{ Q: must we define more terminology from relations? 
\question.
%%%{{{ meta 
%%%}}}

Agora precisamos definir as demais noções e termos que encontramos no~\ref[Relations]?
Por exemplo: precisamos definir os termos ``transitiva'', ``reflexiva'', etc.?

%%}}}

\spoiler

%%{{{ A: No! 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não!
Voltando no~\ref[Relations] podes verificar que todas as outras definições
dependem apenas na noção de relação mesmo
(que acabamos de definir formalmente na~\ref[relation_formal_def]).

%%}}}

%%{{{ eg: equality in A 
\example.
%%%{{{ meta 
%%%}}}

Seja $A$ um conjunto.
O conjunto
$$
\setst {\tup{x,x}\in A^2} {x \in A}
$$
é uma relação, pois realmente é um subconjunto de $A\times A$.
Qual relação é essa?
Ela merece seu próprio nome e sua própria notação.

%%}}}

%%{{{ df: eqin 
\definition.
%%%{{{ meta 
\label eqin
%%%}}}

Dado conjunto $A$, a relação de \dterm{igualdade no $A$}
é a relação
$$
{\eqin A} \defeq \setst {\tup{x,x}\in A^2} {x \in A}.
$$
Logo temos
$$
x \eqin A y \iff x = y \mland x,y \in A.
$$

%%}}}

%%{{{ prop: a_relto_b_is_a_set 
\proposition.
%%%{{{ meta 
\label a_relto_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
\relspace{a,b}
\defeq
\classstt R {$R$ é uma relação de $a$ para $b$}
$$
é um conjunto.

\proof.
Basta achar um conjunto onde todas as relações de $a$ para $b$
pertencem.
Pela definição de relação, todas pertencem ao $\pset(a\times b)$.
De fato, ainda mais é verdade:
$$
\relspace{a,b}
=
\pset(a\times b)
$$
e logo é um conjunto graças aos operadores (totais) $\pset$ e $\times$.

%%}}}

%%{{{ eg: reflexive_and_irreflexive_formally 
\example.
%%%{{{ meta 
%%%}}}

Seja $R\subset A\times A$.
Então temos
$$
\align
\text{$R$ reflexive}
&\iff {\eqin A} \subset R\\
\text{$R$ irreflexive}
&\iff {\eqin A} \inter R = \emptyset
\endalign
$$
etc.

%%}}}

%%{{{ x: rcompose_formal_def 
\exercise.
%%%{{{ meta 
\label rcompose_formal_def
%%%}}}

Mostre que podemos definir o operador de composição de relações
$\dhole\rcom\dhole$ em tal modo quando é aplicado em conjuntos
$a,b$ que são relações (compatíveis), o conjunto
$a\rcom b$ também é uma relação, e a correta:
a composição de $a$ com $b$.
(Lembre-se a~\ref[rcompose].)

%%}}}

%%{{{ x: closures_formal_def 
\exercise.
%%%{{{ meta 
\label closures_formal_def
%%%}}}

Defina formalmente e diretamente como conjuntos os fechos que encontramos
no~\ref[Relations]:
reflexivo (\reftag[rclosure]),
simétrico (\reftag[sclosure]),
transitivo (\reftag[tclosure]).
Tente dar a definição mais curta, elegante, e flexível possível!

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_functions 
\section Construindo as funcções.
%%%{{{ meta 
\label Constructing_the_functions
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

Como nas relações, aqui também nossa especificação deve ser clara:
\emph{traduzir todo o~\ref[Functions] na teoria de conjuntos!}

%%}}}

%%{{{ df: function_formal_def 
\definition Funcção.
%%%{{{ meta 
\label function_formal_def
%%%}}}

Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$ é chamada \dterm{funcção de $A$ para $B$}
sse
$$
\pforall {a \in A}
\lunique {b \in B}
{\tup{a,b} \in f}.
$$
Equivalentemente
(e para ficar mais perto das Condições~\reftag[functionhood_conditions]
do~\ref[Functions]) podemos separar essa condição em duas:
$$
\gather
\pforall {a \in A}
\lexists {b \in B}
{\tup{a,b} \in f}
\tag{TOT}\\
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
\endgather
$$
Escrevemos
$$
f(a) = b
\defiff
\tup{a,b} \in f
$$
e também usamos
$$
f(a)
\defeq
\text{aquele único $b\in B$ tal que $\tup{a,b}\in f$.}
$$
Lembre-se que escrevemos
$f : A \to B$ ou $A \toby f B$ para dizer que
$f$ é uma funcção de $A$ para $B$, etc.
(Veja~\ref[function_notation].)
Formalmente definimos o predicado
$$
\Function(f,a,b)
\sugiff
\Relation(f,a,b)
\land
\pforall {x \in a}
\lunique {y \in b}
{\tup{x,y}\in f}.
$$

%%}}}

%%{{{ prop: a_to_b_is_a_set 
\property.
%%%{{{ meta 
\label a_to_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
(a \to b)
\defeq
\classst f {f : A \to B}
$$
é um conjunto.

\proof.
Fácil:
$$
(a \to b)
=
\setst {f \in \relspace{a,b}} {f : A \to B}
$$
que é conjunto graças ao operador $\relspace{\dhole,\dhole}$
(\ref[a_relto_b_is_a_set]) e ao axioma da separação~\axref[separation].

%%}}}

%%{{{ We get inj surj bij for free 
\remark.
%%%{{{ meta 
%%%}}}

Como as definições de ``injetora'', ``sobrejetora'', e ``bijetora''
do~\ref[Functions] dependem apenas da definição de ``funcção''
(que acabamos de definir), já temos essas definições na teoria de conjuntos!
Simlarmente os operadores $(\dhole\injto\dhole)$, $(\dhole\surjto\dhole)$,
e $(\dhole\bijto\dhole)$ são facilmente definidos graças
à~\ref[a_to_b_is_a_set]
e o axioma da separação~\axref[separation].

%%}}}

%%{{{ eg: eqc_formally_defined 
\example.
%%%{{{ meta 
\label eqc_formally_defined
%%%}}}

Uma definição alternativa e formal do $\eqc$ é a seguinte:
$$
a \eqc b \defiff (a \bijto b) \neq \emptyset.
$$

%%}}}

%%{{{ x: fcompose_fresto_fcross
\exercise.
%%%{{{ meta 
\label fcompose_fresto_fcross
%%%}}}

Defina formalmente as operações e construções de funcções que encontramos
no~\ref[Functions]:
composição (\reftag[fcompose]);
restricção (\reftag[fresto]);
produto (\reftag[fcross]).

%%}}}

%%{{{ x: id_char_const_as_sets 
\exercise.
%%%{{{ meta 
%%%}}}

Descreva curtamente as funcções identidades, características, e constantes como
conjuntos.
Esses conjuntos representam outras coisas (de outros tipos)?

%%}}}

%%{{{ beware: we do note get partial functions for free! 
\beware.
%%%{{{ meta 
%%%}}}

Tem um conceito do~\ref[Functions] que \emph{não} definimos
em termos de ``funcção'', e logo precisamos defini-lo formalmente
aqui: a \emph{funcção parcial}.

%%}}}

%%{{{ df: partial_function 
\definition Funcção parcial.
%%%{{{ meta 
\label partial_function_formally_defined
%%%}}}

Uma relação $f$ de $A$ para $B$ é uma \dterm{funcção parcial} sse
$$
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
$$

%%}}}

%%{{{ x: a_parto_b_is_a_set 
\exercise.
%%%{{{ meta 
\label a_parto_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
(a \parto b)
\defeq
\classst f {f : A \parto B}
$$
é um conjunto.

\solution
Fácil, como na demonstração da~\ref[a_to_b_is_a_set]:
$$
(a \parto b)
=
\setst {f \in \relspace{a,b}} {f : A \parto B}
$$
que é conjunto.

%%}}}

%%{{{ x: parto_formally_defined 
\exercise.
%%%{{{ meta 
\label partial_function_formally_defined_as_function
%%%}}}

Ache um outro jeito para definir funcções parciais como funcções.
(Talvez tu já pensou nisso no~\ref[implement_partial_functions].)
Verifique que dados conjuntos $a,b$ a classe
$(a \parto b)$ também é um conjunto.

\hint
(Resolva primeiro o~\ref[implement_partial_functions].)
Cada funcção parcial $f : A \parto B$ pode ser representada
como uma funcção total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Duas idéias razoáveis:
\crproofalt{Idéia 1:}
Dados conjuntos $A,B$, escolha (como?)\ um objeto fora do $B$
para representar a ``diverjão'', ou valor ``não-definido''.
Lembra-se que $\russell B \notin B$, algo que
temos graças ao \ref[russells_paradox_to_theorem].
Então tome $B' \asseq B \union \russell B$.
\crproofalt{Idéia 2:}
Tome
$$
B'
\asseq
\setstt {Y \subset B} {$\Singleton(Y)$ ou $Y = \emptyset$}.
$$

%%}}}

%%{{{ df: parfun_compatibility 
\definition Compatibilidade.
%%%{{{ meta 
\label parfun_compatibility
\defines
    * funcção!parcial!compatibilidade
    * funcção!parcial!conflito
    ;;
%%%}}}

Sejam $A,B$ conjuntos e $\scr F$ uma família de funcções parciais de $A$ para $B$:
$\scr F \subset (A\parto B)$.
Chamamos a $\scr F$ \dterm{compatível} sse $\Union {\scr F} \in (A\parto B)$.
Digamos que $\scr F$ tem \dterm{conflito} no $a\in A$ sse
existem $y,y'\in B$ com $y\neq y'$ e $\tup{a,y}, tup{a,y'}\in \scr F$;
equivalentemente
$$
\card{ \setst {\tup{a,y}} {y\in B} } > 1.
$$

%%}}}

%%{{{ df: approximation 
\definition Aproximação.
%%%{{{ meta 
\label parfun_approx
\defines
    * funcção!parcial!aproximação
    ;;
%%%}}}

Seja $F : A \to B$.
Chamamos qualquer $f\subset F$ uma aproximação (parcial) da $F$.
Ela é \dterm{própria} se $f\subsetneq F$.

%%}}}

%%{{{ x: fun_approxes_is_set 
\exercise.
%%%{{{ meta 
\label fun_approxes_is_set
%%%}}}

Seja $F : A \to B$.
Demonstre que a classe
$$
\classst f { \text{$f$ é uma aproximação da $F$} }
$$
é um conjunto.

\solution
Usando o Separation~(\axref[separation]) escrevemos
$$
\setst {f \in (A\parto B)} {f \subset F}.
$$

%%}}}

%%{{{ x: fun_with_approxes 
\exercise.
%%%{{{ meta 
\label fun_with_approxes
\pdefs
    \pdef Approxes    {{\scr F}}
    \pdef FinApproxes {\Approxes_{\textrm f}}
    ;;
%%%}}}

Seja $F : A \to B$.
(i) Demonstre que:
$$
F = \Union \Approxes
$$
onde $\scr F$ é o conjunto de todas as aproximações da $F$.
(ii) É verdade também que
$$
F = \Union \FinApproxes
$$
onde $\FinApproxes$ é o conjunto de todas as aproximações finitas da $F$?

\solution%
(i)
Tome $\tup{x,y} \in F$.
Para concluir que $\tup{x,y} \in \Union \Approxes$
precisamos achar uma aproximação $f\in\Approxes$ tal que $\tup{x,y} \in f$.
Aqui uma: a aproximação $\set{\tup{x,y}} \subset F$.
Conversamente, tome $\tup{x,y}$ in $\Union\Approxes$.
Pela definição de $\Union$ então temos que $\tup{x,y}\in f$ para alguma aproximação
$f\in\Approxes$.  Pela definição de aproximação agora, $f\subset F$, ou seja:
$\tup{x,y}\in f \subset F$.
\eop
(ii) Sim.  A direção $\Union \FinApproxes \subset F$ é trivial graças ao (i),
e a direção oposta também provamos no (i) pois a aproximação $\set{\tup{x,y}}$
que escolhemos nessa direção é realmente finita.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_more_familiar_types 
\section Construindo mais tipos familiares.
%%%{{{ meta 
\label Constructing_more_damiliar_types
%%%}}}

%%{{{ x: constructing_indexed_families 
\exercise famílias indexadas.
%%%{{{ meta 
%%%}}}

Construa as famílias indexadas na teoria dos conjuntos.

%%}}}

%%{{{ x: why_do_we_not_gain_sequences_by_indexed_families_for_free 
\exercise.
%%%{{{ meta 
\label why_do_we_not_gain_sequences_by_indexed_families_for_free
%%%}}}

<<Como podemos implementar cada seqüência como uma família
indexada pelo conjunto de indices $\cal I \asseq \nats$,
e como acabamos de construir as famílias indexadas por
qualquer conjunto de indices $\cal I$, logo já temos
construido as seqüências também dentro da teoria dos
conjuntos.>>
Concordas?

\hint
Esse $\nats$ aí é o que mesmo?

%%}}}

%%{{{ Q: what about groups, monoids, rings, fields, etc.? 
\question.
%%%{{{ meta 
%%%}}}

Ainda falta muita coisa: grupos, monóides, anéis, corpos, etc.
Como podemos construí-los na teoria dos conjuntos?

%%}}}

\spoiler

%%{{{ x: constructing_structured_sets 
\exercise.
%%%{{{ meta 
%%%}}}

Construa o conceito de conjunto estruturado na teoria dos conjuntos.

\hint
Apague o $\cdot$ do $;$ ué.

%%}}}

\endsection
%%}}}

%%{{{ Cardinal_arithmetic 
\section Cardinais e sua aritmética.
%%%{{{ meta 
\label Cardinal_arithmetic
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tem mais uma coisa muito legal que conseguimos definir
sem introduzir nenhum axioma ainda: a \emph{aritmética dos
cardinais}.
Infelizmente não podemos ainda definir mesmo os cardinais
mas podemos brincar suficientemente com umas idéias e
entender a aritm

%%}}}

%%{{{ df: cardinal_assignment 
\definition atribuidor de cardinalidade.
%%%{{{ meta 
\label cardinal_assignment
%%%}}}

Um operador unário $\card\dhole$ é chamado
\dterm{atribuidor (forte) de cardinalidade}
sse ele satisfaz:
\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Classes vs. Sets (II) 
\section Classes \vs Conjuntos (II).
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Pelas nossas definições de relação e de funcção, observe
que nem $\dhole\subset\dhole$ é uma relação unária,
nem $\pset\dhole$ é uma funcção unária.

%%}}}

%%{{{ x: Singleton_and_pset_are_too_big 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então certas coisas que \emph{parecem como} relações na verdade
são ``grandes demais'' para ser relações mesmo (segundo nossa
definição de relação dentro da teoria dos conjuntos), e similarmente
sobre funcções.  Vamos chamá-las de predicados ou relações-classes,
e de operadores ou funcções-classes:

%%}}}

%%{{{ df: classrelation 
\definition relação-classe.
%%%{{{ meta 
\label classrelation
\defines
    * predicado
    * relação-classe
    ;;
%%%}}}

Qualquer fórmula com $n$ buracos determina um
\dterm{predicado} $n$-ário, que chamamos também de
\dterm{relação-classe} $n$-ária.

%%}}}

%%{{{ df: functionlike 
\definition function-like, funcção-classe.
%%%{{{ meta 
\label functionlike
%%%}}}

Uma fórmula $\Phi(x,y)$ é \dterm{function-like}, sse:
$$
\forall x
\unique y
\Phi(x,y)
\qquad
\text{ou seja,}
\qquad
\forall x
\exists y
\bigparen{
\Phi(x,y)
\land
\forall y'
\paren{\Phi(x,y') \limplies y = y'}}.
$$
Nesse caso, também usamos os termo \dterm{funcção-classe}, \dterm{operador},
e a notação comum
$$
\Phi(x) = y
\qqqtext{como sinónimo de}
\Phi(x,y).
$$
Seguindo essa linha denotamos por $\Phi(x)$ o único objeto $y$ tal que
$\Phi(x,y)$.
Assim o $\Phi(x)$ denota um \emph{objeto}, mas o $\Phi(x,y)$ uma \emph{afirmação}.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ someset_problem 
\problem Someset is the new Emptyset.
%%%{{{ meta 
\label someset_problem
%%%}}}

Considere o axioma seguinte:
\eop
\noi
{\bf Someset.}
{\proclaimstyle Existe algo.}
$$
\exists s \paren{ s = s }
\axtag[someset=ZF2*]
$$
Mostre que no sistema axiomático
\axref[extensionality]%
+\axref[someset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset],
existe o $\emptyset$.\foot
Dependendo do uso e do contexto, podemos considerar como parte da lógica
que o universo não é vazio, ou seja, existe algo.
Nesse caso nem precisamos o Someset~(\axref[someset]), pois seria implícito.
\toof

%%}}}

%%{{{ triset_problem 
\problem Triset is the new Pairset.
%%%{{{ meta 
\label triset_problem
%%%}}}

Considere o axioma seguinte:
\eop\noi
{\bf Triset.}
{\proclaimstyle
Dados tres objetos distintos existe conjunto com exatamente
esses membros.
}
$$
\forall a
\forall b
\forall c
\lparen{
\bigparen{
a\neq b \land b \neq c \land c \neq a
}
\limplies
\exists s
\forall x
\bigparen{x\in s \liff x = a \lor x = b \lor x = c}
}
\axtag[triset=ZF3*]
$$
\tlist:
\li (0):
No sistema
\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]
construa conjunto de cardinalidade~$3$.
\li (1):
Demonstre que no mesmo sistema
podemos substituir o axioma Pairset~(\axref[pairset]) pelo axioma
Triset~(\axref[triset]) ``sem perder nada''.
Em outras palavras, demonstre que no sistema
\axref[extensionality]%
+\axref[emptyset]%
+\axref[triset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]
\emph{para todos os $a,b$ existe o conjunto $\set{a,b}$}.
\li (2):
Podemos demonstrar a mesma coisa no
\axref[extensionality]%
+\axref[emptyset]%
+\axref[triset]%
+\axref[separation]%
+\axref[unionset]%
?
\endtlist

\hint
Para o (1), veja o (2); para o (2), veja o (1)!

%%}}}

%%{{{ conset_problem 
\problem.
%%%{{{ meta 
\label conset_problem
%%%}}}

Considere o axioma seguinte:
$$
\forall h
\forall t
\exists s
\forall x
\bigparen{
x \in s
\liff
x = h
\lor
x \in t
}.
\axtag[conset=CONS]
$$
(1)
No sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[conset]}
demonstre o \axref[pairset].
\eop\noi
(2)
Mostre que não tem como demonstrar o \axref[conset]
no sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]}.
\eop\noi
(3)
No sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]}
demonstre o \axref[conset].

\solution
(1)
Dados os objetos $a,b$, queremos construir o $\set{a,b}$.
Aplicando o \axref[conset] com $h \asseq b$ e $t \asseq \emptyset$
ganhamos o $\set{b}$, e agora aplicando novamente o mesmo axioma
com $h \asseq a$ e $t \asseq \set{b}$ ganhamos o desejado $\set{a,b}$.
\eop\noi
(2)
Observe que com os axiomas
\axref[extensionality]%
+\axref[emptyset]%
+\axref[conset]\ 
conseguimos construir conjuntos de qualquer cardinalidade finita,
mas com os
\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]\ 
conseguimos construir apenas conjuntos com cardinalidades $0$, $1$, ou $2$.
Basta realmente construir um conjunto com cardinalidade maior que $2$ então.
Aplique o \axref[conset] com $h,t \asseq \emptyset$ ganhando assim
o $\set{\emptyset}$.
Agora com $h \asseq \set\emptyset$ e $t \asseq \emptyset$ ganhando
o $\set{\set{\emptyset}}$.
Com $h \asseq \emptyset$ e $t \asseq \set{\set{\emptyset}}$
ganhamos o $\set{\emptyset, \set{\emptyset}}$.
E finalmente, com $h,t \asseq \set{\emptyset, \set{\emptyset}}$
construimos o $\set{\emptyset, \set{\emptyset}, \set{\emptyset, \set{\emptyset}}}$,
que tem cardinalidade $3$.
\eop\noi
(3)
Sejam $h, t$ conjuntos.
Pelo singleton (\ref[singleton_thm]) ganhamos o $\set h$,
e usando a união binária (\ref[union_and_symdiff_constructed])
nos $\set h$ e $t$ ganhamos o desejado conjunto.

%%}}}

%%{{{ one_class_set_the_other_proper_problem 
\problem.
%%%{{{ meta 
\label one_class_set_the_other_proper_problem
%%%}}}

Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref[extensionality]--\axref[unionset] que:
\item{(i)}  a classe $\classst {\set{x,\set y}} {x \in a \land y \in b}$ é conjunto;
\item{(ii)} a classe $\classstt {\set{x,y}} {$x,y$ conjuntos com $x\neq y$}$ é própria.

\hint
(ii) Absurdo.

%%}}}

%%{{{ two_sets_and_one_proper_class_problem 
\problem.
%%%{{{ meta 
\label two_sets_and_one_proper_class_problem
%%%}}}

Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref[extensionality]--\axref[unionset] que as classes
$$
\align
C &= \classst {\set{x, \set{x,y}}} {x \in a \land y \in b} \\
D &= \classst {\set{x,y}} {
          \paren{ x \in a \lor x \in \Union a }
          \land
          \paren{y \in b \lor y \subset b}
    } \\
\intertext{são conjuntos, mas não a classe}
Z &= \classst {\Inter\Inter z} {z \neq \emptyset \land \Inter z \neq \emptyset}.
\endalign
$$

%%}}}

%%{{{ finite_set_constructor_proof 
\problem.
%%%{{{ meta 
\label finite_set_constructor_proof
%%%}}}

Demonstre o~\ref[finite_set_constructor].

\hint
Indução!

%%}}}

%%{{{ construct_pfset 
\problem.
%%%{{{ meta 
\label construct_pfset
%%%}}}

Demonstre que para todo conjunto $a$, o $\pfset a$ também é conjunto.
Ganhamos assim mais um construtor (unário) de conjuntos: $\pfset\dhole$.

\hint
O desafio aqui é conseguir escrever a afirmação
``o $x$ é um conjunto finito'' com uma fórmula.

%%}}}

\endproblems
%%}}}

%%{{{ The axiom of infinity 
\section O axioma da infinidade.
%%%{{{ meta 
%%%}}}

%%{{{ No infinite sets but Infinite(-) predicate 
\note.
%%%{{{ meta 
%%%}}}

Com todos os nossos axiomas até agora, mesmo tendo conseguido
representar tanta matemática fielmente dentro da teoria de conjuntos,
ainda \emph{não é garantida} a existência de nenhum conjunto infinito.
Mesmo assim, a noção de ``ser infinito'' pode sim ser expressada
em nossa dicionário, num jeito genial graças ao Dedekind{\Dedekind},
que deu a primeira definição de infinito que não presupõe
a definição dos números naturais.  Como?

%%}}}

\spoiler

%%{{{ df: Dedekind-infinite 
\definition Dedekind-infinito.
%%%{{{ meta 
\defines
    * \Infinite(~a)  -- o conjunto $a$ é Dedekind-infinito
    * Dedekind-infinito
    ;;
%%%}}}

Seja $A$ conjunto.  Chamamos o $A$ \Dedekind[infinito]\dterm{Dedekind-infinito} sse
ele pode ser ``injetado'' para um subconjunto próprio dele, ou seja,
sse existem $X\subsetneq A$ e $f : A \bijto X$.
Definimos então o predicado
$$
\Infinite(a) \defiff \exists x
\paren{
x\subsetneq a \land (a \eqc x)
}.
$$

%%}}}

%%{{{ Set successor 
\note Conjunto-sucessor.
%%%{{{ meta 
\indexes
    * conjunto-sucessor
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: setsucc 
\definition Zermelo, von Neumann.
%%%{{{ meta 
\defines
    * \setsucc {~x}  -- o conjunto-sucessor de $x$
    * conjunto-sucessor
    ;;
%%%}}}

Definimos
\vonNeumann[conjunto-sucessor]%
\Zermelo[conjunto-sucessor]%
o \dterm{conjunto-sucessor} dum conjunto $x$ ser o
$$
\align
\setsucc x &\defeq \set x           \tag{Zermelo}\\
\setsucc x &\defeq x \union \set x. \tag{von Neumann}
\endalign
$$
Como não existe ambigüidade, omitimos parenteses escrevendo por exemplo
$\setsucc{\setsucc{\setsucc x}}$ em vez de
$\setsucc{(\setsucc{(\setsucc x)})}$.

%%}}}

%%{{{ ax: Infinity 
\axiom Infinity.
%%%{{{ meta 
\label infinity
\defines
    * axioma!Infinity
    ;;
%%%}}}

Existe um conjunto que tem o $\emptyset$ como membro e é fechado pela
operação $\lam x {\setsucc x}$.
$$
\exists s
\bigparen{
\emptyset \in s
\land
\forall x
\paren{
x \in s
\limplies
\setsucc x \in s
}
}
\axtag[infinity=ZF7]
$$

%%}}}

%%{{{ x: infinity_axiom_guarantees_natlike_object 
\exercise.
%%%{{{ meta 
%%%}}}

Verdade ou falso?
Com o axioma Infinity~(\axref[infinity]) é garantida a existéncia \emph{do} conjunto
$$
\set {
\emptyset,
\setsucc\emptyset,
\setsucc{\setsucc{\emptyset}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
(Escrevemos ``do'' em vez de ``dum'' pois o axioma
Extensionality~(\axref[extensionality]) garanta que se existe, existe único.)

\hint
\emph{Não é} uma conseqüência imediata do~Infinity~(\axref[infinity]).
Por que não?

%%}}}

%%{{{ df: wrong_definition_of_I 
\definition.
%%%{{{ meta 
\label wrong_definition_of_I
%%%}}}

Seja $I$ o conjunto cuja existência é garantida pelo axioma Infinity~(\axref[infinity]).
Ou seja, o conjunto que satisfaz a condição:
$$
\emptyset \in I \land \forall x \paren{x \in I \limplies \setsucc x \in I}.
$$
\mistake

%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
%%%{{{ meta 
\label def_of_I_used_definite_articile
%%%}}}

Qual o problema com a \ref[wrong_definition_of_I]?

\hint
O artigo.

\solution
Para definir $I$ como \emph{o} conjunto que satisfaz tal propriedade
precisamos: \emph{existência \& unicidade}.
Existéncia é o que~\axref[infinity] garanta;
mas não temos---e nem podemos demonstrar---unicidade.
Então precisamos definir o $I$ como \emph{um} conjunto
que satisfaz aquela condição.

%%}}}

%%{{{ Effects and side-effects 
\note Efeitos e efeitos colaterais.
%%%{{{ meta 
%%%}}}

O axioma Infinity~(\axref[infinity]) é o segundo dos nossos axiomas
que garanta diretamente a existência dum certo objeto;
o primeiro foi o Emptyset~(\axref[emptyset]).\foot
Pois todos os outros começam com quantificadores universais.
\toof
Assim que aceitamos o Emptyset, nós definimos o símbolo $\emptyset$
para ser \emph{o} conjunto vazio.
Para poder fazer isso precisamos \emph{demonstrar} a unicidade
do conjunto vazio~(\ref[uniqueness_of_emptyset]).
Mas a condição que aparece no~\axref[infinity] não é
suficientemente forte para ganhar unicidade pelo~\axref[extensionality]!
Possivelmente (e realmente, como nós vamos ver) nosso mundo tem muitos
conjuntos com essa propriedade!

%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
%%%{{{ meta 
\label infinitely_many_infinite_sets
%%%}}}

Mostre que já é garantida uma infinidade de conjuntos infinitos.

\hint
Olha para os subconjuntos de $I$.

\solution
Tome
$$
\align
I_0 &\asseq I\\
I_1 &\asseq I \setminus \set{ \emptyset }\\
I_2 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset }\\
I_3 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset, \setsucc\emptyset }\\
    &\eqvdots
\endalign
$$

%%}}}

%%{{{ How does this infinite set look like? 
\note Como parece esse conjunto infinito?.
%%%{{{ meta 
\pdefs
    \pdef noise {\mathord{\;\vdots\;}}
    ;;
%%%}}}

Bem; sabemos que $I$ é infinito e tal, mas quais são os elementos dele?
É tentador pensar que $I$ é o conjunto
$$
I_* \pseudodefeq \set { \emptyset, \setsucc\emptyset, \setsucc{\setsucc\emptyset}, \setsucc{\setsucc{\setsucc{\emptyset}}},\dotsc}.
$$
No final das contas, vendo o~\axref[infinity],
\emph{o que mais poderia estar no $I$?}
Nada.  Certo?
Não.  Bem o oposto!
\emph{Absolutamente tudo} pode pertencer nesse $I$, pois a
única informação que temos sobre ele não tira nenhum objeto como
possível membro dele!
Realmente, os únicos elementos \emph{garantidos} no $I$ são
aqueles que escrevemos acima como membros do $I_*$, mas o $I$
pode ter mais: pode ter ``lixo'', como este:
$$
I_{\spade,\heart} \pseudodefeq \set {
\emptyset,
\spade,
\heart,
\setsucc\emptyset,
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
Aqui os $\spade$ e $\heart$ denotam dois objetos do nosso universo,
talvez nem são conjuntos, talvez denotam os próprios símbolos
``$\spade$'' e ``$\heart$'', talvez somos nos, eu e tu, etc.
Para a gente, é o lixo.\foot
Sem ofensa.
\toof
\eop
Na verdade, esse último conjunto não pode ser o nosso $I$, pois ele não
satisfaz a condição do~(\axref[infinity]) pois
$$
\spade \in I
\qqtext{mas}
\setsucc\spade \notin I.
$$
Podemos então entender melhor nosso $I$.
Ele é um superconjunto do $I_*$---isto é garantido pelo~(\axref[infinity]) mesmo.
O que mais ele tem?  Não sabemos dizer, mas sabemos que \emph{se tem} outros objetos,
ele obrigatoriamente tem uma infinidade de conjuntos para cada um deles:
$$
\set {
\emptyset,
\spade,
\heart,
\setsucc{\emptyset},
\setsucc{\spade},
\setsucc{\heart},
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\spade}},
\setsucc{\setsucc{\heart}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\setsucc{\setsucc{\setsucc{\spade}}},
\setsucc{\setsucc{\setsucc{\heart}}},
\dotsc
}.
$$
Vamos revisar esse $I$ então.
Sabemos que ele parece assim:
$$
I = \set {
\emptyset,
\noise,
\setsucc{\emptyset},
\noise,
\setsucc{\setsucc{\emptyset}},
\noise,
\setsucc{\setsucc{\setsucc{\emptyset}}},
\noise,
\setsucc{\setsucc{\setsucc{\setsucc{\emptyset}}}},
\noise,
\dotsc
}
$$
onde os $\noise$ representam o lixo,
e nosso próximo trabalho será achar um jeito para nos livrar desse lixo!

%%}}}

\endsection
%%}}}

%%{{{ Constructing the natural numbers 
\section Construindo os números naturais.
%%%{{{ meta 
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

Primeiramente precisamos esclarecer o que precisamos implementar.
Qual é o ``pedido'' do cliente que queremos atender?
Quais são as leis (suficientes e necessárias) que os números naturais devem
respeitar?

%%}}}

\spoiler

%%{{{ Peano system 
\definition Sistema Peano.
%%%{{{ meta 
\label Peano_system
\defines
    * princípio!da indução, Peano
    * sistema Peano
    * axioma!Dedekind--Peano
    ;;
\credits
    * Peano
    * Dedekind
    ;;
%%%}}}

Um \dterm{sistema Peano} é um conjunto estruturado
$\cal N = \sset \Nats {\Zero,\Succ}$ que satisfaz as leis:
$$
\alignat2
&\text{Zero é um número natural:}                     &\qquad&  \Zero \in \Nats                  \tag{P1}\\
&\text{O sucessor é uma operação unária nos naturais:}&&        \Succ \eqtype \Nats \to \Nats    \tag{P2}\\
&\text{Naturais diferentes tem sucessores diferentes:}&&        \Succ \eqtype \Nats \injto \Nats \tag{P3}\\
&\text{Zero não é o sucessor de nenhum natural:}      &&        \Zero \notin \img \Succ \Nats    \tag{P4}\\
&\text{Os naturais satisfazem o princípio da indução:}                                           \tag{P5}
\endalignat
$$
\dterm{Princípio da indução}\/:
\emph{para todo $X\subset \Nats$,}
$$
\bigparen{
\Zero\in X
\land
\forall n
\paren{
n \in X \limplies \Succ n \in X
}
} \limplies X = \Nats.
$$
Observe que graças às (P3) e (P4) temos
$$
\gather
\Succ n = \Succ m \implies n = m \\
\Succ n \neq \Zero
\endgather
$$
para todos os $n,m\in \Nats$.
Os axiomas (P1)--(P5) são conhecidos como \dterm{axiomas Dedekind--Peano}.

%%}}}

%%{{{ Defining a Peano system 
\note Definindo um sistema Peano.
%%%{{{ meta 
%%%}}}

Então o que precisamos implementar é um conjunto estruturado
$\cal N = \sset \Nats {\Zero, \Succ}$.
Isso é fácil: nosso $\cal N$ vai ser uma tripla $\tup {\Nats, \Zero, \Succ}$,
onde seus membros $\Nats$, $\Zero$, e $\Succ$ são tais objetos que as leis
(P1)--(P5) são satisfeitas.
Sabemos que o $\Nats$ precisa ser infinito, então temos que o procurar
entre os conjuntos infinitos da nossa teoria.
Uma primeira idéia seria botar $\Nats \defeq I$, mas essa não parece
uma idéia boa---será difícil ``vender'' uma implementação com lixo!
O que realmente queremos botar como $\Nats$ é o $I_*$
(que não conseguimos ainda defini-lo).
Mas vamos supor que o $I_*$ realmente é um conjunto;
ele vai representar os números naturais,
mas quais serão nossos $\Zero$ e $\Succ$?
Pela especificação dos naturais, $\Zero$ tem que ser um dos membros do $I_*$,
e bem naturalmente escolhemos o $\emptyset$ como o zero.
E o $\Succ$?  Obviamente queremos botar $\Succ = \lam x {\setsucc x}$,
mas para realmente definir o $\Succ$ como funcção, lembramos que em nosso
dicionário ``funcção'' é um certo tipo de conjunto de pares.
Botamos então
$$
\align
\Succ &\pseudodefeq \classst {\tup{n,m}} { m = \setsucc n }
\intertext{e agora só basta achar um conjunto que tem todos esses pares
como membros.  Fácil:}
\Succ &\defeq \setst {\tup{n,m}\in \Nats\times \Nats} { m = \setsucc n }.
\endalign
$$
Então falta só definir esse $I_*$.

%%}}}

%%{{{ Getting rid of noise 
\note Jogando fora o lixo.
%%%{{{ meta 
%%%}}}

Queremos definir o $I_*$ como conjunto; construí-lo pelos axiomas.
Uma primeira tentativa seria começar com o próprio $I$,
e usar o Separation~(\axref[separation]) para filtrar
seus elementos, separando os quais queremos do lixo,
assim botando
$$
I_* = \setst {x\in I} {\phi(x)}.
$$
para algum certo filtro $\phi(\dhole)$.
Qual fórmula vamos usar?

%%}}}

\spoiler

%%{{{ A top-down approach 
\note Uma abordagem top-down.
%%%{{{ meta 
%%%}}}

Não podemos descrever um filtro em nossa linguagem de lógica
(FOL de teoria de conjuntos)!  (Lembra-se, uma fórmula não pode
ter tamanho infinito.)
Precisamos então alguma outra idéia para nos livrar dos elementos ``extra'' do $I$.
\emph{Vamos definir o conjunto $I_*$ com a abordagem top-down!}
Sabemos que nosso $I_*$ desejado é um subconjunto de $I$.
Então vamos começar com a colecção de todos os subconjuntos de $I$
que satisfazem a condição do Infinity:
$$
\scr I
\defeq
\setst {i \in \pset I} {\emptyset \in i \land \forall x\paren{x\in i \limplies \setsucc x \in i}
}.
$$
Queremos agora selecionar o ``menor'' elemento dessa família $\scr I$.
Menor no sentido de ``aquele que está contido em todos''.
Sim, nosso $I_*$ é o $\subset$-menor elemento do $\scr I$!
Para defini-lo basta tomar a intersecção da família $\scr I$,
que podemos pois
$\scr I \neq \emptyset$~(\ref[why_is_scrI_nonempty]):
$$
I_* \defeq \Inter {\scr I}.
$$

%%}}}

%%{{{ x: why_is_scrI_nonempty 
\exercise.
%%%{{{ meta 
\label why_is_scrI_nonempty
%%%}}}

Por que $\scr I \neq \emptyset$?

\solution
Pois $I\in\scr I$.

%%}}}

%%{{{ thm: existence_of_nats 
\theorem Existência dos naturais.
%%%{{{ meta 
\label existence_of_nats
%%%}}}

Existe pelo menos um sistema Peano $\cal N = \sset \Nats {\Zero, \Succ}$.

\sketch.
Definimos
$$
\cal N \defeq \tup{\Nats, \Zero, \Succ},
$$
onde:
$$
\align
\Nats &\defeq \Inter \setst {i \in \pset I} {\emptyset \in i \land \forall x \paren{x\in i \limplies \setsucc x \in i}}\\
\Zero &\defeq \emptyset\\
\Succ &\defeq \setst {\tup{m,n}\in \Nats\times\Nats} { n = \setsucc m }.
\endalign
$$
Temos já justificado que cada objeto que aparece nessa definição
é conjunto pelos axiomas.  Basta só verificar que as (P1)--(P5)
são satisfeitas.

\proof.
A única coisa que deixamos para completar a prova foi
verificar os (P1)--(P5), que é feito nos
exercícios \reftag[zero_is_a_nat]--\reftag[nat_has_induction].

%%}}}

%%{{{ x: P1 zero_is_a_nat 
\exercise P1.
%%%{{{ meta 
\label zero_is_a_nat
%%%}}}

Demonstre que $\Zero\in\Nats$.

%%}}}

%%{{{ x: P2 succ_is_a_function 
\exercise P2.
%%%{{{ meta 
\label succ_is_a_function
%%%}}}

Demonstre que $\Succ$ é uma funcção.

%%}}}

%%{{{ x: P3 succ_is_injective 
\exercise P3.
%%%{{{ meta 
\label succ_is_injective
%%%}}}

Demonstre que $\Succ : \Nats \injto \Nats$.

%%}}}

%%{{{ x: P4 zero_is_not_a_succ 
\exercise P4.
%%%{{{ meta 
\label zero_is_not_a_succ
%%%}}}

Demonstre que $\Zero\notin \img \Succ \Nats$.

%%}}}

%%{{{ x: P5 nat_has_induction 
\exercise P5.
%%%{{{ meta 
\label nat_has_induction
%%%}}}

Seja $X\subset \Nats$ tal que:
\tlist:
\li (1): $\Zero \in X$;
\li (2): para todo $k\in \Nats$, se $k\in X$ então $\Succ k \in X$.
\endtlist
Demonstre que $X=\Nats$.

%%}}}

%%{{{ thm: uniqueness_of_nats 
\theorem Unicidade dos naturais.
%%%{{{ meta 
\label uniqueness_of_nats
\indexes
    * unicidade!dos naturais
    ;;
\credits
    * Dedekind : unicidade dos naturais
    ;;
%%%}}}

Se  $\cal N_1 = \sset {\Nats_1} {\Zero_1, \Succ_1}$
e   $\cal N_2 = \sset {\Nats_2} {\Zero_2, \Succ_2}$
são sistemas Peano, então são isomorfos: $\cal N_1 \iso \cal N_2$.

\wrongproof.
Precisamos definir um isomorfismo
$\phi : \cal N_1 \iso \cal N_2$.
Definimos a funcção $\phi : \Nats_1 \to \Nats_2$ usando recursão:
$$
\align
\phi(\Zero_1) &= \Zero_2\\
\phi(\Succ_1n) &= \Succ_2\phi(n).
\endalign
$$
Pela sua definição, a $\phi$ é um homomorfismo.
Basta só verificar que a $\phi$ é bijetora,
algo que tu vai fazer agora nos exercícios
\reftag[homomorphism_of_nats_is_mono]~\&~\reftag[homomorphism_of_nats_is_epi].
\mistake

%%}}}

%%{{{ x: homomorphism_of_nats_is_mono 
\exercise.
%%%{{{ meta 
\label homomorphism_of_nats_is_mono
%%%}}}

Demonstre que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref[uniqueness_of_nats] é um monomorfismo.

%%}}}

%%{{{ x: homomorphism_of_nats_is_epi 
\exercise.
%%%{{{ meta 
\label homomorphism_of_nats_is_epi
%%%}}}

Demonstre que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref[uniqueness_of_nats] é um epimorfismo.

\hint
Pela definição de sobrejetora e de imagem,
basta demonstrar que
$\img \phi {\Nats_1} = \Nats_2$.

\hint
Já sabemos que $\img\phi{\Nats_1} \subset \Nats2$.
Para demonstrar a igualdade mesmo, use o princípio da indução.

\hint
Precisas demonstrar duas coisas então:
(1) $\Zero_2 \in \img\phi{\Nats_1}$;
(2) para todo $n \in \Nats_2$, se $n \in \img\phi{\Nats_1}$ então $\Succ_2 n \in \img\phi{\Nats_1}$.

\solution
Como $\img \phi {\Nats_1} \subset \Nats_2$,
provamos a igualdade usando o princípio da indução~(P5).
\proofpart{Base.}
$\Zero_2 \in \img\phi{\Nats_1}$:
Imediato pois $\phi(\Zero_1) = \Zero_2$.
\proofpart{Passo indutivo.}
Suponha $k \in \img\phi{\Nats_1}$.
Precisamos mostrar que $\Succ_2 k \in \img\phi{\Nats_1}$.
Pela escolha de $k$, tome $k' \in \Nats_1$ tal que
$\phi(k') = k$.
Calculamos:
\compute
\phi(\Succ_1 k')
&= \Succ_2 (\phi(k')) \by {pela def.~$\phi$} \\
&= \Succ_2 k          \by {pela escolha de $k'$} \\
\endcompute
ou seja, $\Succ_2 k \in \phi[\Nats_1]$.

%%}}}

%%{{{ x: we_dont_have_recursion_yet 
\exercise.
%%%{{{ meta 
\label we_dont_have_recursion_yet
%%%}}}

Qual o erro na demonstração do~\ref[uniqueness_of_nats]?

\hint
O que é uma funcção em nosso dicionário,
e quem garanta que escrevendo assim do nada duas equações
sobre um certo objeto $F$, isso realmente defina
uma funcção?

\solution
Não temos provado que dando equações recursivas como na
prova desse teorema podemos realmente definir uma funcção.
Fazemos isso no~\ref[recursion_theorem], assim
realmente botando o $\qedsymbol$ no~\ref[uniqueness_of_nats].

%%}}}

\endsection
%%}}}

%%{{{ Recursion_theorems 
\section Teoremas de recursão.
%%%{{{ meta 
\label Recursion_theorems
\indexes
    * recursão!teorema    see: teorema de recursão
    ;;
%%%}}}

%%{{{ thm: recursion_theorem 
\theorem Teorema da Recursão.
%%%{{{ meta 
\headerize
\label recursion_theorem
\indexes
    * funcção!parcial!compatibilidade
    * funcção!parcial!conflito
    ;;
\defines
    * teorema!de recursão
    ;;
%%%}}}

Sejam $\cal N = \sset \Nats {\Zero, \Succ}$ um sistema Peano,
$A$ conjunto,
$a \in A$,
e $h: A \to A$.
Então existe única funcção $F : \Nats \to A$ que satisfaz as equações:
$$
\align
F(\Zero)    &= a \tag{1}\\
F(\Succ n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$

\sketch.
Nosso plano é
\tlist:
\li (i): construir o objeto $F$ como conjunto;
\li (ii): mostrar que $F : \Nats \to A$;
\li (iii): mostrar que $F$ satisfaz as (1)--(2);
\li (iv): unicidade.
\endtlist
\eop
(i)
Vamos construir o $F$ \emph{bottom-up}, juntando umas das suas aproximações finitas:
funcções parciais $f : \Nats\parto E$ onde a idéia é que elas ``concordam'' com a $F$
desejada onde elas estão definidas.
Nem vamos considerar todas elas: para nossa conveniência queremos apenas aquelas
cujo domínio é algum $\finord n$.
Por exemplo, as primeiras aproximações seriam as seguintes:
$$
\align
f_0 &= \emptyset\\
f_1 &= \bigset{ \tup{0,a} }\\
f_2 &= \bigset{ \tup{0,a}, \tup{1,h(a)} }\\
f_3 &= \bigset{ \tup{0,a}, \tup{1,h(a)}, \tup{2,h(h(a))} },\\
    &\eqvdots
\endalign
$$
Definimos o conjunto $\scr A$ de todas as aproximações aceitáveis:
$$
\scr A \defeq \setst {f \in (\Nats\parto E)} {\text{$f$ é aproximação aceitável}}
$$
onde falta descrever com uma fórmula nossa idéia de ``ser aproximação aceitável''
(\ref[acceptable_approximation]).
(Das aproximações acima a $f_0$ não é aceitável.)
Agora podemos já definir o $F$:
$$
F \defeq \Union {\scr A}.
$$
\eop
(ii)
Precisamos mostrar a compatibilidade da $\scr A$ e a totalidade da $F$,
ou seja: que não existem \emph{conflitos}
(em outras palavras: que a família de funcções parciais
$\scr A$ é \emph{compatível}\indexed[funcção!parcial!compatibilidade]);
e que $\dom F = \Nats$.
Esses são os exercícios~\ref[compatibility_of_scrF]~\&~\ref[totality_of_F]
respectivamente.
\eop
(iii)
Precisamos verificar a corretude da $F$, que ela atende sua especificação.
Essa parte deve seguir da definição de ``aproximação aceitável''.
Confirmamos isso no~\ref[correctness_of_F].
\eop
(iv)
Para a unicidade da $F$, precisamos mostrar que se $G : \Nats \to A$ tal que
satisfaz as (1)--(2), então $F = G$.  Isso é o~\ref[uniqueness_of_F], e com
ele terminamos nossa prova.

\proof.
A prova completa segue do seu esboço junto com os exercícios:
\reftag[acceptable_approximation],
\reftag[compatibility_of_scrF],
\reftag[totality_of_F],
\reftag[correctness_of_F], e
\reftag[uniqueness_of_F].

%%}}}

%%{{{ x: recursion_theorem_as_cd 
\exercise.
%%%{{{ meta 
\label recursion_theorem_as_cd
%%%}}}

Desenhe um diagrama comutativo que expressa o \ref[recursion_theorem].

\hint
Uma forma razoável tem a forma seguinte:
$$
\cdopt{sep=2cm}
?   \ar[r, "?"]\ar[dr, "?"'] \| ? \ar[r, "?"]\ar[d, dotted, "\unique"] \| ? \ar[d, dotted, "\unique"] \\
                             \| ?     \ar[r, "?"]                      \| ?
\endcd
$$
Basta nomear os objetos e as setas.

\hint
Aqui os objetos:
$$
\cdopt{sep=2cm}
1   \ar[r, "?"]\ar[dr, "?"'] \| \nats \ar[r, "?"]\ar[d, dotted, "\unique"] \| \nats \ar[d, dotted, "\unique"] \\
                             \| A     \ar[r, "?"]                          \| A
\endcd
$$

\solution
$$
\cdopt{sep=2cm}
1   \ar[r, "O"]\ar[dr, "a"'] \| \nats \ar[r, "S"]\ar[d, dotted, "\unique"] \| \nats \ar[d, dotted, "\unique"] \\
                             \| A     \ar[r, "h"]                          \| A
\endcd
$$

%%}}}

%%{{{ x: acceptable_approximation 
\exercise.
%%%{{{ meta 
\label acceptable_approximation
%%%}}}

No contexto do~\ref[recursion_theorem] defina formalmente a afirmação
\wq{$f$ é uma aproximação aceitável}.

\hint
Podemos ``quebrar'' a afirmação nessas partes:
\elist:A
\li: $f : \Nats \parto A$
\li: $\tup{0,a} \in f$
\li: Para qualquer $n\in\Nats_{\neq0}$, se $f$ é definida no $n$,
     então ela também é definida no predecessor de $n$,
     e o valor dela no $n$ é o correto, ou seja,
     o valor que ganhamos aplicando a $h$ no valor do predecessor de $n$.
\endelist
O único que precisamos formalizar agora é o último.

%%}}}

%%{{{ x: compatibility_of_scrF 
\exercise Compatibilidade.
%%%{{{ meta 
\label compatibility_of_scrF
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $\scr A$ é compatível.

%%}}}

%%{{{ x: totality_of_F 
\exercise Totalidade da $F$.
%%%{{{ meta 
\label totality_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $\dom F = \Nats$.

\hint
Verifique que $\dom F \subset \Nats$.
Agora basta demonstrar que $\dom F = \Nats$, usando o princípio da indução.

%%}}}

%%{{{ x: correctness_of_F 
\exercise Corretude da $F$.
%%%{{{ meta 
\label correctness_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $F$ atende sua especificação,
ou seja:
$$
\align
F(\Zero)    &= a \tag{1}\\
F(\Succ n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$

%%}}}

%%{{{ x: uniqueness_of_F 
\exercise Unicidade da $F$.
%%%{{{ meta 
\label uniqueness_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] demonstre a unicidade da $F$, ou seja:
se $G : \Nats \to A$ tal que
$$
\align
G(\Zero)    &= a \tag{1}\\
G(\Succ n)  &= h(G(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$
então $F = G$.
Em outras palavras, as equações (1)--(2)
\emph{determinam} a funcção no $\Nats$.

\hint
Seja $X \subset \Nats$ o conjunto onde $F$ e $G$ ``concordam''.
Mostre que $X = \Nats$ usando o princípio da indução.

%%}}}

\endsection
%%}}}

%%{{{ Consequences of induction and recursion 
\section Conseqüências de indução e recursão.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na~\reftag[Nats_formally] definimos recursivamente umas operações nos naturais.
Graças ao \ref[recursion_theorem], ganhamos todas essas operações em qualquer
sistema Peano.  Vamos lembrar como, e também demonstrar que não importa
\emph{em qual} sistema Peano calculamos: os resultados serão os
correspondentes!

%%}}}

%%{{{ note: Operations and order 
\note Operações e ordem.
%%%{{{ meta 
%%%}}}

Para qualquer sistema Peano $\cal N = \sset \Nats {\Zero, \Succ}$,
definimos as operações de adição e de multiplicação
$$
\xxalignat5
&\text{(a1)}  & n + \Zero   &= n          &&& n \ntimes \Zero   &= \Zero                &&\text{(m1)}\\
&\text{(a2)}  & n + \Succ m &= \Succ(n+m) &&& n \ntimes \Succ m &= (n \ntimes m) + n    &&\text{(m2)}
\endxxalignat
$$
e a relação de ordem no $\Nats$
$$
    n \leq m \defiff (\exists k\in\Nats)[n + k = m].
$$
Sejam dois sistemas Peano
$\cal N_1 = \sset {\Nats_1} {\Zero_1, \Succ_1}$ e 
$\cal N_2 = \sset {\Nats_2} {\Zero_2, \Succ_2}$, e
suas operações de adição $+_1$ e $+_2$, e suas relações de ordem $\leq_1$ e $\leq_2$.
Seja $\phi:\Nats_1\bijto\Nats_2$ o isomorfismo definido pelas
$$
\align
    \phi(\Zero_1)   &= \Zero_2           \tag{$\phi$1}\\
    \phi(\Succ_1 n) &= \Succ_2(\phi(n)). \tag{$\phi$2}
\endalign
$$

%%}}}

%%{{{ property: peano_morphism_respects_addition 
\property.
%%%{{{ meta 
\label peano_morphism_respects_addition
%%%}}}

A $\phi$ respeita a adição, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n +_1 m) = \phi(n) +_2 \phi(m)
$$

\proof.
Por indução no $m\in\Nats_1$:
\proofpart{Base ($m \asseq \Zero_1$):}
{\proclaimstyle para todo $n\in\Nats_1$, $\phi(n +_1 \Zero_1) = \phi(n) +_1 \phi(\Zero_1)$.}
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Zero_1)
&= \phi(n)                    \by {pela (a1)$_1$} \\
&= \phi(n) +_2 \Zero_2        \by {pela (a1)$_2$} \\
&= \phi(n) +_2 \phi(\Zero_1)  \by {pela ($\phi$1)} \\
\endcompute
\proofpart{Passo indutivo:}
Seja $k \in \Nats_1$ tal que
$$
\text{para todo $n \in \Nats_1$, $\phi(n +_1 k) = \phi(n) +_1 \phi(k)$.} \tag{H.I.}
$$
Vamos demonstrar que
$$
\text{\proclaimstylize{para todo $n \in \Nats_1$, $\phi(n +_1 \Succ_1 k) = \phi(n) +_1 \phi(\Succ_1 k)$.}}
$$
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Succ_1 k)
&= \phi(\Succ_1(n +_1 k))       \by {pela (a1)$_2$} \\
&= \Succ_2(\phi(n +_1 k))       \by {pela ($\phi$2)} \\
&= \Succ_2(\phi(n) +_2 \phi(k)) \by {pela (H.I.), com $n\asseq n$} \\
&= \phi(n) +_2 \Succ_2\phi(k)   \by {pela (a2)$_2$} \\
&= \phi(n) +_2 \phi(\Succ_1 k)  \by {pela ($\phi$2)} \\
\endcompute

%%}}}

%%{{{ x: peano_morphism_respects_multiplication 
\exercise.
%%%{{{ meta 
\label peano_morphism_respects_multiplication
%%%}}}

Mostre que $\phi$ respeita a multiplicação, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n \ntimes_1 m) = \phi(n) \ntimes_2 \phi(m).
$$

\hint
Indução no $m\in\Nats_1$.

%%}}}

%%{{{ x: peano_morphism_respects_order 
\exercise.
%%%{{{ meta 
\label peano_morphism_respects_order
%%%}}}

Mostre que $\phi$ respeita a ordem também, no sentido de:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
n\leq_1 m \iff \phi(n)\leq_2 \phi(m).
$$

\hint
Demonstre as duas direções da \bidir\ separadamente.

%%}}}

\endsection
%%}}}

%%{{{ Constructing more numbers 
\section Construindo mais números.
%%%{{{ meta 
\label Constructing_more_numbers
\pdefs
    \pdef eqrat {\approx}
    \pdef eqint {\approx}
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo construido já os naturais,
vamos construir seus parentes também:
os inteiros, os racionais, os reais, e os complexos.

%%}}}

%%{{{ The integers 
\note Os inteiros.
%%%{{{ meta 
%%%}}}

Provavelmente a primeira idéia para implementar um inteiro $x$ é usar
uma $2$-tupla $x \defeq \tup{s,m}$ onde $s$ é um objeto para indicar o sinal
do $x$ e $m \defeq \abs{x}$.
Essa resolução, mesmo tecnicamente possível, não é legal.
Dependendo de se teriamos $2$ ou $3$ sinais podemos acabar com duas distintas
representações de $0$, números $x \neq 0$ com sinal $0$, ou outros problemas
similares.
Além disso, como vamos definir as operações?  Vão acabar sendo definições
por casos no sinal $s$, na ordem dos argumentos, etc.
Nenhum desses problemas é difícil corrigir; mas tudo isso deve aparecer
coisa com cheiro de \dq{ugly hack}.  E é mesmo.
A idéia é representar os inteiros como diferenças de naturais.
O inteiro $5$ então pode ser visto como a diferença $12 - 7$;
e o inteiro $-5$ como a $7 - 12$.
Como podemos formalizar isso numa maneira elegante?

%%}}}

\spoiler

%%{{{ df: eqint 
\definition Números inteiros.
%%%{{{ meta 
\label eqint
%%%}}}

Seja $Z = \nats \times \nats$.
Defina no $Z$ a relação $\eqint$ pela
$$
\tup{a,b} \eqrat \tup{c,d}
\defiff
a + d = c + b.
$$
Sendo uma relação de equivalência (\ref[eqint_is_an_eqrel]),
definimos
$$
\Ints
\defeq
\quoset Z {\eqint}.
$$

%%}}}

%%{{{ x: eqint_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label eqint_is_an_eqrel
%%%}}}

Mostre que $\eqint$ é uma relação de equivalência.

%%}}}

%%{{{ x: formalints_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalints_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Ints$ virar uma representação
de inteiros útil para o \emph{matemático trabalhador}.
(Parte desses exercícios é decidir o que falta mesmo.)

%%}}}

%%{{{ The rational numbers 
\note Os números racionais.
%%%{{{ meta 
%%%}}}

Essa construção é bem interessante---e simples!---pois usa um conceito nosso que
deve ser familiar já: sim, novamente o conjunto quociente.
Queremos identificar o racional $1/2$ com o par $\tup{1,2}$,
mas não podemos identificar o próprio $\rats$ com o $\ints \times \ints_{\neq0}$,
pois $\tup{1,2} \neq \tup{2,4}$ mesmo que $1/2 = 2/4$.
Duas idéias parecem razoáveis: (1) escolher um representante específico para cada
racional, trabalhando assim num subconjunto próprio do $\ints\times\ints_{\neq0}$;
(2) definir a relação $\eqrat$ de \emph{equivalência} no $\ints\times\ints_{\neq0}$,
e representar os racionais \emph{não como} membros desse conjunto,
mas \emph{sim como} classes de equivalência, ou seja, membros do conjunto quociente
$\quoset {\ints\times\ints_{\neq0}} {\eqrat}$.
Vamos seguir essa segunda idéia, pois é mais símples e elegante.

%%}}}

%%{{{ df: eqrat 
\definition Números racionais.
%%%{{{ meta 
\label eqrat 
%%%}}}

Seja $Q = \ints\times\ints_{\neq0}$.
Defina no $Q$ a relação $\eqrat$ pela
$$
\tup{a,b} \eqrat \tup{c,d}
\defiff
ad = bc.
$$
Sendo uma relação de equivalência (\ref[eqrat_is_an_eqrel]),
definimos
$$
\Rats
\defeq
\quoset Q {\eqrat}.
$$

%%}}}

%%{{{ x: eqrat_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label eqrat_is_an_eqrel
%%%}}}

Mostre que $\eqrat$ é uma relação de equivalência.

%%}}}

%%{{{ x: formalrats_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalrats_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Rats$ virar uma representação
de racionais útil para o \emph{matemático trabalhador}.

%%}}}

%%{{{ The real numbers 
\note Os números reais.
%%%{{{ meta 
\label Constructing_the_reals
\credits
    * Dedekind : construção dos reais
    * Cantor : construção dos reais
    * Cauchy : seqüência Cauchy
    ;;
%%%}}}

Existem várias maneiras de construir os reais com o que temos até agora.
Neste texto encontramos as duas ``principais'': de Dedekind, que usa
\emph{Dedekind cuts}, e de Cantor, que usa \emph{seqüências Cauchy}.
Ambas as maneiras são baseadas na idéia que a ``linha'' dos racionais
tem buracos (certos pontos estão faltando) e a construção dos reais
precisa adicionar esses buracos.  Para a metodo de Dedekind, visualizamos
os buracos como suprema que estão em falta de certos conjuntos;
para o Cantor, os buracos são limites de seqüências que \emph{querem
converger mas não conseguem} pois seus limites desejados não estão presentes!
Vamos seguir Dedekind agora;
a abordagem de Cantor fica para o~\ref[reals_as_cauchy_seqs].

%%}}}

\TODO Elaborar/terminar.

%%{{{ Dedekind cut 
\note Dedekind cut.
%%%{{{ meta 
\credits
    * Dedekind!Dedekind cut
    ;;
%%%}}}

Seja $\alpha \in \reals$.  O Dedekind cut que corresponde (representa) o $\alpha$ parece assim:
$$
\tikzpicture
\tikzi dedekindcut;
\endtikzpicture
$$
onde
\mathcols 2
A &= \setst {r \in \rats} {r < \alpha} &
B &= \setst {r \in \rats} {r \geq \alpha}.
\endmathcols
A idéia é que podemos definir o real $\alpha$ para ser esse Dedekind cut.
Observe que  definindo o $A$, determinamos o $B$ também, pois
$B = \rats \setminus A$.
Só que já temos um problema: na definição do $A$ usamos o real $\alpha$, ou seja,
nossa definição presupõe que já temos os reais na nossa disposição;
mas os reais são o que estamos tentando construir, então obviamente não
podemos usá-los para construí-los!
Mesmo assim, podemos usar nossa intuição da reta real e da reta dos racionais
no nosso rascunho para nos ajudar resolver esse problema.
Note que caso que $\alpha$ é um racional a parte $B$ possui mínimo (o próprio $\alpha$);
no outro lado os $B$'s que correspondem em irracionais não possuem mínimo.
Por exemplo, aqui os $1_\reals$ e $\sqrt 2_{\reals}$ como Dedekind cuts:
\math
\tikzpicture
\tikzi dedekindcut_one;
\endtikzpicture
\\
\tikzpicture
\tikzi dedekindcut_sqrttwo;
\endtikzpicture
\endmath
Agora basta achar uma maneira que descreva todos os subconjuntos
do $\rats$ que podem ser usados como $A$'s num Dedekind cut,
para construir o $\reals$ como o conjunto de todos eles:
$$
\Reals \defeq \setstt {A \subset \rats} { $A$ parece como no desenho acima }.
$$

%%}}}

%%{{{ Q: How would you describe these A's? 
\question.
%%%{{{ meta 
%%%}}}

Como descreverias formalmente esses $A$'s?

%%}}}

\spoiler

%%{{{ df: dedekind_cut 
\definition Dedekind cuts.
%%%{{{ meta 
\label dedekind_cut
\defines
    * Dedekind cut
    ;;
\credits
    * Dedekind : Dedekind cut
    ;;
%%%}}}

Chamamos $A$ de {\Dedekind[cut]}\dterm{Dedekind cut} sse:
\elist i:
\li:dedekind_cut_downwards_closed
$A$ é ``fechado pra baixo'': $\pforall {a \in A} \lforall {q \in \rats} {q < a \implies q \in A}$;
\li:dedekind_cut_nomax
$A$ não possui máximo: $\pforall {a \in A} \lexists {a' \in A} {a < a'}$;
\li:dedekind_cut_nonempty
$A \neq \emptyset$;
\li:dedekind_cut_nonfull
$A \neq \rats$.
\endelist
Visualmente parece melhor chamar de \dterm{Dedekind cut} a partição
$\set{A, B}$ ou o par $\tup{A, B}$.  As vezes fazemos isso, algo que
nunca gera confusão graças ao contexto.

%%}}}

%%{{{ x: formalreals_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalreals_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Reals$ virar uma representação
de reais útil para o \emph{matemático trabalhador}.

%%}}}

%%{{{ thm: existence_of_reals 
\theorem Existência dos reais.
%%%{{{ meta 
\label existence_of_reals
\pdefs 
    \pdef R {{\cal R}}
    \pdef P {{\rm P}}
    ;;
%%%}}}

Existe um corpo ordenado competo.

\proof.
Seja
$\R \defeq \sset \Reals {+_\R, \ntimes_\R, -_\R, 0_\R, 1_\R, \P_\R}$
um conjunto estruturado,
onde todos os componentes devem estar já definidos
no~\ref[formalreals_for_the_working_mathematician].
Falta só demonstrar que o $\R$ realmente satisfaz os axiomas
de corpo ordenado completo, que deixo para
o~\ref[formalreals_is_a_complete_ordered_field].

%%}}}

%%{{{ x: formalereals 
\exercise.
%%%{{{ meta 
\label formalereals
%%%}}}

O que acontece se apagar os \reftag[dedekind_cut_nonempty] e
\reftag[dedekind_cut_nonfull] da \ref[dedekind_cut]?

%%}}}

%%{{{ More numbers 
\note Mais numeros.
%%%{{{ meta 
%%%}}}

Podemos construir mais mas nosso objetivo aqui não é formalizar
e implementar tudo; apenas apreciar as possibilidades
e o poder da teoria dos conjuntos nesse quesito, e obter
pelo menos o que precisamos aqui:
naturais, inteiros, racionais, reais.
Como exercício, deixo pra ti a construção dos complexos
(que raramente aparecem aqui como \emph{cameo}).
Se quiser implementar ainda mais, sinta-se a vontade aprofundar.

%%}}}

%%{{{ x: construct_complex 
\exercise.
%%%{{{ meta 
\label construct_complex
%%%}}}

Construa os complexos.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: multiset_formally_defined 
\problem Multisets.
%%%{{{ meta 
\label multiset_formally_defined
\indexes
    * multiset
    ;;
%%%}}}

Alguém te deu a seguinte especificação de multiset
e tu queres implementá-la dentro da teoria de conjuntos.
(Veja também \ref[Multisets] no \ref[Sets].)
\eop
\noi
{\bf ``Definição''.}
Lembre (\ref[Multisets]) que um \dterm{multiset} (ou \dterm{bag})
$M$ é como um conjunto onde um elemento pode pertencer ao $M$ mais que
uma vez (mas não uma infinidade de vezes).
Ou seja, a ordem não importa (como nos conjuntos),
mas a ``multiplicidade'' importa sim.
\eop
Queremos tres operações em multisets, exemplificadas assim:
$$
\align
    \bag{ x, y, y, z, z, z, w } \bagunion
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, y, z, z, z, u, v, v, w }\\
    \bag{ x, y, y, z, z, z, w } \baginter
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, z, z }\\
    \bag{ x, y, y, z, z, z, w } \bagplus
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, x, y, y, y, z, z, z, z, z, u, v, v, w }
\endalign
$$
Também queremos um predicado de ``pertencer'' $\inbag$
e uma relação de ``submultiset'' $\subbag$ tais que:
$$
\xalignat2
x&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\subbag    \bag{ x, x, y, y, z, z }            \\
z&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\notsubbag \bag{ x, x, y, y, z }               \\
u&{}\notinbag \bag{ x, y, y, z, z, z, w }        &\bag{ x, y, z, z }&{}\subbag    \bag{ x, y, z, z }                  \\
x&{}\notinbag \emptybag \quad\text{para todo $x$}&M                 &{}\subbag    M \quad\text{para todo multiset $M$}\\
 &                                               &\emptybag         &{}\subbag    M \quad\text{para todo multiset $M$}. 
\endxalignat
$$
(MS1) Para os multisets $A$ e $B$ temos $A = B$ sse eles têm os mesmos membro
com as mesmas multiplicidades.
Por exemplo,
$$
\bag{x, y, z, z, y} = \bag{x, y, y, z, z} \neq \bag{x,y,z}.
$$
(MS2) Para cada conjunto $A$, a classe
$$
\classstt M {$M$ é multiset e $\forall x(x \inbag M \limplies x \in A)$}
$$
de todos os multisets formados por membros de $A$ é um conjunto.
\item{(i)}
Defina formalmente (em teoria de conjuntos) o termo ``multiset'' e mostre
(como exemplos) como são representados os multisets seguintes:
$$
\emptybag
\qqqquad
\bag{0, 1, 2, 2, 1}
\qqqquad
\bag{1, 2, 2, 3, 3, 3, 4, 4, 4, 4, \dotsc }.
$$
\item{(ii)}
Defina as operações de multisets ($\bagunion, \baginter, \bagplus$)
e os predicados ($\inbag$, $\subbag$).
\item{(iii)}
Demonstre pelos axiomas ZF que tua definição satisfaz as (MS1)--(MS2).

\hint
Para representar a multiplicidade, use uma funcção com codomínio o $\nats_{>0}$.

\solution
(i)
Um \dterm{multiset} é uma tupla $\cal M = \tup{ M ; f }$
onde $M$ é um conjunto e $f : M \to \nats_{>0}$.
$$
\align
\emptybag                       &= \tup{ \emptyset ; \emptyset }\\
\bag{0, 1, 2, 2, 1}             &= \tup{ \set{0,1,2} ; f }\\
\bag{1, 2, 2, 3, 3, 3, \dotsc}  &= \tup{ \nats_{>0} ; \idof {\nats_{>0}} }\\
\endalign
$$
onde $f : \set{0,1,2} \to \nats_{>0}$ é a funcção definida pela
$$
f(n) = \knuthcases {
    1,  &se $n = 0$\cr
    2,  &se $n = 1$\cr
    2,  &se $n = 2$.
}
$$
\eop
(ii)
$$
\align
\tup{A;\alpha} \bagunion \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \baginter \tup{B;\beta}&\defeq\tup{A\inter B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \bagplus  \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. (\alpha(x) + \beta(x))}\\
x \inbag \tup{A;\alpha} &\defiff x \in A\\
\tup{A;\alpha} \subbag \tup{B;\beta} &\defiff A\subset B \mland (\forall x \in A)[ \alpha(x) \leq \beta(x)]
\endalign
$$
\eop
(iii)
A (MS1) é obviamente satisfeita graças à nossa definição de múltiset como tupla
de conjunto e funcção: ganhamos assim a (MS1) pelas definições de $=$ nos três
tipos envolvidos: conjunto; tupla; funcção.
Vamos verificar a (MS2).
Seja $A$ conjunto.
O arbitrário multiset $\cal M$ com membros de $A$ tem a forma
$\cal M = \tup{X , f}$ para algum $X\subset A$ e $f : X \to\nats_{>0}$.
Então $\cal M \in \pset A \times (A \parto \nats_{>0})$ e construimos o conjunto
de todos os multisets com membros de $A$ usando o ZF4:
$$
\namedop{Multisets}(A) \defeq
    \set{
        \cal M\in \pset A \times (A \parto \nats_{>0})
        \st
        \text{$\cal M$ é um multiset}.
    }
$$
Para mostrar que o $\pset A \times (A \parto \nats\setminus\set{0})$ é um conjunto,
precisamos os operadores $\pset$, $\times$, $\parto$, $\setminus$, e o próprio $\nats$, que já temos construido pelos ZF1--ZF7.

%%}}}

%%{{{ prob: formalreals_is_a_complete_ordered_field 
\problem.
%%%{{{ meta 
\label formalreals_is_a_complete_ordered_field
\pdefs 
    \pdef R {{\cal R}}
    \pdef P {{\rm P}}
    ;;
%%%}}}

Demonstre que o $\R$ do \ref[existence_of_reals] satisfaz
mesmo as leis e corpo ordenado completo.

%%}}}

\endproblems
%%}}}

%%{{{ More_axioms 
\section Mais axiomas.
%%%{{{ meta 
\label More_axioms
%%%}}}

%%{{{ Credits 
\note Créditos.
%%%{{{ meta 
\label fol_filter_by_fraenkel_and_skolem
\credits
    * Zermelo
    * Fraenkel
    * Skolem
    ;;
%%%}}}

Todos os axiomas que temos visto até agora são essencialmente os axiomas
de Zermelo, e falta apenas um dos seus axiomas originais
(o axioma da escolha que encontramos na~\reftag[Axioms_of_choice]).
Sobre o axioma Separation~(\axref[separation]), Zermelo usou o termo
``propriedade definitiva'', que temos usado também sobre o ``filtro'',
mas foram Fraenkel e~Skolem que consideraram definir isso
como uma fórmula da linguagem da FOL com $=$ e $\in$.

%%}}}

%%{{{ A letter from Fraenkel to Zermelo 
\note Uma carta de Fraenkel para Zermelo.
%%%{{{ meta 
%%%}}}

{\Fraenkel}Fraenkel percebeu (e comunicou no \yearof{1921} para Zermelo) que
com os seus axiomas não é possível demonstrar a existência duns certos
conjuntos interessantes, como por exemplo o
$$
\bigset{
\Nats, \pset\Nats, \pset\pset\Nats, \pset\pset\pset\Nats, \dotsc
}.
$$
Sim, podemos construir cada um dos seus elementos, mas não a
colecção deles como conjunto!

%%}}}

%%{{{ ax: replacement 
\axiom Replacement (schema).
%%%{{{ meta 
\label replacement
\defines
    * axioma!Replacement (schema)
    ;;
%%%}}}

{\rm Para cada funcção-classe $\Phi(\dhole)$, o seguinte:}
Para todo conjunto $a$, a classe
$
\classimg \Phi a \defeq \classst {\Phi(x)} {x \in a}
$
é um conjunto.
$$
\forall a
\exists b
\forall y
\bigparen{
    y \in b
    \liff
    \lexists {x \in a} {\Phi(x) = y}
}
\axtag[replacement=ZF8]
$$

%%}}}

%%{{{ x: powersingleton_without_powerset 
\exercise.
%%%{{{ meta 
\label powersingleton_without_powerset
%%%}}}

Resolve o~\ref[powersingleton] sem usar o~Powerset~(\axref[powerset]).

\hint
Qual operador $\Phi(\dhole)$ tu podes definir para aplicá-lo no $a$?

\solution
Definimos o operador $\Phi(\dhole)$ assim:
$$
\Phi(x) \defeq \set x.
$$
Facilmente, pelo Replacement~(\axref[replacement]) aplicado no $a$ com
esse $\Phi$ temos que
$\classimg \Phi a$
é um conjunto: o conjunto que procuramos!

%%}}}

%%{{{ A mortal game 
\note Um jogo mortal.
%%%{{{ meta 
%%%}}}

Teu oponente escolha um conjunto (e ele não participa mais no jogo):
esse é o ``conjunto da mesa''.
Em cada rodada do jogo tu tem que escolher um dos membros do conjunto da mesa,
e ele se vira o novo conjunto da mesa.
O objectivo é simples: \emph{continuar jogando pra sempre}.
(Imagine que se o jogo acabar, tu morre---e que tu queres viver---ou algo desse tipo.)
Então uma partida onde o oponente escolheu o conjunto
$$
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}},
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}}}}
$$
seria a seguinte
(sublinhamos as escolhas do jogador onde possível):
$$
\matrix
\format
\c\quad & \c\quad & \c \\
\text{Rodada} & \text{Conjunto} & \text{Movimento}\\
1 & \bigset{ \emptyset, \ \fsset{\emptyset}, \ \underline{\fsset{\emptyset, \fsset{\emptyset}}}, \ \fsset{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}} } } & \fsset{\emptyset, \fsset{\emptyset}}\\
2 & \bigset{\emptyset, \underline{\fsset{\emptyset}}} & \fsset{\emptyset} \\
3 & \bigset{\underline{\emptyset}} & \emptyset\\
4 & \emptyset & \boohoo
\endmatrix
$$
Talvez esse jogador não foi o mais esperto, mas facilmente confirmamos
que qualquer possível estratégia dele é condenada com morte certa depois
dum finito número de rodadas.
\emph{E se o próprio jogador começa escolhendo qual é o conjunto da mesa inicial?}
Qual conjunto tu escolheria?
Pode \emph{imaginar} algum conjunto que seria uma boa opção que porderia garantir
vitória?

%%}}}

\spoiler

%%{{{ x: how_to_win_the_wf_game 
\exercise.
%%%{{{ meta 
\label how_to_win_the_wf_game
%%%}}}

Considere os conjuntos da mesa seguintes:
\tlist:
\li: o conjunto $x$, onde
$$
x = \bigset{ \emptyset, \ \Nats, \ \set{ \emptyset, \set{\set{\emptyset}}}, \ x };
$$
\li: o conjunto $a$, onde
$$
\xalignat3
a &= \bigset{ \emptyset, \ b } &
b &= \bigset{ \set{\emptyset}, \ c } &
c &= \bigset{ \set{\emptyset}, \ \set{ \set{a}, \set{\set{\set{\emptyset}}}}};
\endxalignat
$$
\li: o conjunto $\Omega$, onde
$$
\Omega = \bigset{ \Omega }.
$$
\endtlist
Como tu jogaria nesses jogos?

%%}}}

%%{{{ Can we win? 
\note Podemos ganhar?.
%%%{{{ meta 
%%%}}}

Talvez.  Nossos axiomas não garantam a existência de nenhum conjunto
que nos permitaria ganhar; no outro lado, nem garantam a ausência de
conjuntos como os $x,a,b,c,\Omega$ do~\ref[how_to_win_the_wf_game].
O axioma seguinte resolve essa questão, afirmando que qualquer partida
desse jogo seria realmente mortal.

%%}}}

%%{{{ ax: foundation 
\axiom Foundation.
%%%{{{ meta 
\label foundation
\defines
    * axioma!Foundation
    ;;
%%%}}}

Todo conjunto não vazio tem membro disjunto com ele mesmo.
$$
\pforall {a\neq\emptyset}
\lexists {z \in a} {z\inter a = \emptyset}
\axtag[foundation=ZF9]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos agora pesquisar umas conseqüências desse axioma, também conhecido como
\dterm{Regularity}    * axioma!Regularity    see: Foundation.

%%}}}

%%{{{ x: x_notin_x 
\exercise.
%%%{{{ meta 
\label x_notin_x
%%%}}}

Demonstre diretamente que para todo conjunto $x$, $x\notin x$.
Quais axiomas tu precisou?

\hint
Seja $x$ conjunto.
Não podemos aplicar o~\reftag[foundation] diretamente no $x$,
pois talvez $x = \emptyset$.
Uma abordagem seria separar casos.
Ao inves disso, aplique o~\reftag[foundation] no conjunto $\set x$.

%%}}}

%%{{{ cor: univ_not_in_univ 
\corollary.
%%%{{{ meta 
\label unit_not_in_univ
%%%}}}

$\Univ\notin\Univ$, ou seja, $\Univ$ não é um conjunto.

%%}}}

%%{{{ x: x_y_cannot_belong_to_each_other 
\exercise.
%%%{{{ meta 
\label x_y_cannot_belong_to_each_other
%%%}}}

Demonstre que é impossível para dois conjuntos $x,y$ ter
$x \in y$ e também $y \in x$.

%%}}}

%%{{{ x: no_infinite_in_descending_chain_of_sets 
\exercise.
%%%{{{ meta 
\label no_infinite_in_descending_chain_of_sets
%%%}}}

Demonstre que não existe seqüência infinita de conjuntos
$$
x_0 \ni x_1 \ni x_2 \ni x_3 \ni \dotsb
$$
e mostre que assim ganhamos os
exercícios~\reftag[x_notin_x]~\&~\reftag[x_y_cannot_belong_to_each_other]
como corolários.

%%}}}

%%{{{ x: spooky_pair_becomes_good_pair 
\exercise Spooky pair agora.
%%%{{{ meta 
\label spooky_pair_becomes_good_pair
%%%}}}

Demonstre que com o axioma Foundation podemos sim usar a operação
do~\ref[spooky_pair]
$$
\tup{x,y} \defeq \bigset{ x, \set{x, y} }
$$
como uma implementação de par ordenado.

%%}}}

\endsection
%%}}}

%%{{{ Axioms_of_choice 
\section Axiomas de escolha.
%%%{{{ meta 
\label Axioms_of_choice
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Finalmente encontramos aqui o último axioma de Zermelo,
o mais infame, seu \emph{axioma de escolha}.
Mas, primeiramente, umas definições.

%%}}}

%%{{{ df: choice_set 
\definition Conjunto-escolha.
%%%{{{ meta 
\label choice_set
\defines
    * conjunto-escolha
    ;;
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos o $E$ um \dterm{conjunto-escolha} da $\scr A$ sse
(1) $E \subset \union \scr A$, e
(2) para todo $A \in \scr A$, a intersecção $E \inter A$ é um singleton.

%%}}}

%%{{{ eg: choice_sets 
\example.
%%%{{{ meta 
\label choice_sets
%%%}}}

Aqui umas famílias de conjuntos e um exemplo de conjunto-escolha para cada uma:
$$
\xalignat2
\scr A_1 &= \set{ [0,2], [1,4], [3,5] }
&&{\set{ 0, \,5/2, \,5 }}\\
\scr A_2 &= \set{ \set{a,b}, \set{b,c}, \set{d} }
&&{\set{a,c,d}}\\
\scr A_3 &= \set{ \set{a,b}, \set{b,c}, \set{c,a} }
&&\text{não tem conjunto-escolha}\\
\scr A_4 &= \set{ \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\text{não tem conjunto-escolha}\\
\scr A_5 &= \set{            \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\scr A_4\\
\scr A_6 &= \set{ \finord 1, \finord 2, \finord 3, \dotsc }
&&\text{não tem conjunto-escolha}
\endxalignat
$$

%%}}}

%%{{{ df: choice_function 
\definition Funcção-escolha.
%%%{{{ meta 
\label choice_function
\defines
    * funcção-escolha!de conjunto
    * funcção-escolha!de família
    ;;
%%%}}}

Seja $A$ conjunto.
Chamamos a $\epsilon : \pset A \setminus \set{\emptyset} \to A$
uma \dterm{funcção-escolha do conjunto} $A$ sse $\epsilon(X) \in X$ para todo $X\in\dom\epsilon$.
\eop
Seja $\scr A$ família de conjuntos.
Chamamos a $\epsilon : \scr A \to \Union \scr A$ uma
\dterm{funcção-escolha da família de conjuntos} $\scr A$ sse
$\epsilon(A) \in A$ para todo $A\in \scr A$.

%%}}}

%%{{{ ax: choice_ac 
\axiom Choice (AC).
%%%{{{ meta 
\label choice_ac
\defines
    * axioma!Choice (AC)
    ;;
%%%}}}

Seja $\scr A$ família de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr A \to \Union \scr A$,
tal que
}\\
\text{
para todo $A\in\scr A$,
$\epsilon(A) \in A$.
}
\endgathered
\axtag[ac=AC]
$$

%%}}}

%%{{{ ax: choice_ac_disjoint 
\axiom Choice (forma disjunta).
%%%{{{ meta 
\label choice_ac_disjoint
%%%}}}

Seja $\scr D$ família disjunta de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr D \to \Union \scr D$,
tal que
}\\
\text{
para todo $D\in\scr D$,
$\epsilon(D) \in D$.
}
\endgathered
\axtag[acdisj=ACdis]
$$

%%}}}

%%{{{ ax: choice_ac_pset 
\axiom Choice (forma powerset).
%%%{{{ meta 
\label choice_ac_powerset
%%%}}}

Seja $M$ conjunto não vazio.
Então
$$
\gathered
\text{
existe
$\epsilon : \pset M\setminus\set{\emptyset} \to M$,
tal que
}\\
\text{
para todo
$\emptyset\neq A\subset M$,
$\epsilon(A) \in A$.
}
\endgathered
\axtag[acpset=ACpow]
$$

%%}}}

%%{{{ x: first_ac_equivalences 
\exercise.
%%%{{{ meta 
\label first_ac_equivalences
%%%}}}

Todas as ``formas'' do axioma de escolha (AC) que vimos até agora
são logicamente equivalentes.
Demonstre isso seguindo o ``round-robin'' seguinte:
$$
\text{\axref[ac]}
\implies \text{\axref[acdisj]}
\implies \text{\axref[acpset]}
\implies \text{\axref[ac]}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Depois vamos encontrar mais teoremas (assumindo o \axref[ac]),
que na verdade são equivalentes com ele.

%%}}}

\endsection
%%}}}

%%{{{ Desired and controversial consequences 
\section Conseqüências desejáveis e controversiais.
%%%{{{ meta 
%%%}}}

%%{{{ thm: banach_tarski 
\theorem Banach--Tarski.
%%%{{{ meta 
\label banach_tarski
\indexes
    * paradoxo!Banach--Tarski
    ;;
%%%}}}

{\Banach}{\Tarski}%
Podemos decompor a bola sólida unária
$$
B = \setst {\tup{x,y,z} \in \reals^3} {x^2 + y^2 + z^2 \leq 1}
$$
em $5$ subconjuntos
$\sym 1, \sym 2, \sym 3, \sym 4, \sym 5 \subset S$,
rodar e transladar eles, criando duas cópias sólidas de $B$.

%%}}}

%%{{{ thm: wellordering_thm 
\theorem Bem-ordenação (Zermelo).
%%%{{{ meta 
\label wellordering_thm
\indexes
    * teorema!da bem-ordenação
    ;;
%%%}}}

Todo conjunto $A$ pode ser bem ordenado.

%%}}}

%%{{{ thm: cardinal_comparability_thm 
\theorem Comparabilidade de cardinais.
%%%{{{ meta 
\label cardinal_comparability_thm
%%%}}}

Para todos conjuntos $A,B$, temos $A\leqc B$ ou $B \leqc A$.

%%}}}

\endsection
%%}}}

%%{{{ Weaker choices 
\section Escolhas mais fracas.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Other axiomatizations 
\section Outras axiomatizações.
%%%{{{ meta 
%%%}}}

\TODO elaborate.

%%{{{ montague_theorem 
\note.
%%%{{{ meta 
\label montague_theorem
%%%}}}

Observamos desde o~\ref[axioms_vs_axiomatic_schemata]
que a teoria ZFC tem uma infinidade de axiomas.
Faz sentido se perguntar se alguém poderia achar
outra maneira de axiomatizar a mesma teoria usando
apenas uma quantidade finita de axiomas.
Não é o caso: {\Montague[teorema]}Montague demonstrou
na sua tese~\cite[montaguephd] que isso é impossível.

%%}}}

\endsection
%%}}}

%%{{{ A different point of view 
\section Um outro ponto de vista.
%%%{{{ meta 
%%%}}}

\TODO Skolem's paradox.

\endsection
%%}}}

%%{{{ Other set theories 
\section Outras teorias de conjuntos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Other foundations 
\section Outras fundações.
%%%{{{ meta 
%%%}}}

\TODO ETCS, MLTT, HoTT.

\TODO connection with unityped \vs statically typed languages.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ three_classes_are_sets_problem 
\problem.
%%%{{{ meta 
\label three_classes_are_sets_problem
%%%}}}

Seja $a$ conjunto.
\emph{Sem usar} o Separation~(\axref[separation]),
mostre pelo resto dos axiomas que as classes seguintes são conjuntos:
$$
\xalignat3
    E &= \setlst {\set{x, \Union x,\pset x}} {x\in a} ;&
    F &= \setlst x {x\subsetneq a}                    ;&
    G &= \setst  x {x\neq\emptyset \land x = \Inter x}.
\endxalignat
$$

%%}}}

%%{{{ replacement_replaces_separation 
\problem Replacement is the new Separation---or is it?.
%%%{{{ meta 
\label replacement_replaces_separation
%%%}}}

Podemos tirar o Separation scheme~(\axref[separation])
dos nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~(\axref[replacement]) no lugar dele?

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto $A$, vai ``identificar'' todos
aqueles que \emph{não} tem a propriedade $\phi(\dhole)$,
mas mesmo assim sendo injetora quando restrita naqueles
que satisfazem a.

\hint
Além de tudo isso, os ``originais'' $a\in A$ tem que ser
recuperáveis pelas suas imagens atraves da $\Phi$.

\solution
Seja $A$ conjunto e $\phi(x)$ fórmula.
Definimos a class-function
$$
\Phi(x) =
\knuthcases {
    \set {x},   &se $\phi(x)$\cr
    \emptyset,  &se não.
}
$$
Agora aplicamos o Replacement com essa class-function no conjunto $A$,
ganhando assim como conjunto o $\classimg\Phi A$, cujos elementos são exatamente os
\emph{singletons} $\set{a}$ de todos os $a\in A$ que satisfazem a $\phi(a)$,
e o $\emptyset$.
Usando o ZF6 chegamos no $\Union \classimg\Phi A$ que realmente é o desejado
conjunto
$\setst {a \in A} {\phi(a)}$.

%%}}}

%%{{{ replacement_replaces_pairset 
\problem Replacement is the new Pairset---or is it?.
%%%{{{ meta 
\label replacement_replaces_pairset
%%%}}}

Podemos tirar o Pairset~(\axref[pairset]) dos
nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~(\axref[replacement]) no lugar dele?

\hint
Podemos sim.
Dados \emph{objetos} $a,b$, mostre que existe o conjunto
$\set{a,b}$ que consiste em exatamente esses objetos.

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto suficientemente grande,
vai ter como imagem o desejado $\set{a,b}$.

\solution
Sejam $a,b$ objetos.
Considere a class-function
$$
\Phi (x) \asseq 
\knuthcases {
    a, &se $x=\emptyset$\cr
    b, &se $x\neq\emptyset$.
}
$$
Agora precisamos apenas construir um conjunto $S$ tal que:
$\emptyset \in S$, e $|S| \geq 2$.
Pelo Emptyset, temos o $\emptyset$.
Pelo Powerset aplicado no $\emptyset$ ganhamos o $\set{\emptyset}$, e aplicando mais uma vez o Powerset chegamos no $\set{\emptyset, \set{\emptyset}}$.
Usando o Replacement com a $\Phi(x)$ nesse conjunto, construimos o desejado $\set{a,b}$.
\eop
Em forma de árvore:
$$
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset}$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{Repl; $\Phi$}
\UnaryInfC{$\set{a, b}$}
\DisplayProof
$$

%%}}}

%%{{{ find_the_crime_of_foundation 
\problem.
%%%{{{ meta 
\label find_the_crime_of_foundation
%%%}}}

Na resolução do~\ref[bad_pair], tem um roubo.
Ache e explique.

%%}}}

%%{{{ spooky_pair_problem 
\problem.
%%%{{{ meta 
\label spooky_pair_problem
%%%}}}

No~\ref[spooky_pair] provaste que a operação binária definida pela
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
satisfaz a propriedade~\mref[spec_tup2].
Depois, no~\ref[spooky_pair_becomes_good_pair], usando o \axref[foundation]
conseguimos demonstrar que satisfaz a propriedade~\mref[spec_tup1] também.
Mostre que o~\axref[foundation] é necessário para conseguir isso,
mostrando um contraexemplo: conjuntos $a,b,a',b'$ tais que
$$
\tup{a,b} = \tup{a',b'}
$$
mas mesmo assim pelo menos uma das $a = a'$ e $b = b'$ não é válida.

\hint
Obviamente, teu contraexemplo tem que envolver conjuntos mal-funda\-men\-ta\-dos.

\hint
Considere conjuntos $x,y,o$ com a propriedade
$$
x = \set { o, \set{x,y} }
$$
onde $o \neq y$.

\hint
Calcule o
$$
\tup{ \set{x,y}, o }
$$
e ache que ele é igual com um par ordenado diferente.
(Tem que demonstrar que é difernete mesmo!)

\solution
Considere um $x$ mal-fundamentado, que satisfaz a
$$
x = \set { o, \set{x,y} }
$$
para alguns $y,o$ onde $o \neq y$.
Calculamos o
$$
\align
\tup{ \set{x,y}, o }
&= \set{ \set{x,y}, \set{ \set{x,y}, o } } \\
&= \set{ \set{x,y}, x } \\
&= \tup{ x , y }
\endalign
$$
mesmo com $o \neq y$, ou seja, achamos um contraexemplo mesmo.

%%}}}

%%{{{ choice_rel_problem 
\problem.
%%%{{{ meta 
\label choice_rel_problem
%%%}}}

Mostre que o Choice~\axref[ac] é equivalente com o seguinte axioma:
\eop
\noi
{\bf Choice (Rel).}
{\proclaimstyle
Se uma relação $R \in \relspace{A,B}$ tem a propriedade de totalidade,
então existe funcção $f : A\to B$ com $x \rel R f(x)$ para todo $x\in A$.
}
$$
\bigparen{
R \in \relspace{A,B}
\land
\dom R = A
}
\limplies
\bigparen{
\pexists {f : A \to B}
\lforall {x\in A} {x \mathrel R f(x)}
}
\axtag[acrel=ACrel]
$$

%%}}}

%%{{{ prob: reals_as_cauchy_seqs 
\problem Reais como seqüências Cauchy.
%%%{{{ meta 
\label reals_as_cauchy_seqs
%%%}}}

\TODO Enunciar o problema.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[fromfregetogodel],
\cite[halmosnaive],
\cite[ynmnst],
\cite[kunenfoundations].
\cite[kunen2011],
\cite[cohensetch],
\cite[kunen1980],
\cite[krivineast],
\cite[jechset].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Posets_Lattices 
\chapter Posets; Reticulados.
%%%{{{ meta 
\label Posets_Lattices
%%%}}}

%%{{{ Concept, notation, properties 
\section Conceito, notação, propriedades.
%%%{{{ meta 
%%%}}}

\TODO Conceito.

%%{{{ df: poset 
\definition poset.
%%%{{{ meta 
\label poset
\defines
    * poset
    ;;
%%%}}}

Chamamos o conjunto estruturado $\cal P = \sset P \leq$
um \dterm{poset} (ou conjunto parcialmente ordenado),
sse $\leq$ é uma relação de ordem parcial:
$$
\gather
x \leq x\\
x \leq y \mland y \leq z \implies x \leq z\\
x \leq y \mland y \leq x \implies x = y
\endgather
$$

%%}}}

%%{{{ Notational abuse 
\note Abusos notacionais.
%%%{{{ meta 
%%%}}}

Extendemos o ``tipo'' do predicado $\dhole\leq\dhole$ de elementos de $P$
para elementos e/ou subconjuntos de $P$, definindo:
$$
\align
a \leq Y &\defiff a \leq y, \quad\text{para todo $y\in Y$};\\
X \leq b &\defiff x \leq b, \quad\text{para todo $x\in X$};\\
X \leq Y &\defiff x \leq y, \quad\text{para todo $x\in X$ e $y\in Y$}.
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nas definições seguintes nosso contexto é um poset $\sset P \leq$.

%%}}}

%%{{{ df: incomparable 
\definition.
%%%{{{ meta 
\label incomparable
\defines
    * incomparável
    ;;
%%%}}}

Se $x \nleq y$ e $y \nleq x$ chamamos $x$ e $y$ \dterm{incomparáveis}.
Denotamos assim:
$$
x \incomp y \defiff x \nleq y \mland y \nleq x.
$$

%%}}}

%%{{{ df: chain_antichain 
\definition.
%%%{{{ meta 
\label chain_antichain
\defines
    * anticadeia
    * cadeia
    ;;
%%%}}}

Seja $X\subset P$.
Chamamos o $X$ uma \dterm{cadeia} sse todos os seus elementos são comparáveis.
No caso oposto, onde todos são comparáveis apenas com eles mesmo,
chamamos o $X$ \dterm{anticadeia}.  Simbolicamente:
$$
\align
\text{cadeia:}\quad&       x, y \in X  \implies  x \leq y \mlor y\leq x;\\
\text{anticadeia:}\quad&   x, y \in X  \mland x \leq y \implies x = y.
\endalign
$$

%%}}}

%%{{{ df: covby 
\definition.
%%%{{{ meta 
\label covby
\defines
    * ~x \covby ~y  -- o $x$ é coberto por o $y$
    * cobertura
    ;;
%%%}}}

Se $x\leq y$ e não existe nenhum $z$ estritamente entre os $x$ e $y$
falamos que $y$ \dterm{cobre} o $x$.  Simbolicamente:
$$
x\covby y \defiff x \leq y \mland \lnot\exists z (x < z < y).
$$

%%}}}

%%{{{ Diagramas Hasse 
\note Diagramas Hasse.
%%%{{{ meta 
\defines
    * Hasse!diagrama
    ;;
%%%}}}

Já encontramos diagramas {\Hasse}Hasse no \ref[Group_theory]
(\reftag[hasse_diagrams_first_encounter],
\reftag[hasse_dih_3], \reftag[hasse_dih_4])
onde desenhamos os Hasse duns posets de subgrupos.

%%}}}

%%{{{ beware 
\beware.
%%%{{{ meta 
%%%}}}

Diagramas Hasse podem aparecer bastante diferentes mesmo
sendo do mesmo poset.

%%}}}

%%{{{ eg: cube_and_not_so_cube 
\example.
%%%{{{ meta 
\label cube_and_not_so_cube
\defines
    * reticulado!cubo
    ;;
%%%}}}

Aqui duas formas de desenhar diagramas Hasse para o
$\sset{\pset\set{0,1,2}}{\subset}$:
$$
\xalignat2
&\tikzpicture
\node (max) at (0,4)  {$\set{0,1,2}$};
\node (a)   at (-2,2) {$\set{0,1}$};
\node (b)   at (0,2)  {$\set{0,2}$};
\node (c)   at (2,2)  {$\set{1,2}$};
\node (d)   at (-2,0) {$\set 0$};
\node (e)   at (0,0)  {$\set 1$};
\node (f)   at (2,0)  {$\set 2$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
&
&\tikzpicture
\node (max) at (0,4)       {$\set{0,1,2}$};
\node (a)   at (-2,2.666)  {$\set{1,2}$};
\node (b)   at (0,2.666)   {$\set{0,2}$};
\node (c)   at (2,2.666)   {$\set{0,1}$};
\node (d)   at (-2,-0.666) {$\set 0$};
\node (e)   at (0,-0.666)  {$\set 1$};
\node (f)   at (2,-0.666)  {$\set 2$};
\node (min) at (0,-2)      {$\emptyset$};
\draw (min) -- (d) -- (c) -- (max) -- (a) -- (f) -- (min);
\draw (min) -- (e);
\draw (max) -- (b);
\draw (a) -- (e) -- (c);
\draw (d) -- (b) -- (f);
\endtikzpicture
\endxalignat
$$
Esse poset é chamado \dterm{cubo} por motivos óbvios se olhar
na seu primeiro diagrama, e não-tão-óbvios olhando para o segundo!

%%}}}

%%{{{ df: min_max 
\definition.
%%%{{{ meta 
\label min_max
\defines
    * \max {~A}  -- o máximo de $A$
    * \min {~A}  -- o mínimo de $A$
    * máximo
    * mínimo
    ;;
%%%}}}

Seja $A\subset P$.
Chamamos o $m$ o \dterm{mínimo} de $A$ sse $m\leq a$ para todo $a\in A$.
\emph{Dualmente} chamamos o $m\in A$ o \dterm{máximo} de $A$ sse $a\leq m$ para todo $a\in A$.
Denotamos o mínimo de $A$, se existe, por $\min A$ e seu máximo, se existe, por $\max A$.
\mistake

%%}}}

%%{{{ x: uniqueness_of_min_max 
\exercise.
%%%{{{ meta 
\label uniqueness_of_min_max
%%%}}}

Qual o erro na definição acima?
O ache e o corrija.

%%}}}

%%{{{ x: finite_losets_are_wosets 
\exercise.
%%%{{{ meta 
\label finite_losets_are_wosets 
%%%}}}

Demonstre que qualquer conjunto finito, não vazio, e linearmente ordenado é
bem ordenado.

\hint
Praticamente já resolvido no \ref[finite_numbersets_have_min].
Por quê?  (O que falta observar ou verificar?)

\solution
Já resolvido no \ref[finite_numbersets_have_min], pois na sua resolução
não usamos nenhuma propriedade de números: todo que precisamos foi
que $\leq$ é totalmente ordenado pela $\leq$.
Assim temos que todo conjunto finito, não vazio, e linearmente ordenado
possui mínimo.  Para concluir que é bem ordenado basta observar
que qualquer subconjunto dum conjunto finito, é finito.

%%}}}

%%{{{ df: poset_terminology
\definition.
%%%{{{ meta 
\label poset_terminology
\defines
    * 0_{~P}  -- o zero (o mínimo elemento dum poset)
    * 1_{~P}  -- o um (o máximo elemento dum poset)
    * \bot_{~P}  -- o bottom (o mínimo elemento dum poset)
    * \top_{~P}  -- o top (o máximo elemento dum poset)
    * bottom
    * bounded!por baixo
    * bounded!por cima
    * one!dum poset
    * top
    * zero!dum poset
    ;;
%%%}}}

Se o próprio $P\subset P$ possui elemento
mínimo, o chamamos de \dterm{bottom} de $P$,
e se possui
máximo, o chamamos de \dterm{top} de $P$.
Usamos as notações $\bot_P$ e $\top_P$ respectivamente,
esquecendo o $_P$ quando é implícito pelo contexto.
Sinônimos de bottom e top são os \dterm{zero} e \dterm{um} respectivamente,
usando as notações $0_P$ e $1_P$.
Se um poset possui bottom, ele é chamado \dterm{bounded por baixo},
e se ele possui top, ele é chamado \dterm{bounded por cima}.
Caso que seja bounded por cima e por baixo, o chamamos apenas de
\dterm{bounded}.

%%}}}

%%{{{ df: minimal_maximal 
\definition.
%%%{{{ meta 
\label minimal_maximal
\defines
    * maximal
    * minimal
    ;;
%%%}}}

Chamamos o $x$ um elemento \dterm{minimal} de $P$
sse nenhum elemento está embaixo dele, e, \emph{dualmente}
chamamos o $x$ \dterm{maximal} de $P$ sse nenhum elemento
está acima dele.  Simbolicamente:
$$
\align
\text{$x$ minimal de $P$}&\defiff  \lforall {y \in P} {y \leq x \implies x = y};\\
\text{$x$ maximal de $P$}&\defiff  \lforall {y \in P} {x \leq y \implies x = y}.
\endalign
$$

%%}}}

%%{{{ df: ubs_lbs 
\definition.
%%%{{{ meta 
\label ubs_lbs
\defines
    * \lbs {~A}  -- o conjunto dos lower bounds de $A$
    * \ubs {~A}  -- o conjunto dos upper bounds de $A$
    * lower bound
    * upper bound
    ;;
%%%}}}

Sejam $A\subset P$ e $m\in P$.
O $m$ é um \dterm{upper bound} de $A$ sse $x \leq m$ para todo $x\in A$.
Dualmente, o $m$ é um \dterm{lower bound} de $A$ sse $m \leq x$ para todo $x \in A$.
Usamos a notação
$$
\align
\ubs A &\defeq \setstt {m\in P} {$m$ é um upper bound de $A$}\\
\lbs A &\defeq \setstt {m\in P} {$m$ é um lower bound de $A$}.
\endalign
$$

%%}}}

%%{{{ eg: ubs_lbs_in_reals_example 
\example.
%%%{{{ meta 
\label ubs_lbs_in_reals_example
%%%}}}

No $\reals$, considere seu subconjunto $(1,2]$.
Uns upper bounds dele são os reais $2, 5, \sqrt{12}, 8000$.
No outro ladom uns lower bounds dele são os $-400, -\pi, 0, 1/2, 0.8, 1$.

%%}}}

%%{{{ df: lub_glb 
\definition.
%%%{{{ meta 
\label lub_glb
\defines
    * \Join{~A}  -- o join de $A$
    * \Meet{~A}  -- o meet de $A$
    * \glb{~A}  -- o greatest lower bound de $A$
    * \inf{~A}  -- o infimum de $A$
    * \lub{~A}  -- o least upper bound de $A$
    * \sup{~A}  -- o supremum de $A$
    * greatest lower bound
    * infimum
    * least upper bound
    * supremum
    ;;
%%%}}}

Se os $\ubs A$ e $\lbs A$ tem elemento mínimo e máximo respectivamente,
definimos
$$
\align
\lub A &\defeq \min\ubs A\\
\glb A &\defeq \max\lbs A.
\endalign
$$
Naturalmente chamamos o $\lub A$ o \dterm{least upper bound} de $A$,
e o $\glb A$ o \dterm{greatest lower bound} de $A$.
Usamos \emph{muitos} sinônimos, resumidos aqui:
$$
\xalignat3
\sup A &\ \text{(supremum)}   & \lub A &\ \text{(least upper bound)}    & \Join A &\ \text{(join)}\\
\inf A &\ \text{(infimum)}    & \glb A &\ \text{(greatest lower bound)} & \Meet A &\ \text{(meet)}
\endxalignat
$$

%%}}}

%%{{{ eg: inf_and_sup_of_openclosed_interval 
\example.
%%%{{{ meta 
\label inf_and_sup_of_openclosed_interval
%%%}}}

O $A=(1,2]$ do~\ref[ubs_lbs_in_reals_example] tem
$\inf A = 1$ e $\sup A = 2$.
Observe que $\sup A \in A$ mas $\inf A \notin A$.

%%}}}

%%{{{ x: when_glb_and_lub_is_min_and_max 
\exercise.
%%%{{{ meta 
\label when_glb_and_lub_is_min_and_max
%%%}}}

O que podemos concluir quando $\glb A \in A$ e quando $\lub A \in A$?

%%}}}

%%{{{ df: downset_upset_downs  
\definition.
%%%{{{ meta 
\label downset_upset_downs
\defines
    * \downs{~P}  -- o conjunto de downsets de $P$
    * downset
    * upset
    ;;
%%%}}}

Chamamos o $A\subset P$ um \dterm{downset} no $P$
sse o $A$ é ``fechado para baixo'', e \emph{dualmente},
o chamamos \dterm{upset} sse ele é ``fechado para cima''.
Formalmente,
$$
\align
\text{$A$ downset} &\defiff {a \in A \mland x \leq a \implies x\in A};\\
\text{$A$ upset}   &\defiff {a \in A \mland a \leq x \implies x\in A}.
\endalign
$$
Dado um poset $P$, usamos $\downs P$ para denotar o conjunto de todos os seus
downsets.  Simbolicamente,
$$
\downs P \defeq \setstt {D \subset P} {$D$ é um downset de $P$}.
$$

%%}}}

%%{{{ df: down_up 
\definition.
%%%{{{ meta 
\label down_up
\defines
    * \down {~a}  -- o down de $a$
    * \up {~a}  -- o up de $a$
    ;;
%%%}}}

Definimos para qualquer $a\in P$ os conjuntos
$$
\align
\down a &\defeq \setst {x \in P} {x \leq a}\\
\up a   &\defeq \setst {x \in P} {a \leq x}
\intertext{e generalizamos essas operações de elementos $a\in P$ para subconjuntos $A\subset P$ assim:}
\down A &\defeq \setstt {x \in P} {$x \leq a$ para algum $a \in A$}\\
\up A   &\defeq \setstt {x \in P} {$a \leq x$ para algum $a \in A$}.
\endalign
$$
Observe que $\down x = \down{\set x}$ e $\up x = \up{\set x}$.
Diretamente pelas definições também temos:
$$
\xalignat2
\down A &= \Union_{a\in A} {\down a}&
\up A &= \Union_{a\in A} {\up a}
\endxalignat
$$

%%}}}

%%{{{ x: down_is_downset_up_is_upset 
\exercise.
%%%{{{ meta 
\label down_is_downset_up_is_upset
%%%}}}

Sejam $P$ poset e $A \in P$.
Demonstre que $\down A$ é um downset e $\up A$ um upset.

%%}}}

%%{{{ x: equivalent_statements_to_x_leq_y 
\exercise.
%%%{{{ meta 
\label equivalent_statements_to_x_leq_y
%%%}}}

Sejam $P$ um poset, $x,y\in P$.
Demonstre que as afirmações
\tlist:
\li (i):   $x \leq y$;
\li (ii):  $\down x \subset \down y$;
\li (iii): para todo downset $D$ de $P$ com $y \in D$, temos $x\in D$;
\endtlist
são equivalentes.

\solution
Vamos demonstrar usando um caminho ``round-robin'':
\crtabproofpart{\rm (i)\timplies(ii).}
Seja $a \in \down x$.  Logo $a \leq x$, e como $x\leq y$ (hipótese),
pela transitividade da $\leq$ temos $a \leq y$.  Logo $a\in \down y$.
Ou seja, $\down x \subset \down y$.
\crtabproofpart{\rm (ii)\timplies(iii).}
Seja $D$ downset de $P$ com $y \in D$.
Logo $\down y \subset D$.
Pela hipótese $\down x \subset \down y$ e logo $\down x \subset D$.
Como $x \in \down x$, então $x \in D$.
\crtabproofpart{\rm (iii)\timplies(i).}
Observe que $\down y$ é um downset tal que $y$ pertence nele.
Logo $x \in \down y$ (pela hipótese).
Logo $x \leq y$ (pela def.~de $\down y$).

%%}}}

\endsection
%%}}}

%%{{{ Posets for free: operations and constructions 
\section Posets de graça: operações e construções.
%%%{{{ meta 
%%%}}}

\TODO elaborar.

%{{{ df: discrete_poset 
\definition discreto.
%%%{{{ meta 
\label discrete_poset
\defines
    * poset!discreto
    ;;
%%%}}}

Qualquer conjunto $X$ equipado com a igualdade vira
um poset, que chamamos de \dterm{discreto}.

%%}}}

%%{{{ df: dual_poset 
\definition dual.
%%%{{{ meta 
\defines
    * \dualposet{~P}  -- o poset dual de $P$
    * poset!dual
    ;;
%%%}}}

Dado qualquer poset $\sset P {\leq_P}$ definimos o seu
poset \dterm{dual} que denotamos por $\dualposet P$
apenas virando o $P$ ``de cabeça pra baixo'';
ou seja, usando como ordem do $\dualposet P$ a $\geq_P$:
$$
x \leq_{\dualposet P} y \defiff y \leq_P x.
$$

%%}}}

%%{{{ df: 
\definition números.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: lift_poset 
\definition lift.
%%%{{{ meta 
\label lift_poset
\defines
    * \lift {~P}  -- o lifting do poset $P$
    * poset!lift
    ;;
%%%}}}

Para qualquer poset $P$ definimos seu \dterm{lifting} $\lift P$
botando um novo membro abaixo do $P$.

%%}}}

%%{{{ x: lift_poset_formal_def 
\exercise.
%%%{{{ meta 
\label lift_poset_formal_def
%%%}}}

Formalize a \ref[lift_poset].

%%}}}

%%{{{ df: flat_poset 
\definition flat.
%%%{{{ meta 
\label flat_poset
%%%}}}

Um poset $P$ é chamado \dterm{flat} sse possui mínimo $\bot$ e
$$
x \leq y \iff x = \bot \mlor x = y.
$$

%%}}}

%%{{{ pseudodf: poset_sum_pseudodef 
\pseudodefinition soma.
%%%{{{ meta 
\label poset_sum_pseudodef
\indexes
    * soma!de poset    see: poset
    ;;
\defines
    * ~P \posetplus ~Q  -- a soma do poset $P$ com o poset $Q$
    * poset!soma
    ;;
%%%}}}

Dados posets disjunos $P,Q$ definimos sua \dterm{soma}
$P \posetplus Q$ para ser o poset botando cada
membro de $Q$ para ser maior de cada membro de
$P$; fora disso, consultamos as ordens dos $P$
e $Q$.

%%}}}

%%{{{ x: poset_sum_formal_def 
\exercise.
%%%{{{ meta 
\label poset_sum_formal_def
%%%}}}

Defina formalmente a soma de posets $P \posetplus Q$
numa maneira que é capaz de lidar até com posets
cujos carrier sets não são necessariamente disjuntos.

%%}}}

%%{{{ x: lift_P_as_sum 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o $\lift P$ como somatório.

\solution
$\lift P \defeq \ordnum 1 \ordplus P$.

%%}}}

%%{{{ df: poset_union_pseudodef 
\pseudodefinition união.
%%%{{{ meta 
\label poset_union_pseudodef
%%%}}}

Dados $P$ e $Q$ posets disjuntos definimos sua \dterm{união}
$P \posetunion Q$ para ser o poset botando o $P$ e o $Q$
um no lado do outro.

%%}}}

%%{{{ x: poset_union_formal_def 
\exercise.
%%%{{{ meta 
\label poset_union_formal_def
%%%}}}

Defina formalmente a união de posets $P \posetunion Q$
numa maneira que é capaz de lidar até com posets
cujos carrier sets não são necessariamente disjuntos.

%%}}}

%%{{{ Q: How would you order the points of a product of posets? 
\question.
%%%{{{ meta 
%%%}}}

Dados posets $P,Q$, como tu definaria~(formalmente)~uma ordem nos
membros de $P \times Q$ para ele virar um poset também?

%%}}}

\spoiler

%%{{{ A.: there are two ways: 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Tem duas ordens bem diferentes e importantes que podemos definir
no $P\times Q$: a ``coordinatewise'' e a ``(anti)lexicográfica'':

%%}}}

%%{{{ df: product_order_componentwise 
\definition produto: componentwise.
%%%{{{ meta 
\label product_order_componentwise
\indexes
    * ordem!coordinatewise    see: componentwise
    ;;
\defines
    * ordem!componentwise
    ;;
%%%}}}

Sejam $P,Q$ posets.
Definimos a $\leq_{P \cross Q}$ no $P \times Q$ pela:
$$
(p,q) \leq_{P \cross Q} (p',q')
\defiff
p\leq_P p'
\mland
q\leq_Q q'.
$$
Chamamos essa ordem de \dterm{componentwise}
ou \dterm{coordinatewise}.

%%}}}

%%{{{ df: product_order_lexico 
\definition produto: (anti)lexicó.
%%%{{{ meta 
\label product_order_lexico
\defines
    * ordem!antilexicográfica
    * ordem!lexicográfica
    ;;
%%%}}}

Sejam $P,Q$ posets.
Definimos a \dterm{ordem lexicográfica} no $P \cross Q$
pela
$$
\align
(p,q) \leq_{P \cross Q} (p',q')
&\defiff
p <_P p'
\mlor
\paren{
p = p'
\mland
q \leq_Q q'
}.
\intertext{%
A ordem é chamada assim pois é a ordem seguida nos diccionários
(e ``lexicó'' significa ``diccionário'').
Similarmente definimos a ordem \dterm{antilexicográfica}
começando as comparações no lado oposto:
}
(p,q) \leq'_{P \cross Q} (p',q')
&\defiff
q <_Q q'
\mlor
\paren{
q = q'
\mland
p \leq_P p'
}.
\endalign
$$

%%}}}

%%{{{ remark: generalizations of product orders to generalized products 
\remark.
%%%{{{ meta 
%%%}}}

A ordem padrão que vamos considerar em produtos de posets
é a coordinatewise.  Observe que ela generaliza tranqüilamente
para famílias indexadas por qualquer conjunto de índices $\cal I$;
no outro lado, para generalizar a (anti)lexicográfica, o $\cal I$
necessita uma órdem também.

%%}}}

%%{{{ x: product_order_componentwise_generalized 
\exercise.
%%%{{{ meta 
\label product_order_componentwise_generalized
%%%}}}

Generalize a ordem componentwise para o produto cartesiano de
família indexada de posets.

%%}}}

%%{{{ x: product_order_lexico_generalized 
\exercise.
%%%{{{ meta 
\label product_order_lexico_generalized
%%%}}}

Generalize a ordem (anti)lexicográfica para o produto cartesiano
de família indexada de posets.

%%}}}

%%{{{ Q: How would you define an order on a function space? 
\question.
%%%{{{ meta 
%%%}}}

Dado poset $P$ e conjunto $A$, como definarias uma ordem
no espaço $(A \to P)$?

%%}}}

\spoiler

%%{{{ df: pointwise_order 
\definition pointwise.
%%%{{{ meta 
\label pointwise_order
\indexes
    * pointwise!order    see: ordem
    ;;
\defines
    * ordem!pointwise
    ;;
%%%}}}

Sejam $P$ poset e $A$ conjunto.
Definimos a ordem \dterm{pointwise} no espaço de funcções $\funs A P$
pela
$$
f \leq g
\defiff
\lforall {x \in A} {fx \leq_P gx}.
$$

%%}}}

%%{{{ x: pointwise_order_on_partial_function_space 
\exercise.
%%%{{{ meta 
\label pointwise_order_on_partial_function_space
%%%}}}

A mesma ordem ordena o $(A \parto P)$?

%%}}}

\endsection
%%}}}

%%{{{ Duality_in_posets 
\section Dualidade.
%%%{{{ meta 
\label Duality_in_posets
%%%}}}

\TODO escrever.

\endsection
%%}}}

%%{{{ Mappings 
\section Mapeamentos.
%%%{{{ meta 
%%%}}}

%%{{{ df: monotone_embedding_isomorphism 
\definition.
%%%{{{ meta 
\label monotone_embedding_isomorphism
\defines
    * isomorfismo!de ordem
    * monótona
    * order-embedding
    * order-isomorfismo
    ;;
%%%}}}

Sejam $\sset P {\leq_P}$ e $\sset Q {\leq_Q}$ posets
e $\phi : P \to Q$.
Definimos
$$
\align
\text{$\phi$ monótona}
&\defiff x\leq_P y \implies \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-embedding}
&\defiff \text{$\phi$ injetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-isomorfismo}
&\defiff \text{$\phi$ bijetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)
\endalign
$$

%%}}}

%%{{{ criterion: order_embedding_criterion 
\criterion.
%%%{{{ meta 
\label order_embedding_criterion
%%%}}}

Se $\phi : P \to Q$ tal que
$$
x \leq_P y \iff \phi(x) \leq_Q \phi(y)
$$
então $\phi$ é um order-embedding.
Segue que se $\phi$ é sobrejetora, ela é um order-isomorfismo.

\proof.
Basta demonstrar que $\phi$ é injetora.
Tome $x,y \in P$.
Temos
\compute
\phi(x) = \phi(y)
&\implies \phi(x) \leq_Q \phi(y) \mland \phi(y) \leq_Q \phi(x)  \by {\ref[converse_of_antisymmetry]} \\
&\implies x \leq_P y \mland y \leq_P x                          \by {pela hipótese} \\
&\implies x = y.                                                \by {transitividade} \\
\endcompute

%%}}}

%%{{{ x: converse_of_antisymmetry 
\exercise Converso de antissimetria.
%%%{{{ meta 
\label converse_of_antisymmetry
%%%}}}

Justifique o primeiro passo (a primeira implicação) na demonstração do~\ref[order_embedding_criterion].

%%}}}

%%{{{ x: downsets_of_poset_iso_downsets_of_dual 
\exercise.
%%%{{{ meta 
\label downsets_of_poset_iso_downsets_of_dual
%%%}}}

Defina um $\phi : \downsets P \iso \downsets { \dual P }$.

\solution
$\phi(X) = P\setminus X$

%%}}}

%%{{{ x: downsets_of_disjunion_iso_product_of_downsets 
\exercise.
%%%{{{ meta 
\label downsets_of_disjunion_iso_product_of_downsets
%%%}}}

Defina um
$\psi : \downsets { P_1 \disjunion P_2 } \iso \downsets {P_1} \times \downsets {P_2}$.

\solution
$\psi(D) = \tup{ D \inter P_1, D \inter P_2 }$

%%}}}

%%{{{ x: posets_of_divisors 
\exercise.
%%%{{{ meta 
\label posets_of_divisors
%%%}}}

Para $n\in\nats$, definimos o poset
${\cal D}_n \defeq \sset {D_n} {\divides}$
onde $D_n \defeq \setst {d \in \nats} {d \divides n}$.
\item{(i)}
Desenha o diagrama Hasse de ${\cal D}_{30}$.
\item{(ii)}
Ache conjunto $A$ tal que ${\cal D}_{30} \iso \sset {\pset A} {\subset}$
e defina um isomorfismo $\phi : D_{30} \to \pset A$.
\item{(iii)}
Existe conjunto $B$ tal que ${\cal D}_0 \iso \sset {\pset B} {\subset}$?
Se sim, ache o $B$ e defina um isomorfismo
$\phi : D_0 \to {\pset B}$;
se não, demonstre que é impossível.

\solution
\noi (i)
Primeiramente calculamos: $D_{30} = \set{1, 2, 3, 5, 6, 10, 15, 30}$.
$$
\tikzpicture
\node (max) at (0,4)  {$30$};
\node (a)   at (-2,2) {$6$};
\node (b)   at (0,2)  {$10$};
\node (c)   at (2,2)  {$15$};
\node (d)   at (-2,0) {$2$};
\node (e)   at (0,0)  {$3$};
\node (f)   at (2,0)  {$5$};
\node (min) at (0,-2) {$1$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\eop
\noi (ii)
Tome o $A = \set{2,3,5}$ e defina a funcção $\phi : \pset A \to D_{30}$
pelas equações:
$$
\align
\phi(30) &= A\\
\phi(15) &= \set{3,5}\\
\phi(10) &= \set{2,5}\\
\phi(6)  &= \set{2,3}\\
\phi(2)  &= \set{2}\\
\phi(3)  &= \set{3}\\
\phi(5)  &= \set{5}\\
\phi(1)  &= \emptyset
\endalign
$$
Seu diagrama Hasse parece assim:
$$
\tikzpicture
\node (max) at (0,4)  {$\set{2,3,5}$};
\node (a)   at (-2,2) {$\set{2,3}$};
\node (b)   at (0,2)  {$\set{2,5}$};
\node (c)   at (2,2)  {$\set{3,5}$};
\node (d)   at (-2,0) {$\set 2$};
\node (e)   at (0,0)  {$\set 3$};
\node (f)   at (2,0)  {$\set 5$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\noi
Obs: qualquer conjunto $A$ com $|A|=3$ serve!
Uma avantagem desse é que podemos bem elegantemente definir a bijecção
inversa, mandando cada subconjunto de $\set{2,3,5}$ para seu produtório!
\eop
\noi (iii)
Não existe, pois $D_0 = \nats$ (contável)
e logo não pode ser equinúmero com o powerset de nenhum conjunto $B$.
\eop
\noi (iv)
Verdade, a funcção $\phi : D_0 \to \setst {D_n} {n\in \nats}$ definida pela
$$
\phi(n) = D_n
$$
é um isomorfismo, pois:
$$
n \divides m \iff D_n \subset D_m.
$$

%%}}}

\endsection
%%}}}

%%{{{ Lattices as posets 
\section Reticulados como posets.
%%%{{{ meta 
%%%}}}

%%{{{ df: lattice_as_poset 
\definition.
%%%{{{ meta 
\label lattice_as_poset
\indexes
    * lattice    see: reticulado
    ;;
\defines
    * lattice!como poset
    ;;
%%%}}}

Um poset $\cal L = \sset L {\leq}$
é um \dterm{lattice} (ou \dterm{reticulado}) sse 
para todo $x,y \in L$, os $\sup\set{x,y}$ e $\inf\set{x,y}$
existem.

%%}}}

\endsection
%%}}}

%%{{{ Lattices as algebraic structures 
\section Reticulados como estruturas algébricas.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No~\ref[Algebraic_structures] introduzimos reticulados
como uma estrutura algébrica.\foot
Leia a~\ref[Lattices_as_algebras] se não tá ligado.
\toof
Aqui a definição novamente:

%%}}}

%%{{{ df: lattice_as_algebra_human 
\definition.
%%%{{{ meta 
\label lattice_as_algebra_human
\defines
    * lattice!como algebra
    ;;
%%%}}}

Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join,\meet$ são operadores binários no $L$.
Chamamos o $L$ um \dterm{lattice} (ou \dterm{reticulado}) sse
as operações $\join,\meet$ são associativas, comutativas,
e idempotentes, e satisfazem as leis seguintes \emph{de absorção}:
$$
\align
a \join (b \meet a) &= a\\
a \meet (b \join a) &= a
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Complete lattices 
\section Reticulados completos.
%%%{{{ meta 
%%%}}}

%%{{{ df: complete_lattice 
\definition.
%%%{{{ meta 
\label complete_lattice
%%%}}}

Um reticulado $L$ é um \dterm{reticulado completo} sse
para todo $S\subset L$ ambos os $\Join S$ e $\Meet S$ são definidos.

%%}}}

%%{{{ x: every_complete_lattice_is_bounded 
\exercise.
%%%{{{ meta 
\label every_complete_lattice_is_bounded
%%%}}}

Todo reticulado completo é bounded.

%%}}}

%%{{{ remark: what do we gain in a complete lattice 
\remark.
%%%{{{ meta 
%%%}}}

Já provamos que num reticulado $L$ os joins e meets existem para qualquer
subconjunto \emph{não vazio e finito} dele.
Então num reticulado \emph{completo}, sabemos disso para o vazio
e para os subconjuntos infinitos também.

%%}}}

\TODO generalize o~\ref[set_limits] para qualquer reticulado completo.

\endsection
%%}}}

%%{{{ Fixpoints_in_posets 
\section Fixpoints.
%%%{{{ meta 
\label Fixpoints_in_posets
%%%}}}

%%{{{ df: fixpoints 
\definition.
%%%{{{ meta 
\label fixpoints
\defines
    * \fixpoints {~f}  -- o conjunto dos fixpoints de $f$
    * \gfp {~f}  -- o maior fixpoint de $f$
    * \lfp {~f}  -- o menor fixpoint de $f$
    * fixpoint!greatest
    * fixpoint!least
    ;;
%%%}}}

Seja $f : X \to X$.
Usamos a notação
$$
\fixpoints f
\defeq
\setstt { x \in X } {$x$ é um fixpoint de $f$}
$$
e se $X$ é um poset e $\fixpoints F$ tem mínimo e máximo botamos
\mathcall
\lfp f &\defeq \min(\fixpoints f)  \called {o \dterm{menor fixpoint} de $f$} \\
\gfp f &\defeq \max(\fixpoints f). \called {o \dterm{maior fixpoint} de $f$} \\
\endmathcall

%%}}}

%%{{{ df: prefixpoint_postfixpoint 
\definition prefixpoints, postfixpoints.
%%%{{{ meta 
\label prefixpoint_postfixpoint
\defines
    * postfixpoint
    * prefixpoint
    ;;
%%%}}}

Sejam $P$ poset e $F : P \to P$ e seja $p \in P$.
Chamamos o $p$ de \dterm{prefixpoint da $F$}
sse $Fp \leq p$.  Dualmente $p$ é um \dterm{postfixpoint da $F$}
sse $p \leq Fp$.

%%}}}

%%{{{ thm: knaster_tarski_fixpoint 
\theorem Knaster--Tarski.
%%%{{{ meta 
\label knaster_tarski_fixpoint
\indexes
    * teorema!Knaster--Tarski fixpoint
    ;;
%%%}}}

{\Knaster}{\Tarski}%
Seja $L$ reticulado completo e $F : L \to L$ monótona.
Então $F$ tem um fixpoint.

\sketch.
Sejam
$$
\xalignat2
D &\asseq \setst { x \in L } { x \leq Fx } &
U &\asseq \setst { x \in L } { Fx \leq x }.
\endxalignat
$$
os conjuntos de todos os postfixpoints e prefixpoints
da $F$ respecitivamente.
Considere o conjunto $\fixpoints F$.
Observe que $\fixpoints F = D \inter U$.
Vamos demonstrar que o $\Join D$ é um fixpoint de $F$.
(O $\Meet U$ é similar.)
Precisamos $\Join D = F(\Join D)$.
Vamos demonstrar $\Join D \leq F(\Join D)$ primeiro
e depois $F(\Join D) \leq \Join D$.
\proofpart{$\Join D \leq F(\Join D)$:}
Como $\Join D$ é o least upper bound de $D$,
basta demonstrar $F(\Join D)$ é um upper bound de $D$.
\proofpart{$F(\Join D) \leq \Join D$:}
Aqui como $\Join D$ é um upper bound de $D$,
basta mostrar que $F(\Join D)$ é um membro de $D$.
(Nessa parte podemos e vamos usar a $\Join D \leq F(\Join D)$
que acabamos de demonstrar!)

\proof.
Seja
$D \asseq \setst { x \in L } { x \leq Fx }$.
Vamos demonstrar que $\Join D$ é um fixpoint de $F$,
ou seja $F(\Join D) = \Join D$.
Quebramos a prova em duas partes:
\proofpart{$\Join D \leq F(\Join D)$:}
Basta mostrar que $F(\Join D)$ é um upper bound de $D$.
Tome $d \in D$.
Logo $d \leq Fd$\fact1~(pela definição de $D$)
e também $d \leq \Join D$\fact2,
pois $\Join D$ é um upper bound de $D$.
Como $F$ é monótona, da \byfact2~ganhamos
$Fd \leq F(\Join D)$\fact3.
Juntando (transitividade) as \byfact1~e~\byfact3:
$$
d \leq Fd \leq F(\Join D)
$$
ou seja, $d \leq F(\Join D)$ e como $d$ foi arbitrário elemento de $D$,
concluimos que $F(\Join D)$ é um upper bound de $D$.
Logo $\Join D \leq F(\Join D)$.
\proofpart{$F(\Join D) \leq \Join D$:}
Basta demonstrar que $F(\Join D) \in D$, pois $\Join D$ é um upper bound de $D$.
Como já provamos que $\Join D \leq F(\Join D)$, ganhamos a
$F(\Join D) \leq F(F(\Join D))$ (pela monotonicidade da $F$).
Ou seja, o $F(\Join D)$ satisfaz a definição de $D$, e logo pertence nele:
$F(\Join D) \in D$.
Como $\Join D$ é um upper bound de $D$, temos $F(\Join D) \leq \Join D$.

%%}}}

%%{{{ remark: the full Knaster--Tarski theorem 
\remark.
%%%{{{ meta 
%%%}}}

O teorema Knaster--Tarski fala ainda mais:
o $\fixpoints F\subset L$ é um reticulado completo
(\ref[knaster_tarski_fixpoint_full]).

%%}}}

\TODO explicar e desenhar.

%%{{{ cor: real_f_monotone_on_closed_interval_has_lfp_and_gfp 
\corollary.
%%%{{{ meta 
\label real_f_monotone_on_closed_interval_has_lfp_and_gfp
%%%}}}

Sejam $a,b\in\reals$ com $a\leq b$,
e funcção $f : [a,b] \to [a,b]$ monótona.
Logo $f$ tem um máximo e um mínimo fixpoint.

%%}}}

%%{{{ remark: we do not need f to be continuous 
\remark.
%%%{{{ meta 
%%%}}}

Observe que no~\ref[real_f_monotone_on_closed_interval_has_lfp_and_gfp]
não precisamos da $f$ ser continua.

%%}}}

%%{{{ note: a new proof of Schröder--Bernstein 
\note Uma nova prova de Schröder--Bernstein.
%%%{{{ meta 
%%%}}}

Ganhamos também como corolário o teorema Schröder--Bernstein
(\reftag[schroder_bernstein])!
Os detalhes estão no~\ref[schroder_bernstein_lattice_proof].

%%}}}

%%{{{ df: orbit 
\pseudodefinition órbita.
%%%{{{ meta 
\label orbit
%%%}}}

Seja $a \in A$ e $f : A \to A$.
Chamamos a seqüência 
$$
a, f a, f^2 a, \dotsc
$$
de $f$-\dterm{órbita} de $a$,
omitindo o prefixo \symq{$f$-} quando o mapa
é implícito pelo contexto.

%%}}}

%%{{{ x: orbit_of_bottom 
\exercise.
%%%{{{ meta 
\label orbit_of_bottom
%%%}}}

Sejam $P$ um poset com $\bot$ e $f$ um endomapa no $P$.
Defina formalmente a $f$-órbita do $\bot$.

\solution
Como já definimos as iterações de qualquer endomapa
(\ref[function_iterations]), podemos simplesmente
definir a órbita do $\bot$ como a seqüência
$\seqn {f^n(\bot)} n$.
Alternativamente definimos diretamente por recursão:
$$
\align
x_0     &= \bot \\
x_{n+1} &= f(x_n).
\endalign
$$

%%}}}

%%{{{ df: chaincomplete 
\definition.
%%%{{{ meta 
\label chaincomplete
%%%}}}

Um poset $P$ é chamado \dterm{chain-completo} sse
todo chain $C \subset P$ possui lub.

%%}}}

%%{{{ x: chaincomplete_has_bottom 
\exercise.
%%%{{{ meta 
\label chaincomplete_has_bottom
%%%}}}

Todo poset chain-completo possui bottom.

\solution
O $\emptyset$ é uma chain---como poderia não ser?---e
logo o $\Join \emptyset$ existe.
Mas o $\Join \emptyset$ é o bottom pela sua definição
como menor de todos os upper bounds.
(Já observamos que todo membro de $p$ é trivialmente um upper bound do $\emptyset$.)

%%}}}

%%{{{ df: countably_continuous 
\definition.
%%%{{{ meta 
%%%}}}

Um mapa $f : P \to Q$ é chamado \dterm{contavelmente continuo} sse
$f$ respeita os lubs de todas as \emph{cadeias não vazias e contáveis:}
$f( \Join C ) = \Join \img f C$.

%%}}}

%%{{{ thm: Kleene_strongly_least_fixpoint 
\theorem Kleene.
%%%{{{ meta 
\label Kleene_strongly_least_fixpoint
\defines
    * fixpoint!strongly least
    ;;
\credits
    * Kleene : strongly least fixpoint
    ;;
%%%}}}

Sejam $P$ poset chain-completo e $\pi : P \to P$
endomapa monótono e contavelmente continuo.
Logo $\pi$ possui exatamente um
\dterm{strongly least fixpoint} $x^*$:
$$
\gather
\pi(x^*) = x^* \tag{i} \\
\lforall {y \in P} {\pi(y) \leq y \implies x^* \leq y} \tag{ii}
\endgather
$$

\sketch.
A idéia é tomar como $x^*$ o lub dos elementos da órbita do $\bottom$
e demonstrar que ele realmente é o strongly least fixpoint, ou seja,
que ele satisfaz as (i) e (ii), e que é o único tal ponto.

\proof.
Pelo \ref[chaincomplete_has_bottom], o $P$ possui $\bot$.
Consideramos a $\pi$-órbita do $\bot$:
$$
\bot, \pi(\bot), \pi(\pi(\bot)), \dotsc
$$
O conjunto dos seus membros é uma cadêia
(\ref[monotone_orbit_of_bottom_is_a_chain])
e logo possui lub pois $P$ é chain-completo.
Tome
$$
x^* \asseq \Join \set{ \bot, \pi(\bot), \pi^2(\bot), \dotsc }
$$
então.
Confirmamos que: (i) $x^*$ é um fixpoint (\ref[lub_of_orbit_is_a_fixpoint]);
e, ainda mais (ii) o strongly least (\ref[lub_of_orbit_is_the_srongly_least_fixpoint]).

%%}}}

%%{{{ x: monotone_orbit_of_bottom_is_a_chain 
\exercise.
%%%{{{ meta 
\label monotone_orbit_of_bottom_is_a_chain
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ x: lub_of_orbit_is_a_fixpoint 
\exercise.
%%%{{{ meta 
\label lub_of_orbit_is_a_fixpoint
%%%}}}

O $x^*$ da demonstração
do~\ref[Kleene_strongly_least_fixpoint] é um fixpoint.

%%}}}

%%{{{ x: lub_of_orbit_is_the_srongly_least_fixpoint 
\exercise.
%%%{{{ meta 
\label lub_of_orbit_is_the_srongly_least_fixpoint
%%%}}}

O $x^*$ da demonstração
do~\ref[Kleene_strongly_least_fixpoint] é o strongly
least fixpoint.

%%}}}

\endsection
%%}}}

%%{{{ Irreducible elements 
\section Elementos irredutíveis.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Boolean_algebras 
\section Álgebras booleanas.
%%%{{{ meta 
\label Boolean_algebras
\credits
    * Boole : álgebra
    ;;
%%%}}}

\endsection
%%}}}

%%{{{ Heyting_algebras 
\section Álgebras Heyting.
%%%{{{ meta 
\label Heyting_algebras
\credits
    * Heyting : álgebra
    ;;
%%%}}}

\endsection
%%}}}

%%{{{ Categories_and_posets 
\section Pouco de cats---categorias e posets.
%%%{{{ meta 
\label Categories_and_posets
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ x: rats_is_dense 
\problem.
%%%{{{ meta 
\label rats_is_dense
%%%}}}

Demonstre que o $\rats$ com sua ordem padrão é denso.

%%}}}

%%{{{ df: cofinito_em_nats 
\definition.
%%%{{{ meta 
\label cofinito_em_nats
\defines
    * cofinito
    ;;
%%%}}}

Chamamos um $A\subset \nats$ \dterm{cofinito} sse
seu complemento $\nats\setminus A$ é finito.

%%}}}

%%{{{ prob: family_of_cofinite_lattice 
\problem.
%%%{{{ meta 
\label family_of_cofinite_lattice
\defines
    * reticulado!de conjuntos
    ;;
%%%}}}

Mostre que as famílias
$$
\align
\scr L_1 &\asseq \setstt {A \subset \nats} {$A$ é cofinito}\\
\scr L_2 &\asseq \setstt {A \subset \nats} {$A$ é finito ou cofinito}
\endalign
$$
são \dterm{reticulados de conjuntos}, ou seja,
reticulados com relação de ordem $\subset$.

\solution
\proofpartstylize{Sobre o $\scr L_1$.}
Sejam $A, B \in \scr L_1$.
Pela definição então $\nats\setminus A$ e $\nats\setminus B$ são finitos.
Vou mostrar que $A\union B$ e $A\inter B$ são cofinitos, e logo pertencem ao
$\scr L_1$ também.
Calculamos 
$$
\align
\nats\setminus(A\union B) &=\paren{\nats\setminus A} \inter \paren{\nats\setminus B}\\
\nats\setminus(A\inter B) &=\paren{\nats\setminus A} \union \paren{\nats\setminus B},
\endalign
$$
logo os dois conjuntos no lado esquerdo são finitos como intersecção e união de
finitos respectivamente.
\eop
\proofpartstylize{Sobre o $\scr L_2$.}
Sejam $A, B \in \scr L_2$.
Separamos em casos:
\eop
\case{Caso ambos finitos:}
Facilmente $A\union B$ e $A \inter B$ são finitos também,
como intersecção e união de conjuntos finitos.
Logo ambos pertencem ao $\scr L_2$.
\eop
\case{Caso ambos cofinitos:}
Provamos isso na demonstração sobre o $\scr L_1$.
\eop
\case{Caso contrário:}
Temos um dos $A,B$ finito e o outro cofinito.
Sem perda de generalidade, suponha que $A$ finito, $B$ cofinito.
O $A\inter B$ é trivialmente finito como intersecção de finito com qualquer conjunto.
Logo $A\inter B \in \scr L_2$.
O $A\union B$ é cofinito, pois
$$
\nats\setminus(A \union B) = \paren{\nats\setminus A} \inter \paren{\nats\setminus B}
$$
que é finito para o mesmo motivo (intersecção com o $\nats\setminus B$ que é finito).
Logo $A\union B \in \scr L_2$.

%%}}}

%%{{{ prob: family_of_cofinite_not_complete_lattice 
\problem.
%%%{{{ meta 
\label family_of_cofinite_not_complete_lattice
%%%}}}

Mostre que nenhum dos $\scr L_1,\scr L_2$ do~\ref[family_of_cofinite_lattice]
é completo.

\hint
Seja $A_n \asseq \nats\setminus\set{0,2,\dotsc, 2n - 2}$ o $\nats$ sem os
primeiros $n$ números pares.
Mostre que:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.

\solution
Vamos demonstrar primeiramente a afirmação seguinte:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.
\eop
\proofstylize{{\proofname} da afirmação:}
Suponha que para todo $n\in\nats$, $B \subset A_n$.
Logo
$$
\align
    B &\subset \Inter_{i=0}^\infty A_i\\
\intertext{e complementando os dois lado,}
\nats\setminus B
    &\supset \nats\setminus\Inter_{i=0}^\infty A_i\\
    &= \Union_{i=0}^\infty(\nats\setminus A_i)\\
    &= \Union_{i=0}^\infty(\set{0,2,\dotsc, 2n-2})\\
    &= 2\nats.
\endalign
$$
Como $2\nats$ é infinito, o $B$ não é cofinito.
\eop
Agora voltamos a demonstrar que nenhum dos $\scr L_1, \scr L_2$ é completo.
Considere o conjunto
$$
\cal S \asseq \set { A_0, A_1, A_2, \dotsc }
$$
Observe que
$\cal S \subset \scr L_1, \scr L_2$
pois todos os seus elementos são claramente cofinitos.
Mesmo assim, o $\Inter \cal S$ não é cofinito
$\Inter \cal S$ é o conjunto de todos os ímpares)
e logo não pertence em nenhum dos $\scr L_1, L_2$.

%%}}}

%%{{{ prob: knaster_tarski_fixpoint_full 
\problem Teorema Knaster--Tarski completo.
%%%{{{ meta 
\label knaster_tarski_fixpoint_full
%%%}}}

No contexto do~\ref[knaster_tarski_fixpoint], demonstre que
o subconjunto $\fixpoints F \subset L$ é um reticulado completo.

%%}}}

%%{{{ prob: banach_decomposition_theorem 
\problem Teorema de decomposição de Banach.
%%%{{{ meta 
\label banach_decomposition_theorem
%%%}}}

\TODO escrever.

%%}}}

%%{{{ prob: schroder_bernstein_lattice_proof 
\problem Teorema de Schröder--Bernstein.
%%%{{{ meta 
\label schroder_bernstein_lattice_proof
%%%}}}

Sejam $f : A \injto B$ e $g : B \injto A$ funcções injetoras.
Usando o teorema fixpoint de Knaster--Tarski~\reftag[knaster_tarski_fixpoint]
prove que existe funcção bijetora $h : A \bijto B$.

\hint
O $\sset{\pset A}{\subset}$ é um reticulado completo.

\hint
Considere a funcção $F : \pset A \to \pset A$ definida pela
$$
F(X) = A \setminus \paren{ \img g {B \setminus {\img f X}} }.
$$
Mostre que ela é monótona.

\hint
Pelo teorema Knaster--Tarski~\reftag[knaster_tarski_fixpoint]
a $F$ tem um fixpoint $C \subset A$, e
$$
C = F(C)
\iff
C = A \setminus \paren{ \img g {B \setminus {\img f C}} }
\iff
A \setminus C = \img g {B \setminus {\img f C}}.
$$

\hint
Defina a desejada $h : A \bijto B$ por casos:
$$
h(x) = \knuthcases {
\dots, & se $x \in C$ \cr
\dots, & se $x \in A\setminus C$.
}
$$

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[DaveyPriestley],
\cite[gratzerlatticefirst],
\cite[gratzerlatticefoundation].

\cite[ynmnst: Cap.~6].

\cite[corilascar1: Cap.~2],
\cite[bellmachover: Cap.~4],
\cite[halmosboolean].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Wosets_Ordinals 
\chapter Wosets; Ordinais.
%%%{{{ meta 
\label Wosets_Ordinals
%%%}}}

%%{{{ intro 
\chapintro
O termo \emph{wellorder} (ou \emph{well-order}) de inglês tem sido traduzido
como \emph{boa ordem} em português.  Aqui eu uso o termo \emph{bem-ordem}.
Além de ficar mais perto no termo internacional, a palavra ``bem'' tem
um significado \emph{bem} mais usado em português do que em inglês,
onde não é muito \emph{well} known, exemplificado aqui:\foot
e com certeza \emph{well} beyond nossos interesses aqui
\toof
\eop\smallskip
Uma ordem é uma relação legal.
\eop
Uma \emph{bem}-ordem é uma relação \emph{bem}~legal---vamos descobrir isso neste capítulo.
%%}}}

%%{{{ Wellorderings 
\section Bem-ordens.

%%{{{ df: woset 
\definition Bem-ordem.
%%%{{{ meta 
\label woset
\indexes
    * conjunto!bem-ordenado    see: woset
    ;;
\defines
    * woset
    ;;
%%%}}}

Seja $\sset A <$ um conjunto totalmente ordenado.
Sua ordem $<$ é uma \dterm{bem-ordem}, sse
\emph{cada subconjunto $S\subset A$ possui um elemento mínimo}.
Nesse caso chamamos o $A$ \dterm{bem-ordenado} ou \dterm{woset}
(de \dterm{well-ordered set}).

%%}}}

\TODO Elaborar.

\endsection
%%}}}

%%{{{ Transfinite induction 
\section Indução transfinita.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Transfinite recursion 
\section Recursão transfinita.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Ordinal_arithmetic 
\section Aritmética ordinal.
%%%{{{ meta 
\label Ordinal_arithmetic
%%%}}}

%%{{{ x: omegaomega_plus_one_is_well_ordered 
\exercise.
%%%{{{ meta 
\label omegaomega_plus_one_is_well_ordered
%%%}}}

O $\omega^2+1$ é bem ordenado.

\hint
Lembre-se que usamos a ordem (anti)lexicográfica nos produtos.
Tome $A$ tal que $\emptyset\neq A \subset \omega^2 + 1$ e ache se u mínimo.
Separe casos dependendo se $A=\set{\top}$ ou não,
onde $\top$ o máximo elemento do $\omega^2+1$.

\solution
Seja $A\subset \omega^2 + 1$ com $A\neq\emptyset$.
Temos a seguinte ordem no $\omega^2 + 1$:
$$
\mubrace{
 \mubrace{\tup{0,0} < \tup{1,0} < \tup{2,0} < \dotsb}{\dsize\omega} 
 <
 \mubrace{\tup{0,1} < \tup{1,1} < \tup{2,1} < \dotsb}{\dsize\omega} 
 <
 \dotsb
}{\dsize\omega^2}
<
\set\top.
$$
\case{Caso $A = \set {\top}$}:
$\min A = \top$.
\eop
\case{Caso $A \neq \set {\top}$}:
Como $A\neq \emptyset$, concluimos que $A\inter \omega^2 \neq \emptyset$.
Sejam:
$$
\align
y_0 &\asseq \min\setst {y\in\nats} {\lexists {x\in\nats} {\tup{x,y}\in A}}\\
x_0 &\asseq \min\setst {x\in\nats} {\tup{x,y_0}\in A}
\endalign
$$
onde os dois mínima existem graças ao PBO dos naturais.
Facilmente, $\min A = \tup{x_0,y_0}$.

%%}}}

%%{{{ x: solving_for_ordinals 
\exercise.
%%%{{{ meta 
\label solving_for_ordinals
%%%}}}

O que podes concluir sobre os ordinais $\alpha$ e $\beta$ se\dots:
$$
\xxalignat3
\text{(i)}~&\omega + \alpha = \omega & \text{(iii)}~& \omega \cdot \alpha = \omega & \text{(v)}~& \alpha +     \beta = \omega\\
\text{(ii)}~&\alpha + \omega = \omega & \text{(iv)}~& \alpha \cdot \omega = \omega & \text{(vi)}~& \alpha \cdot \beta = \omega
\endxxalignat
$$

\solution
\item{(i)}   $\alpha = 0$
\item{(ii)}  $\alpha$ é finito
\item{(iii)} $\alpha=1$
\item{(iv)}  $\alpha$ finíto \& $\alpha\neq 0$
\item{(v)}   $\text{ou}\,\leftbrace {\aligned&\text{$\alpha$ finíto      \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=0$}\endaligned}$
\item{(vi)}  $\text{ou}\,\leftbrace {\aligned&\text{$1\leq\alpha<\omega$ \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=1$}\endaligned}$

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[goldreisets],
\cite[ynmnst],
\cite[jechset],
\cite[kanamori],
\cite[kunen2011].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Denotational_semantics 
\chapter Semântica denotacional.
%%%{{{ meta 
\label Denotational_semantics
%%%}}}

%TODO: Check http://pages.cs.wisc.edu/~horwitz/CS704-NOTES/

%%{{{ A language of binary numerals 
\section Uma linguagem de numerais binários.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ A little programming language 
\section Uma pequena linguagem de programação.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Domain theory 
\section Teoria de domínios.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[stoysemantics],
\cite[tennent1976],
\cite[tennentsemantics].

\cite[streicherdomainsfp].

\cite[lpbook].

\cite[winskelsemantics],
\cite[guntersemantics].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Metric_spaces 
\chapter Espaços métricos.
%%%{{{ meta 
\label Metric_spaces
%%%}}}

%%{{{ intro 
\chapintro
Logo depois do desenvolvemento da teoria de conjuntos de
{\Cantor}Cantor, no ano \yearof{1906} {\Frechet}Fréchet introduziu
os \dterm{espaços métricos} na sua tese de doutorado~\cite[frechetthesis].
Neste capítulo estudamos as primeiras idéias básicas.
%%}}}

%%{{{ Distances 
\section Distáncias.
%%%{{{ meta 
\label Distances
%%%}}}

%%{{{ pseudodf: metric_space 
\pseudodefinition espaço métrico.
%%%{{{ meta 
\label metric_space_pseudodef
%%%}}}

Um \dterm{espaço métrico} é um conjunto equipado com uma
noção de \dterm{distância} entre quaisquer dois membros dele
em tal forma que:
\tlist:
\li (Met0): a distância de cada ponto para ele mesmo é $0$;
\li (Met1): a distância entre pontos distintos é positiva;
\li (Met2): a distância de $x$ para $y$ é a mesma da de $y$ para $x$;
\li (Met3): as distâncias satisfazem a disegualdade triangular.
\endtlist

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora formalizar:

%%}}}

%%{{{ df: metric_space 
\definition espaço métrico.
%%%{{{ meta 
\label metric_space
%%%}}}

Seja $X$ conjunto.
Uma funcção $d : X^2 \to \reals$ é chamada
\dterm{métrica} no $X$ sse:
$$
\align
&d(x,x) = 0                   \tag{Met0} \\
&x \neq y \implies d(x,y) > 0 \tag{Met1} \\
&d(x,y) = d(y,x) \iff x = y   \tag{Met2} \\
&d(x,y) \leq d(x,w) + d(w,y). \tag{Met3}
\endalign
$$
Chamamos a última \dterm{disegualdade triangular},
e dados pontos $x,y \in X$ chamamos o valor $d(x,y)$
de $d$-\dterm{distância} entre os $x,y$,
omitindo o prefixo \symq{$d$-} quando a métrica é implicita
pelo contexto.
Um conjunto estruturado $\sset X d$ onde $d$ é uma métrica no $X$
é chamado \dterm{espaço métrico}.

%%}}}

%%{{{ df: pseudometric 
\definition pseudométrica.
%%%{{{ meta 
\label pseudometric
%%%}}}

Uma funcção $d : X^2 \to \reals$ que satisfaz as
(Met0), (Met2), e (Met3) da~\ref[metric_space]
é chamada \dterm{pseudométrica}.

%%}}}

%%{{{ eg: metric_space_eg_reals 
\example.
%%%{{{ meta 
\label metric_space_eg_reals
%%%}}}

Os reais $\sset \reals d$ onde
$$
d(x,y) = \abs{x - y}.
$$

%%}}}

%%{{{ eg: metric_space_eg_plane 
\example.
%%%{{{ meta 
\label metric_space_eg_plane
%%%}}}

O plano euclideano $\sset {\reals^2} d$ onde
$$
d(\tup{x_1,x_2},\tup{y_1,y_2}) = \sqrt{ (x_1-y_1)^2 + (x_2 - y_2)^2 }.
$$

%%}}}

%%{{{ eg: metric_space_eg_discrete 
\example.
%%%{{{ meta 
\label metric_space_eg_discrete
%%%}}}

Seja $X$ um conjunto e defina a funcção $d : X^2 \to \reals$ pela
$$
d(x,y) =
\knuthcases {
0, & se $x = 0$ \cr
1, & caso contrário.
}
$$
O $\sset X d$ é um espaço métrico.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Esse espaço é bastante importante e merece seu próprio nome:

%%}}}

%%{{{ df: discrete_metric 
\definition discreto.
%%%{{{ meta 
\label discrete_metric
%%%}}}

Dado conjunto $X$, a \dterm{métrica discreta} nele é a funcção
$d : X^2 \to \reals$ definida pela
$$
d(x,y) =
\knuthcases {
0, & se $x = y$ \cr
1, & caso contrário.
}
$$
O $\sset X d$ é chamado \dterm{espaço métrico discreto}.

%%}}}

%%{{{ x: explain_euclidean_metric_of_plane 
\exercise.
%%%{{{ meta 
\label explain_euclidean_metric_of_plane
\credits
    * Pythagoras : métrica euclideana
    ;;
%%%}}}

Donde chegou essa $d$ do~\ref[metric_space_eg_plane]?

\hint
De Pythagoras.
Como?
Demonstre!

%%}}}

%%{{{ x: derive standard metric of ℝ³ 
\exercise.
%%%{{{ meta 
%%%}}}

Qual seria a métrica ``standard'' do $\reals^3$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Em qualquer espaço métrico, podemos definir a noção de
$\epsilon$-perto:

%%}}}

%%{{{ df: epsilon_close_in_metric 
\definition ε-perto.
%%%{{{ meta 
\label epsilon_close_in_metric
\defines
    * perto!em espaço métrico
    ;;
%%%}}}

Sejam $x,y\in X$ e $\epsilon > 0$.
Dizemos que
$$
\text{$x,y$ são $\epsilon$-perto}
\defiff
d(x,y) < \epsilon.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Assim temos de graça a definição de limite.
Literalmente copiamos a~\ref[limit_of_sequence_of_reals]:

%%}}}

%%{{{ df: limit_in_metric 
\definition limite.
%%%{{{ meta 
\label limit_in_metric
\defines
    * {~{\seqn a n}} \limto ~\ell  -- a seqüência $\seqn a n$ tende ao $\ell$
    * limite!espaço métrico
    ;;
%%%}}}

Seja $\seqn a n$ uma seqüência num espaço métrico $\sset X d$.
Dizemos que $\seqn a n$ \dterm{tende ao limite} $\ell$
sse a partir dum membro $a_N$, todos os seus membros
ficam $\epsilon$-perto do $\ell$.
Ou seja:
$$
\seqn a n \limto \ell
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i \geq N}
{$a_i$ é $\epsilon$-perto de $\ell$}.
$$
Escrevemos
$$
\liml_n a_n = \ell
$$
como sinônimo de $\seqn a n \limto \ell$.
\mistake

%%}}}

%%{{{ beware: we need to prove uniqueness again 
\beware.
%%%{{{ meta 
%%%}}}

Lembra do erro da~\ref[limit_of_sequence_of_reals]
que descobreste no~\reftag[limit_of_sequence_of_reals_uniqueness_needed]?
Pois é, junto com a definição, copiamos seu errinho também,
mas não ganhamos de graça sua resolução,
pois a demonstração de unicidade de limites
(\ref[uniqueness_of_limits_of_reals])
usou a definição de \emph{$\epsilon$-perto} dos reais,
e aqui isso mudou.
Então sim, tu tens um trabalho pra fazer agora:

%%}}}

%%{{{ x: uniqueness_of_limits_in_metric 
\exercise Unicidade de limites (espaços métricos).
%%%{{{ meta 
\label uniqueness_of_limits_in_metric
%%%}}}

Demonstre a unicidade dos limites.

\hint
Olhe para a demonstração do~\ref[uniqueness_of_limits_of_reals].

%%}}}

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Open_sets_and_neighborhoods_in_metric_spaces 
\section Conjuntos abertos e fechados.
%%%{{{ meta 
\label Open_sets_and_neighborhoods_in_metric_spaces
%%%}}}

%%{{{ open_in_metric 
\definition.
%%%{{{ meta 
\label open_in_metric
%%%}}}

Um conjunto $A \subset X$ é \dterm{aberto} (ou \dterm{open})
sse todo $a \in A$ tem bola contida no $A$:
$$
\text{$A$ aberto}
\defiff
\pforall {a \in A}
\lexists {\epsilon > 0}
         {\ball \epsilon a \subset A}.
$$

%%}}}

%%{{{ x: trivial_opens_in_metric 
\exercise.
%%%{{{ meta 
\label trivial_opens_in_metric
%%%}}}

Em todo espaço métrico $\sset X d$,
$X$ e $\emptyset$ são abertos.

%%}}}

%%{{{ x: balls_are_open 
\exercise.
%%%{{{ meta 
%%%}}}

Cada bola $\ball \epsilon x$ é um conjunto aberto.

%%}}}

%%{{{ df: nbhd_in_metric 
\definition.
%%%{{{ meta 
\label nbhd_in_metric
%%%}}}

Sejam $N \subset X$ e $a \in X$.
Dizemos que $A$ é uma \dterm{vizinhança} (ou \dterm{neighborhood},
ou \dterm{nbhd}) de $x$ sse $N$ contenha uma bola de $a$:
$$
\text{$N$ vizinhança de $a$}
\defiff
\lexists
{\epsilon > 0}
{\ball \epsilon a \subset N}
$$

%%}}}

%%{{{ x: nbhd_does_not_imply_open 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
<<cada vizinhança é um conjunto aberto>>.

\hint
A afirmação é falsa.
Ache uma vizinhança $N_x$ dum ponto $x$ tal que $N_x$
não é aberto.
Dá pra achar nos reais.

%%}}}

%%{{{ property: binary_intersections_opens_are_open 
\property.
%%%{{{ meta 
\label binary_intersections_of_opens_are_open
%%%}}}

Intersecção finita de abertos é aberto.

%%}}}

%%{{{ cor: finite_intersections_of_opens_are_open 
\corollary.
%%%{{{ meta 
\label finite_intersections_of_opens_are_open
%%%}}}

Intersecções finitas de abertos são abertas.

%%}}}

%%{{{ property: arbitrary_unions_of_opens_are_opens 
\property.
%%%{{{ meta 
\label arbitrary_unions_of_opens_are_opens
%%%}}}

Uniões arbitrárias de abertos são abertas.

%%}}}

%%{{{ df: punctured_in_metric 
\definition puncturados.
%%%{{{ meta 
\label punctured_in_metric
%%%}}}

Chamamos a $\ball \epsilon a \setminus \set{a}$ de
\dterm{bola puncturada} do $a$.
Similarmente, se e $N$ é uma vizinhança de $a$,
chamamos o $N \setminus \set{a}$ de
\dterm{vizinhança puncturada} de $a$.

%%}}}

%%{{{ df: limit_point 
\definition limit point.
%%%{{{ meta 
%%%}}}

Sejam $A \subset X$ e $\ell \in X$.
Chamamos o $\ell$ um \dterm{limit point} de $A$ sse
existe seqüência $\seqn a n \subset A\setminus\set{\ell}$
que tende ao $\ell$:
$$
\seqn a n \limto \ell.
$$

%%}}}

%%{{{ criterion: limit_point_of_A_if_each_punctured_intersects_A 
\criterion.
%%%{{{ meta 
%%%}}}

Sejam $A \subset X$ e $\ell \in X$.
$$
\text{$\ell$ limit point de $A$}
\iff
\text{toda bola puncturada de $\ell$ intersecta o $A$}.
$$

%%}}}

%%{{{ df: closed_in_metric 
\definition.
%%%{{{ meta 
\label closed_in_metric
%%%}}}

Um conjunto $A \subset X$ é \dterm{fechado} sse
$A$ é fechado pela operação de limites, ou seja,
sse todos os limit points do $A$ estão no $A$,
ou seja:
$$
\text{$A$ fechado}
\defiff
\lforall
{\ell \in X}
{\text{$\ell$ limit point de $A$} \implies \ell \in A}.
$$

%%}}}

%%{{{ criterion: closed_iff_complement_of_open 
\criterion.
%%%{{{ meta 
%%%}}}

Um conjunto $A \subset X$ é fechado sse
seu complemento $X \setminus A$ é aberto.

%%}}}

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: continuous_in_metric 
\definition.
%%%{{{ meta 
\label continuous_in_metric
%%%}}}

Sejam $f : \sset X d \to \sset Y \rho$ e $x_0 \in X$.
Chamamos a $f$ de \dterm{continua no $x_0$} sse:
$$
\pforall {\epsilon > 0}
\pexists {\delta > 0}
\lforall {x \in X}
{\text{$x_0,x$ são $\delta$-perto} \implies \text{$f x_0, f x$ são $\epsilon$-perto}};
$$
ou, equivalentemente:
$$
\pforall {\epsilon > 0}
\lexists {\delta > 0}
{\img f {\ball \delta {x_0}} \subset \ball \epsilon {f x_0}}.
$$
Chamamos $f$ de \dterm{continua} sse $f$ é continua em cada $x \in X$.

%%}}}

\endsection
%%}}}

%%{{{ Connectedness 
\section Conexidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Completeness 
\section Completude.
%%%{{{ meta 
%%%}}}

%%{{{ df: complete_metric_space 
\definition complete.
%%%{{{ meta 
\label complete_metric_space
%%%}}}

Um espaço metrico em qual todas as seqüências Cauchy convergem
é chamado \dterm{completo}.

%%}}}

\endsection
%%}}}

%%{{{ Compactedness 
\section Compacidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: compact_metric_space 
\definition.
%%%{{{ meta 
%%%}}}

Um espaço métrico é chamado \dterm{compacto} sse é totalmente limitado
e completo.

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_metric_spaces 
\section Pouco de cats---categorias e espaços métricos.
%%%{{{ meta 
\label Categories_and_metric_spaces
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[simmonstopology],
\cite[kolmogorovfomin],
\cite[carothersreal].

``Baby Rudin''~\cite[babyrudin].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: General_topology 
\chapter Topologia geral.
%%%{{{ meta 
\label General_topology
%%%}}}

%%{{{ What is a topology? 
\section O que é uma topologia.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Topology constructions 
\section Construções de topologias.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Bases and subbases 
\section Bases e subbases.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Connectedness 
\section Conexidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Compactness 
\section Compactividade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Hausdorff_and_separation_axioms 
\section Hausdorff e axiomas de separação.
%%%{{{ meta 
\label Hausdorff_and_separation_axioms
%%%}}}

\endsection
%%}}}

%%{{{ Categories_and_topological_spaces 
\section Pouco de cats---categorias e espaços topológicos.
%%%{{{ meta 
\label Categories_and_topological_spaces
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: reals_uncountable_second_proof 
\problem Cantor \vs Reais: 1884.
%%%{{{ meta 
\label reals_uncountable_second_proof
\credits
    * Cantor
    ;;
\indexes
    * conjunto!perfeito
    * perfeito!conjunto     see: conjunto
    ;;
%%%}}}

Encontramos aqui a segunda demonstração de Cantor sobre a incontabilidade
dos reais, \cite[cantor1884].
Cantor definiu os conceitos de ponto de acumulação, conjunto fechado, conjunto
denso em todo lugar, e conjunto perfeito.
Demonstre que:
\elist i:
\li: qualquer conjunto perfeito e não vazio é incontável;
\li: o intervalo $[0,1]$ da reta real é perfeito;
\endelist
concluindo assim que o $[0,1]$ é incontável.

%%}}}

%%{{{ prob: Why does this proof (1884) fail for rationals? 
\problem.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que o
$\setst{q \in \rats}{a \leq q\leq b}$ também é incontável?

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[janichtopology],
\cite[simmonstopology],
\cite[munkrestopology],
\cite[willardtopology].

\cite[vickerstopology],
\cite[escardosynthetic].

\cite[johnstonestone].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Category_theory 
\chapter Teoria das categorias.
%%%{{{ meta 
\label Category_theory
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[babylawvere],
\cite[arbibmanesarrows],
\cite[papalawvere].

\cite[goldblatttopoi].

\cite[awodeycats],
\cite[barrwellscatscs],
\cite[joyofcats],
\cite[borceuxhandbook1].

\cite[riehlcats],
\cite[maclanecats].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Graph_theory 
\chapter Teoria de grafos.
%%%{{{ meta 
\label Graph_theory
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Umas introduções extensas em teoria dos grafos são
o clássico~\cite[bondymurty1976]
e o mais novo~\cite[ChartrandZhang].
Depois continua com~\cite[diestelgraph]
e~\cite[bondymurty2011].
Finalmente, um nível ainda mais avançado, \cite[bollobasmodern].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Universal_algebra 
\chapter Álgebra universal.
%%%{{{ meta 
\label Universal_algebra
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Lambda_calculus 
\chapter Lambda calculus.
%%%{{{ meta 
\label Lambda_calculus
%%%}}}

%%{{{ The untyped lambda calculus 
\section O $\lambda$-calculus não-tipado.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Faithfully representing mathematics 
\section Representando matemática fielmente.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Programming 
\section Programmando.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Recursion and fixpoints 
\section Recursão e fixpoints.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Functional programming revisited 
\section Programação funccional revisitada.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: what_does_this_lambda_term_with_minus_do 
\problem.
%%%{{{ meta 
\label what_does_this_lambda_term_with_minus_do
%%%}}}

Suponha que já temos definido um $\lambda$-term $\Lmac{minus}$,
que comporta corretamente, no sentido que:
$$
\align
\Lmac{minus}\ {\Lnum n}\ {\Lnum m}
&\Lfinto \knuthcases {
  \Lnum {n - m},   &se $n \geq m$\cr
  \Lnum {0},       &se $n < m$.
}
\endalign
$$
Explique o comportamento do termo
$$
\Lmac f  \asseq  \Llam n {n\ (\Lmac{minus}\ {\Lnum 1})\ {\Lnum 0}}
$$
quando for aplicado para um numeral de {\Church[numeral]}Church $\Lnum k$:
qual é a funcção $f : \nats\to\nats$ que o termo $\Lmac f$ computa?

\hint
Cuidado com {\Curry[currificação]}Curry.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[nederpeltgeuvers],
\cite[lecturesch].
\cite[hindleyseldinlambdacl],
\cite[krivinelambda].
\cite[barendregtlambda].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Combinatory_logic 
\chapter Lógica combinatória.
%%%{{{ meta 
\label Combinatory_logic
%%%}}}

%%{{{ Our first combinators 
\section Nossos primeiros combinadores.
%%%{{{ meta 
%%%}}}

%%{{{ df: first_combinators 
\definition.
%%%{{{ meta 
\label first_combinators
%%%}}}

$$
\xalignat4
    \cI\,x    &\Cto x     &   \cB\,x\,y\,z &\Cto x\,(y\,z) &   \cS\,x\,y\,z &\Cto x\,z\,(y\,z)&\cR\,x\,y\,z &\Cto y\,z\,x\\\\
    \cK\,x\,y &\Cto x     &   \cBp\,x\,y\,z&\Cto y\,(x\,z) &   \cW\,x\,y    &\Cto x\,y\,y     &\cV\,x\,y\,z &\Cto z\,x\,y\\\\
    \cM\,x    &\Cto x\,x  &   \cC\,x\,y\,z &\Cto x\,z\,y   &                                
\endxalignat
$$

%%}}}

%%{{{ x: some_equiv_to_I 
\exercise.
%%%{{{ meta 
\label some_equiv_to_I
%%%}}}

Mostre que o combinador
$\C S\ \C K\ (\C W\ (\C I\ \C B))$ comporta como o $\C I$.

%%}}}

%%{{{ x: another_equiv_to_I 
\exercise.
%%%{{{ meta 
\label another_equiv_to_I
%%%}}}

Mostre que o combinator
$\C C\ (\C W\ \C K)\ \C K\ \C W$ comporta como o $\C I$.

%%}}}

%%{{{ x: CL_define_Bp 
\exercise.
%%%{{{ meta 
\label CL_define_Bp
%%%}}}

Defina o $\cBp$ dos $\cI$, $\cM$, $\cB$, $\cC$.

%%}}}

%%{{{ x: CL_define_R 
\exercise.
%%%{{{ meta 
\label CL_define_R
%%%}}}

Defina o $\cR$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$.

%%}}}

%%{{{ x: CL_define_V 
\exercise.
%%%{{{ meta 
\label CL_define_V
%%%}}}

Defina o $\cV$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$, $\cR$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[mockingbird],
\cite[bimbocl],
\cite[hindleyseldinlambdacl].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Mathematical_logic 
\chapter Lógica matemática.
%%%{{{ meta 
\label Mathematical_logic
%%%}}}

%%{{{ Semantics of ZOL: worlds and models 
\section Semântica da ZOL: mundos e modelos.
%%%{{{ meta 
%%%}}}

%%{{{ note 
\note Mundos: valuação e sua extenção recursiva.
%%%{{{ meta 
%%%}}}

\TODO escrever.

%%}}}

%%{{{ note 
\note Tautologias.
%%%{{{ meta 
%%%}}}

\TODO escrever.

%%}}}

\endsection
%%}}}

%%{{{ Semantics of FOL: worlds and models 
\section Semântica da FOL: mundos e modelos.
%%%{{{ meta 
%%%}}}

%%{{{ note 
\note Mundos: estruturas, e valuação de variáveis.
%%%{{{ meta 
%%%}}}

\TODO escrever.

%%}}}

%%{{{ note 
\note Definição da verdade.

\TODO escrever.

%%}}}

%%{{{ note 
\note Tautologias.

\TODO escrever.

%%}}}

%%{{{ note 
\note Emulando constantes por funcções.

\TODO escrever.

%%}}}

%%{{{ note 
\note Emulando funcções por relações.

\TODO escrever.

%%}}}

%%{{{ note 
\note Modelos.

\TODO escrever.

%%}}}

%%{{{ note 
\note Como demonstrar que duas formulas (não) são equivalentes.

\TODO escrever.

%%}}}

%%{{{ note 
\note Independência de axiomas: o 5o axioma de Euclides.

\TODO escrever.

%%}}}

\endsection
%%}}}

%%{{{ Complete sets of connectives 
\section Conjuntos de conectivos completos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Classical and intuitionistic logic 
\section Lógica clássica e intuicionista.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Sobre lógica matemática:
\cite[kleeneIM],
\cite[curryfoundations];
\cite[kleenelogic],
\cite[smullyanfol];
\cite[corilascar1]~\&~\cite[corilascar2],
\cite[shoenfieldlogic],
\cite[bellmachover].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Computability_and_complexity 
\chapter Computabilidade e complexidade.
%%%{{{ meta 
\label Computability_and_complexity
%%%}}}

%%{{{ A surprisingly difficult question 
\section Uma questão surpresamente difícil.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Models of computation 
\section Modelos de computação.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Decision problems 
\section Problemas de decisão.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The halting problem 
\section O problema da parada.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Asymptotic notation 
\section A notação assintótica.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Analysis of algorithms 
\section Análise de algorítmos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Computational complexity 
\section Complexidade computacional.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[cutlandcomputability],
\cite[kleeneIM],
\cite[rogersrecursive].

\cite[kozenac], \cite[kozentc].

\cite[daviscu], \cite[davisccl], \cite[alicebook].

\cite[bellmachover: Cap.~7].

\cite[dpv],
\cite[jonescomputability].
\cite[gareyjohnson].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Theory_of_recursive_functions 
\chapter Teoria de funcções recursivas.
%%%{{{ meta 
\label Theory_of_recursive_functions
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[kleeneIM: Part~III],
\cite[shoenfieldrecursion],
\cite[ynmrandc],
\cite[rogersrecursive].

\cite[bellmachover: Cap.~6--8].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Formal_languages 
\chapter Linguagens formais.
%%%{{{ meta 
\label Formal_languages
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[alicebook],
\cite[kozenac],
\cite[davisccl: Part~2].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Intuitionistic_logic 
\chapter Lógica intuicionista.
%%%{{{ meta 
\label Intuitionistic_logic
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[heytingintuitionism].
\cite[dummettintuitionism].
\cite[proofsandtypes].
\cite[lecturesch].
\cite[bishopfca]~\&~\cite[bishopbridgesconstructive].
\cite[girardblindspot].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Proof_theory 
\chapter Teoria das provas.
%%%{{{ meta 
\label Proof_theory
%%%}}}

%%{{{ Systems à la Hilbert 
\section Sistemas à la Hilbert.
%%%{{{ meta 
\label Hilbert_style
\credits
    * Hilbert : estilo de sistema de prova
    ;;
%%%}}}

\endsection
%%}}}

%%{{{ Dedução natural 
\section Natural deduction.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Sequent calculus 
\section Sequent calculus.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[vonplatoelements],
\cite[bimboproof],
\cite[negrivonplatospt],
\cite[takeuti],
\cite[prawitz],
\cite[proofsandtypes],
\cite[olthdem],
\cite[kleeneIM].
\cite[lecturesch].
\cite[girardblindspot].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Linear_logic 
\chapter Lógica linear.
%%%{{{ meta 
\label Linear_logic
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[girardllss].
\cite[girardblindspot].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Type_theory 
\chapter Teoria dos tipos.
%%%{{{ meta 
\label Type_theory
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[nederpeltgeuvers].
\cite[proofsandtypes].
\cite[programmingmltt].
\cite[piercetapl].
\cite[hott].

\endfurther
%%}}}

\endchapter
%%}}}

\endinput

