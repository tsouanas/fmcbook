%%{{{ [vim] 
% vim:foldmarker=%{{{,%}}}
% vim:foldmethod=marker
% vim:foldcolumn=7
%%}}}
%% fmcmain.tex
%% author: Thanos Tsouanas <thanos@tsouanas.org>
%% Copyright (c) 2016--2024 Thanos Tsouanas
%% All rights reserved.

%%{{{ chapter: Introductions 
\chapter Introduções.
%%%{{{ meta 
\label Introductions
%%%}}}

%%{{{ intro 
\chapintro
Sim, plural:
neste capítulo intoduzo todas as noções e idéias básicas com
a profundidade mínima---e logo com umas mentiras
também, e logo com uns erros---para começar aprofundar
nos próximos capítulos.
Se encontrar alguma notação, algum termo, símbolo, processo, etc.,
que tu não reconhece, continue lendo;
o importante é entender bem as idéias básicas.
E os detalhes?  Depois.
%%}}}

%%{{{ Propositions_vs_objects 
\section Proposições \vs objetos.
%%%{{{ meta 
\label Propositions_vs_objects
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Olhando para matemática de longe, podemos enxergar dois tipos principais:
\emph{proposições} e \emph{objetos}
(também \emph{indivíduos}).\foot
Para o leitor que já sabe o que é um \dterm{sintagma nominal}
em lingüística, as expressões que denotam objetos são exatamente
os sintagmas nominais.
\toof
O primeiro e mais elementar desafio do meu leitor seria entender
essas duas noções, no ponto que nunca confundiria uma por outra.

%%}}}

%%{{{ eg: object_phrase_examples 
\example Objetos.
%%%{{{ meta 
\label object_phrase_examples
%%%}}}

Uns exemplos de frases que denotam objetos:
\elist:
\li: Brasil
\li: a mãe do Bart
\li: $(1 + 1)^3$
\li: Évariste Galois
\li: 8
\li: Matemática
\endelist
Não faz sentido supor nenhuma delas, nem duvidar, nem tentar demonstrar,
nem nada disso.  Não têm verbo!  Imagine alguém dizer:
\quote
\wq{Eu acho que $(1+1)^3$.}
\endquote
Tu acha que $(1+1)^3$ o quê?!

%%}}}

%%{{{ eg: proposition_phrase_examples 
\example Proposições.
%%%{{{ meta 
\label proposition_phrase_examples
%%%}}}

Uns exemplos de frases que denotam proposições:
\elist:
\li: Brasil é um país na Europa.
\li: A mãe do Bart fala português.
\li: $(1 + 1)^3 = 3^2-1$
\li: Galois morreu baleado.
\li: $8 \leq 12$
\li: Matemática estuda cavalos.
\endelist
Cada uma dessas frases, tem um verbo, e afirma algo completo.
Não importa a veracidade dessas proposições, o importante aqui é
entender que essas frases realmente são proposições.
Faz sentido afirmá-las, questioná-las, demonstrá-la, refutá-las, etc.

%%}}}

%%{{{ warning: expressions_that_denote_prop_not_always_do_so 
\warning Expressões que denotam proposições.
%%%{{{ meta 
\label expressions_that_denote_prop_not_always_do_so
%%%}}}

Umas expressões matemáticas que normalmente denotam proposições
podem assumir um papel diferente dependendo do contexto.
Por exemplo, \symq{$x=y$} normalmente denota a proposição
\dq{$x$ é igual ao $y$}; mas se o contexto já tem seu verbo
principal, o papel da \symq{$x=y$} pode mudar:
\math
\textwq{Por outro lado, {\xlthole} é primo e logo \dots}
\endmath
Aqui, pelo contexto, precisamos algo que denota um objeto:
não faria sentido afirmar que uma proposição é primo.
Nesse caso a expressão \symq{$x=y$} pode ser lida como
qualquer uma das:
\mathcol
x = y & :\quad\text{``\aR{$x$, que é igual a $y$,}''} \\
x = y & :\quad\text{``\aB{$x$ é igual ao $y$, e $y$}''}.
\endmathcol
Assim, a frase
\math
\textwq{Por outro lado, $2^n + 1 = 5$ é primo e logo \dots},
\endmath
pode ser lida, respectivamente, como qualquer uma das:
\math
\textwq{Por outro lado, \aR{$2^n + 1$, que é igual a $5$,} é primo e logo \dots} \\
\textwq{Por outro lado, \aB{$2^n + 1$ é igual a $5$, e $5$} é primo e logo \dots}.
\endmath
A mesma coisa vale sobre outras notações que vamos encontrar depois:
\symq{$x \in A$}, \symq{$A \subset B$}, \symq{$f : A \to B$}, etc.

%%}}}

\endsection
%%}}}

%%{{{ Equality_vs_equivalence 
\section Igualdade \vs equivalência.
%%%{{{ meta 
\label Equality_vs_equivalence
%%%}}}

%%{{{ equal or equivalent? 
\note Igual ou equivalente?.
%%%{{{ meta 
\indexes
    * sse
    ;;
%%%}}}

Usamos os símbolos \symq{$=$} e \symq{$\iffsymbol$} para afirmar uma relação especifica entre as
coisas que aparecem nos dois lados deles.
Só que os \emph{tipos} de coisas são diferentes para cada símbolo.
O \symq{$=$} fica entre \emph{objetos},
o \symq{$\iffsymbol$} entre \emph{proposições}.
\eop
Usamos \symq{$=$} para dizer que os objetos nos seus lados
são \emph{iguais}, ou seja, as coisas escritas nos seus dois lados,
denotam o mesmo objeto.
Por exemplo \sq{$1+5$} denota um número e \sq{$3$}
também denota um número, e escrevendo
$$
1 + 5 = 3
$$
estamos afirmando---erroneamente nesse caso---que as duas
expressões denotam o mesmo número.
Se tivesse escrito \sq{$1 + 5 = 3 + 3$} teria sido uma afirmação correta.
Pronunciamos o \sq{$A = B$} como \utter{$A$ é igual ao $B$}.
\eop
Usamos \symq{$\iffsymbol$} para dizer que as proposições nos seus lados são
\emph{logicamente equivalentes}, ou seja, são ambas verdadeiras ou ambas falsas.
Escrevemos então
$$
\text{$p$ é primo e $p>2$}
\iff
\text{$p$ é um primo ímpar}
$$
e nesse caso essa é uma afirmação correta.
Note que não sabemos dizer qual é o caso aqui: são ambas verdadeiras, ou ambas falsas?
Não sabemos qual número é denotado pela variável $p$, mesmo assim as afirmações
são equivalentes.
Pronunciamos o \sq{$A \iff B$} como \utter{$A$ é equivalente a $B$}
ou \utter{$A$ se e somente se $B$}, usando a abreviação \dterm{sse}
para a frase \wq{se e somente se}.
\eop
Entendemos o \symq{$\impliessymbol$} como uma abreviação de
\wq{implica} e o \symq{$\impliedbysymbol$} como uma abreviação de
\wq{é implicado por}.
Podemos ler as expressões seguintes assim também:
$$
\xalignat2
A \implies B   & :\quad\textwq{se $A$ então $B$} &
A \iff B       & :\quad\textwq{$A$ se e somente se $B$}.
\endxalignat
$$

%%}}}

%%{{{ x: which_is_if_and_which_is_only_if 
\exercise.
%%%{{{ meta 
\label which_is_if_and_which_is_only_if
%%%}}}

Já que \symq{$\iffsymbol$} corresponde à frase \wq{se e somente se},
faz sentido pensar que uma das setinhas envolvidas
(\symq{$\impliessymbol$} e \symq{$\impliedbysymbol$})
corresponde na frase \wq{se} e a outra na \wq{somente se}.
Qual é qual?

\solution
$$
\align
A \implies   B & :\quad\text{$A$ somente se $B$}\\
A \impliedby B & :\quad\text{$A$ se $B$}
\endalign
$$

%%}}}

%%{{{ x: which_is_nec_and_which_is_suf 
\exercise.
%%%{{{ meta 
\label which_is_nec_and_which_is_suf
%%%}}}

Mesma pergunta, agora lendo o \symq{$\iffsymbol$}
como \wq{é suficiente e necessário para}.
Uma direção corresponde ao \wq{suficiente} outra ao \wq{necessário}.
Qual é qual?

\solution
$$
\align
A \implies   B & :\quad\text{$A$ é suficiente para $B$}\\
A \impliedby B & :\quad\text{$A$ é necessário para $B$}.
\endalign
$$

%%}}}

%%{{{ relevance logics 
\note Lógicas de relevância.
%%%{{{ meta 
\label relevance_logics
\defines
    * lógica!de relevância
    ;;
%%%}}}

Note que seguindo nossa interpretação de implicação e equivalência nos permite
corretamente afirmar implicações e equivalências entre
proposições que não tem nada a ver uma com outra.
Por exemplo, seria correto afirmar:
\tlist:
\li: $0 = 1$ se e somente se existe número natural maior que todos os outros.
\li: $1 + 1 = 2 \iff \text{Creta é uma ilha grega}$.
\li: Se Brasil é um país na Europa, então 4 é um número par.
\li: Se $4$ é um número par, então Grécia é um país na Europa.
\endtlist
Felizmente, afirmações desse tipo raramente aparecem em matemática.
Lógicas que tomam cuidado para proibir
implicações entre proposições irrelevantes são chamadas
\dterm{lógicas de relevância} (por motivos óbvios) mas não
vamos estudá-las aqui.

%%}}}

%%{{{ remark: subjuntivo 
\remark Subjuntivo.
%%%{{{ meta 
\label subjuntivo
\indexes
    * subjuntivo
    * intuicionismo
    * constructivismo   see: intuicionismo
    ;;
%%%}}}

Considere a frase
$$
\textwq{$n$ é par se e somente se existir inteiro $k$ tal que $n = 2k$}.
$$
Usar o \emph{subjuntivo} \wq{existir} aqui não faz muito sentido:
não se trata de algo que futuramente pode acontecer ou não.
Ou existe (hoje, ontem, sempre) tal inteiro $k$ ou não existe;
daí seria melhor escrever usando o verbo no \dq{modo normal}:\foot
também conhecido como \emph{presente do indicativo}
\toof
$$
\textwq{$n$ é par se e somente se existe inteiro $k$ tal que $n = 2k$}.
$$
Mas há um ponto de vista filosófico
(que tá bem alinhado com a lógica constructiva que analisaremos logo)
onde esse subjuntivo faz até sentido numa
maneira que pode aparecer meio engraçada:
\emph{até o momento que um ser humano vai chegar e mostrar pra mim
um tal inteiro $k$,
eu não vou considerar nada sobre a paridade do $n$}.
Se alguém me perguntar \emph{\wq{$n$ é par ou $n$ não é par?}},
eu, sendo intuicionista, vou simplesmente responder: \emph{\wq{Eu não sei.}}.
Entretanto, o matemático clássico responderia \emph{\wq{Sim.}}.

%%}}}

\endsection
%%}}}

%%{{{ Type_errors 
\section Type erros.
%%%{{{ meta 
\label Type_errors
%%%}}}

%%{{{ What is it? 
\note O que é?.
%%%{{{ meta 
\defines
    * mal-tipado
    * type error
    ;;
%%%}}}

Um \dterm{type error} ocorre quando usamos uma expressão cujo tipo é
incompatível com o tipo esperado pelo contexto.
Esse tipo de erro é muito comum quando começamos aprender matemática
e infelizmente é completamente destruidor: com um type error nosso texto
\emph{nem compila}, nem chega a dizer algo para ter chances de ser avaliado
para sua corretude.
Um texto com type errors não chega a ter significado nenhum.
Chamamos de \dterm{mal-tipada} uma expressão que contem type errors.

%%}}}

%%{{{ Type errors 
\note O type error mais grave.
%%%{{{ meta 
%%%}}}

Claramente o type error mais gritante seria confundir objeto com proposição ou
vice versa, pois como discutimos (\reftag[Propositions_vs_objects])
são os grupos mais distantes.

%%}}}

%%{{{ eg: biggest_type_error_eg 
\example.
%%%{{{ meta 
\label biggest_type_error_eg
%%%}}}

Todas as frases seguintes têm o type error mais grave:
confusão entre proposição e objeto:
\tlist:
\li (1): $(x+y)^2 \iff x^2 + 2xy + y^2$.
\li (2): $x(a-(b+c)) = xa - x(b + c) \implies xa - xb - xc$.
\li (3): Concluimos que $(A \subset B) = (B \subset A)$.
\li (4): Suponha $n$.  Vamos demonstrar que $n+1$.
\endtlist
(1) Temos uma suposta equivalência entre dois objetos.
O \sq{$\iffsymbol$} tava esperando ver (receber) proposições
nos seus lados, mas recebeu objetos.
(2) No lado esquerdo da implicação temos uma proposição,
(isso tá OK), mas no seu lado direito aparece um objeto.
Não faz sentido implicar um objeto:
\dialogue
\say Se chover amanhã, então Maria.
\say \dots então Maria o quê?!
\enddialogue
(3) Aqui aparece igualdade entre duas proposições em vez de objetos.
(4) Como assim supor um objeto?  E como assim demonstrar um objeto?
Supomos proposições, e demonstramos suposições.  O que significa
supor Alex?  O que significa demonstrar o $5$?

%%}}}

%%{{{ x: biggest_type_error_exercise 
\exercise.
%%%{{{ meta 
\label biggest_type_error_exercise
%%%}}}

Mude cada uma das frases do~\ref[biggest_type_error_eg]
para resolver o type error.
Não se preocupe com a \emph{veracidade}.

\solution
\tlist:
\li (1): $(x+y)^2 = x^2 + 2xy + y^2$.
\li (2): $x(a-(b+c)) = xa - x(b + c) = xa - xb - xc$.
\li (3): Concluimos que $(A \subset B) \iff (B \subset A)$.
\li (4): Suponha que $n$ é lindo.  Vamos demonstrar que $n+1$ é feio.
\endtlist

%%}}}

%%{{{ Refining_further 
\note Refinando mais.
%%%{{{ meta 
\label Refining_further
%%%}}}

Podemos subdividir os objetos em tipos também, por exemplo:
números, pessoas, conjuntos de pessoas, palavras, cidades, funções, programas, etc.
Sobre proposições, vamos fazer algo parecido no \ref[Proofs]:
conjunções, disjunções, implicações, negações, etc.

%%}}}

\endsection
%%}}}

%%{{{ Definitions 
\section Definições.
%%%{{{ meta 
\label Definitions
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tanto em matemática quanto fora de matemática, para facilitar nosso pensamento
e a comunicação com outras pessoas introduzimos novos termos, e novas notações
de certos conceitos, assim evitando a necessidade de descrever em todo detalhe
a mesma idéia repetidamente.

%%}}}

%%{{{ From mind to paper 
\note De mente para papel.
%%%{{{ meta 
%%%}}}

O processo de definir algo começa na nossa cabeça, onde
identificamos---ou pelo menos, achamos que identificamos---um conceito
que consideramos interessante e que merece seu próprio nome, sua própria
notação, etc.
Depois disso começa o processo de \emph{traduzir} nossa idéia, do mundo
mental para uma linguagem, freqüentemente sendo uma linguagem natural
pouco enriquecida com notação, termos, convenções, etc., para atender
as necessidades de matemática.
Também precisamos de \emph{escolher um nome bonito} para nossa definição,
uma notação conveniente e útil.

%%}}}

%%{{{ defiff_defeq (definition vs proposition) 
\note Definição \vs proposição.
%%%{{{ meta 
\label defiff_defeq
\defines
    * ~A \defiff ~B -- $A$ tá sendo definida para ser equivalente a $B$
    * ~A \defeq  ~B -- $A$ tá sendo definido para ser igual a $B$
    ;;
%%%}}}

Para enfatizar que estamos definindo algo, e não afirmando uma equivalência
ou uma igualdade, decoramos o símbolo correspondente por um \symq{$\deftag$}:
usamos \sq{$A \defiff B$} para \emph{definir a proposição} $A$ para significar
a mesma coisa com a proposição $B$;
usamos \sq{$A \defeq B$} para \emph{definir o objeto} $A$ como um novo nome
do objeto $B$.
Olhe nisso:
$$
\xalignat2
&\tubrace {\tobrace A {(prop)} \defiff \tobrace B {\phantom(prop\phantom)}} {definição} &
&\tubrace {\tobrace A {prop}   \iff    \tobrace B {prop}} {afirmação}.
\endxalignat
$$
Na \sq{$A \defiff B$} estamos \emph{definindo algo:} a expressão $A$, que vai acabar
tendo o significado da proposição $B$, logo apos dessa definição.
Ou seja, na esquerda do \symq{$\defiffsymbol$} temos uma \dterm{futura-proposição},
na sua direita temos uma proposição mesmo.
Na \sq{$A \iff B$}, estamos \emph{afirmando algo:}
que as proposições $A,B$ são equivalentes.
Necessariamente então ambas já têm significados conhecidos.
Similarmente sobre as
$$
\xalignat2
&\tubrace {\tobrace A {(obj)} \defeq \tobrace B {obj}} {definição} &
&\tubrace {\tobrace A {obj}   =      \tobrace B {obj}} {afirmação}:
\endxalignat
$$
a primeira é uma definição, a segunda a afirmação que $A,B$ são iguais.

%%}}}

%%{{{ eg: with_and_without_def 
\example.
%%%{{{ meta 
%%%}}}

Qual a diferença entre as duas expressões?:
$$
\align
\text{$n$ é ímpar} &\defiff \text{$n = 2k + 1$ para algum inteiro $k$}\\
\text{$n$ é ímpar} &\iff    \text{$n = 2k + 1$ para algum inteiro $k$}.
\endalign
$$

\solution.
A primeira linha \emph{é uma definição}.
Estamos \emph{definindo} o que significa \wq{ser ímpar},
dizendo como traduzir a afirmação \wq{$n$ é ímpar} para uma
outra afirmação que supostamente entendemos.
A segunda linha \emph{é uma afirmação}:
afirma que as duas proposições nos seus lados são equivalentes.
Ou seja, é algo que pode ser demonstrado ou refutado.
E para usar o \symq{$\iffsymbol$} com certeza seus dois lados precisam ser
proposições bem-definidas.

%%}}}

%%{{{ remark: conventions_with_defs 
\remark Convenções.
%%%{{{ meta 
\label conventions_with_defs
%%%}}}

Essa ênfase com o \symq{$\deftag$} não é obrigatória, e muitas vezes
o contexto é suficiente para deixar claro que se trata de definição
e não de afirmação.
Note que por convenção a coisa sendo definida vai no lado esquerdo
do símbolo que decoramos com esse \symq{$\deftag$} e a sua definição
fica no lado direito.
Então mesmo que nos símbolos \symq{$=$} e \symq{$\iffsymbol$} podemos
trocar seus lados, nos \symq{$\defeq$} e \symq{$\defiffsymbol$} não!

%%}}}

%%{{{ examples_and_nonexamples 
\note Exemplos e nãœxemplos.
%%%{{{ meta 
\label examples_and_nonexamples
\defines
    * exemplo
    * nãœxemplo
    ;;
%%%}}}

Talvez já temos vários \dterm{exemplos} de objetos que satisfazem nossa
definição, ou nem sabemos se existem tais objetos!  Observe então que
para definir algo não é necessário---e com certeza nem suficiente!---mostrar
exemplos de objetos.
Mesmo assim, quando escrevemos um texto matemático e queremos ajudar nosso
leitor confirmar seu entendimento da nossa definição, podemos dar uns
exemplos e/ou uns \dterm{nãœxemplos} (ou seja, objetos que \emph{não}
satisfazem nossa definição).
Mas é importante entender que a natureza deles nunca é essencial
para a definição, e que \emph{eles não fazem parte da definição}.
É apenas uma ferramenta pedagógica.

%%}}}

%%{{{ eg: examples_and_nonexamples_example
\example.
%%%{{{ meta 
\label examples_and_nonexamples_example
%%%}}}

As afirmações seguintes são todas corretas:
\tlist:
\li: $41$ é um exemplo de: número ímpar\foot
sim, acabei de usar a palavra exemplo para
dar um exemplo para ajudar entender o que
significa exemplo
\toof
\li: $18$ é um exemplo de: múltiplo de $3$
\li: $16$ é um nãœxemplo de: múltiplo de $3$
\li: $16$ é um nãœxemplo de: número ímpar
\endtlist
Mas não contam como definição do que significa ser ímpar,
ou ser múltiplo de $3$.

%%}}}

%%{{{ beware: nonexample_vs_counterexample 
\beware nãœxemplo \vs contraexemplo.
%%%{{{ meta 
\label nonexample_vs_counterexample
\defines
    * contraexemplo
    ;;
%%%}}}

Não confunda as palavras \wq{nãœxemplo} e \wq{contraexemplo}.
Um \dterm{nãœxemplo} é algo que \emph{não} satisfaz uma definição,
que não tem uma propriedade, etc.
Por outro lado, quando usamos o termo \dterm{contraexemplo}?
Apenas quando estamos tentando \emph{refutar} uma afirmação da forma
\wq{todos os tais $x$ têm tal propriedade}.
Qualquer tal objeto $x$ que não possui essa propriedade
conta como contraexemplo dessa afirmação.
Isso vai ficar mais claro na~\ref[Examples_and_counterexamples]
do~\ref[Proofs] (onde estudamos demonstrações).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Dando uma definição de algum termo, notação, etc., precisamos deixar claro
o que exatamente eles denotam.
Considere como exemplo a noção de \emph{primos gêmeos} que aparece em
teoria dos números:

%%}}}

%%{{{ eg: eg_def_of_twin_primes 
\example.
%%%{{{ meta 
\label eg_def_of_twin_primes
%%%}}}

Considere a definição:
\quote
\wq{Dois números $p,q$ são \dterm{primos gêmeos} sse
$p,q$ são primos e $\abs{p-q} = 2$.}
\endquote
Dados então dois números $a,b$, sabemos o que a afirmação
``$a,b$ são primos gêmeos''
significa:
$$
\text{$a,b$ são primos e $\abs{a-b} = 2$}.
$$

%%}}}

%%{{{ context_of_a_definition 
\note Contexto.
%%%{{{ meta 
\label context_of_a_definition
%%%}}}

Para definir qualquer coisa precisamos primeiramente deixar claro o
\dterm{contexto}.  No~\ref[eg_def_of_twin_primes] o contexto é:
$$
\align
p &\eqtype \text{número} \\
q &\eqtype \text{número}.
\intertext{Porém, se a definição fosse <<dois números primos $p,q$ são \dterm{primos gêmeos} sse $\abs{p-q} = 2$>> o contexto seria pouco diferente:}
p &\eqtype \text{número primo} \\
q &\eqtype \text{número primo}.
\endalign
$$

%%}}}

%%{{{ what_is_tijolo 
\note O que é tijolo?.
%%%{{{ meta 
\label what_is_tijolo
\defines
    * tijolo
    ;;
%%%}}}

No meu primeiro semestre como professor no Brasil, em algum momento---%
não lembro porquê---um aluno na sua explicação usou a palavra ``tijolo''.
O problema é, que eu nunca tinha encontrado essa palavra antes; então
perguntei ao meu aluno:
\spoken
\wq{O que é tijolo?}
\endspoken
Neste momento o aluno sentiu um desafio:
como você explica o que é um tijolo para um gringo?\foot
O aluno não falava inglês---nem grego!---e logo a gente não tinha
uma linguagem ``fallback'' para usá-la e tirar minha dúvida.
\toof
Ele precisou dar uma \emph{definição} dessa palavra.
A resposta dele foi
\spoken
\wq{Tijolo é tijolo, ué!}
\endspoken
\dots E isso não me ajudou muito.

%%}}}

%%{{{ Circular definition 
\note Definições circulares.
%%%{{{ meta 
\indexes
    * tijolo    see: tijolo
    ;;
\defines
    * definição circular
    ;;
\credits
    * Knuth : index loop
    ;;
%%%}}}

A resposta do aluno acima é um exemplo duma \dterm{definição circular}.
$$
\tikzpicture
\node (word) at (0,0) {tijolo};
\draw[-Latex] (word.-45) arc (-150:150:6mm);
\endtikzpicture
$$
Tenho então uma questão pra ti:
\spoken
\wq{O que é um conjunto?}
\endspoken
Uma resposta razoável neste momento seria a seguinte:
\spoken
\wq{Um conjunto é uma colecção de objetos.}
\endspoken
E, se eu sei o que significa \wq{colecção} eu vou entender
o que é um conjunto e vou ficar feliz; mas caso contrário, eu vou perguntar:
\spoken
\wq{E o que é uma colecção?}
\endspoken
Provavelmente aquele aluno que me ensinou o que é ``tijolo'' ia responder:
\spoken
\wq{Uma colecção é um conjunto de objetos.}
\endspoken
Aqui o problema é o mesmo com o ``tijolo'', só que um tiquinho menos óbvio,
pois o cíclo aqui pelo menos tem duas setinhas:
$$
\tikzpicture
\node[inner sep=2pt, outer sep=2pt] (word1) at (-1,0) {conjunto};
\node[inner sep=2pt, outer sep=2pt] (word2) at (1,0)  {colecção};
\draw (word1) edge[out=315,in=225,-Latex] (word2);
\draw (word2) edge[out=135,in=45, -Latex] (word1);
\endtikzpicture
$$
Pensando numa forma computacional, entendemos essa definição como um
programa cuja execução caiu num \emph{loop infinito}.
Como ele nunca termina, nos nunca sabemos se um objeto satisfaz
ou não essa definição.

%}}}

%%{{{ teaser: recursive_definitions_teaser 
\teaser Definições recursivas.
%%%{{{ meta 
\label recursive_definitions_teaser
%%%}}}

Alguém pode pensar que o problema com as definições circulares é que a palavra
que estamos definindo apareceu na sua própria definição.
Isso \emph{não} é o caso!
Numa \dterm{definição recursiva} a palavra que queremos definir parece aparacer
dentro da sua própria definição, e mesmo assim, não estamos caindo num loop infinito,
e realmente conseguimos definir o que queremos.
Mas bora deixar esse assunto para depois, quando com pouco mais experiência
vamos trabalhar com recursão.

%%}}}

%%{{{ Errors in definitions 
\note Erros em definições.
%%%{{{ meta 
%%%}}}

Pode ser que para algum erro uma suposta definição acaba não definindo
nada pois seu texto não conseguiu descrever nenhum conceito.
Ou, pode ser que acabou definindo algo mesmo, só que esse algo não é
o que queríamos definir!

%%}}}

%%{{{ eg: wrong_def_par_that_does_not_compile 
\example definição errada que nem compila.
%%%{{{ meta 
\label wrong_def_par_that_compiles
%%%}}}

Considere a definição seguinte:
\quote
Definição.
Seja $n$ um inteiro.
Chamamos o $n$ de \dterm{par} se e somente se $n = 2k$.
\endquote
Essa definição \emph{nem compila}.
Por quê?

\solution.
O compilador reclamaria com a mensagem
\quote
Usou \symq{$k$} mas \symq{$k$} não está declarado aqui.
\endquote
Para esclarecer mais a situação, vamos testar a afirmação
\wq{$6$ é par}.
Abrindo a definição temos que \wq{$6$ é par} significa \wq{$6 = 2k$}.
Ou seja, basta verificar se realmente $6 \askeq 2k$.
Mas nessa afirmação está sendo referido um objeto \sq{$k$} que
nunca foi declarado (nem definido).  \emph{Quem é esse $k$?}
Ninguém sabe.  Não faz sentido então afirmar nada que envolve \sq{$k$}.

%%}}}

%%{{{ eg: wrong_def_par_that_compiles 
\example definição errada que compila.
%%%{{{ meta 
\label wrong_def_par_that_compiles
%%%}}}

Considere a definição seguinte:
\quote
Definição.  Seja $n$ um inteiro.  Chamamos o $n$ de \dterm{par} se e somente se
$n = 2k$ para qualquer inteiro $k$.
\endquote
Essa definição ``compila''.
Mas o conceito que foi definido não é o que o seu escritor tinha no coração dele.

%%}}}

%%{{{ x: check_wrong_def_par_that_compiles 
\exercise.
%%%{{{ meta 
\label check_wrong_def_par_that_compiles
%%%}}}

Por quê?
Qual o problema com a definição do~\ref[wrong_def_par_that_compiles]?
Como podemos consertar?

\solution
Essa definição não aceita objetos que deveria aceitar.
Por exemplo, o $2$ não é um número par segundo essa definição,
pois, lembrando:
$$
\text{$6$ é par} \intiff \text{para todo inteiro $k$, $6=2k$}.
$$
Para \emph{refutar} a afirmação que $6$ é par então, basta achar
um inteiro $k$ tal que $6 \neq 2k$.
Tome $k \asseq 1$ e observe que $6 \neq 2\ntimes 1$ e pronto,
o $6$ acabou sendo um número não par!
Para consertar a definição basta trocar o ``para todo''
por ``para algum''!

%%}}}

%%{{{ What is ``well-defined''? 
\note O que é ``bem-definido''?.
%%%{{{ meta 
%%%}}}

Essa frase deixa muita gente confusa em matemática.
Realmente fica estranho pedir para teu leitor demonstrar, por exemplo,
que um tal símbolo, notação, função, não foi bem-definida.
Como assim?
Se não foi bem-definida, como que estamos usando sua notação então?
A idéia nesse caso seria explicar exatamente o porquê que o compilador
reclamaria na sua definição.  Em geral, o erro fica na falta de determinicidade:
\emph{fingimos} que determinamos um certo objeto que nomeamos numa certa forma,
mas na verdade deixamos muita liberdade (ambigüidade) no nosso leitor,
pois vários objetos satisfazem essa condição, então nossa descripção \emph{não
determinou} um objeto.  No outro extremo, pode ser que nenhum objeto satisfaz
a condição, então é como se a gente tentou dar nome para algo que nem existe.

%%}}}

%%{{{ The importance of definitions 
\note A importância das definições.
%%%{{{ meta 
%%%}}}

Superficialmente alguém pode pensar que \dq{não existe definição errada}.
Ficando no pé da letra seria difícil convencer esse alguém que ele não
tem razão.  Mas muitas vezes dar as definições \dq{certas} é o que te
permite demonstrar um teorema difícil que seria inatacável sem elas.
Uma definição deve ser escrita na maneira mais simples possível para entender e usar.
E deve capturar um conceito interessante.
Tendo as definições corretas, raciocinamos melhor,
e conseguimos formular nosso pensamento numa forma
curta e entendível.
Com prática, vamos conseguir identificar quando faria sentido definir
um termo novo, dar uma definição elegante e correta, e escolher
um nome bom, e se for útil uma notação conveniente também.

%%}}}

%%{{{ Comparison with programming 
\note Comparação com programação.
%%%{{{ meta 
\defines
    * entry point
    ;;
%%%}}}

Enquanto programando, para muitos programadores a parte mais
desafiadora (e divertida) é \emph{inventar os nomes corretos}\foot
Ou até \emph{descobrir os nomes escondidos},
dependendo do caso e do ponto de vista, para enfatizar!
\toof
para partes dos seus programas.
Em muitas linguagens existe um \dterm{entry point} para teu programa, onde a execução começa.
Por exemplo, em C isso seria o corpo da função $\code{main}$.
Seria bizarro (no mínimo) tentar escrever um programa inteiro apenas
usando os primitivos da C dentro dessa função $\code{main}$.
Felizmente as linguagens oferecem ferramentas de abstracção para
o programador---umas bem mais que outras---e assim começamos definindo
nossos próprios conceitos: funções, variáveis, constantes, tipos, etc.

%%}}}

\endsection
%%}}}

%%{{{ Intension_vs_extension 
\section Intensão \vs extensão.
%%%{{{ meta 
\label Intension_vs_extension
%%%}}}

%%{{{ intension vs extension 
\note.
%%%{{{ meta 
\defines
    * extensão
    * intensão
    ;;
%%%}}}

Muitas vezes é útil diferenciar entre a intensão e a extensão de expressões que denotam tanto objetos quanto proposições.
Considere a frase \emph{a mãe de Thanos}, que denota a minha mãe mesmo, \emph{Styliani}.
Agora vamos supor para esse exemplo que minha mãe é \emph{a reitora da UFRN}.
Temos três expressões que denotam o mesmo objeto: mainha.
Alguém diria que
$$
{\mathit{a mãe de Thanos}}
\;=\;
{\mathit{a reitora da UFRN}}
\;=\;
{\mathit{Styliani}}.
$$
Realmente a \dterm{extensão} dessas três frase é a mesma.
Mas a \dterm{intensão} é diferente: é uma coisa ser a mãe de Thanos,
outra coisa ser a reitora da UFRN, e outra coisa ser a Styliani.
Para enfatizar que não faz sentido tratar as três frases como \emph{iguais},
considere as frases seguintes:
\quote
\wq{Eu não sabia que a mãe de Thanos é a reitora da UFRN.}\CR
\wq{A mãe de Thanos é Styliani, mas não sei quem é a reitora da UFRN.}
\endquote
Agora, supondo que realmente são iguais essas frases, tente trocar
uma por outra e tu vai descobrir que o significado muda bastante;
uns exemplos:
\quote
\wq{Eu não sabia que Styliani é a mãe de Thanos.}\CR
\wq{Eu não sabia que a mãe de Thanos é a mãe de Thanos.}\CR
\wq{A reitora da UFRN é Styliani, mas não sei quem é a mãe de Thanos.}
\endquote
As extensões são iguais pois todas essas frases denotam o mesmo objeto, mas as intensões não.
Nesse exemplo usei um objeto (Styliani) para explicar a diferença entre igualdade intensional e extensional.
A mesma idéia aplica se entre \emph{equivalência} intensional e extensional.
Considere a equivalência entre as proposições que cada uma afirma algo sobre um número $x$:
$$
\text{$x$ é primo e par}
\iff
\text{uma molécula de água tem $x$ átomos de hidrogênio}
\iff
\text{$x = 2$}
$$
Sim, as proposições são equivalentes extensionalmente:
ambas são verdadeiras ou ambas são falsas.
Mas a intensão de cada proposição é bem diferente.
Considere dado um número $x$.
Para decidir se a primeira é verdadeira precisamos saber
o que significa número primo, o que significa número par,
e também saber responder sobre nosso $x$ se satisfaz ambas
essas definições.
Para a segunda, precisamos saber pouca coisa de química:
$\mathrm H_2\mathrm O$ é a molécula da água.
Finalmente para a terceira não precisamos nenhum conhecimento
(além de reconhecer a constante \symq{$2$} como um nome do número dois),
pois afirma diretamente que $x$ é o número $2$.

%%}}}

%%{{{ notation: intensional_notation 
\notation.
%%%{{{ meta 
\label intensional_notation
\defines
    * ~A = ~B         -- igualdade extensional
    * ~A \iff ~B      -- equivalência extensional
    * ~A \inteq ~B    -- igualdade intensional
    * ~A \intiff ~B   -- equivalência intensional
    ;;
%%%}}}

Em matemática os símbolos \symq{$=$} e \symq{$\iffsymbol$}
são usados na maneira extensional:
\symq{$A = B$} significa que $A$ e $B$ denotam o mesmo objeto;
\symq{$A \iff B$} significa que as proposições $A,B$ são logicamente equivalentes.
Para diferenciar entre intensional e extensional,
adicionamos mais uma linha nos símbolos correspondentes:
usamos \symq{$\inteq$} para igualdade intensional
e \symq{$\intiffsymbol$} para equivalência intensional.

%%}}}

%%{{{ remark: definition_and_intension 
\remark Definição e intensão.
%%%{{{ meta 
\label definition_and_intension
%%%}}}

A partir duma definição
$$
A \defiff B
$$
as expressões $A$ e $B$ não são apenas extensionalmente (logicamente) equivalentes,
mas intensionalmente também: definimos o $A$ para ter o próprio significado (intensão) de $B$.
Então depois da definição acima claro que temos
$$
A \iff B
$$
mas, ainda mais, temos
$$
A \intiff B.
$$
Parece então que em vez de \symq{$\defiffsymbol$} deveriamos decorar
o \symq{$\intiffsymbol$} com o \symq{\deftag}
mas não precisamos fazer isso pois já o fato que é uma definição implica
que as expressões nos dois lados vão ter até a mesma intensão!\foot
Assim não vamos precisar de escrever \symq{$\defintiffsymbol$}.
\toof
Mesma coisa sobre o \symq{$\defeq$}.

%%}}}

%%{{{ advice: compare_the_algorithms_advice 
\advice Compare os algoritmos.
%%%{{{ meta 
\label compare_the_algorithms_advice
%%%}}}

Uma dica para decidir se os dois lados são intensionalmente iguais ou
equivalentes é \emph{comparar os algoritmos} em vez dos seus resultados.
Olhe para cada lado e considere o algoritmo que alguém precisaria executar
para achar seu valor (se é objeto) ou para verificar sua veracidade
(se é proposição).
Se os algoritmos são os mesmos, temos igualdade (ou equivalência) intensional.
Se os seus resultados são os mesmos, temos igualdade (ou equivalência)
extensional.

%%}}}

%%{{{ x: intensional_implies_extensional 
\exercise.
%%%{{{ meta 
\label intensional_implies_extensional
%%%}}}

Verdadeiro ou falso?:
\tlist:
\li (i):  se $A \inteq B$ então $A = B$;
\li (ii): se $A \intiff B$ então $A \iff B$.
\endtlist
Observe que para cada uma dessas afirmações fazer sentido
os $A,B$ denotam objetos na primeira, mas proposições na segunda.

%%}}}

%%{{{ x: intensional_vs_extensional_quiz 
\exercise.
%%%{{{ meta 
\label intensional_vs_extensional
\pdefs
    \pdef phrases ####1####2{$\left\{\aligned &####1 \\ &####2 \endaligned\right.$}
    ;;
%%%}}}

Para cada um par de expressões escolha a melhor opção dos:
$$
\intiffsymbol, \quad
\iffsymbol, \quad
{\inteq}, \quad
{=}.
$$
Observe que as versões intensionais são mais fortes que as extensionais,
então quando aplica a versão intensional, precisa escolhé-la.
\elist 1:listoula
\cdhere
\li:six
\phrases
    {2 \ntimes 3}
    {6}
\li:twothree
\phrases
    {2 \ntimes 3}
    {3 \ntimes 2}
\li:love
\phrases
    {\text{$x$ ama $y$}}
    {\text{$y$ é amado por $x$}}
\li:even
\phrases
    {\text{$n$ é par}}
    {\text{existe $k \in \ints$ tal que $n = 2k$}}
\li:matheus
\phrases
    {\text{Matheus mora na capital do RN}}
    {\text{Matheus mora na maior cidade do RN}}
\li:athens
\phrases
    {\text{a capital da Grécia}}
    {\text{Aténas}}
\li:sarcofago
\phrases
    {\text{o vocalista da banda Sarcófago é professor da UFMG}}
    {\text{Wagner Moura é professor da maior universidade de MG}}
\li:aristoteles
\phrases
    {\text{Aristoteles foi professor de Alexandre o Grande}}
    {\text{Aristoteles ensinou Alexandre o Grande}}
\li:cheese
\phrases
    {\text{A terra é plana}}
    {\text{A lua é feita de queijo}}
\li:zeros
\phrases
    {x^2 + y^2 \leq 0}
    {x = y = 0}
\li:squares
\phrases
    {x^2 + y^2 \leq 0}
    {0 \geq x \ntimes x + y \ntimes y}
\li:manysquares
\phrases
    {(x^2 + y^2)^2}
    {(x\ntimes x + y^2)(x^2 + y \ntimes y)}
\endelist

\solution
\refcd intensional_vs_extensional
Temos:
\tlist:
\li: \symq{$\intiffsymbol$} para os pares:
     \refnear[love], \refnear[even], \refnear[squares];
\li: \symq{$\iffsymbol$} para os pares:
     \refnear[matheus], \refnear[sarcofago], \refnear[cheese], \refnear[zeros], \refnear[aristoteles];
\li: \symq{${\inteq}$} para o par
     \refnear[manysquares];
\li: \symq{${=}$} para os pares:
     \refnear[six], \refnear[twothree], \refnear[athens].
\endtlist
Aqui considerei que elevar um número ao 2 \emph{significa} multiplicar
o número por ele mesmo.
Caso que considerou exponenciação como operação primitiva e não definida
em termos da multiplicação, seria correto mudar as~\refnear[squares]
e~\refnear[manysquares] de intensional para extensional.
Similarmente considerei que \emph{ser professor de alguém} envolve
mais coisas do que simplesmente ensinar algo para alguém.

%%}}}

\endsection

%%}}}

%%{{{ Variables 
\section Variáveis.
%%%{{{ meta 
\label Variables
%%%}}}

%%{{{ intro 
\secintro
Vamos usar e estudar variáveis demais.
Por enquanto precisas só entender o básico.
Esta secção, é esse básico.
%%}}}

%%{{{ from_pronouns_to_variables 
\note De pronomes para variáveis.
%%%{{{ meta 
\label from_pronouns_to_variables
\defines
    * variável
    ;;
%%%}}}

Considere as proposições:
\tlist:
\li (i):   \wq{Existe número tal que ele é múltiplo de todos os números.}
\li (ii):  \wq{Para todo país, existe cidade tal que ela fica perto da fronteira dele.}
\li (iii): \wq{Para toda pessoa, existe pessoa tal que ela a ama.}
\endtlist
aqui usamos os pronomes \sq{ele}, \sq{ela}, \sq{a},
para referir a algum objeto que foi ``introduzido''
a partir dos \wq{existe} e \wq{para todo}.
Na segunda frase graças à coincidência que temos em português onde
a palavra \sq{país} é masculina, e a \sq{cidade} feminina, não
existe confusão: \sq{ele} refere ao país, e \sq{ela} refere à cidade.\foot
Já em grego não temos essa coincidência para nos ajudar nessa frase pois ambos os substantivos são femininos;
e em inglês ambos são neutros e seriam referidos pelo mesmo pronome: \emph{it}.
\toof
Porém, na última frase não é claro a que as palavras \sq{ela} e \sq{a} referem.
Usando variáveis escrevemos as primeiras duas assim:
\tlist:
\li (i):   \wq{Existe número $n$ tal que $n$ é múltiplo de todos os números.}
\li (ii):  \wq{Para todo país $p$, existe cidade $c$ tal que $c$ fica perto da fronteira de $p$.}
\endtlist
Agora olhe na terceira frase.
Temos duas razoáveis maneiras de interpretá-la, dependendo de
a que cada pronome refere:
\tlist:
\li (iii)${}_1$: \wq{Para toda pessoa $x$, existe pessoa $y$ tal que $x$ ama $y$.}
\li (iii)${}_2$: \wq{Para toda pessoa $x$, existe pessoa $y$ tal que $y$ ama $x$.}
\endtlist
Observe que os significiados são bem diferentes:
\tlist:
\li (iii)${}_1$: \wq{Toda pessoa ama.}
\li (iii)${}_2$: \wq{Toda pessoa é amada.}
\endtlist
Ou seja, a frase (iii) não tem um significado bem determinado e sendo ambígua não podemos usá-la.

%%}}}

%%{{{ variable_occurrence 
\note Ocorrência de variável.
%%%{{{ meta 
\label variable_occurrence
\defines
    * variável!ocorrência
    ;;
\indexes
    * variável!instância    see: ocorrência
    ;;
%%%}}}

Numa frase que envolve variáveis é muito importante poder separar
(e falar sobre) cada \dterm{ocorrência} (ou \dterm{instância})
de variável na frase.
Na frase seguinte por exemplo, temos $4$~ocorrências da
variável $p$ e $2$~da variável $q$.
$$
\textwq{$\undertag p 1$ é primo e para todo primo $\undertag p 2$ tal que $\undertag p 3$ divide $\undertag q 1$, $\undertag p 4^2$ divide $\undertag q 2$}
$$
Sublinhei e rotulei todas.
Mesmo sem isso, alguém poderia falar da
\wq{terceira ocorrência da variável $p$} e entenderiamos qual seria.

%%}}}

%%{{{ x: typecheck_warmup 
\exercise typecheck warmup.
%%%{{{ meta 
\label typecheck_warmup
%%%}}}

Considere as expressões:
% TODO: fix reflabs
\elist a:
\eachitem expression
\li: $(x + y)^2 = x^2 + 2xy$;
\li:motherof a mãe de $p$;
\li: $2^n + 1$;
\li: $p$ é irmão de $q$;
\li: a capital do país $p$;
\li: $a$ mora em Atenas.
\endelist
Para cada uma decida se ela denota objeto ou proposição.

\solution
\context tt
\x $(x + y)^2 = x^2 + 2xy$ : proposição ; \\
\x a mãe de $p$            : objeto     ; \\
\x $2^n + 1$               : objeto     ; \\
\x $p$ é irmão de $q$      : proposição ; \\
\x a capital do país $p$   : objeto     ; \\
\x $a$ mora em Atenas      : proposição ; \\
\endcontext

%%}}}

%%{{{ variables_free_and_bound 
\note Variáveis livres e ligadas.
%%%{{{ meta 
\label variables_free_and_bound
\defines
    * variável!ligada
    * variável!livre
    ;;
\indexes
    * dummy        see: variável ligada
    ;;
%%%}}}

Cada uma das expressões da~\ref[typecheck_warmup] refere a pelo
menos uma coisa por meio de variáveis, e logo seu significado é dependente
(dessas variáveis).
Essas \emph{ocorrências de variáveis} chamamos de \dterm{livres}.
Sobre as expressões que denotam proposições:
não sabemos o que cada uma afirma sem saber quais são
os objetos denotados por essas variáveis;
similarmente sobre as expressões que denotam objetos:
não sabemos qual objeto é denotado sem saber quais são
os objetos denotados por essas variáveis.
Agora considere as expressões:
\elist 1:
\li: existe $k \in \ints$ tal que $13 = 2k + 1$;
\li: existem números $x,y$ tais que $(x + y)^2 = x^2 + 2xy$;
\li: aquela função que dada um número $x$ retorna o $x+1$;
\li: o conjunto de todos livros $b$ tais que existe palavra $w$ no $b$ com tantas letras quantas as letras do título de $b$;
\li: para toda pessoa $p$, a pessoa $q$ não gosta de $p$.
\endelist
Aqui as ocorrências das variáveis são todas \dterm{ligadas},
exceto na última frase onde ambas as ocorrências da variável $p$
são ligadas, mas (a única ocorrência de) $q$ é livre.\foot
Na literatura aparece como sinônimo de variável ligada
o termo \dterm{dummy} (boba) também.
\toof

%%}}}

%%{{{ bound_to_nothing 
\note.
%%%{{{ meta 
\label bound_to_nothing
%%%}}}

Oxe!
Como assim a \sq{$w$} do \ref[variables_free_and_bound] é ligada?
Ligada com quê?
A \sq{$w$} do \wq{existe $w$} tem papel de \emph{ligador de variável}
(\reftag[binders_and_their_bindings])
aconteceu que o escopo desse ligador
não teve nenhuma \sq{$w$} livre para ser ligada com o \sq{$w$}
do \wq{existe $w$}.
Isso não torna a \sq{$w$} do \wq{existe $w$} livre;
apenas uma ligada que\dots acabou não ligando com nada.
Pense no codigo seguinte:
\sourcecode boundtonothing.rs;
o $\code{i}$ não é livre.
Acabou nao conseguindo ligar ninguém mas mesmo assim, com certeza
livre não tá.
Em certos casos vale a pena distinguïr as ocorrências não-livres
entre ligadores e ligadas, mas aqui chamamos todas elas de simplesmente
ligadas.

%%}}}

%%{{{ remark: variable_vs_occurrence_abuse 
\remark.
%%%{{{ meta 
\label variable_vs_occurrence_abuse
%%%}}}

Quando não existe possibilidade de confundir,
falamos apenas de \wq{variável} em vez de \wq{tal ocorrência de variável}.
Assim, mesmo que ser livre ou ligada não é uma propriedade de variáveis
mas de instâncias de variáveis, nos permitimos o abuso de usar frases
como \wq{$x$ é ligada}, etc.
Acabei de fazer isso no~\reftag[bound_to_nothing].

%%}}}

%%{{{ remark: implicit_bindings 
\remark Ligações implícitas.
%%%{{{ meta 
\label implicit_bindings 
%%%}}}

Linguisticamente falando a ligação existe sim;
só que não foi feita usando variáveis em forma explícita.
Foi deixada implicita.
Aqui o que foi escondido:
\wq{existe palavra $w$ no livro $b$ tal que $w$
tem tantas letras quantas letras tem o título do $b$}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Precisamos entender \emph{muito bem} essa idéia de variáveis
ligadas e livres, mas antes de continuar com isso\dots

%%}}}

%%{{{ x: typecheck spinoff exercise 
\exercise.
%%%{{{ meta 
%%%}}}

Para cada uma das cinco expressões do~\reftag[variables_free_and_bound]:
objeto ou proposição?

\solution
(1) proposição;
(2) proposição;
(3) objeto;
(4) objeto;
(5) proposição.

%%}}}

%%{{{ advice: how_to_tell_if_variable_is_free 
\advice.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free
%%%}}}

Para saber se uma variável \sq{$x$} aparece livre numa expressão,
tente enunciar uma frase com o mesmo significado da expressão
sem pronunciar \utter{x}.
Se conseguir, a variável é ligada.
Por exemplo, a frase (5) do~\reftag[variables_free_and_bound]
afirma que \wq{$q$ não gosta de ninguém}.

%%}}}

%%{{{ x: how_to_tell_if_variable_is_free_exercise_1 
\exercise.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free_exercise_1
%%%}}}

Enuncie cada uma das (1)--(4)
% TODO: fix reflabs
do~\reftag[variables_free_and_bound]
sem pronunciar nenhuma das variáveis ligadas que aparecem.

\solution
(1) existe número inteiro tal que seu dobro mais um é igual ao $13$;
(2) existem dois números inteiros tais que sua soma quadrada é igual à soma
do quadrado do primeiro e do dobro do produto do primeiro com o segundo;
(3) aquela função que dada um número retorna a soma desse número com o $1$;
(4) o conjunto de todos livros em quais aparece palavra com tantas letras quantas as letras do título do próprio livro.
\eop
(Se enunciou a (1) com a simples \wq{$13$ é ímpar} tá tudo OK; vamos voltar
a discutir questões de paridade (par, ímpar, etc.) no~\ref[Proofs].)

%%}}}

%%{{{ x: how_to_tell_if_variable_is_free_exercise_2 
\exercise.
%%%{{{ meta 
\label how_to_tell_if_variable_is_free_exercise_2
%%%}}}

Mesma coisa sobre as frases seguintes:
\elist 1:
\li: existem pessoas $p,q$ tais que $p$ ama $q$ e $q$ ama $p$;
\li: existe pessoa $p$ tal que $p$ ama $q$ e $q$ ama $p$;
\li: $x+y = z$;
\li: existe número $x$ tal que $x+y = z$;
\li: existem números $x,z$ tais que $x+y = z$;
\li: para todo número $y$, existe número $x$ tal que $x+y=z$;
\li: para quaisquer números $y,z$, existe número $x$ tal que $x+y=z$.
\endelist

\solution
\elist 1:
\li: existem pessoas que se amam mutalmente;
\li: existe pessoa que ama e é amada pela pessoa $q$;
\li: $x + y = z$;
\li: existe número tal que sua soma com $x$ é igual ao $z$;
\li: existem números tais que somando $y$ num deles resulta no outro;
\li: para qualquer número, existe número tal que a soma com o primeiro é igual ao $z$;
\li: para quaisquer dois números, existe número cuja soma com o primeiro é igual ao segundo.
\endelist

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver agora a mesma idéia no contexto de programação:

%%}}}

%%{{{ eg: freeboundvars_c 
\example.
%%%{{{ meta 
\label freeboundvars_c
%%%}}}

Considere o código seguinte:
\sourcecode freeboundvars.c;
A $\code{i}$ da primeira linha é livre, e nas suas outras ocorrências ligada;
a $\code{w}$ é livre em todo canto.

%%}}}

%%{{{ beware: variable_both_bound_and_free 
\beware.
%%%{{{ meta 
\label variable_both_bound_and_free
%%%}}}

Numa frase, a mesma variável pode ter ocorrências livres e ligadas também!
Olha por exemplo a frase do~\ref[variable_occurrence].
A primeira ocorrência da $p$ é livre, mas todas as outras são ligadas!

%%}}}

%%{{{ variable_assignment 
\note Atribuição e substituição.
%%%{{{ meta 
\label variable_assignment
\pdefs
    \pdef Amanda {\mathrm{Amanda}}
    \pdef Larry  {\mathrm{Larry}}
    ;;
%%%}}}

Quando queremos \dterm{substituir} uma variável por um
outro termo, ou \dterm{atribuir} um valor a uma variável,
para evitar o uso do símbolo da igualdade
\symq{$=$} e escrever frases como \wq{para $n=1$ temos\dots}
usamos o símbolo \symq{$\asseq$}: \wq{para $n\asseq 1$ temos\dots}.
A idéia é que a expressão na esquerda é para assumir o valor
determinado pela direita.
Escrevemos, por exemplo:
\tlist:
\li: A proposição (5) do~\reftag[variables_free_and_bound] com $q \asseq \Larry$ é a proposição que a Larry não gosta de ninguém.
\li: \emph{Usando} a (5) do~\reftag[variables_free_and_bound] para $p \asseq \Amanda$ \emph{inferimos} que a pessoa $q$ não gosta de Amanda.
\endtlist
Naturalmente, usamos o \symq{$\eqass$} nas raras vezes que
queremos inverter os papeis da esquerda e da direita.
Caso que a variável que estamos substituindo é uma variavel
proposicional (ou seja, serve para denotar proposições
e não objetos) podemos usar os \symq{$\assiff$} e \symq{$\iffass$}.

%%}}}

%%{{{ variable_renaming 
\note Renomeamento.
%%%{{{ meta 
\label variable_renaming
%%%}}}

Considere o texto seguinte:
$$
\textwq{Existe número $x$ tal que $x^2 = k$.}
$$
A variável \sq{$x$} \emph{sendo ligada} pode ser renomeada
por outra, por exemplo, a \sq{$n$}, sem mudar o significado
da proposição:
$$
\textwq{Existe número $n$ tal que $n^2 = k$.}
$$
Porém, não podemos renomear a \sq{$k$},
pois ela é livre, e logo o significado da proposição
mudaria, pois em vez de ser uma afirmação sobre
um certo objeto $k$, viraria uma afirmação sobre
outra coisa.
O processo de (re)nomear variáveis tem certos perigos,
então precisamos tomar cuidado.
Vamos analisar:

%%}}}

%%{{{ variable_capturing_and_shadowing 
\note Capturamento e sombreamento de variável.
%%%{{{ meta 
\label variable_capturing_and_shadowing
\defines
    * variável!capturada
    * variável!fresca
    * variável!sombreamento
    ;;
\indexes
    * capturada    see: variável
    ;;
%%%}}}

Leia o texto seguinte:
\quote
\flwq {Seja $p$ a maior potência de $2$ que divide o $x$.\CR
       Qualquer número que divide $p$, também divide $x$.}
\endquote
Aqui conseguimos evitar o uso de variável na segunda linha para referir
nesse número que divide o $p$.
Realmente ficou sem ambigüidade o texto, então realmente não necessitamos.
Mas se quisermos usar, podemos usar qualquer uma?
Não sempre!
Precisamos tomar cuidado.
Vamos tentar usar uma \dterm{variável fresca}, ou seja,
uma variável que não temos usado ainda:
\quote
\flwq {Seja $p$ a maior potência de $2$ que divide o $x$.\CR
       Para todo número $d$, se $d$ divide $p$, então $d$ divide $x$.}
\endquote
Primeiramente confirme que \emph{nada mudou no significado} do texto.
Usamos a variável \sq{$d$} para referir ao divisor arbitrário de $p$.
Essa (usar uma variável fresca) seria a melhor e mais segura escolha aqui.
Mas, o que acontece se usar, por exemplo, a \sq{$x$}?
Vamos ver:
\quote
\flwq {Seja $p$ a maior potência de $2$ que divide o $x$.\CR
       Para todo número $x$, se $x$ divide $p$, então $x$ divide $x$.}
\endquote
Acabou de acontecer sombreamento e capturamento.
Para explicar vou pintar as variáveis no texto anterior onde usamos \sq{$d$}:
\quote
\flwq {Seja $\aG p$ a maior potência de $2$ que divide o $\aR x$.\CR
       Para todo número $\aB d$, se $\aB d$ divide $\aG p$, então $\aB d$ divide $\aR x$.}
\endquote
e no novo, onde usamos a \sq{$x$}:
\quote
\flwq {Seja $\aG p$ a maior potência de $2$ que divide o $\aR x$.\CR
       Para todo número $\aB x$, se $\aB x$ divide $\aG p$, então $\aB x$ divide $\aB x$.}
\endquote
A partir da frase \wq{Para todo número $\aB x$},
o $\aR x$ da linha anterior não tem mais como ser referido
até o fim desse escopo, nesse caso até o ponto final da linha.
Aconteceu \dterm{sombreamento} (\dterm{shadowing}) da variável
$\aR x$ nesse escopo.
Dizemos também que a variável $\aR x$ da segunda linha da versão anterior,
foi \dterm{capturada} pela frase \wq{Para todo número $\aB x$}, ou seja, virou azul.

%%}}}

%%{{{ eg: shadowing_c 
\example.
%%%{{{ meta 
\label shadowing_c
%%%}}}

Para os programadores, aqui um exemplo de código e uma análise relevante:
\sourcecode shadowing.c;
Nas linhas 12--14 aconteceu sombreamento da $\code{i}$ que foi declarada
na linha 2, por causa do $\code{for}$.
Esse $\code{for}$ capturou a $\code{i}$ que aparece na linha 13.
Ainda mais, a variável $\code{a}$ declarada na linha 1 foi sombreada
no escopo ta função $\code{foo}$ pois escolhemos usar o mesmo nome
para segunda parámetro da função $\code{foo}$, e logo qualquer
ocorrências de $\code{a}$ no corpo da $\code{foo}$ refere ao segundo
argumento da função, e não à $\code{a}$ da linha 1.
Assim, dentro do corpo da função não temos mais como referir à $\code{a}$.

%%}}}

%%{{{ binders_and_their_bindings 
\note Ligadores de variáveis e suas ligações.
%%%{{{ meta 
\label binders_and_their_bindings
\defines
    * ligador!de variável
    ;;
%%%}}}

Já encontramos dois \dterm{ligadores (binders) de variáveis}:
\wq{existe {\thole} tal que \dots}
e
\wq{para todo {\thole}, \dots}.
Tem muito mais que esses dois, e provavelmente o leitor já encontrou vários
em matemática, programação, ou na vida mesmo~(\ref[find_more_binders]).
Para entender melhor que onde aparecem variáveis ligadas não está sendo
afirmado algo sobre certos objetos denotados por essas variáveis, podemos
desenhar explicitamente as ligações.
É melhor pensar que uma proposição \emph{é} sua forma com ligações,
assim a desvinculando das escolhas de nome de variáveis insignificantes
que seu escritor favoreceu.
Espero que isso fique mais claro depois do exemplo seguinte:

%%}}}

%%{{{ eg: free_and_bound_variables_eg 
\example.
%%%{{{ meta 
\label free_and_bound_variables_eg
%%%}}}

Considere a proposição
$$
\text{\tenrm $n-d$ e $n+d$ são primos}. \tag{1}
$$
Sem sequer saber o que significa ser um número primo,
sabemos que essa proposição afirma que dois números (o $n-d$ e o $n+d$) possuem essa propriedade (misteriosa de ser primo).
Aparecem as variáveis \sq{$n$} e \sq{$d$}, e em todas as suas ocorrências são livres.
Ou seja, a proposição (1) pode ser vista como uma afirmação sobre dois números $n$ e $d$.
Podemos \emph{quantificiar} uma ou ambas delas, por um dos quantificadores que discutimos:
$$
\text{\tenrm existe $d$ tal que $n-d$ e $n+d$ são primos}. \tag{2}
$$
Aqui todas as ocorrências da \sq{$d$} são ligadas
(com o ligador \wq{existe $d$ tal que \dots}).
Ou seja, a proposição (2) afirma algo sobre um certo número $n$.
Ela não fala nada sobre $d$.  Podemos pronunciá-la sem dizer \utter{d}:
\emph{\wq{Existe numero que tanto subtraindo ele de $n$,
quanto somando ele com $n$, resulta em números primos.}}.
Mas não sem dizer \wq{n}.
Podemos desenhar as ligações da~(2) para esclarecer:
\Tikzi varbindings2;
Voltando na (1) podemos quantificar a outra variável:
$$
\text{\tenrm existe $n$ tal que $n-d$ e $n+d$ são primos}. \tag{3}
$$
Agora $d$ é livre e $n$ ligada, ou seja (3) afirma algo
sobre um certo número $d$, e nada sobre nenhum $n$.
Podemos pronunciá-la sem dizer \utter{n}:
\emph{\wq{Existe numero que tanto subtraindo $d$ dele,
quanto somando $d$ nele, resulta em números primos.}}.
Mas não sem dizer \utter{d}.
Deixo os desenhos de ligações pra ti (\ref[bindings_exercise]).
Observe que os significados das (2) e (3) são bem diferentes:
\tlist:
\li: Na (2) o $n$ é fixo (podemos pensar o $n$ como o centro da nossa busca)
e ficamos estendendo mais e mais os dedos (com distâncias iguais do centro)
até encontrar (se encontrar) uma certa distância $d$ tal que (novamente)
ambos os nossos dedos apontam para primos.
\li: Na (3) o $d$ é fixo (podemos pensar o $d$ como distância) e
procuramos $n$ com essa propriedade.
Parece que fixamos nossos dedos numa distância $2d$ ($d$ pela esquerda
e $d$ pela direita) e procuramos achar se existe $n$ no meio tal que
ambos os nossos dedos apontam para primos.
\endtlist
Agora, volte na (2) e considere a proposição
$$
\text{\tenrm para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos}. \tag{4}
$$
que obtemos botando esse
\wq{\trueR{para todo $n$, se $n \geq N$ então}}
na frente da (2).
Aconteceu o seguinte:
\Tikzi varbindings4;
Essa então é uma afirmação sobre um certo número $N$.
Quantificando \sq{$N$} também, podemos chegar na:
$$
\text{\tenrm existe $N$ tal que para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos} \tag{5}
$$
Te deixo desenhar suas ligações (\ref[bindings_exercise]).

%%}}}

%%{{{ x: bindings_exercise 
\exercise.
%%%{{{ meta 
\label bindings_exercise
%%%}}}

Desenhe as ligações da (3) e (5) do~\ref[free_and_bound_variables_eg].

\solution
A proposição (3) escrita com variáveis
$$
\text{\tenrm existe $n$ tal que $n-d$ e $n+d$ são primos} \tag{3}
$$
e agora com ligações:
\Tikzi varbindings3;
A proposição (5) escrita com variáveis:
$$
\text{\tenrm existe $N$ tal que para todo $n$, se $n \geq N$ então existe $d$ tal que $n-d$ e $n+d$ são primos} \tag{5}
$$
e agora com ligações:
\Tikzi varbindings5;

%%}}}

%%{{{ x: find_more_binders 
\exercise.
%%%{{{ meta 
\label find_more_binders
%%%}}}

Já encontramos dois ligadores
\wq{existe {\thole} tal que \dots}
e
\wq{para todo {\thole}, \dots}.
Dê mais exemplos de ligadores que tu conhece:
de matemática, de programação, de vida\dots

%%}}}

%%{{{ x: renaming 
\exercise.
%%%{{{ meta 
%%%}}}

Na (3) do~\ref[free_and_bound_variables_eg]
podemos renomear a variável\dots:
\mathcols 3
\text{(i)}    &~\text{\sq{$n$} por \sq{$m$}?} &
\text{(ii)}   &~\text{\sq{$n$} por \sq{$d$}?} &
\text{(iii)}  &~\text{\sq{$d$} por \sq{$x$}?}
\endmathcols

\solution
(i) sim, pois $m$ não aparece livre no escopo e assim não vai acontecer
capturamento de variável não-desejado;
(ii) não, pois $d$ aparece livre no escopo e assim seria capturado
e logo nem seria mais uma afirmação sobre $d$;
(iii) não, pois não seria mais uma afirmação sobre o $d$, mas sobre o $x$.

%%}}}

%%{{{ x: renaming (trick question) 
\exercise.
%%%{{{ meta 
%%%}}}

E na (5)\dots:
\mathcols 3
\text{(i)}  &~\text{\sq{$N$} por \sq{$n$}?} &
\text{(iii)}&~\text{\sq{$n$} por \sq{$N$}?} &
\text{(v)}  &~\text{\sq{$d$} por \sq{$n$}?} \\
\text{(ii)} &~\text{\sq{$N$} por \sq{$d$}?} &
\text{(iv)} &~\text{\sq{$n$} por \sq{$d$}?} &
\text{(vi)} &~\text{\sq{$d$} por \sq{$N$}?}
\endmathcols
Cuidado!

\solution
(i) não, pois teriamos sombreamento do antigo \sq{$N$} e precisamos referi-lo;
(ii) sim---mesmo que fica esquisito!---pois o sombreamento acontece num escopo onde não precisamos referir mais o antigo \sq{$N$};
(iii) não, pois teriamos sombreamento do antigo \sq{$N$} e precisamos referi-lo;
(iv) não, pois teriamos sombreamento do antigo \sq{$n$} que tá sendo referido depois;
(v) não: mesmo problema com o (iv);
(vi) sim: mesma situação com o (ii).

%%}}}

%%{{{ beware: variables_do_not_vary 
\beware.
%%%{{{ meta 
\label variables_do_not_vary
%%%}}}

Em matemática---por incrível que pareça---uma variável
não\dots varia!  Ela denota um objeto especifico
e pronto, não pode mudar depois duns minutos para denotar
algo diferente, nem mudar no mesmo escopo da mesma expressão
como acontece por exemplo com o que
chamamos de \dq{variáveis} em programação imperativa.
Encontrando então a expressão \sq{$f(x) + x$}, não tem
como as duas ocorrências de \symq{$x$} denotar objetos
diferentes.

%%}}}

%%{{{ used_but_unused_variables_phrases 
\note.
%%%{{{ meta 
\label used_but_unused_variables_phrases
%%%}}}

Antes de fechar nossa discussão sobre variáveis tenho
uma última coisa para expôr.
Considere as frases:
% TODO: fix reflabs
\elist 1:
\li: todo inteiro $x$ divide ele mesmo;
\li: existe número $n$ tal que ele é primo e par;
\li: qualquer conjunto $A$ é determinado por seus membros;
\li: não existe país $P$ tal que a pessoa $p$ não viajou para esse país;
\li: existe pessoa $p$ tal que para todo filme $f$ na lista $F$, $p$ assistiu tal filme.
\endelist
E agora\dots

%%}}}

%%{{{ Q: what is the problem with those phrases? 
\question.
%%%{{{ meta 
%%%}}}

Qual o problema com elas?

%%}}}

\spoiler

%%{{{ used_but_unused_variables 
\beware variáveis inúteis.
%%%{{{ meta 
%%%}}}

Cada uma dessas frases usa pelo menos uma variável ligada
numa maneira completamente inútil: a frase introduz uma
variável para denotar algo, mas nunca usa essa variável
mesmo para referir a esse algo!  Acaba usando pronomes.
\emph{Nunca introduza uma variável se não pretende usá-la mesmo!}
Aqui as mesmas frases, essa vez sem as variáveis inúteis:
% TODO: fix reflabs
\elist 1:
\li: todo inteiro divide ele mesmo;
\li: existe número (tal que ele é) primo e par;
\li: qualquer conjunto é determinado por seus membros;
\li: não existe país tal que a pessoa $p$ não viajou para esse país;
\li: existe pessoa $p$, tal que $p$ assistiu todos os filmes da lista $F$.
\endelist
Observe que na última frase podemos nos livrar da variável \sq{$p$} também
já que é ligadas.\foot
Assim:
\wq{alguém assistiu todos os filmes que estão na lista $F$}.
\toof
Mas pelo menos ela foi usada (referenciada) sim, e aqui o objetivo era jogar
fora as variáveis que não foram usadas.

%%}}}

\endsection
%%}}}

%%{{{ Types_of_numbers 
\section Tipos de números.
%%%{{{ meta 
\label Types_of_numbers
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos encontrar e estudar vários tipos de números:
naturais (\ref[Recursion_induction]), inteiros (\ref[The_integers]),
racionais (\ref[Galois_theory]), reais (\ref[The_reals]), \dots
Além disso, nos capítulos~\reftag[Cantors_paradise]
e~\reftag[Set_theory] vamos identificar certos
reais que são ainda mais selvagens do que os irracionais:
os transcendentais; e uns números transfinitos: os cardinais
e os ordinais.

%%}}}

%%{{{ from and to the reals 
\note De e para os reais.
%%%{{{ meta 
%%%}}}

Uma abordagem é começar considerando como conhecida ou dada
a noção dos números reais, freqüentemente identificados com
os pontos duma linha reta que extende infinitamente para ambas
as direcções; um ponto dela chamamos de $0$, botamos na sua direita
mais um ponto chamado de $1$, e pensamos que a distancia entre
esses pontos é medida pelo número real $1$ mesmo;
na outra direção temos o $-1$, etc., etc., e o leitor
provavelmente já ouviu dessa estoria muitas vezes na vida.\foot
Caso contrário vamos voltar a discutir isso numa
maneira melhor bem depois, nos capítulos~\reftag[The_reals]
e~\reftag[Set_theory].
\toof
Nada disso faz sentido formalmente falando, mas não estamos
falando formalmente neste momento, e com certeza essa
imagem geométrica ajuda demais em elaborar uma intuição
sobre os reais.
\eop
Então: \emph{começando com a reta dos reais} como dada, podemos procurar
e definir um subconjunto dela para representar os racionais,
um subconjunto deles para os inteiros e um deles para os naturais.
Naturalmente definimos primeiramente os naturais,
depois adicionamos para cada ponto o seu oposto chegando assim nos inteiros,
e depois formamos todas as fracções $m/n$ para quaisquer inteiros $m,n$ com $n\neq 0$
e pronto, temos o racionais também.
\eop
Podemos trabalhar também no sentido contrário (\ref[Set_theory]):
\emph{começar com os naturais}, usá-los para \emph{construir} os inteiros,
usá-los para construir os racionais, e usá-los para construir os reais, etc.
Nesse contexto, \sq{construir} significa definir.

%%}}}

\endsection
%%}}}

%%{{{ Numbers, numerals, digits 
\section Números, numerais, dígitos.
%%%{{{ meta 
%%%}}}

%%{{{ number_numeral_digit 
\note.
%%%{{{ meta 
\label number_numeral_digit
\indexes
    * algarismo    see: dígito
    ;;
\defines
    * dígito
    * numeral
    * número
    ;;
%%%}}}

Aceitamos \emph{por enquanto} como dado o conceito dos números que usamos
para contar, que costumamos denotar por
$$
0, 1, 2, 3, \dots, 247, 248, 249, \dots
$$
Usando então apenas um \emph{alfabeto} composto de dez símbolos
$$
\digit 0\ \ 
\digit 1\ \ 
\digit 2\ \ 
\digit 3\ \ 
\digit 4\ \ 
\digit 5\ \ 
\digit 6\ \ 
\digit 7\ \ 
\digit 8\ \ 
\digit 9
$$
e seguindo as regras bem-conhecidas do sistema decimal conseguimos
denotar qualquer um dos números, mesmo que tem uma infinidade deles!
\eop
Chamamos esses símbolos de \dterm{dígitos} ou \dterm{algarismos}.
Para \emph{representar os números}, usamos palavras (ou \emph{strings})
que formamos justapondo esses dígitos; essas palavras chamamos de
\dterm{numerais do sistema posicional decimal}.
Sem contexto, lendo o \sq{10} já temos uma ambigüidade:
é o numeral $\numeral {10}$ ou o número dez?
Para apreciar essa diferença ainda mais, note que o numeral $\numeral {10}$,
pode representar outro número em outro contexto.
Por exemplo, no sistema binário, o numeral $\numeral {10}$
representa o número dois.
E a ambigüidade pode ser ainda maior lendo ``1'':
é o numeral $\numeral {1}$; o número um; ou o dígito~$\digit 1$?
Quando o contexto é suficiente para entender, não precisamos mudar a fonte
como acabei de fazer aqui, nem escrever explicitamente o que é.
Note que existem numerais bem diferentes para denotar esses números:
o numeral (romano) {XII}
e o numeral (grego) {ιβ} denotam o mesmo número, que em português chamamos de \emph{doze}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Temos então umas pequenas linguagens que nos permitem descrever \emph{números}.
Não fatos sobre números.
Nem cálculos com números.
Números.
Quais números?
Todos os números \emph{naturais} (veja~\reftag[Types_of_numbers]),
cuja totalidade simbolizamos com $\nats$ e deixamos seu estudo para o \ref[Recursion_induction].

%%}}}

\endsection
%%}}}

%%{{{ Sets_functions_relations 
\section Conjuntos, funções, relações.
%%%{{{ meta 
\label Sets_functions_relations
%%%}}}

%%{{{ intro 
\secintro
Rascunhamos aqui três tipos importantíssimos, só para ter uma idéia
do que se trata, pois vamos precisá-los desde já!
Mas cada um deles tem seu próprio capítulo dedicado ao seu estudo:
estudamos conjuntos no~\ref[Collections],
funções no~\reftag[Functions],
e relações no~\reftag[Relations].
Agora, bora rascunhar!
%%}}}

%%{{{ sets_first_contact 
\note Conjuntos.
%%%{{{ meta 
\label sets_first_contact
\defines
    * conjunto!primeiro contato
    ;;
%%%}}}

Um \dterm{conjunto} é uma colecção de objetos que já conhecemos.
Denotamos um conjunto escrevendo seus membros entre ``chaves'',
separados por vírgulas, por exemplo
$$
\set{1,2,3}
$$
denota o conjunto cujos membros são os números $1$, $2$, e $3$.
Conjuntos não têm seus membros numa certa ordem; e também não
faz sentido perguntar quantas vezes um objeto pertence àlgum conjunto:
$$
\set{1,2,3} = \set{3,1,2} = \set{1,1,3,2,2,1}.
$$
\emph{Dizemos que dois conjuntos são iguais sse
eles possuem exatamente os mesmos membros.}
Vamos também usar a notação
$$
\setstt x {$x$ é um múltiplo de $3$}
$$
para descrever o conjunto de todos os múltiplos de $3$
e---parabéns para nos---acabamos de definir um conjunto infinito
numa maneira tão curta e simples!
A gente lê o conjunto acima assim:
$$
\textwq{o conjunto de todos os $x$, tais que $x$ é um múltiplo de $3$}.
$$
Costumamos usar letras maiúsculas para denotar conjuntos,
mas não ficamos obsecados demais com essa costume.
Usamos a notação $x \in A$, para afirmar que $x$ é um dos membros
do conjunto $A$, e escrevemos $A \subset B$ para afirmar que
cada membro de $A$ é um membro de $B$ (nesse caso dizemos que
$A$ é um \dterm{subconjunto de $B$}).
Por exemplo, o conjunto de todos os brasileiros é um subconjunto
do conjunto de todos os humanos.
Usamos variações da notação em cima como por exemplo
$$
\setstt {p \is \Int} {$p$ e $p+2$ são números primos}
$$
denotando o conjunto de todos os inteiros $p$ tais que
$p$ é primo e $p+2$ também.
\eop
Temos tudo que precisamos para começar até chegar no~\ref[Collections]
onde estudamos mesmo conjuntos e outros tipos de \dq{containers},
notavelmente tuplas:

%%}}}

%%{{{ tuples_first_contact 
\note Tuplas.
%%%{{{ meta 
\label tuples_first_contact
\defines
    * tupla!primeiro contato
    ;;
%%%}}}

Quando temos uns objetos botados numa certa
ordem, temos uma \dterm{tupla}.
Denotamos a tupla dos objetos $x_1,\dotsc,x_n$ assim:
$$
\tup{x_1,\dotsc,x_n}
\qqqtext{ou}
\tupp{x_1,\dotsc,x_n}.
$$
Observe que temos
$$
\tup{1,2,3} \neq \tup{1,3,2}
$$
pois \emph{consideramos duas tuplas iguais
sse elas concordam em cada posição}.

%%}}}

%%{{{ functions_first_contact 
\note Funções.
%%%{{{ meta 
\label functions_first_contact
\defines
    * função!primeiro contato
    ;;
%%%}}}

\dterm{Funções} são objetos que dados objetos \dterm{retornam}
objetos.
É comum usar as letras $f,g,h$, etc.~para denotar funções, mas, novamente
isso não é uma regra inquebrável.
Escrevemos
$$
f : A \to B
$$
para dizer que $f$ é uma função que dada qualquer objeto de tipo $A$,
retorna algum objeto de tipo $B$.
Dado qualquer $x \is A$, escrevemos \symq{$f \fa x$} ou $f(x)$ para o \dterm{valor}
ou \dterm{saida} da $f$ no $x$, e chamamos $x$ de \dterm{argumento}
ou \dterm{entrada} da $f$.
Observe que $f \fa x \is B$.  O objeto $f \fa x$ é determinado pelo $x \is A$,
ou seja, para qualquer $x \in A$, \emph{exatamente um} objeto é denotado por $f \fa x$.
Por exemplo, $\mother(x)$ pode denotar a mãe duma pessoa $x$.
Aqui entendemos que
$$
\align
\mother           &: \Person \to \Person
\intertext{onde $\Person$ é o tipo cujos habitantes são todas as pessoas.
Por outro lado, seria errado pensar que}
\namedfun{sister} &: \Person \to \Person
\endalign
$$
também é uma função, pois para certos $x \is \Person$ o $\mathit{sister}(x)$
não seria determinado!

%%}}}

%%{{{ x: why_sister_is_not_a_function 
\exercise.
%%%{{{ meta 
\label why_sister_is_not_a_function
%%%}}}

Quais são esses $x\in P$ tais que $\mathit{sister}(x)$ não é determinado?
Cuidado: tem mais que uma categoria de $x$'s ``problemáticos''!

\solution
As pessoas que não tem nenhuma irmã, e também as pessoas que tem mais que uma!

%%}}}

%%{{{ arity_first_contact 
\note Aridade.
%%%{{{ meta 
\label arity_first_contact
\defines
    * arity!primeiro contato
    ;;
%%%}}}

Uma função pode precisar mais que um argumento:
a adição por exemplo precisa dois números para retornar seu valor.
A quantidade de argumentos que uma função $f$ precisa é chamada \dterm{aridade}
da $f$.
Não são apenas funções que têm aridade, relações também têm:

%%}}}

%%{{{ relations_first_contact 
\note Relações.
%%%{{{ meta 
\label relations_first_contact
\defines
    * relação!primeiro contato
    ;;
%%%}}}

Funções dadas objetos viram objetos.
\dterm{Relações} dadas objetos viram proposições.
Por exemplo
$$
\textwq{{\lthole} é a mãe de {\lthole}}
$$
é uma relação de aridade $2$, mas
\math
\textwq{Stella é a mãe de {\lthole}} \\
\textwq{{\lthole} é a mãe de Thanos}
\endmath
são relações de aridade $1$.
Para relações de qualquer aridade emprestamos a notação de funções
e escrevemos, por exemplo
\mathcol
\mathrm{MotherOf}(x,y)       & :\quad \textwq{$x$ é a mãe de $y$} \\
\mathrm{StellaIsMotherOf}(x) & :\quad \textwq{Stella é a mãe de $x$} \\
\mathrm{MotherOfThanos}(x)   & :\quad \textwq{$x$ é a mãe de Thanos}.
\endmathcol

%%}}}

%%%{{{ notation: wherefix_notation 
\notation infix, prefix, postfix, mixfix.
%%%{{{ meta 
\label wherefix_notation
\defines
    * notação!infix
    * notação!prefix
    * notação!postfix
    * notação!mixfix
    ;;
\indexes
    * infix    see: notação
    * prefix   see: notação
    * postfix  see: notação
    * mixfix   see: notação
    ;;
%%%}}}

Especialmente para funções e relações de aridade $2$ usamos
também notação \dterm{infix} em vez de \dterm{prefix}, ou seja,
escrevemos o símbolo da função ou relação \emph{entre}
os seus argumentos em vez de \emph{antes}.
Como exemplo considere as $(+)$, $(=)$, $(\leq)$, etc.:
\mathcols 4
&\text{em vez de escrever:} &&\mathord{+}(1,2)&&\mathord{=}(1+1,2) &&\mathord{\leq}(0,\mathord{+}(x,y)) \\
&\text{escrevemos:}         &&1+2             &&1+1=2              &&0 \leq x + y.
\endmathcols
Às vezes também usamos notação \dterm{postfix}: exemplo padrão aqui seria
a função fatorial que denotamos por um simples \symq{!} postfixo,
escrevendo, por exemplo, $3!$ em vez de $\mathord{!}(3)$.
Quando escrevemos partes da notação do operador e os argumentos intercalados
falamos de notação \dterm{mixfix}, por exemplo:
$\code{if}\thole\code{then}\thole\code{else}\thole$.

%%%}}}

%%{{{ warning: function_vs_relation_naming_convention 
\warning Convenção notacional.
%%%{{{ meta 
\label function_vs_relation_naming_convention
%%%}}}

Para enfatizar a diferença entre funções e relações, tentarei
denotar funções com nomes que começam com letra minúscula,
e relações com maiúscula:
usarei \symq{$\mother(x)$} para \emph{o objeto} (aqui pessoa)
\wq{mãe de $x$}, e \symq{$\Mother(x)$} para \emph{a proposição}
\wq{$x$ é uma mãe}.
Novamente, essa também é uma convenção que vou seguir, um costume,
e não uma regra inquebrável.

%%}}}

\endsection
%%}}}

%%{{{ Theorems_and_friends 
\section Teoremas e seus amigos.
%%%{{{ meta 
\label Theorems_and_friends
%%%}}}

%%{{{ theorem 
\note Teorema.
%%%{{{ meta 
\label theorem
\defines
    * teorema
    ;;
%%%}}}

Chamamos de \dterm{teorema} uma proposição que já foi demonstrada
por alguém.
Então: que tipo de coisa é um teorema?  É uma proposição.
E ainda mais, sabemos que essa proposição é verdadeira, pois já possui
uma demonstração.
Uma proposição $P$ que não conseguimos demonstrar ainda, talvez um belo dia
alguém vai demonstrar e assim vamos falar do teorema $P$, ou pode ser
que alguém refute, e logo sabemos que não se-trata dum teorema.
Mas por enquanto, não sabemos se $P$ é um teorema ou não.

%%}}}

%%{{{ lemma_corollary 
\note Lemma, teorema, corolário.
%%%{{{ meta 
\label lemma_corollary
\defines
    * corollary
    * lemma
    ;;
%%%}}}

Matematicamente falando então não existe diferença essencial entre lemma e teorema,
nem entre teorema e corolário;
mas cuidado no seu uso pois nosso objetivo em matemática é \emph{comunicar},
e chamando um teorema de lemma ou de corolário comunica algo diferente.
Pense que estamos tentando demonstrar uma proposição que consideramos importante,
e provavelmente não vai ser muito simples demonstrá-la.
Chamamos de \dterm{lemma} um teorema que demonstramos para usar em demonstrar
nosso teorema.  E assim que demonstrar nosso teorema, talvez para divulgá-lo
e falar da importância dele, consideramos várias proposições que são
conseqüências (fáceis) do nosso teorema principal.
Esses são os \dterm{corolários} dele.

%%}}}

%%{{{ conjecture 
\note Conjectura.
%%%{{{ meta 
\label conjecture
\defines
    * conjectura
    ;;
%%%}}}

Uma proposição interessante que alguém afirmou e tentou demonstrar
sem conseguir, é uma \dterm{conjectura}.  Em qualquer momento
pode ser que alguém consiga demonstrar: nesse caso a proposição
vai ganhar o direito de ser chamada um teorema.
Similarmente, pode ser que alguém consegue refutar:
nesse caso a proposição é mais uma conjectura, pois já sabemos
a resposta (negativa) sobre sua veracidade.
Já no~\reffull[The_integers] vamos conhecer umas conjecturas que têm
atrapalhado---ou, entretido---matemáticos por séculos.
O que talvez pareça estranho---e eu espero pelo menos um pouco incrível
para meu leitor---é que existe mais uma possibilidade para
``resolver'' uma tal \dterm{questão em aberto}:
pode ser que alguém \emph{demonstre que não tem como demonstrá-la
nem como refutá-la!}
Mas é cedo demais para analisar mais isso; paciência; durante
esse texto vamos ver vários tais exemplos dessa situação e acabar
entendendo bem a situação.

%%}}}

\endsection
%%}}}

%%{{{ Proofs_first_encounter 
\section Demonstrações.
%%%{{{ meta 
\label Proofs_first_encounter
%%%}}}

%%{{{ What is a proof? 
\note O que é?.
%%%{{{ meta 
\defines
    * demonstração
    ;;
%%%}}}

Vamos começar com a idéia que uma \dterm{demonstração}
é uma argumentação ao favor duma proposição, convincente
e sem erros, escrita como um pedaço de texto, entendível
para uma pessoa que entende as noções matemáticas envolvidas.

%%}}}

%%{{{ proving_language_first_encounter 
\note Linguagem de demonstração.
%%%{{{ meta 
\label proving_language_first_encounter
\defines
    * linguagem!de demonstração
    ;;
%%%}}}

Normalmente a linguagem que usamos para escrever demonstrações
é uma linguagem natural, como grego, português, inglês, etc.,
\emph{enriquecida} saudavelmente por símbolos e notações
matemáticas.  Além disso, entendemos essa linguagem como
uma coisa mutável (especialmente aumentável), algo que
aproveitamos introduzindo novas notações, noções, convenções,
etc.
Infelizmente, especialmente quando começamos estudar
e \emph{fazer} matemática, não é uma idéia boa ter de
lidar com umas ambigüidades que as linguagens naturais carregam.
Vamos elaborar uma \emph{linguagem de demonstração},
bastante ``seca''---e sem a expressividade nem a beleza
que uma linguagem natural oferece---e tratá-la como se
fosse uma \emph{linguagem de programação:}
vamos diferenciar entre linhas de código e comentários,
e identificar certas palavras-chaves, explicar seus
efeitos, como, por que, e quando podemos usar.
Exatamente como na linguagem C, por exemplo, temos as
palavras $\code{while}$, $\code{return}$, $\code{float}$,
$\code{switch}$, $\code{else}$, etc., cada uma com seu
uso correto, sua sintaxe, sua semântica, etc.
A idéia é que uma demonstração escrita em linguagem natural,
corresponde \dq{por trás} num texto feito por \dq{linhas de código}
escritas nessa linguagem de demonstração.
Demonstrações escritas na linguagem de demonstração
acabam sendo cansativas de ler, sem graça:
pode parecer que foi um robô escreveu.
Essa seria uma linguagem \dterm{low-level} para demonstrar
teoremas.
Um dos nossos objetivos aqui é aprender como ler e escrever
numa linguagem \dterm{high-level}, natural e humana mesmo,
mas entendendo em qualquer momento as linhas de código
\dq{compiláveis} por trás.
Elaboramos isso no~\reffull[Proofs], onde estabelecemos
nosso sistema de demonstrações e sua linguagem low-level.
No~\reffull[The_integers] botamos isso na prática e começamos
aumentar o nível gradualmente; no~\reffull[Recursion_induction] aprofundamos
nas idéias de recursão e indução e enriquecemos nossa linguagem;
no~\reffull[The_reals] continuamos aumentando o nível, chegando
a escrever numa forma \dterm{mid-level} ou até um tiquinho mais alta.

%%}}}

%%{{{ Programming vs. proving 
\note Programando \vs demonstrando.
%%%{{{ meta 
%%%}}}

Em muitos sentidos \emph{demonstrar} e \emph{programar}
são atividades parecidas---tanto que podemos até identificá-las!\foot
Isso não é um modo de falar, nem um exagero,
mas infelizmente vou ter que pedir para bastante paciência no teu lado,
pois vamos demorar até chegar a entender essa idéia.
\toof
Além disso vou fazer muitas metáforas usando noções de programação.
Caso que o leitor não tem nenhum contato com programação,
deveria começar (aprender) programar em paralelo---com certeza,
mas o que deveria ter dito aqui foi que o leitor sem experiência
de programação vai perder apenas certos exemplos, metáforas, e
referências, e nada essencial.  Esses exemplos são aqui para ajudar
o programador, não para prejudicar o não-programador.
No final das contas, o não-programador já se-prejudica sozinho na vida,
pela falta de\dots ``progranoção''!

%%}}}

%%{{{ Theses vs. hypotheses 
\note Teses \vs hipoteses.
%%%{{{ meta 
%%%}}}

\wq{Tese} vem da grega \emph{θέσις} e similarmente \wq{hipótese} da
palavra \emph{ὑπόθεσις}.
\dterm{Tese} significa \emph{posição},
e nesse sentido também \emph{opinião}.
Tu tens uma tese sobre um assunto, e queres argumentar para defendê-la.
O prefixo \wq{ὑπο-} (hipo-) denota uma idéia de \emph{embaixo de}.
O equivalente prefixo latino (e usado em português) é o \wq{sub-}.
\dterm{Hipoteses} então são \emph{su(b)posições}, ou seja,
afirmações \dq{embaixo} da tese: as proposições de quais a tese depende.

%%}}}

\endsection
%%}}}

%%{{{ Axioms_and_primitive_notions 
\section Axiomas e noções primitivas.
%%%{{{ meta 
\label Axioms_and_primitive_notions
%%%}}}

%%{{{ an ``annoying'' child 
\note Uma criança ``chata''.
%%%{{{ meta 
%%%}}}

Imagine tentando convencer uma criança sobre alguma proposição $P$:
\dialogue
\say $P$.
\say por que $P$?
\say $P$ pois $Q$.
\say E por que $Q$?
\say $Q$ pois $R$.
\say E por que $R$?
\enddialogue
Quem conversou com uma criança sabe que não tem como ganhar nesse
jogo.  Não tem como justificar tudo: esse dialogo continuando
nessa forma nunca vai terminar.
A idéia é que nosso ``oponente'' ou ``inimigo'' (nesse exemplo a criança)
vai continuar duvidando qualquer uma das novas proposições que usamos
em nossa argumentação, \emph{até finalmente chegar em algo que concorda
aceitar}.  Talvez no exemplo da criança chegando numa afirmação do tipo
\wq{comer sorvete é bom} faria o dialogo terminar:
\dialogue
\say \dots pois comer sorvete é bom.
\say Ah sim, faz sentido.
\enddialogue

%%}}}

%%{{{ Euclidean geometry 
\note Um exemplo: geometria euclideana.
%%%{{{ meta 
\label euclidean_geometry_example
\defines
    * geometria!euclideana
    ;;
\credits
    * Euclid : geometria euclideana
    ;;
%%%}}}

Euclides na Grécia antiga elaborou, investigou,
e estabeleceu o que chamamos de \dterm{geometria euclideana}.
Uma das mais importantes idéias que temos desde então é a percepção
que precisamos deixar claro quais são nossos axiomas, e trabalhar
para elaborar nossa teoria, investigando suas conseqüências: os teoremas.
Similarmente, separamos as noções primitivas que aceitamos sem definir
formalmente, e as usando continuamos em aumentar mais e mais nosso vocabulário.
As noções primitivas da geometria euclideana são os \dterm{pontos}
e as \dterm{linhas} (retas).
E também a relação entre pontos e linhas seguinte:
$$
\textwq{o ponto {\lthole} pertence à linha {\lthole}}.
$$
Não definimos o que significa ser um ponto; nem ser uma linha;
nem o que significa que um ponto pertence àlguma linha.
De fato, Euclides tentou dar uma intuição, uma descripção informal
sobre suas noções primitivas em vez de escrever algo do tipo
\quote
Essas aqui são noções primitivas, não me perguntem o que significam; aceitem.
\endquote
A partir dessas noções primitivas, podemos \emph{definir} conceitos interessantes.
Por exemplo, em vez de adicionar como primitiva a noção de linhas parallelas,
podemos realmente definir o que significa ser parallela, numa maneira que
a criança chata do exemplo acima um belo momento cairia apenas em noções
primitivas e não teria como continuar com seus \wq{e o que é\dots?}.

%%}}}

%%{{{ x: define_parallel_line 
\exercise.
%%%{{{ meta 
\label define_parallel_line
%%%}}}

Defina o que significa \dterm{ser parallelas}.

\solution
Começamos assim:
\quote
Definição.
Sejam $a,b$ duas linhas.
Dizemos que $a,b$ são parallelas sse $a,b$ não se tocam.
\endquote
Não podemos parar com essa definição pois no lado direito usamos
uma frase que não significa nada (por enquanto): não definimos
o que significa que duas linhas ``se tocam''.
Basta então definir isso:
\quote
Definição.
Sejam $a,b$ duas linhas.
Dizemos que $a,b$ se tocam sse não existe ponto $p$ tal que
$p$ pertence à linha $a$ e $p$ pertence à linha $b$.
\endquote
Pronto, agora nada ficou ``solto'', acabou sendo reduzido para as noções primitivas de
ponto, linha, e o predicado primitivo de ``ponto pertence a linha''.

%%}}}

\endsection
%%}}}

%%{{{ Arithmetic expressions 
\section Expressões de aritmética.
%%%{{{ meta 
%%%}}}

%%{{{ arithmetic_expressions
\note Expressões sintácticas e sua semântica.
%%%{{{ meta 
\label arithmetic_expressions
\defines
    * expressão!aritmética
    ;;
\indexes
    * aritmética    seealso: expressão
    ;;
%%%}}}

Aprendendo aritmética queremos expressar números numa maneira mais interessante
do que simplesmente usar os próprios nomes deles:
\sq{$2+5$}, por exemplo, é uma \dterm{expressão de aritmética}.
Podemos pensar que essas expressões acabam denotando números:
a expressão \sq{$2+5$} denota \emph{o número 7}.
Alternativamente podemos usá-las para denotar os próprios cálculos:
a expressão \sq{$2+5$} denota \emph{o cálculo de somar o 2 com o 5}.
E nesta paragrafo estou usando o \sq{$2+5$} para referir à propria
expressão sintáctica mesmo.
Mas em todos essas interpretações as expressões de aritmética denotam objetos
(números ou cálculos ou até elas mesmo) e ainda não temos como expressar
\emph{afirmações} sobre eles.

%%}}}

%%{{{ denotational_semantics_first_mention 
\note Semântica denotacional.
%%%{{{ meta 
\label denotational_semantics_first_mention
\defines
    * semântica!denotacional
    ;;
\indexes
    * sintáxe
    * semântica
    ;;
%%%}}}

As expressões fazem parte da \dterm{sintaxe} duma linguagem (aqui, duma
linguagem de aritmética).
Uma \dterm{semântica} atribui um significado para esses objetos
sintácticos.  Já encontramos três exemplos acima: uma interpretou a expressão
como número, outra como cálculo, outra (trivial) como um string mesmo.
Vamos voltar a esse assunto várias vezes, uma das mais interessantes
sendo quando analisaremos essas idéias no contexto de linguagens de programação
(\ref[Denotational_semantics]).

%%}}}

\endsection
%%}}}

%%{{{ Arithmetic_expressions_syntax_vs_semantics 
\section Expressões aritméticas: sintaxe \vs semântica.
%%%{{{ meta 
\label Arithmetic_expressions_syntax_vs_semantics
%%%}}}

%%{{{ precedence 
\note Precedência.
%%%{{{ meta 
\label precedence
\defines
    * precedência
    ;;
%%%}}}

Considere agora a expressão
$$
1 + 5 \ntimes 2
$$
que envolve os numerais $1$, $5$, e $2$,
e os símbolos de funções $(+)$ (adição) e $(\ntimes)$ (multiplicação).
O que ela representa?
A multiplicação de $1 + 5$ com $2$, ou a adição de $1$ com $5 \ntimes 2$?
A segunda opção, graças a uma convenção que temos%
---e que você provavelmente já encontrou na vida.
Digamos que a $(\ntimes)$ ``pega mais forte'' do que a $(+)$,
então precisamos ``aplicá-la'' primeiro.
Mais formalmente, a $(\ntimes)$ tem uma \dterm{precedência} mais alta que a da $(+)$.
Quando não temos convenções como essa, usamos parenteses para tirar a ambigüidade
e deixar claro como parsear uma expressão.
Então temos
$$
(1 + 5) \ntimes 2 \neq 1 + 5 \ntimes 2 = 1 + (5 \ntimes 2).
$$

%%}}}

%%{{{ syntactic_associativity 
\note Associatividade sintáctica.
%%%{{{ meta 
\defines
    * ~A \syneq ~B  -- igualdade sintáctica
    * associatividade!sintáctica
    * igualdade!semântica
    * igualdade!sintáctica
    ;;
%%%}}}

E a expressão
$$
1+5+2
$$
representa o quê?
Não seja tentado dizer \wq{tanto faz}, pois mesmo que as duas
razoáveis interpretações
$$
(1+5) + 2
\qqqqtext{e}
1 + (5+2)
$$
\emph{denotam valores} iguais, elas expressam algo diferente:
$$
\align
(1 + 5) + 2&: \quad\text{adicione o $1+5$ com o $2$};\\
1 + (5 + 2)&: \quad\text{adicione o $1$ com o $5+2$}.
\endalign
$$
Ou seja: a intensão é diferente, 
Então\dots
$$
(1 + 5) + 2 \askeq 1 + (5 + 2)
$$
Como \emph{expressões} (a \emph{sintaxe}) são diferentes;
como \emph{intensões} também;
como \emph{valores} (a \emph{semântica}) são iguais,
pois denotam o mesmo objeto: o número oito.
Como já discutimos (\reftag[Intension_vs_extension]) em matemática
ligamos sobre as denotações das expressões,
e logo escrevemos igualdades como
$$
(1 + 5) + 2 = 6 + 2 = 8 = 1 + 7 = 1 + (5 + 2).
$$
Lembre que o símbolo \symq{$=$} em geral denota
\dterm{igualdade semântica}:
$A=B$ significa que os dois lados, $A$ e $B$, denotam o mesmo objeto.
Querendo representar \dterm{igualdade sintáctica}, às vezes usamos
outros símbolos.  Vamos usar o \symq{$\syneq$} agora, de modo que:
$$
\align
1 + 2 = 3
&\qqqtext{mas}
1 + 2 \synneq 3;\\
(1 + 5) + 2 = 1 + (5 + 2)
&\qqqtext{mas}
(1 + 5) + 2 \synneq 1 + (5 + 2);
\quad\text{etc.}
\endalign
$$
Voltando à expressão \sq{$1 + 5 + 2$}, precisamos
\emph{declarar uma associatividade esquerda ou direita}.
Vamos concordar que \sq{$a + b + c$} representa a expressão
\sq{$((a + b) + c)$}, ou seja, atribuimos à $(+)$ uma
\dterm{associatividade esquerda}.
Mas $(+)$ não é uma operação associativa?
Sim, e isso implica que \emph{como valores},
$$
((a + b) + c) = (a + (b + c)).
$$
Essa associatividade é uma propriedade matemática
(algébrica) da operação $(+)$.  Umas operações binárias
possuem essa propriedade e as chamamos de \dterm{associativas}
(e.g.~adição, multiplicação) e outras não (e.g.~exponenciação).
Por outro lado, a associatividade que \emph{declaramos} acima
não é uma propriedade da operação, não é uma proposição
para demonstrar ou refutar ou nada disso.
É sim uma definição sintáctica, e logo chamamos de
\dterm{associatividade sintáctica}.
Sem essa convenção \sq{$a + b + c$} não representaria
nenhuma expressão de aritmética!

%%}}}

%%{{{ x: syneq or semeq? 
\exercise.
%%%{{{ meta 
\label syneq_or_semeq
%%%}}}

Sejam $a,b,c$ números naturais.
Usando \symq{$=$} para igualdade semântica e \symq{$\syneq$} para igualdade
sintáctica, decida para cada uma das afirmações seguintes
se é verdadeira ou falsa:
% TODO: fix reflabs
\elist i:
\li: $a + b + c                \syneq  a + (b + c)$
\li: $a + b + c                \syneq  (a + b) + c$
\li: $a + b + c                =       a + (b + c)$
\li: $a + b + c                =       (a + b) + c$
\li: $2 \ntimes 0 + 3          =       0 + 3$
\li: $2 \ntimes 0 + 3          \syneq  0 + 3$
\li: $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \syneq  1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \syneq  2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          =       2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li: $1 + 2                    \syneq  2 + 1$
\endelist

\solution
Temos:
\elist i:
\li: $a + b + c                \synneq a + (b + c)$
\li: $a + b + c                \syneq  (a + b) + c$
\li: $a + b + c                =       a + (b + c)$
\li: $a + b + c                =       (a + b) + c$
\li: $2 \ntimes 0 + 3          =       0 + 3$
\li: $2 \ntimes 0 + 3          \synneq 0 + 3$
\li: $(2 \ntimes 0) + 3 + 0    =       1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \synneq 1 + 1 + 1$
\li: $2 \ntimes 0 + 3          \synneq 2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \neq    2 \ntimes (0 + 3)$
\li: $2 \ntimes 0 + 3          \syneq  (2 \ntimes 0) + 3$
\li: $1 + 2                    \synneq 2 + 1$
\endelist

%%}}}

%%{{{ x: syntactic_implies_semantic 
\exercise.
%%%{{{ meta 
\label syntactic_implies_semantic
%%%}}}

Verdadeiro ou falso?:
$$
A \syneq B \implies A = B
$$

%%}}}

\endsection
%%}}}

%%{{{ Language_vs_metalanguage 
\section Linguagem \vs metalinguagem.
%%%{{{ meta 
\label Language_vs_metalanguage
%%%}}}

%%{{{ metalanguage 
\note (Meta)linguagem.
%%%{{{ meta 
\label metalanguage
\defines
    * linguagem-objeto
    * metalinguagem
    ;;
%%%}}}

Já encontramos o conceito de linguagem como um objeto de estudo.
Logo vamos estudar bem mais linguagens, de lógica matemática,
estudar linguagens de programação, etc.
É preciso entender que enquanto estudando uma linguagem,
esse próprio estudo acontece também usando uma (outra) linguagem.
Aqui usamos por exemplo português,\foot
quase
\toof
demonstrando propriedades, dando definições,
afirmando relações, etc., de outras linguagens que estudamos,
como da aritmética, de lógica matemática, de programação, etc.
Para enfatizar essa diferença e para tirar certas ambigüidades,
chamamos \dterm{linguagem-objeto} a linguagem que estudamos,
e \dterm{metalinguagem} a linguagem que usamos para falar
sobre a linguagem-objeto.
Note que todos os símbolos \symq{$\iffsymbol$}, \symq{$\impliessymbol$},
e~\symq{$\impliedbysymbol$} fazem parte da \emph{metalinguagem},
e não é para confundir com os \symq{${\liff}$}, \symq{${\limplies}$},
e~\symq{${\limplied}$} que geralmente usamos como símbolos de
certas \emph{linguagens formais} de lógica.

%%}}}

%%{{{ metavariables 
\note (Meta)variável.
%%%{{{ meta 
\label metavariables
\defines
    * metavariável
    ;;
%%%}}}

Imagine que você trabalha como programador e teu chefe lhe pediu
fazer uma mudança no código de todos os teus programas escritos na linguagem de
programação C.
Ele disse:
\wq{Em todo programa teu $\Pi$, substitua cada variável $\alpha$
de tipo $\tau$ que aparece no código fonte por
$\alpha\code{\_of\_}\tau$.}
\wq{Por exemplo,} ele continuou abrindo o programa no seu editor,
\wq{essa variável aqui $\code{i}$ que é de tipo $\code{int}$,
precisa ser renomeada para $\code{i\_of\_int}$;
e essa $\code{count}$ também para $\code{count\_of\_int}$;
e essa $\code{mean}$ de tipo $\code{float}$, para $\code{mean\_of\_float}$,
etc.}.
\eop
Nesse pedido---obviamente sem noção, algo muito comum em pedidos de chefes
de programadores---aparecem duas ``espécies'' de variáveis diferentes:
as $\Pi$, $\alpha$, e $\tau$ são variáveis de uma espécie;
as $\code{i}$, $\code{i\_of\_int}$,
$\code{count}$, $\code{count\_of\_int}$,
$\code{mean}$, e $\code{mean\_of\_float}$
de outra.
Chamamos as $\Pi$, $\alpha$, e $\tau$ de \dterm{metavariáveis},
pois elas pertencem à metalinguagem, e não à linguagem-objeto,
que nesse exemplo é a linguagem de programação C.
Observe que a metavariável $\Pi$ denota programas escritas na linguagem-objeto (C)
a metavariável $\alpha$ denota variáveis de C,
e a metavariável $\tau$ denota tipos da C.

%%}}}

\endsection
%%}}}

%%{{{ Abbreviations and syntactic sugar 
\section Abreviações e açúcar sintáctico.
%%%{{{ meta 
\label Abbreviations_and_syntactic_sugar
%%%}}}

%%{{{ x: ArEx_outer_parentheses_missing 
\exercise.
%%%{{{ meta 
\label ArEx_outer_parentheses_missing
%%%}}}

Tente gerar a expressão
$$
(1 + 5) \ntimes 2
$$
usando a~\ref[ArEx_bnf_2].

\solution
Não tem como!

%%}}}

%%{{{ abbreviations 
\note Abreviações.
%%%{{{ meta 
\label abbreviations
\defines
    * abreviação
    ;;
%%%}}}

Seguindo nossa~\ref[ArEx_bnf_2], cada vez que escrevemos um
operador binário começamos e terminamos com \symq{$($} e \symq{$)$}
respectivamente.
Logo, \sq{$1 + 2$} nem é uma expressão gerada por essa gramática!
Mas como é tedioso botar as parenteses mais externas,
temos a convenção de omiti-las.
Logo, consideramos a \sq{$1 + 2$} como uma \dterm{abreviação}
da expressão aritmética \sq{$(1 + 2)$}.
Então qual é o primeiro caráter da \sq{$1 + 2$}?
É sim o \symq{$($}, pois consideramos o $1+2$ apenas como um nome
que usamos na metalinguagem para denotar a expressão aritmética
\sq{$(1+2)$}, que pertence à linguagem-objeto.

%%}}}

%%{{{ beware: abbr_not_always_shorter 
\beware.
%%%{{{ meta 
\label abbr_not_always_shorter
%%%}}}

Não se iluda com a palavra ``abreviação'' que usamos aqui:
uma expressão pode ser mais curta do que uma das suas abreviações!
Nosso motivo não é preguiça de escrever;
mas sim ajudar nossos olhos humanos a parsear.

%%}}}

%%{{{ syntactic_sugar 
\note Açúcar sintáctico.
%%%{{{ meta 
\label syntactic_sugar
\defines
    * ~A \sugeq ~B   -- açúcar sintáctico de objeto
    * ~A \sugiff ~B  -- açúcar sintáctico de proposição
    * açúcar sintáctico
    ;;
%%%}}}

Querendo enriquecer uma linguagem com um novo conceito, uma nova operação,
etc., parece que precisamos aumentar sua sintaxe para adicionar certos
símbolos e formas para corresponder nessas novas idéias.
Mas isso não é sempre necessário.
Por exemplo, suponha que trabalhamos com a linguagem da~\ref[ArEx_bnf_3],
e queremos usá-la com sua interpretação canônica, onde suas expressões
aritméticas geradas denotam realmente as operações que conhecemos desde
pequenos.
Agora, queremos adicionar uma operação unária $S$, escrita na forma prefixa,
onde a idéia é que $Sn$ denota o sucessor de $n$ (o próximo inteiro):
$$
Sn \sugeq n + 1
$$
Nesse caso, em vez de realmente alterar a sintaxe da nossa linguagem,
podemos definir como \dterm{açúcar sintáctico} o uso de $S$ tal que,
para qualquer expressão aritmética $\alpha$, o $S\alpha$ denota a
expressão $(\alpha + 1)$.
Por exemplo, $S4$ é apenas uma abreviação para o $(4 + 1)$,
e $SS4$ só pode denotar o $((4 + 1) + 1)$.\foot
Percebeu que esse $\alpha$ aqui é uma metavariável?
\toof
Açúcar sintáctico é muito usado em linguagens de programação,
para agradar os programadores (que ganham assim um mecanismo
``doce'' para usar nos seus programas) sem mexer e complicar
a linguagem de verdade.
Para um exemplo mais perto da vida real, imagine que numa
linguagem orientada a objetos, certos objetos escutem às
mensagens \sq{$\code{.set(\mathit i,\mathit v)}$}
e \sq{$\code{.get(\mathit i)}$} a idéia sendo que utilizamos
a primeira método para atribuir o valor $v$ à posição $i$
e a segunda para solicitar em tal posição.
Mas ninguém merece escrever isso, e logo introduzimos:
$$
\alignat2
&\code{\mathit a[\,\mathit i\,] = \mathit v} &&\quad\sugeq\quad \code{\mathit a.set(\mathit i,\mathit v)} \\
&\code{\mathit a[\,\mathit i\,]}             &&\quad\sugeq\quad \code{\mathit a.get(\mathit i\/)}
\endalignat
$$
Observe que esse açúcar não é um simples \emph{search and replace}
do padrão \sq{$\code{\mathit a[\,\mathit i\,]}$},
pois seu sentido muda dependendo de se aparece no lado esquerdo duma
atribuição (primeira linha) ou não (segunda linha).

%%}}}

%%{{{ x: for_while_sugar 
\exercise.
%%%{{{ meta 
\label for_while_sugar
%%%}}}

Mostre como um $\code{while}$ loop pode ser implementado como
açúcar sintáctico numa linguagem que tem $\code{for}$ loops
mas não $\code{while}$ loops,
e vice versa.

\hint
Use metavariáveis para abstrair as partes interessantes
de cada loop que precisarás (e assim poderás) usar na sua implementação.

\hint
Para implementar o $\code{while}$ por exemplo, considere
que o desafío é transformar o programa $\code{while}(\alpha)\{\kappa\}$.
Para o $\code{for}$, talvez algo como $\code{for}(\alpha;\beta;\gamma)\{\kappa\}$
ajudaria.


%%}}}

%%{{{ x: recursion_loop_sugar 
\exercise.
%%%{{{ meta 
\label recursion_loop_sugar
%%%}}}

Mostre como um $\code{for}$ loop no estilo da linguagem C
pode ser implementado sem usar nenhum dos loops disponíveis
em C (for, while, do-while).

\hint
Recursão.

%%}}}

\endsection
%%}}}

%%{{{ Derivation_trees 
\section Árvores de derivação.
%%%{{{ meta 
\label Derivation_trees
%%%}}}

%%{{{ Parsing 
\note Parsing.
%%%{{{ meta 
\label parsing
\defines
    * parsing
    * árvore!de derivação
    * árvore!sintáctica
    ;;
%%%}}}

Lendo uma expressão ``linear'' como a \sq{$1 + 5 \ntimes 2$}
nós a \dterm{parseamos} para revelar sua estrutura,
freqüentemente representada numa forma bidimensional,
como uma \dterm{árvore sintáctica}.
Temos então as árvores:
$$
1 + (5 \ntimes 2)
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$+$}
  child {node [circle,draw] (a) {$1$}}
  child {node [circle,draw] (b) {$\vphantom+\ntimes$}
    child {node [circle,draw] (b1) {$5$}}
    child {node [circle,draw] (b2) {$2$}}
  };
\endtikzpicture
\endgathered
\qqqquad
(1 + 5) \ntimes 2
\quad\leadsto\quad
\gathered
\tikzpicture[scale=0.8]
\node [circle,draw] (z) {$\vphantom+\ntimes$}
  child {node [circle,draw] (a) {$+$}
    child {node [circle,draw] (a1) {$1$}}
    child {node [circle,draw] (a2) {$5$}}
  }
  child {node [circle,draw] (b) {$2$}};
\endtikzpicture
\endgathered
$$
Não vamos usar mais este tipo de árvore sintáctica nessas notas.

%%}}}

%%{{{ Derivation trees 
\note Árvores de derivação.
%%%{{{ meta 
\indexes
    * derivação    seealso: árvore
    ;;
\defines
    * árvore!de derivação
    ;;
%%%}}}

Em vez, vamos usar \dterm{árvores de derivação} como essas:
$$
\xalignat2
&
\PROOF {
\A {1}
          \A {5}       \A {2}
          \I2---------------- {$(\ntimes)$}
           {$(5 \ntimes 2)$}
\I2------------------------- {$(+)$}
      {$1 + (5 \ntimes 2)$}
}
&&
\PROOF {
\A {1}    \A {5}
\I2------------- {$(+)$}
   {$(1 + 5)$}            \A {2}
   \I2-------------------------- {$(\ntimes)$}
        {$(1 + 5) \ntimes 2$}
}
\endxalignat
$$
Sendo esse nosso primeiro contato com árvores sintácticas, vou explicar
em detalhe como as escrevemos.  Começamos então com a expressão (linear)
que queremos parsear:
$$
(1 + 5) \ntimes 2.
$$
Graças à sua parêntese, o ``operador principal'' (o mais ``externo'')
é o $(\ntimes)$\;.  Isso quer dizer que, no final das contas, essa expressão
representa uma multiplicação de duas coisas.
Exatamente por isso, reduzimos essa expressão em duas novas, escrevendo
uma linha em cima dela, onde temos agora dois lugares para botar essas
duas coisas.  No lado da linha, escrevemos sua ``justificativa''
$$
\PROOF {
\A {$\hole$}     \A {$\hole$}
\I2-------------------------- {$\holed \ntimes$}
     {$(1 + 5) \ntimes 2$}
}
$$
e nos dois buracos que aparecem botamos as expressões que estão
nos lados desse $(\ntimes)$:
$$
\PROOF {
\A {$\holed {(1 + 5)}$}    \A {$\holed {\vphantom(2}$}
\I2--------------------------------------------------- {$(\ntimes)$}
                    {$(1 + 5) \ntimes 2$}
}
$$
Agora \sq{$2$} já é uma expressão \dterm{atômica} (ou seja, inquebrável),
mas a \sq{$(1 + 5)$} não é; então repetimos o mesmo processo nela:
$$
\PROOF {
\A {$\holed 1$}    \A {$\holed 5$}
\I2------------------------------- {$\holed +$}
             {$(1 + 5)$}
                              \A {${\vphantom(2}$}
           \I2------------------------------------ {$(\ntimes)$}
                    {$(1 + 5) \ntimes 2$}
}
$$
Chegamos finalmente na árvore
$$
\PROOF {
\A {$1$}    \A {$5$}
\I2----------------- {$(+)$}
      {$(1 + 5)$}
                       \A {${\vphantom(2}$}
      \I2---------------------------------- {$(\ntimes)$}
               {$(1 + 5) \ntimes 2$}
}
$$
que mostra como a expressão aritmética \sq{$(1 + 5) \ntimes 2$}
que é a \dterm{raiz} (ou \dterm{root}) dessa árvore é composta por
os numerais $1$, $5$, e $2$ que são as suas \dterm{folhas}
(ou \dterm{leaves}).

%%}}}

%%{{{ Q: What did we derive? 
\question.
%%%{{{ meta 
%%%}}}

Mas, como assim ``de derivação''?  O que derivamos?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
\pdefs
    \pdef ArExp {\namedtype{ArExp}}
    ;;
%%%}}}

Podemos visualizar a árvore acima como uma derivação (demonstração!)~da
afirmação \wq{\sq{$(1+5) \ntimes 2$} é uma expressão de aritmética} que
podemos simbolizar assim:
$$
(1 + 5) \ntimes 2 \is \ArExp.
$$
Cada node da árvore (incluindo sua raiz e suas folhas) são
afirmações, mesmo se a parte de afirmar fica invisível (implícita).
Aqui todas as nodes têm a mesma parte invisível.
Aqui a mesma árvore com nada invisível:
$$
\PROOF {
\A {$1 \is \ArExp$}    \A {$5 \is \ArExp$}
\I2------------------------------------------- {$(+)$}
              {$(1 + 5) \is \ArExp$}
                                              \A {${\vphantom(2 \is \ArExp}$}
              \I2--------------------------------------------------------------- {$(\ntimes)$}
                               {$(1 + 5) \ntimes 2 \is \ArExp$}
}
$$

%%}}}

\endsection
%%}}}

%%{{{ More_errors 
\section Mais erros.
%%%{{{ meta 
\label More_errors
%%%}}}

%%{{{ logical_error 
\note De lógica.
%%%{{{ meta 
\label logical_error
\defines
    * falácia
    ;;
%%%}}}

Uma argumentação errada envolve concluir algo que não segue
necessariamente pelas premissas usadas:
talvez usamos incorretamente uma hipótese,
talvez reduzimos incorretamente nosso alvo para outro,
\dots
Assim, não conseguimos convencer uma pessoa que sabe
pensar sobre a validade da nossa tese.
Em termos de programação, nosso programa
(i.e., nossa demostração) \emph{não compilou!}
Durante esse texto vamos encontrar e discutir várias \dterm{falácias},
ou seja, erros comuns em argumentação, mas não vamos focar agora em
criar e discutir uma lista de falácias aqui.
Logo no~\ref[Proofs] estudaremos qual é a maneira correta de
raciocinar e demontrar proposições e também discutimos umas
falácias comuns (\reftag[Fallacies]).
Mas só pra te dar uma idéia desde já, vamos ver um exemplo
duma argumentação.

%%}}}

%%{{{ eg: olive_tree 
\example.
%%%{{{ meta 
\label olive_tree
%%%}}}

Considere a inferência seguinte, que quer convencer alguém sobre
a tese que uma certa árvore é uma oliveira.
\quote
\flwq{Oliveiras têm azeitonas.\CR
Essa árvore tem azeitonas.\CR
Portanto, essa árvore é uma oliveira.}
\endquote
Aqui a partir das hipoteses nas duas primeiras linhas,
inferimos a tese (terceira).

%%}}}

%%{{{ Q: Is everything OK with this inference? 
\question.
%%%{{{ meta 
%%%}}}

Tá tudo OK com essa inferência?

%%}}}

\spoiler

%%{{{ A: Nope 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não, a inferência tá erradíssima, mesmo que sua conclusão---por sorte!---acontece
que é válida: o processo de inferi-la, não foi!
Compare com:
\quote
\flwq{Jogadores de basquetes são fortes.\CR
Esse homem é forte.\CR
Portanto, esse homem é jogador de basquete.}
\endquote
Observe que a estrutura da inferência é exatamente
\emph{a mesma} com a anterior.  Não parecida; mesma!
Outra maneira: substitua a palavra \sq{árvore}
pela palavra \sq{pizza} na argumentação original.

%%}}}

%%{{{ mathematical_error 
\note De matemática.
%%%{{{ meta 
\label mathematical_error
%%%}}}

Usando propriedades inválidas, erros em cálculos, etc.
Não tem muita coisa para discutir sobre esse tipo de erro:
ficar acordado ajuda evitá-los.

%%}}}

%%{{{ semantical_error 
\note De semântica.
%%%{{{ meta 
\label semantical_error
%%%}}}

Isso acontece quando o que escrevemos realmente significa algo,
mas não o que temos na nossa cabeça.
É quando um programador escreveu seu cógido e ele compilou ``com
sucesso'', mas o programa que foi criado não faz o que ele queria.
Isso acontece muito dando definições como discutimos
na~\ref[Definitions].

%%}}}

%%{{{ ethical_aesthetical_error 
\note De ética e de estética.
%%%{{{ meta 
\label ethical_aesthetical_errors
\defines
    * erro!de aestética
    * erro!de ética
    ;;
%%%}}}

\emph{Meio} brincando, quero analisar mais dois tipos de erros.
\dterm{Erro ético} é uma escolha de nome ou notação desonesta,
que ajuda o leitor---ou até o escritor---errar.
\dterm{Erro de aestética} seria uma escolha de nome ou notação que
quebra um padrão ou uma convenção estabelecida; algo que introduz uma
complexidade desnecessária.  Um bom programador dedica grande parte do
seu tempo na escolha de nomes para suas variáveis, suas funções, etc.
Um nome bom deve ajudar em pensar, carregar informação correta sem ficar
pesado ou cansativo para usar, etc.
Com prática tu deves desenvolver um bom gosto nisso!

%%}}}

%%{{{ eg: ethical_aesthetical_errors 
\example.
%%%{{{ meta 
%%%}}}

Considere a frase:
\quote
\wq{Para quaisquer $a,x,y\in\ints$ se $a$ divide $x$ e $x$ divide $y$ então $a$ divide $y$.}
\endquote
A escolha de nomes dessas variáveis não faz sentido nenhum.  Queremos três nomes para os três inteiros que estão na mesma situação, moram no mesmo bairro, são parentes da mesma família.  Não faz sentido quebrar a norma alfabética pegando um nome do bairro dos $a,b,c,\dots$ e outros dois do bairro dos $x,y,z,\dots$.
Outra:
\quote
\wq{Seja $n$ um número real e seja $x$ o menor natural tal que $n \leq x$.}
\endquote
Aqui temos um natural e um real e escolhemos a letra `n' para o real.  Bizarro.

%%}}}

\endsection
%%}}}

%%{{{ Heart_level_and_slang 
\section Nível coração e palavras de rua.
%%%{{{ meta 
\label Heart_level_and_slang
%%%}}}

\TODO terminar.

%%{{{ intro 
\secintro
O maior objetivo deste texto é te ajudar elaborar
teu entendimento de matemática nos dois níveis.
Não faz sentido pensar que esses dois lados estão
combatendo um o outro.  Eles se ajudam e se completam,
e estão dando à matemática sua elegância e beleza
característica.
%%}}}

%%{{{ two_levels_of_understanding 
\note Dois níveis de entendimento.
%%%{{{ meta 
\label two_levels_of_understanding
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ heart_level 
\note Nível coração.
%%%{{{ meta 
\label heart_level
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ advice: slang_advice 
\advice palavras de rua.
%%%{{{ meta 
%%%}}}

Vamos dizer que acabamos de definir um objeto.
Então crie um apelido legal para esse objeto.
Sinta-se à vontade virar de melhor amigo até um bully.
Quais são as propriedades que ele tem?
O que \dterm{característico} sabemos dele?
É um conjunto?
Então\dots se fosse um time, qual seria o nome dele?
Se fosse uma banda, uma empresa, um vilarejo?
E esses membros que já temos mencionado nele,
como traduzem na nossa metáfora?
É uma função?
Talvez algo que termina em {-or(a)}?
É uma relação?
Então invente uma gíria significativa para
a \dq{situação} descrita por ela.
Use tua imaginação, teu humor, inspira-se
de coisas que tu conhece bem e que tu gosta.
Quando puder, tente fazer isso em mais que uma maneira:
no teu bairro então o tal objeto ganhou esse apelido;
quais outros apelidos tu acha que ele tem em outros bairros?
\emph{Cada apelido, cada gíria, é mais uma ferramenta
valiosa para pensar; não subestime esse processo!}
E muitas vezes, uma metáfora boa num contexto, que nos ajudou
pensar e chegar numa idéia linda, pode acabar nos limitando em outro,
ou, até pior, nos ajudar errar, nos levar para caminhos inúteis, etc.

%%}}}

%%{{{ mechanic_level 
\note Lado mecânico.
%%%{{{ meta 
\label mechanic_level
%%%}}}

Aí chega o outro lado do entendimento que não vai nos permitir
ser enganados e levados por esses caminhos errados.
E, alem disso, nos momentos que nossas metáforas não nos ajudam,
ou que simplesmente não temos nenhuma maneira ``de rua'' para
descrever e pensar, ele pode nos dar o apóio para andar uns passos
no jogo, seguindo agora nossa intuição elaborada jogando o jogo
e conhecendo suas regras.

%%}}}

%%{{{ advice: game_advice 
\advice jogo formal.
%%%{{{ meta 
\label mechanic_advice
%%%}}}

No~\ref[Proofs] estudamos os principais conectivos de lógica
que mais usamos em matemática.  Lá enfatiso o ponto que
matemática pode ser vista como um jogo formal, com suas
regras e seu objetivo: o jogador joga escrevendo demonstrações
e definições, seguindo as regras do jogo.
Como tu vai ver, temos até um tabuleiro (de Dados/Alvos)
e cada ``movimento'' no jogo é uma linha, que altera
o estado desse tabuleiro.
Quando tu tá tentando escrever ou entender uma demonstração,
\emph{fique atualizando esse tabuleiro no teu rascunho,
com cada linha escrita ou lida!}

%%}}}

%%{{{ notation 
\notation.
%%%{{{ meta 
\defines
    * ~A \hearteq ~B   -- os $A,B$ são sinônimos no nível coração, com palavras de rua
    * ~A \heartiff ~B  -- as $A,B$ são sinônimas no nível coração, com palavras de rua
    ;;
%%%}}}

Para enfatizar que estou\dots \dq{caindo}, \dq{subindo}, ou \dq{entrando}
ao nível coração, decoro os símbolos correspondentes com um $\heart$.
Aqui uns exemplos imaginários para ilustrar:
$$
\xalignat2
r    &\hearteq \text{o árbitro};        & f(x) \leadsto g(x)  &\heartimplies \text{$x$ é triste}; \\
G    &\hearteq \text{os goleiros};      & u < v               &\heartiff     \text{$u$ observa $v$}; \\
g(T) &\hearteq \text{o goleiro do $T$}; & r = g(A)            &\heartiff     \text{o árbitro é o goleiro do $A$}; \\
N(x) &\hearteq \text{o bairro do $x$};  & N(x) = N(y)         &\heartiff     \text{$x,y$ são vizinhos}.
\endxalignat
$$

%%}}}

\endsection
%%}}}

%%{{{ Further reading 
\further.

Matemática elementar:
\cite[simmonsprecalculus] (para uma revisão rápida);
\cite[langbasicmath] (para uma (re)visão com mais detalhes).

Sobre geometria euclideana:
\cite[elements],
\cite[coxeterrevisited];
\cite[hartshorneeuclidbeyond].

Mais sobre falácias:
\cite[wiki:List_of_fallacies].

Sobre linguagens:
\cite[curryfoundations: Cap.~2].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Proofs 
\chapter Demonstrações.
%%%{{{ meta 
\label Proofs
%%%}}}

\TODO terminar e arrumar.

%%{{{ intro 
\chapintro
Neste capítulo estudamos varios tipos diferentes de proposições,
e para cada uma discutimos qual é a maneira correta de usá-la
para inferir algo novo, e também o que conta como argumentação
válida para demonstrá-la.
Para cada proposição precisamos saber:
\tlist:
\li: como atacá-la;
\li: como usá-la.
\endtlist
Aqui \emph{atacar} significa \emph{progressar em demonstrar},
e nesse contexto \emph{matar um teorema} é sinónimo de
\emph{demonstrar um teorema}.\foot
Vamos pegar emprestada muita da terminologia de \emph{jogos}
e de \emph{programação} para nos ajudar comunicar certas idéias.
\toof
(Lembra do túmulo \sq{$\qedsymbol$} de {\Halmos}Halmos?)
A partir dessas ``regras principais'' e talvez outros princípios de lógica
podemos derivar mais maneiras de usar ou de demonstrar proposições.
Para realmente aprender como demonstrar teoremas,
existe apenas um caminho: \emph{demonstrando}.
E vamos fazer isso no resto desse texto mesmo.
Nosso objectivo aqui \emph{não é} estudar profundamente estratégias
de demonstração num contexto abstrato, mas apenas introduzir umas
idéias e estabelecer uma terminologia e metodologia para nos ajudar
demonstrar teoremas e falar sobre demonstrações.
Durante esse capítulo vamos desenvolver uma
\emph{linguagem de demonstração} e usá-la como um ``backend'',
uma low-level linguagem em qual as nossas demonstrações
escritas numa linguagem mais humana ``compilam''.
%%}}}

\TODO diss truth tables.

%%{{{ Proofs, games, programs 
\section Demonstrações, jogos, programas.
%%%{{{ meta 
\label proofs_games_programs
%%%}}}

%%{{{ lorenzen dialogue games 
\note.
%%%{{{ meta 
%%%}}}

Existem várias maneiras de usar jogos para estudar demonstrações.
Num dos mais comuns, é selecionada uma afirmação e dois jogadores
estão jogando um \emph{contra} o outro:
um acredita na afirmação e está tentando demonstrá-la;
o outro não, e está tentando refutá-la.
Muitas variações disso existem e correspondem principalmente
em alterações da ``lógica por trás''.

%%}}}

%%{{{ one-player game 
\note.
%%%{{{ meta 
%%%}}}

Mas aqui vamos usar terminologia de jogos numa maneira
diferente, onde o jogo é jogado só por você mesmo,
como um jogo de Solitaire ou de Minesweeper.\foot
Podes visualizar esses jogos como jogos de 2 jogadores
onde teu oponente só joga uma vez (e joga primeiro) escolhendo
a ordem das cartas no caso de Solitaire ou onde botar as minas no
caso de Minesweeper.  Após disso, quem joga é apenas você.
\toof
Tu estás jogando com um ou mais alvos, onde cada alvo é uma afirmação
matemática que tu estás querendo matá-la (demonstrar).
Para conseguir isso, tu tens na tua disposição:
certas \emph{armas}: os seus dados (hipoteses),
definições, teoremas, etc., e finalmente \emph{a própria lógica},
que é representada aqui por \emph{as próprias regras do jogo}.
O jogo é feito numa maneira que se não roubar
(ou seja, se seguir as regras),
então tua demonstração realmente estabelece a veracidade dos teus alvos.

%%}}}

%%{{{ where's the compiler? 
\note Cadê o compilador?.
%%%{{{ meta 
\label where_is_the_compiler
%%%}}}

Um dos maiores problemas em nossos primeiros contatos com
matemática \emph{de verdade}, é ``roubar sem querer''.
Em programação, o compilador assume bastante um papel de
regulador que não nos permite roubar.
O desafio em matemática é que, escrevendo uma demonstração, estamos assumindo
o papel tanto do programador quanto do compilador.
No início isso pode aparecer uma carga muito pesada,
mas praticando acaba sendo algo natural.
No mesmo sentido, o programador iniciante ``briga'' com o compilador
o tempo todo, e com mais experiência ele assume (conscientemente ou não)
cada vez mais um papel de compilador mental também, e acaba brigando
cada vez menos com o compilador da sua máquina.

%%}}}

%%{{{ the game and its board 
\note O jogo e seu tabuleiro (REPL).
%%%{{{ meta 
\defines
    * proof!script
    * proof!state
    * estado!de demonstração
    * REPL!de demonstração
    * script!de demonstração
    ;;
\indexes
    * demonstração       seealso: proof
    * demonstração!REPL      see: REPL
    * demonstração!script    see: script
    * demonstração!estado    see: estado
    * state                  see: estado
    ;;
%%%}}}

Podemos pensar que o jogo acontece em duas partes.
A primeira parte é a \wq{\proofName}:
É aqui que o jogador (você) joga, onde cada movimento
é escrever uma frase mais nessa parte.
Chamamos essa parte também de \dterm{proof script}.
A segunda parte é a tabela de Dados/Alvos.
O enunciado do teorema que queres demonstrar cria o contexto da prova,
ou seja, ele está deixando claro quais são os \emph{dados},
e qual (ou quais) os \emph{alvos}.
Com cada movimento---ou seja, frase escrita na parte
\wq{\proofName})---a tabela
dos Dados/Alvos muda para refletir a situação atual
do jogo: o \dterm{estado} (ou \dterm{state}).
Novos dados podem ser adicionados, uns alvos podem
ser matados, outros nascidos.
O jogo termina quando não tem mais nenhum alvo vivo.
\eop
As partes do jogo e seu tabuleiro parecem assim então:
\repl
~ x: phantomed placeholder ;
\givens
~ x: phantomed placeholder ;
\goals
~ x: phantomed placeholder ;
\endrepl

%%}}}

%%{{{ eg: x odd => x^2 odd 
\example.
%%%{{{ meta 
%%%}}}

Nesse exemplo encontramos uma demonstração dum teorema sobre inteiros.
Neste momento apenas siga essa demonstração, movimento-por-movimento,
para entender a idéia desse jogo e nada mais.
A afirmação que queremos demonstrar é a seguinte:
$$
\textwq{Todos os quadrados de ímpares são ímpares.}
$$
Primeiramente precisas entender bem a forma do teu alvo:
$$
\lforall {n \is \Int} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}}
$$
Bora começar jogar então!
\repls
\maxproof  : Suponha $x$ ímpar. ;
\maxgiven  : \ \ \lexists {k \is \Int} {x = 2k+1}  ;
\maxgoal   : \lforall {n \is \Int} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
\repl
\givens
\goals
~     : \lforall {n \is \Int} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
\endrepl
Começamos com nossa primeira linha:
\repl
~ a   : Seja $x$ inteiro. ;
\givens
~ a   : x \is \Int ;
\goals
~ a/  : \lforall {n \is \Int} {\text{$n$ ímpar} \implies \text{$n^2$ ímpar}} ;
~ a   : \text{$x$ ímpar} \implies \text{$x^2$ ímpar} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~ a   : Suponha $x$ ímpar. ;
\givens
~     : x \is \Int ;
~ a  t: $x$ ímpar ;
\goals
~ a/  : \text{$x$ ímpar} \implies \text{$x^2$ ímpar} ;
~ a  t: $x^2$ ímpar ;
\endrepl
\endrepls
Neste momento, olhamos para o tabuleiro de Dados/Alvos e anotamos, como rascunho,
o significado dumas dessas afirmações.
\repls
\maxproof : Seja $k \is \Int$ tal que $x = 2k+1$. ;
\maxgiven : \ \ \lexists {k \is \Int} {x = 2k+1}  ;
\maxgoal  : \ \ \lexists {a \is \Int} {x = 2a+1}  ;
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
\givens
~     : x \is \Int ;
~    t: $x$ ímpar ;
~    =: \lexists {k \is \Int} {x = 2k+1} ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a \is \Int} {x^2 = 2a + 1} ;
\endrepl
Poderiamos escrever uma
\emph{linha de comentário} na nossa demonstração,
mas por enquanto quero mostrar apenas as
\emph{linhas de código} mesmo.
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~ a   : Seja $k \is \Int$ tal que $x = 2k+1$. ;
\givens
~     : x \is \Int ;
~    t: $x$ ímpar ;
~ a   : k \is \Int ;
~ a   : x = 2k + 1 ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a \is \Int} {x^2 = 2a + 1} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~     : Seja $k \is \Int$ tal que $x = 2k+1$. ;
~ a   : Calculamos: ;
~,a  c: x^2 &= (2k+1)^2 \\
            &= 4k^2 + 4k + 1 \\
            &= 2(2k^2+2k) + 1 \\ ;
\givens
~     : x \is \Int ;
~    t: $x$ ímpar ;
~     : k \is \Int ;
~     : x = 2k + 1 ;
~ a   : x^2 = 2(2k^2 + 2k) + 1 ;
\goals
~    t: $x^2$ ímpar ;
~    =: \lexists {a \is \Int} {x^2 = 2a + 1} ;
\endrepl
\repl
~     : Seja $x$ inteiro. ;
~     : Suponha $x$ ímpar. ;
~     : Seja $k \is \Int$ tal que $x = 2k+1$. ;
~     : Calculamos: ;
~,   c: x^2 &= (2k+1)^2 \\
            &= 4k^2 + 4k + 1 \\
            &= 2(2k^2+2k) + 1 \\ ;
~ a   : Usando o inteiro $2k^2+2k$, ;
~,a s :   temos que $x^2$ é ímpar. \qed;
\givens
~     : x \is \Int ;
~    t: $x$ ímpar ;
~     : k \is \Int ;
~     : x = 2k + 1 ;
~     : x^2 = 2(2k^2 + 2k) + 1 ;
~ a  t: $x^2$ ímpar ;
\goals
~ a/ t: $x^2$ ímpar ;
~    =: \lexists {a \is \Int} {x^2 = 2a + 1} ;
\endrepl
\endrepls
Matamos todos os alvos---só tinha um---então podemos concluir que o que
queríamos demonstrar, foi demonstrado (ou seja: é um teorema mesmo).

%%}}}

%%{{{ remark: the text above is terrible 
\remark.
%%%{{{ meta 
%%%}}}

O texto que a demonstração acabou sendo talvez pouco \emph{feio}.
Parece escrito por um robô que não entende nada (mas mesmo assim é eficaz).
Não costumamos escrever demonstrações nesse jeito.
Em vez disso, um texto \dq{real e humano} que corresponde
nessa demonstração seria algo do tipo:
\quotepar
Seja $x$ inteiro ímpar,
e logo seja $k\in\ints$ tal que $x = 2k + 1$.
Preciso mostrar que $x^2$ é ímpar também.
Calculamos:
$$
x^2 = (2k+1)^2 = 4k^2 + 4k + 1 = 2(2k^2+2k) + 1.
$$
Como $2k^2+2k\in\ints$, logo $x^2$ é ímpar.
\endquote
Mesmo assim, é importante entender o \dq{backend} e esse
lado \emph{dinâmico} duma demonstração, em termos da tabela \dq{Dados/Alvo(s)}
e das mudanças que estão acontecendo nela.
Então quando tu vai escrever tuas próprias demonstrações,
pelo menos no início, podes aproveitar um rascunho
para fazer teu \emph{bookkeeping}, escrevendo e apagando
coisas nele com cada frase que escreveu na tua prova.
Com mais experiência, esse processo vai virar automático e subconsciente.

%%}}}

%%{{{ REPL 
\note REPL.
%%%{{{ meta 
\label REPL
\indexes
    * LISP
    * Python
    * programação
    ;;
\defines
    * REPL
    ;;
%%%}}}

Muitas linguagens de programação hoje em dia têm \dterm{REPL:}
Read--Eval--Print Loop.
Começou em LISP e é exatamente o que ele promete.
Um programa que:
(1) lê expressões (em geral escritas pelo usuário);
(2) calcula para achar o valor da expressão;
(3) imprime o valor
(4) loop para o (1).
Executando o programa \tool{python} por exemplo, abrimos
uma sessão com o REPL da linguagem Python, e brincamos
com o sistema.
Abrindo o REPL certas coisas já estão definidas e carregadas
na memória, e muitas vezes abrimos já especificando um
\dterm{script}, um arquivo que contem linhas de código
e que já defina várias coisas na nossa linguagem.
Podemos pensar que uma demonstração é parecida com uma
sessão num REPL, onde o script carregado é o enunciado
da demonstração, e cada linha que escrevemos na demonstração
corresponde numa linha que o programador escreveria no REPL.
Uma diferença é que o demonstrador precisa assumir o
papel de tanto do escritor quanto do sistema, não vai
ver nada impresso, e nenhum cálculo vai ser feito
\emph{para} ele; tudo \emph{por} ele mesmo.
Consideramos então que os cálculos utilizados fazem
parte da demonstração, e precisamos justificar cada
passo deles.
\emph{Obviamente} certos passos deixamos sem
justificativa se as consideramos óbvias, mas vejá
também o~\ref[obvious_trivial_immediate].

%%}}}

%%{{{ code_vs_comment 
\note Linha de código \vs comentário.
%%%{{{ meta 
\label code_vs_comment
%%%}}}

Vamos continuar pouco ainda mais essa metáfora relacionada a programação.
Lendo um texto de demonstração certas partes valem como linhas de
código e outras como comentários.
\dterm{Linhas de código} tem efeito no tabuleiro do jogo:
mudam algo nos alvos ou nos dados.
\dterm{Comentários} servem o mesmo propósito em programação: ajudar
o leitor (humano) do nosso código entender nossa idéia e seguir
nossos passos; não fazem parte da demonstração;
não oferecem nenhum progresso.
Com prática---e dependendo de quem é o teu alvo
(leitor)---tu vai ganhar uma noção de onde botar
um comentário, quão detalhado deveria ser, etc.\foot
Cuidado pois existe um máu hábito de decorar programas
com comentários demais, e o mesmo problema pode
acontecer com demonstrações.
Tanto em programação quanto em demonstração a dica
é a mesma sobre escrever comentários:
\emph{escreva um comentário apenas se sua falta
deixaria o leitor confuso}.
Seja lacônico.
\toof

%%}}}

%%{{{ keywords 
\note Keywords.
%%%{{{ meta 
%%%}}}

Cada linguagem de programação tem seus \dterm{reserved keywords}
que, quando usados corretamente formam expressões e outras
construções da linguagem para finalmente virar um programa.
Por exemplo uns keywords de C seriam os
$\code{if}$, $\code{while}$, $\code{int}$, $\code{void}$, $\code{switch}$, etc.
Observe que tem várias categorias sintacticamente corretas:
expressões, comandos, literais, etc., e a gramática da linguagem
não nos permite trocar uma frase duma categoria para uma frase de outra.
Uma frase da categoria \emph{declaração de variável}, por exemplo,
precisa começar com uma frase da categoria \emph{tipo}
(por exemplo \sq{$\code{int}$} seguida por uma frase da categoria \emph{variável}
(por exemplo \sq{$\code{x1}$}) e terminar com o \sq{$\code{;}$}.
Assim foi formada a declaração
$$
\code{int x1;}
$$
Lembra que falei que demonstrar e programar é a mesma coisa?
Bem; em demonstrações, é a mesma coisa!
Temos as categorias de frases, os keywords, e as regras que precisamos
seguir para escrever frases bem formadas, e também as regras de lógica
que precisamos respeitar, se é pra nosso código ``compilar'' e servir
o seu propósito.
Exemplos de keywords são \emph{\symqq{seja}}, \emph{\symqq{ou}},
\emph{\symqq{suponha}}, \emph{\symqq{tal que}}, etc.

%%}}}

\endsection
%%}}}

%%{{{ Attacking the logical structure of a proposition 
\section Atacando a estrutura lógica duma proposição.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Enquanto nosso alvo não é atômico, podemos atacá-lo numa maneira direta,
``batendo na lógica'' mesmo.
Similarmente, tendo dados não atômicos podemos usá-los na nossa
demonstração considerando a estrutura lógica deles.

%%}}}

%%{{{ x: how_to_use_and_how_to_attack_each_connective 
\exercise.
%%%{{{ meta 
\label how_to_use_and_how_to_attack_each_connective
%%%}}}

Até agora encontramos como usar os $\exists,\land$ e como atacar os $\forall,\exists,\limplies$.
Para cada um dos conectivos que ainda não achamos como usar ou atacar, pense em:
o que tu podes escrever na tua demonstração; o que efeito tem nos dados; e o que nos alvos.
$$
\vbox{\halign{
\hfil##\hfil            &\qquad ##\quad\hfil              & \qquad ## \hfil\cr
                        & {\bf Usar}                      & {\bf Atacar}\cr
\tablethickrule
$\sforall x \phi(x)$    & $?^{\phantom?}$                 & <<Seja $u$.>>\cr
                        &                                 & Novos dados: $u$\cr
                        &                                 & Novo alvo: $\phi(u)$\cr
\tablerule
$\sexists x \phi(x)$    & <<Seja $u$ tal que $\phi(u)$.>> & <<Demonstrarei $\phi(u)$.>> (eu escolho o $u$)\cr
                        & Novos dados: $u$, $\phi(u)$     & Efeito nos dados: --\cr
                        & Efeito nos alvos: --            & Novo alvo: $\phi(u)$\cr
\tablerule
$\phi \land \psi$       & --                              & ?\cr
                        & Novos dados: $\phi$, $\psi$     &  \cr
                        & Efeito nos alvos: --            &  \cr
\tablerule
$\phi \lor \psi$        & ?                               & ?\cr
                        &                                 &  \cr
                        &                                 &  \cr
\tablerule
$\phi \limplies \psi$   & ?                               & <<Suponha $\phi$.>>\cr
                        &                                 & Novo dado: $\phi$\cr
                        &                                 & Novo alvo: $\psi$\cr
\tablerule
$\lnot \phi$            & ?                               & ?\cr
}}
$$

%%}}}

\endsection
%%}}}

%%{{{ Igualdade 
\section Igualdade.
%%%{{{ meta 
\label Equality
%%%}}}

%%{{{ Laws 
\law Leis da igualdade.
%%%{{{ meta 
\headerize
\label laws_of_eq
%%%}}}

Aceitamos como parte da nossa lógica que a igualdade é:
\dterm{reflexiva}, \dterm{simétrica}, e \dterm{transitiva}:
$$
\PROOFmr {
\I0---------------- {Refl}
   {\alpha = \alpha}
}
\qquad
\PROOFmr {
\A {\alpha = \beta}
\I1------------------ {Sym}
   {\beta = \alpha}
}
\qquad
\PROOFmr {
\A {\alpha = \beta}
\A                       {\beta = \gamma}
\I2---------------------------------------- {Trans}
           {\alpha = \gamma}
}
$$
Além disso, aceitamos a \dterm{lei de substituição:}
\emph{em qualquer fórmula ou qualquer termo podemos
substituir um subtermo por um igual
sem mudar o significado da fórmula ou termo}.

%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
%%%}}}

Ganhando como dado o $\alpha = \beta$, tu agora podes
substituir $\alpha$ por $\beta$ e vice versa em qualquer
contexto que eles aparecem!

%%}}}

%%{{{ How to attack? 
\note Como atacar?.
%%%{{{ meta 
%%%}}}

Simples: pega um lado, e calcule até chegar no outro!
Às vezes fica difícil enxergar um caminho direto de $\alpha$
pra $\beta$; nesse caso tente pegar um lado até chegar num ponto $\gamma$; depois pega o outro lado e se conseguir chegar no mesmo ponto $\gamma$, teu alvo já era!

%%}}}

\endsection
%%}}}

%{{{ Real_life_proof_examples 
\section Real-life exemplos: divisibilidade.
%%%{{{ meta 
\label Real_life_proof_examples
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para brincar com algo da ``vida real'', vamos definir
a relação de \emph{dividir} entre números e demonstrar
vários teoremas relacionados.

%%}}}

\TODO espalhar os teoreminhas no capítulo todo e botar mais.

%%{{{ definition of divides for now
\blah Definição.
%%%{{{ meta 
%%%}}}

Sejam $a,b\in\ints$.
Digamos que \dterm{o $a$ divide o $b$} (ou \dterm{o $b$ é divisível por $a$}), sse $b = ak$ para algum $k\in\ints$.
Nesse caso, escrevemos $a \divides b$.
Em símbolos:
$$
a \divides b \defiff \lexists {k\in\ints} {b = ak}.
$$
Os \dterm{divisores} do $a$ são todos os inteiros $d$ tais que $d \divides a$.
Naturalmente, usamos a notação $a\ndivides b$ quando $a$ não divide $b$.

%%}}}

%%{{{ eg: divides_and_ndivides_examples 
\example.
%%%{{{ meta 
\label divides_and_ndivides_examples
%%%}}}

$3 \divides 12$, porque $12 = 3 \ntimes 4$ e $4\in\ints$, mas
$8 \ndivides 12$, porque, nenhum inteiro $u$ satisfaz $12 = 8u$.
\mistake

%%}}}

%%{{{ x: wrong_use_of_because 
\exercise.
%%%{{{ meta 
\label wrong_use_of_because
%%%}}}

Qual o problema no~\ref[divides_and_ndivides_examples]?

\solution
A segunda ocorrência da palavra \wq{porque} não faz sentido nenhum:
o que segue depois não é uma justificação da tese $8 \ndivides 12$,
mas sim apenas uma repetição da mesma afirmação.
Essencialmenteo que tá escrito nessa frase é:
\standout
\emph{o 8 não divide o 12 porque o 8 não divide o 12.}
\endstandout
Substituindo por um <<ou seja>>, a frase faz sentido, e serve
apenas como um \emph{comentário}, lembrando para o leitor a definição:
\standout
$8 \ndivides 12$, \emph{ou seja}, nenhum inteiro $u$ satisfaz $12 = 8u$.
\endstandout
Procure mais sobre isso no~\ref[proof_by_repeating_the_definition].

%%}}}

%%{{{ prop: wrong_property_of_product_dividing_common_multiple 
\proposition.
%%%{{{ meta 
\label wrong_property_of_product_dividing_common_multiple
%%%}}}

Sejam $a,b,m\in\ints$.  Se $a \divides m$ e $b \divides m$, então $ab \divides m$.

\wrongproof.
Como $a \divides m$, pela definição de $(\divides)$, existe $u\in\ints$ tal que
$a = mu$.  Similarmente, como $b \divides m$, existe $v\in\ints$ tal que
$b = mv$.  Multiplicando as duas equações por partes, temos
$$
ab = (mu)(mv) = m(umv),
$$
e como $umv\in\ints$, $ab \divides m$.

%%}}}

%%{{{ x: find the error and prove that it is false 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o erro na demonstração acima e \emph{demonstre} que a proposição é falsa!

\hint
Presta atenção na definição do $(\divides)$.

\hint
Procure um contraexemplo onde $a$ e $b$ tem um fator em comun.

\solution
O erro fica na aplicação da definição de $a \divides b$\thinspace:
ao invés de $\lexists {k\in\ints} {b = ak}$,
a demonstração usou $\lexists {k\in\ints} {a = bk}$.
\eop
Para ver que a proposição realmente é falsa, considere o contraexemplo seguinte:
$$
a = 6,\qquad
b = 15,\qquad
m = 30.
$$
Realmente temos
$6  \divides 30$ e 
$15 \divides 30$,
mas
$6\ntimes 15 = 90 \ndivides 30$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A falsa \ref[wrong_property_of_product_dividing_common_multiple]
tem uma ``versão correta'' que encontramos depois
(\ref[product_of_coprimes_divides_common_multiple]).

%%}}}

%%{{{ x: implications_with_divisibility_of_linear_combinations 
\exercise.
%%%{{{ meta 
\label implications_with_divisibility_of_linear_combinations
%%%}}}

Sejam $a,b,c\in\ints$.
Demonstre ou refute cada uma das afirmações:
$$
\alignat2
\text{(i)}   &\qquad& a \divides \phantom1b + c\phantom1                          &\implies a \divides b \mland a \divides c\\
\text{(ii)}  &\qquad& a \divides b + c \mland a \divides \phantom1b - c\phantom2  &\implies a \divides b                    \\
\text{(iii)} &\qquad& a \divides b + c \mland a \divides \phantom1b + 2c          &\implies a \divides b                    \\
\text{(iv)}  &\qquad& a \divides b + c \mland a \divides 2b + 2c                  &\implies a \divides b                    \\
\text{(v)}   &\qquad& a \divides b + c \mland a \divides 2b + 3c                  &\implies a \divides 3b + 2c\,.
\endalignat
$$

\solution
A (ii) é falsa: um contraexemplo seria o $a = 2$, $b = c = 1$.
Realmente, temos
$$
2 \divides 1 + 1 = 2 \mland 2 \divides 1 - 1 = 0,
\qqtext{mas}
2\ndivides 1.
$$
\eop
A (iii) é verdadeira:
$$
\rightbrace {
\aligned
        a \divides b + c \implies a \divides 2b + 2c\\
                                 a \divides \phantom1b + 2c
\endaligned
}
\implies
a \divides \mubrace{(2b + 2c) - (b + 2c)} {\dsize b}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Conjunction 
\section Conjunção.
%%%{{{ meta 
\label Conjunction
%%%}}}

%%{{{ Understand 
\note Entender.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
%%%}}}

Escrevendo como regras---agora temos duas---de inferência
$$
\PROOFm {
\A {\phi\land\psi}
\I1--------------- {}
        {\phi}
}
\qqqquad
\PROOFm {
\A {\phi\land\psi}
\I1--------------- {}
        {\psi}
}
$$
Na prática, podes pensar que tendo como dado o $\phi\land\psi$ tu ganha os dados $\phi$ e $\psi$.

%%}}}

%%{{{ How do I attack it? 
\note Como eu ataco?.
%%%{{{ meta 
%%%}}}

Para convencer alguém que $\phi \land \psi$, precisamos convencê-lo que $\phi$, e também convencê-lo que $\psi$.
Ou seja, o alvo $\phi \land \psi$ é reduzível em dois alvos: o $\phi$ e o $\psi$.
$$
\PROOFm {
   \A {\phi}     \A {\psi}
\I2----------------------- {}
        {\phi\land\psi}
}
$$

%%}}}

\endsection
%%}}}

%%{{{ Implication 
\section Implicação.
%%%{{{ meta 
\label Implication
\defines
    * implicação
    ;;
%%%}}}

%%{{{ secintro: (Controversial) 
\secintro
Controversial.
%%}}}

%%{{{ implication_understand 
\note Entender.
%%%{{{ meta 
\label implication_understand
\defines
    * trivialmente
    ;;
%%%}}}

Pensando no que uma implicação realmente é, vamos visualizá-la como uma premissa:
$$
\textwq{Prometo que $B$ com a condição $A$.}
$$
E o que é prometido caso que a condição $A$ não for verdadeira?
\emph{Nada!}
É importante entender essa parte, e talvez essa piada conhecida ajuda:
\quotepar
Um filho tá gritando e seu pai vire e fala pra ele:
\emph{``se tu continuar gritando, eu vou bater em ti!''}
O filho, com medo, imediatemente fica calado, e logo após seu pai bate nele.
\endquote
A pergunta para pensar é: \emph{o pai mentiu?}
Em matemática entendemos a implicação numa forma que não culpa esse pai
de mentiroso.\foot
relaxe que tu podes culpar o pai para outras coisas se quiser
\toof
Entendemos a implicação
$$
\textwq{se $\namedhole A$ então $\namedhole B$}
$$
como uma promessa.
Aqui o pai não prometeu nada no caso que seu filho parasse de gritar!
Nesse exemplo bobo então, a afirmação do pai é verdadeira \dterm{trivialmente}
como a gente fala:
ou seja, como não aconteceu a \emph{premissa},
não tem como culpá-lo de mentiroso, e logo a implicação inteira é verdadeira.

%%}}}

%%{{{ modus_ponens : What did I gain? 
\note O que eu ganhei?.
%%%{{{ meta 
\label modus_ponens
\defines
    * modus ponens
    ;;
%%%}}}

Tenho nos meus dados a implicação $\phi\limplies\psi$.
O que eu posso fazer agora, que não podia fazer antes?
Considerando só essa proposição, nada demais!
Sozinha parece inútil: pensando numa metáfora de jogo com cartas,
para jogar essa carta e ganhar algo, preciso ter mais uma carta:
sua \dterm{premissa} $\phi$.
Jogando ambas juntas, ganhamos a $\psi$.
Podemos pensar então numa implicação $\phi\limplies\psi$
como uma fabrica do dado $\psi$, só que para \emph{funcionar},
ela precisa da proposição $\phi$.
Escrevendo como regra de inferência,
$$
\PROOFm {
   \A {\phi \limplies \psi}   \A {\phi}
\I2------------------------------------ {}
                  {\psi}
}
$$
O nome dessa regra é \dterm{modus ponens}.

%%}}}

%%{{{ How do I attack it? 
\note Como eu ataco?.
%%%{{{ meta 
%%%}}}

Para convencer teu inimigo sobre a veracidade duma implicação $\phi \implies \psi$
tu tens o direito de mandá-lo \emph{aceitar} a premissa $\phi$.
No final das contas, ele tá duvidando a proposição $\psi$,
\emph{dado a proposição $\phi$}.
Ou seja, para atacar uma implicação $\phi\limplies\psi$ escrevemos
\quote
Suponha $\phi$.
\endquote
Assim ganhamos nos nossos dados o $\phi$ e nosso alvo é $\psi$.

%%}}}

\endsection
%%}}}

%%{{{ Existential 
\section Existencial.
%%%{{{ meta 
\label Existential
%%%}}}

\endsection
%%}}}

%%{{{ Disjunction 
\section Disjunção.
%%%{{{ meta 
%%%}}}

%%{{{ Understand 
\note Entender.
%%%{{{ meta 
%%%}}}

A disjunção $\phi\lor\psi$ representa uma informação ambígua, estritamente mais
fraca que qualquer uma das $\phi,\psi$: $\phi\lor\psi$ é a proposição que pelo
menos uma das $\phi,\psi$ é válida.

%%}}}

%%{{{ disjunctive_syllogism 
\note Silogismo disjuntivo.
%%%{{{ meta 
\label disjunctive_syllogism
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Negation 
\section Negação.
%%%{{{ meta 
%%%}}}

\TODO Botando negações pra dentro.

\TODO Negando fórmulas atômicas.

\endsection
%%}}}

%%{{{ Universal 
\section Universal.
%%%{{{ meta 
%%%}}}

%%{{{ Vacuously_true 
\note Por vacuidade.
%%%{{{ meta 
\label Vacuously_true
%%%}}}

\TODO Escrever.

%%}}}

\TODO arbitrário \vs aleatório.

\endsection
%%}}}

%%{{{ Examples_and_counterexamples 
\section Exemplos e contraexemplos.
%%%{{{ meta 
\label Examples_and_counterexamples
%%%}}}

\TODO elaborar e referir ao~\ref[nonexample_vs_counterexample].

%%{{{ eg: nonexample_vs_counterexample_example 
\example.
%%%{{{ meta 
\label nonexample_vs_counterexample_example
%%%}}}

As afirmações seguintes são corretas:
% TODO: fix reflabs
\tlist:
\li (i):   $21$ é um contraexemplo para a: todos os múltiplos de $3$ são pares;
\li (ii):  $18$ é um contraexemplo para a: todos os múltiplos de $3$ são ímpares;
\li (iii): $18$ é um contraexemplo para a: nenhum múltiplo de $3$ é par;
\li (iv):  $18$ não é um contraexemplo para a: todos os ímpares são multiplos de $3$;
\li (v):   $18$ não é um contraexemplo para a: todos os ímpares são múltiplos de $7$;
\li (vi):  $21$ não é um contraexemplo para a: todos os ímpares são múltiplos de $3$.
\endtlist
Vamos ver curtamente a razão de cada uma das últimas três:
nas (iv) e (v) o $18$ nem é ímpar então não tem chances de ser
contraexemplo de qualquer afirmação que todos os ímpares fazem algo;
na (vi) o $21$ é ímpar mas ele \emph{tem sim} a propriedade descrita, e logo
também não é um \emph{contra}exemplo.\foot
Para misturar nossa conversa com a discussão sobre exemplos e nãœxemplos
(\reftag[examples_and_nonexamples]):
acabei de listar aqui, em ordem:
três exemplos de contraexemplos e
três nãœxemplos de contraexemplos.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Logical equivalence 
\section Equivalência lógica.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
\pdefs
    \pdef explodes {\leadsto}
    ;;
%%%}}}

%%{{{ prob: explodes 
\problem.
%%%{{{ meta 
\label explodes
\pdefs
    \pdef explodes {\doublemidrel}
    ;;
\defines
    * explode
    ;;
%%%}}}

Sejam $a,b\in\ints_{\geq 0}$.
Digamos que \dterm{o $a$ explode o $b$}, sse $b = a^n$ para algum $n\in \alert?$.
Nesse caso, escrevemos $a\explodes b$.
Dependendo do qual conjunto botamos no {\alert?} chegamos numa definição diferente:
$$
a\explodes b \defiff
\knuthcases {
\lexists {n\in\ints}          {b = a^n}   &(Definição D1) \cr
\lexists {n\in\ints_{\geq 0}} {b = a^n}   &(Definição D2) \cr
\lexists {n\in\ints_{> 0}}    {b = a^n}.  &(Definição D3)
}
$$
\eop\noi
Proposição P1:
para quaisquer $a,b,c\in\ints_{\geq 0}$,
se $a \explodes b$ e $b \explodes c$ então $a \explodes c$.
\eop\noi
Proposição P2:
para quaisquer $a,b\in\ints_{\geq 0}$,
se $a \explodes b$ então $a \divides b$.
\eop\noi
Proposição P3:
para quaisquer $a,b,c\in\ints_{\geq 0}$,
se $a \divides b$ e $b \explodes c$ então $a \divides c$.
\eop
Como cada proposição depende da definição de <<explode>> temos
em total 9 proposições.
Para cada uma delas, demonstre ou refute.

%%}}}

\endproblems
%%}}}

%%{{{ EFQ 
\section Ex falso quodlibet.
%%%{{{ meta 
\label EFQ
%%%}}}

%%{{{ discussion 
\note.
%%%{{{ meta 
%%%}}}

Em qualquer momento durante uma demonstração, o estado é a tabela de Dados/Alvos, e nosso objetivo é mostrar que se os dados são todos verdadeiros, então os alvos também devem ser.  Mas o que acontece se dentro dos nossos dados temos uma \dterm{inconsistência}, ou seja, nosso estado descreve uma situação impossível.  Nesse caso, ganhamos trivialmente o jogo, pois conseguimos mostrar a impossibilidade dos dados acontecerem, então não temos nada mais pra fazer: matamos assim qualquer alvo pois garantimos que a premissa (que os dados são verdadeiros) é falsa.
Na pratica isso significa que se em qualquer momento numa demonstração conseguimos como dado uma contradição ($\bottom$), já podemos parar vitoriosamente:
\emph{explodimos o mundo inteiro, e logo nosso alvo morreu também}.
Como regra, temos
$$
\PROOFm {
\A {\bottom}
\I1--------- {}
    {\phi}
}
$$
para qualquer $\phi$.

%%}}}

\endsection
%%}}}

%%{{{ LEM_spell 
\section Feitiço: LEM.
%%%{{{ meta 
\label LEM_spell
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Suponha que está tentando demonstrar uma afirmação.
Para matar esse monstro, em qualquer momento da tua prova,
você pode separar em casos, e mostrar como matá-lo
em cada um deles.
Quando decidir atacar nessa maneira precisa tomar certos cuidados.

%%}}}

%%{{{ our new goals 
\note Nossos novos alvos.
%%%{{{ meta 
\label case_split_clones_goal
%%%}}}

O alvo tá sendo clonado igualzíssimo para cada um dos casos.

%%}}}

%%{{{ remark: seems weird choice to case split 
\remark.
%%%{{{ meta 
%%%}}}

Mas, peraí.
A gente quer matar um monstro $G$.
Depois desse passo de separar em, sei lá, 4 casos,
agora nosso objectivo é matar 4 cópias desse monstro,
uma em cada caso.
Se fosse cada um desses novos monstros pelo menos
um pouquinho mais fraco, o motivo de separar em casos
faria sentido.  Mas, como eu acabei de dizer,
em cada caso temos que matar um clone de $G$.
Não uma versão diferente de $G$.  O mesmo $G$!

%%}}}

%%{{{ Q: why case split? 
\question.
%%%{{{ meta 
%%%}}}

Por que separar em casos então e multiplicar nossos alvos?

%%}}}

\spoiler

%%{{{ A: the monsters don't get weaker, but we get stronger 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não é que teus novos alvos são mais fracos---pois eles não são---mas
é você mesmo que fica mais forte em cada um deles.
Em cada caso, ganhas mais uma arma:
o dado que o próprio caso te oferece para matar esse mesmo alvo.

%%}}}

%%{{{ Don't forget a case 
\note Não deixar nenhum caso por fora.
%%%{{{ meta 
%%%}}}

Uma maneira de ter certeza que não esqueceu nada, é escolher uma
propriedade $A$ e separar nos dois casos complementares:
$A$ ou não $A$.
Para um exemplo de como errar, suponha que queremos demonstrar
que para todo inteiro $n$, o $n(n-1)$ é um múltiplo de $3$.
Consideramos dois casos:
\tlist:
\li: Caso $n = 3k$   para algum $k\in\ints$.
\li: Caso $n = 3k+1$ para algum $k\in\ints$.
\endtlist
Em cada um deles, é fácil demonstrar que realmente $n(n-1)$ é
um múltiplo de $3$.  Mas claramente temos um erro aqui,
pois, como um contraexemplo tome o inteiro $5$ e calcule:
$5(5-1) = 20$, e com certeza $20$ não é um múltiplo de $3$.
O problema é que em nossa separação em casos a gente não
considerou todas as possibilidades!
Esquecemos um terceiro caso:
\quote
Caso contrário.
\endquote
Como aprenderemos no~\ref[The_integers],
a única possibilidade que deixamos,
esse \dq{caso contrário} é equivalente ao:
\quote
Caso $n = 3k+2$  para algum $k\in\ints$.
\endquote
Uma separação em casos correta então seria considerar todos os:
\tlist:
\li: Caso $n = 3k$   para algum $k\in\ints$.
\li: Caso $n = 3k+1$ para algum $k\in\ints$.
\li: Caso $n = 3k+2$ para algum $k\in\ints$.
\endtlist
E com essa separação, felizmente, não podemos demonstrar
essa afirmação errada, pois no terceiro caso, não temos como
matar nosso alvo!

%%}}}

\endsection
%%}}}

%%{{{ RAA_spell 
\section Feitiço: RAA.
%%%{{{ meta 
\label RAA_spell
%%%}}}

\endsection
%%}}}

%%{{{ Contrapositive_spell 
\section Feitiço: Contrapositivo.
%%%{{{ meta 
\label Contrapositive_spell
%%%}}}

\endsection
%%}}}

%%{{{ NNE_spell 
\section Feitiço: NNE.
%%%{{{ meta 
\label NNE_spell
%%%}}}

\endsection
%%}}}

%%{{{ Disjunction_as_implication_spell 
\section Feitiço: Disjunção como implicação.
%%%{{{ meta 
\label Disjunction_as_implication_spell
%%%}}}

\endsection
%%}}}

%%{{{ Uniqueness proofs 
\section Provas de unicidade.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ More_jargon_and_slang 
\section Mais jargão e gírias.
%%%{{{ meta 
\label More_jargon_and_slang
%%%}}}

%%{{{ obvious_trivial_immediate 
\note Óbvio, trivial, imediato: é mesmo?.
%%%{{{ meta 
\label obvious_trivial_immediate
\defines
    * demonstração!por intimidação
    * trivial
    * óbvio
    ;;
%%%}}}

Muitas vezes matemáticos costumamos deixar certos passos sem
justificativas, ou até enfatizamos escrevendo palavras como
\wq{trivial}, \wq{imediato}, \wq{óbvio}, \wq{fácil}.
Muitas vezes essas palavras são usadas como sinônimos,
mas seus significados não são exatamente iguais.
\dterm{Trivial} é algo que não necessita pensar em nada,
e é só fazer o trabalho de corno óbvio para terminar.\foot
A palavra \dterm{trivial} também é usada para
demonstrações de implicações cuja premissa é falsa,
algo que vamos discutir na~\ref[Implication].
\toof
Note bem que isso significa que o escritor já sabe bem claramente
\emph{qual} é esse trabalho e com certeza
\emph{é capaz de fazê-lo até seu fim} caso que ele for desafiado.
\dterm{Óbvio} e \dterm{fácil} são palávras notórias entre
matemáticos, como também a frase \wq{exercício para o leitor}.
Normalmente significa que os passos e/ou suas justificativas para
uma parte da demonstração devem ser óbvios (quais exatamente são)
para o leitor.
O uso honesto de ambas é muito conveniente, mas infelizmente elas
podem ser usadas também para criar uma
\dterm{demonstração por intimidação}, a idéia sendo que o leitor
não vai assumir que não consegue ver o passo ``fácil'' em questão,
e logo vai aceitar a demonstração.  \emph{Nunca faça isso!}
\dterm{Imediato} usamos dentro dum caso ou parte duma demonstração
cujo alvo é \emph{intensionalmente equivalente} a um dos dados,
ou quando não falta nada para verificar.\foot
A palavra \dterm{imediato} também é usada para
demonstrações por vacuidade.
\toof
Não fique obcecado com essas ``definições'' ou ``instruções''
sobre o uso dessas palavras; como falei: muitas vezes são
usadas sinonimamente.  Com experiência elaborarás uma noção
melhor de quando e como usá-las.

%%}}}

\endsection
%%}}}

%%{{{ Common errors and fallacies 
\section Erros comuns e falácias.
%%%{{{ meta 
\label Fallacies
\indexes
    * falácia
    ;;
%%%}}}

%%{{{ proof_by_repeating_the_definition 
\note Prova por repetição da definição.
%%%{{{ meta 
\label proof_by_repeating_the_definition
%%%}}}

Imagine que uma pessoa tá querendo demonstrar que $3$ divide $12$
e considere a argumentação seguinte:
\quote
<<O $3$ divide o $12$ pois existe inteiro $k$ tal que $3k = 12$.>>
\endquote
Para apreciar quão inútil seria isso,
imagine um advogado defendendo um cara suspeito 
\quote
<<Meu cliente é inocente, porque ele não matou a vítima.>>
\endquote
Ninguém deveria considerar essa frase como um argumento convincente
e válido da inocência do acusado.
Nesse contexto, \wq{$x$ é inocente} \emph{significa}
\wq{$x$ não matou a vítima}.
É \emph{exatamente a mesma afirmação}, expressada com outras palavras.
Ou seja, traduzindo o argumento do advogado, percebemos que o que ele falou mesmo foi:
\quote
<<Meu cliente não matou a vítima, porque ele não matou a vítima.>>
\endquote
ou
\quote
<<Meu cliente é inocente, porque ele é inocente.>>
\endquote
dependendo de qual direção da tradução escolhemos aplicar.
Esse advogado não deveria ter muito sucesso no seu futuro assim!\foot
Infelizmente muitas pessoas caem por esse tipo de argumento
na vida real, onde políticos, pastores, e advogados como o não-tão-fictício
do meu exemplo, \dq{argumentam} em maneiras erradas para convencer seus
ouvidores (que não estudaram matemática).
\toof

%%}}}

%%{{{ Forget one of the branches 
\note Esquecer um dos ramos.
%%%{{{ meta 
%%%}}}

Lembre-se o modus ponens:
$$
\PROOFm {
\A  {\phi \implies \psi}
\A                           {\phi}
\I2--------------------------------- {M.P.}
                 {\psi}
}
$$
Que nos permite inferir a proposição $\psi$,
pelas \emph{duas} proposições
\elist:
\li: $\phi \implies \psi$;
\li: $\phi$.
\endelist
É comum esquecer sobre uma das duas e mesmo assim tentar
inferir (a partir da outra) a mesma conclusão $\psi$.
Estudando matemática é mais freqüente esquecer a $\phi$;
na vida real qualquer uma das duas pode acabar sendo ``esquecida''.

%%}}}

%%{{{ Denying the antecedent 
\note Refutação do antecedente.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Let and prove vs. Prove that all 
\note Seja e demonstre \vs demonstre que todos.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ if_vs_since 
\note Se \vs como.
%%%{{{ meta 
\label if_vs_since
%%%}}}

Considere as frases seguintes:
$$
\gather
\text{<<Se $\namedhole A$, $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, $\namedhole B$.>>}
\endgather
$$
Observe que, em português, cada uma delas tem uma
palavra implícita logo após da virgula:
$$
\gather
\text{<<Se $\namedhole A$, ({\lthole}) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, ({\lthole}) $\namedhole B$.>>}
\endgather
$$
Quais são?
Na primeira frase a palavra implícita é a ``então'', e na segunda a ``logo'':
$$
\gather
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}\\
\text{<<Como $\namedhole A$, (logo) $\namedhole B$.>>}
\endgather
$$
Numa lida superficial as duas frases podem aparecer parecidas.
Mas são bem, bem diferentes!

%%}}}

%%{{{ x: explain_the_difference_between_if_and_since 
\exercise.
%%%{{{ meta 
\label explain_the_difference_between_if_and_since
%%%}}}

Qual é a diferença entre as duas frases?

\solution
A frase
$$
\text{<<Se $\namedhole A$, (então) $\namedhole B$.>>}
$$
é uma afirmação: que a proposição $A$ implica a proposição $B$.
Ou seja, não está afirmando que a proposição $A$ é verdadeira (nem que é falsa),
e também nada sobre a veracidade da $B$.
Por outro lado, a frase
$$
\text{<<Como $\namedhole A$, (logo) $\namedhole B$.>>}
$$
é uma \emph{argumentação}.
Seu escritor já usa como fato conhecido que $A$ é verdadeira,
e além disso, ele tá afirmando que $B$ também é verdadeira por causa disso.
Em outras palavras, o escritor está \emph{inferindo} a $B$ a partir das
afirmações $A$ e $A \implies B$ que ele deixa como implícito que o
leitor aceita ambas.

%%}}}

%%{{{ warning: only_declare_variables 
\warning Declare apenas variáveis.
%%%{{{ meta 
\label only_declare_variables
%%%}}}

Não podemos ``sejar'' algo que envolve um termo.
Não faz sentido escrever
\quote
Seja $x+y$ natural.
\endquote
por exemplo.
Novamente: depois dum ``seja'' segue uma variável,
inclusive fresca para evitar sombreamento (\reftag[variable_capturing_and_shadowing]).
Voltando no exemplo da soma, não faria sentido escrever:
\quote
Sejam $x,y$ naturais.
Seja $x+y$ a soma dos $x$ e $y$.
\endquote
Não!
Já definimos a operação binária $(+)$ entre naturais, então
não podemos ``sejar'' a expressão \symq{$x+y$}.
Quando ``sejamos'' algo como um membro arbitrário dum conjunto
usamos apenas uma variável!  Nem constantes, nem termos que
envolvem operações.  Imagine alguém escrevendo:
<<seja $3\in\ints$>>, ou <<seja $x^2 \in \reals$>>.
Não!  A operação $\dhole^2$ já é definida, e logo para
qualquer real $r$ o real $r^2$ já é definido!
Para dar um exemplo para quem programou em linguagem similar à C.
Tu escreverias essas declarações?
\sourcecode onlydeclarevars.c;
Espero que não!

%%}}}

\TODO complete and provide math and life examples.

%%{{{ mother_of_all
\note Mãe de todos.
%%%{{{ meta 
\label mother_of_all
%%%}}}

\TODO mother of all vs everybody has a mom.

%%}}}

%%{{{ let_vs_suppose 
\note Seja \vs suponha.
%%%{{{ meta 
\label let_vs_suppose
%%%}}}

Vamos analisar pouco as duas frases que as vezes geram
uns mal-entendidos: \wq{Seja \dots} e \wq{Suponha \dots}.
Vamos começar com umas perguntas:

\TODO Terminar.

%%}}}

%%{{{ let_vs_exists 
\note Seja \vs existe.
%%%{{{ meta 
\label let_vs_exists
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Wrong; now what? 
\section Deu errado; e agora?.
%%%{{{ meta 
%%%}}}

\TODO Erro na demonstração não é suficiente para dizer que o teorema é errado.

\TODO Conseqüência de teorema errado não é suficiente para concluir que
a conseqüência é errada também.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: change_order_of_like_quantifiers 
\problem.
%%%{{{ meta 
\label change_order_of_like_quantifiers
%%%}}}

Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre as equivalências:
\mathcols 2
\pforall x \lforall y {\phi(x,y)} &\iff \pforall y \lforall x {\phi(x,y)}; &
\pexists x \lexists y {\phi(x,y)} &\iff \pexists y \lexists x {\phi(x,y)}.
\endmathcols

%%}}}

%%{{{ prob: change_order_of_unlike_quantifiers 
\problem.
%%%{{{ meta 
\label change_order_of_unlike_quantifiers 
%%%}}}

Sem saber qual afirmação é denotada por $\phi(x,y)$, demonstre \emph{uma} das duas direções da equivalência
$$
\pforall x \lexists y {\phi(x,y)}
\askiff
\pexists y \lforall x {\phi(x,y)}.
$$
Podes demonstrar ou refutar a outra?

%%}}}

%%{{{ prob: sym_and_trans_derivable 
\problem.
%%%{{{ meta 
\label sym_and_trans_derivable
%%%}}}

Precisamos mesmo aceitar como axiomas todas as leis no \ref[laws_of_eq]?

\hint
Não.
Da pra aceitar apenas duas elas como axiomas e derivar as outras duas.
Quais?
Como?

\hint
Podemos derivar a simetria e a transitividade
a partir da reflexividade e da substituição (que aceitamos sim como
axiomas).
Como?

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[nivenirrational].
\cite[velleman: Cap.~3].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The_integers 
\chapter Os inteiros.
%%%{{{ meta 
\label The_integers
\pdefs
    \pdef Pos {\mathord{\mathrm{Pos}}}
    \pdef Neg {\mathord{\mathrm{Neg}}}
    ;;
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo estudamos os inteiros e sua teoria:
inicialmente demonstraremos as propriedades mais básicas,
que talvez parecem quase infantis.  Logo depois, neste
capítulo ainda, encontramos e demonstramos os primeiros
teoremas realmente lindos e interessantes.
Além disso, andamos aqui nossos primeiros passos na
\dterm{teoria dos números inteiros}.
Terminamos com umas aplicações dessa teoria na área de
criptografia; algo que deixaria muitos matemáticos do passado
surpresos (e talvez frustrados): como uma coisa tão \emph{pura}
acaba sendo aplicada em algo tão\dots aplicado!\foot
Oi, {\Hardy}G.~H.~Hardy!
\toof
%%}}}

%%{{{ First steps 
\section Primeiros passos.
%%%{{{ meta 
%%%}}}

%%{{{ How do the integers behave? 
\note.
%%%{{{ meta 
%%%}}}

Os (números) inteiros tu provavelmente já conheceu:
$$
\dotsc, \quad -3, \quad -2, \quad -1, \quad 0, \quad 1, \quad 2, \quad 3,\quad \dotsc
$$
Talvez tu não questiona sua existência---qualquer coisa que isso pode significar---e
talvez não questiona nem suas propriedades que aprendeu enquanto criança.
\eop
Aqui não vamos \emph{definir} então \emph{o que é} um inteiro;
o que significa ser um (número) inteiro.\foot
Caso que isso pareceu óbvio pra ti, segure tua reação
até o~\ref[Set_theory] onde vamos fazer exatamente isso:
construir (definir) mesmo os inteiros!
\toof
\eop
Em vez disso, vamos responder em outra pergunta: \emph{como comportam os inteiros?}
Os inteiros não são assim uns bichinhos soltos sem alma;
eles chegam junto com uma \dterm{estrutura} feita por constantes
(uns \dq{destacados} inteiros, vamos dizer), umas operações, e ainda mais.
\eop
Sobre suas operações binárias (adição e multiplicação) provavelmente já foi
ensinado que ambas são associativas, possuem identidades---talvez chamaram
isso de {elemento neutro}?---, ambas são comutativas, o $-x$ é o oposto
de $x$---o que isso significa mesmo?---, a multiplicação distribua-se sobre
a adição, etc.~etc.!\foot
acabei assumindo que tu conheces certas palavras também (associativa,
comutativa, etc.)~mas isso não é essencial:
se tu encontrou alguma palavra desconhecida (ou esquecida), se preocupe não;
continue e vamos introduzir tudo diretinho daqui a pouco.
\toof
Além dessas \emph{operações},
nos inteiros temos uma \emph{relação de ordem} cujas propriedades também
devem ser conhecidas.
Sabes, por exemplo, que para qualquer inteiro $x$ temos $x^2 \geq 0$,
e que para quisquer inteiros $x,y$ tais que $x \leq y$, temos $-y \leq -x$,
e muitas mais coisas.
\eop
Caso que tudo isso pareceu estranho pra ti,
especialmente a questão sobre o que aceitar e o que não,
está num caminho bom!
Neste capítulo separamos exatamente o que vamos aceitar (axiomas e noções primitivas),
e o que vamos demonstrar (teoremas) e definir (noções definidas).
Eu não vou supor conhecimento sobre outras operações, e sugiro esquecê-lo
desde já, pois pode acabar te confundindo.
Tradicionalmente denotamos o conjunto dos inteiros por $\ints$.\foot
\emph{Zahl} em alemão significa número.
\toof
Neste capítulo trabalharemos inteiramente no mundo dos inteiros, e logo
entendemos que os quantificadores ($\forall, \exists$) \emph{quantificam sobre os inteiros}
exceto se explicitamente especificar algo diferente.

%%}}}

%%{{{ warning: a single word makes a huge difference 
\warning Uma palavrinha.
%%%{{{ meta 
%%%}}}

Considere as duas definições:
\elist i:
\li: Denotamos por $A$ o conjunto cujos membros são todos inteiros.
\li: Denotamos por $B$ o conjunto cujos membros são todos os inteiros.
\endelist
Vamos ver como uma palavrinha (aqui o \emph{os}) pode fazer tanta diferença.
A primeira não defina nada.  O problema é que há mais que um conjunto
que goza dessa popriedade: o conjunto $\set{2,5}$ é mesmo um conjunto cujos membros
são todos inteiros: ele só tem dois membros, e ambos são inteiros.
Do $\set{3,4,8}$, também todos os membros são inteiros.
Por isso, o uso do artigo definido \emph{o} nesta frase é \emph{plenamente errado}.
Não podemos usá-lo sem garantir unicidade, e aqui é algo que não temos
como garantir.
Por outro lado, a segunda realmente defina um conjunto:
o conjunto de todos os inteiros, que denotamos por $\ints$.

%%}}}

%%{{{ spec: int_spec_1 
\specification Os inteiros (1/5).
%%%{{{ meta 
\label int_spec_1
\defines
    * inteiros
    ;;
%%%}}}

Usamos $\Int$ para denotar um tipo cujos membros chamamos de (números) inteiros e onde temos:
\mathcol
0         &\is \Int \\
1         &\is \Int \\
(+)       &\is \Int \times \Int \to \Int \\
(-)       &\is \Int \to \Int \\
(\ntimes) &\is \Int \times \Int \to \Int. \\
\endmathcol
Estipulamos as proposições seguintes como axiomas:
\mathcol
\cforall {a,b,c}  {a + (b + c) = (a + b) + c}   \stag[ZA-Ass] \\
\cforall {a}      {a + 0 = a}                   \stag[ZA-IdR] \\
\cforall {a}      {a + (-a) = 0}                \stag[ZA-InvR] \\
\cforall {a,b}    {a + b = b + a}               \stag[ZA-Com] \\
\\
\cforall {a,b,c}  {a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}
                                                \stag[ZM-Ass] \\
\cforall {a}      {a\ntimes 1 = a}              \stag[ZM-IdR] \\
\cforall {a,b}    {a\ntimes b = b \ntimes a}    \stag[ZM-Com] \\
\\
\cforall {d,a,b}  {(a+b)\ntimes d = (a \ntimes d) + (b \ntimes d)}.
                                                \stag[Z-DistR] \\
\endmathcol

%%}}}

%%{{{ int_syntactic_associativities 
\note Associatividades sintácticas.
%%%{{{ meta 
\label int_syntactic_associativities
\defines
    * associatividade!sintáctica
    ;;
%%%}}}

Temos operações binárias nas nossas mãos que escrevemos com notações \dterm{infixas}:
escrevemos $x + y$ para denotar a aplicação da $(+)$ nos argumentos $x,y$,
em vez de optar para notação \dterm{prefixa} escrevendo $(+)(x,y)$ ou $+(x,y)$.
Sem atribuir uma \dterm{associatividade sintáctica} para esses símbolos,
expressões como as
\mathcols 2
& a + b + c + d + e &
& a \ntimes (1 + a) \ntimes b \ntimes c
\endmathcols
não significam nada!  Dá pra entender que a primeira é pra ser uma soma
(dos 5 termos $a,b,c,d,e$) e a segunda um produto (dos 4 termos $a, 1+a, b, c$),
mas tanto a $(+)$ quanto a $(\ntimes)$ são operações binárias e logo não podem
\emph{funcionar} nesse jeito.
Escolhemos atribuir associatividade sintáctica à direita para ambas:
dizemos que elas \dterm{associam à direita}.
Assim, as expressões acima agora são apenas abreviações das
\mathcols 2
& a + (b + (c + (d + e))) &
& a \ntimes ((1 + a) \ntimes (b \ntimes c)).
\endmathcols

%%}}}

%%{{{ int_syntactic_precedence 
\note Precedência sintáctica.
%%%{{{ meta 
\label int_syntactic_precedence
\defines
    * precedência!sintáctica
    ;;
%%%}}}

Queremos fazer mais um acordo sintáctico que vai nos permitir escrever
expressões onde as duas operações parecem \dq{em níveis iguais} como se
estivessem brigando sobre quem vai receber o que como argumento.
Considere as expressões:
\mathcols 2
& a \ntimes b + c &
& a \ntimes b + c \ntimes d \ntimes e + a.
\endmathcols
Agora nem sabemos se elas denotam somatórios ou produtórios:
A primeira é a soma dos 2 termos $a \ntimes b, c$ ou o produto dos termos $a, b+c$?
E a segunda é a soma dos 3 termos $a \ntimes b, c \ntimes d \ntimes e, a$ ou o produto dos 4 termos
$a, b+c, d, e+a$?
Resolvemos atribuir à $(\ntimes)$ uma precedência mais alta, dizendo que ela
\dterm{pega mais forte} do que a $(+)$.\foot
A idéia aqui é imaginar as operações numa expressão como a $a + b \ntimes c$ como ímãs
atraindo os argumentos, e pela nossa atribuição o ímã $(\ntimes)$ é mais forte e logo
ele \dq{ganha} tal briga e a expressão denota o $a + (b \ntimes c)$.
Mais num outro sentido, quem ganhou a batalha final foi a $(+)$:
a expressão inteira acabou denotando um somatório e não um produtório.
\toof
Assim, as expressões acima denotam somatórios e não produtórios:
\mathcols 2
& (a \ntimes b) + c &
& (a \ntimes b) + (c \ntimes d \ntimes e) + a.
\endmathcols

%%}}}

%%{{{ int_juxtaposition_notation 
\note Mais uma convenção sintáctica.
%%%{{{ meta 
\label int_juxtaposition_notation
\defines
    * justaposição
    ;;
%%%}}}

Quando não tiver ambiguïdade, denotamos a aplicação da operação $(\ntimes)$
silenciosamente, por \dterm{justaposição:} escrevemos $ab$ para denotar o
produto $a \ntimes b$.  Assim,
$$
ab(c+da)bce
\inteq
a \ntimes b \ntimes (c + d \ntimes a)\ntimes b \ntimes c \ntimes e.
$$

%%}}}

%%{{{ x: int_left_versions_as_theorems 
\exercise.
%%%{{{ meta 
\label int_left_versions_as_theorems
%%%}}}

Para cada axioma que parece favorecendo o lado direito,
sua versão esquerda é um teorema:
o $0$ é uma $(+)$-identidade-L;
o $1$ é uma $(\ntimes)$-identidade-L;
para todo $a$ o $-a$ é um $(+)$-inverso-L de $a$; e
a $(\ntimes)$ distribui-se sobre a $(+)$ pela esquerda também:
\mathcol
\cforall {a}      {0 + a = a}           \stag[ZA-IdL]   \\
\cforall {a}      {(-a) + a = 0}        \stag[ZA-InvL] \\
\cforall {a}      {1\ntimes a = a}      \stag[ZM-IdL]   \\
\cforall {d,a,b}  {d\ntimes (a+b) = (d\ntimes a) + (d \ntimes b)}.
                                        \stag[Z-DistL] \\
\endmathcol

\hint
Ambas as $(+),(\ntimes)$ são comutativas.

%%}}}

%%{{{ int_subtraction_as_syntactic_sugar 
\note Açúcar sintáctico: subtração.
%%%{{{ meta 
\label int_subtraction_as_syntactic_sugar
\indexes
    * notação!sobrecarregar   see: sobrecarregamento
    ;;
\defines
    * subtração!nos inteiros
    * sobrecarregamento!notação
    ;;
%%%}}}

Será que esquecemos de adicionar nas operações primitivas a subtração?
Não: introduzimos açúcar sintáctico para denotar a aplicação da operação
\emph{binária}
\mathcol
(-) &\eqtype \Int \times \Int \to \Int \\
\endmathcol
de subtração definindo
\mathcol
a - b &\defeq a + (-b).
\endmathcol
Observe que o símbolo ${-}$ tá sendo \dterm{sobrecarregado} mas
o contexto sempre deixará claro qual das
\mathcols 2
(-) &\eqtype \Int \to \Int  &
(-) &\eqtype \Int \times \Int \to \Int
\endmathcols
está sendo usada.

%%}}}

%%{{{ int_numerals_and_powers 
\note Açúcar sintáctico: numerais e potências.
%%%{{{ meta 
\label int_numerals_and_powers
%%%}}}

Introduzimos imediatamente as definições seguintes:
\mathcols 4
2 &\eqtype \Int  & 3 &\eqtype \Int  & 4 &\eqtype \Int &~&\cdots \\
2 &\defeq  1 + 1 & 3 &\defeq  2 + 1 & 4 &\defeq  3 + 1&~&\cdots \\
\endmathcols
Considerando que temos acesso aos números naturais definimos para
qualquer inteiros $x$ os símbolos
\mathcols 4
x^0 &\eqtype \Int  & x^1 &\eqtype \Int         & x^2 &\eqtype \Int         &~&\cdots \\
x^0 &\defeq  1     & x^1 &\defeq  x\ntimes x^0 & x^2 &\defeq  x\ntimes x^1 &~&\cdots \\
\endmathcols

%%}}}

%%{{{ warning: three dots 
\warning Três pontinhos.
%%%{{{ meta 
%%%}}}

Nenhuma dessas definições pode ser aceita formalmente na sua inteiridade:
parece que eu acabei de escrever uma linha infinita, introduzindo assim uma
infinidade de novos símbolos.
Mas calma: aceite por enquanto que cada nome desses que tu já conhece
corresponde no que tu realmente entende, e logo vamos justificar
\emph{em maneira finita} o sistema posicional de numerais
que conhecemos desde criança, justificando sim toda essa infinidade
de nomes para os inteiros, e todas as potências (naturais) de qualquer inteiro $x$
também.

%%}}}

%%{{{ x: int_passing 
\exercise.
%%%{{{ meta 
\label int_passing
%%%}}}

Demonstre as leis de ``passar termo por outro lado'':
\mathcol
\cforall {a,b,c}  {a + b = c \iff a = c - b} \\
\cforall {a,b,c}  {a + b = c \iff b = c - a} \\
\cforall {a,b}    {a = b     \iff a - b = 0}. \\
\endmathcol

%%}}}

%%{{{ x: int_do_the_same_on_both_sides 
\exercise.
%%%{{{ meta 
\label int_do_the_same_on_both_sides
%%%}}}

Seja $\heartop$ uma operação binária.
Demonstre que para quaisquer $a,b,x$,
\mathcol
a = b &\implies a \heartop x = b \heartop x; \\
a = b &\implies x \heartop a = x \heartop b. \\
\endmathcol
Observe que isso tem como casos especiais que podemos somar (ou multiplicar)
o mesmo inteiro nos dois lados duma equação (pelo mesmo lado),
já que a operação binária $\heartop$ aqui é uma operação arbitrária.

%%}}}

%%{{{ x: int_undo_the_same_on_both_sides 
\exercise.
%%%{{{ meta 
\label int_undo_the_same_on_both_sides
%%%}}}

Podemos \dq{desfazer} a mesma operação nos dois lados?:
$$
a \heartop x = b \heartop x \askimplies a = b.
$$

%%}}}

%%{{{ thm: int_cancellation_law_for_addition 
\theorem.
%%%{{{ meta 
\label int_cancellation_law_for_addition
%%%}}}

\mathcol
\cforall {a,b,c}  {a + c = b + c \implies a = b}; \stag[ZA-CanR] \\
\cforall {a,b,c}  {c + a = c + b \implies a = b}. \stag[ZA-CanL] \\
\endmathcol

\proof.
Essa é tua: \ref[int_cancellation_law_for_addition_proof].

%%}}}

%%{{{ x: int_cancellation_law_for_addition_proof 
\exercise.
%%%{{{ meta 
\label int_cancellation_law_for_addition_proof
%%%}}}

Demonstre o \ref[int_cancellation_law_for_addition].
Cuidado: terminando uma, não faz sentido a outra ocupar um espaço parecido no teu texto!

\hint
Adicione o $(-c)$ nos dois lados pela direita para demonstrar a primeira.

\solution
Vou começar com a primeira.
Sejam $a,b,c$ inteiros.
Suponha $a + c = b + c$.
Logo $(a + c) + (-c) = (b + c) + (-c)$ (pelo \ref[int_do_the_same_on_both_sides]).
Logo $a + (c + (-c)) = b + (c + (-c))$ pela $(+)$-associatividade nos dois lados.
Logo $a + 0 = b + 0$ pela \mref[ZA-InvR] nos dois lados.
Logo $a = b$ pela \mref[ZA-IdR] nos dois lados.
A segunda é similar, algo que podemos afirmar graças ao \ref[int_left_versions_as_theorems]!
Alternativamente, podemos demonstrar a segunda aplicando a comutatividade
da adição nos dois lados da hipótese, virando assim um corolário simples da primeira.

%%}}}

%%{{{ x: refute the cancellation law for multiplication 
\exercise.
%%%{{{ meta 
%%%}}}

Enuncie e refute a proposição correspondente para a multiplicação.

%%}}}

%%{{{ thm: int_uniqueness_of_additive_identity 
\theorem Unicidade da $(+)$-identidade.
%%%{{{ meta 
\headerize
\label int_uniqueness_of_additive_identity
%%%}}}

Existe único $u$ tal que para todo $x$, $u + x = x = x + u$.

\proof.
Preciso demonstrar duas coisas.
\crproofpart {Existência: existe pelo menos uma identidade aditiva.}
Essa parte é imediata pois já conhecemos uma $(+)$-identidade:
o $0$, pelas \mref[ZA-IdR] e \mref[ZA-IdL], que afirmam exatamente isso.
\crproofpart {Unicidade: existe no máximo uma unicidade aditiva.}
Basta demonstrar que qualquer $u$ que é uma $(+)$-identidade, necessariamente
é o próprio $0$:
$$
\lforall {u} {\text{$u$ é uma $(+)$-identidade} \implies u = 0}.
$$
Seja $u$ uma $(+)$-identidade.
Calculamos:
\compute
u &= u + 0 \by {pois $0$ é uma $(+)$-identidade-R} \\
  &= 0.    \by {pois $u$ é uma $(+)$-identidade-L} \\
\endcompute

%%}}}

%%{{{ thm: int_uniqueness_of_multiplicative_identity 
\theorem Unicidade da $(\ntimes)$-identidade.
%%%{{{ meta 
\headerize
\label int_uniqueness_of_multiplicative_identity
%%%}}}

Existe único $u$ tal que para todo $x$, $ux = x = xu$.

\proof.
Essa também é tua: \ref[int_uniqueness_of_multiplicative_identity_proof].

%%}}}

%%{{{ x: int_uniqueness_of_multiplicative_identity_proof 
\exercise.
%%%{{{ meta 
\label int_uniqueness_of_multiplicative_identity_proof
%%%}}}

Demonstre o \ref[int_uniqueness_of_multiplicative_identity].

\hint
Imite a demonstração do \ref[int_uniqueness_of_additive_identity].

%%}}}

%%{{{ thm: int_uniqueness_of_additive_inverses 
\theorem Unicidade dos inversos aditivos.
%%%{{{ meta 
\headerize
\label int_uniqueness_of_additive_inverses
%%%}}}

Para todo $x$, existe único $x'$ tal que $x' + x = 0 = x + x'$.

\proof.
Seja $x$ inteiro.
\crproofpart {Existência: existe pelo menos um $(+)$-inverso de $x$.}
Imediato pois $-x$ é um (+)-inverso de $x$ (pelas \mref[ZA-InvR] e \mref[ZA-InvL]).
\crproofpart {Unicidade: existe no máximo um $(+)$-inverso de $x$.}
Seja $x'$ um $(+)$-inverso de $x$.
Ou seja, $x + x' = 0$ (usando apenas o fato que $x'$ é um inverso direito).
Como $-x$ também é um inverso direito, temos $x + (-x) = 0$.
Preciso demonstrar que $x' = -x$.
Calculamos:
\compute
x + x'
&= 0            \by {$x'$ é um inverso direito de $x$} \\
&= x + (-x)     \by {$-x$ é um inverso direito de $x$} \\
\endcompute
Como $x + x' = x + (-x)$, logo $x' = -x$ (pela \mref[ZA-CanL] com $c,a,b := x, x', -x$).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O próximo lemmazão deixa muitos teoremas como corolários triviais.

%%}}}

%%{{{ lemma: int_uniqueness_of_solutions 
\lemma Unicidade de resoluções.
%%%{{{ meta 
\headerize
\label int_uniqueness_of_solutions
%%%}}}

Para quaisquer $a,b$, existe único $x$ tal que $a + x = b$ e existe único $y$ tal que $y + a = b$.

\proof.
Teu também!  (\ref[int_uniqueness_of_solutions_proof])

%%}}}

%%{{{ x: int_uniqueness_of_solutions_proof 
\exercise.
%%%{{{ meta 
\label int_uniqueness_of_solutions_proof
%%%}}}

Demonstre o \ref[int_uniqueness_of_solutions].

\hint
Separe em duas partes: existência e unicidade.

\hint
Para a existência procure achar o que pode encaixar no lugar do $x$
para satisfazer a igualdade (umas coisas precisam ser canceladas.

\hint
Para a unicidade, já que achou um objeto que serve na existência,
basta supor que um $x$ satisfaz mesmo a equação $a + x = b$ e concluir
que $x$ deve ser igual ao objeto que achou na parte da existência.

%%}}}

%%{{{ x: corollaries show off 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre as unicidades anteriores (\reftag[int_uniqueness_of_additive_identity],
\reftag[int_uniqueness_of_additive_inverses]) como corolários
do \ref[int_uniqueness_of_solutions].

%%}}}

%%{{{ thm: int_neg_of_neg 
\theorem Negação é involutiva.
%%%{{{ meta 
\label int_neg_of_neg
%%%}}}

Para todo $x$, $-(-x) = x$.

\proof.
Temos $x + (-x) = 0$\fact1 (pela \mref[ZA-InvR] com $a := x$).
Também temos $(-(-x)) + (-x) = 0$ (pela \mref[ZA-InvL] com $a := -x$).
Logo $x = -(-x)$ (pela \ref[int_uniqueness_of_solutions] com $a,b := (-x),0$).

%%}}}

%%{{{ x: int_neg_x_is_minus_one_times_x 
\exercise.
%%%{{{ meta 
\label int_neg_x_is_minus_one_times_x
%%%}}}

Para todo $a$, $(-1)a = -a$.

%%}}}

%%{{{ x: int_product_and_neg 
\exercise.
%%%{{{ meta 
\label int_product_and_neg
%%%}}}

Para quaisquer $a,b$, $(-a)b = -(ab) = a(-b)$.

%%}}}

%%{{{ x: int_product_with_two_minuses 
\exercise.
%%%{{{ meta 
\label int_product_with_two_minuses
%%%}}}

Para quaisquer $a,b$, $(-a)(-b) = ab$.

%%}}}

%%{{{ x: int_neg_of_sum 
\exercise.
%%%{{{ meta 
\label int_neg_of_sum
%%%}}}

Para quaisquer $a,b$, temos $-(a-b) = b - a$ e $-(a+b) = -a-b$.

%%}}}

\spoiler

%%{{{ Three candidates 
\note Três candidatos.
%%%{{{ meta 
%%%}}}

Três sugestões razoáveis nesse ponto seriam as seguintes:
\mathcol
\cforall {a}      {a \ntimes 0 = 0}                        \stag[Z-AnnR] \\
\cforall {c,a,b}  {c \neq 0 \mland ac = bc \implies a = b} \stag[Z-MCanR] \\
\cforall {a,b}    {ab = 0 \implies a = 0 \mlor b = 0}.     \stag[Z-NZD] \\
\endmathcol
O primeiro afirma que o $0$ é um \dterm{anulador};
o segundo é a \dterm{lei de cancelamento multiplicativo pela direita};
o terceiro afirma que não há \dterm{zerodivisores} (no mundo dos inteiros).
Com certeza todas devem ser satisfeitos pelo nosso sistema de inteiros;
então que tal adicioná-las como axiomas?

%%}}}

%%{{{ Not that fast (1) 
\note Não tão rápido assim (1).
%%%{{{ meta 
%%%}}}

Primeiramente precisamos ver se conseguimos \emph{demonstrar} essas
proposições, as ganhando assim como teoremas.
Tente agora demonstrar cada uma delas e não desista fácil!
Consegues alguma?

%%}}}

\spoiler

%%{{{ x: int_zero_annihilator 
\exercise.
%%%{{{ meta 
\label int_zero_annihilator
%%%}}}

Demonstre que $0$ é um $(\ntimes)$-anulador:
\mathcol
\cforall {a}      {0 \ntimes a = 0}     \stag[Z-AnnL] \\
\cforall {a}      {a \ntimes 0 = 0}.    \stag[Z-AnnR] \\
\endmathcol

%%}}}

%%{{{ Two candidates 
\note Dois candidatos.
%%%{{{ meta 
%%%}}}

Os \mref[Z-MCanR] e \mref[Z-NZD] são de fato \emph{indemonstráveis}
pelos axiomas que temos até agora.
Por enquanto---e apenas por enquanto!---aceite isso, pois realmente é
um fato, e responda na próxima pergunta:
\emph{então já que são indemonstráveis, bora adicioná-los como axiomas?}
O que achas?

%%}}}

\spoiler

%%{{{ Not that fast (2) 
\note Não tão rápido assim (2).
%%%{{{ meta 
%%%}}}

Mesmo que realmente nenhuma das duas é demonstrável pelos axiomas atuais,
não faz sentido adicioná-las simultaneamente:
talvez uma das duas já é forte o suficiente para permitir demonstrar a outra.
Neste caso, acontece que ambas são igualmente fortes:
escolhendo qualquer uma das duas para adicionar nos nossos axiomas,
podemos inferir a outra como teorema!
Qual das duas vamos escolher então?
Felizmente essa escolha não vai fazer nenhuma diferença matemática para nossos
objetivos aqui.  Mesmo assim, que seja apenas por motivos burocráticos e
administrativos, precisamos fazer uma escolha---talvez jogando
uma moeda no ar---então vamo lá:

%%}}}

%%{{{ spec: int_spec_2 
\specification Os inteiros (2/5).
%%%{{{ meta 
\label int_spec_2
\defines
    * inteiros
    ;;
%%%}}}

Estipulamos mais um axioma:
\mathcol
\cforall {a,b}    {ab = 0 \implies a = 0 \mlor b = 0}      \stag[Z-NZD] \\
\endmathcol

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Imediatamente demonstramos a outra proposição como teorema antes de esquecer:

%%}}}

%%{{{ thm: int_cancellation_law 
\theorem A lei de cancelamento multiplicativo.
%%%{{{ meta 
\label int_cancellation_law
%%%}}}

Temos:
\mathcol
\cforall {c,a,b}  {c \neq 0 \mland ac = bc \implies a = b}. \stag[Z-MCanR] \\
\cforall {c,a,b}  {c \neq 0 \mland ca = cb \implies a = b}. \stag[Z-MCanL] \\
\endmathcol

\proof Demonstrarás agora.
\ref[int_cancellation_law_proof].

%%}}}

%%{{{ x: int_cancellation_law_proof
\exercise.
%%%{{{ meta 
\label int_cancellation_law_proof
%%%}}}

Demonstre a lei de cancelamento multiplicativo.

\hint
A chave principal na demonstração é nosso axioma mais recente de não zerodivisores, \mref[Z-NZD].

\solution
\proofpart {Primeiramente} demonstrarei a \mref[Z-MCanL].
Sejam $c,a,b$ inteiros tais que $c \neq 0$\fact1 e $ca = cb$\fact2.
Vou demonstrar que $a = b$.
Pela \byfact2, $ca - cb = 0$.
Logo $c(a-b) = 0$.
Logo $c = 0$ ou $a-b=0$.
Separamos em casos, e o primeiro é impossível pelo \byfact1.
Caso $a-b=0$.
Logo $a = b$.
\crproofpart {Segundamente} a \mref[Z-MCanR].
Ela é similar, e também segue como corolário da \mref[Z-MCanL] aplicando
a comutatividade da multiplicação na sua hipótese.

%%}}}

\endsection
%%}}}

%{{{ Divisibility 
\section Divisibilidade.
%%%{{{ meta 
\label Divisibility
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No \ref[Proofs] já encontramos a relação de <<divide>> que realmente é
a mais interessante relação para os inteiros.
Será que vamos aumentar então a estrutura dos inteiros para incluí-la como
\emph{noção primitiva} com
$$
(\divides) \eqtype \Int \times \Int \to \Prop?
$$
Não!
A noção de <<divide>> podemos realmente \emph{definir} em termos do que temos até agora
e logo não vamos adicioná-la como primitiva.

%%}}}

%%{{{ df: divides 
\definition Divisibilidade.
%%%{{{ meta 
\label divides
\defines
    * ~a \divides ~b  -- $a$ divide $b$
    * divide
    * divisor
    * divisível
    * multiplo
    ;;
%%%}}}

Sejam $a,b\in\ints$.
Digamos que \dterm{o $a$ divide o $b$} (ou \dterm{o $b$ é divisível por $a$}),
sse $b = ak$ para algum $k\in\ints$.
Nesse caso, escrevemos $a \divides b$.
Em símbolos:
$$
a \divides b \defiff \lexists {k\in\ints} {b = ak}.
$$
Os \dterm{divisores} do $a$ são todos os inteiros $d$ tais que $d \divides a$.
Naturalmente, usamos a notação $a \ndivides b$ quando $a$ não divide $b$.

%%}}}

%%{{{ thm: divides_is_a_preorder 
\theorem Divide é uma preordem.
%%%{{{ meta 
\label divides_is_a_preorder
%%%}}}

Para quaisquer inteiros $a,b,c$,
\mathcall
& a \divides a                                            \called {reflexividade} \\
& a \divides b \mland b \divides c \implies a \divides c. \called {transitividade}
\endmathcall

\proof Demonstrarás agora mesmo.
\ref[divides_is_a_preorder_proof].

%%}}}

%%{{{ x: divides_is_a_preorder_proof 
\exercise.
%%%{{{ meta 
\label divides_is_a_preorder_proof
%%%}}}

Demonstre o \ref[divides_is_a_preorder].

%%}}}

%%{{{ thm: divides_bottom 
\theorem bottom.
%%%{{{ meta 
\label divides_bottom
%%%}}}

$\lforall a {1 \divides a}$.

\proof Demonstrarás agora mesmo.
\ref[divides_bottom_proof].

%%}}}

%%{{{ x: divides_bottom_proof 
\exercise.
%%%{{{ meta 
\label divides_bottom_proof
%%%}}}

Demonstre o \ref[divides_bottom].

%%}}}

%%{{{ thm: divides_top 
\theorem top.
%%%{{{ meta 
\label divides_top
%%%}}}

$\lforall a {a \divides 0}$.

\proof.
Essa também é tua \ref[divides_top_proof].

%%}}}

%%{{{ x: divides_top_proof 
\exercise.
%%%{{{ meta 
\label divides_top_proof
%%%}}}

Demonstre o \ref[divides_top].

%%}}}

%%{{{ lemma: divides_linear_combinations 
\lemma combinações lineares.
%%%{{{ meta 
\label divides_linear_combinations
%%%}}}

\elist i:
\li: $d \divides a \implies \lforall x {d \divides ax}$;
\li: $d \divides a \mland d \divides b \implies d \divides a + b$;
\li: $d \divides a \mland d \divides b \implies \lforall {x,y} {d \divides ax + by}$.
\endelist

\proof.
Todas tuas: \ref[divides_linear_combinations_proof].

%%}}}

%%{{{ x: divides_linear_combinations_proof 
\exercise.
%%%{{{ meta 
\label divides_linear_combinations_proof
%%%}}}

Demonstre todas as propriedades da \ref[divides_linear_combinations], com duas estratégias diferentes:
(A) demonstre as duas primeiras, e mostre como ganhar a terceira como corolário delas;
(B) demonstre a terceira, e mostre como ganhar as duas primeiras como corolário ela.

%%}}}

%%{{{ x: divides_sign_blind 
\exercise sign-blind.
%%%{{{ meta 
\label divides_sign_blind
%%%}}}

Para quaisquer $a,b$, se $a \divides b$, então $-a \divides b$, $a \divides -b$, e (logo) $-a \divides -b$.

%%}}}

%%{{{ x: divides_multiply_both_rule 
\exercise.
%%%{{{ meta 
\label divides_multiply_both_rule
%%%}}}

Sejam $a,b,c$ inteiros com $c \neq 0$.
Demonstre: $a \divides b \!\iff\! ca \divides cb$.
Alguma das duas direções continua válida sem a hipótese $c \neq 0$?

%%}}}

\endsection
%%}}}

%%{{{ Sets_of_ints_closed_under_operations 
\section Conjuntos fechados sob operações.
%%%{{{ meta 
\label Sets_of_ints_closed_under_operations
%%%}}}

%%{{{ df: int_closed_under_addition 
\definition $(+)$-fechado.
%%%{{{ meta 
\label int_closed_under_addition
\defines
    * conjunto!$(+)$-fechado
    ;;
%%%}}}

Seja $A$ um conjunto de inteiros.
(Escrevemos: $A \is \Set\fa\Int$.)
Dizemos que $A$ é \dterm{fechado sob adição} sse
a soma de quaisquer $a,b\in A$ pertence ao $A$:
$$
\lforall {a,b \in A} {a+b \in A}.
$$
Também chamamos o $A$ de $(+)$-\dterm{fechado}.

%%}}}

%%{{{ remark: What does (∀a,b∈A)[...] mean? 
\remark.
%%%{{{ meta 
%%%}}}

Dessugarizando a forma que escrevi a proposição acima obtemos
$$
\lforall {a,b \in A} {a+b \in A}
\intiff
\lforall {a,b \is \Int} {a,b \in A \implies a+b \in A}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A definição pode ser generalizada para qualquer operação $n$-ária
(i.e., de aridade $n$---veja~\ref[arity_first_contact]).

%%}}}

%%{{{ x: int_define_closed_under_binary_op 
\exercise.
%%%{{{ meta 
\label int_define_closed_under_binary_op
%%%}}}

Escreva a definição generalizada de \wq{ser fechado sob uma operação binária},
a deixando bem escrita.
Cuidado: cada definição precisa começar estabelecendo primeiramente
o contexto necessário para o conceito que queremos definir ser afirmável.

\hint
O contexto deve incluir um conjunto de inteiros $A$
e uma operação binária $\heartop \is A \times A \to A$.

\hint
Começa assim:
\quote
<<Sejam $A$ conjunto de inteiros e $\heartop$ uma operação binária:
$$
\heartop \is \Int \times \Int \to \Int.\text{>>}.
$$
\endquote
Isso estabelece o contexto desejado para finalmente definir
o que precisamos.
Continuaria assim:
\quote
<<Chamamos o conjunto $A$ de $(\heartop)$-fechado sse\dots>>
\endquote

\solution
Sejam $A$ conjunto de inteiros e $\heartop$ uma operação binária:
$$
\heartop \is \Int \times \Int \to \Int.
$$
Chamamos o conjunto $A$ de $(\heartop)$-fechado sse
$$
\lforall {a,b \in A} {a \heartop b \in A}.
$$

%%}}}

%%{{{ prop: int_3Z_is_closed_under_addition 
\proposition.
%%%{{{ meta 
\label int_3Z_is_closed_under_addition
%%%}}}

O conjunto
$$
3\ints \defeq \setst {3x} {x \in \ints}
$$
é $(+)$-fechado.

\proof.
Sejam $a,b$ inteiros tais que $a,b \in 3\ints$.
Vou demonstrar que $a + b \in 3\ints$.
Vamos traduzir esses dois dados que temos sobre os $a,b$ e nosso alvo também,
já que todos envolvem a idéia de \emph{pertencer ao $3\ints$:}
\mathcol
a   \in \setst {3x} {x \in \ints} &\intiff \lexists {x \in \ints} {a   = 3x}; \\
b   \in \setst {3x} {x \in \ints} &\intiff \lexists {x \in \ints} {b   = 3x}; \\
a+b \in \setst {3x} {x \in \ints} &\intiff \lexists {x \in \ints} {a+b = 3x}. \\
\endmathcol
Logo sejam $u,v\in\ints$ inteiros tais que $a = 3u$\fact1 e $b = 3v$\fact2.
Precisamos escrever o $a+b$ na forma $3x$ para algum inteiro $x$.
Calculamos:
\compute
a + b
&= 3u + b       \by {pela \byfact1} \\
&= 3u + 3v      \by {pela \byfact2} \\
&= 3(u + v).    \by {pela \mref[Z-DistL]} \\
\endcompute
Logo $a + b \in 3\ints$.

%%}}}

%%{{{ advice: by_the_choice_of 
\advice \wq{Pela escolha de}.
%%%{{{ meta 
\label by_the_choice_of
\defines
    * pela escolha de
    ;;
%%%}}}

Na demonstração da~\ref[int_3Z_is_closed_under_addition] precisamos
citar os dados $a = 3u$ e $b = 3v$, e logo acabamos os rotulando,
usando os rótulos {\fact1} e {\fact2}, assim citando <<pela \byfact1>>
e <<pela \byfact2>> no cálculo.
Podemos evitar todo esse trabalho burocrático e conseguir
citar \emph{cada um desses dois dados} sem sequer rotulá-los.
Como?  A justificativa <<pela escolha de\dots>> serve exatamente
pra isso.  O cálculo acima fica assim:
\compute
a + b
&= 3u + b       \by {pela escolha de $u$} \\
&= 3u + 3v      \by {pela escolha de $v$} \\
&= 3(u + v).    \by {pela \mref[Z-DistL]} \\
\endcompute
Mas o que exatamente significa esse \dterm{pela escolha de}?
O seguinte: \emph{Caro leitor, vá lá no momento que tal objeto
foi declarado nesta demonstração, e olha que ele foi escolhido
para satisfazer algo.  É exatamente esse algo que estou citando aqui.}

%%}}}

%%{{{ noneg 
\nonexample.
%%%{{{ meta 
%%%}}}

O conjunto de todos os inteiros ímpares não é $(+)$-fechado (por quê?).
Nem o conjunto de todos os inteiros não nulos (diferentes de $0$) (por quê?).
Nem o conjunto de todos os inteiros cujos numerais no sistema decimal não termina em \sq{1} (por quê?).

%%}}}

%%{{{ x: why? why? why? 
\exercise.
%%%{{{ meta 
%%%}}}

Por quê?
Por quê?
Por quê?

\hint
Para cada conjunto basta achar um testemunha, ou seja,
um parzinho $(x,y)$ de membros dele tal que $x+y$ não pertence a ele.

\solution
Aqui três testemunhas, um para cada conjunto respectivamente:
\mathcols 3
1    + 1 &= 2 &
(-5) + 5 &= 0 &
17   + 4 &= 21
\endmathcols

%%}}}

%%{{{ x: emptyints_and_ints_are_op_closed: Ø and ℤ are (+,-,-,·)-closed 
\exercise.
%%%{{{ meta 
\label emptyints_and_ints_are_op_closed
%%%}}}

O $\ints$ e o $\emptyset$ são fechados sob:
adição, negação, subtração, multiplicação.
O $\ints$ porque não tem como sair (já que é o universo inteiro);
o $\emptyset$ porque não tem como entrar (e pra sair, precisa primeiro entrar).
Verifique.

%%}}}

%%{{{ x: generalize (+)-closed to op-closed for any op 
\exercise.
%%%{{{ meta 
%%%}}}

Generalize a noção de \wq{ser fechado sob uma operação binária}
ainda mais: considerando uma operação $n$-ária,
de qualquer aridade $n \geq 1$.

\solution
Seja $f$ uma operação $n$-ária nos inteiros.
Dizemos que $A$ é $f$-fechado sse para quaisquer
$a_1,\dotsc,a_n \in A$, temos $f(a_1,\dotsc,a_n) \in A$.

%%}}}

%%{{{ x: emptyset_and_universe_are_closed_under_any_op 
\exercise.
%%%{{{ meta 
\label emptyset_and_universe_are_closed_under_any_op
%%%}}}

Enuncie e demonstre uma versão mais geral dos dois extremos do
\ref[emptyints_and_ints_are_op_closed].

%%}}}

%%{{{ x: int_mZ_is_closed_under_addition_negation_subtraction_multiplication 
\proposition.
%%%{{{ meta 
\label int_mZ_is_closed_under_addition_negation_subtraction_multiplication
%%%}}}

Seja $m$ inteiro.
O conjunto
$$
m\ints \defeq \setst {mx} {x \in \ints}
$$
é fechado sob: adição $(+)$, negação $(-)$, subtração $(-)$, multiplicação $(\ntimes)$.

\proof.
\proofpart {Adicão.}
Basta substituir todos os \sq{$3$} por \sq{$m$} na
demonstração da \ref[int_3Z_is_closed_under_addition],
já que a única informação sobre o $3$ que precisamos naquela demonstração
foi que $3$ é um inteiro.
\crproofpart {Multiplicação.}
Sejam $a,b \in m\ints$ e logo seja $u$ tal que $a = mu$.
Calculamos:
\compute
ab
&= (mu)b    \by {pela escolha de $u$} \\
&= m(ub)    \by {pelo \mref[ZM-Ass]} \\
&\in m\ints.
\endcompute
\crproofpart {Negação.}
Deixo pra ti (\ref[int_mZ_is_closed_under_negation_proof]).
\crproofpart {Subtração.}
Isso é corolário fácil das duas anteriores pela maneira que definimos subtração.
Vamos seguir os detalhes mesmo assim.
Sejam $a,b$ inteiros tais que $a \in m\ints$\fact1, $b \in m\ints$\fact2.
Como $m\ints$ é fechado sob negação, temos $-b \in m\ints$\fact3.
Agora pelas \byfact1 e \byfact2 temos o desejado $a - b \in m\ints$, já que
$m\ints$ é $(+)$-fechado.

%%}}}

%%{{{ x: int_mZ_is_closed_under_negation_proof 
\exercise.
%%%{{{ meta 
\label int_mZ_is_closed_under_negation_proof
%%%}}}

Demonstre que $m\ints$ é fechado sob a negação $(-)$.

\solution
Seja $a \in m\ints$ e logo seja $u$ tal que $a = mu$.
Calculamos:
\compute
-a
&= -(mu)    \by {pela escolha de $u$} \\
&= m(-u)    \by {pelo \ref[int_product_and_neg]} \\
&\in m\ints.
\endcompute

%%}}}

%%{{{ x: which of the following sets are closed under which ops? 
\exercise.
%%%{{{ meta 
%%%}}}

Quais dos conjuntos abaixo são fechados sob quais das operações
$(+),(-),(-),(\ntimes)$?\foot
Não finja que tu não entendeu o porquê que o $(-)$ foi repetido alí.
\toof
$$
\mathcoled {
    I &= \ints_{\neq 0} \\
    U &= \set{0} \\
    W &= \set{0,1} \\
    T &= \set{-1,0,1} \\
} \quad \mathcoled {
    A &= \set{0,4,6,10,12,16,18,22,24,\dotsc} \\
    B &= \set{1,2,4,8,16,\dotsc} \\
    C &= \set{\dotsc,-9,-6,-3,0,3,6,9,\dotsc} \\
    D &= \set{\dotsc,-8,-5,-2,1,4,7,10,\dotsc}. \\
}
$$
Antes de tudo, defina os conjuntos $A,B,C,D$ sem usar \sq{$\ldots$},
usando a notação set-builder.

%%}}}

%%{{{ Q: what about closed under nullary ops? 
\question.
%%%{{{ meta 
%%%}}}

Por que nos limitar no caso $n>1$ e não considerar o $n=0$ também?
O que significaria fechado sob uma operação nulária---aliás,
faz sentido falar de operações nulárias?

%%}}}

\spoiler

%%{{{ nullary_ops 
\note Operações nulárias.
%%%{{{ meta 
\label nullary_ops
%%%}}}

Uma operação binária (de aridade $2$) recebe $2$ inteiros e retorna um inteiro.
Uma operação unária precisa $1$ inteiro para retornar um inteiro.
Uma operação nulária (de aridade $0$) então deve ser algo que recebendo\dots
$0$ inteiros, já retorna um inteiro.
Podemos identificar isso com as constantes.
Nesse sentido, afirmar que $A$ é fechado sob $0$
significa simplesmente que $0 \in A$, e similarmente sobre o $1$.

%%}}}

%%{{{ x: minus_closed_implies_plus_closed 
\exercise.
%%%{{{ meta 
\label minus_closed_implies_plus_closed
%%%}}}

Demonstre que se um conjunto $F$ é fechado sob a \emph{operação binária de subtração}
$(-)$ então $F$ deve ser $(+)$-fechado também, e mostre que o reciproco não
é necessariamente verdadeiro.

%%}}}

%%{{{ Q: int_does_subtraction_closed_imply_mZ 
\question.
%%%{{{ meta 
\label int_does_subtraction_closed_imply_mZ
%%%}}}

Demonstramos que o conjunto
$$
m\ints \defeq \setst {mx} {x \in \ints}
$$
de todos os múltiplos de $m$ é fechado sob adição e subtração.
Será que podemos dizer algo sobre a direção contrária?
Sabendo que um conjunto de inteiros $F$ é fechado por adição e subtração,
será que podemos inferir que existe um certo inteiro $m$ tal que $F = m\ints$?
Tente dar sua própria resposta nisso desde já; pois logo a gente voltar
a resolver mesmo essa questão (com o \ref[form_of_closed_under_subtraction]).

%%}}}

\endsection
%%}}}

%%{{{ Order_and_positivity_ints 
\section Ordem e positividade.
%%%{{{ meta 
\label Order_and_positivity_ints
%%%}}}

%%{{{ int_something_missing_order 
\note Algo está faltando (1).
%%%{{{ meta 
\label int_something_missing_order
%%%}}}

Mesmo que temos demonstrado tanta coisa importante sobre os inteiros,
ainda falta um componente crucial que também faz parte da estrutura
deles:
a ordem $(<)$, ou seja a noção de comparar dois inteiros e ver
se um é menor que o outro ou não.
\eop
Parece então razoável aumentar a estrutura para
$$
\sset \ints {0, 1, +, -, \ntimes, <}
$$
com
$$
(<) \is \Int \times \Int \to \Prop.
$$
Isso apenas declara que tipo de coisa é esse $(<)$: é uma relação binária nos inteiros.
Não confunda isso com uma definição do que significa mesmo $x < y$.

%%}}}

%%{{{ int_something_missing_positivity 
\note Algo está faltando (2).
%%%{{{ meta 
\label int_something_missing_positivity
%%%}}}

Uma outra idéia seria aumentar a estrutura dos inteiros para incluir um
\emph{subconjunto} $\Pos$ de $\ints$: o subconjunto dos inteiros positivos.
Em vez de complicar a tipagem considerando o $\Pos$ como um conjunto de inteiros mesmo,
o declarando como
$$
\Pos \is \Set(\Int),
$$
vamos considerar o $\Pos$ com a tipagem seguinte:
$$
\Pos \is \Int \to \Prop.
$$
Ou seja, $\Pos$ não é, literalmente, o \emph{conjunto} dos inteiros positivos;
$\Pos$ é o \emph{predicado} (unário) <<{\thole} é positivo>>.
Escrevemos, de acordo com a tipagem,
$$
\Pos \fa x \qqqqtext{ou} \Pos(x)
$$
para significar <<$x$ é positivo>>.
Mas observe que isso \emph{não define} o $\Pos$, pois não temos definido mesmo
o que significa <<ser positivo>>.  Aqui estamos apenas falando como
pronunciar a afirmação $\Pos \fa x$.

%%}}}

%%{{{ int_positivity_intro 
\note Bora adicionar?.
%%%{{{ meta 
\label int_positivity_intro
%%%}}}

Ambas as idéias parecem razoáveis, então talvez
faria sentido adicionar ambas mesmo como partes primitivas nos inteiros, assim:
$$
\sset \ints {0,1,+,-,\ntimes,{<},\Pos}
$$
com
\mathcols 2
(<)    &\is \Int \times \Int \to \Prop &
{\Pos} &\is \Int \to \Prop. \\
\endmathcols
Mas realmente não precisamos ambas.  Tendo uma (qualquer uma das duas), a outra
é definível, em tal forma que seus axiomas correspondentes são demonstráveis como teoremas.
Mesmo assim, precisamos escolher qual vai ser a primitiva; e aqui escolhemos a $\Pos$.

%%}}}

%%{{{ spec: int_spec_3 
\specification Os inteiros (3/5).
%%%{{{ meta 
\label int_spec_3
\indexes
    * abuso notacional
    ;;
\defines
    * inteiros
    ;;
%%%}}}

Aumentamos a estrutura dos inteiros adicionando um predicado unário:
$$
\sset \ints {0,1,+,-,\ntimes,\Pos}
$$
com
$$
{\Pos} \is \Int \to \Prop.
$$
Introduzimos logo como açúcar sintáctico um \emph{abuso notacional} que nos permite
tratar o predicado $\Pos$ \emph{como se fosse} conjunto:
$$
x \in \Pos \abuseiff \Pos \fa x.
$$
Estipulamos os axiomas seguintes sobre os inteiros positivos:
\mathcols 3
\qquad
&&\cforall  {a,b \in \Pos} {a + b \in \Pos}
&&\text{($\Pos$ é $(+)$-fechado)}        \stag[ZP-ACl] \\
&&\cforall  {a,b \in \Pos} {a\ntimes b \in \Pos}
&&\text{($\Pos$ é $(\ntimes)$-fechado)}  \stag[ZP-MCl] \\
&&\cforallt {a} {e.u.d.: $a \in \Pos$; $a = 0$; $-a \in \Pos$}.
                                         \stag[ZP-Tri] \\
\endmathcols
onde <<e.u.d.>>~significa \emph{exatamente uma das}.

%%}}}

%%{{{ df: int_negativity 
\definition Negatividade.
%%%{{{ meta 
\defines
    * negativo!inteiro
    ;;
%%%}}}

Seja $x$ inteiro.
Dizemos que $x$ é \dterm{negativo} sse $-x$ é positivo.
Introduzimos também a notação
$$
\Neg \is \Int \to \Prop
$$
com o mesmo abuso notacional que nos permite tratá-la
como se fosse conjunto.

%%}}}

%%{{{ df: int_orders 
\definition ordens.
%%%{{{ meta 
%%%}}}

Tendo escolhido como primitiva a noção de positividade,
queremos introduzir como açúcar sintáctico as notações
usuais de ordem para poder escrever $x < y$, $x \geq y$, etc.
Como podemos definir o que significa $x < y$?
\eop
Sejam $x,y$ inteiros.  Definimos as relações
$$
(<),(\leq),(>),(\geq) \is \Int \times \Int \to \Prop
$$
pelas
\mathcols 2
x < y    &\defiff \text{$y - x$ é positivo} &
x \leq y &\defiff \text{$x < y$ ou $x = y$} \\
x > y    &\defiff y < x &
x \geq y &\defiff y \leq x \\
\endmathcols

%%}}}

%%{{{ Strict and nonstrict orders 
\note Conjuntos ordenados.
%%%{{{ meta 
%%%}}}

Relações binárias como a $(<)$ e a $(\leq)$ que definimos aqui
são chamadas relações de ordem: a $(<)$ é uma ordem estrita, a $(\leq)$ não.
Um conjunto cujos membros podemos comparar com uma relação de ordem
destacada é chamado conjunto ordenado e mais pra frente vamos dedicar
capítulos inteiros para seu estudo numa maneira abstrata.
Por enquanto precisamos só trabalhar com o conjunto de inteiros,
e com certeza sabemos como comparar inteiros: tanto com a $(<)$,
quanto com a $(\leq)$.

%%}}}

%%{{{ x: int_negative_iff_lt_zero 
\exercise.
%%%{{{ meta 
\label int_negative_iff_lt_zero
%%%}}}

Demonstre que para todo inteiro $x$, $x$ é negativo sse $x < 0$.

%%}}}

%%{{{ thm: int_lt_axioms_as_theorems 
\theorem.
%%%{{{ meta 
\label int_lt_axioms_as_theorems 
%%%}}}

A relação $(<)$ goza das propriedades seguintes:
\mathcol
\cforall  {a,b,c} {a < b \mland b < c \implies a < c}     \stag[ZO-Trans] \\
\cforallt {a,b}   {exatamente uma das: $a < b$; $a = b$; $a > b$}
                                                          \stag[ZO-Tri] \\
\cforall  {a,b,c} {a < b \implies a + c < b + c}          \stag[ZO-A]   \\
\cforall  {a,b,c} {a < b \mland c > 0 \implies ac < bc}.  \stag[ZO-M]   \\
\endmathcol

\proof.
\proofpart {Parte} \mref[ZO-Trans].
Sejam $a,b,c$ inteiros.
Suponha $a < b$ e $b < c$, ou seja, $b-a \in \Pos$\fact1 e $c-b \in \Pos$\fact2.
Preciso demonstrar $a < c$, ou seja, $c-a \in \Pos$.
Como $\Pos$ é $(+)$-fechado, pelas \byfact1 e \byfact2 temos $(b-a) + (c-b) \in \Pos$.
Basta então estabelecer que $(b-a) + (c-b) = c-a$.
Calculamos:
\compute
(b-a) + (c-b)
&\inteq  (b + (-a)) + (c + (-b)) \\
&=       (c + (-b)) + (b + (-a)) \by {$(+)$-com.~com $a,b := (b + (-a)), (c + (-b))$} \\
&=       ((c + (-b)) + b) + (-a) \by {$(+)$-ass.~com $a,b,c := (c+(-b)), b, -a$} \\
&=       (c + ((-b) + b)) + (-a) \by {$(+)$-ass.~com $a,b,c := c, -b, b$} \\
&=       (c + 0) + (-a)          \by {\mref[ZA-InvL] com $a := b$} \\
&=       c + (-a)                \by {\mref[ZA-IdR] com $a := c$} \\
&\inteq  c - a.                  \\
\endcompute
\proofpart {Parte} \mref[ZO-Tri].
No \ref[ZO-Tri_proof]
\crproofpart {Parte} \mref[ZO-A].
Sejam $a,b,c$ inteiros.
Suponha $a < b$, ou seja $b - a \in \Pos$.
Preciso demonstrar $a + c < b + c$, ou seja, $(b + c) - (a + c) \in \Pos$.
Calculamos:
\compute
(b + c) - (a + c)
&\inteq (b + c) + (-(a + c)) \noby \\
&=      (b + c) + (-1)(a + c)      \\
&=      (b + c) + ((-1)a + (-1)c)  \\
&=      (b + c) + ((-a) + (-c))    \\
&=      (b + c) + ((-c) + (-a))    \\
&=      ((b + c) + (-c)) + (-a)    \\
&=      (b + (c + (-c))) + (-a)    \\
&=      (b + 0) + (-a)             \\
&=      b + (-a)                   \\
&\inteq b - a.                     \\
\endcompute
\proofpart {Parte} \mref[ZO-M].
Sejam $a,b,c$ inteiros.
Suponha $a < b$ e $c > 0$.
Ou seja, $b - a \in \Pos$\fact1 e $c \in \Pos$\fact2.
Vou demonstrar $ac < bc$, ou seja, $bc - ac \in \Pos$.
Mas $bc - ac = (b - a)c$ (por quê?) e realmente $(b - a)c \in \Pos$
pelas \byfact1 e \byfact2, pois $\Pos$ é $(\ntimes)$-fechado.

%%}}}

%%{{{ x: ZO-A_details 
\exercise.
%%%{{{ meta 
\label ZO-A_details
%%%}}}

Justifique cada linha do cálculo da demonstração de \mref[ZO-A].

%%}}}

%%{{{ x: ZO-A_lemma_opportunity 
\exercise.
%%%{{{ meta 
\label ZO-A_lemma_opportunity
%%%}}}

Tem algo feio nas primeiras 4 linhas desse cálculo aí.
O quê?

\hint
Deveriam ser 1 nesta demonstração.  Como?

\solution
Deveriamos perceber a oportunidade de demonstrar um lemmazinho
que nos permite diretamente ir de $-(a + c)$ para $(-a) + (-c)$.

%%}}}

%%{{{ x: ZO-M_details 
\exercise.
%%%{{{ meta 
\label ZO-M_details
%%%}}}

Escreva o cálculo que não escrevi na demonstração de \mref[ZO-M], justificando
cada um dos seus passos.

%%}}}

%%{{{ x: ZO-Tri_proof 
\exercise.
%%%{{{ meta 
\label ZO-Tri_proof
%%%}}}

Demonstre a parte \mref[ZO-Tri] do \ref[int_lt_axioms_as_theorems].

\hint
Use a tricotomía \mref[ZP-Tri].

\hint
Sejam $a,b$ inteiros.
Aproveitando a tricotomía \mref[ZP-Tri] basta demonstrar as três equivalências:
\mathcols 3
b - a    \in \Pos &\iff a < b &
b - a    = 0      &\iff a = b &
-(b - a) \in \Pos &\iff a > b.
\endmathcols

\solution
Sejam $a,b$ inteiros.
Aproveitamos a tricotomía \mref[ZP-Tri] e para conseguir a \mref[ZO-Tri]
basta demonstrar as três equivalências:
\mathcols 3
b - a    \in \Pos &\iff a < b &
b - a    = 0      &\iff a = b &
-(b - a) \in \Pos &\iff a > b.
\endmathcols
A primeira é imediata (temos até $\intiffsymbol$, pois se trata da própria definição de $a<b$).
A terceira segue diretamente pelo \ref[int_neg_of_sum] ($-(b-a)=a-b$).
Para a segunda demonstramos cada direção separadamente:
\lrdir: Temos $b + (-a) = 0$ pela hipótese desta direção e também $a + (-a) = 0$
pela \mref[ZA-InvR].
Logo $a = b$ pela \ref[int_uniqueness_of_solutions]
para a equação $\uhole + (-a) = 0$.
\rldir: Precisamos demonstrar $b - a = 0$, só que $a=b$ e logo basta demontrar $a - a = 0$, que é imediato pela \mref[ZA-InvR].

%%}}}

%%{{{ thm: int_lt_is_a_strict_total_order 
\theorem.
%%%{{{ meta 
\label int_lt_is_a_strict_total_order 
\defines
    * ordem!irreflexiva
    * ordem!assimétrica
    * ordem!conectada
    * ordem!estrita
    ;;
%%%}}}

A relação $(<)$ é uma \dterm{ordem estrita}, ou seja, ela é
\dterm{transitiva}, \dterm{irreflexiva}, e \dterm{assimétrica}:
\mathcall
\cforall  {a,b,c} {a < b \mland b < c \implies a < c}   \called {transitiva} \\
\cforall  {a}     {a \nlt a}                            \called {irreflexiva} \\
\cforall  {a,b}   {a < b \implies b \nlt a}.            \called {assimétrica}  \\
\intertext{Ainda mais, ela é \dterm{conectada} ou \dterm{estritamente total}:}
\cforall  {a,b}   {a \neq b \implies a < b \mlor b < a} \called {conectada} \\
\endmathcall
e portanto ela é uma \dterm{ordem estrita total}.

\proof.
A transitividade já demonstramos no \ref[int_lt_axioms_as_theorems].
O resto é o \ref[int_lt_is_a_strict_total_order_proof]:

%%}}}

%%{{{ x: int_lt_is_a_strict_total_order_proof 
\exercise.
%%%{{{ meta 
\label int_lt_is_a_strict_total_order_proof
%%%}}}

A relação $(<)$ é \dterm{irreflexiva}, \dterm{assimétrica}, e \dterm{conectada}.

%%}}}

%%{{{ thm: int_leq_is_a_total_order 
\theorem.
%%%{{{ meta 
\label int_leq_is_a_total_order 
%%%}}}

A relação $(\leq)$ goza das propriedades seguintes:
\mathcall
\cforall  {a}     {a \leq a}                                    \called {reflexividade}  \\
\cforall  {a,b}   {a \leq b \mland b \leq a \implies a = b}     \called {antissimetria}  \\
\cforall  {a,b,c} {a \leq b \mland b \leq c \implies a \leq c}  \called {transitividade} \\
\intertext{e por isso chamamos de \dterm{ordem}.  Ainda mais ela goza da}
\cforall  {a,b}   {a \leq b \mlor b \leq a}                     \called {totalidade} \\
\endmathcall
e logo ela é ainda mais: uma \dterm{ordem total}.

\proof Demonstrarás agora mesmo.
É o \ref[int_leq_is_a_total_order_proof].

%%}}}

%%{{{ x: int_leq_is_a_total_order_proof 
\exercise.
%%%{{{ meta 
\label int_leq_is_a_total_order_proof
%%%}}}

Demonstre que $(\leq)$ é uma ordem total (\ref[int_leq_is_a_total_order]).

%%}}}

%%{{{ x: int_lt_multiplicative_cancellation 
\exercise.
%%%{{{ meta 
\label int_lt_multiplicative_cancellation
%%%}}}

Sejam $c,a,b$ inteiros.
Se $c > 0$, então $ac < bc$ implica $a < b$.

%%}}}

%%{{{ x: int_sum_inequalities 
\exercise.
%%%{{{ meta 
\label int_sum_inequalities
%%%}}}

Para quaisquer inteiros $a,b,u,v$, se $a < b$ e $u < v$, então $a + u < b + v$.

%%}}}

%%{{{ x: int_we_cannot_multiply_inequalities 
\exercise.
%%%{{{ meta 
\label int_we_cannot_multiply_inequalities
%%%}}}

Sejam $a,b,u,v$ inteiros.
Demonstre, refute, ou mostre independente:
se $a < b$ e $u < v$, então $au < bv$.

%%}}}

%%{{{ lemma: int_nonzeros_have_positive_squares 
\lemma.
%%%{{{ meta 
\label int_nonzeros_have_positive_squares
%%%}}}

Para todo $a \neq 0$, $a^2$ é positivo.

\proof.
Seja $a$ inteiro tal que $a \neq 0$.
Vou demonstrar que $a^2$ é positivo.
Separamos em casos: $a$ positivo; $a=0$; $-a$ positivo, onde o segundo caso é eliminado pela hipótese.
\proofcase {Caso $a$ positivo.}
Imediato pelo \mref[ZP-MCl] (com $a,b := a$) pois $a^2 = a \ntimes a$.
\proofcase {Caso $-a$ positivo.}
Novamente pelo \mref[ZP-MCl] (essa vez com $a,b := -a$) pois $a^2 = (-a)(-a)$.

%%}}}

%%{{{ prop: int_one_is_positive_too_soon 
\proposition.
%%%{{{ meta 
\label int_one_is_positive_too_soon
%%%}}}

$1$ é positivo.

\proof.
Isso é um corolário imediato do \ref[int_nonzeros_have_positive_squares] pois
$1 = 1^2$.\mistake

%%}}}

%%{{{ Q: why wrong? 
\question.
%%%{{{ meta 
%%%}}}

Qual o erro na demonstração acima?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

A demonstração aplica a
$$
\lforall {a} {a \neq 0 \implies \text{$a^2$ é positivo}}
$$
(o \ref[int_nonzeros_have_positive_squares]) no inteiro $1$,
fingindo que isso fornece a proposição que $1^2$ é positivo.
Mas, olhando bem, o \reftag[int_nonzeros_have_positive_squares]
aplicado no $1$ fornece na verdade \emph{a implicação}
$$
1 \neq 0 \implies \text{$1^2$ é positivo}
$$
então para conseguir mesmo seu lado direito (que é o que precisamos aqui),
devemos conseguir seu lado esquerdo, $1 \neq 0$, que é algo
que não temos demonstrado.
Com certeza desejamos que $0 \neq 1$ para nossos inteiros,
então ou precisamos demonstrá-lo para ganhar como teorema,
ou estipulá-lo como axioma.

%%}}}

%%{{{ Q: How can we prove 0 ≠ 1? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos demonstrar $0 \neq 1$?
Tente, antes de continuar para ver a resposta!

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Eu espero que tu deu pelo menos um esforço mental tentando
demonstrar $0 \neq 1$.
E eu sei que tu não conseguiu.\foot
Caso que tu achas que conseguiu,
tu acabou de ganhar um exercício bônus: ache o erro na tua demonstração!
\toof
De fato, é algo que precisamos aceitar aqui como axioma:

%%}}}

%%{{{ spec: int_spec_4: The nontriviality of the integers 
\specification Os inteiros (4/5).
%%%{{{ meta 
\label int_spec_4
\defines
    * inteiros
    ;;
%%%}}}

Estipulamos o
\mathcol
&{0 \neq 1}      \stag[Z-NZero]\\
\endmathcol
como axioma para os inteiros.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora consertamos a demonstração do \ref[int_one_is_positive]
e conseguimos finalmente o $1 > 0$:

%%}}}

%%{{{ thm: int_one_is_positive 
\theorem.
%%%{{{ meta 
\label int_one_is_positive
%%%}}}

$1$ é positivo.

\proof.
Isso é um corolário imediato do \ref[int_nonzeros_have_positive_squares]
pois $1 \neq 0$ e $1 = 1^2$.

%%}}}

%%{{{ x: int_no_imaginary_unit 
\exercise.
%%%{{{ meta 
\label int_no_imaginary_unit
%%%}}}

Demonstre que a equação $x^2 + 1 = 0$ não possui resolução no incógnito $x$.

%%}}}

\endsection
%%}}}

%%{{{ Minima and maxima 
\section Mínima e máxima.
%%%{{{ meta 
%%%}}}

%%{{{ df: int_minb_and_maxb 
\definition.
%%%{{{ meta 
\label int_minb_and_maxb
%%%}}}

Definimos as operações binárias de mínimo e máximo:
\mathcols 2
\minb &\eqtype \Int \times \Int \to \Int &
\maxb &\eqtype \Int \times \Int \to \Int \\
\minb (x,y) &\defeq \cased {
x, & caso $x \leq y$; \\
y, & caso $x > y$;\\
} & 
\maxb (x,y) &\defeq \cased {
y, & caso $x \leq y$; \\
x, & caso $x > y$.\\
}
\endmathcols
Em notação infixa usamos os símbolos $(\meet)$ e $(\join)$, respectivamente.

%%}}}

%%{{{ x: int_min_max_algebraic_properties 
\exercise.
%%%{{{ meta 
\label int_min_max_algebraic_properties
%%%}}}

Para cada uma das propriedades algébricas que temos destacado até agora
investigue quais são satisfeitas pelos $(\meet)$ e $(\join)$.
Não esqueça investigar possíveis distributividades.

%%}}}

%%{{{ notation: leq_set_notation_abuse 
\notation.
%%%{{{ meta 
\label leq_set_notation_abuse
%%%}}}

Sejam $A$ um conjunto de inteiros e $x$ um inteiro.
Abusando a notação escrevemos $x \leq A$ e $A \leq x$:
\mathcols 2
x \leq A &\abuseiff \lforall {a \in A} {x \leq a} &
A \leq x &\abuseiff \lforall {a \in A} {a \leq x}.
\endmathcols

%%}}}

%%{{{ df: int_min 
\definition mínimo, máximo.
%%%{{{ meta 
\label int_min
\defines
    * {~x} = \min {~A}  -- $x$ é membro mínimo do $A$
    * {~x} = \max {~A}  -- $x$ é membro máximo do $A$
    * mínimo
    * máximo
    ;;
%%%}}}

Seja $A$ um conjunto de inteiros.
Um membro $m\in A$ é chamado de \dterm{(membro) mínimo do $A$}
sse para todo $a \in A$, $m \leq a$.
Escrevemos
$$
m = \min A
\defiff
m \in A \mland m \leq A.
$$
Note que necessariamente um mínimo dum conjunto $A$, se existe, pertence ao $A$.
Similarmente definimos a noção de \dterm{(membro) máximo} (\ref[int_max]).

%%}}}

%%{{{ warning: notational_abuse_of_equals_min 
\warning abuso notacional.
%%%{{{ meta 
\label notational_abuse_of_equals_min
%%%}}}

Escrevendo \symq{$m = \min A$} dá para confundir e pensar que se trata de
uma igualdade.  Na verdade é apenas uma conjunção desfarçada, vestindo roupas
notacionais de $(=)$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para justificar a definição do símbolo $\min A$, \emph{devemos}
demonstrar o seguinte:

%%}}}

%%{{{ x: int_uniqueness_of_minimum 
\exercise Unicidade de mínimo.
%%%{{{ meta 
\label int_uniqueness_of_minimum
%%%}}}

Um conjunto de inteiros não pode ter mais que um mínimo.

\hint
Por fight club: suponha que um conjunto tem mínima $m_1,m_2$ e aplicando
a definição de ``mínimo'' e propriedades de $(\leq)$, conclua que são iguais.

\hint
Pelas $m_1 \leq m_2$ e $m_2 \leq m_1$ concluimos que $m_1 = m_2$.

\solution
Sejam $m_1, m_2$ mínima dum conjunto $A$, ou seja, temos
$m_1, m_2 \in A$, e também
$$
\lforall {a\in A} {m_1 \leq a} \qquad
\lforall {a\in A} {m_2 \leq a}
$$
Usando a primeira com $a \asseq m_2$ e a segunda com $a \asseq m_1$ temos:
$$
m_1 \leq m_2 \mland
m_2 \leq m_1.
$$
Portanto, $m_1 = m_2$ (pela antissimetria da $(\leq)$).

%%}}}

%%{{{ x: int_min_eq_min_means_what 
\exercise.
%%%{{{ meta 
\label int_min_eq_min_means_what
%%%}}}

Tecnicamente expressões como \symq{$\min A = \min B$}
e \symq{$\max A < \min B$} também não foram definidas.
Mesmo assim, é útil ter essas notações significando algo.
Defina ambas atribuindo a elas seus significados desejados.

%%}}}

%%{{{ beware: no_standalone_use_of_min 
\beware.
%%%{{{ meta 
\label no_standalone_use_of_min
%%%}}}

Definimos o predicado
$$
\uhole = \min \uhole : \Int \times \Set\fa\Int \to \Prop
$$
assim podendo escrever coisas como \symq{$1 = \min A$};
mas a expressão \symq{$\min A$} sozinha não foi definida.

%%}}}

%%{{{ x: int_max 
\exercise E o máximo?.
%%%{{{ meta 
\label int_max
%%%}}}

Defina o que significa \dterm{(membro) máximo} dum conjunto de inteiros $A$,
e demonstre o que deves demonstrar junto com tua definição.

%%}}}

%%{{{ x: int_from_min_to_max 
\exercise de min pra max.
%%%{{{ meta 
\label int_from_min_to_max
%%%}}}

Seja $A \subset \ints$.
Definimos o conjunto $-A$ de todos os opostos de $A$ assim:
$$
-A \defeq \setst {-a} {a \in A},
$$
ou seja, $-A$ é o conjunto de todos os $-a$, tais que $a \in A$.
Demonstre que se $A$ possui mínimo, então $-A$ possui máximo e
\mathcol
\min A &= -\max(-A) \\
\intertext{e, dualmente, se $A$ possui máximo, então $-A$ possui mínimo e}
\max A &= -\min(-A).
\endmathcol

%%}}}

\endsection
%%}}}

%%{{{ Absolute_value_ints 
\section Valor absoluto.
%%%{{{ meta 
\label Absolute_value_ints
%%%}}}

%%{{{ df: int_absolute_value 
\definition valor absoluto.
%%%{{{ meta 
\defines
    * valor absoluto
    ;;
%%%}}}

Introduzimos o operador unário
$$
\abs{\uhole} \is \Int \to \Int
$$
definido por casos assim:
$$
\abs x \defeq \cased {
 x, & se $x \geq 0$; \\
-x, & se $x < 0$.
}
$$
Chamamos o $\abs x$ de \dterm{valor absoluto de $x$}.\foot
O $\abs x$ é conhecido em português como \dterm{módulo de $x$},
mas vamos falar tanto a palavra ``módulo'' que acho melhor usar
o ``valor absoluto'' do \emph{absolute value} para este uso.
\toof

%%}}}

%%{{{ x: int_abs_nonneg 
\exercise.
%%%{{{ meta 
\label int_abs_nonneg
%%%}}}

Para todo $x$ inteiro, $\abs x \geq 0$.

%%}}}

%%{{{ x: int_abs_zero 
\exercise.
%%%{{{ meta 
\label int_abs_zero
%%%}}}

Para todo $x$ inteiro, $\abs x = 0 \iff x = 0$.

%%}}}

%%{{{ x: int_abs_idemp 
\exercise idempotência.
%%%{{{ meta 
\label int_abs_idemp
%%%}}}

Para todo $x$ inteiro, $\abs {\abs x} = \abs x$.

\hint
Use a \mref[ZO-Tri] para separar em casos.

%%}}}

%%{{{ x: int_abs_of_neg_is_abs_of_id 
\exercise.
%%%{{{ meta 
\label int_abs_of_neg_is_abs_of_id
%%%}}}

Para todo $x$ inteiro, $\abs {-x} = \abs x$.

\hint
Use a \mref[ZO-Tri] para separar em casos.

%%}}}

%%{{{ x: int_abs_leq_abs 
\exercise.
%%%{{{ meta 
\label int_abs_leq_abs
%%%}}}

Demonstre: $\lforall {a,u} {\abs a \leq \abs u  \iff  -\abs u \leq a \leq \abs u}$.

%%}}}

%%{{{ x: int_abs_bounds 
\exercise.
%%%{{{ meta 
\label int_abs_bounds
%%%}}}

Demonstre: $\lforall {a}   {-\abs a \leq a \leq \abs a}$.

%%}}}

%%{{{ thm: int_triangle_ineq 
\theorem.
%%%{{{ meta 
\label int_triangle_ineq
%%%}}}

Para quaisquer $a,b$ inteiros,
$$
\abs {a + b} \leq \abs a + \abs b.
$$

\proof.
Sejam $a,b$ inteiros.
Logo (\reftag[int_triangle_ineq_details])
\math
-\abs a \leq a \leq \abs a\phantom. \\
-\abs b \leq b \leq \abs b. \\
\endmath
Logo (\reftag[int_triangle_ineq_details]) $-\abs a -\abs b \leq a + b \leq \abs a + \abs b$.\newline
Logo (\reftag[int_triangle_ineq_details]) $-(\abs a + \abs b) \leq a + b \leq \abs a + \abs b$.\newline
Logo (\reftag[int_triangle_ineq_details]) $\abs{a + b} \leq \abs a + \abs b$.

%%}}}

%%{{{ x: int_triangle_ineq_details 
\exercise.
%%%{{{ meta 
\label int_triangle_ineq_details 
%%%}}}

Justifique em detalhe cada \wq{logo} da demonstração do \ref[int_triangle_ineq].

%%}}}

%%{{{ x: int_abs_eq_abs 
\exercise.
%%%{{{ meta 
\label int_abs_eq_abs
%%%}}}

Sejam $a,b$ inteiros.  Demonstre:
$\abs a = \abs b \implies a = b \mlor a = -b$.

%%}}}

%%{{{ x: int_abs_of_diff 
\exercise.
%%%{{{ meta 
\label int_abs_of_diff
%%%}}}

Sejam $a,b$ inteiros.  Demonstre:
$\abs {\abs a - \abs b} \leq \abs {a - b} \leq \abs a + \abs b$.

%%}}}

%%{{{ x: int_abs_of_prod 
\exercise multiplicatividade.
%%%{{{ meta 
\label int_abs_of_prod
%%%}}}

$\lforall {a,b} {\abs {ab} = \abs a \abs b}$.

%%}}}

\endsection
%%}}}

%%{{{ Unprovability and metatheorems 
\section Indemonstrabilidade e metateoremas.
%%%{{{ meta 
\label Unprovability_and_metatheorems
%%%}}}

%%{{{ Why not try harder 
\note Por que desistimos de demonstrá-la?.
%%%{{{ meta 
%%%}}}

Se a gente tentar demonstrar uma proposição a partir duns axiomas
e não conseguir produzir uma demonstração correta, podemos concluir
que tal proposição é indemonstrável?
Não necessariamente.  Nosso insucesso não garanta que não vai chegar
daqui uns dias um matemático que vai pensar em algo que nós não conseguimos
pensar ainda.
Enquanto demonstrar ou refutar uma proposição, se trata duma \dterm{questão aberta}.
Mesmo assim, em certos casos podemos sim demonstrar que ninguém nunca vai conseguir
nem demonstrar nem refutar uma certa proposição.
\eop
Considere como exemplo a proposição $0 \neq 1$.
Podemos realmente \emph{demonstrar} a \emph{indemonstrabilidade da proposição $0 \neq 1$ a partir dos axiomas anteriores}.
Isso se trata na verdade duma \dterm{metademonstração}, já que é uma demonstração
sobre demonstrações sobre inteiros.
Efetivamente podemos demonstrar a (meta)proposição:
\emph{não existe demonstração de $0 \neq 1$ a partir dos axiomas anteriores}.
Podemos também demonstrar a \emph{irrefutabilidade da $0 \neq 1$ a partir
dos mesmos axiomas}, ou seja, a indemonstrabilidade da sua negação.
Essas duas informações juntas fazem tal proposição ser \dterm{independente}
dos axiomas anteriores: os axiomas não determinam sua vericidade, ou seja
tanto a $0 \neq 1$ quanto a sua negação são \dterm{compatíveis} com os axiomas
que trabalhávamos no momento.
\eop
Talvez numa primeira lida isso parece muito louco.
Como demonstrar que algo é indemonstrável?
Na verdade a idéia é bem simples:
basta fazer duas coisas:
(i) Construir um mundo onde todos os axiomas são válidos (precisamos verificar isso), e onde nossa proposição também é.
(Isso significa que nossa proposição é \emph{compatível} com tais axiomas.)
(ii) Construir um mundo onde todos os axiomas são válidos e onde nossa proposição não é.
(Isso significa que a negação da nossa proposição também é compatível com tais axiomas.)
Se alguém chegar alegando que conseguiu demonstrar tal demonstração, sabemos que sua suposta demonstração seria errada pois a usando poderiamos inferir que a proposição deveria ser válida no mundo do (ii), que é impossível.
Similarmente, se alguém afirmar que conseguiu refutar a mesma proposição, com certeza não conseguiu, pois tal suposta refutação geraria uma contradição graças ao mundo do (i).
Concluimos então que ninguém pode nem demonstrar nem refutar tal proposição a partir dos axiomas.

%%}}}

%%{{{ The unprovability of 0 ≠ 1 
\note A indemonstrabilidade de $0 \neq 1$.
%%%{{{ meta 
%%%}}}

Mas o que mesmo significa \emph{construir um mundo para o
$\sset \ints {0, 1, +, -, \ntimes, \Pos}$?}
Simplesmente interpretar cada um dos seus componentes, em forma compatível
com sua tipágem.
E se todos os axiomas da especificação são válidos quando os interpretamos nesse mundo,
o chamamos de \dterm{modelo} (ou \dterm{implementação}) da especificação.\foot
\toof
Para nosso exemplo precisamos decidir:
qual colecção de objetos vai servir o papel de $\ints$;
qual objeto deles vai ser o $0$;
qual objeto deles vai ser o $1$;
quais vão ser as operações $+,-,\ntimes$; e
qual vai ser o predicado $\Pos$
(quais dos nossos \dq{inteiros} vão ser chamados de \dq{positivos}).
\eop
Agora se a gente construir um mundo de
$$
\sset \ints {0, 1, +, -, \ntimes, \Pos}
$$
onde todos os axiomas até agora são válidos, mas onde $0 \neq 1$ não é,
seria uma garantia que não há tal demonstração e logo não faz sentido
continuar pensando em achar uma, e portanto vamos adicioná-la como axioma,
já que é algo fundamental para os inteiros que queremos axiomatizar aqui.
\eop
Eu deixo esse papel de construir tal mundo para
ti (\ref[unprovability_of_nontriviality_of_ints]).

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: Z-NZD_iff_Z-MCanL 
\problem NZD \vs MCan.
%%%{{{ meta 
\label Z-NZD_iff_Z-MCanL
%%%}}}

No texto escolhi adicionar como axioma a lei de não zerodivisores~\mref[Z-NZD]
e demonstramos como teorema a lei de $(\cdot)$-cancelamento.
Demonstre que o caminho contrário também é possivel, estabelecendo assim
a equivalência das duas proposições a partir dos axiomas anteriores.

%%}}}

%%{{{ prob: int_order_as_primitive 
\problem Ordem como primitiva.
%%%{{{ meta 
\label int_order_as_primitive
%%%}}}

Aqui escolhemos tratar a noção $\Pos$ de positividade como primitiva,
e definimos a ordem $(<)$ em termos de $\Pos$.
Faça tudo que precisa para mostrar que o outro caminho é equivalente.

\hint
Começa com o
$$
\sset \ints {0,1,+,-,\ntimes,<}
$$
estipulando as proposições do \ref[int_lt_axioms_as_theorems] como axiomas.
Defina a $\Pos$, e demonstre suas leis como teoremas.

%%}}}

%%{{{ prob: unprovability_of_nontriviality_of_ints 
\problem A indemonstrabilidade da não trivialidade dos inteiros.
%%%{{{ meta 
\label unprovability_of_nontriviality_of_ints
%%%}}}

Mostre que não tem como demonstrar $0 \neq 1$ pelos axiomas da \reffull[int_spec_3].

%%}}}

%%{{{ prob: unprovability_of_nozerodivisors_of_ints 
\problem A indemonstrabilidade da não zerodivisores dos inteiros.
%%%{{{ meta 
\label unprovability_of_nozerodivisors_of_ints
%%%}}}

Mostre que não tem como demonstrar a~\mref[Z-NZD] pelos axiomas da~\reffull[int_spec_1].

%%}}}

%%{{{ prob: nontriviality_implies_zero_neq_one 
\problem.
%%%{{{ meta 
\label unprovability_of_nontriviality_of_ints
%%%}}}

Retire o $0 \neq 1$ dos axiomas, e no seu lugar adicione a proposição
superficialmente mais fraca:
\mathcol
\cexists {u,v} {u \neq v}  \stag[Z-NTriv] \\
\endmathcol
Demonstre $0 \neq 1$.

%%}}}

\endproblems
%%}}}

%%{{{ Wishlist_for_ints 
\section Wishlist.
%%%{{{ meta 
\label Wishlist_for_ints
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Estamos quase lá.  Falta adicionar um axioma na nossa especificação para
finalmente encerrar a sua elaboração e começar desfrutar teoremas
da teoria dos inteiros.
Mas vamos tentar fazer um \emph{wishlist} do que desejamos conseguir.
Queremos:
\elist:
\li: (diversas versões de) indução;
\li: que os conjuntos de inteiros que são inferiormente cotados são \emph{bem ordenados};
\li: divisão (de Euclides);
\li: sistemas posicionais de numerais;
\li: mdc, mmc, e algoritmos para achá-los;
\li: teorema binomial;
\li: fatoração e teorema fundamental da aritmética;
\li: infinidade de primos (irredutíveis);
\endelist
Assim que conseguir tudo isso continuaremos para elaborar aritmética modular
e umas das suas aplicações, incluindo criptografia e assinaturas digitais.

%%}}}

\endsection
%%}}}

%%{{{ The_wellordering_principle_for_ints 
\section O princípio da boa ordem.
%%%{{{ meta 
\label The_wellordering_principle_for_ints
%%%}}}

%%{{{ df: int_woset 
\definition conjunto bem ordenado.
%%%{{{ meta 
%%%}}}

Seja $W$ um conjunto de inteiros.
Chamamos o $W$ de \dterm{bem ordenado} sse qualquer subconjunto habitado de $W$ possui mínimo.
Em símbolos:
\math
\text{$W$ é bem ordenado}
\defiff
\lforall {H \subset W} {\text{$H$ habitado} \implies \text{$H$ possui mínimo}}.
\endmath

%%}}}

%%{{{ spec: int_spec_5 (5/5) 
\specification Os inteiros (5/5).
%%%{{{ meta 
\label int_spec_5
\indexes
    * PBO    see: princípio da boa ordem
    ;;
\defines
    * princípio!da boa ordem
    ;;
%%%}}}

Estipulamos o princípio da boa ordem como último axioma:
\math
\text{O conjunto dos inteiros positivos é bem ordenado.}  \stag[Z-WOP]
\endmath

%%}}}

%%{{{ thm: no_int_between_0_and_1 
\theorem.
%%%{{{ meta 
\label no_int_between_0_and_1
%%%}}}

Não existe inteiro $k$ tal que\/ $0 < k < 1$.

\proof.
Suponha que existe inteiro $k$ tal que $0 < k < 1$.
Preciso chegar numa contradição.
Pela hipótese, o conjunto $C = \setst {c\in\ints} {0 < c < 1}$
de todos os tais inteiros é habitado (pelo menos pelo $k$).
Logo, pelo PBO, seja $m = \min C$ o menor membro de $C$.
Ou seja, sobre o $m$ sabemos que:
(a) $0 < m < 1$;
(b) para todo $c \in C$, $m \leq c$.
Eu vou achar um outro membro de $C$ que é ainda menor que o $m$,
assim contradizendo a escolha de $m$.
Esse membro é o $m^2$.
Basta demonstrar que: (i) $m^2 \in C$; (ii) $m^2 < m$.
Como $0 < m < 1$ (pela (a)), logo multiplicando tudo por $m$ temos
$0m < mm < 1m$, ou seja, $0 < m^2 < m$, que já nos dá o (ii).
Mas $m < 1$ e logo $0 < m^2 < m < 1$.
Como $0 < m^2 < 1$, consegui o (i): $m^2 \in C$.
Chegamos assim numa contradição, pois $m$ foi escolhido para
ser o menor membro de $C$.

%%}}}

%%{{{ cor: no_int_between_two_consecutive_ints 
\corollary.
%%%{{{ meta 
\label no_int_between_two_consecutive_ints
%%%}}}

Para todo inteiro $u$, não existe inteiro $k$ tal que\/ $u < k < u+1$.

\proof.
Tu demonstrarás isso agora no~\ref[no_int_between_two_consecutive_ints_proof].

%%}}}

%%{{{ x: no_int_between_two_consecutive_ints_proof 
\exercise.
%%%{{{ meta 
\label no_int_between_two_consecutive_ints_proof
%%%}}}

Demonstre o \ref[no_int_between_two_consecutive_ints].

\hint
É só \dq{shiftar} o \ref[no_int_between_0_and_1].

\hint
Supondo que há inteiro estritamente entre dois inteiros consecutivos,
forneça um inteiro entre $0$ e $1$.

\solution
Seja $u$ inteiro.
Suponha que já inteiros entre $u$ e $u+1$, e logo seja $k$ tal que $u < k < u+1$.
Logo $0 < k - u < 1$, contradizendo o \ref[no_int_between_0_and_1].

%%}}}

%%{{{ remark: int_WOP_alt 
\remark.
%%%{{{ meta 
\label int_WOP_alt
%%%}}}

Vamos supor que temos um conjunto de inteiros $A$ e, ainda mais,
sabemos que ele tem pelo menos um membro positivo.
A PBO não parece aplicável no $A$ já que ele pode possuir
membros não positivos, assim não sendo um subconjunto do $\Pos$.
Mesmo assim, seu subconjunto
$$
A_{>0} \defeq \setstt {a \in A} {$a$ positivo}
$$
é feito totalmente por positivos e é habitado, e logo
podemos sim usar o PBO para solicitar o menor membro de $A_{>0}$,
ou seja, podemos solicitar \emph{o menor membro positivo} de $A$.

%%}}}

%%{{{ x: shifted_WOP 
\exercise PBO shiftado.
%%%{{{ meta 
\label shifted_WOP
%%%}}}

Sejam $\ell$ inteiro e $A$ um conjunto de inteiros.
Demonstre que se $A$ possui membro $a \geq \ell$,
então o $\setst {a \in A} {\ell \leq a}$ possui mínimo.

%%}}}

%%{{{ remark: sets_as_predicates 
\remark Conjuntos como predicados.
%%%{{{ meta 
\label sets_as_predicates
%%%}}}

Já encontramos a idéia de identificar objetos do tipo
$\Set(\Int)$ (conjuntos de inteiros) por predicados unários nos intéiros
(objetos do tipo $\Int \to \Prop$).
Aplicamos a mesma idéia aqui, no sentido contrário para olhar
no princípio da boa ordem (até shiftado) numa versão formulada com predicados:

%%}}}

%%{{{ x: int_WOP_predicate_form 
\exercise PBO shiftado, predicate form.
%%%{{{ meta 
\label int_WOP_predicate_form
%%%}}}

Sejam $\phi \is \Int \to \Prop$ e $\ell \is \Int$ tais que
para algum $x \geq \ell$, $\phi(x)$.
Logo existe um inteiro $m$ tal que:
(i) $\phi(m)$;
(ii) $m \geq \ell$;
(iii) $\lforall {x < \ell} {\lnot \phi(x)}$.

%%}}}

%%{{{ Q: what more axioms would you add? 
\question.
%%%{{{ meta 
%%%}}}

Tu acha que deveriamos adicionar mais proposições como
axiomas na nossa especificação?
Cuidado: em geral, não queremos axiomas desnecessários:
se podemos demonstrar algo a partir dos axiomas já
estipulados, não faz sentido estipulá-lo como axioma também!

%%}}}

\endsection
%%}}}

%%{{{ Inductions_for_ints 
\section Induções.
%%%{{{ meta 
\label Inductions_for_ints
%%%}}}

%%{{{ thm: ints_principle_of_induction_set_form 
\theorem Indução (set form).
%%%{{{ meta 
\label ints_principle_of_induction_set_form
\defines
    * indução!para os inteiros positivos
    ;;
%XXX: This should not have to be repeated here,
%     but chapter-wise pdefs become null in appendices.
\pdefs
    \pdef Pos {\mathord{\mathrm{Pos}}}
    ;;
%%%}}}

Para qualquer conjunto de inteiros $P$,
se $1 \in P$ e $P$ é $({+}1)$-fechado,\foot
$\text{$P$ é $({+}1)$-fechado} \intiff \text{para todo $x \in P$, $x+1 \in P$}$
\toof
então $\Pos \subset P$, ou seja, todos os inteiros positivos pertencem ao $P$.

\sketch.
Caso contrário, existeriam \dq{contraexemplos}, ou seja,
inteiros positivos que não pertencem ao $P$.
Aplicamos a PBO para escolher $m$ como o menor deles
e olhamos para o inteiro anterior que deve ser positivo
e, ainda mais, menor que $m$, e logo pertence ao $P$,
algo que obrigaria $m$ também pertencer.

\proof.
Vou demonstrar que para todo $p$ positivo, $p \in P$.
Seja $p$ positivo.
Separo em casos:
\crproofcase {Caso $p \in P$.}
Imediato.
\crproofcase {Caso $p \nin P$.}
Basta achar uma contradição, eliminando este caso.
Seja
$$
C \defeq \setst {c \in \Pos} {c \nin P}
$$
o conjunto de todos os positivos que \dq{escaparam} do $P$.
Observe que pela sua construção, $C \subset \Pos$
e que pela hipótese do caso, $p \in C$.
Logo $C$ é habitado e logo (pela PBO) possui mínimo.
Logo seja $m$ o menor membro de $C$.
Ou seja: $m$ positivo, $m \nin P$, e para todo $x$ positivo com $x \nin P$, $x \leq m$.
Observe que $m \neq 1$, pois $1 \in P$.
Logo $m > 1$, já que $m$ é positivo.
Logo $m - 1$ é positivo também, e logo $m - 1 \in P$,
pela escolha de $m$ como mínimo positivo fora do $p$.
Logo $(m-1) + 1 \in P$, pois $p$ é $(+1)$-fechado.
Impossível, pois $(m-1) + 1 = m$ e $m \nin P$, chegando
assim na contradição desejada.

%%}}}

%%{{{ int_induction_how_to_use
\note Como usar.
%%%{{{ meta 
\label int_induction_how_to_use
\indexes
    * indução!como usar
    ;;
%%%}}}

As versões de indução que demonstramos aqui
são enunciadas em termos dum conjunto $P$ que,
satisfazendo certas condições, concluímos que deve
possuir como membros todos os objetos do nosso interesse.
\eop
Na sua versão original, os objetos do nosso interesse
são os inteiros positivos, e as condições que o $P$
precisa satisfazer são:
\mathcols 2
&1 \in P &
&\lforall x {x \in P \implies x + 1 \in P}
\endmathcols
Lembre que quando a gente queria introduzir a noção dos
inteiros positivos na nossa especificação, em vez de
introduzí-la como conjunto, optamos para considerar
como \emph{predicado unário}.
(Se não lembra: \ref[int_positivity_intro].)
Ainda mais, introduzimos logo apos açúcar sintáctico
que nos permitiu identificar as duas abordagens, escrevendo
$x \in \Pos$ e $\Pos \fa x$ sinonimamente.
\eop
Vamos aproveitar essa equivalência entre os dois conceitos
só que na direção contrária agora.  Vamos visualizar
o conjunto $P$ dos objetos do nosso interesse como
o predicado de <<ser interessado>>, e escrever $P \fa x$
em vez de $x \in P$, ou, voltando para o uso das metavariáveis gregas,
$\phi(x)$.
Visto assim, isso é uma ferramenta para demonstrar proposições
da forma
$$
\lforall {x \in \ints_{>0}} {\phi(x)}
$$
onde $\phi$ é uma propriedade que inteiros podem ter ou não, ou seja:
$$
\phi \is \Int \to \Prop.
$$
Para demonstrar então que todos os \emph{inteiros positivos}
gozam da propriedade $\phi$, basta demonstrar:
\mathcols 2
&\phi(1) &
&\lforall {x \geq 1} {\phi(x) \implies \phi(x+1)}. \\
\endmathcols

%%}}}

%%{{{ thm: ints_principle_of_induction_predicate_form 
\theorem Indução (predicate form).
%%%{{{ meta 
\label ints_principle_of_induction_predicate_form
\defines
    * indução!para os inteiros positivos
    ;;
%%%}}}

Seja $\phi$ qualquer predicado unário afirmável sobre inteiros, ou seja,
$\phi \is \Int \to \Prop$.
Suponha que:
\elist:
\li: $\phi(1)$;
\li: $\lforall x {\phi(x) \implies \phi(x+1)}$.
\endelist
Logo para todo inteiro positivo $p$, $\phi(p)$.

\proof Já demonstrado.
Basta só traduzir as afirmações sobre conjuntos da demonstração
do~\reftag[ints_principle_of_induction_set_form] para as correspondentes
sobre predicados: $x \in P$ por $\phi(x)$, etc.

%%}}}

%%{{{ x: no_int_between_0_and_1_by_induction 
\exercise.
%%%{{{ meta 
\label no_int_between_0_and_1_by_induction
%%%}}}

Demonstre o \ref[no_int_between_0_and_1] usando indução.

\hint
Nenhum inteiro negativo satisfaz $0 < m < 1$.
Então para demonstrar que nenhum inteiro fica estritamente entre $0$ e $1$, basta demonstrar
que todos os não-negativos $n$ satisfazem $n=0$ ou $n\geq 1$

\hint
Seja
$
\phi(n) \defiff \text{$n=0$ ou $n\geq1$}
$.

\hint
A base é trivial.

\hint
Para o passo indutivo, tomando um $k\in\nats$ tal que $\phi(k)$, separa tua prova
em dois casos, dependendo da razão que o $\phi(k)$ seja verdade.

%%}}}

%%{{{ cor: ints_shifted_induction 
\corollary Indução shiftada.
%%%{{{ meta 
\label ints_shifted_induction
%%%}}}

Para qualquer conjunto de inteiros $P$,
se $\ell \in P$ e $P$ é $({+}1)$-fechado,
então todos os inteiros $x$ tais que $x \geq \ell$
pertencem ao $P$.

\sketch.
Aplicamos o princípio da indução no conjunto
$$
P - \ell \defeq \setst {p - \ell} {p \in P}
$$
de todos os membros de $P$ \dq{shiftados} por $-\ell$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A versão seguinte, conhecida como \dq{indução forte}
não merece seu apelido.  A demonstramos como teorema
e logo não se trata de algo mais forte mesmo.
Mesmo assim, é muito mais natural e conveniente
em certos casos e logo faz sentido a destacar.

%%}}}

%%{{{ cor: int_strong_induction 
\corollary Indução forte.
%%%{{{ meta 
\label int_strong_induction
%%%}}}

Seja $P$ conjunto de inteiros.
Suponha
$$
\pforall x {
    \lforall {0 < i < x} {i \in P}
    \implies
    x \in P
    }.
$$
Logo todos os inteiros positivos pertencem ao $P$.\foot
O quantificador no \symq{$\pforall {0 < i < x}$} quantifica o $i$.
Ou seja, essa parte no que escrevi acima, \emph{desaçucarizando}, fica assim:
$\lforall {i} {0 < i < x \implies i \in P}$.
\toof

\proof.
Suponha que há inteiros positivos que não pertencem ao $P$.
Seja $m$ o menor deles (PBO).
Logo, para todo positivo $i < m$, $i \in P$.
Logo $m \in P$, e chegamos numa contradição.

%%}}}

%%{{{ int_induction_rule_of_inference 
\note Regra de inferência.
%%%{{{ meta 
\label int_induction_rule_of_inference
\indexes
    * regra!de inferência
    ;;
%%%}}}

Graças ao \ref[ints_principle_of_induction_predicate_form] podemos
enriquecer nosso sistema de demonstrações com a regra de inferência
seguinte:
$$
\PROOFmr {
     \A {\phi(1)}     \A {\lforall k {\phi(k) \implies \phi(k+1)}}
\I2---------------------------------------------------------------------- {Ind$_\phi$}
                     {\lforall {x > 1} {\phi(x)}}
}
$$
Essa corresponde à versão original; adaptá-la para as outras versões, é pra ti.

%%}}}

%%{{{ x: int_induction_rules_of_inference
\exercise.
%%%{{{ meta 
\label int_induction_rules_of_inference 
%%%}}}

Escreva como regras de inferência as variações de indução que encontramos (shifted e forte).

%%}}}

\endsection
%%}}}

%%{{{ Sums_and_products_lame_version 
\section Somatórios e produtórios iterativos.
%%%{{{ meta 
\label Sums_and_products_lame_version
%%%}}}

%%{{{ iterative_sum_and_product 
\note.
%%%{{{ meta 
\label iterative_sum_and_product
\defines
    * somatório iterativo
    * produtório iterativo
    * \Sum_{i=s}^t \tau(i))   -- o somatório $\tau(s) + \dotsb + \tau(t)$
    * \Prod_{i=s}^t \tau(i))  -- o produtório $\tau(s) \ntimes \dotsb \ntimes \tau(t)$
    ;;
%%%}}}

Sejam $s,t$ inteiros e $\tau(i)$ uma expressão em qual ocorre possivelmente a variável $i$.
Queremos definir a notação $\Sum_{i=s}^t\tau(i)$ para denotar a soma de todos os inteiros
denotados pelos termos $\tau(s), \dotsc, \tau(t)$, e similarmente a $\Prod_{i=s}^t\tau(i)$
para denotar o seu produto:
\mathcols 2
\Sum_{i=s}^t  \tau(i) &= \tau(s) + \dotsb + \tau(t) &
\Prod_{i=s}^t \tau(i) &= \tau(s) \ntimes \dotsb \ntimes \tau(t).
\intertext {Caso $s > t$ não temos nenhum termo para operar,
e logo se trata de somatório vazio e de produtório vazio respectivamente;
e precisamos pensar qual seria o valor correto para cada um desses casos:}
\Sum_{i=s}^t  \tau(i) &= \alert? &
\Prod_{i=s}^t \tau(i) &= \alert?
\intertext {Caso $s \leq t$ existem duas maneiras óbvias para definir
cada um deles, ambas recursivas:}
\Sum_{i=s}^t \tau(i) &\defeq \pathed {
\paren{\Sum_{i=s}^{t-1} \tau(i)} + \tau(t) \\
\pathween {\dots\orword\dots}
\tau(s) + \Sum_{i=s+1}^t \tau(i)
}
&
\Prod_{i=s}^t \tau(i) &\defeq \pathed {
\paren{\Prod_{i=s}^{t-1} \tau(i)} \ntimes \tau(t) \\
\pathween {\dots\orword\dots}
\tau(s) \ntimes \Prod_{i=s+1}^t \tau(i).\\
}
\endmathcols

%%}}}

%%{{{ df: iterative_sum_of_ints_def 
\definition Somatório iterativo.
%%%{{{ meta 
\label iterative_sum_of_ints_def
\defines
    * somatório iterativo
    * \Sum_{i=s}^t \tau(i))  -- o somatório $\tau(s) + \dotsb + \tau(t)$
    ;;
%%%}}}

Sejam $s,t$ inteiros e $\tau(i)$ uma expressão em qual ocorre possivelmente a variável $i$.
Definimos recursivamente:
\mathcol
\Sum_{i=s}^t \tau(i) &\defeq \cased {
\paren{\Sum_{i=s}^{t-1} \tau(i)} + \tau(t), & caso $s \leq t$; \\
0, & caso $s > t$. \\
}
\endmathcol

%%}}}

%%{{{ x: iterative_sum_of_ints_calc 
\exercise.
%%%{{{ meta 
\label iterative_sum_of_ints_calc
%%%}}}

Verifique que $\Sum_{i=1}^4 i = 10$, mostrando todos os passos do cálculo.

%%}}}

%%{{{ x: iterative_sum_of_ints_equiv 
\exercise.
%%%{{{ meta 
\label iterative_sum_of_ints_equiv
%%%}}}

Demonstre que a definição alternativa
\mathcol
\Sum_{i=s}^t \tau(i) &\defeq \cased {
\tau(s) + \Sum_{i=s+1}^t \tau(i), & caso $s \leq t$; \\
0, & caso $s > t$; \\
}
\endmathcol
é equivalente à \ref[iterative_sum_of_ints_def].

%%}}}

%%{{{ x: iterative_sum_of_ints_calc 
\exercise.
%%%{{{ meta 
\label iterative_sum_of_ints_calc
%%%}}}

Verifique que $\Sum_{i=1}^4 i = 10$, essa vez aplicando pelo menos uma
vez a \ref[iterative_sum_of_ints_def] e pelo menos uma vez a propriedade
do \ref[iterative_sum_of_ints_equiv], novamente mostrando todos os passos do cálculo.

%%}}}

%%{{{ x: iterative_sum_of_ints_intension 
\exercise.
%%%{{{ meta 
\label iterative_sum_of_ints_intension
%%%}}}

Já sabemos que não há diferença extensional entre as duas maneiras de definir somatórios.
Há diferença intensional?

%%}}}

%%{{{ Q: How would you define iterative products? 
\question.
%%%{{{ meta 
%%%}}}

Como definarias produtórios iterativos?
Verifique tua tentativa calculando um produtório curto como o $\Prod_{i=1}^3 i$
antes de continuar.

%%}}}

\spoiler

%%{{{ df: iterative_product_of_ints_def 
\definition Produtório iterativo.
%%%{{{ meta 
\label iterative_product_of_ints_def
\defines
    * produtório iterativo
    * \Prod_{i=s}^t \tau(i))  -- o produtório $\tau(s) \ntimes \dotsb \ntimes \tau(t)$
    ;;
%%%}}}

Sejam $s,t$ inteiros e $\tau(i)$ uma expressão em qual ocorre possivelmente a variável $i$.
Definimos recursivamente:
\mathcol
\Prod_{i=s}^t \tau(i) &\defeq \cased {
1, & caso $s > t$; \\
\paren{\Prod_{i=s}^{t-1} \tau(i)} \ntimes \tau(t), & caso $s \leq t$. \\
}
\endmathcol

%%}}}

%%{{{ x: iterative_product_of_ints_def 
\exercise Produtório iterativo.
%%%{{{ meta 
\label iterative_product_of_ints_def
\defines
    * produtório iterativo
    * \Prod_{i=s}^t \tau(i))  -- o produtório $\tau(s) \ntimes \dotsb \ntimes \tau(t)$
    ;;
%%%}}}

Obtenha os resultados correspondente aos exercícios~\reftag[iterative_sum_of_ints_equiv]
e~\reftag[iterative_sum_of_ints_intension].

\hint
Cuidado sobre o produtório vazio.

\solution
Definimos recursivamente:
\mathcol
\Prod_{i=s}^t \tau(i) &\defeq \cased {
1, & caso $s > t$; \\
\Prod_{i=s}^{t-1} \tau(i) \ntimes \tau(t), & caso $s \leq t$. \\
}
\endmathcol

%%}}}

%%{{{ x: distributivity_over_iterative_sum 
\exercise.
%%%{{{ meta 
\label distributivity_over_iterative_sum
%%%}}}

Adivinhe um lado direito interessante e demonstre:
$\Sum_{i=s}^t c\tau(i) = {?}$.

\hint
$\Sum_{i=s}^t c\tau(i) = c\Sum_{i=s}^t \tau(i)$.

%%}}}

%%{{{ x: iterative_sum_distributes_over_addition 
\exercise.
%%%{{{ meta 
\label iterative_sum_distributes_over_addition
%%%}}}

Mesma coisa:
$\Sum_{i=s}^t \paren{\tau(i) + \sigma(i)} = {?}$.

\hint
$\Sum_{i=s}^t \paren{\tau(i) + \sigma(i)} = \paren{\Sum_{i=s}^t \tau(i)} + \paren{\Sum_{i=s}^t \sigma(i)}$.

%%}}}

%%{{{ x: iterative_sum_split 
\exercise split.
%%%{{{ meta 
\label iterative_sum_split
%%%}}}

$\Sum_{i=s}^t \tau(i) = \Sum_{i=s}^{?} \tau(i) + \Sum_{i={?}}^t \tau(i)$.

\hint
Para qualquer $w$ tal que $s \leq w \leq t$, $\Sum_{i=s}^t \tau(i) = \Sum_{i=s}^{w-1} \tau(i) + \Sum_{i=w}^t \tau(i)$.

%%}}}

%%{{{ x: iterative_sum_index_shift 
\exercise index shift.
%%%{{{ meta 
\label iterative_sum_index_shift
%%%}}}

$\Sum_{i=s}^t \tau(i) = \Sum_{i={?}}^{?} \tau(i-d)$.

\hint
$\Sum_{i=s}^t \tau(i) = \Sum_{i=s+d}^{t+d} \tau(i-d)$.

%%}}}

%%{{{ x: iterative_sum_count 
\exercise.
%%%{{{ meta 
\label iterative_sum_count
%%%}}}

$\Sum_{i=s}^t 1 = {?}$

\hint
$
\Sum_{i=s}^t 1 = \cased {
t - s + 1, & caso $s \leq t$; \\
0,         & caso $s > t$.
}
$

%%}}}

%%{{{ x: distributivity_over_iterative_product 
\exercise.
%%%{{{ meta 
\label distributivity_over_iterative_product
%%%}}}

$\Prod_{i=s}^t c\tau(i) = {?}$.

\hint
$\Prod_{i=s}^t c\tau(i) = c^n\Prod_{i=s}^t \tau(i)$,
onde $n = \cased {
t - s + 1, & caso $s \leq t$; \\
0,         & caso $s > t$.
}$

%%}}}

%%{{{ x: iterative_product_distributes_over_multiplication 
\exercise.
%%%{{{ meta 
\label iterative_product_distributes_over_multiplication
%%%}}}

$\Prod_{i=s}^t \paren{\tau(i) \ntimes \sigma(i)} = {?}$.

\hint
$\Prod_{i=s}^t \paren{\tau(i) \ntimes \sigma(i)} = \paren{\Prod_{i=s}^t \tau(i)} \ntimes \paren{\Prod_{i=s}^t \sigma(i)}$.

%%}}}

%%{{{ x: iterative_product_split 
\exercise split.
%%%{{{ meta 
\label iterative_product_split
%%%}}}

$\Prod_{i=s}^t \tau(i) = \Prod_{i=s}^{?} \tau(i) + \Prod_{i={?}}^t \tau(i)$.

\hint
Para qualquer $w$ tal que $s \leq w \leq t$, $\Prod_{i=s}^t \tau(i) = \Prod_{i=s}^{w-1} \tau(i) + \Prod_{i=w}^t \tau(i)$.

%%}}}

%%{{{ x: iterative_product_index_shift 
\exercise index shift.
%%%{{{ meta 
\label iterative_product_index_shift
%%%}}}

$\Prod_{i=s}^t \tau(i) = \Prod_{i={?}}^{?} \tau(i-d)$.

\hint
$\Prod_{i=s}^t \tau(i) = \Prod_{i=s+d}^{t+d} \tau(i-d)$.

%%}}}

%%{{{ x: iterative_product_exp 
\exercise.
%%%{{{ meta 
\label iterative_product_exp
%%%}}}

$\Prod_{i=s}^t c^{\tau(i)} = {?}$

\hint
$\Prod_{i=s}^t c^{\tau(i)} = c^{\Sum_{i=s}^t \tau(i)}$.

%%}}}

%%{{{ complaint: sum_and_product_doing_too_much 
\complaint.
%%%{{{ meta 
\label sum_and_product_doing_too_much
%%%}}}

Os \symq{$\Sum$} e \symq{$\Prod$} que definimos aqui estão fazendo uma mistura
de trabalhos e isso não é uma idéia boa: eles mesmo geram uma lista de termos
simultaneamente somando e multiplicando seus termos.
Isso dificulta tanto o trabalho de definir e manipular certos objetos,
quanto o trabalho de demonstrar teoremas sobre eles.
Seria melhor separar o trabalho de gerar uma lista (a partir duma
expressão-padrão, um início, e um fim) e o trabalho de operar em forma
generalizada nos seus componentes.  Faremos isso no \ref[Recursion_induction].

%%}}}

%%{{{ x: gauss_sum 
\exercise Somatório de Gauss.
%%%{{{ meta 
\label gauss_sum
\credits
    * Gauss : somatório
    ;;
%%%}}}

Demonstre que para todo inteiro $n\geq 0$,
$$
2 \Sum_{i=1}^n i = n (n+1).
$$

\hint
Indução.

\solution
Por indução.
Primeiramente demonstramos a \proofpart {base:}
$$
2 \Sum_{i=1}^0 i \askeq 0 (0+1).
$$
Calculamos:
\math
2 \Sum_{i=1}^0 i
= 2 \ntimes 0
= 0
= 0 (0+1).
\endmath
\proofpart {Passo indutivo.}
Seja $k \geq 0$ tal que
$$
2 \Sum_{i=1}^k i = k (k+1).  \tag{H.I.}
$$
Calculamos:
\compute
2 \Suml_{i=1}^{k+1} i
&= 2\paren{\paren{\Suml_{i=1}^k i} + (k+1)} \\
&= 2\paren{\Suml_{i=1}^k i} + 2(k+1) \\
&= k(k+1) + 2(k+1) \by {pela H.I.} \\
&= (k+2)(k+1) \\
&= (k+1)(k+2).
\endcompute

%%}}}

%%{{{ x: sum_of_squares_formula 
\exercise.
%%%{{{ meta 
\label sum_of_squares_formula
%%%}}}

Demonstre que para todo $n \geq 0$,
$$
6 \Sum_{i=1}^n i^2
= 2 n^3 + 3 n^2 + n.
$$

%%}}}

%%{{{ x: sum_of_cubes_eq_square_of_sum 
\exercise.
%%%{{{ meta 
\label sum_of_cubes_eq_square_of_sum
%%%}}}

Demonstre que para todo inteiro $n$,
\mathcol
\Sum_{i=1}^n i^3 &= \paren{\Sum_{i=1}^n i}^2 \\
\text{ou seja,}\qquad
1^3 + 2^3 + \dotsb + n^3 &= \paren{ 1 + 2 + \dotsb + n }^2.
\endmathcol

%%}}}

%%{{{ x: sum_of_threes_and_fives 
\exercise.
%%%{{{ meta 
\label sum_of_threes_and_fives
%%%}}}

Qualquer número inteiro positivo $n \geq 8$ pode ser escrito
como somatório de $3$'s e $5$'s.

%%}}}

%%{{{ x: 8(1 + ⋯ + n) ≟ (2n + 1)² 
\exercise.
%%%{{{ meta 
%%%}}}

Seja
$$
\phi(n) \defiff 8(1 + 2 + \dotsb + n) = \paren{2n + 1}^2.
$$
\tlist:
\li (i):
Demonstre que para todo $k \geq 0$, se $\phi(k)$ então $\phi(k+1)$.
\li (ii):
Critique a oração:
\emph{\wq{Logo, por indução, temos que para todo $n \geq 0$, $\phi(n)$.}}.
\li (iii):
Mudando apenas o \sq{$=$} para \sq{$>$} ou \sq{$<$}, defina um outro
predicado $\psi(\dhole)$ tal que para todo $n \geq 0$, $\psi(n)$
(demonstre por indução).
\endtlist

%%}}}

%%{{{ x fibonacci 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n \geq 0$,
$$
\Sum_{i=0}^n F_i = F_{n+2} - 1,
$$
onde, novamente, $F_n$ o $n$-ésimo número Fibonacci.

%%}}}

%%{{{ x fibonacci 2 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n \geq 0$,
$$
\Sum_{i=1}^n F_i^2 = F_n F_{n+1},
$$
onde $F_n$ o $n$-ésimo número Fibonacci.

%%}}}

\endsection
%%}}}

%%{{{ Binomial_theorem 
\section Binomial e seus coeficientes.
%%%{{{ meta 
\label Binomial_theorem
%%%}}}

%%{{{ x: binomial_theorem_for_2 
\exercise.
%%%{{{ meta 
\label binomial_theorem_for_2
%%%}}}

Demonstre que para quaisquer inteiros $x,y$,
$(x+y)^2 = x^2 + 2xy + y^2$.

%%}}}

%%{{{ x: binomial_theorem_for_3 
\exercise.
%%%{{{ meta 
\label binomial_theorem_for_3
%%%}}}

Demonstre que para quaisquer inteiros $x,y$,
$(x+y)^3 = x^3 + 3x^2y + 3xy^2 + y^3$.

\hint
Use o que tu acabou de demonstrar sobre o $(x+y)^2$, no \ref[binomial_theorem_for_2].

%%}}}

%%{{{ binomial theorem discussion 
\note Binomial.
%%%{{{ meta 
%%%}}}

Nosso objetivo agora é generalizar para responder ao
\mathcol
(x+y)^n &= ?
\intertext{Facilmente percebemos que}
(x+y)^n &= x^n + \dotsb + y^n
\intertext{mas esse uso de \sq{${}\dotsb{}$} é tão abusivo que parece
até piada considerar como progresso.  Podemos melhorar pouco, percebendo
que no final das contas nossa resposta deve ser um somatório de termos
$x^iy^j$.  Por exemplo, no \ref[binomial_theorem_for_3] achamos}
(x+y)^3
&= xxx + xxy + xyx + yxx + xyy + yxy + yyx + yyy \\
&= x^3y^0 + x^2y + x^2y + x^2y + xy^2 + xy^2 + xy^2 + x^0y^3.
\intertext{O objetivo é \emph{achar os coeficientes} de cada termo desses:}
&= \mubrace {x^3y^0} 1
 + \mubrace {x^2y + x^2y + x^2y} 3
 + \mubrace {xy^2 + xy^2 + xy^2} 3
 + \mubrace {x^0y^3} 1 \\
&= 1\,x^3y^0 + 3\,x^2y + 3\,xy^2 + 1\,x^0y^3.
\intertext{Observe também como podemos melhorar os $i,j$ no $x^iy^j$:
temos $i+j = n$, e logo podemos escrever tudo em termos de apenas uma variável
(vou escolher a \sq{$r$}): $x^{n-r}y^r$.
Sabemos então que $(x+y)^n$ pode ser escrito como um somatório de termos $x^{n-r}y^r$
e o desafio é achar para um deles quantas vezes precisamos somá-lo.
Em outras palavras, procuramos o coeficiente de tal termo no somatório.
Vamos denotar por $\binom n r$ o coeficiente do termo $x^{n-r}y^r$:}
(x + y)^n
&= \binom n 0 x^n + \binom n 1 x^{n-1}y + \dotsb + \binom n {n-1} xy^{n-1} + \binom n n y^n \\
&= \Sum_{r=0}^n \binom n r x^{n-r}y^r.
\endmathcol

%%}}}

%%{{{ thm: binomial_theorem 
\theorem Teorema binomial.
%%%{{{ meta 
\label binomial_theorem
\headerize
\indexes
    * binomial!teorema    see: teorema
    * teorema!binomial
    ;;
%%%}}}

Para qualquer $n \geq 0$ e qualquer $0 \leq i \leq n$, temos
$$
\binom n r = \comb n r.
$$

\preproof Argumentação combinatorial.
Queremos achar quantas vezes o termo $x^{n-r}y^r$ aparece na expansão do binomial.
Escrevendo
$$
(x+y)^n = \tubrace {(x+y)(x+y)\dotsb(x+y)} {$n$ vezes}
$$
observamos que para cada das $\comb n r$ maneiras de escolher $r$ dos termos acima,
corresponde um termo $x^{n-r}y^r$:
\dq{escolha quais dos termos desse produtório vão oferecer seus $y$'s
(o resto dos termos oferecerá seu $x$)}.
Isso justifica o $\binom n r = \comb n r$.
(Veja o~\ref[binomial_theorem_for_7_combinations] para um exemplo.)

\proof.
Por indução.
\crproofpart {Base.}
Calculamos:
\compute
(x+y)^0 &= 1; \noby \\
\Sum_{r=0}^0 \comb 0 r x^{n-r}y^r &= \comb 0 0 x^{0-0}y^0 = 1 \ntimes 1 \ntimes 1 = 1.
\endcompute
\proofpart {Passo indutivo.}
Seja $k$ tal que $(x+y)^k = \Sum_{r=0}^k \comb k r x^{k-r}y^k$\fact{HI}.
Calculamos:
\compute
(x+y)^{k+1}
&= (x+y) (x+y)^k \noby \\
&= x(x+y)^k y(x+y)^k \\
&\dotseq \Sum_{r=0}^{k+1} \comb {k+1} r x^{k-(r-1)}y^r.
\endcompute
Onde o \sq{$\dotseq$} é trabalho teu (\ref[binomial_theorem_proof_by_induction_exercise]).

%%}}}

%%{{{ eg: binomial_theorem_for_7_combinations 
\example.
%%%{{{ meta 
\label binomial_theorem_for_7_combinations
%%%}}}

Para $n \asseq 7$ e $r \asseq 4$, a escolha indicada pelos termos sublinhados no
$$
\let\ul=\underline
(x+y)^7 = (x+y) \, \ul{(x+y)} \, (x+y) \, \ul{(x+y)} \, \ul{(x+y)} \, (x+y) \, \ul {(x+y)}
$$
corresponde ao termo $xyxyyxy = x^3y^4$, e cada diferente escolha das $\comb 7 4$
corresponde ao mesmo termo mas com uma maneira diferente para formá-lo:
$$
\tubrace
    {xxxyyyy,~xxyxyyy,~xxyyxyy,~xxyyyxy,~xxyyyyx,~xyxxyyy,~\dotsc,~yyxyxx,~yyyyxxx}
    {$\comb 7 4 \,=\, 35$ strings feitos por $3$ $x$'s e $4$ $y$'s}.
$$

%%}}}

%%{{{ x: binomial_theorem_proof_by_induction_exercise 
\exercise Teorema binomial: por indução.
%%%{{{ meta 
\label binomial_theorem_proof_by_induction_exercise
\indexes
    * teorema!binomial!por indução
    ;;
%%%}}}

Demonstre o \ref[binomial_theorem].

\hint
Aplique a hipótese indutiva.

\hint
$$
x(x+y)^k y(x+y)^k
= x\Sum_{r=0}^k \comb k r x^{k-r} y^r
+ y\Sum_{r=0}^k \comb k r x^{k-r} y^r.
$$

\hint
O $x$ sendo distribuido no primeiro somatório aumenta $+1$ no expoente de $x$,
e similarmente o $y$ no segundo aumenta $+1$ no expoente de $y$.

\hint
$$
  x\Sum_{r=0}^k \comb k r x^{k-r} y^r
+ y\Sum_{r=0}^k \comb k r x^{k-r} y^r
=  \Sum_{r=0}^k \comb k r x^{(k-r)+1} y^r
+  \Sum_{r=0}^k \comb k r x^{k-r} y^{r+1}.
$$

\hint
Separe o primeiro termo do primeiro somatório e o último termo do segundo.

\hint
\longmath
  \Sum_{r=0}^k \comb k r x^{(k-r)+1}y^r
+ \Sum_{r=0}^k \comb k r x^{k-r}y^{r+1} \\
= x^{k+1}
+ \Sum_{r=1}^k     \comb k r x^{(k-r)+1}y^r
+ \Sum_{r=0}^{k-1} \comb k r x^{k-r}y^{r+1}
+ y^{k+1}.
\endlongmath

\hint
Mexa com os índices utilizados nos dois somatórios para conseguir
que ambos começam e terminam no mesmo $r$.

\solution
Calculamos:
\widecompute
(x+y)^{k+1} \\
&= (x+y) (x+y)^k \\
&= x(x+y)^k + y(x+y)^k \\
&= x\paren{\Sum_{r=0}^k \comb k r x^{k-r} y^r}
 + y\paren{\Sum_{r=0}^k \comb k r x^{k-r} y^r} \\
&=  \paren{\Sum_{r=0}^k \comb k r x^{(k-r)+1} y^r}
 +  \paren{\Sum_{r=0}^k \comb k r x^{k-r}     y^{r+1}} \\
&= x^{k+1}
 + \paren{\Sum_{r=1}^k     \comb k r x^{(k-r)+1} y^r}
 + \paren{\Sum_{r=0}^{k-1} \comb k r x^{k-r}     y^{r+1}}
 + y^{k+1} \\
&= x^{k+1}
 + \paren{\Sum_{r=1}^k \comb k r     x^{(k-r)+1} y^r}
 + \paren{\Sum_{r=1}^k \comb k {r-1} x^{k-(r-1)} y^{(r-1)+1}}
 + y^{k+1} \\
&= x^{k+1}
 + \paren{\Sum_{r=1}^k \comb k r     x^{k-(r-1)} y^r}
 + \paren{\Sum_{r=1}^k \comb k {r-1} x^{k-(r-1)} y^r}
 + y^{k+1} \\
&= x^{k+1}
 + \paren{\Sum_{r=1}^k (\comb k r
                     + \comb k {r-1}) x^{k-(r-1)} y^r}
 + y^{k+1} \\
&= x^{k+1}
 + \paren{\Sum_{r=1}^k \comb {k+1} r x^{k-(r-1)} y^r}
 + y^{k+1} \\
&= \comb {k+1} 0 x^{k+1}
 + \paren{\Sum_{r=1}^k \comb {k+1} r x^{k-(r-1)} y^r}
 + \comb {k+1} {k+1} y^{k+1} \\
&= \comb {k+1} 0 x^{(k+1)-0} y^0
 + \paren{\Sum_{r=1}^k \comb {k+1} r x^{(k+1)-r} y^r}
 + \comb {k+1} {k+1} x^{(k+1)-(k+1)} \rlap{$y^{k+1}$} \\
&= \Sum_{r=0}^{k+1} \comb {k+1} r x^{(k+1)-r} y^r.
\endwidecompute

%%}}}

\endsection
%%}}}

%%{{{ Euclid's division lemma 
\section O lemma da divisão de Euclides.
%%%{{{ meta 
%%%}}}

%%{{{ lemma: euclidean_division 
\lemma Lemma da Divisão de Euclides.
%%%{{{ meta 
\headerize
\label euclidean_division
\credits
    * Euclid : lemma da divisão
    ;;
\indexes
    * divisão!lemma
    * divisão    seealso: Euclides
    ;;
%%%}}}

Dados inteiros $a$ e $b$ com $b \neq 0$,
existem inteiros $q$ e $r$ tais que:
$$
a = bq + r,
\qquad
0 \leq r < \abs b.
\mtag[euclidean_div=EucDiv]
$$
Além disso, os $q$ e $r$ são \emph{determinados unicamente}.

\sketch.
\proofpart {Existência:}
Considera a seqüência infinita:
$$
\ldots,~
a - 3b,~
a - 2b,~
a -  b,~
a     ,~
a +  b,~
a + 2b,~
a + 3b,~
\ldots
$$
Verifique que ela tem elementos não-negativos e,
aplicando a PBO, considere o menor deles.
\proofpart {Unicidade:}
Suponha que $a=bq+r=bq'+r'$
para alguns $q,r,q',r'\in\ints$ tais que satisfazem as restricções
$0 \leq r < \abs b$ e $0 \leq r' < \abs b$.
Basta mostrar que $r=r'$ e $q=q'$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por causa dessa existência e unicidade, podemos definir:

%%}}}

%%{{{ df: division 
\definition Divisão.
%%%{{{ meta 
\label division
\defines
    * divisão
    * quociente!divisão
    * resto!divisão
    * \quot(~a,~b)  -- o quociente de $a$ dividido por $b$
    * \rem(~a,~b)   -- o resto de $a$ dividido por $b$
    ;;
%%%}}}

Dados $a,b\in\ints$ com $b>0$, são determinados os inteiros $q$ e $r$
que satisfazem a~\mref[euclidean_div].
Chamamos o $q$ de \dterm{quociente} e o $r$ de
\dterm{resto} da divisão de $a$ por $b$ e os denotamos por
$\quot(a,b)$ e $\rem(a,b)$ respectivamente:
$$
a = b \stimes \quot(a,b) + \rem(a,b)
\qquad
0\leq \rem(a,b) < \abs b.
$$

%%}}}

%%{{{ x: n_divides_exactly_one_of_n_consecutive_integers 
\exercise.
%%%{{{ meta 
\label n_divides_exactly_one_of_n_consecutive_integers
%%%}}}

Seja $n$ positivo.  Se $a_0,a_1,\dotsc,a_{n-1}$ são $n$ inteiros consecutivos,
então $n \divides a_i$ para um único $i\in\set{0,\dots,n-1}$.

\hint
Seja $a=a_0$.  Assim $a_i = a + i$.

\hint
Divida o $a$ por $n$ e, olhando para o resto $r$,
ache o certo $i$ tal que $n \divides a_i$.

\hint
Para a unicidade, ache o resto da divisão de $n$ pelo arbitrário $a_j$.

%%}}}

%%{{{ x: 3|n or 3|n²-1 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $n\in\ints$, se $3 \ndivides n$
então $3 \divides n^2 - 1$.

\hint
Ou fatore o $n^2-1$ e use o~\ref[n_divides_exactly_one_of_n_consecutive_integers],
ou considere os casos possíveis dependendo dos restos da divisão de $n$ por $3$.

%%}}}

%%{{{ x: negative_remainders 
\exercise.
%%%{{{ meta 
\label negative_remainders
%%%}}}

Demonstre que dado qualquer inteiro $a$, existem únicos inteiros $q$ e $r$
tais que $a = 3q + r$ e $-1\leq r \leq 1$.

\hint
Use a divisão de Euclides.

%%}}}

\endsection
%%}}}

%%{{{ Expansions_and_positional_systems 
\section Expansão e sistemas posicionais.
%%%{{{ meta 
\label Expansions_and_positional_systems
%%%}}}

%%{{{ intro 
\secintro
Até agora temos usado os numerais que conhecemos desde crianças
para referir aos números inteiros.  Considerei dado que tu já
sabes todos esses (infinitos!)~nomes de números, e que tu entendes
como interpretar e \dq{como funciona} esse sistema de numerais.
Mas suponha que um ser alienígena que usa um sistema de numerais
completamente diferente do nosso acha difícil acreditar que nosso
sistema funciona mesmo:  \utter{Como vós sabeis\foot
os alienígenas conjugam até no segundo plural, pelo jeito\dots
\toof
que não tem números inteiros sem numeral?}
Nesta secção estudamos esse sistema, respondemos nessa e em mais
perguntas, e encontramos outros sistemas posicionais de numerais.
%%}}}

%%{{{ Symbols for digits 
\note Símbolos para os dígitos e separadores de casas.
%%%{{{ meta 
%%%}}}

Para os sistemas posicionais com base $b \leq 10$ usamos os símbolos
$$
\mathtt 0, \mathtt 1, \mathtt 2, \mathtt 3, \mathtt 4,
\mathtt 5, \mathtt 6, \mathtt 7, \mathtt 8, \mathtt 9.
$$
como dígitos.
Quando a base $b$ é maior mas ainda $b \leq 36$ usamos os
$$
\mathtt A, \mathtt B, \mathtt C, \dotsc, \mathtt X, \mathtt Y, \mathtt Z
$$
com valores $10,11,12,\dots,33,34,35$ respectivamente.
O sistema mais usado com base $b>10$ é o \dterm{hexadecimal} com $b = 16$,
onde realmente usamos os dígitos
$$
\mathtt 0, \mathtt 1, \mathtt 2, \mathtt 3, \mathtt 4,
\mathtt 5, \mathtt 6, \mathtt 7, \mathtt 8, \mathtt 9,
\mathtt A, \mathtt B, \mathtt C, \mathtt D, \mathtt E, \mathtt F.
$$
Tendo estabelecido um sistema de numerais para os \emph{valores dos dígitos},
podemos simplesmente usar esses numerais sem se preocupar com os símbolos
dos dígitos para escrever numerais de outros sistemas.
Nesse caso separamos as casas com um símbolo novo (que não faz parte do
nosso sistema de numerais estabelecido) como separador:
usando o decimal escolhemos por exemplo o símbolo $:$ como separador
das casas e assim podemos escrever o número $151208$ no sistema
sexagesimal assim:
$$
42 : 0 : 8 = 42 \ntimes 60^2 + 0 \ntimes 60^1 + 8 \ntimes 60^0.
$$

%%}}}

%%{{{ remark: 0x_etc 
\remark.
%%%{{{ meta 
\label 0x_etc
%%%}}}

Muitas linguagens de programação usam o prefixo $\mathtt{0x}$ como indicação
que o numeral que segue é hexadecimal.  Similarmente o $\mathtt{0o}$ (ou simplesmente
um numeral que começa com $\mathtt 0$) indica octal, e o $\mathtt{0b}$ binário.
Por exemplo $\mathtt{0x20}$ seria o numero $\numbase 16 {20}$, ou seja o $32$;
$\mathtt{0b100}$ seria o $\numbase 2 {100}$, ou seja o $4$, e $\mathtt{0750}$ ou $\mathtt{0o750}$ seria o $\numbase 8 {750}$, ou seja o $488$.
Essas são apenas convenções que certas linguagens seguem, então em forma geral
não conte com nenhuma delas (a mais estabelecida sendo a do $\mathtt{0x}$).

%%}}}

%%{{{ thm: expansion_in_base 
\theorem expansão em base.
%%%{{{ meta 
\label expansion_in_base
\indexes
    * teorema!expansão em base
    ;;
%%%}}}

Seja $b \geq 2$.
Todo inteiro $x \geq 0$ tem uma única expansão em base $b$:
existem únicos $m, d_0, \dotsc, d_m$ tais que:
$$
x = d_m b^m + \dotsb + d_1 b^1 + d_0 b^0
$$
onde:
\tlist:
\li  (i): para todo $i \in \set{0,\dotsc,m}$, $d_i \in \set{0,\dotsc,b-1}$;
\li (ii): $d_m = 0 \implies m=0$.
\endtlist

\proof.
Demonstrarás agora, com duas maneiras diferentes:
pelo princípio da boa ordem (\ref[expansion_in_base_proof_by_WOP]) e
por indução (\ref[expansion_in_base_proof_by_induction]).

%%}}}

%%{{{ x: expansion_in_base_proof_by_WOP 
\exercise.
%%%{{{ meta 
\label expansion_in_base_proof_by_WOP
%%%}}}

Demonstre o~\ref[expansion_in_base] pelo PBO.

%%}}}

%%{{{ x: expansion_in_base_proof_by_induction 
\exercise.
%%%{{{ meta 
\label expansion_in_base_proof_by_induction
%%%}}}

Demonstre o~\ref[expansion_in_base] por indução.

%%}}}

\TODO mencione mais non-standard positional systems: negabinary, complex-base, gray code.

\endsection
%%}}}

%%{{{ When_one_base_is_not_enough 
\section Quando uma base não é suficiente.
%%%{{{ meta 
\label When_one_base_is_not_enough
%%%}}}

%%{{{ df: fibonacci 
\definition Fibonacci.
%%%{{{ meta 
\label fibonacci
\defines
    * Fibonacci!números
    ;;
\credits
    * Fibonacci : números
    ;;
\indexes
    * Fibonacci!números   seealso: Lucas
    ;;
%%%}}}

Definimos a seqüência dos \dterm{números Fibonacci} recursivamente assim:
\mathcol
F_0     &= 0 \\
F_1     &= 1 \\
F_{n+2} &= F_{n+1} + F_n.
\endmathcol

%%}}}

%%{{{ df: lucas 
\definition Lucas.
%%%{{{ meta 
\label lucas
\defines
    * Lucas!números
    ;;
\credits
    * Lucas : números
    ;;
\indexes
    * Lucas!números       seealso: Fibonacci
    ;;
%%%}}}

Definimos a seqüência dos \dterm{números Lucas} recursivamente assim:
\mathcol
L_0     &= 2 \\
L_1     &= 1 \\
L_{n+2} &= L_{n+1} + L_n.
\endmathcol

%%}}}

%%{{{ x: lucas 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule o valor $L_{12}$.

%%}}}

\TODO Computando seus valores.

%%{{{ prop: lucas_altdef_first_attempt 
\proposition.
%%%{{{ meta 
\label lucas_altdef_first_attempt
\indexes
    * Fibonacci
    * Lucas
    ;;
%%%}}}

Para todo $n \geq 1$, seja
$$
\ell_n = F_{n-1} + F_{n+1},
$$
onde $F_n$ é o $n$-ésimo número Fibonacci (veja~\ref[fibonacci]).
Queremos mostrar que para todo $n \geq 1$, $L_n = \ell_n$,
onde $L_n$ é o $n$-ésimo número Lucas (veja~\ref[lucas]).

\wrongproof.
Nos vamos demonstrar por indução que \emph{para todo $n \geq 1$, $L_n = \ell_n$}.
Vamos primeiramente verificar que para $n=1$, realmente temos $L_n = \ell_n$:
\compute
\ell_1 &= F_0 + F_2      \by {def.~de $\ell_n$} \\
       &= 0 + F_1 + F_0  \by {def.~de $F_n$} \\
       &= 0 + 1 + 0      \by {def.~de $F_n$} \\
       &= 1              \\
       &= L_1.           \by {def.~de $L_n$} \\
\intertext{Seja $k\in\nats$ com $k\geq 2$, tal que $L_{k-1} = \ell_{k-1}$.
Realmente temos}
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$} \\
&= \ell_{k-1} + \ell_{k-2}                  \by {H.I.} \\
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell_n$} \\
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $(+)$} \\
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$} \\
&= \ell_k.                                  \by {def.~de $\ell_n$} \\
\endcompute
que termina nossa demonstração.

%%}}}

%%{{{ x: lucas_altdef_find_error 
\exercise.
%%%{{{ meta 
\label lucas_altdef_find_error
%%%}}}

Na demonstração acima roubamos.
Ache onde e explique como, e pense numa solução.

%%}}}

%%{{{ lucas_altdef_final 
\proposition.
%%%{{{ meta 
\label lucas_altdef_final
%%%}}}

Com a notação da~\ref[lucas_altdef_first_attempt],
para todo $n\geq 1$, $\ell_n = L_n$.

\proof.
Nos vamos demonstrar por indução que \emph{para todo $n \geq 1$, $L_n = \ell_n$}.
Vamos primeiramente verificar que para $n=1$ e $n=2$, realmente temos $L_n = \ell_n$.
Para $n=1$:
\compute
\ell_1 &= F_0 + F_2      \by {def.~de $\ell_n$} \\
       &= 0 + F_1 + F_0  \by {def.~de $F_n$} \\
       &= 0 + 1 + 0      \by {def.~de $F_n$} \\
       &= 1              \\
       &= L_1.           \by {def.~de $L_n$} \\
\endcompute
E para $n=2$:
$$
\xalignat2
\computed {
      L_2 &= L_1 + L_0  \by {def.~de $L_n$} \\
          &= 1 + 2      \by {def.~de $L_n$} \\
          &= 3          
}
&&
\computed {
\ell_2 &= F_1 + F_3          \by {def.~de $\ell_n$} \\
        &= 1 + F_2 + F_1      \by {def.~de $F_n$} \\
        &= 1 + 1 + 1          \\
        &= 3.
}
&
\endxalignat
$$
Seja $k\in\nats$ com $k\geq 3$ tal que
$$
L_{k-1} = \ell_{k-1}
\qquad
\text{e}
\qquad
L_{k-2} = \ell_{k-2}
$$
(nossas \emph{duas} hipoteses indutivas).
Vamos demonstrar que $L_k = \ell_k$.
Calculamos:
\compute
L_k
&= L_{k-1} + L_{k-2}                        \by {def.~de $L_n$} \\
&= \ell_{k-1} + \ell_{k-2}                  \by {H.I.} \\
&= (F_{k-2} + F_k) + (F_{k-3} + F_{k-1})    \by {def.~de $\ell_n$, $k\geq3$} \\
&= (F_{k-2} + F_{k-3}) + (F_k + F_{k-1})    \by {ass.~e com.~de $(+)$} \\
&= F_{k-1} + F_{k+1}                        \by {def.~de $F_n$, $k\geq3$} \\
&= \ell_k,                                  \by {def.~de $\ell_n$} \\
\endcompute
que termina nossa demonstração.

%%}}}

%%{{{ x: new_proof_of_sum_of_threes_and_fives_with_three_bases 
\exercise.
%%%{{{ meta 
\label new_proof_of_sum_of_threes_and_fives_with_three_bases
%%%}}}

Ache uma nova demonstração do~\ref[sum_of_threes_and_fives] por indução
com três bases.

\hint
$k = (k-3) + 3$.

\solution
Seja $k\geq 8 + 3 = 11$ tal que $k-1$, $k-2$, e $k-3$
podem ser escritos como somatórios de $3$'s e $5$'s (H.I.).
Temos
\compute
k &= (k-3) + 3      \\
  &= (3x + 5y) + 3  \quad\text{para alguns $x,y\in\nats$} \by {pela H.I.} \\
  &= 3(x+1) + 5y.
\endcompute
Como precisamos a veracidade da proposição para o valor $k-3$,
devemos mostrar as $3$ bases, para os inteiros $8$, $9$, e $10$:
$$
\alignat 2
8  &= 3 + 5     &&= 3\ntimes 1 + 5\ntimes 1\\
9  &= 3 + 3 + 3 &&= 3\ntimes 3 + 5\ntimes 0\\
10 &= 5 + 5     &&= 3\ntimes 0 + 5\ntimes 2.
\endalignat
$$

%%}}}

%%{{{ two_ways_to_organize_inductive_step 
\note Duas maneiras de organizar tua demonstração.
%%%{{{ meta 
\label two_ways_to_organize_inductive_step
%%%}}}

Ok, vamos supor que tu tá tentando demonstrar algo da forma
$$
\lforall {n \geq 0} {\phi(n)}
$$
por indução, e que tu decidiu usar duas bases
(obviamente a $\phi(0)$ e a $\phi(1)$).
Como seria teu passo indutivo?
Tem duas maneiras boas para proceder agora:
\crproofalt{Maneira 1:}
\wq{Seja $k \geq 2$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k-2)$\fact{H.I.2}.
Vou demonstrar que $\phi(k)$.}
Nessa maneira, preciso tomar cuidado que nenhum inteiro menor que $k-2$ aparece
em algum canto errado, pois não sei nada sobre eles; até pior pode ser
que aparecem objetos que nem são definidos.
\crproofalt{Maneira 2:}
\wq{Seja $k \geq 0$ tal que $\phi(k)$\fact{H.I.1} e $\phi(k+1)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+2)$.}
E agora preciso tomar o mesmo cuidado, só que agora com inteiros
menores que~$k$.
\eop
\emph{Ambas as maneiras são corretas} e bem escritas e bem entendíveis
e tudo mais---e dá pra variar mais também, pois não são
únicas~(\ref[third_way_to_organize_inductive_step]).
Qual vamos escolher?  Depende de gosto e às vezes do contexto também.
Na maioria das vezes eu vou favorecer a primeira:
meus olhos gostam da associação dos (H.I.$i$) com os $\phi(k-i)$.
Na mesma linha de pensar, na segunda maneira as hipoteses indutivas são as
$\phi(k)$ e $\phi(k+1)$, e o alvo seria o $\phi(k+2)$;
então a (H.I.2) parece mais com o alvo do que com a (H.I.1).
Ou seja: \emph{nos meus olhos}, os dados e o alvo ficam mais arrumados
na maneira 1.
Mas como falei: ambas corretas; questão de gosto; então consulte teus
próprios olhos.

%%}}}

%%{{{ x: third_way_to_organize_inductive_step 
\exercise.
%%%{{{ meta 
\label third_way_to_organize_inductive_step
%%%}}}

Qual seria a terceira \dq{óbvia} maneira?
Com que inteiros tem que tomar cuidado se escolhê-la?

\solution
\wq{Seja $k \geq 0$ tal que $\phi(k-1)$\fact{H.I.1} e $\phi(k)$\fact{H.I.2}.
Vou demonstrar que $\phi(k+1)$.}
Nessa maneira, preciso tomar cuidado com inteiros menores de $k-1$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: WOP_iff_PFI 
\problem.
%%%{{{ meta 
\label WOP_iff_PFI
%%%}}}

Retire o \mref[Z-WOP] e para cada $\phi \is \Int \to \Prop$, adicione
o axioma seguinte:
$$
\phi(1) \mland \lforall {k > 0} {\phi(k) \implies \phi(k+1)}
    \implies \lforall {x > 0} {\phi(x)}.
    \mtag[Z-PI=Z-PI$_\phi$]
$$
Consegues o \mref[Z-WOP] como teorema?

%%}}}

%%{{{ prob: induction_iff_strong_induction 
\problem.
%%%{{{ meta 
\label induction_iff_strong_induction
\indexes
    * PIFF
    * PIF
    ;;
%%%}}}

$\text{PIF} \iff \text{PIFF}$.

%%}}}

%%{{{ prob: where_is_the_base_of_strong_induction 
\problem Cadê a base da indução forte?.
%%%{{{ meta 
\label where_is_the_base_of_strong_induction
%%%}}}

Seguindo o teorema acima, parece que não precisamos demonstrar uma ``base''
na indução forte.
Critique a seguinte afirmação:
\quote
Quando quero demonstrar um teorema da forma $\lforall n {\phi(n)}$ usando indução,
eu preciso demostrar uma(s) base(s) $\phi(0), \phi(1), \dotsc, \phi(b-1)$
e depois demonstrar $\phi(k)$ para algum $k$ sobre qual tenho dadas as $b$ hipoteses:
$\phi(k-1), \phi(k-2), \dotsc, \phi(k-b)$.
Por outro lado, usando indução forte eu preciso mostrar menos coisas:
não tenho nenhuma base para demonstrar; e, além disso, no meu esforço
para demonstrar o $\phi(k)$, eu não vou ter apenas umas poucas $b$ hipoteses indutivas,
mas sim todos os $\phi(i)$, um para cada $i<k$.
Como os dois princípios são válidos, eu vou sempre usar indução forte.
\endquote

\hint
Quantos $i\in\nnints$ satisfazem $i < 0$?

%%}}}

%%{{{ prob: generalizing_binary_ops_on_ints 
\problem.
%%%{{{ meta 
\label generalizing_binary_ops_on_ints
%%%}}}

Na \ref[Sums_and_products_lame_version] generalizamos os operadores binários
$(+)$ e $(\ntimes)$ para versões iterativas.
Mostre como fazer a mesma coisa para um operador binário arbitrário $(\heart)$.
Quais propriedades dele precisamos?

%%}}}

%%{{{ prob: every_finite_set_of_ints_has_min_and_max 
\problem.
%%%{{{ meta 
\label every_finite_set_of_ints_has_min_and_max
%%%}}}

Todo conjunto finito e habitado de inteiros possui membro mínimo e membro máximo.

\hint
Indução no tamanho do conjunto finito.

%%}}}

%%{{{ prob: squares_smaller_than_powers_of_two_induction 
\problem.
%%%{{{ meta 
\label squares_smaller_than_powers_of_two_induction
%%%}}}

Demonstre que para todo $n \geq 5$,
$$
n^2 < 2^n.
$$

%%}}}

%%{{{ prob: triminos 
\problem Triminôs.
%%%{{{ meta 
\label triminos
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ prob: horses_and_birthdays 
\problem Cavalos e aniversários.
%%%{{{ meta 
\label horses_and_birthdays
%%%}}}

Vamos demonstrar o seguinte:
\quote
\wq{Para todo $n \geq 0$, em qualquer conjunto de $n$ pessoas,
só tem pessoas com o mesmo dia de aniversário.}
\endquote
\proofstylize{Suposta demonstração.}
\quote\it
<<Por indução no $n$.
\crproofpart {Base.}
Trivial: em qualquer conjunto de $0$ pessoas, só tem pessoas com o mesmo aniversário, pois não tem nenhuma pessoa e logo não tem como achar pessoas de aniversários diferentes.
\crproofpart {Passo indutivo.}
Seja $k \geq 0$ tal que \emph{em qualquer conjunto de $k$ pessoas, só tem pessoas com o mesmo dia de aniversário}.
Seja $A$ conjunto de $k+1$ pessoas:
$$
A = \set{ p_0, p_1, \dotsc, p_{k-1}, p_k }.
$$
Considere os conjunto
$$
\align
A'  &= \set{ p_0, p_1, \dotsc, p_{k-1} } \\
A'' &= \set{      p_1, \dotsc, p_{k-1}, p_k }.
\endalign
$$
Ambos os $A', A''$ têm $k$ pessoas, e logo pela hipótese indutiva todos os membros de $A'$ têm o mesmo aniversário entre si; e também todos os membros de $A''$ têm o mesmo aniversário entre si.
Como a pessoa $p_1$ está no $A'$, todos os membros de $A'$ têm o mesmo aniversário com o $p_1$.
Mas a pessoa $p_1$ também etsá no $A''$, e logo todos os membros de $A''$ têm o mesmo aniversário com o $p_1$.
Ou seja:
todos os $p_0, p_1, \dotsc, p_{k-1}, p_k$ têm aniversario no mesmo dia.>>
\endquote
Numa maneira parecida podemos demonstrar várias afirmações doidas, como por exemplo a seguinte:
\quote
\wq{Para todo $n \geq 0$, em qualquer conjunto de $n$ cavalos, só tem cavalos da mesma cor.}
\endquote
Obviamente o que \dq{demonstramos} é errado, e logo na demonstração existe pelo menos um erro---%
caso contrário seria uma indicação que o princípio da indução não é válido!
Qual é?

%%}}}

%%{{{ prob: balanced_ternary 
\problem Balanced ternary.
%%%{{{ meta 
\label balanced_ternary
\pdefs
    \pdef T {{\mathtt T}}
    \pdef O {{\mathtt O}}
    \pdef I {{\mathtt I}}
    ;;
%%%}}}

Para qualquer inteiro $x$ existem únicos $m,d_0,\dotsc,d_m$ tais que
$$
x = d_m 3^m + \dotsb + d_1 3^1 + d_0 3^0,
$$
onde:
\tlist:
\li  (i): para todo $i \in \set{0,\dotsc,m}$, $d_i \in \set{-1,0,1}$;
\li (ii): $d_m = 0 \implies m=0$.
\endtlist
Usando como digitos os símbolos $\T$, $\O$, $\I$ com valores $-1$, $0$, $1$ respectivamente
podemos então escrever qualquer inteiro sem sequer precisar um símbolo de sinal para os negativos.  Uns exemplos:
$$
\matrix
\format
\r\ &\;\c\;& \ \r\         &\c & \ \r\           &\c & \ \r\           &\c & \ \r\            &\quad\c\quad& \ \r     \\
0   &=     &               &   &                 &   &                 &   &    0 \ntimes 3^0 &\leadsto    & \O       \\
1   &=     &               &   &                 &   &                 &   &    1 \ntimes 3^0 &\leadsto    & \I       \\
7   &=     &               &   &   1 \ntimes 3^2 & + &(-1) \ntimes 3^1 & + &    1 \ntimes 3^0 &\leadsto    & \I\T\I   \\
-7  &=     &               &   &(-1) \ntimes 3^2 & + &   1 \ntimes 3^1 & + & (-1) \ntimes 3^0 &\leadsto    & \T\I\T   \\
26  &=     & 1 \ntimes 3^3 & + &   0 \ntimes 3^2 & + &   0 \ntimes 3^1 & + & (-1) \ntimes 3^0 &\leadsto    & \I\O\O\T \\
\endmatrix
$$

%%}}}

%%{{{ prob: factorial_base_system_lemma 
\problem.
%%%{{{ meta 
\label factorial_base_system_lemma
%%%}}}

Demonstre por indução que para todo $n \in \nats$,
$\quad\dsize\Sum\limits_{i=0}^n i \ntimes \factorial i = \factorialp {n+1} - 1$.

%%}}}

%%{{{ prob: factorial_base_system 
\problem Factorial base system.
%%%{{{ meta 
\label factorial_base_system
%%%}}}

Os sistemas posicionais de numerais que encontramos até agora usam um fixo conjunto de dígitos para cada posição.
Agora vamos encontrar um onde para cada posição $i$, podemos usar dígitos com valores nos $0,\dotsc,i$.
Na posição $0$ então temos apénas uma opção: o próprio $0$, e logo essa posição sempre tá ocupada por $0$.
Na posição $1$ já temos dois dígitos disponíveis, com valores $0$ e $1$.
Na posição $42$ temos quarenta e dois dígitos disponíveis; seus valores são: o $0$, o $1$, o $2$, \dots, o $40$, o $41$, e o $42$.
Cuidado, vamos usar aqui seus valores como dígitos, mesmo que no papel o $42$
que acabei de escrever dá a impressão que ele mesmo é composto por dois dígitos,
mas não é o caso aqui!
Por isso, usamos o $:$ para separarar ``as casas''.
O primeiro numeral em baixo seria válido, mas o segundo não
\mathcols 2
&4:0:2:2:0:0 &
&5:2:4:2:0:0
\endmathcols
pois na posição $3$ tem o $4>3$.
Novamente os valores dos dígitos vão acabar sendo coeficientes de algo que depende da posição e todos os termos serão somados.
Como sempre, escrevemos um número $x$ como
\mathcols 2
x & = d_n a_n + d_{n-1} a_{n-1} + \dotsb d_2 a_2 + d_1 a_1 + d_0 a_0  &
0 &\leq d_i \leq D_i
\endmathcols
onde $D_i$ denota o maior valor de dígito para a $i$-ésima posição.
Neste sistema temos:
\mathcols 3
a_i &= \factorial i    &
D_i &= i
\endmathcols
Demonstre que tal sistema \dq{funciona}:
cada inteiro pode ser escrito neste sistema numa única maneira.

%%}}}

\TODO Dar exemplos para o problema seguinte ou transformar em discussão.

%%{{{ prob: not_all_that_seems_LEM_is_LEM 
\problem.
%%%{{{ meta 
\label not_all_that_seems_LEM_is_LEM
%%%}}}

Uns leigos divulgando o LEM (\reftag[LEM_spell]) estão tentando
vender a idéia que seria essencial para demonstrar mais
proposições do que realmente é!

%%}}}

\endproblems
%%}}}

%%{{{ More on sets closed under subtraction 
\section Mais sobre conjuntos fechados sob subtração.
%%%{{{ meta 
%%%}}}

%% About (+,-)-closed sets

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos finalmente responder na pergunta \ref[int_does_subtraction_closed_imply_mZ].
Um conjunto de inteiros fechado sob a \emph{subtração} $(-)$
(e logo sob a $(+)$ também, pois \ref[minus_closed_implies_plus_closed]),
não tem muita liberdade na \dq{forma} dele.
O lemma seguinte mostra essa forma geral que todos eles devem ter.

%%}}}

%%{{{ lemma: form_of_closed_under_subtraction 
\lemma.
%%%{{{ meta 
\label form_of_closed_under_subtraction
%%%}}}

Seja $S$ um conjunto de inteiros não vazio e $(-)$-fechado.
Logo $S=\set{0}$ ou existe inteiro $d>0$ tal que
$S$ é o conjunto de todos os múltiplos de $d$:
$$
S = \setst {md} {m \in \ints}.
$$

\proof.
Suponha que $S\neq\set{0}$.  Basta demonstrar que
existe inteiro $d>0$ tal que
$$
S = \setst {md} {m \in\ints}.
$$
Organizamos o resto da demonstração em três partes:
\elist A:
\li:form_of_closed_under_subtraction_part1_task
Definir um $d>0$ que será o inteiro positivo desejado:
\ref[form_of_closed_under_subtraction_part1].
\li:form_of_closed_under_subtraction_part2_task
Demonstrar que todos os multiplos de $d$ pertencem ao $S$:
\ref[form_of_closed_under_subtraction_part2].
\li:form_of_closed_under_subtraction_part3_task
Demonstrar que nada mais pertence ao $S$:
\ref[form_of_closed_under_subtraction_part3].
\endelist
Com isso temos que o conjunto $S$ e o conjunto de todos os
múltiplos de $d$ possuem exatamente os mesmos membros,
que foi o que precisamos demonstrar.

%%}}}

%%{{{ x: form_of_closed_under_subtraction_part1 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_subtraction_part1
%%%}}}

Resolva a parte \reftag[form_of_closed_under_subtraction_part1_task] da
demonstração do~\ref[form_of_closed_under_subtraction].

\hint
Use o PBO (mas cuidado pois precisas de demonstrar algo antes de usá-lo).

\hint
Antes de usar o PBO precisas demonstrar que o $S$ possui membros positivos.

\solution
Vou demonstrar que $S$ tem membros positivos.
Seja $x \in S$ tal que $x \neq 0$ ($S\neq\emptyset$ e $S\neq\set{0}$).
Caso $x>0$, já encontramos um membro positivo do $S$.
Caso $x<0$, basta mostrar que $-x \in S$, pois $-x > 0$.
Como $S$ é $(-)$-fechado, temos $x - x \in S$; ou seja, $0 \in S$.
Usando novamente que $S$ é $-$-fechado, temos $0 - x \in S$, ou seja $-x \in S$.
Pelo PBO, \emph{seja $d$ o menor membro positivo do $S$}.

%%}}}

%%{{{ x: form_of_closed_under_subtraction_part2 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_subtraction_part2
%%%}}}

E a \reftag[form_of_closed_under_subtraction_part2_task].

\hint
Use indução, mas cuidado para não esquecer nada.

\solution
Primeiramente vou demonstrar por indução que
para todo $n\in\nats$, $nd \in S$.
A base é imediata: $0d = 0 \in S$.
Seja $k \in \nats$ tal que $kd \in S$\fact{HI}.
Calculamos:
$$
(k+1)d = kd + d \in S
$$
pois $d \in S$ e $kd \in S$ (pela HI) e $S$ é $(+)$-fechado
(pelo~\ref[minus_closed_implies_plus_closed])
Seja $x < 0$, e observe que $(-x)d\in S$ (pois $-x > 0$) e logo
$0 - (-x)d \in S$, ou seja, $xd \in S$.

%%}}}

%%{{{ x: form_of_closed_under_subtraction_part3 
\exercise.
%%%{{{ meta 
\label form_of_closed_under_subtraction_part3
%%%}}}

Preciso mesmo enunciar?

\hint
Tome um arbitrário $a \in S$ e use o lemma da Divisão de Euclides.

%%}}}

%%{{{ x: form_of_closed_under_subtraction_without_disjunction 
\exercise.
%%%{{{ meta 
%%%}}}

Sem usar disjunção, escreva uma proposição equivalente com a conclusão do
\ref[form_of_closed_under_subtraction] e explique por que ela é equivalente.

\hint
Existe $n\in\ints_{\geq 0}$ tal que $S = \setst {kn} {k\in\ints}$.

%%}}}

\endsection
%%}}}

%{{{ Invertibles_Units_Associates 
\section Invertíveis, units, sócios.
%%%{{{ meta 
\label Invertibles_Units_Associates
%%%}}}

%% Invertibles & Units

%%{{{ df: int_invertible 
\definition invertibilidade.
%%%{{{ meta 
\label int_invertible
\defines
    * invertível!inteiro
    ;;
%%%}}}

Seja $x$ inteiro.
Dizemos que $x$ é \dterm{$(\ntimes)$-invertível na esquerda}
sse
existe $(\ntimes)$-inverso direito de $x$,
e simetricamente definimos o que significa $(\ntimes)$-invertível na direita.
Em símbolos:
\mathcol
\text{$x$ é invertível-L} &\defiff \lexists {x'} {xx' = 1}; \\
\text{$x$ é invertível-R} &\defiff \lexists {x'} {x'x = 1}; \\
\text{$x$ é invertível}   &\defiff \text{$x$ é invertível-L} \mland \text{$x$ é invertível-R}. \\
\endmathcol
Observe que já que $(\ntimes)$ é comutativa as três afirmações são equivalentes para os inteiros.

%%}}}

%%{{{ df: int_unit 
\definition unit.
%%%{{{ meta 
\label int_unit
\defines
    * unit!inteiro
    ;;
\credits
    * Euclid : medir
    ;;
%%%}}}

Seja $u$ inteiro.
Dizemos que $u$ é um \dterm{unit}
sse
ele consegue \dterm{medir} qualquer inteiro,\foot
Euclides mesmo usou o verbo \wq{medir} em vez do verbo \wq{dividir} que usamos hoje.
\toof
ou seja,
sse para todo $x$, existe $k$ tal que $uk = x$:
$$
\text{$u$ unit} \defiff \pforall x \lexists k {uk = x} \defiff \lforall x {u \divides x}.
$$

%%}}}

%%{{{ x: int_invertible_iff_unit
\exercise.
%%%{{{ meta 
\label int_invertible_iff_unit
%%%}}}

Demonstre que invertível e unit são sinônimos nos inteiros.

%%}}}

%%{{{ x: if_ab_is_1_then_what 
\exercise.
%%%{{{ meta 
\label if_ab_is_1_then_what
%%%}}}

Sejam $a,b$ inteiros com $ab=1$.
Demonstre que $a=b=1$ ou $a=b=-1$.
Conclua que os únicos inteiros invertíveis são os $1, -1$.

%%}}}

%%{{{ x: divides_is_almost_a_partial_order 
\exercise.
%%%{{{ meta 
\label divides_is_almost_a_partial_order
%%%}}}

Demonstre:
\mathcol
\cforall {a,b}        {a \divides b \mland b \divides a \implies \abs a = \abs b}; \\
\cforall {a,b \geq 0} {a \divides b \mland b \divides a \implies      a =      b}. \\
\endmathcol

%%}}}

%% Associates

%%{{{ df: int_associates 
\definition Sócios.
%%%{{{ meta 
\label int_associates
\defines
    * sócios
    ;;
%%%}}}

Seja $a,b$ inteiros.
Dizemos que os $a,b$ são \dterm{sócios} (entre si) sse $a \divides b$ e $b \divides a$.

%%}}}

%%{{{ x: justify_associates_sym 
\exercise.
%%%{{{ meta 
\label justify_associates_sym
%%%}}}

Justifique o plural e o \wq{entre si} na definição acima.

\hint
Aqui o que devemos demonstrar é que a relação é simétrica; sem isso
a gente precisaria especificar quem é sócio de quem.

%%}}}

%%{{{ x: int_associates_and_abs 
\exercise sócios e abs.
%%%{{{ meta 
\label int_associates_and_abs
%%%}}}

Demonstre ou refute: para quaisquer inteiros $a,b$,
$$
\text{$a,b$ sócios} \iff \abs a = \abs b.
$$

\hint
Demonstre.

%%}}}

%%{{{ x: int_associates_and_units 
\exercise sócios e units.
%%%{{{ meta 
\label int_associates_and_units
%%%}}}

Sejam $a,b \neq 0$.
$$
\text{$a,b$ sócios} \iff \ltexists {$u$ unit} {a = ub}.
$$

\hint
Demonstre.

%%}}}

\endsection
%%}}}

%%{{{ Drawing_orders 
\section Desenhando ordens.
%%%{{{ meta 
\label Drawing_orders
%%%}}}

%%{{{ divs_12_and_divs_18 
\note.
%%%{{{ meta 
\label divs_12_and_divs_18
%%%}}}

Desenhamos:
$$
\tikzpicture
\tikzi hassedivs1218;
\endtikzpicture
$$
Pintamos os divisores de 12 de vermelho e os de 18 de azul,
$$
\tikzpicture
\tikzi hassecomdivs1218;
\endtikzpicture
$$
e focamos nos divisores em comum (roxa):
$$
\tikzpicture
\tikzi hassedivs6;
\endtikzpicture
$$

%%}}}

%%{{{ comdivs_fake 
\note E se fosse assim?.
%%%{{{ meta 
\label comdivs_fake
%%%}}}

Não sempre teremos um habitante dominando seu conjunto:
$$
\tikzpicture
\tikzi hassecomdivsfake;
\endtikzpicture
$$

%%}}}

\TODO Continuar e conectar com mdc.

\endsection
%%}}}

%%{{{ Best_common_divisor 
\section Melhor divisor comum.
%%%{{{ meta 
\label Best_common_divisor
%%%}}}

%%{{{ df: a_gcd 
\definition.
%%%{{{ meta 
\label a_gcd
\indexes
    * mdc               see: divisor, máximo comum
    * máximo divisor    see: divisor
    ;;
\defines
    * melhor!divisor comum
    * {~d} = \gcd {~a} {~b}  -- $d$ é um mdc dos $a$ e $b$
    * divisor!máximo comum, um
    * coprimos
    ;;
%%%}}}

Sejam $a,b,d$ inteiros.
O inteiro $d$ é \dterm{um máximo divisor comum (mdc)} dos $a,b$
sse $d$~é~um divisor comum e um multiplo de todos os divisores comuns.
Em símbolos:
$$
\text{$d$ é um mdc dos $a,b$}
\defiff
\tubrace {d \divides a \mland d \divides b}
         {divisor comun}
\mland
\tubrace {\lforall {\text{$c$ divisor comum}} {c \divides d}}
         {o \dq{melhor} dos divisores comuns}.
$$
Nesse caso, escrevemos:
$$
d = \gcd a b.
$$
Se $1 = \gcd a b$, dizemos que os $a,b$ são \dterm{coprimos} (entre si).

%%}}}

%%{{{ beware: not_really_an_equality_gcd 
\beware Desfarçando como igualdade.
%%%{{{ meta 
\label not_really_an_equality_gcd
%%%}}}

Mais uma vez, abusamos aqui a notação para escrever uma proposição
\dq{com roupas de igualdade}, quando na verdade não é.
Veja primeiramente (\ref[gcd_symbol_is_not_welldefined]) que seu lado
direito nem significa algo sozinho.
Entendemos então a notação inteira como um predicado ternário nos inteiros
$$
\uhole = \gcd {\uhole} {\uhole}
\is
\Int \times \Int \times \Int \to \Prop.
$$

%%}}}

%%{{{ x: gcd_symbol_is_not_welldefined 
\exercise.
%%%{{{ meta 
\label gcd_symbol_is_not_welldefined
%%%}}}

Parece que a~\ref[a_gcd] tem um erro: o símbolo $\gcd a b$ não foi bem-definido!
O que precisamos demonstrar para conseguir realmente a tipagem
$$
\gcd \uhole \uhole \is \Int \times \Int \to \Int?
$$

\solution
Duas coisas:
\eop
\proofstylize{Existência:}
\emph{para todos inteiros $a$, $b$, existe inteiro $d$ que satisfaz as relações acima.}
\eop
\proofstylize{Unicidade:}
\emph{se $g$, $g'$, são inteiros que satisfazem essas relações, então $g=g'$.}

%%}}}

%%{{{ remark: no_hope_for_true_uniqueness 
\remark.
%%%{{{ meta 
\indexes
    * unicidade
    ;;
%%%}}}

Definimos o conceito de mdc totalmente em termos da relação~$(\divides)$
e logo não temos chances de conseguir \dterm{unicidade} de mdc.
Para qualquer inteiro $d$ que acaba sendo um mdc dos $a,b$,
com certeza seu sócio $-d$ também vai já que a $(\divides)$ não consegue
distingüi-los.
Então a melhor coisa que podemos esperar é uma noção de unicidade mais fraca:
unicidade pelos olhos da $(\divides)$, ou, como falamos mesmo:
\dterm{unicidade a menos de sócios:}

%%}}}

%%{{{ thm: gcd_uniqueness_up_to_associates 
\theorem unicidade a menos de sócios.
%%%{{{ meta 
\label gcd_uniqueness_up_to_associates
%%%}}}

Sejam $a,b$ inteiros.
Se $d,d'$ são mdc dos $a,b$, então $d,d'$ são sócios.

\sketch.
Aplicamos a definição de mdc para cada um dos $d$ e $d'$,
para chegar em $d \divides d'$ e $d' \divides d$.

\proof.
Suponha que $d,d'$ são mdc's de $a$ e $b$.
Como $d$ é um mdc, todos os divisores em comum dos $a$ e $b$ o dividem.
Mas, como $d'$ é um divisor em comum, então $d' \divides d$.
Simetricamente concluimos que $d \divides d'$, e logo $d,d'$ são sócios.

%%}}}

%%{{{ cor: uniqueness of mdc in nonnegs 
\corollary.
%%%{{{ meta 
%%%}}}

Sejam $a,b$ inteiros.
Existe único $d\in\nnints$ tal que $d$ é um mdc dos $a,b$.

%%}}}

%%{{{ generalized_the_gcd 
\note Artigo definido generalizado.
%%%{{{ meta 
\label generalized_the_gcd
%%%}}}

Agora podemos sim definir o símbolo $\gcd a b$
e tratar a expressão $d = \gcd a b$ como uma igualdade mesmo;
o leitor que não quer desviar muito com a literatura popular
pode fazer isso.  Mas não havendo motivo de prejudicar uns inteiros
contra seus sócios, e para introduzir a idéia de \dterm{um artigo definido generalizado},
vou insistir que falar \emph{do} {mdc}~em vez \emph{de um} {mdc}, faz sentido,
dado que entendemos que estamos olhando o mundo dos inteiros pelos olhos da preordem $(\divides)$.
Nesse uso, encontrando o símbolo $\gcd a b$, a idéia é que ele denota um mdc, e que
qual dos possíveis sócios ele é, não vai importar, pois não vamos sair desse mundinho.
Por exemplo, não faz sentido perguntar se $\gcd a b > 0$ ou não, já que isso está
misturando uma outra ordem (a $(>)$) com a ordem utilizada no mdc, e, querendo
investigar esse tipo de perguntas, precisamos abandonar o conforto da abstração
do mundinho da $(\divides)$.

%%}}}

%%{{{ df: the_gcd 
\definition O máximo divisor comum.
%%%{{{ meta 
\label the_gcd
\defines
    * \gcd {~a} {~b}  -- o máximo divisor comum de $a$ e $b$
    * divisor!máximo comum, o
    ;;
%%%}}}

Sejam $a,b$ inteiros.
$$
d = \gcd a b
\defiff
\tubrace { d \divides a \mland d \divides b } {divisor comun}
\mland
\tubrace { d\in\nnints \mland \lforall c {\paren{c \divides a \mland c \divides b} \implies c \divides d} } {o máximo}
$$

%%}}}

%%{{{ x: coprime_def_needs_a_proof 
\exercise.
%%%{{{ meta 
\label coprime_def_needs_a_proof
%%%}}}

Na \ref[a_gcd] definimos o que significa que dois inteiros $a,b$
são coprimos (entre si).  Para essa definição \dq{compilar}
algo precisa ser demonstrado.  Enuncie e demonstre.

\solution
O \wq{os $a,b$ são {\dots} (entre si)} presuponha que tal propriedade
é simétrica nos seus argumentos $a,b$, e logo precisamos demonstrar a
comutatividade: $\gcd a b = \gcd b a$, que faz parte do \ref[gcd_op_properties].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos já demonstrar umas propriedades básicas de mdc.

%%}}}

%%{{{ x: gcd_signs 
\exercise.
%%%{{{ meta 
\label gcd_signs
%%%}}}

Um mdc não enxerga sinais: para quaisquer inteiros $a,b$,
$$
\gcd a b
= \gcd a {-b}
= \gcd {-a} {b}
= \gcd {-a} {-b}.
$$

%%}}}

%%{{{ x: gcd_op_properties
\exercise.
%%%{{{ meta 
\label gcd_op_properties
%%%}}}

Sejam $a,b,c$ inteiros.  Logo:
\mathcall
&\gcd a a = a                           \called {idempotência} \\
&\gcd a 0 = a                           \called {identidade-R} \\
&\gcd a 1 = 1                           \called {absorção-R} \\
&\gcd a b = \gcd b a                    \called {comutatividade} \\
&\gcd {\gcd a b} c = \gcd a {\gcd b c}  \called {associatividade}
\endmathcall

%%}}}

%%{{{ eg: gcd_example 
\example.
%%%{{{ meta 
\label gcd_example
%%%}}}

Ache um mdc dos $12,18$.

\solution.
Vamos primeiramente calcular os divisores de cada um desses números:
\mathcol
\divs(12) &= \set{ \pm 1, \pm 2, \pm 3, \pm 4, \pm 6, \pm 12 } \\
\divs(18) &= \set{ \pm 1, \pm 2, \pm 3, \pm 6, \pm 9, \pm 18 }.
\intertext{Segundo a definição de mdc, se tem inteiro $d$ que merece
esse nome, ele é um dos divisores comuns:}
\comdivs(12,18) &= \divs(12) \inter \divs(18) = \set{ \pm 1, \pm 2, \pm 3, \pm 6 }.
\endmathcol
$$
$$

%%}}}

%% Existence of GCD and coefficients form

%%{{{ But do they exist? 
\note Mas existem?.
%%%{{{ meta 
%%%}}}

Ainda não tratamos a \emph{existência} de mdc.
Definir o que um objeto precisa satisfazer para ser chamado por um nome
não garanta que de fato existe tal objeto.
Por enquanto, pode ser que para certos inteiros existe um mdc deles,
mas para outros, não.
Demonstraremos que não é o caso, com duas demostrações bem diferentes.
Primeiramente apresentamos uma demonstração não-construtiva, que depende
do princípio da boa ordem, conhecida como Lemma de Bézout.
Ele não apenas garanta a existência de mdc, mas, também afirma que
ele pode ser escrito numa certa forma.
Na próxima secção, melhoramos a situação mostrando o \emph{algoritmo}
de Euclides, que, ainda mais mostra uma maneira efetiva de construir
(achar) o mdc de quaisquer inteiros dados, e ainda-ainda mais, aproveitando
sua versão \dq{estendida}, fornecer a forma de escrevê-lo garantida
pelo Lemma de Bézout.

%%}}}

%%{{{ lemma: bezout_lemma 
\lemma Lemma de Bézout.
%%%{{{ meta 
\headerize
\label bezout_lemma
\credits
    * Bezout : lemma
    ;;
\defines
    * combinação linear
    ;;
%%%}}}

Sejam $a,b$ inteiros.
Logo existe $d$ que satisfaz a definição de $\gcd a b$, e
ele pode ser escrito como \dterm{combinação linear}
dos $a$ e $b$, com coeficientes inteiros; ou seja,
$$
\lexists {s,t} {d = sa + tb}.
$$
Além disso, o $\gcd a b$ divide qualquer combinação linear dos $a$ e $b$.

\sketch.
Considere o conjunto $C$ de todas as combinações lineares dos $a,b$:
$$
C \defeq \setst {sa + tb} {s,t \in \ints}.
$$
Infira que existe $d$ tal que $L = d\ints$.
Verifique que tal $d$ é um mdc dos $a,b$.
Como $d \in C = d\ints$, conclua que $d$ divide qualquer combinação linear dos $a,b$.

%%}}}

%%{{{ x: bezout_coefs_are_not_unique 
\exercise.
%%%{{{ meta 
\label bezout_coefs_are_not_unique
%%%}}}

Investigue se a forma do $\gcd a b$ como combinação linear dos $a$ e $b$
é unicamente determinada.

\hint
Não é.  Mostre um contraexemplo.

\solution
Toma $3$ e $4$.  Temos $\gcd 4 3 = 1$, mas:
\mathcol
1 &= (-2)\ntimes 4 + 3\ntimes 3\\
1 &= \phantom{(-}4\phantom{)}\ntimes 4 - 5\ntimes 3.
\endmathcol

%%}}}

%%{{{ ppty: gcd_of_comparable 
\property.
%%%{{{ meta 
\label gcd_of_comparable
%%%}}}

$a \divides b \implies \gcd a b = a$.
Especificamente, $\gcd a 0 = a$.

\sketch.
Precisamos apenas verificar as condições da definição de mdc,
que seguem pelas propriedades de $(\divides)$ que já demonstramos.

%%}}}

%%{{{ x: common_divisor_written_as_linear_combination_means_gcd 
\exercise.
%%%{{{ meta 
\label common_divisor_written_as_linear_combination_means_gcd
%%%}}}

Sejam $a,b$ inteiros.  Demonstre ou refute:
para qualquer inteiro $c$ tal que
(i) $c$ é divisor comum dos $a,b$ e
(ii) $c$ pode ser escrito como combinação linear dos $a,b$,
temos que $c$ é um mdc dos $a,b$.

\hint
Já demonstramos (\ref[bezout_lemma]) que
$$
C = \setst {ax + by} {x,y \in \ints}
=
d\ints
$$
onde $d$ é um mdc dos $a,b$.

\solution
Pelo \ref[bezout_lemma] temos que
$$
C = \setst {ax + by} {x,y \in \ints}
=
d\ints
$$
onde $d$ é um mdc dos $a,b$.
Pela hipótese (ii), $c \in C = d\ints$, e logo $d \divides c$.
Pela hipótese (i), $c$ sendo um divisor comum dos $a,b$, divide o mdc deles: $c \divides d$.
Portanto $c$ é um mdc dos $a,b$.

%%}}}

%%{{{ x: gcd_of_two_is_gcd_of_one_plus_sum 
\exercise.
%%%{{{ meta 
\label gcd_of_two_is_gcd_of_one_plus_sum
%%%}}}

Sejam $a,b$ inteiros.
Demonstre que
$$
\gcd a b = \gcd a {a+b}.
$$

\hint
Lembre a definição de mdc.

\hint
Talvez as propriedades do \reftag[divides_linear_combinations] são úteis.

\solution
Basta mostrar que os conjuntos dos divisores comuns dos $a,b$ e dos $a,a+b$ são iguais.
\crproofpart{$\comdivs(a,b) \subset \comdivs(a,a+b)$.}
Seja $c$ divisor comum dos $a,b$.
Preciso mostrar que $c \divides a$ (que é imediato pela escolha de $c$),
e que $c \divides a + b$, que segue pela \ref[divides_linear_combinations].
\crproofpart{$\comdivs(a,b) \supset \comdivs(a,a+b)$.}
Seja $c$ divisor comum dos $a,a+b$.
Preciso mostrar que $c \divides a$ (que é imediato pela escolha de $c$),
e que $c \divides b$, que segue pela \ref[divides_linear_combinations]
pois $b = 1\ntimes(a + b) + (-1)\ntimes a$.

%%}}}

%%{{{ x: consecutive_fibs_are_coprime 
\exercise.
%%%{{{ meta 
\label consecutive_fibs_are_coprime
\indexes
    * Fibonacci!seqüência
    ;;
%%%}}}

Demonstre que para todo $n\in\nats$, $\gcd {F_n} {F_{n+1}} = 1$,
onde $F_n$ é o $n$-ésimo termo da seqüência Fibonacci~(\ref[fibonacci]).

\hint
Tu não pulou o~\ref[gcd_of_two_is_gcd_of_one_plus_sum], certo?

\solution
Vamos demonstrar o pedido por indução.
A base
$$
\gcd {F_0} {F_1} = \gcd 0 1 = 1.
$$
Seja $k\in\nats$ tal que $\gcd {F_k} {F_{k+1}} = 1$\fact{HI}.
Precisamos mostrar que $\gcd {F_{k+1}} {F_{k+2}} = 1$.
Calculando,
\compute
\gcd {F_{k+1}} {F_{k+2}}
    &= \gcd {F_{k+1}} {F_{k+1} + F_k}   \by {pela definição da $F_n$} \\
    &= \gcd {F_{k+1}} {F_k}             \by {pelo~\ref[gcd_of_two_is_gcd_of_one_plus_sum], com $a\asseq F_{k+1},\ b\asseq F_k$} \\
    &= \gcd {F_k} {F_{k+1}}             \by {pelo~\ref[gcd_op_properties]} \\
    &= 1.                               \by {pela hipótese indutiva}
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ The_Euclidean_algorithm 
\section O algoritmo de Euclides.
%%%{{{ meta 
\label The_euclidean_algorithm
\credits
    * Euclid : algoritmo
    ;;
%%%}}}

%%{{{ Idea 
\note Idéia.
%%%{{{ meta 
%%%}}}

Sejam $a,b$ inteiros positivos.
Como achamos o $\gcd a b$?
Nos vamos aplicar o lemma da divisão~(\reftag[euclidean_division]) repetitivamente,
até chegar em resto $0$:
$$
\matrix
\format
\r\;    &\;\c\;  & \; \c \;                   & \l      & \;\c\; & \c      & \qquad\qquad\l          \\
a       &   =    & b                          & q_0     &  +     & r_0,    & 0\leq r_0 < b           \\
b       &   =    & r_0                        & q_1     &  +     & r_1,    & 0\leq r_1 < r_0         \\
r_0     &   =    & r_1                        & q_2     &  +     & r_2,    & 0\leq r_2 < r_1         \\
r_1     &   =    & r_2                        & q_3     &  +     & r_3,    & 0\leq r_3 < r_2         \\
        & \vdots &                            &         &        &         & \hfil\vdots\hfil        \\
r_{n-3} &   =    & r_{n-2}                    & q_{n-1} &  +     & r_{n-1},& 0\leq r_{n-1} < r_{n-2} \\
r_{n-2} &   =    & \boxed{\mathstrut r_{n-1}} & q_n     &  +     & \mubrace {r_n} {0},     & 0 = r_n < r_{n-1}.      
\endmatrix
$$
O $\gcd a b$ estará na posição marcada acima.
Vamos agora descrever o algoritmo formalmente, e demonstrar
(informalmente e formalmente) sua corretude!

%%}}}

%%{{{ algorithm: euclidean_algorithm 
\algorithm Algoritmo de Euclides.
%%%{{{ meta 
\headerize
\label euclidean_algorithm
\credits
    * Euclid : algoritmo
    ;;
\defines
    * algoritmo!de Euclides
    ;;
%%%}}}

% TODO: XXX: URGENT: fix this!
\eop\noi\centerline{$\euclid(a,b)$}
{\hrule width \hsize height 1pt\relax}
\vskip4pt
\algospec
 INPUT: $a,b \is \Int$
OUTPUT: $\gcd a b$
\endspec
\elist:
\li: Se $b=0$, retorna $a$.
\li: Retorna $\euclid(b,r)$, onde $r = \rem(a,b)$.
\endelist
{\hrule width \hsize height 1pt\relax}

%%}}}

%%{{{ eg: euclidean_algorithm_example 
\example.
%%%{{{ meta 
\label euclidean_algorithm_example
%%%}}}

Ache o $\gcd {101} {73}$ com o algoritmo de Euclides.

\solution.
Sabendo que os dois números são primos, fica imediato que eles são coprimos
entre si também: a reposta é 1.
\eop
Aplicando o algoritmo de Euclides, para achar o $\gcd {101} {73}$, dividimos o $101$ por $73$:
$$
\alignat 2
101 &= 73       \ntimes \tubrace {\phantom 1} {quociente} + \tubrace {\phantom{28}} {resto},      &\qquad&0 \leq \tubrace {\phantom{28}} {resto} < 73
\intertext{e sabemos que assim reduziremos o problema para o alvo de achar o $\gcd {73} {\text{resto}}$.  Pensando, achamos os valores:}
101 &= 73       \ntimes \tubrace {1} {quociente} + \tubrace {28} {resto},      &\quad&0 \leq \tubrace {28} {resto} < 73 
\intertext{ou seja, $\gcd {101} {73} = \gcd {73} {28}$.  Então, repetimos:}
73  &= 28       \ntimes \tubrace {2} {quociente} + \tubrace {17} {resto},      &&0 \leq \tubrace {17} {resto} < 28
\intertext{ou seja, $\gcd {73} {28} = \gcd {28} {17}$.  Repetimos:}
28  &= 17       \ntimes \tubrace {1} {quociente} + \tubrace {11} {resto},      &&0 \leq \tubrace {11} {resto} < 17
\intertext{ou seja, $\gcd {28} {17} = \gcd {17} {11}$.  Repetimos:}
17  &= 11       \ntimes \tubrace {1} {quociente} + \tubrace {6}  {resto},      &&0 \leq \tubrace {6} {resto} < 11
\intertext{ou seja, $\gcd {17} {11} = \gcd {11} 6$.  Repetimos:}
11  &= 6        \ntimes \tubrace {1} {quociente} + \tubrace {5}  {resto},      &&0 \leq \tubrace {5} {resto} < 6
\intertext{ou seja, $\gcd {11} 6 = \gcd 6 5$.  Repetimos:}
6   &= 5        \ntimes \tubrace {1} {quociente} + \tubrace {1}  {resto},      &&0 \leq \tubrace {1} {resto} < 5
\intertext{ou seja, $\gcd 6 5 = \gcd 5 1$.  Como $\gcd 5 1 = 1$, nem precisamos repetir, mas vamos mesmo assim:}
5   &= \boxed 1 \ntimes \tubrace {5} {quociente} + \tubrace {0} {resto}.      &&
\endalignat
$$
Mais compactamente, os passos são:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l  & \c     & \c & \c       & \c & \c    & \c & \c     & \r            & \c    & \l          \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28, & \qquad & 0  & {}\leq{} & 28 & {}<{} & 73 & \qquad & \gcd{101}{73} & {}={} & \gcd{73}{28}\\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17, &        & 0  & {}\leq{} & 17 & {}<{} & 28 &        & \gcd{73 }{28} & {}={} & \gcd{28}{17}\\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11, &        & 0  & {}\leq{} & 11 & {}<{} & 17 &        & \gcd{28 }{17} & {}={} & \gcd{17}{11}\\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6,  &        & 0  & {}\leq{} & 6  & {}<{} & 11 &        & \gcd{17 }{11} & {}={} & \gcd{11}{6 }\\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5,  &        & 0  & {}\leq{} & 5  & {}<{} & 6  &        & \gcd{11 }{6 } & {}={} & \gcd{6 }{5 }\\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1,  &        & 0  & {}\leq{} & 1  & {}<{} & 5  &        & \gcd{6  }{5 } & {}={} & \gcd{5 }{1 }\\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0   &        &    &          &    &       &    &        & \gcd{5  }{1 } & {}={} & \gcd{1 }{0 } = \boxed 1.
\endmatrix
$$
Pronto: $\gcd {101} {73} = 1$.

%%}}}

%%{{{ remark: using euclidean_algorithm for gcd of ints 
\remark.
%%%{{{ meta 
%%%}}}

Podemos utilizar o algoritmo de Euclides para achar o $\gcd a b$
onde $a,b\in\ints$ também,
graças ao~\ref[gcd_signs]:
$(a,b) = (\abs a, \abs b) = \euclid(\abs a, \abs b)$.

%%}}}

%%{{{ x: find_a_couple_of_gcds 
\exercise.
%%%{{{ meta 
\label find_a_couple_of_gcds
%%%}}}

Usando o algoritmo de Euclides, ache os:
(i) $\gcd {108} {174}$; 
(ii) $\gcd {2016} {305}$.

\solution
(i) Para o $\gcd {108} {174} = \gcd {174} {108}$ calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l    & \c     & \c & \c       & \c & \c    & \c & \c     & \r             & \c    & \l            \\
174 & {}={} & 108      & {}\ntimes{} & 1  & {}+{} &{66},  & \qquad & 0  & {}\leq{} & 66 & {}<{} & 108& \qquad & \gcd{174}{108} & {}={} & \gcd{108}{66 }\\
108 & {}={} & 66       & {}\ntimes{} & 1  & {}+{} &{42},  &        & 0  & {}\leq{} & 42 & {}<{} & 66 &        &                & {}={} & \gcd{66 }{42 }\\
66  & {}={} & 42       & {}\ntimes{} & 1  & {}+{} &{24},  &        & 0  & {}\leq{} & 24 & {}<{} & 42 &        &                & {}={} & \gcd{42 }{24 }\\
42  & {}={} & 24       & {}\ntimes{} & 1  & {}+{} &{18},  &        & 0  & {}\leq{} & 18 & {}<{} & 24 &        &                & {}={} & \gcd{24 }{18 }\\
24  & {}={} & 18       & {}\ntimes{} & 1  & {}+{} &{6 },  &        & 0  & {}\leq{} & 6  & {}<{} & 18 &        &                & {}={} & \gcd{18 }{6  }\\
18  & {}={} & \boxed 6 & {}\ntimes{} & 3  & {}+{} &{0 }   &        &    &          &    &       &    &        &                & {}={} & \gcd{6  }{0  } = \boxed 6.
\endmatrix
$$
\eop
\noi
(ii) Calculamos:
$$
\matrix
\format
\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
2016& {}={} & 305      & {}\ntimes{} & 6  & {}+{} &{186},  & \qquad & 0  & {}\leq{} &186 & {}<{} &305 & \qquad & \gcd{2016}{305} & {}={} & \gcd{305}{186}\\
305 & {}={} & 186      & {}\ntimes{} & 1  & {}+{} &{119},  &        & 0  & {}\leq{} &119 & {}<{} &186 &        &                 & {}={} & \gcd{186}{119}\\
186 & {}={} & 119      & {}\ntimes{} & 1  & {}+{} &{67 },  &        & 0  & {}\leq{} &67  & {}<{} &119 &        &                 & {}={} & \gcd{119}{67 }\\
119 & {}={} & 67       & {}\ntimes{} & 1  & {}+{} &{52 },  &        & 0  & {}\leq{} &52  & {}<{} &67  &        &                 & {}={} & \gcd{67 }{52 }\\
67  & {}={} & 52       & {}\ntimes{} & 1  & {}+{} &{15 },  &        & 0  & {}\leq{} &15  & {}<{} &52  &        &                 & {}={} & \gcd{52 }{15 }\\
52  & {}={} & 15       & {}\ntimes{} & 3  & {}+{} &{7  },  &        & 0  & {}\leq{} &7   & {}<{} &15  &        &                 & {}={} & \gcd{15 }{7  }\\
15  & {}={} & 7        & {}\ntimes{} & 2  & {}+{} &{1  },  &        & 0  & {}\leq{} &1   & {}<{} &7   &        &                 & {}={} & \gcd{7  }{1  }\\
7   & {}={} & \boxed 1 & {}\ntimes{} & 7  & {}+{} &{0  }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{1  }{0  } = \boxed 1.
\endmatrix
$$
%$$
%\matrix
%\format
%\r  & \c    & \c       & \l        & \l & \c    & \l     & \c     & \c & \c       & \c & \c    & \c & \c     & \r              & \c    & \l            \\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  & \qquad & 0  & {}\leq{} &    & {}<{} &    & \qquad & \gcd{    }{   } & {}={} & \gcd{   }{   }\\
%    & {}={} &          & {}\ntimes{} &    & {}+{} &{   },  &        & 0  & {}\leq{} &    & {}<{} &    &        &                 & {}={} & \gcd{   }{   }\\
%    & {}={} & \boxed 1 & {}\ntimes{} &    & {}+{} &{   }   &        &    &          &    &       &    &        &                 & {}={} & \gcd{   }{   } = .
%\endmatrix
%$$

%%}}}

%%{{{ codeit: implement_euclidean_algorithm 
\codeit.
%%%{{{ meta 
\label implement_euclidean_algorithm
%%%}}}

Implemente o algoritmo de Euclides e verifique tuas soluções nos exercícios anteriores.

%%}}}

%%{{{ codeit: implement_verbose_euclidean_algorithm 
\codeit.
%%%{{{ meta 
\label implement_verbose_euclidean_algorithm
%%%}}}

Implemente um modo ``verbose'' no teu programa
do~\ref[implement_euclidean_algorithm],
onde ele mostra todas as equações e desigualdades, e não apenas o resultado final.

%%}}}

%%{{{ lemma: euclid_gcd_lemma 
\lemma Euclides.
%%%{{{ meta 
\label euclid_gcd_lemma
\credits
    * Euclid : lemma de mdc
    ;;
\indexes
    * mdc!lemma
    ;;
%%%}}}

Se $a,b\in\ints$ com $b > 0$, então $\gcd a b = \gcd b r$,
onde $r$ o resto da divisão de $a$ por $b$.

\wrongproof.
Dividindo o $a$ por $b$, temos $a = bq + r$.
Vamos mostrar que qualquer inteiro $d$ satisfaz a equivalência:
$$
\align
d \divides a
\mland
d \divides b
&\iff
d \divides b
\mland
d \divides r.\\
\intertext{Realmente, usando as propriedades~\reftag[divides_linear_combinations], temos:}
d \divides a
\mland
d \divides b
&\implies
d \divides \mobraceb {a - bq} {r}\\
d \divides \mubraceb {bq + r} {a}
&\impliedby
d \divides b
\mland
d \divides r.
\endalign
$$
Isso mostra que os divisores em comum dos $a$ e $b$, e dos $b$ e $r$ são os mesmos,
ou, formalmente:
$$
\setst {c\in\ints} {c \divides a \mland c \divides b}
=
\setst {c\in\ints} {c \divides b \mland c \divides r}.
$$
Logo,
\compute
\gcd a b
&= \max\setst {c\in\ints} {c \divides a \mland c \divides b}  \by {def.~$\gcd a b$} \\
&= \max\setst {c\in\ints} {c \divides b \mland c \divides r}  \by {demonstrado acima} \\
&= \gcd b r                                                   \by {def.~$\gcd b r$}
\endcompute
que estabeleça a corretude do algoritmo.

%%}}}

%%{{{ x: what_is_the_problem_with_euclid_gcd_lemma 
\exercise.
%%%{{{ meta 
\label what_is_the_problem_with_euclid_gcd_lemma
%%%}}}

Qual é o problema com a demonstração do~\ref[euclid_gcd_lemma]?

\solution
A definição do mdc $(a,b)$ não foi
\wq{o $(\leq)$-maior divisor comum dos $a$ e $b$}.
Lembre-se a~\ref[a_gcd].
Veja também o~\ref[gcd_alternative_definition].

%%}}}

%%{{{ thm: euclidean_algorithm_correctness 
\theorem Corretude do \sayname{algorithm} de Euclides.
%%%{{{ meta 
\label euclidean_algorithm_correctness
%%%}}}

O~\ref[euclidean_algorithm] é correto.

\sketch.
Precisamos demonstrar duas coisas: \emph{terminação\/}\/ e \emph{corretude}.
\eop
\proofstylize{Corretude.}
Se o algoritmo precisou $n$ passos, temos que verificar:
$$
\gcd a b
= \gcd b {r_0}
= \gcd {r_0} {r_1}
= \gcd {r_1} {r_2}
= \dotsb
= \gcd {r_{n-1}} {r_n}
= \gcd {r_n} 0
= r_n.
$$
Todas as igualdades exceto a última seguem por causa do~\ref[euclid_gcd_lemma];
a última por causa da~\ref[gcd_of_comparable].
\eop
\proofstylize{Terminação.}
Note que a seqüência de restos $r_0, r_1, \ldots$ é estritamente
decrescente, e todos os seus termos são não negativos:
$$
0\leq \dotsb < r_2 < r_1 < r_0 < b.
$$
Logo, essa seqüência não pode ser infinita.
Realmente, o tamanho dela não pode ser maior que $b$,
então depois de no máximo $b$ passos, o algorítmo terminará.

\proof.
Demonstrado no \ref[euclidean_algorithm_correctness_formal_proof_by_induction]
por indução e no \reftag[euclidean_algorithm_correctness_formal_proof_by_wop]
pelo princípio da boa ordem.

%%}}}

%%{{{ x: euclidean_algorithm_proof_why_informal 
\exercise.
%%%{{{ meta 
\label euclidean_algorithm_proof_why_informal
%%%}}}

Explique por que as argumentações acima
(\reftag[euclidean_algorithm_correctness])
tanto de corretude quanto de terminação
são \emph{esboços} mesmo e não demonstrações.

\hint
${}\dotsb{}$

\hint
${}\dotsb{}$

\solution
São os ``${}\dotsb{}$'' mesmo!
Para formalizá-los em definições usamos recursão;
pra formalizá-los em demonstrações usamos indução.

%%}}}

%%{{{ How do we find the coefs of the linear combination 
\note.
%%%{{{ meta 
%%%}}}

Nós já demonstramos que o mdc de dois inteiros $a$ e $b$
pode ser escrito como uma combinação linear deles, mas como podemos
realmente \emph{achar}\/ inteiros $s,t\in\ints$ que satisfazem a
$$
\gcd a b = as + bt,     \qquad s,t\in\ints?
$$
Surpresamente a resposta já está ``escondida'' no mesmo algoritmo de Euclides!

%%}}}

%%{{{ algorithm: extended_euclidean_algorithm 
\algorithm Algoritmo estendido de Euclides.
%%%{{{ meta 
\label extended_euclidean_algorithm
\credits
    * Euclid : algoritmo estendido
    ;;
\defines
    * algoritmo!estendido de Euclides
    ;;
%%%}}}

% TODO: XXX: URGENT: fix this 
\algospec
 INPUT: $a,b\in\ints$, $b>0$
OUTPUT: $s,t\in\ints$ tais que $\gcd a b = as + bt$.
\endspec

%%}}}

%%{{{ eg: write_a_gcd_as_a_linear_combination 
\example.
%%%{{{ meta 
\label write_a_gcd_as_a_linear_combination
%%%}}}

Escreva o $\gcd {101} {73}$ como combinação linear dos $101$ e $73$.

\solution.
Primeiramente, precisamos aplicar o algoritmo de Euclides para achar o mdc,
como no~\ref[euclidean_algorithm_example],
mas vamos também resolver cada equação por o seu resto:
$$
\matrix
\format
\r  & \c    & \c       & \l          & \l & \c    & \l & \c           & \r & \c    & \c & \c    &\c & \c         & \c  \\
101 & {}={} & 73       & {}\ntimes{} & 1  & {}+{} & 28 & \qquad\qquad &28  & {}={} &101 & {}-{} &   &{}       {} & 73 \\
73  & {}={} & 28       & {}\ntimes{} & 2  & {}+{} & 17 &              &17  & {}={} &73  & {}-{} & 2 &{}\ntimes{} & 28 \\
28  & {}={} & 17       & {}\ntimes{} & 1  & {}+{} & 11 &              &11  & {}={} &28  & {}-{} &   &{}       {} & 17 \\
17  & {}={} & 11       & {}\ntimes{} & 1  & {}+{} & 6  &              &6   & {}={} &17  & {}-{} &   &{}       {} & 11 \\
11  & {}={} & 6        & {}\ntimes{} & 1  & {}+{} & 5  &              &5   & {}={} &11  & {}-{} &   &{}       {} & 6  \\
6   & {}={} & 5        & {}\ntimes{} & 1  & {}+{} & 1  &              &1   & {}={} &6   & {}-{} &   &{}       {} & 5  \\
5   & {}={} & \boxed 1 & {}\ntimes{} & 5  & {}+{} & 0. &              &    &       &    &       &    &          &     \\
\endmatrix
$$
Utilizando as equações no lado direto, de baixo para cima, calculamos:
$$
\def\hl{\underline}
\alignat 2
1 &= \hl6 - \hl5                                           &\quad&\text{(6 e 5)   }\\
  &= \hl6 - (\hl{11} - \hl6)
   = \hl6 - \hl{11} + \hl6
   = -\hl{11} + 2\ntimes \hl6                                   &&\text{(11 e 6)  }\\
  &= -\hl{11} + 2\ntimes (\hl{17} - \hl{11})
   = -\hl{11} + 2\ntimes \hl{17} - 2\ntimes \hl{11}
   = 2\ntimes \hl{17} - 3\ntimes \hl{11}                        &&\text{(17 e 11) }\\
  &= 2\ntimes \hl{17} - 3\ntimes (\hl{28} - \hl{17})
   = 2\ntimes \hl{17} - 3\ntimes \hl{28} + 3\ntimes 17
   = -3\ntimes \hl{28} + 5\ntimes \hl{17}                       &&\text{(28 e 17) }\\
  &= -3\ntimes \hl{28} + 5\ntimes (\hl{73} - 2\ntimes \hl{28})
   = -3\ntimes \hl{28} + 5\ntimes \hl{73} - 10\ntimes \hl{28}
   = 5\ntimes \hl{73} -13\ntimes \hl{28}                        &&\text{(73 e 28) }\\
  &= 5\ntimes \hl{73} -13\ntimes (\hl{101} - \hl{73})
   = 5\ntimes \hl{73} -13\ntimes \hl{101} + 13\ntimes \hl{73}
   = -13\ntimes \hl{101} + 18\ntimes \hl{73}                    &&\text{(101 e 73)}
\endalignat
$$
No lado direto mostramos nosso progresso, no sentido de ter conseguido
escrever o mdc como combinação linear de quais dois números.
Sublinhamos os inteiros que nos interessam para não perder nosso foco.
Em cada nova linha, escolhemos o menor dos dois números sublinhados,
e o substituimos pela combinação linear que temos graças ao algoritmo de Euclides.
Obviamente, essa notação e metodologia não tem nenhum sentido matematicamente
falando.  Serve apenas para ajudar nossos olhos humanos.
\eop
Achamos então $s,t\in\ints$ que satisfazem a equação $1 = sa + tb$:
são os $s = -13$ e $t = 18$.

%%}}}

%%{{{ x: more_gcds_as_linear_combinations 
\exercise.
%%%{{{ meta 
\label more_gcds_as_linear_combinations
%%%}}}

Usando o algoritmo estendido de Euclides, escreve:
(i) o $\gcd {108} {174}$ como combinação linear dos 108 e 174; 
(ii) o $\gcd {2016} {305}$ como combinação linear dos 2016 e 305.

%%}}}

%%{{{ diophantine_equations 
\note Equações de Diophantus.
%%%{{{ meta 
%%%}}}

\TODO escrever e posicionar.

%%}}}

%%{{{ How many steps does Euclid need? 
\note Quantos passos precisa o Euclides.
%%%{{{ meta 
%%%}}}

Para demonstrar a terminação do algoritmo de Euclides
estabelecemos uma garantia que o $\euclid(a,b)$ depois
$b$ passos no máximo termina.
Como o exercício seguinte mostra, o algoritmo de Euclides
é \emph{bem mais eficiente} do que isso:
depois dois passos, as duas entradas, nos piores dos casos,
são reduzidas à metade!

%%}}}

%%{{{ x: less_steps_in_euclid
\exercise.
%%%{{{ meta 
\label less_steps_in_euclid
%%%}}}

Se $a \geq b$, então $r < a/2$, onde $r$ o resto da divisão de $a$ por $b$.

\hint
Separe os casos: ou $b > a/2$ ou $b \leq a/2$.

\hint
Qual seria o resto em cado caso?

\hint
Num caso, dá para achar exatamente o resto.
No outro, use a restricção que o resto satisfaz.

\solution
\proofcase {Caso $b > a/2$:}
Então $r = a-b < a/2$.
\proofcase {Caso $b < a/2$:}
Então $r < b < a/2$.

%%}}}

%%{{{ Q: How efficient is Euclid's algorithm? 
\question.

Quão eficiente é o algoritmo de Euclides?

%%}}}

\spoiler

\TODO Sobre eficiência, operações primitivas, oráculos.

%%{{{ lemma: euclid_algorithm_efficiency 
\lemma.
%%%{{{ meta 
\label euclid_algorithm_efficiency
%%%}}}

\TODO Eficiência de Euclides.

%%}}}

%%{{{ x: euclid_vs_fibonacci 
\exercise Euclides \vs Fibonacci.
%%%{{{ meta 
\label euclid_vs_fibonacci
%%%}}}

Para todo $n\geq1$ e quaisquer inteiros $a > b > 0$,
se $\euclid(a,b)$ precisa $n$ passos (divisões) para terminar,
então $a \geq F_{n+2}$ e $b \geq F_{n+1}$, onde $F_i$ é o $i$-ésimo
número Fibonacci.

\hint
Indução.

\hint
$x>y \implies \quot(x,y) \geq 1$.

\solution
Por indução.
\proofpart {Base.}
Sejam inteiros $a > b > 0$
tais que $\euclid(a,b)$ precisa $1$ passo para terminar:
Precisamos inferir que $a \geq F_3 = 2$ e $b \geq F_2 = 1$,
imediato pois $a > b > 0$.
\proofpart {Passo indutivo.}
Seja $k \geq 1$ tal que para quaisquer inteiros $u > v > 0$,
se $\euclid(u,v)$ precisa $k$ passos (divisões) para terminar,
emtão $u \geq F_{k+2}$ e $v \geq F_{k+1}$:
$$
\lforall {u > v > 0} {\text{$\euclid(u,v)$ termina em $k$ passos} \implies u \geq F_{k+2} \mland v \geq F_{k+1}}.
\tag{HI}
$$
Sejam inteiros $a > b > 0$ tais que $\euclid(a,b)$ termina em $k+1$ passos.
Executamos o primeiro desses passos, obtendo os $q_0, r_0$:
$$
\matrix
\format
\r\;    &\;\c\;  & \; \c \;                   & \l      & \;\c\; & \c      & \qquad\qquad\l          \\
a       &   =    & b                          & q_0     &  +     & r_0,    & 0\leq r_0 < b           \\
\endmatrix
$$
Agora em $k$ passos o algoritmo terminará, mas neste ponto o algoritmo
manda executar o $\euclid(b,r_0)$.  Ou seja o $\euclid(b,r_0)$ precisa
$k$ passos, e $b > r_0 > 0$, e logo pela HI com $u \asseq b$ e $v \asseq r_0$
inferimos:
$$
b \geq F_{k+2}
\qqquad
r_0 \geq F_{k+1}.
\tag{HI*}
$$
Calculamos:
\compute
a &=    bq_0 + r_0                  \\
  &\geq F_{k+2} q_0 + F_{k+1}       \by {HI*} \\
  &\geq F_{k+2} \stimes 1 + F_{k+1} \by {$q_0 \geq 1$ pois $a>b$} \\
  &=    F_{k+2} + F_{k+1}           \\
  &=    F_{k+3}.                    \by {def.~$F_{k+3}$} \\
\endcompute

%%}}}

%%{{{ x: fibonacci_gcd 
\exercise mdc, fibonacci.
%%%{{{ meta 
\label fibonacci_gcd 
%%%}}}

O fibonacci do mdc de dois números naturais é o mdc do fibonacci de cada:
$$
\lforall {n,m\in\nats} {\gcd {F_n} {F_m} = F_{\gcd n m}}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Factorization 
\section Fatoração.
%%%{{{ meta 
%%%}}}

%%{{{ Q: given a positive integer n, how can we break it to construction blocks? 
\question.
%%%{{{ meta 
%%%}}}

Dado um inteiro positivo $n$, como podemos ``quebrá-lo'' em blocos de construção?

%%}}}

%%{{{ what is our cement? 
\note Cimento.
%%%{{{ meta 
%%%}}}

Vamos primeiramente responder nessa questão com outra:
\emph{Qual seria nosso ``cimento''?}
Tome como exemplo o número $n=28$.
Usando $(+)$ para construí-lo com blocos, podemos quebrá-lo:
$$
\align
28 &= 16 + 12.
\intertext{E agora quebramos esses dois blocos:}
   &= \overbrace{10 + 6}^{16} + \overbrace{11 + 1}^{12};
\intertext{e esses:}
   &= \overbrace{3 + 7}^{10} + \overbrace{3 + 3}^{6} + \overbrace{4 + 7}^{11} + 1
\intertext{e o $1$ não é mais ``quebrável''.
Nesse quesito, ele é um bloco atômico, um ``tijolo''.
Repetimos esse processo até chegar num somatório cujos termos são todos tijolos:}
 &= \tubrace{1 + 1 + 1 + 1 + \dotsb + 1} {$28$ termos}.
\endalign
$$
O leitor é convidado pensar sobre as observações seguintes:
\elist i:
\li:
Começando com qualquer inteiro positivo $n$,
depois um \emph{finito} número de passos, o processo termina:
nenhum dos termos que ficam pode ser quebrado.
\li:
Existe apenas um tipo de bloco atômico: o $1$.
Podemos então formar qualquer número $n$ começando com $n$ tijolos ($n$ $1$'s)
e usando a operação $(+)$ para juntá-los.
\li:
Não faz sentido considerar o $0$ como tijolo, pois escrevendo o $1$ como
$$
1 = 1 + 0 \qqqqtext{ou}
1 = 0 + 1
$$
não conseguimos ``quebrá-lo'' em peças menores.  Pelo contrário,
ele aparece novamente, da mesma forma, no lado direito.
\endelist

%%}}}

%%{{{ x: partitioning_restricted_best_strategy 
\exercise.
%%%{{{ meta 
\label partitioning_restricted_best_strategy
%%%}}}

Qual é a melhor estratégia para desconstruir o $n$ em $1$'s conseguindo
o menor número de passos possível?  Quantos passos precisa?
Suponha que em cada passo tu tens de escolher apenas \emph{um} termo
(não atômico) e decidir em quais duas partes tu o quebrarás.

\hint
Olha na forma final do somatório.
O que acontece em cada passo?

\solution
Todas as estratégias são iguais: em cada passo, um $(+)$ é adicionado,
e todas terminam no mesmo somatório com $n$ \symq{$1$}s e $n-1$ \symq{$+$}s.
Então começando com qualquer número $n$, depois de $n-1$ passos chegamos
na sua forma $n = 1 + 1 + \dotsb + 1$.

%%}}}

%%{{{ x: partitioning_restricted_best_strategy_proof 
\exercise.
%%%{{{ meta 
\label partitioning_restricted_best_strategy_proof
\pdefs
    \pdef steps {\namedfun{steps}}
    ;;
%%%}}}

Demonstre formalmente tua resposta no~\ref[partitioning_restricted_best_strategy].

\hint
Como nos livramos dos pontos informais ``$\dotsb$''?

\hint
Indução.

\hint
Seja $\steps(x)$ o número de passos necessários para quebrar o $x$ em $1$'s.

%%}}}

%%{{{ times in stead of plus 
\note ``Vezes'' em vez de ``mais''.
%%%{{{ meta 
\indexes
    * primo!informalmente
    ;;
%%%}}}

Vamos agora usar como cimento a operação $(\ntimes)$,
ilustrando o processo com o número $2016$:
\goodbreak
$$
\align
2016
&= 12 \ntimes 168
\intertext{e repetimos\dots}
&= \overbrace{4\ntimes 3}^{12} \ntimes \overbrace{28 \ntimes 6}^{168}
\intertext{e agora vamos ver:
o $4$ pode ser quebrado sim ($2\ntimes2$), mas o $3$?
Escrever $3 = 3\ntimes 1$ com certeza não é um jeito aceitável para quebrar o $3$
em blocos de construção ``mais principais'': o lado direto é mais complexo!
Quebrando com $(\ntimes)$ então, o $3$ é um bloco atômico, um tijolo!
Continuando:}
&= \overbrace{2\ntimes 2}^{4}{} \ntimes 3 \ntimes (7\ntimes 4) \ntimes (2\ntimes3)\\
&= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes \overbrace{2\ntimes2}^4{} \ntimes 2\ntimes3
\intertext{onde todos os fatores são atômicos.
Podemos construir o número $2016$ então assim:}
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3,
\endalign
$$
usando os tijolos 2, 3, e 7, e a operação de multiplicação.
Nos vamos definir formalmente esses tijolos (que vão acabar sendo os inteiros que
chamamos de \dterm{irredutíveis} ou \dterm{primos}: \reftag[int_irreducible], \reftag[int_prime], \reftag[int_irreducible_iff_prime]), e estudar suas propriedades.
\eop
Ilustrando com o mesmo número $2016$, um outro caminho para processar seria o seguinte:
\mathcol
2016
&= 48 \ntimes 42 \\
&= \mobrace {8 \ntimes 6} {48} \ntimes \mobrace {6 \ntimes 7} {42} \\
&= \mobrace {2 \ntimes 4} {8}  \ntimes \mobrace {2 \ntimes 3} {6} \ntimes {\mobrace {2\ntimes 3} {6}} \ntimes 7\\
&= 2 \ntimes {\mobrace {2\ntimes 2} {4}} \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7
\intertext{então no final temos:}
2016
&= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endmathcol

%%}}}

%%{{{ x: fundamental_theorem_of_arithmetic_omen 
\exercise.
%%%{{{ meta 
\label fundamental_theorem_of_arithmetic_omen
%%%}}}

O que tu percebes sobre as duas desconstruções?:
\mathcol
2016 &= 2\ntimes 2 \ntimes 3 \ntimes 7 \ntimes 2\ntimes2 \ntimes 2\ntimes3; \\
2016 &= 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 3 \ntimes 7.
\endmathcol

\solution
Esquecendo a ordem que os fatores parecem, são iguais:
cada construção precisa os mesmos blocos atômicos (o $2$, o $3$, e o $7$),
e cada um deles foi usado o mesmo número de vezes:
$2016 = 2^5 3^2 7$.

%%}}}

%%{{{ x: factorize_some_integers 
\exercise.
%%%{{{ meta 
\label factorize_some_integers
%%%}}}

Fatore os inteiros $15$, $16$, $17$, $81$, $100$, $280$, $2015$, e $2017$
em fatores irredutíveis.

\solution
Calculamos:
\mathcols 4
15 &= 3 \ntimes 5 &  17 &= 17  & 100  &= 2^2 \ntimes 5^2          & 2015 &= 5 \ntimes 13 \ntimes 31 \\
16 &= 2^4         &  81 &= 3^4 & 280  &= 2^3 \ntimes 5 \ntimes 7  & 2017 &= 2017. \\
\endmathcols

%%}}}

%%{{{ codeit: program_factor_naive 
\codeit FactorNaive.
%%%{{{ meta 
\label program_factor_naive
%%%}}}

Escreva um programa que mostra para cada entrada, uma fatoração em primos.
Execute teu programa para verificar tuas respostas no~\ref[factorize_some_integers].
Note que muitos sistemas unixoides têm um programa \cmd{factor} já instalado:
\shell
\# factor 65536 65537 65538 \\
65536: 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \\
65537: 65537 \\
65538: 2 3 3 11 331
\endshell

%%}}}

%%{{{ Q: how many different construction blocks for times? 
\question.
%%%{{{ meta 
%%%}}}

Usando adição, nos precisamos apenas um tipo de tijolo para construir qualquer
inteiro positivo: o $1$.
Usando a multiplicação nos já percebemos que vários tipos são necessários; mas quantos?

%%}}}

%%{{{ A: soon 
\note Resposta (Euclides).
%%%{{{ meta 
%%%}}}

Essa pergunta e sua resposta não são triviais!
Recomendo para ti, tentar responder e \emph{demonstrar} tua afirmação.
Logo vamos encontrar a resposta (de Euclides)
que é um dos teoremas mais famosos e importantes na história de matemática
(\ref[primes_is_infinite]).

%%}}}

\endsection
%%}}}

%{{{ Irreducibles_Primes 
\section Irredutíveis, primos.
%%%{{{ meta 
\label Irreducibles_Primes
%%%}}}

%% Irreducibles & Primes

%%{{{ df: int_irreducible 
\definition Irredutível.
%%%{{{ meta 
\label int_irreducible
\indexes
    * irredutível   seealso: primo
    * redutível     seealso: composto
    * composto      seealso: redutível
    * primo         seealso: irredutível
    ;;
\defines
    * irredutível
    * redutível
    ;;
%%%}}}

Seja $p\neq 0$ inteiro.
Chamamos o $p$ \dterm{irredutível} sse $p$ não é unit e para quaisquer $a,b$ tais que $p = ab$,
pelo menos um dos $a,b$ é unit:
$$
\text{$p$ irredutível} \defiff \text{$p$ não unit} \mland \lforall {a,b} { p = ab \implies \text{$a$ unit} \mlor \text{$b$ unit} }.
$$
Caso contrário, $p$ é \dterm{redutível}.
Chamamos o $p$ de \dterm{composto} sse $p$ não é unit e existem não units $a,b$ tais que $p = ab$.

%%}}}

%%{{{ thm: int_irreducible_divisors 
\theorem.
%%%{{{ meta 
\label int_irreducible_divisors
%%%}}}

Seja $x$ inteiro.
Logo $x$ irredutível sse os únicos divisores de $x$ são os $1,-1,x,-x$.

\proof Demonstrarás no~\ref[int_irreducible_divisors_proof].

%%}}}

%%{{{ x: int_irreducible_divisors_proof 
\exercise.
%%%{{{ meta 
\label int_irreducible_divisors_proof
%%%}}}

Demonstre o \ref[int_irreducible_divisors].

%%}}}

%%{{{ df: int_prime 
\definition Primo.
%%%{{{ meta 
\label int_prime
\defines
    * primo
    ;;
%%%}}}

Seja $p \neq 0$ inteiro.
Chamamos o $p$ de \dterm{primo} sse $p$ não é unit e para quaisquer inteiros
$a,b$, se $p$ divide o produto $ab$ então $p$ divide pelo menos um dos $a,b$.
Em símbolos:
$$
\Prime(p) \defiff
  \text{$p$ não unit} \mland
  \lforall {a,b} {p \divides ab \implies p \divides a \mlor p \divides b}.
$$

%%}}}

%%{{{ warning: we have negative primes here 
\warning.
%%%{{{ meta 
%%%}}}

Nossas definições de irredutível e de primo, não conseguem discriminar
a partir da positividade: se um inteiro $x$ é primo (ou irredutível),
seu sócio $-x$ também é.
É comum excluir os negativos dessas definições, mas não vou negá-los
esse direito aqui.
Mais sobre essa escolha logo depois de conhecer o teorema principal
deste assunto, o \ref[fundamental_theorem_of_arithmetic].

%%}}}

%%{{{ lemma: euclid_lemma 
\lemma Lemma de Euclides.
%%%{{{ meta 
\headerize
\label euclid_lemma
\credits
    * Euclid : lemma
    ;;
%%%}}}

Todo inteiro irredutível é primo.

\sketch.
Sejam $a,b$ inteiros e $p$ irredutível tal que $p \divides ab$.
Suponha que $p \ndivides a$.
Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$:
$$
1 = as + pt,    \qquad\text{para alguns $s,t\in\ints$}.
$$
Multiplica os dois lados por $b$, e explica por que necessariamente $p \divides b$.

\proof.
Sejam $a,b$ inteiros e $p$ irredutível tal que $p \divides ab$.
Suponha que $p\ndivides a$.  Logo o $\gcd a p = 1$ pode ser escrito como combinação linear de $a$ e $p$,
ou seja, existem $s,t\in\ints$ tais que:
\mathcol
1 &= as + pt.
\intertext{Multiplicando os dois lados por $b$, temos:}
b &= asb + ptb.
\endmathcol
Observe que como $p \divides ab$, segue que $p \divides asb$ (por~\ref[divides_linear_combinations]).
Obviamente $p \divides ptb$ também.
Logo, $p \divides asb + ptb = b$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O converso disso também é válido e logo as noções de irredutível e de primo
coincidem no mundo dos inteiros:

%%}}}

%%{{{ thm: int_irreducible_iff_prime 
\theorem.
%%%{{{ meta 
\label int_irreducible_iff_prime
%%%}}}

Todo inteiro é irredutível sse é primo.

\proof.
A direção {\lrdir} é o \ref[euclid_lemma].
A direção {\rldir} é o \ref[euclid_lemma_converse].

%%}}}

%%{{{ x: euclid_lemma_converse 
\exercise.
%%%{{{ meta 
\label euclid_lemma_converse
%%%}}}

Todo inteiro primo é irredutível.

%%}}}

%%{{{ lemma: lemma_euclides_coprime_version 
\lemma.
%%%{{{ meta 
\label lemma_euclides_coprime_version
%%%}}}

Se $\gcd d a = 1$ e $d \divides ab$, então $d \divides b$.

\sketch.
A demonstração é practicamente a mesma com aquela do~\ref[euclid_lemma]:
lá nós precisamos da primalidade do $p$ apenas para
concluir que $\gcd a p = 1$.
Aqui temos diretamente a hipótese $\gcd a d = 1$.

\proof.
Seja $a,b,d\in\ints$, tais que
$\gcd d a = 1$ e $d \divides ab$.
Como $\gcd a d = 1$, podemos escrevê-lo como combinação linear dos $a$ e $d$:
$$
1 = sa + td,\qquad\text{para alguns $s,t\in\ints$}.
$$
Multiplicando por $b$, ganhamos
$$
b = sab + tdb,
$$
e argumentando como na demonstração do~\ref[euclid_lemma]
concluimos que $d \divides b$.

%%}}}

%%{{{ cor: product_of_coprimes_divides_common_multiple 
\corollary.
%%%{{{ meta 
\label product_of_coprimes_divides_common_multiple
%%%}}}

Se $a \divides m$, $b \divides m$, e $\gcd a b = 1$, então $ab \divides m$.

\proof.
Como $a \divides m$, temos $m = au$ para algum $u\in\ints$.
Mas $b \divides m=au$, e como $\gcd b a = 1$, temos $b \divides u$
(por~\ref[lemma_euclides_coprime_version]).
Então $bv = u$ para algum $v\in\ints$.
Substituindo, $m = au = a(bv) = (ab)v$, ou seja, $ab \divides m$.

%%}}}

%%{{{ x: pq|n² ⇒ pq|n 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para quaisquer primos distintos $p,q$,
$$
pq \divides n^2  \implies  pq \divides n.
$$

\hint
Tá certo.  Demonstre.

\hint
Temos $p,q$ primos distintos e logo coprimos e logo o
\ref[product_of_coprimes_divides_common_multiple] ajuda.

\solution
Como $p \divides pq$ e $pq \divides n^2$, logo $p \divides n^2$.
Ou seja $p \divides n$\fact1 pelo \ref[euclid_lemma].
Similarmente $q \divides n$\fact2.
Mas $p,q$ são primos distintos, logo coprimos, e
ambos dividem o $n$ (\byfact1 e \byfact2)
logo $pq \divides n$
(pelo \ref[product_of_coprimes_divides_common_multiple]).

%%}}}

%%{{{ x: int_zero_and_one_are_what 
\exercise.
%%%{{{ meta 
\label int_zero_and_one_are_what
%%%}}}

O $0$ é primo?  Redutível?  Composto?
O $1$?

\solution
Nenhum dos dois é nem primo nem composto:
a definição começa declarando
$p$ como um natural tal que $p \geq 2$.
Logo, não é aplicável nem para o 0 nem para o 1.

%%}}}

%%{{{ x: 2_is_the_only_even_prime 
\exercise.
%%%{{{ meta 
\label 2_is_the_only_even_prime
%%%}}}

$2$ é o \dq{único} primo par.\foot
Em aspas, quando eu digo $2$ aqui, eu incluo seu sócio $-2$ também.
(Óbvio?)
\toof

%%}}}

%%{{{ eg: first_primes 
\example.
%%%{{{ meta 
\label first_primes
%%%}}}

Os primeiros 31 primos positivos são os
  2,   3,   5,   7,  11,  13,  17,  19, 23,  29,
 31,  37,  41,  43,  47, 53,  59,  61,  67,  71,
 73,  79,  83,  89, 97, 101, 103, 107, 109, 113, e 127.

%%}}}

%%{{{ x: in_primes_divides_means_equals 
\exercise.
%%%{{{ meta 
\label in_primes_divides_means_equals
%%%}}}

Sejam $p,q$ primos, tais que $p \divides q$.
Mostre que $p,q$ são sócios.

%%}}}

%%{{{ x: every_composite_number_is_divisible_by_a_prime 
\exercise.
%%%{{{ meta 
\label every_composite_number_is_divisible_by_a_prime
%%%}}}

Seja $x$ composto.
Demonstre que $x$ tem um divisor primo $p$ tal que $p^2 \leq x$.

%%}}}

%%{{{ codeit: program_factor 
\codeit factor.
%%%{{{ meta 
\label program_factor
%%%}}}

Use o~\ref[every_composite_number_is_divisible_by_a_prime]
para melhorar teu programa do~\ref[program_factor_naive].

%%}}}

%%{{{ thm: primes_is_infinite 
\theorem Euclid.
%%%{{{ meta 
\label primes_is_infinite
\credits
    * Euclid : infinidade dos primos
    ;;
\indexes
    * infinidade!dos primos
    * infinito      seealso: infinidade
    ;;
%%%}}}

Existe uma infinidade de primos.

\sketch.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$, considere o número
$p_1\dotsb p_n + 1$ e use-o para achar um primo fora do $P$.

\proof.
Para qualquer conjunto finito de primos
$P = \set{p_1,\dotsc,p_n}$,
observe que o número $p=p_1\dotsb p_n + 1$ não é divisível por nenhum dos $p_i$'s
(porque $p_i \divides p$ e $p_i \divides p_1\dotsb p_n$ implicam
$p \divides 1$, absurdo).
Então, como $p \geq 2$, ou o $p$ é primo e $p \nin P$,
ou $p$ é divisível por algum primo $q \nin P$
(por~\ref[every_composite_number_is_divisible_by_a_prime]).
Nos dois casos, existe pelo menos um primo fora do $P$.

%%}}}

%%{{{ Q: How can we find all primes up to a given bound? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos achar todos os primos até um dado limitante $b$?

%%}}}

%%{{{ A: sieve_of_eratosthenes 
\note O crivo de Eratosthenes.
%%%{{{ meta 
\label sieve_of_eratosthenes
\credits
    * Eratosthenes : crivo
    ;;
\defines
    * crivo!de Eratosthenes
    ;;
\pdefs
    \pdef ci {\uveryfaded}
    \pdef co {\phantom}
    ;;
%%%}}}

Eratosthenes (276--194 a.C.)~conseguiu responder com sua método conhecida como
o \dterm{crivo de Eratosthenes}.
Eu a aplicarei aqui para achar todos os primos menores ou iguais que $b=128$.
Primeiramente liste todos os números de $2$ até $b=128$:
$$
\matrix
\format
~\r  &~\r  &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   &~\r   \\
   {   }&   {  2}&   {   3}&   {   4}&   {   5}&   {   6}&   {   7}&   {   8}&   {   9}&   {  10}&   {  11}&   {  12}&   {  13}&   {  14}&   {  15}&   {  16}\\
   { 17}&   { 18}&   {  19}&   {  20}&   {  21}&   {  22}&   {  23}&   {  24}&   {  25}&   {  26}&   {  27}&   {  28}&   {  29}&   {  30}&   {  31}&   {  32}\\
   { 33}&   { 34}&   {  35}&   {  36}&   {  37}&   {  38}&   {  39}&   {  40}&   {  41}&   {  42}&   {  43}&   {  44}&   {  45}&   {  46}&   {  47}&   {  48}\\
   { 49}&   { 50}&   {  51}&   {  52}&   {  53}&   {  54}&   {  55}&   {  56}&   {  57}&   {  58}&   {  59}&   {  60}&   {  61}&   {  62}&   {  63}&   {  64}\\
   { 65}&   { 66}&   {  67}&   {  68}&   {  69}&   {  70}&   {  71}&   {  72}&   {  73}&   {  74}&   {  75}&   {  76}&   {  77}&   {  78}&   {  79}&   {  80}\\
   { 81}&   { 82}&   {  83}&   {  84}&   {  85}&   {  86}&   {  87}&   {  88}&   {  89}&   {  90}&   {  91}&   {  92}&   {  93}&   {  94}&   {  95}&   {  96}\\
   { 97}&   { 98}&   {  99}&   { 100}&   { 101}&   { 102}&   { 103}&   { 104}&   { 105}&   { 106}&   { 107}&   { 108}&   { 109}&   { 110}&   { 111}&   { 112}\\
   {113}&   {114}&   { 115}&   { 116}&   { 117}&   { 118}&   { 119}&   { 120}&   { 121}&   { 122}&   { 123}&   { 124}&   { 125}&   { 126}&   { 127}&   { 128}\rlap.
\endmatrix
$$
Agora comece com o primeiro número na lista, o $2$, e apague todos os maiores múltiplos dele:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\ci{   4}&   {   5}&\ci{   6}&   {   7}&\ci{   8}&   {   9}&\ci{  10}&   {  11}&\ci{  12}&   {  13}&\ci{  14}&   {  15}&\ci{  16}\\
   { 17}&\ci{ 18}&   {  19}&\ci{  20}&   {  21}&\ci{  22}&   {  23}&\ci{  24}&   {  25}&\ci{  26}&   {  27}&\ci{  28}&   {  29}&\ci{  30}&   {  31}&\ci{  32}\\
   { 33}&\ci{ 34}&   {  35}&\ci{  36}&   {  37}&\ci{  38}&   {  39}&\ci{  40}&   {  41}&\ci{  42}&   {  43}&\ci{  44}&   {  45}&\ci{  46}&   {  47}&\ci{  48}\\
   { 49}&\ci{ 50}&   {  51}&\ci{  52}&   {  53}&\ci{  54}&   {  55}&\ci{  56}&   {  57}&\ci{  58}&   {  59}&\ci{  60}&   {  61}&\ci{  62}&   {  63}&\ci{  64}\\
   { 65}&\ci{ 66}&   {  67}&\ci{  68}&   {  69}&\ci{  70}&   {  71}&\ci{  72}&   {  73}&\ci{  74}&   {  75}&\ci{  76}&   {  77}&\ci{  78}&   {  79}&\ci{  80}\\
   { 81}&\ci{ 82}&   {  83}&\ci{  84}&   {  85}&\ci{  86}&   {  87}&\ci{  88}&   {  89}&\ci{  90}&   {  91}&\ci{  92}&   {  93}&\ci{  94}&   {  95}&\ci{  96}\\
   { 97}&\ci{ 98}&   {  99}&\ci{ 100}&   { 101}&\ci{ 102}&   { 103}&\ci{ 104}&   { 105}&\ci{ 106}&   { 107}&\ci{ 108}&   { 109}&\ci{ 110}&   { 111}&\ci{ 112}\\
   {113}&\ci{114}&   { 115}&\ci{ 116}&   { 117}&\ci{ 118}&   { 119}&\ci{ 120}&   { 121}&\ci{ 122}&   { 123}&\ci{ 124}&   { 125}&\ci{ 126}&   { 127}&\ci{ 128}\rlap.
\endmatrix
$$
Tome o próximo número que está ainda na lista, o $3$, e faça a mesma coisa:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\ci{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\ci{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\ci{  21}&\co{  22}&   {  23}&\co{  24}&   {  25}&\co{  26}&\ci{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\ci{ 33}&\co{ 34}&   {  35}&\co{  36}&   {  37}&\co{  38}&\ci{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\ci{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\ci{  51}&\co{  52}&   {  53}&\co{  54}&   {  55}&\co{  56}&\ci{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\ci{  63}&\co{  64}\\
   { 65}&\co{ 66}&   {  67}&\co{  68}&\ci{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\ci{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\ci{ 81}&\co{ 82}&   {  83}&\co{  84}&   {  85}&\co{  86}&\ci{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\ci{  93}&\co{  94}&   {  95}&\co{  96}\\
   { 97}&\co{ 98}&\ci{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\ci{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\ci{ 111}&\co{ 112}\\
   {113}&\co{114}&   { 115}&\co{ 116}&\ci{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\ci{ 123}&\co{ 124}&   { 125}&\co{ 126}&   { 127}&\co{ 128}\rlap.
\endmatrix
$$
Repita o processo (o próximo agora seria o $5$) até não tem mais números para tomar.
Os números que ficarão são todos os primos até o $128$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\ci{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\ci{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
   { 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\ci{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\ci{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&   {  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\ci{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&   {  91}&\co{  92}&\co{  93}&\co{  94}&\ci{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\ci{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&   { 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\ci{ 125}&\co{ 126}&   { 127}&\co{ 128}\rlap.
\endmatrix
$$
Tomando o $7$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\ci{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\ci{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\ci{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\ci{ 119}&\co{ 120}&   { 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}\rlap.
\endmatrix
$$
Tomando o $11$:
$$
\matrix
\format
~\r &~\r &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r  &~\r   \\
   {   }&   {  2}&   {   3}&\co{   4}&   {   5}&\co{   6}&   {   7}&\co{   8}&\co{   9}&\co{  10}&   {  11}&\co{  12}&   {  13}&\co{  14}&\co{  15}&\co{  16}\\
   { 17}&\co{ 18}&   {  19}&\co{  20}&\co{  21}&\co{  22}&   {  23}&\co{  24}&\co{  25}&\co{  26}&\co{  27}&\co{  28}&   {  29}&\co{  30}&   {  31}&\co{  32}\\
\co{ 33}&\co{ 34}&\co{  35}&\co{  36}&   {  37}&\co{  38}&\co{  39}&\co{  40}&   {  41}&\co{  42}&   {  43}&\co{  44}&\co{  45}&\co{  46}&   {  47}&\co{  48}\\
\co{ 49}&\co{ 50}&\co{  51}&\co{  52}&   {  53}&\co{  54}&\co{  55}&\co{  56}&\co{  57}&\co{  58}&   {  59}&\co{  60}&   {  61}&\co{  62}&\co{  63}&\co{  64}\\
\co{ 65}&\co{ 66}&   {  67}&\co{  68}&\co{  69}&\co{  70}&   {  71}&\co{  72}&   {  73}&\co{  74}&\co{  75}&\co{  76}&\co{  77}&\co{  78}&   {  79}&\co{  80}\\
\co{ 81}&\co{ 82}&   {  83}&\co{  84}&\co{  85}&\co{  86}&\co{  87}&\co{  88}&   {  89}&\co{  90}&\co{  91}&\co{  92}&\co{  93}&\co{  94}&\co{  95}&\co{  96}\\
   { 97}&\co{ 98}&\co{  99}&\co{ 100}&   { 101}&\co{ 102}&   { 103}&\co{ 104}&\co{ 105}&\co{ 106}&   { 107}&\co{ 108}&   { 109}&\co{ 110}&\co{ 111}&\co{ 112}\\
   {113}&\co{114}&\co{ 115}&\co{ 116}&\co{ 117}&\co{ 118}&\co{ 119}&\co{ 120}&\ci{ 121}&\co{ 122}&\co{ 123}&\co{ 124}&\co{ 125}&\co{ 126}&   { 127}&\co{ 128}\rlap.
\endmatrix
$$
E já podemos parar aqui, certos que os números que ainda ficam na lista, são todos os primos desejados.

%%}}}

%%{{{ Q: Why? 
\question.
%%%{{{ meta 
%%%}}}

Por quê?

%%}}}

\spoiler

%%{{{ x: prime_factor_sqrt_criterion 
\exercise.
%%%{{{ meta 
\label prime_factor_sqrt_criterion
%%%}}}

Seja $a>0$ inteiro composto.
Queremos dizer que \proclaim{$a$ possui fator primo $p \leq {\sqrt a}$}.
Mas como não definimos a $\sqrt \uhole$ nos inteiros, reformulamos nossa afirmação assim:
\proclaim{para todo $x$, se $x^2 > a$, então existe primo $p \leq x$ tal que $p \divides a$}.

\hint
Considere o menor divisor de $a$.
O que pode afirmar sobre ele?

%%}}}

%%{{{ codeit: implement_eratosthenian_algorithm 
\codeit.
%%%{{{ meta 
\label implement_eratosthenian_algorithm
%%%}}}

Implemente o algoritmo de Eratosthenes e o use para achar todos os primos até o $1024$.

%%}}}

\endsection
%%}}}

%%{{{ The_fundamental_theorem_of_arithmetic 
\section O teorema fundamental da aritmética.
%%%{{{ meta 
\label The_fundamental_theorem_of_arithmetic
\credits
    * Euclid : Elementos
    * Gauss : Disquisitiones Arithmeticæ
    ;;
%%%}}}

%%{{{ intro 
\secintro
Chegamos finalmente no resultado principal que esclarecerá
o que percebemos no~\ref[fundamental_theorem_of_arithmetic_omen]:
o~\ref[fundamental_theorem_of_arithmetic],
ilustrado (parcialmente) já por Euclides
(circa~\yearof{300}~a.C.)~nos seus \emph{Elementos}~\cite[elements]
e demonstrado completamente por Gauss (no ano \yearof{1798}) no seu
\emph{Disquisitiones Arithmeticæ}~\cite[disquisitiones].
%%}}}

%%{{{ thm: fundamental_theorem_of_arithmetic 
\theorem Teorema fundamental da aritmética.
%%%{{{ meta 
\headerize
\label fundamental_theorem_of_arithmetic
\indexes
    * teorema!fatoração única    see: fundamental da aritmética
    * teorema!fundamental da aritmética
    * indução!forte
    ;;
\credits
    * Gauss
    * Euclid
    ;;
%%%}}}

Todo inteiro $x\neq 0$ pode ser escrito como um produtório de primos.
Essa expressão é única a menos de sócios e desconsiderando a ordem dos fatores do produtório.

\proof.
Seja $x\in\ints$ com $x > 1$.
\crproofpart {Existência:}
Usamos indução forte (veja~\reftag[int_strong_induction]).
Caso $x$ primo,
trivialmente ele mesmo é o produtório de primos (produtório de tamanho 1).
Caso contrário, $x = ab$, para uns $a,b$ com $1<a<x$ e $1<b<x$,
logo sabemos (hipoteses indutivas) que cada um deles pode ser
escrito na forma desejada:
\mathnote
a &= p_1p_2\dotsb p_{k_a}  \rtext{para alguns $p_i$'s primos;} \\
b &= q_1q_2\dotsb q_{k_b}  \rtext{para alguns $q_j$'s primos.}
\endmathnote
Então temos
$$
x = ab = (p_1p_2\dotsb p_{k_a})(q_1q_2\dotsb )
       = p_1p_2\dotsb p_{k_a}q_1q_2\dotsb q_{k_b}
$$
que realmente é um produtório de primos.
\crproofpart {Unicidade:}
Suponha que para alguns primos $p_i$'s e $q_j$'s, e uns naturais $s,t$, temos:
\mathcol
x &= p_1 p_2 \dotsc p_s,\\
x &= q_1 q_2 \dotsc q_t.
\endmathcol
Vamos mostrar que $s = t$ e que para todo $i\in\set{1,\dotsc,s}$, $p_i = q_j$.
Temos
$$
p_1 p_2 \dotsc p_s = q_1 q_2 \dotsc q_t,
$$
e $p_1$ é primo que divide o lado esquerdo, então divide também o lado direito:
$$
p_1 \divides q_1 q_2 \dotsc q_t.
$$
Pelo \ref[euclid_lemma], $p_1\divides q_{j_1}$ para algum $j_1$.
Mas o $q_{j_1}$, sendo um dos $q_j$'s, também é primo.
Logo $p_1 = q_{j_1}$ (veja~\ref[in_primes_divides_means_equals]).
Cancelando o $p_1$, temos:
$$
p_2 \dotsc p_s = q_1 q_2 \dotsc q_{j_1 - 1} q_{j_1 + 1} q_t,
$$
Agora repetimos até um dos dois lados não ter mais fatores primos.
Necessariamente, isso vai acontecer ``simultaneamente'' nos dois lados
(caso contrário teriamos um produtório
de primos igual com 1, impossível), ou seja: $s = t$.
Note que as equações $p_i = q_{j_i}$ mostram a unicidade desejada.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Graças ao teorema fundamental da aritmética podemos definir a:

%%}}}

%%{{{ df: canonical_representation_of_ints 
\definition Representação canônica de inteiros.
%%%{{{ meta 
\label canonical_representation_of_ints
\defines
    * representação canônica!de inteiro
    ;;
%%%}}}

Seja $0\neq n\in\ints$.
Sua \dterm{representação canônica} é o produtório
$$
n =
(\pm 1)
\Prod_{i=1}^k
p_i^{a_i}
=
(\pm 1)
p_1^{a_1}
p_2^{a_2}
\dotsb
p_k^{a_k},
$$
onde os $p_1 < p_2 < \cdots < p_k$'s são primos, e $a_i\in\nats_{>0}$ para $i=1,\dotsc,k$.
\eop
Observe que se relaxar a restricção nos exponentes tal que $a_i\in\nats$,
cada $n\in\ints$ ($n\neq 0$) pode ser representado (também únicamente) como o produtório
$$
n =
(\pm 1)
\Prod_{i=0}^k
p_i^{a_i}
=
(\pm 1)
p_0^{a_0}
p_1^{a_1}
\dotsb
p_k^{a_k},
$$
onde agora os $p_0 < p_1 < \cdots < p_k$ são \emph{todos os $k+1$ primeiros primos},
sendo então $p_0 = 2$, e $p_k$ o maior primo divisor do $n$.
Chamamos essa forma a \dterm{representação canônica completa} do $n$.
(Veja também o~\ref[encoding_of_finite_sequences].)

%%}}}

\endsection
%%}}}

%%{{{ Valuations_of_ints 
\section Valuações.
%%%{{{ meta 
\label Valuations_of_ints
%%%}}}

%%{{{ intro 
\secintro
Já temos, nos inteiros, um conceito de \emph{tamanho:} $\abs { \uhole }$.
A partir dele, definimos uma idéia de \emph{distância:} $\abs {{\uhole} - {\uhole}}$.
Agora vamos ver uma maneira bem diferente de definir tamanho nos inteiros,
e logo uma nova idéia de distância também.
%%}}}

%%{{{ df: int_valuation 
\definition Valuação.
%%%{{{ meta 
\label int_valuation
\indexes
    * valuação      seealso: primo
    ;;
\defines
    * valuação
    ;;
%%%}}}

Fixe um primo $p$.
Definimos a função $V_p \hastype \Int \to \Int$ pelas
$$
V_p \fa a = \max \setst i {p^i \divides a}.
$$
Chamamos a $V_p$ de \dterm{$p$-valuação}.
Defina o \dterm{tamanho $p$-ádico} e a \dterm{distância $p$-ádica} pelas
\mathcols 2
\normx p a     &\defeq p^{-(V_p~a)}; &
d_p (x,y)      &\defeq \normx p {x - y}.
\endmathcols
Quando o \sq{${}_p$} é óbvio pelo contexto, o omitimos dessas notações.

%%}}}

%%{{{ x: p_valuation_of_zero 
\exercise.
%%%{{{ meta 
\label p_valuation_of_zero
%%%}}}

A \ref[int_valuation] tem um erro.  Ache e corrija!

%%}}}

%%{{{ x: p_valuation_of_sum_and_product 
\exercise.
%%%{{{ meta 
\label p_valuation_of_sum_and_product
%%%}}}

Seja $V$ uma $p$-valuação para algum primo $p$.
Demonstre:
\elist i:
\li: $V \fa (a+b) \geq \min \set {V \fa a, V \fa b}$;
\li: $V \fa (ab) = V \fa a + V \fa b$.
\endelist

%%}}}

%%{{{ x: p_valuation_of_gcd_and_lcm 
\exercise.
%%%{{{ meta 
\label p_valuation_of_gcd_and_lcm
%%%}}}

Seja $V$ uma $p$-valuação para algum primo $p$.
Demonstre:
\elist i:
\li: $V \fa (a,b) = \min \set {V \fa a, V \fa b}$;
\li: $V \fa [a,b] = \max \set {V \fa a, V \fa b}$.
\endelist

%%}}}

%%{{{ x: p_norm_properties 
\exercise.
%%%{{{ meta 
\label p_norm_properties
%%%}}}

Demonstre:
\elist i:
\li: $\norm {ab} = \norm a \norm b$;
\li: $\norm {a + b} \leq \max \set {\norm a, \norm b} \leq \norm a + \norm b$.
\endelist

%%}}}

%%{{{ x: product_of_p_norms 
\exercise.
%%%{{{ meta 
\label product_of_p_norms
%%%}}}

Seja $x$ inteiro.
Demonstre:
$$
\Prod_{\text{$p$ primo}} \normx p x = \frac 1 {\abs x}
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A partir dum primo $p$, definimos a função $d_p$ que chamamos de
distância $p$-ádica, mas devemos demonstrar que ela merece o nome \emph{distância:}

%%}}}

%%{{{ x: p_distance_properties 
\exercise.
%%%{{{ meta 
\label p_distance_properties
\indexes
    * distância          seealso: métrica
    * distância!função
    ;;
%%%}}}

A distância definida a partir da $\normx p \uhole$ realmente
é uma \dterm{função de distância}, ou seja:
\elist i:
\li: $d_p(x,y) \geq 0$;
\li: $d_p(x,y) = 0 \implies x=y$;
\li: $d_p(x,x) = 0$;
\li: $d_p(x,y) = d_p(y,x)$;
\li: $d_p(x,z) \leq d_p(x,y) + d_p(y,z)$.
\endelist

%%}}}

\endsection
%%}}}

%%{{{ Conjectures_in_number_theory 
\section Conjecturas.
%%%{{{ meta 
\label Conjectures_in_number_theory
%%%}}}

\TODO definir a função Collatz.

%%{{{ conjecture: collatz_conjecture 
\conjecture Collatz.
%%%{{{ meta 
\label collatz_conjecture
\credits
    * Collatz : conjectura
    ;;
\defines
    * conjectura!de Collatz
    ;;
%%%}}}

A função definida acima é total e (logo) igual à constante $\lam x 1$.

%%}}}

%%{{{ Goldbach 
\note Goldbach.
%%%{{{ meta 
\credits
    * Goldbach
    * Euler
    ;;
%%%}}}

No ano \yearof{1742} Goldbach comunicou para Euler
as conjecturas seguintes:

%%}}}

%%{{{ conjecture: weak_goldbach_conjecture 
\conjecture fraca de Goldbach.
%%%{{{ meta 
\label weak_goldbach_conjecture
\credits
    * Goldbach : conjectura
    ;;
\defines
    * conjectura!de Goldbach
    ;;
%%%}}}

Todo número maior que $5$ pode ser escrito como soma de três primos.

%%}}}

%%{{{ conjecture: goldbach_conjecture 
\conjecture Goldbach.
%%%{{{ meta 
\label goldbach_conjecture
\credits
    * Goldbach : conjectura
    ;;
\defines
    * conjectura!de Goldbach
    ;;
%%%}}}

Todo número par maior que $2$ pode ser escrito como soma de dois primos.

%%}}}

%%{{{ df: twin_prime 
\definition Primos gêmeos.
%%%{{{ meta 
\label twin_prime
%%%}}}

Seja $p$ inteiro.  Dizemos que $p$ é um primo gémeo sse ambos os $p,p+2$ são primos.

%%}}}

%%{{{ conjecture: twin_primes_conjecture 
\conjecture Twin primes.
%%%{{{ meta 
\label twin_primes_conjecture
\defines
    * conjectura!dos primos gêmeos
    ;;
%%%}}}

Existe uma infinidade de primos gêmeos.

%%}}}

%%{{{ conjecture: legendre_conjecture 
\conjecture Legendre.
%%%{{{ meta 
\label legendre_conjecture
\credits
    * Legendre : conjectura
    ;;
\defines
    * conjectura!de Legendre
    ;;
%%%}}}

Para todo $n > 0$, existe primo entre $n^2$ e $(n+1)^2$.

%%}}}

%%{{{ Wiles_theorem_Fermat_conjecture 
\theorem Wiles (conjectura de Fermat).
%%%{{{ meta 
\label Wiles_theorem_Fermat_conjecture
\credits
    * Wiles : teorema
    * Fermat : conjectura
    ;;
%%%}}}

Para qualquer $n > 2$, não existem inteiros $a,b,c > 0$ que satisfazem a equação
$$
a^n + b^n = c^n.
$$

\proof Demonstrado.
A artilharia utilizada para matar este teorema fica
\emph{muito} fora do nosso alcance (e com certeza do Fermat também!
O artigo principal é o \cite[wiles95] (101 páginas!),
e o \cite[taylorwiles95] completa o que faltou para consertar
e finalizar a demonstração.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_induction 
\problem.
%%%{{{ meta 
\label euclidean_algorithm_correctness_formal_proof_by_induction
\pdefs
    \pdef euclid {{\algorithmstylize{Euclid}}}
    ;;
%%%}}}

Como tu percebeu resolvendo o~\ref[euclidean_algorithm_proof_why_informal],
nenhuma das duas partes do~\ref[euclidean_algorithm_correctness]
foi demonstrada mesmo.
Demonstre as duas partes usando indução.

\hint
Precisa expressar o alvo na forma $\lforall n {\phi(n)}$.

\hint
``\emph{Para todo $x\in\ints$, o $\euclid(x,n)$ termina com o resultado certo}.''

\hint
O que significaria $\phi(0)$?  $\phi(b)$?

\hint
Ser forte é coisa boa.

\solution
Seja
$$
\phi(n) \defiff \lforall {x\in\ints} {\text{$\euclid(x,n)$ termina com $\gcd x n$}}
$$
Vamos demonstrar que $\lforall {n\in\nats} {\phi(n)}$ por indução forte.
Seja $k\in\nats$ tal que $\phi(i)$ para todo $i<k$ (hipótese indutiva).
Precisamos demonstrar o $\phi(k)$, ou seja, que
\emph{para todo $x\in\ints$, $\euclid(x,k)$ termina e $\euclid(x,k) = \gcd x k$}.
Seja $x\in\ints$, e aplica o $\euclid(x,k)$ para um passo.
Se $k=0$, a computação termina imediatamente com o resultado $x$, que é correto
(\reftag[gcd_of_comparable]).
Se $k>0$, o algoritmo manda reduzir sua computação para a computação do $\euclid(k,r)$,
onde $r = x \bmod k < k$.
Seguindo o~\ref[euclid_gcd_lemma] $\gcd x k = \gcd k r$, então
falta verificar que o $\euclid(k,r)$ termina mesmo com $\gcd k r$,
que segue pela hipótese indutiva porque $r < k$ e logo $\phi(r)$ é válido.

%%}}}

%%{{{ prob: euclidean_algorithm_correctness_formal_proof_by_wop 
\problem.
%%%{{{ meta 
\label euclidean_algorithm_correctness_formal_proof_by_wop
%%%}}}

Demonstre as duas partes
do~\ref[euclidean_algorithm_correctness] usando o princípio da boa ordem.

\hint
Considera as duas partes separamente:
qual conjunto é o não vazio em cada parte?

\hint
Vai pelo absurdo.

\hint
O que seria um contraxemplo para cada parte?
\emph{O que acontece se existem contraexemplos?}

\hint
Sobre sua terminação:
Considere o menor $m$ tal que o $\euclid(x,m)$ não termina
para algum $x\in\ints$.

\hint
Sobre sua corretude:
Considere o menor $m$ tal que o $\euclid(x,m)$
termina com resultado errado par algum $x\in\ints$.
Mas mostre primeiro a terminação.

\solution
Demonstramos cada parte separamente:
\crtabproofpart {Terminação.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\euclid(a,c)$
não termina para algum $x\in\ints$.}
Seja $m$ o menor deles (PBO):
$$
m = \min\setst {c\in\nats} {\lexistst {x\in\ints} {$\euclid(x,c)$ não termina}}.
$$
Logo, para algum certo $a\in\ints$, temos que $\euclid(a,m)$ não termina.
Com certeza $m\neq 0$, porque nesse caso o algoritmo termina imediatamente.
Logo $m > 0$ e aplicando o $\euclid(a,m)$ para apenas um passo
a sua computação é reduzida no computação do $\euclid(m,r)$,
onde $r = a \bmod m < m$, \emph{e agora precisamos mostrar que o
$\euclid(m,r)$ termina para chegar num absurdo}.
Pela escolha do $m$ como \emph{mínimo} dos contraexemplos,
o $r$ não pode ser contraexemplo também.
Em outras palavras, o $\euclid(x,r)$ realmente termina para qualquer $x$,
então para $x=m$ também, que foi o que queríamos demonstrar.
\crtabproofpart {Corretude.}
Para chegar num absurdo, suponha que existem contraexemplos:
\emph{inteiros $c\geq0$, tais que o $\euclid(x,c)$
acha resultado errado para algum $x\in\ints$.}
Seja $m$ o menor desses contraexemplos (PBO):
$$
m = \min\setst {c\in\nats} {\lexists {x\in\ints} {\euclid(x,c) \neq \gcd x c}}.
$$
Logo, para algum certo $a\in\ints$, temos $\euclid(a,m) \neq \gcd a m$.
Esse $m$ não pode ser $0$, porque nesse caso o algoritmo retorna sua primeira entrada $a$;
resultado correto por causa do~\ref[gcd_of_comparable].
Então $m>0$.
Aplicamos para um passo o $\euclid(a,m)$.
Como $m\neq 0$, o algoritmo manda realizar o segundo passo:
retornar o que $\euclid(m,r)$, onde $r = a \bmod m < m$.
(E sabemos que o $\euclid(m,r)$ vai retornar algo, porque
já demonstramos a terminação do algoritmo para todas as suas possíveis entradas!)
Para concluir, observe:
\compute
\euclid(m,r) 
&= \euclid(a,m)     \by {pelas instruções do algoritmo} \\
&\neq \gcd a m      \by {escolha dos $m$ e $a$} \\
&= \gcd m r.        \by {pelo~\ref[euclid_gcd_lemma]} \\
\endcompute
Então $\euclid(m,r) \neq \gcd m r$ e achamos um contraexemplo (o $r$)
menor que o mínimo (o $m$)---absurdo!

%%}}}

%%{{{ prob: p_divides_comb_p_r 
\problem.
%%%{{{ meta 
\label p_divides_comb_p_r
%%%}}}

Para todo $p$ primo, e todo $r\in\set{1,\dotsc,p-1}$,
$$
p \divides \comb p r.
$$
O que acontece se $r=0$ ou $r \geq p$?

\hint
$\comb p r \in\ints$, $r < p$, e $p-r < p$.

%%}}}

%%{{{ prob: implications_with_divisibility_of_linear_combinations_generalization 
\problem.
%%%{{{ meta 
\label implications_with_divisibility_of_linear_combinations_generalization
%%%}}}

(Generalização do~\ref[implications_with_divisibility_of_linear_combinations].)
Para quais $u,v\in\ints$, a afirmação
$$
a \divides b + c \mland a \divides ub + vc \implies a \divides xb + yc \quad \text{para todos $x,y\in\ints$}
$$
é válida?

%%}}}

%%{{{ prob: factorial_bound_for_prime 
\problem.
%%%{{{ meta 
\label factorial_bound_for_prime
%%%}}}

Seja $n\in\nats$, $n>1$.
Entre $n$ e $n!$ existe primo.

\hint
Olhe para o $n!-1$.

\hint
Se $n!-1$ não é primo, toma um dos seus primos divisores, $p$.

\hint
Necessariamente $p > n$.

%%}}}

%%{{{ prob: n consecutive composite numbers 
\problem.
%%%{{{ meta 
%%%}}}

Seja $n\in\nats$.
Ache $n$ consecutivos números compostos.

\hint
$!$

\hint
$m!+2$.

\hint
$m!+3$\dots

\hint
$m!+m$.

%%}}}

%%{{{ prob: gcd_alternative_definition 
\problem {Definição alternativa de mdc}.
%%%{{{ meta 
\label gcd_alternative_definition
%%%}}}

Uma definição alternativa do mdc é a seguinte:
{\it Sejam $a,b\in\ints$.
O mdc dos $a$ e $b$ é o maior dos divisores em comum de $a$ e $b$.}
Ache um problema com essa definição, corrige-o, e depois compare
com a \ref[the_gcd].

\hint
O que acontece se $a=b=0$?
O que acontece se pelo menos um dos $a$ e $b$ não é o $0$?

\solution
Se $a=b=0$, o símbolo $\gcd a b$ não é definido,
porque todo $n\in\nats$ é um divisor em comum,
mas como o $\nats$ não tem um elemento máximo,
não existe o maior deles.
\eop
Precisamos restringir a definição para ser aplicável
apenas nos casos onde pelo menos um dos $a$ e $b$
não é o $0$ (escrevemos isso curtamente: $ab\neq 0$).
Assim, quando a nova definição é aplicável, ela realmente
defina o mesmo número, fato que segue pelas propriedades:
$$
\align
\gcd x 0 = 0 &\implies x = 0\\
x \divides y \mland y \neq 0 &\implies \abs x \leq \abs y.
\endalign
$$

%%}}}

%%{{{ prob: partitioning_restricted_best_strategy_parallel 
\problem Contando os passos.
%%%{{{ meta 
\label partitioning_restricted_best_strategy_parallel
%%%}}}

O que muda no~\ref[partitioning_restricted_best_strategy]
se em cada passo podemos quebrar todos os termos que aparecem?
Qual é a melhor estratégia, e quantos passos são necessários?

\hint
Tente quebrar o $10$ usando várias estratégias.
O que tu percebes?

\hint
Qual é o maior termo e como ele muda depois cada passo?

\solution
Agora a estratégia ótima seria quebrar cada termo ``no meio''.
Assim, para o $10$ temos:
$$
\align
10 &= 5 + 5\\
   &= (2 + 3) + (2 + 3)\\
   &= [(1 + 1) + (1 + 2)] + [(1 + 1) + (1 + 2)]\\
   &= 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1
\endalign
$$
em apenas $4$ pássos.
Depois de cada passo, se o maior termo fosse o $m$, agora é o $\ceil {\frac m 2}$.
Precisamos tantos passos quantas vezes que podemos dividir o $n$ por $2$ até
chegar na unidade $1$: precisamos $\ceil {\log_2(n)}$ passos.

%%}}}

%%{{{ prob: encoding_of_finite_sequences 
\problem Codificação de seqüências finitas.
%%%{{{ meta 
\label encoding_of_finite_sequences
%%%}}}

Seja $S$ o conjunto de seqüências finitas de números naturais.
Descreva uma método para ``codificar'' os elementos de $S$
com os elementos de $\nats\setminus\set0$.
Tua método deve ser uma \emph{revertível}, no sentido que
cada seqüência finita
$$
s = \tup{s_0,s_1,\dotsc,s_{k_s}}\in S
$$
deve corresponder em exatamente um número natural $n_s\in\nats\setminus\set0$,
e, dado esse número $n_s\in\nats_{>0}$, deveria ser possível ``extrair''
a seqüência $s$ cuja codificação é o $n_s$.
Não se preocupe se existem naturais que não são codificações de nenhuma
seqüência.

\hint
Use o teorema fundamental da aritmética~(\reftag[fundamental_theorem_of_arithmetic]).

\hint
Seja $p_i$ o $i$-ésimo primo ($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
Como podemos escrever o aleatório $n\in\nats$?

\hint
Olha nos exponentes na forma
$
n =
p_0^{a_0}
p_1^{a_1}
p_2^{a_2}
\cdots
p_{k_n}^{a_{k_n}}
$.

\hint
Teste tua codificação nas seqüências $\tup{1,3}$ e $\tup{1,3,0}$.
Como essas seqüências são diferentes, suas codificações devem ser diferentes também.
E a seqüência vazia $\tup{}\in S$?  

\solution
Seja
$$
p_0 < p_1 < p_2 < p_3 < \dotsb
$$
a seqüência infinita dos primos.  (Assim, $p_0 = 2$, $p_1 = 3$, $p_2 = 5$, etc.)
Seja
$$
\tup{s_0, s_1, \dotsc, s_{n-1}} \in S
$$
uma seqüência de naturais de tamanho $n$.
Vamos codificá-la com o inteiro
$$
c_s
= \Prod_{i=0}^{n-1} p_i^{s_i + 1}
= p_0^{s_0 + 1} p_1^{s_1 + 1} p_2^{s_2 + 1} \cdots p_{n-1}^{s_{n-1} + 1}.
$$
(Note que a seqüência vazia ($n=0$) correponde no número $1\in\nats_{>0}$.)
\eop
Conversamente, dado um número $c\in\nats_{>0}$ que codifica uma seqüência,
como podemos ``decodificar'' a seqüência que corresponda com ele?
Graças o teorema fundamental da aritmética~(\reftag[fundamental_theorem_of_arithmetic]),
temos
$$
c = p_0^{a_0} p_1^{a_1} \cdots p_{m-1}^{a_{m-1}}.
$$
Se existe exponente $a_j = 0$, o $c$ não codifica nenhuma seqüência.
Caso contrário, todos os exponentes são positivos, e o $c$ codifica
a seqüência
$$
\tup{a_0-1, a_1-1, \dotsc, a_m-1} \in S.
$$

%%}}}

%%{{{ prob: canonical_representation_of_rats 
\problem Representação canônica de racionais.
%%%{{{ meta 
\label canonical_representation_of_rats
%%%}}}

Generalize a representação canônica de inteiros para racionais.

\hint
Qual foi tua resposta no~\ref[canonical_representation_with_int_exponents]?

%%}}}

%%{{{ prob: p_valuation_based_form 
\problem.
%%%{{{ meta 
\label p_valuation_based_form
%%%}}}

Seja $V \hastype \Int \to \Int$ tal que goza das propriedades
do~\ref[p_valuation_of_sum_and_product]:
\elist i:
\li: $V (a+b) \geq \min \set {V \fa a, V \fa b}$;
\li: $V (ab) = V \fa a + V \fa b$.
\endelist
Demonstre que existem inteiro $c$ e primo $p$ tais que $V = cV_p$, onde
$$
V = cV_p \intiff \lforall a {V(a) = cV_p(a)}.
$$

\hint
Comece achando um $p$ tal que $V(p) > 0$.

%%}}}

\endproblems
%%}}}

%%{{{ The idea behind congruence relation 
\section A idéia da relação de congruência.
%%%{{{ meta 
%%%}}}

\TODO pintar com cores, metáfora de times, planetas.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos fixar um inteiro positivo $m$.
Agora graças à divisão de Euclides~(\reftag[euclidean_division]),
qualquer inteiro $a$ pode ser escrito na forma
\mathcols 2
&a = mk + r, &
&0 \leq r < m,
\endmathcols
num jeito único, ou seja, os inteiros $k,r$ são determinados
pelos $a,m$.
\eop
Enquanto investigando a (ir)racionalidade dos $\sqrt 2$, $\sqrt 3$, $\sqrt {\vphantom3 m}$,
etc., nós percebemos que foi útil separar os inteiros em classes,
``agrupando'' aqueles que compartilham o mesmo resto quando divididos por $m$.
Trabalhando com essa idéia nós encontramos nosso primeiro contato com
\emph{aritmética modular}.\foot
Mentira.  Não foi o primeiro não: somos todos acostumados com
aritmética modular mesmo sem perceber.  Um desses contatos é por causa de ter
que contar com horas e relógios, cuja aritmética não parece muito com aquela
dos inteiros.  Por exemplo: $21 + 5 = 26$, mas se agora são 21h00, que horas
serão depois de 5 horas?  Nossos relógios não vou mostrar 26h00, mas 02h00.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Two almost equivalent definitions 
\section Duas definições quase equivalentes.
%%%{{{ meta 
%%%}}}

\TODO reescrever para corresponder à seção anterior.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Precisamos definir formalmente a noção informal de \emph{\dq{dois inteiros $a$
e $b$ pertencem à mesma classe, quando separamos eles em times usando o
inteiro $m$}}.
A primeira coisa que precisamos perceber é que essa frase é uma afirmação sobre $3$ inteiros.
Queremos então uma definição e uma notação que captura essa relação \emph{de aridade $3$}.

%%}}}

%%{{{ Congruences intuitively 
\note Congruência intuitivamente.
%%%{{{ meta 
%%%}}}

Chamamos dois inteiros \dterm{congruentes} módulo um terceiro inteiro,
sse eles têm o mesmo resto, quando divididos por ele.

%%}}}

%%{{{ Critique 
\note Crítica.
%%%{{{ meta 
%%%}}}

Primeiramente, o texto da definição é bem informal e ambíguo.
Para tirar essas ambigüidades, precisamos introduzir variáveis para
referir sobre os \dq{mesmos restos}:

%%}}}

%%{{{ df: congruence_intuitive_definition 
\definition Intuitiva.
%%%{{{ meta 
\label congruence_intuitive_definition
%%%}}}

Sejam $a,b,m$ inteiros com $m>0$, e sejam $q_a$, $r_a$, $q_b$, e $r_b$
os inteiros determinados pelas divisões:
\mathcols 2
a &= mq_a + r_a   && 0 \leq r_a < m \\
b &= mq_b + r_b   && 0 \leq r_b < m.
\endmathcols
Digamos que os $a$ e $b$ são \dterm{congruentes} módulo~$m$,
sse $r_a = r_b$.

%%}}}

%%{{{ remark: from_same_remainders_to_divides_the_diference 
\remark.
%%%{{{ meta 
\label from_same_remainders_to_divides_the_diference
%%%}}}

Olhando para dois números $a$ e $b$, congruêntes módulo~$m$,
o que podemos dizer sobre a diferença deles?
Observe:
$$
\rightbrace {
\aligned
a - b
&= (mq_a + r_a) - (mq_b + r_b)\\
&= mq_a - mq_b + r_a - r_b\\
&= m(q_a - q_b) + (r_a - r_b)\\
&= m(q_a - q_b) + 0\\
&= m(q_a - q_b)
\endaligned
}
\qquad
\aligned
\text{ou seja, $m \divides a - b$.}
\endaligned
$$
Essa observação nos mostra um caminho mais curto e elegante para definir o mesmo
conceito.  É o seguinte:

%%}}}

%%{{{ df: congruence_modulo_int 
\definition Congruência (Gauss).
%%%{{{ meta 
\label congruence_modulo_int
\credits
    * Gauss : definição de congruência
    ;;
\defines
    * ~a \cong {~b} \pmod {~m}  -- $a$ é congruente com $b$ módulo $m$
    * congruência
    * módulo
    ;;
%%%}}}

Sejam $a,b,m\in\ints$ com $m>0$.
Digamos que os $a$ e $b$ são \dterm{congruentes} \dterm{módulo} $m$,
sse $m \divides a - b$.
Em símbolos, escrevemos
$$
a \cong b \pmod m
\defiff m \divides a - b
$$
e lemos: \emph{o $a$ é congruente com $b$ módulo~$m$}.

%%}}}

%%{{{ beware: cong_mod_is_a_ternary_relation 
\beware.
%%%{{{ meta \label cong_mod_is_a_ternary_relation
%%%}}}

A notação de congruência às vezes iluda de ser interpretada como se fosse
uma relação entre o lado esquerdo $L$ e o lado direito $R$, assim:
$$
\tubrace {a} {L} \cong \tubrace {b \pmod m} {R}.
$$
\emph{Não!}
Principalmente, o lado direito, $b \pmod m$, nem é definido, então não tem significado,
e nem faz sentido afirmar algo sobre ele.
Prestando mais atenção, percebemos que o $\hole \cong \hole$ também não foi definido!
O que nós definimos foi o:
$$
\holed u \cong \holed v \pmod {\holed w}
$$
dados $u,v,w\in\ints$ com $w>1$.

%%}}}

%%{{{ notation: a ≡ₘ b 
\note Notação.
%%%{{{ meta 
%%%}}}

Talvez ficaria mais intuitivo (e menos confúso) usar a notação
$$
a \congmod m b \defiff a \cong b \pmod m
$$
que introduzimos aqui pois às vezes ajuda.
Mas a notação mais usada é a da \ref[congruence_modulo_int]

%%}}}

%%{{{ Intuition 
\note Intuição.
%%%{{{ meta 
%%%}}}

Se precisamos para algum motivo pessoal---porque sim---separar mentalmente a
notação de congruência em dois lados, o único jeito que faz algum sentido
seria o:
$$
\tubrace {\mathstrut a \cong b} {L}
\quad
\tubrace {\!\!\pmod m} {R}.
$$
Assim, entendemos que ``algo acontece'' (lado $L$), ``dentro algo'' (lado $R$),
onde ``algo acontece'' seria ``o $a$ \emph{parece} com $b$'',
e ``dentro algo'' seria ``módulo~$m$''.
Mas, claramente tudo isso é apenas uma guia (caso que queremos)
e nada mais que isso.  Para argumentar sobre a relação de congruência,
usamos \emph{apenas sua definição formal!}

%%}}}

%%{{{ blah: to use both definitions so we must prove their equivalence 
\blah.
%%%{{{ meta 
%%%}}}

Para ganhar o direito de usar qualquer uma das duas definições, precisamos
mostrar que são equivalentes:

%%}}}

%%{{{ thm: cong_mod_equivalence_of_definitions 
\theorem Equivalência das duas definições.
%%%{{{ meta 
\label cong_mod_equivalence_of_definitions
%%%}}}

Sejam $a,b,m\in\ints$ com $m>0$, e sejam $q_a, r_a, q_b, r_b\in\ints$
os números determinados por as divisões:
$$
\alignat 2
a &= mq_a + r_a     &\qquad& 0 \leq r_a < m\\
b &= mq_b + r_b     && 0 \leq r_b < m
\endalignat
$$
Temos a equivalência:
$$
a \cong b \pmod m
\iff
r_a = r_b.
$$

\sketch.
Precisamos mostrar as duas direções do \bidir.
A direção \rldir, é practicamente
a~\ref[from_same_remainders_to_divides_the_diference].
Para a direção \lrdir, vamos mostrar que $r_a - r_b = 0$.
Usamos a hipótese e propriedades de~$(\divides)$
para mostrar que $m \divides r_a - r_b$,
e depois as duas desigualdades para confirmar que, com suas restricções,
o único inteiro múltiplo de $m$ que as satisfaz é o~$0$.

\proof.
Precisamos mostrar as duas direções do \bidir:
\eop
\lrdir:
Suponha que
$a \cong b \pmod m$, ou seja,
$m \divides a - b$.
Resolvendo as duas equações das divisões por os restos $r_a$ e $r_b$,
temos:
$$
\rightbrace {
\aligned
r_a &= a - mq_a \\
r_b &= b - mq_b 
\endaligned
}
\implies
\aligned
r_a - r_b
&= (a - mq_a) - (b - mq_b)\\
&= (a - b) - (mq_a - mq_b)\\
&= (a - b) - m(q_a - q_b).
\endaligned
$$
Observe que $m \divides a-b$ e $m \divides m(q_a - q_b)$.
Então $m$ tem que dividir a diferença deles também:
$$
m \divides \mubrace {(a - b) - m(q_a - q_b)} {\dsize r_a - r_b}
$$
Usando as duas desigualdades: $0 \leq \abs{r_a - r_b} < m$.
Como $\abs{r_a-r_b}$ é um múltiplo de $m$, concluimos que necessariamente
$0 = \abs{r_a - r_b}$, ou seja: $r_a = r_b$.
\eop
\rldir:
Suponha que $r_a = r_b$.
Temos:
\compute
a - b
&= (mq_a + r_a) - (mq_b + r_b)  \\
&= (mq_a - mq_b) - (r_a - r_b)  \\
&= (mq_a - mq_b) - 0            \by {hipótese} \\
&= m(q_a - q_b),
\endcompute
e como $q_a - q_b\in\ints$,
concluimos que
$m \divides a - b$, ou seja:
$a \cong b \pmod m$.

%%}}}

%%{{{ beware: binary_mod 
\beware A operação binária ``mod''.
%%%{{{ meta 
\label binary_mod
%%%}}}

Em linguagens de programação é comum encontrar o operador \emph{binário}
``mod'', frequentemente denotado com o símbolo \symq{\code \%}.
Em matemática, essa função \emph{binária} (aridade 2) é mais
encontrada como \symq{$\bmod$} mesmo.
Cuidado não confundir a \emph{função}
$\bmod : \ints\times\nats_{>0} \to \nats$
com a \emph{relação} $a \cong b \pmod m$.
Faz sentido escrever:
$$
69 \bmod 5 = 4.
$$
Isso significa apenas que o resto da divisão de 69 por 5, é 4.
Por outro lado, nenhuma das expressões abaixo tem significado!:
$$
69 \pmod 5 = 4
\qquad\qquad
4 = 69 \pmod 5
$$

%%}}}

%%{{{ x: explain_the_type_of_bmod 
\exercise.
%%%{{{ meta 
\label explain_the_type_of_bmod
%%%}}}

Explique o tipo da função $\bmod : \ints\times\nats_{>0} \to \nats$.

\hint
Qual seria o valor de $4 \bmod 0$?

\solution
Pelo~\ref[euclidean_division],
precisamos $b \neq 0$ para definir a divisão de $a$ por $b$.

%%}}}

%%{{{ x: mod_vs_mod 
\exercise mod \vs mod.
%%%{{{ meta 
\label mod_vs_mod
%%%}}}

Para cada uma das expressões abaixo uma das três opções é válida:
(a) ela denota um termo;
(b) ela denota uma afirmação; ou
(c) ela não tem significado.
Para cada expressão, decida qual é a opção certa e:
se for a (a), ache o seu valor (qual objeto ela denota);
se for a (b), ache se é válida ou não.
% TODO: fix reflabs
\elist 1:
\li: $69 \pmod 5 = 4$
\li: $12 = 3 \pmod 8 $
\li: $12 \cong 20 \pmod 4 $
\li: $8 \pmod 3 \cong 12$
\li: $108 \cong 208 \pmod {(43 \bmod 30)}$
\li: $x \bmod 4 = 2 \implies x \cong 0 \pmod 2$
\li: $5^{192\,\bmod\,3}$
\li: $13\pmod 8 \cong 23 \pmod {18}$
\endelist

\solution
Vamo lá:
\elist 1:
\li:
$69 \pmod 5 = 4$ não significa nada.
\li:
$12 = 3 \pmod 8$ não significa nada.\foot
Se o \symq{$=$} fosse \symq{$\cong$}, então significaria que $8 \divides 12 - 3 = 9$ (que é falso).
\toof
\li:
$12 \cong 20 \pmod 4$ significa $4 \divides 12 - 20 = -8$, que é válido.
\li:
$8 \pmod 3 \cong 12$ não significa nada.
\li:
$108 \cong 208 \pmod {(43 \bmod 30)}$ significa que $43\bmod 30 \divides 108 - 208$,
e para decidir se é válida ou não, calculamos $43\bmod 30 = 13$,
e $108 - 208 = -100$ e substituimos: $13 \divides -100$, que é falso.
\li:
$\lforall {x\in\ints} {x \bmod 4 = 2 \limplies x \cong 0 \pmod 2}$
denota a afirmação que para todo $x\in\ints$,
se $x \bmod 4 = 2$ então $x \cong 0 \pmod 2$, que é válido:
seja $x\in\ints$ tal que $x \bmod 4 = 2$.
Logo $x = 4k + 2 = 2(2k + 1)$ para algum $k\in\ints$,
ou seja, $2 \divides x = x - 0$.
\li:
$5^{192 \bmod 3}$ é o número 5 elevado ao resto da divisão de 192 por 3.
Como $3 \divides 192$ (por quê?  1 + 9 + 2 = 12; 1 + 2 = 3;
veja o~\ref[divisibility_criterion_3_9]), temos $192 \bmod 3 = 0$,
então o valor da expressão é o número $5^0 = 1$.
\li:
$13\pmod 8 \cong 23 \pmod {18}$ não significa nada.
\endelist

%%}}}

\endsection
%%}}}

%%{{{ Modular arithmetic 
\section Aritmética modular.
%%%{{{ meta 
%%%}}}

%%{{{ Fixing an $m$ 
\note Fixando um $m$.
%%%{{{ meta 
%%%}}}

Observe que
\mathcol
\hole \cong \hole \pmod \hole &\hastype \Int \times \Int \times \Int \to \Prop.
\intertext{Ou seja, se trata duma relação \emph{ternária}.
Naturalmente, fixando um inteiro $m$, a expressão}
\hole \cong \hole \pmod m     &\hastype \Int \times \Int \to \Prop.
\endmathcol
é uma relação binária que chamamos de \dterm{congruência módulo~$m$} e denotamos
também por $(\congmod m)$.
Suas propriedades investigamos agora.

%%}}}

%%{{{ thm: congruence_mod_m_is_an_eqrel 
\theorem relação de equivalência.
%%%{{{ meta 
\label congruence_mod_m_is_an_eqrel
%%%}}}

Fixe um inteiro $m$.
Para todos os inteiros $a,b,c$, temos:
\mathcall
(1)\quad&a \congmod m a                                               \called {(reflexividade)} \\
(2)\quad&a \congmod m b \mland b \congmod m c \implies a \congmod m c \called {(transitividade)} \\
(3)\quad&a \congmod m b \implies b \congmod m a.                      \called {(simetria)}
\endmathcall

\sketch.
Todas são facilmente demonstradas aplicando diretamente
a definição de congruência módulo~$m$ (\reftag[congruence_modulo_int])
e as propriedades básicas da $(\divides)$.

\proof.
(1) Segue imediatamente pois $m \divides a - a = 0$.
(2) Pela hipótese temos $m \divides a - b$ e $m \divides b - c$.
Então pelo~\ref[divides_linear_combinations] $m \divides (a-b) + (b-c) = a-c$.
(3) Pela hipótese temos $m \divides a - b$\thinspace;
logo (\reftag[divides_linear_combinations] de novo) $m \divides -(a - b) = b - a$.

%%}}}

%%{{{ remark: equivalence relation 
\remark.
%%%{{{ meta 
\indexes
    * relação!de equivalência
    ;;
%%%}}}

Uma relação que satisfaz essas três propriedades é chamada
\dterm{relação de equivalência}~(\reftag[Equivalence_relations]).
Ou seja, o \ref[congruence_mod_m_is_an_eqrel] que acabamos de demonstrar
afirma simplesmente que \proclaim{$(\congmod m)$ é uma relação de equivalência}.
Estudamos relações no~\ref[Relations].  Paciência!

%%}}}

%%{{{ prop: modular_arithmetic_properties 
\property.
%%%{{{ meta 
\label modular_arithmetic_properties
%%%}}}

Se $a \cong b \pmod m$, então para todo $x\in\ints$ temos:
$$
(1)\quad a + x \cong b + x   \pmod m;
\quad\enspace
(2)\quad ax \cong bx         \pmod m;
\quad\enspace
(3)\quad -a \cong -b         \pmod m.
$$

\sketch.
Todas seguem facilmente pela definição (\reftag[congruence_modulo_int]) de congruência módulo~$m$.

%%}}}

%%{{{ thm: congruence_mod_m_is_a_congruence 
\theorem congruência.
%%%{{{ meta 
\label congruence_mod_m_is_a_congruence
%%%}}}

Fixe um inteiro $m$.
Sejam $a,a',b,b'$ tais que $a \congmod m a'$ e $b \congmod m b'$.
Logo:
\mathcall
(1)\quad&a + b \congmod m a' + b'              \called {$(+)$-compatível} \\
(2)\quad&a \ntimes b \congmod m a' \ntimes b'  \called {$(\ntimes)$-compatível} \\
(3)\quad&-a \congmod m -a'.                    \called {$(-{\uhole})$-compatível}
\endmathcall

\proof Demonstrarás agora.
\ref[congruence_mod_m_is_a_congruence_proof].

%%}}}

%%{{{ x: congruence_mod_m_is_a_congruence_proof 
\exercise.
%%%{{{ meta 
\label congruence_mod_m_is_a_congruence_proof
%%%}}}

Demonstre o \ref[congruence_mod_m_is_a_congruence].

%%}}}

%%{{{ congruences_first_contact 
\note Congruências.
%%%{{{ meta 
\label congruences_first_contact 
%%%}}}

O que foi isso?
Efetivamente, o \ref[congruence_mod_m_is_a_congruence]
está nos permitindo substituir congruentes por congruentes em qualquer
expressão de soma, de multiplicação, e de negação, garantindo que o novo resultado
vai ser congruente ao original.

%%}}}

%%{{{ x: from_mod_m_to_mod_am 
\exercise.
%%%{{{ meta 
\label from_mod_m_to_mod_am
%%%}}}

Suponha que $x \cong t \pmod m$, e seja $a$ um inteiro positivo.
O que podemos concluir sobre o $x$ módulo~$ma$?

\hint
Use as definições de congruência (\reftag[congruence_modulo_int]) e de $(\divides)$ (\reftag[divides])
para escrever o $x$ na forma $x = mk + t$.

\hint
Agora divida o $k$ por $a$.

\solution
Pela definição de congruência (\reftag[congruence_modulo_int]) e de $(\divides)$ (\reftag[divides]) temos que:
$$
\align
x &= mk + t, \quad\text{para algum $k$ inteiro}.
\intertext{Dividindo o $k$ por $a$,
temos $k = aq + i$, onde $q,i\in\ints$ e $0\leq i < a$.  Substituindo:}
x &= m(aq + i) + t\\
  &= maq + (mi + t).
\intertext{Logo, chegamos nas $a$ congruências}
x &\cong mi + t \pmod{ma}, \quad\text{para $i=0,\dotsc,a-1$},
\endalign
$$
e $x$ tem que satisfazer (exatamente) uma delas.

%%}}}

%%{{{ x: from_equality_to_congruence 
\exercise De igualdades para congruências.
%%%{{{ meta 
\label from_equality_to_congruence
%%%}}}

Sejam $a,b$ inteiros.
Se $a = b$, então $a \congmod m b$ para qualquer inteiro $m$.

%%}}}

%%{{{ x: from_congruence_to_equality 
\exercise De congruências para igualdades?.
%%%{{{ meta 
\label from_congruece_to_equality
%%%}}}

Há inteiros $m$ tais que o recíproco é válido?
Ou seja, tais que podemos inferir $a = b$ a partir de apenas $a \congmod m b$.

%%}}}

\endsection
%%}}}

%%{{{ Inverses and cancellations 
\section Inversos e cancelamentos.
%%%{{{ meta 
%%%}}}

%%{{{ df: inverse_modulo_m 
\definition Inverso.
%%%{{{ meta 
\label inverse_modulo_m
\defines
    * ~a^{-1}  -- o inverso (multiplicativo) do $a$ (módulo~$m$)
    * inverso!multiplicativo módulo~$m$
    ;;
%%%}}}

Seja $a,a',m\in\ints$.
Chamamos $a'$ \dterm{um inverso (multiplicativo) de $a$ módulo~$m$},
sse
$$
aa' \cong 1 \pmod m.
$$
Se existe inverso do $a$, o denotamos com $a^{-1}$ (dado um módulo~$m$).\mistake

%%}}}

%%{{{ x: what is wrong? 
\exercise.
%%%{{{ meta 
%%%}}}

Qual o problema com a definição do $a^{-1}$?

\solution
Para o símbolo $a^{-1}$ ser bem-definido, precisamos mostrar que, caso que
existe um inverso, ele é único, que nos realmente mostramos
no~\ref[inverse_modulo_m_uniqueness].

%%}}}

%%{{{ blah: we speak of *the* inverse thanks to the following thm 
\blah.
%%%{{{ meta 
%%%}}}

Podemos falar sobre \emph{o} inverso (em vez de \emph{um} inverso)
módulo $m$, graças ao teorema seguinte.

%%}}}

%%{{{ thm: inverse_modulo_m_uniqueness 
\theorem Unicidade do inverso.
%%%{{{ meta 
\label inverse_modulo_m_uniqueness
%%%}}}

Sejam $a,m\in\ints$.
Se $b,b'\in\ints$ satisfazem a $ax \cong 1 \pmod m$, então $b \cong b' \pmod m$.

\proof.
Como
$$
ab  \cong 1 \pmod m \qquad\mland\qquad ab' \cong 1 \pmod m,
$$
pela transitividade e reflexividade da congruência módulo~$m$, temos:
$$
ab \cong ab' \pmod m.
$$
Pelo~\ref[modular_arithmetic_properties], podemos multiplicar os dois
lados por $b$:\foot
Nada especial sobre $b$ contra o $b'$.
Poderiamos multiplicar por qualquer inverso do $a$ aqui.
\toof
$$
bab \cong bab' \pmod m.
$$
Daí,
$(ba)b \cong (ba)b' \pmod m$,
ou seja $b \cong b' \pmod m$.

%%}}}

%%{{{ eg: the mod9-inverse of 2 is 5 
\example.
%%%{{{ meta 
%%%}}}

O inverso de $2$ módulo~$9$ é o $5$, porque $2\ntimes 5 = 10 \cong 1 \pmod 9$.

%%}}}

%%{{{ blah: as the following eg shows, inverses are not guaranteed 
\blah.
%%%{{{ meta 
%%%}}}

Como o exemplo seguinte mostra, inversos não existem sempre:

%%}}}

%%{{{ eg: 4 has no mod6-inverse 
\example.
%%%{{{ meta 
%%%}}}

O $4$ não tem inverso módulo~$6$.

\solution.
Podemos verificar com força bruta:
$$
\align
4 \ntimes 1 = \phantom04    &\cong 4 \pmod 6\\
4 \ntimes 2 = \phantom08    &\cong 2 \pmod 6\\
4 \ntimes 3 = 12            &\cong 0 \pmod 6\\
4 \ntimes 4 = 16            &\cong 4 \pmod 6\\
4 \ntimes 5 = 20            &\cong 2 \pmod 6
\endalign
$$
Pronto.

%%}}}

%%{{{ blah: the following thm clears things up 
\blah.
%%%{{{ meta 
%%%}}}

O teorema seguinte esclarece a situação:

%%}}}

%%{{{ thm: find_inverse_modulo_m 
\theorem Inverso módulo $m$.
%%%{{{ meta 
\label find_inverse_modulo_m
%%%}}}

Sejam $a,m\in\ints$.
$$
\text{$a$ tem inverso módulo~$m$}
\iff
\gcd a m = 1.
$$

\proof.
Precisamos mostrar as duas direções do \bidir.
\eop
\lrdir:
Escrevemos o $\gcd a m = 1$ como combinação\indexed[combinação linear] linear dos $a$ e $m$
(sabemos que é possível por \ref[bezout_lemma], e, até melhor construtível
graças ao algoritmo estendido de Euclides,~\ref[extended_euclidean_algorithm]):
$$
\alignat 2
1 &= sa + tm, &&\qquad\text{para alguns $s,t\in\ints$.}
\intertext{Então temos:}
1 &\cong sa + tm    &&\pmod m\\
  &\cong sa + 0     &&\pmod m\\
  &\cong sa         &&\pmod m.
\endalignat
$$
Acabamos de achar um inverso de $a$ módulo~$m$: o $s$.
\eop
\rldir:
Seja $b$ um inverso de $a$ módulo~$m$; em outras palavras:
$$
ab \cong 1 \pmod m,
$$
ou seja, $m \divides ab - 1$, e $mu = ab - 1$ para algum $u\in\ints$.
Conseguimos escrever
$$
1 = um - ba,
$$
a combinação linear dos $a$ e $m$.
Pelo~\ref[bezout_lemma], $\gcd a m \divides 1$,
logo $\gcd a m = 1$.

%%}}}

%%{{{ blah: Soon we will see one more method: Fermat's 
\blah.
%%%{{{ meta 
%%%}}}

Logo (\ref[Some_ideas_of_Fermat]) vamos encontrar mais
uma maneira legal de achar inversos módulo um inteiro.

%%}}}

%%{{{ beware: wrong_cancellation_law_modulo_m 
\beware.
%%%{{{ meta 
\label wrong_cancellation_law_modulo_m
%%%}}}

A lei de cancelamento, mesmo válido nas igualdades,
não é válido nas congruências em geral.
Por exemplo,
$3\ntimes 2 \cong 3\ntimes 8 \pmod {18}$,
mas não podemos cancelar os $3$ nos dois lados:
$2 \ncong 8 \pmod {18}$.

%%}}}

%%{{{ blah: the following shows when we can actually cancel 
\blah.
%%%{{{ meta 
%%%}}}

Felizmente, o teorema seguinte mostra quando realmente podemos cancelar:

%%}}}

%%{{{ thm: cancellation_law_modulo_m 
\theorem Lei de cancelamento módulo $m$.
%%%{{{ meta 
\label cancellation_law_modulo_m
%%%}}}

Seja $m$ inteiro.  Para todo $c$ coprimo com $m$,
$$
ca\cong cb\pmod m \implies a \cong b \pmod m.
$$

\sketch.
Multiplicamos tudo por $c^{-1}$, cuja existência (módulo~$m$) é garantida
pela hipótese (aplicando o~\ref[find_inverse_modulo_m]).

\proof.
Como $\gcd c m = 1$, existe $c^{-1}$ (módulo~$m$) então:
$$
\align
ca\cong cb\pmod m
&\implies          c^{-1}c a\cong          c^{-1}c b\pmod m\\
&\implies \phantom{c^{-1}c}a\cong \phantom{c^{-1}c}b\pmod m.
\endalign
$$

%%}}}

%%{{{ x: cancellation_law_modulo_m_altproof 
\exercise.
%%%{{{ meta 
\label cancellation_law_modulo_m_altproof
%%%}}}

Aplicando as definições e propriedades de congruência e da relação $(\divides)$,
ache uma outra demonstração do~\reftag[cancellation_law_modulo_m].

\solution
Pela hipótese $m \divides ca - cb = c(a - b)$.
Mas $\gcd m c = 1$, então
(pelo~\ref[lemma_euclides_coprime_version])
$m \divides a - b$, ou seja, $a \cong b \pmod m$.

%%}}}

%%{{{ thm: wilsons_theorem 
\theorem Wilson.
%%%{{{ meta 
\label wilsons_theorem
%%%}}}

Seja $p$ inteiro.
$$
\text{$p$ primo}
\iff
(p-1)! \congmod p {-1}.
$$

\proof Demonstrarás agora no~\ref[wilsons_theorem_proof].

%%}}}

%%{{{ x: wilsons_theorem_proof 
\exercise.
%%%{{{ meta 
\label wilsons_theorem_proof
%%%}}}

Demonstre o~\ref[wilsons_theorem].

\hint
Para a {\rldir}, considere sua contrapositiva.
Para a {\lrdir}, lembre que todos os $x$ com $1 \leq x \leq p-1$ são invertíveis.

\hint
Para a {\lrdir}, lembre os $(\ntimes)$-inversos vêm
em parzinhos; quais deles são casados com eles mesmo?
(Ou seja: quais são o seu próprio inverso?)

%%}}}

\endsection
%%}}}

%%{{{ Exponentiation 
\section Exponenciação.
%%%{{{ meta 
%%%}}}

%%{{{ Never gets big 
\note Nunca grande demais.
%%%{{{ meta 
%%%}}}

Calculando nos inteiros (com igualdade) expressões que envolvem
diversas operações os passos intermediários podem acabar precisando
um espaço grande, e o processo todo um tempo longo também.
Por exemplo, queremos calcular o inteiro $106^{1540}$:
$$
106^{1540}
=
935475693614
\tubrace {\dots\qquad\dots} {\clap{(3095 dígitos omitidos)}}
159789080576.
$$
O que muda quando a gente \emph{trabalha módulo um inteiro?}
\eop
A maneira leiguíssima seria calcular o inteiro $106^{1540}$, achar seu
valor, e depois dividir este número---boa sorte---com o $50$, para achar
o resto da divisão que seria um $x$ satisfatório para nossa busca.
Observe que o problema não está apenas no último passo da exponenciação:
durante esse cálculo precisamos fazer $1539$ multiplicações
entre números enormes.  Podemos fazer melhor?
\eop
Antes de tudo, observe que graças à congruência podemos substituir o $106$
por qualquer congruente seu (módulo $50$), por exemplo o $6$.
Precisamos calcular o $6^{1540}$ (módulo $50$) então.
\eop
Mas, seguindo fielmente a definição de exponenciação,
essa melhoria não vai acabar fazendo alguma diferença grande:
continuamos precisando performar $1539$ multiplicações custosas.
\eop
Uma observação critical aqui é que precisando calcular várias operações
\dq{modulares}, temos controle para não permitir ao tamanho dos resultados intermediários
crescer muito: \emph{em vez de deixar a modularização para o final, a performamos
no fim de cada operação que chegou num resultado grande}.
E o que significa grande?  Bem, alguém pode ser satisfeito trabalhando com números
no $\set {0,1,\dots,49}$, mas eu prefiro menores ainda:
dá para substituir os $49,48,\dotsc,26$ pelos seus congruentes $-1,-2,\dotsc,-24$.
Assim teriamos:
$$
\llap{\text{1539 multiplicações}}
\quad\leftbrace {
\quad\mathcoled {
6 ^ 2 &= 6     \ntimes 6  = 36   \cong -14 \\
6 ^ 3 &= (-14) \ntimes 6  = -84  \cong 16  \\
6 ^ 4 &= 16    \ntimes 6  = 96   \cong -4  \\
6 ^ 5 &= (-4)  \ntimes 6  = -24  \cong -24 \\
      &\eqvdots \\
6 ^ {1540}
      &= (-4)  \ntimes 6  = -24  \cong -24.
}}
$$

%%}}}

%%{{{ Q: how can we improve this? 
\question.
%%%{{{ meta 
%%%}}}

Como procederia para achar um $x$ \dq{pequeno} tal que $6^{1540} \congmod {50} x$?

%%}}}

\spoiler

%%{{{ A cool way 
\blah Resposta: quadrados iterados.
%%%{{{ meta 
%%%}}}

Calculamos os quadrados
\mathcols 2
6^2      &= 36             \cong -14 & 6^{64}   &\cong -4   \\
6^4      &= (-14)^2  = 196 \cong -4  & 6^{128}  &\cong -16  \\
6^8      &= (-4)^2   = 16  \cong 16  & 6^{256}  &\cong 6    \\
6^{16}   &= 16^2     = 256 \cong 6   & 6^{512}  &\cong -14  \\
6^{32}   &= 6^2      = 36  \cong -14 & 6^{1024} &\cong -4.  \\
\endmathcols
E agora temos:
$$
6^{1540} = 6^{1024 + 512 + 4} = 6^{1024} 6^{512} 6^4 = (-4)(-14)(-4) = -224 \cong -24 \pmod {50}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Solving_some_congruences 
\section Resolvendo umas congruências.
%%%{{{ meta 
\label Solving_some_congruences
%%%}}}

%%{{{ cor: ax_cong_1_mod_m 
\corollary.
%%%{{{ meta 
\label ax_cong_1_mod_m
%%%}}}

Dados inteiros $a,m$, a congruência
$$
ax \cong 1 \pmod m
$$
tem resolução para $x$ sse $\gcd a m = 1$.

\proof.
Observe que aqui \wq{$x$ é resolução} significa
\wq{$x$ é o $(\ntimes)$-inverso de $a$}, e logo esta proposição
é corolário imediato do \ref[find_inverse_modulo_m].

%%}}}

%%{{{ cor: ax_cong_b_mod_m 
\corollary.
%%%{{{ meta 
\label ax_cong_b_mod_m
%%%}}}

Dados inteiros $a,b,m$ com $a,m$ coprimos, a congruência
$$
ax \cong b \pmod m
$$
tem resolução para $x$.

\sketch.
Suponha $a,m$ coprimos.
Logo o $a$ possui inverso $a'$.
É rotina verificar que o $a'b$ satisfaz a congruência desejada.

%%}}}

%%{{{ x: ax_cong_b_mod_m_converse 
\exercise.
%%%{{{ meta 
\label ax_cong_b_mod_m_converse
%%%}}}

Enuncie o reciproco do \ref[ax_cong_b_mod_m] e demonstre ou refute.

%%}}}

%%{{{ x: roots_of_1_mod_m 
\exercise raizes quadradas de 1.
%%%{{{ meta 
\label roots_of_1_mod_m
%%%}}}

Podemos, em geral, resolver a congruência $x^2 \cong 1 \pmod m$?

%%}}}

\endsection
%%}}}

%%{{{ The_chinese_remainder_theorem 
\section O teorema chinês do resto.
%%%{{{ meta 
\label The_chinese_remainder_theorem
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já sabemos como resolver congruências do tipo
$$
ax \cong b \pmod m,
$$
e agora vamos ver como resolver uns \emph{sistemas}
de congruências.

%%}}}

%%{{{ thm: chinese_remainder_theorem_binary_case 
\theorem Teorema chinês do resto (binário).
%%%{{{ meta 
\headerize
\label chinese_remainder_theorem_binary_case
%%%}}}

Sejam $m_1,m_2,b_1,b_2$ inteiros tais que $m_1, m_2$ são coprimos.
Logo existe inteiro $x$ que satisfaz o sistema de congruências
\system
x &\cong    b_1   \pmod {m_1} \\
x &\cong    b_2   \pmod {m_2}.
\endsystem
Além disso, a solução do sistema é única módulo~$m_1m_2$.

\sketch.
\proofstylize{Existência:}
Observe que o inteiro $b_1$ com certeza satisfaz a primeira congruência.
O problema é que talvez não satisfaça a segunda.
Felizmente, temos mais inteiros que satisfazem a primeira na nossa disposição.
Muito mais: uma infinidade deles: cada congruente ao $b_1$, ou seja
os membros do conjunto
$$
\setst {m_1k + b_1} {k \in \ints}
$$
são exatamente todos os inteiros que satisfazem a primeira.
Agora estamos numa situação bem melhor, basta achar algum deles que satisfaz
a segunda.
Observe que cada membro desse conjunto é determinado por uma escolha de $k\in\ints$.
Ou seja, basta achar um inteiro $k$ tal que $m_1k + b_1$ satisfaz a segunda.
Talvez conseguimos achar até uma infinidade de tais inteiros.
Vamo lá!
Procuramos inteiros $k$ tais que
$$
m_1k + b_1 \cong b_2 \pmod {m_2},
$$
ou seja, tais que
$$
m_1k \cong b_2 - b_1 \pmod {m_2}.
$$
(Por quê?)
Mas sabemos como resolver essa congruência para $k$.
(Né?  Por quê?)

%%}}}

%%{{{ x: first why 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no primeiro \dq{por quê?} acima.

\solution
Somamos o $-b_1$ aos dois lados.

%%}}}

%%{{{ x: second why 
\exercise.
%%%{{{ meta 
%%%}}}

E no segundo.

\solution
É da forma $ax \cong b \pmod m$ com $a$ invertível (pois $\gcd a m = 1$),
ou seja, sabemos como resolver desde a \ref[Solving_some_congruences].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver isso na prática:

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
\system
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12}.
\endsystem

\solution.
Os inteiro que satisfazem a primeira congruência são os membros do
$$
\setst {5k + 1} {k\in\ints}.
$$
Basta achar os valores de $k$ tais que $5k+1$ também satisfaz a segunda,
ou seja, resolver a congruência
\modcompute
5k+1 &\cong 7   \cmod {12} \noby \\
\intertext{por $k$.  Passando o $(+1)$ peloutro lado (por que podemos
fazer isso numa congruência?)~temos}
5k &\cong 7-1   \cmod {12}\\
   &\cong 6     \cmod {12}.
\intertext{Agora basta \dq{dividir por $5$}, ou seja, multiplicar ambos
os lados pelo $5^{-1}$, ou seja, pelo inverso de $5$ módulo $12$,
que sabemos que existe pois $\gcd 5 {12} = 1$ e logo $5$ é invertível
módulo $12$.
Percebemos que $5$ é seu próprio inverso, pois
$5^2 = 25 \cong 1 \pmod {12}$,
e se não percebemos isso, usamos o algoritmo de Euclides para calcular
o inverso de $5$ módulo $12$.
Temos:}
k  &\cong 5\ntimes 6   \cmod {12}\\
   &\cong 30           \cmod {12}\\
   &\cong 6            \cmod {12}.
\endmodcompute
Logo, para qualquer inteiro $k'$, tomando $k = 12k' + 6$,
o $5k+1$ satisfaz ambas as congruências.
Substituindo:
$$
5k + 1
= 5(12k' + 6) + 1
= 60k' + 30 + 1
= 60k' + 31.
$$
Em termos de classes módulo $60$, achamos a única resolução:
$$
x \cong 31 \pmod {60}.
$$

%%}}}

%%{{{ Q: What if we have more congruences? 
\question.
%%%{{{ meta 
%%%}}}

E se o sistema tem mais congruências?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Supondo que os módulos são \emph{coprimos dois-a-dois},
nenhum problema!
Basta só focar em duas congruências cada vez,
e substituí las por uma, que corresponde na sua
resolução (módulo o produto dos seus módulos).

%%}}}

%%{{{ x: chinese_from_binary_to_ternary 
\exercise.
%%%{{{ meta 
\label chinese_from_binary_to_ternary
%%%}}}

Ache todos os inteiros $x\in\ints$ que satisfazem o sistema de congruências:
\system
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12} \\
x &\cong 3 \pmod 7.
\endsystem

\hint
Já descobrimos que
$$
x \cong 31 \pmod {60}
\iff
\systemed {
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12}
}
$$
e logo
$$
\systemed {
x &\cong 1 \pmod 5 \\
x &\cong 7 \pmod {12} \\
x &\cong 3 \pmod 7
}
\iff
\systemed {
x &\cong 31 \pmod {60} \\
x &\cong \phantom03  \pmod 7.
}
$$
Como $\gcd {60} 7 = 1$, sabemos que o sistema tem resolução única módulo $420$
e ainda mais, sabemos como achar essa resolução
(tudo isso graças ao \ref[chinese_remainder_theorem_binary_case]).

%%}}}

%%{{{ thm: chinese_remainder_theorem 
\theorem Teorema chinês do resto.
%%%{{{ meta 
\headerize
\label chinese_remainder_theorem
\indexes
    * chinês!teorema do resto    see: teorema chinês
    * congruência!sistema
    * sistema!de congruências
    * teorema!chinês do resto
    ;;
%%%}}}

Sejam $a_1,\dotsc,a_k,m_1,\dotsc,m_k\in\ints$,
com os $m_i$'s coprimos dois-a-dois:
$$
\lforall {i,j\in\set{1,\dotsc,k}} {i\neq j \implies \gcd {m_i} {m_j} = 1}.
$$
Logo existe $x\in\ints$ que satisfaz o sistema de congruências
\mathcol
x &\cong    a_1  \pmod {m_1} \\
x &\cong    a_2  \pmod {m_2} \\
  &\eqvdots                  \\
x &\cong    a_k  \pmod {m_k}.
\endmathcol
Além disso, a solução do sistema é única módulo~$m_1\dotsb m_k$.

\sketch.
\proofstylize{Existência:}
Seja
\mathcol
M   &\asseq \Prod_{i=1}^k m_i = m_1m_2\dotsb m_k
\intertext{e, para todo $i\in\set{1,\dotsc,k}$, defina o}
M_i &\asseq \Prod\submath{j=1\\j\neq i}^k m_j
     = m_1\dotsb m_{i-1}m_{i+1}\dotsb m_k
     = \frac M {m_i}.
\endmathcol
Observe que $M_i$ é invertível módulo~$m_i$,
então seja $B_i$ o seu inverso.
Verificamos que o inteiro
$$
x = \Sum_{i=1}^k a_i M_i B_i
$$
satisfaz todas as $k$ congruências,
e é então uma solução do sistema.
\eop
\proofstylize{Unicidade:}
Suponha que $x'\in\ints$ é uma solução do sistema.
Usando a definição de congruência e propriedades
de $(\divides)$, mostramos que $x' \cong x \pmod M$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Bora achar todos os inteiros $x$ que satisfazem o sistema de congruências:
\mathcol
x &\cong 2 \pmod 9 \\
x &\cong 1 \pmod 5 \\
x &\cong 2 \pmod 4.
\endmathcol

\solution Bora.
Observamos primeiramente que os módulos $9$, $5$, e $4$ realmente são coprimos
dois-a-dois.  Então, pelo teorema chinês do resto,
o sistema realmente tem solução.
Seguindo sua método---e usando os mesmos nomes para as variáveis como
no~\ref[chinese_remainder_theorem] mesmo---calculamos os:
\mathcols 2
M_{\phantom0}   &= 9\ntimes5\ntimes4 = 180  &      &                \\
M_1 &= \phantom{9\ntimes{}}5\ntimes4 = 20   &  B_1 &\cong 5 \pmod 9 \\
M_2 &= 9\phantom{{}\ntimes5}\ntimes4 = 36   &  B_2 &\cong 1 \pmod 5 \\
M_3 &= 9\ntimes5\phantom{{}\ntimes4} = 45   &  B_3 &\cong 1 \pmod 4,
\endmathcols
onde os invérsos $B_i$'s podemos calcular usando o algoritmo estendido de
Euclides~(\reftag[extended_euclidean_algorithm]) como na prova
do~\ref[find_inverse_modulo_m]), mas nesse caso, sendo os módulos tão pequenos
fez mas sentido os achar testando, com ``força bruta''.
Então, graças ao teorema chinês, as soluções são exatamente os inteiros $x$ que satisfazem
\modcompute
x
&\cong a_1M_1B_1 + a_2M_2B_2 + a_3M_3B_3
                      \cmod M \noby \\
&\cong 2 \ntimes 20\ntimes 5 + 1 \ntimes 36\ntimes 1 + 2 \ntimes 45\ntimes 1
                      \cmod {180} \\
&\cong 200 + 36 + 90  \cmod {180} \\
&\cong 146            \cmod {180}.
\endmodcompute
Para resumir, as soluções do sistema são todos os elementos do
$\setst {180k + 146} {k\in\ints}$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Vamo achar todos os inteiros $x$ com $\abs x < 64$ que satisfazem o sistema de congruências:
\mathcol
x  &\cong 1 \pmod 3 \\
3x &\cong 1 \pmod 4 \\
4x &\cong 2 \pmod 5.
\endmathcol

\solution Vamo.
Para aplicar o teorema chinês do resto precisamos os $3$, $4$, e $5$ coprimos dois-a-dois,
que realmente são.
Mas observe que o sistema não está na forma do teorema;
aí, não podemos aplicá-lo diretamente.
Nosso primeiro alvo então seria transformar a segunda e a terceira congruência para
equivalentes, na forma necessária para aplicar o teorema.
Na segunda vamos nos livrar do fator $3$, e na terceira do fator $4$.
Como $\gcd 3 4 = 1$,\foot
Qual \sq{4} foi esse?
\toof
o $3$ é invertível módulo~$4$.
Como o $3\cong -1 \pmod 4$, temos diretamente que $3^{-1} \cong -1 \pmod 4$.
Similarmente achamos o inverso $4^{-1} \cong -1 \pmod 4$.
Então temos:
$$
\rsystemed {
x  &\cong 1 \pmod 3\\
3x &\cong 1 \pmod 4\\
4x &\cong 2 \pmod 5
}
\iff
\bsystemed {
x  &\cong \phantom{1^{-1}}1 \pmod 3\\
3^{-1}3x &\cong 3^{-1}1 \pmod 4\\
4^{-1}x &\cong 4^{-1}2 \pmod 5
}
\iff
\lsystemed {
x &\cong \phantom{-}1 \pmod 3\\
x &\cong -1 \pmod 4\\
x &\cong -2 \pmod 5.
}
$$
Agora sim, podemos aplicar o teorema chinês.
Usando os mesmos nomes para as variáveis
como no~\ref[chinese_remainder_theorem], calculamos:
\mathcols 2
M_{\phantom0} &= 3\ntimes4\ntimes5              = 60  &      &               \\
M_1           &= \phantom{3\ntimes{}}4\ntimes5  = 20  &  B_1 &\cong 2 \pmod 3\\
M_2           &= 3\phantom{{}\ntimes4}\ntimes5  = 15  &  B_2 &\cong 3 \pmod 4\\
M_3           &= 3\ntimes4\phantom{{}\ntimes5}  = 12  &  B_3 &\cong 3 \pmod 5, 
\endmathcols
onde os invérsos $B_1$ e $B_2$ calculamos percebendo que
$20\cong-1 \pmod 3$ e $15\cong-1 \pmod 4$, e o $B_3$ com força bruta mesmo.
Pronto: as soluções do sistema são exatamente os inteiros $x$ que satisfazem:
\modcompute
x &\cong a_1 M_1 B_1        + a_2 M_2 B_2        + a_3 M_3 B_3          \cmod M \\
  &\cong 1\ntimes20\ntimes2 + 3\ntimes15\ntimes3 + 3\ntimes12\ntimes3   \cmod {60} \\
  &\cong 40 + 135 + 108   \cmod {60} \\
  &\cong 40 + 15 + 108    \cmod {60} \by {$135\cong15\pmod{60}$} \\
  &\cong 55 + 48          \cmod {60} \by {$108\cong48\pmod{60}$} \\
  &\cong -5 + 48          \cmod {60} \by {$\phantom055\cong-5\pmod{60}$} \\
  &\cong 43               \cmod {60}.
\endmodcompute
Logo, o conjunto de todas as soluções do sistema é o $\setst {60k + 43} {k\in\ints}$.
Facilmente verificamos que os únicos dos seus elementos que satisfazem nossa
restricção $\abs x < 64$ são os inteiros obtenidos pelos valores de $k = 0$ e $-1$:
$x_1 = 43$, $x_2 = -17$.

%%}}}

%%{{{ x: coprime_vs_pairwise_coprime 
\exercise ``entre si'' vs ``dois-a-dois''.
%%%{{{ meta 
\label coprime_vs_pairwise_coprime
%%%}}}

Considere as frases:
\tlist:
\li (i):  Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos entre si.
\li (ii): Os inteiros $a_1, a_2, \dotsc, a_n$ são coprimos dois-a-dois.
\endtlist
Mostre com um contraexemplo que as duas afirmações não são equivalentes.

\hint
Procure um contraexemplo com três inteiros.

\solution
Os $2$, $4$, $5$ são coprimos entre si (têm mdc $1$)
mas mesmo assim não são coprimos dois-a-dois:
$\gcd 2 4 = 2$.

%%}}}

%%{{{ x: solve systems of congruences 
\exercise.
%%%{{{ meta 
%%%}}}

Ache as soluções dos sistemas de congruências seguintes:
\mathcols 2
\text{(1)}\quad&
\lmodsystemed {
x  &\cong 3  \cmod 4 \\
5x &\cong 1  \cmod 7 \\
x  &\cong 2  \cmod 9
}
&
\text{(2)}\quad&
\lmodsystemed {
x  &\cong 3  \cmod 3 \\
3x &\cong 3  \cmod 4 \\
4x &\cong 2  \cmod 5 \\
5x &\cong 1  \cmod 7.
}
\endmathcols

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O exercício seguinte te convida descobrir que o teorema chinês pode ser aplicado
em casos mais gerais do que aparece inicialmente!

%%}}}

%%{{{ x: solve more systems of congruences 
\exercise.
%%%{{{ meta 
%%%}}}

Resolva os sistemas de congruências:
\mathcols 2
\text{(1)}\quad&
\lmodsystemed {
5x &\cong 2   \cmod 6 \\
x  &\cong 13  \cmod {15} \\
x  &\cong 2   \cmod 7
}
&
\text{(2)}\quad&
\lmodsystemed {
x  &\cong 2   \cmod 6 \\
x  &\cong 13  \cmod {15} \\
x  &\cong 2   \cmod 7.
}
\endmathcols

\hint
Observe que não podes aplicar o teorema chinês diretamente: $\gcd 6 {15} > 1$.

\hint
Tente substituir a congruência $5x \cong 2  \pmod 6$ com um sistema equivalente, de \emph{duas} congruências.

\hint
Mostre que para qualquer $a\in\ints$,
$$
\rightbrace {
a \cong 2 \pmod 6
}
\iff
\lsystemed {
a &\cong 0 \pmod 2 \\
a &\cong 2 \pmod 3.
}
$$

\hint
Não todos os sistemas de congruências têm soluções.
(Acontéce quando temos restricções contraditórias.)
Nesse exercício um dos dois sistemas não tem solução.

%%}}}

\endsection
%%}}}

%%{{{ Divisibility_criteria 
\section Critéria de divisibilidade.
%%%{{{ meta 
\label Divisibility_criteria
\indexes
    * divisibilidade!critéria
    ;;
%%%}}}

%%{{{ criterion: divisibility_criterion_powers_of_10 
\criterion Divisibilidade por potências de 10.
%%%{{{ meta 
\label divisibility_criterion_powers_of_10
%%%}}}

Um inteiro $c\neq 0$ é divisível por $10^k$
sse
o $c$ escrito em base decimal termina com $k$ dígitos 0.

%%}}}

%%{{{ criterion: divisibility_criterion_2_5 
\criterion Divisibilidade por 2 ou 5.
%%%{{{ meta 
\label divisibility_criterion_2_5
%%%}}}

Seja $m \in \set{2, 5}$.
Um inteiro $c$ é divisível por $m$
sse
o valor do último dígito do $c$ (em base decimal) é divisível por~$m$.

%%}}}

%%{{{ criterion: divisibility_criterion_3_9 
\criterion Divisibilidade por 3 ou 9.
%%%{{{ meta 
\label divisibility_criterion_3_9
%%%}}}

Seja $m \in \set{3, 9}$.
Um inteiro $c$ é divisível por $m$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) é
divisível por~$m$.

%%}}}

%%{{{ criterion: divisibility_criterion_4_20_25_50
\criterion Divisibilidade por 4, 20, 25, 50.
%%%{{{ meta 
\label divisibility_criterion_4_20_25_50
%%%}}}

Seja $m\in\set{4, 20, 25, 50}$.
Um inteiro $c$ é divisível por $m$
sse
o número formado pelos dois últimos dígitos do $c$ (em base decimal)
é divisível por~$m$.

%%}}}

%%{{{ criterion: divisibility_criterion_11 
\criterion Divisibilidade por 11.
%%%{{{ meta 
\label divisibility_criterion_11
%%%}}}

Um inteiro $c$ é divisível por $11$
sse
o somatório dos valores dos dígitos do $c$ (em base decimal) em posição par
menos o somatório dos valores dos seus dígitos em posição ímpar
é divisível por~$11$.

%%}}}

%%{{{ x: divisibility_criterion_6 
\exercise Divisibilidade por 6.
%%%{{{ meta 
\label divisibility_criterion_6
%%%}}}

Ache um critério (para o sistema decimal) para divisibilidade por 6.

\hint
$6 = 2\ntimes 3$

\solution
Observe que por causa do~\ref[product_of_coprimes_divides_common_multiple], temos:
$$
6\divides c
\iff
2 \divides c
\mland
3 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $3$.

%%}}}

%%{{{ prop: divisibility_criterion_8_wrong 
\proposition Divisibilidade por 8.
%%%{{{ meta 
\label divisibility_criterion_8_wrong
%%%}}}

Um número $c$ é divisível por 8 sse ele satisfaz
os critéria de divisibilidade por $2$ e $4$.

\wrongproof.
Observe que por causa do~\ref[product_of_coprimes_divides_common_multiple], temos:
$$
8 \divides c
\iff
2 \divides c
\mland
4 \divides c.
$$
Logo, aplicamos os critéria de divisibilidade por $2$ e por $4$.

%%}}}

%%{{{ x: divisibility_criterion_8_wrong_why 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_8_wrong_why
%%%}}}

Ache o erro no~\ref[divisibility_criterion_8_wrong],
e compare com a solução do~\ref[divisibility_criterion_6].

\hint
Veja o~\ref[product_of_coprimes_divides_common_multiple].

\solution
Como $\gcd 4 2 = 4 \neq 1$, não podemos aplicar
o~\ref[product_of_coprimes_divides_common_multiple].
Um contraexemplo:
$2 \divides 12$ e $4 \divides 12$, mas $2\ntimes 4 = 8 \ndivides 12$.

%%}}}

%%{{{ x: divisibility_criterion_8_powers_of_2 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_8_powers_of_2
%%%}}}

Ache um critério (no sistema decimal) para divisibilidade por 8,
e generalize para divisibilidade por $2^k$

\hint
$8 = 2^3$, e $2 \divides 10$.

\hint
$2 \divides 10 \implies 2^3 \divides 10^3$.

%%}}}

%%{{{ x: divisibility_criterion_2_exp_x_times_5_exp_y 
\exercise.
%%%{{{ meta 
\label divisibility_criterion_2_exp_x_times_5_exp_y
%%%}}}

Ache um critério (no sistema decimal) para divisibilidade por $2^x5^y$, onde $x,y\in\nats$.

\hint
Os $2$ e $5$ são divisores de $10$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: three_divides_product_of_pythagorean_triples 
\problem.
%%%{{{ meta 
\label three_divides_product_of_pythagorean_triples
%%%}}}

Sejam $a,b,c$ inteiros tais que $a^2 + b^2 = c^2$.
Então $3 \divides abc$.

\hint
Caso que qualquer um dos $a,b,c$ é multiplo de $3$, já éra.
Basta então considerar o caso onde nenhum deles é multiplo de $3$.

\hint
O quadrado dum número que não é múltiplo de $3$ é congruente ao $1$ módulo $3$.

%%}}}

%%{{{ prob: freshmans_dream 
\problem O sonho do calouro.
%%%{{{ meta 
\headerize
\label freshmans_dream
\indexes
    * sonho do calouro
    ;;
%%%}}}

Seja $p$ primo, $x,y\in\ints$.
$$
(x + y)^p \cong x^p + y^p \pmod p.
$$

\hint
Use o teorema binomial~\reftag[binomial_theorem].

\hint
Use o \ref[p_divides_comb_p_r].

\solution
Temos
\compute
(x + y)^p
&= \Sum_{i=0}^p \binom p i x^{p-i}y^i             \by {por~\ref[binomial_theorem]} \\
&= \binom p 0 x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + \binom p p y^p             \by {$p\geq2$} \\
&= x^p + \Sum_{i=1}^{p-1} \binom p i x^{p-i}y^i + y^p     \\
&= x^p + \Sum_{i=1}^{p-1} p c_i x^{p-i}y^i + y^p, \quad\text{para algum $c_i\in\ints$}  \by {por~\ref[p_divides_comb_p_r]} \\
&= x^p + p \Sum_{i=1}^{p-1} c_i x^{p-i}y^i + y^p          \\
&\cong x^p + y^p \pmod p.
\endcompute

%%}}}

%%{{{ prob: infinitely_many_primes_3_mod_4 
\problem.
%%%{{{ meta 
\label infinitely_many_primes_3_mod_4
%%%}}}

Existe uma infinidade de primos ``da forma $4n+3$'', ou seja, o conjunto
$$
\setstt {4n+3} {$n\in\nats$ e $4n+3$ primo}
$$
é infinito.

\hint
Esquecendo o $2$, todos os primos são da forma $4n+1$ ou $4n+3$.
Suponha que $p_1, p_2,\dotsc, p_k$ ($k\in\nats$)
são todos os primos da segunda forma.

\hint
O que Euclides faria?

\hint
Tente achar (criar) um número da mesma forma tal que nenhum dos $p_i$ o divide.

\hint
$N = 4p_1p_2\dotsb p_k - 1$.

\hint
$N$ não pode ter apenas divisores da forma $4n+1$.  Por quê?

\hint
\dots porque multiplicando numeros da forma $4n+1$ seu produto continua da mesma forma.

\solution
Considere $k\in\nats$ arbitrário.
Basta encontrar um primo da forma $4n+3$ que é maior que o $k$-ésimo primo.
Seja $N = 4p_1p_2\dotsb p_k - 1$, que é um numero da forma $4n+3$
que não é divisível por nenhum dos $p_1,\dotsb,p_k$.
Agora observe que $N$ não pode ter apenas divisores da forma $4n+1$,
pois se fosse o caso ele seria da mesma forma.
Logo pelo menos um dos primos que o dividem é da forma $4n+3$
e maior que o $p_k$ (pelo \byfact1) e logo achamos o primo que estavamos procurando.

%%}}}

%%{{{ prob: why 4n+1 is more difficult? 
\problem.
%%%{{{ meta 
%%%}}}

Depois de ter resolvido o \ref[infinitely_many_primes_3_mod_4],
explique por que sua demonstração não é trivialmente adaptável
para resolver a mesma questão sobre os primos da forma $4n+1$.

\hint
\mathcols 2
(4n+3)(4n+3) &\askeq 4n'+3  & (-1)^n &\askeq -1
\endmathcols

%%}}}

%%{{{ thm: dirichlet_theorem_arithmetic_progression 
\theorem Dirichlet.
%%%{{{ meta 
\label dirichlet_theorem_arithmetic_progression
\credits
    * Dirichlet : teorema
    * Legendre : conjecura
    ;;
%%%}}}

Sejam inteiros $a,m$ coprimos.
Existe uma infinidade de primos $p$ tal que $p \cong a \pmod m$.

\preproof.
Este teorema foi conjecturado---e usado!---por Legendre no ano
\yearof{1785} e finalmente demonstrado por Dirichlet no ano \yearof{1837}.

\sketch Cadê a demonstração?.
Infelizmente, não temos uma demonstração com as ferramentas elementares
que temos elaborado aqui.  Para matá-lo usamos artilharia pesada,
\dterm{teoria dos números analítica}, que aproveita a Análise Matemática
para estudar assuntos da teoria dos números.
O livro \cite[serrearithmetic: Chapter VI] dedica um capítulo inteiro
à demonstração deste teorema, e o \cite[apostolant: Chapter 7] também!

%%}}}

\endproblems
%%}}}

%%{{{ Some_ideas_of_Fermat 
\section Umas idéias de Fermat.
%%%{{{ meta 
\label Some_ideas_of_Fermat
\credits
    * Fermat
    ;;
%%%}}}

%%{{{ intro 
\secintro
Fermat~(\yearof{1607}--\yearof{1665}) percebeu
que para qualquer primo $p$, e qualquer inteiro $a$ não divisível por $p$,
o $a^p - a$ era sempre múltiplo de $p$:
$$
p \ndivides a \implies p \divides a^{p - 1} - 1.
$$
Observe que como $a^p - a = a(a^{p-1} - 1)$, temos
\mathcol
p \divides a^p - a
&\iff p \divides a(a^{p-1} - 1) \\
&\iff p \divides a \mlor p \divides a^{p-1} - 1.
\endmathcol
Hoje a gente escreveria a observação de Fermat
$$
a^p \cong a \pmod p,
$$
notação e percepção inacessível a Fermat naquela epoca,
uns 158 anos antes do \cite[disquisitiones] (\yearof{1798}) de Gauss.
%%}}}

%%{{{ thm: fermatinho 
\theorem Teorema pequeno de Fermat.
%%%{{{ meta 
\aka Fermatinho.
\headerize
\label fermatinho
\credits
    * Fermat : teorema pequeno (Fermatinho)
    * Euler : primeira demonstração de Fermatinho
    * Leibniz : primeira demonstração de Fermatinho
    ;;
\indexes
    * teorema!Fermatinho
    * teorema!pequeno de Fermat    see: Fermatinho
    * Fermatinho                   see: teorema, Fermatinho
    ;;
%%%}}}

Seja $p$ primo.
Logo
$$
\lforall a {a^p \congmod p a}.
$$

\preproof.
Fermat não demonstrou este teorema; alegou que não quis
encher o saco do seu leitor com os detalhes da demonstração.
Pelo contrário, eu vou encher teu saco mesmo.
Quem de fato demonstrou (e publicou) esse teorema primeiro,
foi o suiço Euler, no ano \yearof{1736}.
Leibniz tinha também escrito efetivamente a mesma demonstração de Euler
em algum momento antes do ano \yearof{1683}, mas nunca chegou a publicá-la.
Agora chega de história, bora demonstrar.

\proof.
Basta demonstrar o teorema para todo $a \geq 0$, ou, ainda mais,
basta verificar apenas os $a \in \set {0, \dotsc, p-1}$, pois estamos
trabalhando módulo $p$.
\eop
Por indução no $a$.
\proofcase {Base.}  Calculamos $0^p = 0 \congmod p 0$ e pronto.
\proofcase {Passo indutivo.}
Seja $k$ tal que $k^p \congmod p k$.
Precisamos mostrar que $(k+1)^p \congmod p {k + 1}$.
Calculamos:
\compute
(k+1)^p
&\congmod p {k^p + 1^p}  \by {\ref[freshmans_dream]} \\
&\congmod p {k + 1^p}    \by {h.i.} \\
&\congmod p {k + 1}.
\endcompute

%%}}}

%%{{{ cor: fermatinho_coprime_case 
\corollary.
%%%{{{ meta 
\label fermatinho_coprime_case
\credits
    * Fermat : teorema pequeno
    ;;
\indexes
    * teorema!Fermatinho
    ;;
%%%}}}

Sejam $p$ primo e $a$ inteiro tais que $a,p$ são coprimos.
Então
$$
a^{p-1} \congmod p 1.
$$

\proof.
Tua: \ref[fermatinho_coprime_case_proof].

%%}}}

%%{{{ x: fermatinho_coprime_case_proof 
\exercise.
%%%{{{ meta 
\label fermatinho_coprime_case_proof
%%%}}}

Obtenha o \ref[fermatinho_coprime_case] pelo \ref[fermatinho].

\hint
Sendo $a$ coprimo com $p$, $a$ é invertível módulo $p$.

\solution
Pelo \ref[fermatinho], temos
$$
a^p \congmod p a = a1
$$
e como $p$ é primo, logo $p > 0$ e logo $a^p = aa^{p - 1}$.
Substituindo obtemos
$$
aa^{p-1} \congmod p a1.
$$
Como $a$ é coprimo com $p$, logo $a$ é cancelável, e logo
$$
a^{p-1} \congmod p 1.
$$

%%}}}

%%{{{ New way to compute modular inverse 
\note Nova maneira de calcular inversos.
%%%{{{ meta 
\credits
    * Fermat : inverso modular
    ;;
%%%}}}

O Fermatinho nos permite calcular rapidamente inversos.

%%}}}

%%{{{ x: how? 
\exercise.
%%%{{{ meta 
%%%}}}

Como?

\hint
$a^{p-1} = a^{p-2}a$.

\solution
Dado um $a$ coprimo com $p$, já que $a^{p-1} \congmod p 1$,
logo $a^{p-2}a = a^{p-1} \congmod p 1$, e logo $a^{p-2}$ é
um inverso de $a$ módulo $p$.

%%}}}

%%{{{ x: Compute the inverse of 108 modulo 241
\exercise.
%%%{{{ meta 
%%%}}}

Calcule (na mão!) o $(\ntimes)$-inverso de $108$ módulo $241$.

\hint
Tome $a := 108$ e $p := 241$ no Fermatinho.

\solution
Pelo \ref[fermatinho], $108^{240} \congmod {241} 1$, ou seja,
$108^{239} 108 \congmod {241} 1$.
Segue que $108^{239}$ é um inverso de $108$ módulo $241$.

%%}}}

%%{{{ New way to perform modular exponentiation 
\note Nova maneira para exponenciação modular.
%%%{{{ meta 
%%%}}}

O Fermatinho nos permite calcular rapidamente potências módulo um inteiro.

%%}}}

%%{{{ x: how? 
\exercise.
%%%{{{ meta 
%%%}}}

Como?

%%}}}

%%{{{ eg: last_digit_of_big_number_example 
\example.
%%%{{{ meta 
\label last_digit_of_big_number_example
%%%}}}

Ache o último dígito do $2^{800}$.

\solution.
Procuramos um $y$ tal que $2^{800}\cong y \pmod {10}$
(por quê?).
Usando o \ref[fermatinho] temos:
$$
\align
2^4 &\cong 1 \pmod 5,
\intertext{logo}
2^{800} = (2^4)^{200} &\cong 1 \pmod 5.
\endalign
$$
Então módulo~$10$ temos duas possibilidades (por quê?):
$$
2^{800} \cong
\knuthcases {
1 \pmod {10}\cr
6 \pmod {10}.\cr
}
$$
Podemos já eliminar a primeira porque $2^{800}$ é par.
Finalmente, o último dígito de $2^{800}$ é o $\digit6$.

%%}}}

%%{{{ x: first why 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no primeiro ``por quê?'' do~\ref[last_digit_of_big_number_example].

\hint
Escreva o inteiro como somatório baseado na sua forma decimal.

\hint
Divide ele por 10.

\solution
Para o número $n$ escrito em base decimal como
$\delta_k\delta_{k-1}\dotsb \delta_1\delta_0$,
temos:
$$
\align
n
&= d_0 + 10d_1 + 100d_2 + \dotsb 10^{k-1}d_{k-1} + 10^kd_k\\
&= \tubrace {d_0} {resto} + 10\tubrace {(d_1 + 10d_2 + \dotsb 10^{k-2}d_{k-1} + 10^{k-1}d_k)} {quociente},
\endalign
$$
onde $d_i$ é o correspondente valor do dígito $\delta_i$.
(Evitamos aqui confundir o ``dígito'' com seu valor usando notação diferente
para cada um, para enfatizar a diferença entre os dois conceitos.)

%%}}}

%%{{{ x: second why and new proof via chinese 
\exercise.
%%%{{{ meta 
%%%}}}

Responda no segundo também, e ache um outro caminho para chegar no resultado,
usando o \ref[chinese_remainder_theorem].

\hint
Qual a solução do sistema
\modsystem
x &\cong 1 \cmod 5 \\
x &\cong 0 \cmod 2 ?
\endmodsystem

\solution
Podemos ou aplicar o teorema chinês (\ref[chinese_remainder_theorem]) no sistema de congruências
\modsystem
x &\cong 1 \cmod 5 \\
x &\cong 0 \cmod 2,
\endmodsystem
ou, como $5 \divides 10$, usar diretamente o~\ref[from_mod_m_to_mod_am],
para concluir que $x = 10k + 5i + 1$, onde $i=0,1$.

%%}}}

%%{{{ x: 41^75 mod 3 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o resto da divisão de $41^{75}$ por $3$.

\hint
Procure $y$ tal que $41^{75} \cong y \pmod 3$.

\hint
$\gcd {41} 3 = 1$.

\hint
$41^{75} = 41^{74}\ntimes 41$.

\hint
Fermat.

\solution
Como $\gcd {41} 3 = 1$, pelo teorema de Fermat (\ref[fermatinho])
temos
$$
41^2 \cong 1 \pmod 3,
$$
e agora dividindo o $75$ por $2$, temos $75 = 2\ntimes 37 + 1$, então:
$$
\alignat 3
41^2 \cong 1 \pmod 3 &\implies (41^2)^{37}  &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}      &&\cong \phantom01  &&\pmod 3    \\
                     &\implies 41^{74}41    &&\cong 41          &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong 41          &&\pmod 3    \\
                     &\implies 41^{75}      &&\cong \phantom02  &&\pmod 3.
\endalignat
$$
Outro jeito para escrever exatamente a mesma idéia,
mas trabalhando ``de fora pra dentro'', seria o seguinte:
$$
\alignat 2
41^{75} &= 41^{2 \ntimes 37 + 1} \\
        &= 41^{2 \ntimes 37} 41 \\
        &= (41^2)^{37} 41 \\
        &\cong  1^{37} 41   &&\pmod 3\\
        &\cong  41          &&\pmod 3\\
        &\cong  2           &&\pmod 3.
\endalignat
$$

%%}}}

\endsection
%%}}}

%%{{{ Primality 
\section Primalidade.
%%%{{{ meta 
\label Primality
%%%}}}

%%{{{ intro 
\secintro
Investigamos aqui o problema seguinte:
\proclaim{dado um inteiro $x$, verifique se $x$ é primo ou não.}
%%}}}

%%{{{ What we have so far 
\note O que temos até agora.
%%%{{{ meta 
%%%}}}

Fatore o $x$ em primos (\ref[fundamental_theorem_of_arithmetic];
veja se a fatoração do $x$ é o próprio $x$.
Qual o problema com isso?
Demora demais!
Seria legal se a gente poderia decidir se $x$ é primo ou não
sem necessariamente precisar fatorá-lo.
No final das contas, fatorando acabamos com \emph{muita} mais informação
do que estamos buscando aqui.
\eop
De fato, \emph{pensando pouco}, parece que estou exagerando sobre o quão
ruim que é a situação: não precisamos achar a fatoração completa
do $x$.  Assim que achar o primeiro fator primo podemos já parar
o processo pois já temos nossa resposta.
\eop
De mais-fato-ainda, \emph{pensando mais}, isso não acaba sendo tão melhor
do que a idéia de achar a fatoração completa.
Cada divisão custa, e se a quantidade delas fosse pequena
em comparação com o tamanho do nosso número $x$, seria aceitável; mas não é.
Aqui \wq{pequena em comparação} significa de ordem de complexidade menor.

%%}}}

%%{{{ criterion: wilson_criterion
\criterion Wilson.
%%%{{{ meta 
\label wilson_criterion
%%%}}}

Para qualquer inteiro $p$,
$$
\text{$p$ primo}
\iff
(p-1)! \congmod p {-1}.
$$

\proof Demonstrado no~\ref[wilsons_theorem].

%%}}}

%%{{{ chinese_hypothesis 
\note Hipotese chinesa.
%%%{{{ meta 
\label chinese_hypothesis
%%%}}}

Começando testar uns números contra o teste de Fermat, observamos que
todos que \dq{são pegos} por ele, já estão pegos aplicando o teste
$2$-fermatinho.  Assim parece que nem precisamos testar contra os
$a$-fermatinhos para $a > 2$.
Essa hipótese é conhecida como \dterm{hipótese chinesa:}
$$
\lforall x
    {
      \lexists {1 < a < x - 1} {a^x \ncongmod x a}
      \implies
      2^x \ncongmod x 2
    }.
$$
É fácil ver como tal conjectura chegou a ser estipulada: de fato, todos
os inteiros até o $340$ são testemunhas dela.
Mas é um $\lforall x {\dots}$ que está sendo alegado aqui, e não há quantidade
suficiente de testemunhas que podemos testar para de fato confiar nela.
Surpreendentemente, o próximo número, o $341$ é o primeiro contraexemplo
para essa hipótese: de fato, $2^341 \congmod {341} 2$, mas mesmo assim
tem $a$-fermatinho que o $341$ não consegue enganar.

%%}}}

%%{{{ x: fooler_of_chinese 
\exercise Enganador da chinesa.
%%%{{{ meta 
\label fooler_of_chinese
%%%}}}

Verique que $2^{341} \ncongmod 341 2$, e que $341$ não consegue enganar mesmo o fermatinho:
ache um $a$-fermatinho por qual o $341$ é pego.

%%}}}

%%{{{ Carmichael_numbers 
\note Números Carmichael.
%%%{{{ meta 
\label Carmichael_numbers
\defines
    * número!Carmichael
    ;;
\credits
    * Carmichael : números
    ;;
\indexes
    * Carmichael!número   see: número
    ;;
%%%}}}

O $341$ foi o primeiro número que conseguiu enganar o $2$-fermatinho,
mas mesmo assim não conseguiu enganar o próprio fermatinho,
como tu descubriu no \ref[fooler_of_chinese] (né?)~achando um $a$ tal
que o $a$-fermatinho pegou o $341$ em flagrante.
Continuando testando os próximos números, parece de novo que
ninguém consegue enganar o fermatinho.
Novamente tal conclusão é errada: chegando no número $561$ encontramos
o primeiro exemplo de enganador de fermatinho.
O $561$ não é primo ($561 = 3 \ntimes 11 \ntimes 17$), mas mesmo assim
ele consegue enganar todos os $a$-fermatinhos!
Tais inteiros chamamos de \dterm{números Carmichael}, e eles são
bem raros em comparação com os primos---algo que vai acabar
facilitando nossa vida daqui a pouco.
Para um tempão não sabíamos se há uma quantidade infinita deles ou não;
de fato, há uma infinidade de números Carmichael, algo que foi demonstrado
só em 1994; mas não vamos precisar disso aqui.

%%}}}

%%{{{ pseudoprimes 
\note Pseudoprimos.
%%%{{{ meta 
\label pseudoprimes
%%%}}}

Dado um \dq{pseudocritério} de primalidade, como o da hipótese chinesa (o $2$-fermatinho)
ou o fermatinho, chamamos de \dterm{pseudoprimo} um número $x$ que conseguiu
satisfazer tal pseudocritério sem ser mesmo um primo.
A noção de pseudoprimo, então, depende do pseudocritério.
Percebemos então que $341$ é um pseudoprimo para o $2$-fermatinho,
e $561$ é um pseudoprimo para o fermatinho.

%%}}}

%%{{{ thm: fermatinho_loop_efficiency 
\theorem loop de fermatinho: eficiência.
%%%{{{ meta 
\label fermatinho_loop_efficiency
\indexes
    * eficiência!de Fermatinho
    ;;
%%%}}}

Seja $m>0$.
Se existe inteiro $a$ coprimo com $m$ tal que $a^{m-1} \ncongmod m 1$,
então para pelo menos metade dos inteiros $0 \leq x < m$,
$$
x^{m-1} \ncongmod m 1.
$$

\proof.
Seja $a$ um tal inteiro: coprimo com $m$ e tal que $a^{m-1} \ncongmod m 1$.
Basta associar com cada inteiro-aprovado (que conseguiu passar o teste),
um que não o passou, em forma \dterm{injetiva:} associamos
distintos aprovados com distintos reprovados.
Isso garanta que a quantidade dos dos aprovados não pode superar
a metade, que é exatamente o que precisamos demonstrar.
O mapeamento que procuramos é a $(x \mapsto ax)$: associamos cada
aprovado $x$ o inteiro $ax$, e basta demonstrar que:
(i) $ax$ realmente é reprovado (\reftag[fermatinho_loop_efficiency_proofpart_1];
(ii) o mapeamento realmente é injetivo (\reftag[fermatinho_loop_efficiency_proofpart_2]).
Deixo contigo.

%%}}}

%%{{{ x: fermatinho_loop_efficiency_proofpart_1 
\exercise.
%%%{{{ meta 
\label fermatinho_loop_efficiency_proofpart_1
%%%}}}

Demonstre a parte (i) do~\ref[fermatinho_loop_efficiency].

%%}}}

%%{{{ x: fermatinho_loop_efficiency_proofpart_2 
\exercise.
%%%{{{ meta 
\label fermatinho_loop_efficiency_proofpart_2
%%%}}}

Demonstre a parte (ii) do~\ref[fermatinho_loop_efficiency].

%%}}}

\endsection
%%}}}

%%{{{ Prime_generation 
\section Geração de primos.
%%%{{{ meta 
\label Prime_generation
%%%}}}

\TODO Terminar.

%%{{{ prime generation 
\note.
%%%{{{ meta 
%%%}}}

Já temos umas maneiras de \emph{gerar} primos à vontade.
O crivo de Eratosthenes (\ref[sieve_of_eratosthenes])
gera todos os primos até um dado número, e a demonstração
de Euclides sobre a quantidade dos primos fornece um gerador
de primos também.
Mas, aqui um desafio: achar um primo grande.
Nenhuma dessas idéias funciona bem aqui, pois aqui \wq{bem} significa
que tu vai achar tal primo antes de morrer.
E o que significa \wq{grande}?
Depende da situação, obviamente, então vamos considerar que um desafiador
escolha um comprimento $\ell$ e uma base $b$ e nosso objetivo é achar um primo $p$ cujo
númeral canônico na base $b$ tem tamanho $\ell$.
Efetivamente procuramos primo $b^\ell \leq p < b^{\ell+1}$.
Vamo concretizar a situação?
Ache um primo $p$ que, escrito no sistema posicional binário,
ocupa $4096$ bits.

%%}}}

%%{{{ Q: How would you proceed? 
\question.
%%%{{{ meta 
%%%}}}

Como procederias?

%%}}}

\spoiler

%%{{{ A: chutando
\note Chutando.
%%%{{{ meta 
%%%}}}

Por incrível que pareça, uma maneira muito eficiente é \emph{chutando}.
Escolhe aleatoriamente cada bit; verifique se o número gerado é primo;
se é, acabou, senão, chute novamente.

%%}}}

%%{{{ but does this work? 
\note Mas isso funciona?.
%%%{{{ meta 
%%%}}}

Essa idéia só vai funcionar se os primos não são muito raros.
Apresento aqui, sem demonstração, o famoso \emph{teorema dos números primos}
que estabelece exatamente a freqüência asintótica dos primos:

%%}}}

%%{{{ thm: prime_number_theorem 
\theorem Teorema dos Números Primos.
%%%{{{ meta 
\headerize
\label prime_number_theorem
\credits
    * Poussin : teorema dos números primos
    * Hadamard : teorema dos números primos
    * Riemann : função zeta
    ;;
\indexes
    * teorema!dos números primos
    * PNT       see: teorema dos números primos
    ;;
%%%}}}

Seja $\pi(x) \defeq \setstt {p \leq x} {$p$ primo}$.
Temos
$$
\pi(x) \assympeq \frac x {\log x}.
$$
Equivalentemente, $\seqn p n \assympeq \sequence {n \log n} n$.

\preproof.
A pergunta a qual este teorema responde tinha preocupado muitas lendas
(incluindo Euler, Gauss, Legendre, Dirichlet, Chebychev, e Riemann)
até finalmente foi demonstrado, por Hadamard e Poussin independentemente,
no ano \yearof{1896}, utilizando ferramentas de análise complexa, introduzidas
pelo Riemann.

\sketch Cadê a demonstração?.
As demonstrações mais conhecidas utilizam ferramentas de análise complexa
e, mesmo que existem umas elementares, ficam fora tanto do nosso alcance
quanto do nosso foco aqui.\foot
Análise complexa não é nada complexo nem é nada para dar medo para meu leitor.
Logo depois do estudo dos reais no \ref[The_reals], terás todas as ferramentas
para estudar o assunto, caso quiser; e tenho umas referências pra ti no fim
daquele capítulo.
\toof
O leitor interessado pode encontrar a demonstração em textos de teoria
dos números (analítica), por exemplo no \cite[apostolant: Chapter 13]
ou no \cite[hardywright: Chapter XXII].

%%}}}

%%{{{ what does that mean? 
\note O que isso significa, na prática, agora?.
%%%{{{ meta 
%%%}}}

Que existem por volta de $1/\ell$ primos com $\ell$ dígitos.
Ou seja, chutando $\ell$ algarismos $b$-ários, temos por volta de $1/\ell$ chances
de \dq{acertar} um primo.
No \reffull[The_reals] aprendemos sobre limites de seqüências de números e o enunciado
do \ref[prime_number_theorem] vai aparecer menos obscuro.
Mas por enquanto, é só entendê-lo na forma que mencionei aqui.

%%}}}

\endsection
%%}}}

%%{{{ Residue_systems 
\section Sistemas de resíduos.
%%%{{{ meta 
\label Residue_systems
%%%}}}

%%{{{ df: residue_systems_modulo_int 
\definition.
%%%{{{ meta 
\label residue_systems_modulo_int
\defines
    * resíduo
    * sistema completo de resíduos
    * sistema reduzido de resíduos
    ;;
\indexes
    * s.r.r.     see: sistema reduzido de resíduos
    * s.c.r.     see: sistema completo de resíduos
    ;;
%%%}}}

Se $x \cong y \pmod m$ dizemos que $y$ é \dterm{um resíduo de $x$ módulo $m$}.
Seja $S = \set{r_1,r_2,\dotsc,r_n}$ um conjunto de inteiros.
Chamamos o $S$ de \dterm{sistéma completo de resíduos módulo $m$} sse
para todo inteiro $x$ existe único $r \in S$ tal que $r$ é um resíduo de $x$ módulo $m$.
Ou seja, cada inteiro tem exatamente um representante seu (do seu time) nesse conjunto $R$.
Chamamos o $S$ de \dterm{sistéma reduzido de resíduos módulo $m$} sse:
(i) todos os membros de $S$ são coprimos com $m$;
(ii) $r_i \congmod m r_j$ implica $i=j$ (ou seja, os membros de $S$ são distintos dois-a-dois módulo $m$);
(iii) para todo inteiro $x$ coprimo com $m$, existe $r \in S$ tal que
$r$ é um resíduo de $x$ módulo $m$.
Se falar apenas de sistema completo (s.c.)~ou de sistema reduzido (s.r.)~sem
mencionar o módulo $m$, é porque o consideramos implícito pelo contexto.

%%}}}

%%{{{ x: all s.r. of the same type have the same cardinality 
\exercise.
%%%{{{ meta 
%%%}}}

Todos os sistemas de resíduos módulo $m$ do mesmo tipo (completo ou reduzido)
têm a mesma cardinalidade entre si.

%%}}}

%%{{{ notation: first definition of φ(m) 
\notation.
%%%{{{ meta 
%%%}}}

Denotamos a cardinalide (comum) dos sistemas \emph{reduzidos}
de resíduos módulo $m$ por $\tot m$.
Investigamos a função $\totsym$ logo na \ref[Enter_Euler].

%%}}}

%%{{{ x: Σ C & Π R 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $C$ um sistema completo e $R$ um sistema reduzido.
O que podes afirmar sobre os
\mathcols 2
\Sum  C &= {?}  &
\Prod R &= {?}
\endmathcols
Demonstre a corretude dos teus palpites.

%%}}}

%%{{{ Systems for free 
\note Sistemas de graça.
%%%{{{ meta 
%%%}}}

Tendo um sistema (completo ou reduzido) de resíduos módulo $m$, ganhamos
\dq{gratuitamente} outros sistemas (do mesmo tipo) de resíduos módulo o mesmo $m$.
A idéia dos próximos exercícios é investigar o que podemos concluir se começar
mexendo com um tal sistema $S$ para gerar outros.
O~que podemos concluir sobre o $S + \ell$?  Sobre o $aS$?
Virando as mesas, se por acaso o $R + \ell$ ou o $aS$ acaba,
sendo sistemas também, o que podemos concluir sobre o $\ell$?  Sobre o $a$?

%%}}}

\spoiler

%%{{{ x: C complete ⇒ C + ℓ complete 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $C$ um sistema completo de resíduos módulo $m$
Então o conjunto $C + \ell$ também é um sistéma completo de resíduos módulo $m$.

%%}}}

%%{{{ x: C complete ⇒ (aC complete ⇔ coprime a,m) 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $C$ sistema completo e $a$ inteiro.
Suponha que $aC$ também é um sistema completo.
O~que podes concluir sobre o $a$?
O recíproco da tua resposta é válido?

%%}}}

%%{{{ x: R reduced ⇒ (R + ℓ reduced ⇔ ℓ ≡ₘ 0) 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $R$ sistema reduzido e $\ell$ inteiro.
Suponha que $R + \ell$ também é um sistema reduzido.
O~que podes concluir sobre o $\ell$?

%%}}}

%%{{{ x: R reduced ⇒ (aR reduced ⇔ coprime a,m) 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $R$ sistema reduzido e $a$ inteiro.
Suponha que $aR$ também é um sistema reduzido.
O~que podes concluir sobre o $a$?
O recíproco da tua resposta é válido?

%%}}}

%%{{{ why_systems 
\note Por quê <<sistemas>>?.
%%%{{{ meta 
%%%}}}

Usamos a palavra \dq{sistema} em vez da \dq{conjunto}.  Por quê?
A idéia é que estamos interessados não apenas nos membros de tais conjuntos,
mas sim na estrutura algébrica que herdam dos inteiros.
Os exercícios seguintes devem deixar isso mais claro.

%%}}}

%%{{{ x: R complete => R (int)-closed-modulo-m 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $C$ um sistema completo de resíduos módulo $m$.
Mostre que $C$ é fechado módulo $m$ sob a estrutura algébrica dos inteiros
($0$, $1$, $(+)$, $(\ntimes)$, $(-\uhole)$). 

%%}}}

%%{{{ x: R reduced => R (1,(·))-closed-modulo-m 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $R$ um sistema reduzido de resíduos módulo $m$.
Então $R$ é $(1, (\ntimes))$-fechado módulo $m$.
Ainda mais, é fechado (módulo $m$, sempre) sob $(\ntimes)$-inversos.

%%}}}

%%{{{ x: coprime m,n & M reduced mod m & N reduced mod n ⇒ nM + mN reduced mod mn 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $m,n$ coprimos, e sejam $M$ e $N$ sistemas
reduzidos de resíduos módulo $m$ e $n$ respectivamente.
Demonstre que o $nM + mN$ é um sistema reduzido de resíduos módulo $mn$.

%%}}}

\endsection
%%}}}

%%{{{ Enter_Euler 
\section Euler entra.
%%%{{{ meta 
\label Enter_Euler
%%%}}}

%%{{{ df: euler_phi_function 
\definition Função totiente de Euler.
%%%{{{ meta 
\label euler_phi_function
\credits
    * Euler : função totiente
    ;;
\indexes
    * Euler!função    see: função totiente
    * totiente        see: função totiente
    ;;
\defines
    * {\totsym} -- a função totiente de Euler
    * função!totiente de Euler
    ;;
%%%}}}

Seja inteiro $n>0$.
Definimos
$$
\tot n \defeq \size { \setst {i \in \set{1,\dotsc,n}} {\gcd i n = 1} }.
$$
Em palavras, $\tot n$ é o número dos inteiros entre $1$ e $n$ que são coprimos com $n$.

%%}}}

%%{{{ x: calculate some values of phi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule os valores da $\tot n$ para $n=1,2,3,4,8,11,12,16.$

%%}}}

%%{{{ prop: tot_of_prime 
\property.
%%%{{{ meta 
\label tot_of_prime
%%%}}}

$\text{$p$ primo} \implies \tot p = p-1.$

\proof.
Como $p$ é primo, ele é coprimo com todos os $1,\dotsc,p-1$.
E como $\gcd p p = p \neq 1$, pela definição da $\totsym$ temos
$\tot p = p-1$.

%%}}}

%%{{{ x: number_of_multiples_of_a_until_an 
\exercise.
%%%{{{ meta 
\label number_of_multiples_of_a_until_an
%%%}}}

Quantos multiplos de $a$ existem no $\set{1,2,\dotsc,a^n}$?

%%}}}

%%{{{ x: tot_is_par_for_n_greater_than_2 
\exercise.
%%%{{{ meta 
\label tot_is_par_for_n_greater_than_2
%%%}}}

$\tot n$ é par para todo $n\geq 3$.

\hint
Ache uma maneira de ``casar'' entre-si todos os $1 \leq i < n$ que são
coprimos com o $n$.

%%}}}

%%{{{ x: tot_of_power_of_prime 
\exercise.
%%%{{{ meta 
\label tot_of_power_of_prime
%%%}}}

$
\text{$p$ primo} \implies
\tot {p^a} = p^a - p^{a-1} = p^{a-1} (p-1)
$.

\hint
Use a definição de $\totsym$ e o~\ref[number_of_multiples_of_a_until_an].

\solution
Seguindo a definição de $\totsym$, vamos contar todos os números
no $\set{1,2,\dotsc,p^i}$ que são coprimos com $p^i$.
Quantos não são?
Observe que como $p$ é primo,
os únicos que não são coprimos com ele,
são os múltiplos de $p$.
Pelo~\ref[number_of_multiples_of_a_until_an] temos a resposta.

%%}}}

%%{{{ x: sum_of_tots_of_powers_of_prime 
\exercise.
%%%{{{ meta 
\label sum_of_tots_of_powers_of_prime
%%%}}}

Sejam $p$ primo e $k\in\ints$.  Calcule o valor do somatório
$\Sum_{i=0}^k \tot {p^i}$.

\hint
Calcule o valor de cada termo aplicando o~\ref[tot_of_power_of_prime].

%%}}}

%%{{{ x: tot_of_product_of_primes 
\exercise.
%%%{{{ meta 
\label tot_of_product_of_primes
%%%}}}

$\text{$p,q$ primos, $p\neq q$} \implies \tot {pq} = (p-1)(q-1)$.

%%}}}

%%{{{ thm: tot_is_multiplicative 
\theorem.
%%%{{{ meta 
\label tot_is_multiplicative
\indexes
    * multiplicativa    see: função
    ;;
\defines
    * função!multiplicativa
    ;;
%%%}}}

A função $\totsym$ é \dterm{multiplicativa}:
$$
\gcd m n = 1 \implies \tot {mn} = \tot m \tot n.
$$

\sketch.
Arrume todos os números $1,2,\dotsc,mn$ numa tabela de dimensão $n \times m$ assim:
$$
\def\cvdts{\hfil\vdots\hfil}
\eightrm
\matrix
\format
\r\       & \ \r\     & \ \r \    &\ \ \c\ \ & \ \r\     &\ \ \c\ \ & \ \r\        & \ \r   \\
       1  &        2  &        3  & \cdots   &        r  & \cdots   &          m-1 &  m     \\
     m+1  &      m+2  &      m+3  & \cdots   &      m+r  & \cdots   &      m+(m-1) & 2m     \\
    2m+1  &     2m+2  &     2m+3  & \cdots   &     2m+r  & \cdots   &     2m+(m-1) & 3m     \\
    \cvdts&     \cvdts&     \cvdts&          &     \cvdts&          &     \cvdts   & \cvdts \\
(n-1)m+1  & (n-1)m+2  & (n-1)m+3  & \cdots   & (n-1)m+r  & \cdots   & (n-1)m+(m-1) & nm     \\
\endmatrix
$$

%%}}}

\TODO terminar.

%%{{{ x: tot_is_multiplicative_as_a_corollary_of_chinese 
\exercise.
%%%{{{ meta 
\label tot_is_multiplicative_as_a_corollary_of_chinese
%%%}}}

Obtenha o \ref[tot_is_multiplicative] como corolário
do~\ref[chinese_remainder_theorem_binary_case].

%%}}}

%%{{{ cor: tot_product_formula 
\corollary.
%%%{{{ meta 
\label tot_product_formula
%%%}}}

Se $n\geq 2$, então
$$
\tot n
= n \!\!\Prod\submath{\text{$p$ primo}\\p \divides n}\!\! \paren{1-\frac 1 p}
= n
\paren{1-\frac 1 {p_1}}
\paren{1-\frac 1 {p_2}}
\dotsb
\paren{1-\frac 1 {p_k}},
$$
onde os $p_i$'s são todos os primos divisores de $n$.

\sketch.
Escrevemos o $n$ na sua representação canônica pelo
\ref[fundamental_theorem_of_arithmetic]
e aplicamos repetitivamente o~\ref[tot_is_multiplicative].

\proof.
Pelo \ref[fundamental_theorem_of_arithmetic] seja
$$
n \eqass p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}
$$ a
\indexed[representação canônica!de inteiro]representação canônica do $n$.
Calculamos:
\compute
\tot n
&= \tot {p_0^{a_0} p_1^{a_1} \dotsb p_k^{a_k}}              \\
&= \tot {p_0^{a_0}} \tot{p_1^{a_1}} \dotsb \tot{p_k^{a_k}}  \by {\ref[tot_is_multiplicative]} \\
&=
p_0^{a_0}\paren{1 - \frac 1 {p_0}}
p_1^{a_1}\paren{1 - \frac 1 {p_1}}
\dotsb
p_k^{a_k}\paren{1 - \frac 1 {p_k}}                          \by {\ref[tot_of_power_of_prime]} \\
&=
p_0^{a_0}p_1^{a_1}\dotsb p_k^{a_k}
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}\\
&=
n
\paren{1 - \frac 1 {p_0}}\paren{1 - \frac 1 {p_1}}\dotsb\paren{1 - \frac 1 {p_k}}.
\endcompute

%%}}}

%%{{{ x: tot_preserves_divides 
\exercise.
%%%{{{ meta 
\label tot_preserves_divides
%%%}}}

$a \divides b \implies \tot a \divides \tot b$.

%%}}}

%%{{{ x: tot_of_even  
\exercise.
%%%{{{ meta 
\label tot_of_even
%%%}}}

$
\tot {2n} =
\knuthcases {
2\tot n,& $n$ é par \cr
\tot n, & $n$ é ímpar.
}
$

%%}}}

%%{{{ thm: euler_congruence_theorem 
\theorem Euler, de congruência.
%%%{{{ meta 
\label euler_congruence_theorem
\credits
    * Euler : teorema de congruência
    ;;
%%%}}}

Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$

\sketch.
Considere o conjunto
$$
\align
 R &= \set{r_1, r_2, \dotsc, r_{\tot m}}
\intertext{de todos os inteiros $r$ com $1 \leq r \leq m$, e $\gcd r m = 1$, e o conjunto}
aR &= \setst {ar} {r \in R}\\
   &= \set{ar_1, ar_2, \dotsc, ar_{\tot m}}.
\endalign
$$
Observamos agora que (módulo~$m$) os $ar_1,ar_2,\dotsc,ar_{\tot m}$
são apenas uma permutação dos $r_1,r_2,\dotsc,r_{\tot m}$.
Logo os seus produtórios são congruentes:
$$
(ar_1)(ar_2)\dotsb (ar_{\tot m})
\cong
r_1r_2\dotsb r_{\tot m}
\pmod m.
$$
Trabalhando na última congruência chegamos na congruência desejada.

%%}}}

%%{{{ cor: fermatinho_as_euler_corollary 
\corollary.
%%%{{{ meta 
\label fermatinho_as_euler_corollary
\credits
    * Euler
    ;;
\indexes
    * teorema!Fermatinho
    ;;
%%%}}}

Sejam $p$ primo e $a\in\ints$ com $\gcd a p = 1$.
Então
$$
a^{p-1} \cong 1 \pmod p.
$$

\sketch.
O resultado é imediato usando o teorema de Euler
(\reftag[euler_congruence_theorem]) e a~\ref[tot_of_prime].

\proof.
Como $p$ é primo, sabemos que $\tot p = p-1$, então temos:
\compute
a^{p-1}
&= a^{\tot m}       \by {\ref[tot_of_prime]} \\
&\cong 1 \pmod m.   \by {\ref[euler_congruence_theorem]}
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: little_fermat_multionomial_proof 
\problem.
%%%{{{ meta 
\label little_fermat_multionomial_proof
\credits
    * Leibniz : demonstração do pequeno Fermat
    * Euler : demonstração do pequeno Fermat
    ;;
%%%}}}

Ache mais uma demonstração do \dq{pequeno Fermat} usando o teorema multinominal.
Essa provavelmente é a primeira demonstração do teorema, feita (sem publicar)
por Leibniz, e redescoberta depois por Euler.

%%}}}

%%{{{ prob: odd_to_any_power_is_odd_oneliner 
\problem.
%%%{{{ meta 
\label odd_to_any_power_is_odd_oneliner
%%%}}}

Demonstre numa linha o~\ref[odd_to_any_power_is_odd]:
\proclaim{para todo $n\in\nats$ e todo inteiro ímpar $a$, $a^n$ é ímpar.}

\hint
Considere módulo $2$.

%%}}}

%%{{{ prob: generalization of odd_to_any_power_is_odd 
\problem.
%%%{{{ meta 
%%%}}}

(Generalização do~\ref[odd_to_any_power_is_odd].)
Sejam $a\in\ints$ e $m\in\nats$.
Demonstre numa linha que para todo $n\in\nats$,
existe $b\in\ints$ tal que $(am + 1)^n = bm + 1$.

\hint
Considere módulo $m$.

%%}}}

%%{{{ prob: m! divides the product of m consecutive ints 
\problem.
%%%{{{ meta 
%%%}}}

Demonstre que para todo $m\in\nats$, o produto de quaisquer $m$
consecutivos inteiros é divisível por $m!$.

%%}}}

%%{{{ prob: tot_of_product_general 
\problem.
%%%{{{ meta 
\label tot_of_product_general
%%%}}}

Demonstre que
$$
\tot {mn}
=
{\tot m \tot n}
\frac
d
{\tot d}
,\qquad\text{onde $d={\gcd m n}$}.
$$
Note quantas e quais das propriedades que já demonstramos são casos especiais dessa!

%%}}}

%%{{{ prob: a_certain_sum_is_one_mod_pq 
\problem.
%%%{{{ meta 
\label a_certain_sum_is_one_mod_pq 
%%%}}}

Sejam $p,q$ primos com $p\neq q$.
Demonstre que
$$
p^{q-1} + q^{p-1} \cong 1 \pmod {pq}.
$$

\hint
O que seria o $p^{q-1} + q^{p-1}$ módulo~$p$?
E módulo~$q$?

\hint
China.

%%}}}

%%{{{ prob: a_certain_sum_is_one_mod_ab 
\problem.
%%%{{{ meta 
\label a_certain_sum_is_one_mod_ab
%%%}}}

Ache uma generalização do \ref[a_certain_sum_is_one_mod_pq]
aplicável para inteiros $a,b$ com $\gcd a b = 1$.

\hint
Nesse caso \emph{não} temos
$$
a^{b-1} + b^{a-1} \cong 1 \pmod {ab}.
$$

\hint
$p-1 = \tot p$ para qualquer primo $p$.

\hint
Demonstre que:
$$
a^{\tot b} + b^{\tot a} \cong 1 \pmod {ab}.
$$

%%}}}

\endproblems
%%}}}

%%{{{ Cryptography 
\section Criptografia.
%%%{{{ meta 
%%%}}}

%%{{{ The idea of cryptography 
\TODO A idéia da criptografia.
%%}}}

%%{{{ Cryptography vs steganography 
\TODO Criptografia \vs steganografia.
%%}}}

%%{{{ Cryptography vs codification 
\TODO Criptografia \vs codificação.
%%}}}

%%{{{ Public-key cryptography 
\TODO Criptografia ``public-key''.
%%}}}

%%{{{ Criptografia RSA 
\TODO RSA criptografia e descriptografia.
%%}}}

%%{{{ thm 
\theorem.
%%%{{{ meta 
%%%}}}

Sejam $e, M$ inteiros com $\gcd e {\tot M} = 1$,
e seja $d$ um inverso de $e$ módulo~$\tot M$: $ed \cong 1 \pmod {\tot M}$.
Para cada $x$ com $\gcd x M = 1$,
$$
\paren{x^e}^d \cong m \pmod M.
$$

\proof.
Observe primeiramente que:
$$
ed \cong 1 \pmod {\tot M}
\intiff \tot M \divides ed - 1
\intiff \lexists {k\in\ints} {k\tot M = ed - 1}.
$$
Seja $k\in\ints$ então um tal $k$, e agora resolvendo por $ed$:
$$
ed = k\tot M + 1.
\tag{*}
$$
Calculamos:
\compute
\paren{x^e}^d
&= x^{ed}                   \\
&= x^{k\tot M + 1}          \by {por~(*)} \\
&= x^{k\tot M} x            \\
&= \paren{x^k}^{\tot M} x   \\
&\cong x  \pmod M,          \by {pelo teorema de Euler~\reftag[euler_congruence_theorem]} \\
\endcompute
onde no último passo precisamos a hipótese que $x$ e $M$ são coprimos
e logo, $x^k$ e $M$ também são.

%%}}}

%%{{{ x: what happens if m and φM are not coprime? 
\exercise.
%%%{{{ meta 
%%%}}}

O que acontece se $x$ e $M$ não são coprimos?

%%}}}

\endsection
%%}}}

%%{{{ Digital signatures 
\section Assinaturas digitais.
%%%{{{ meta 
%%%}}}

\TODO Terminar.

%%{{{ Waitaminat 
\note Perae!.
%%%{{{ meta 
%%%}}}

Recebi mesmo uma mensagem que Alice mandou pra mim.
Foi mesmo encryptada com minha chave pública, eu sou o único
que consigo descryptar facilmente essa mensagem para ler
seu conteúdo original.
Mas temos um problema sério aqui.
Mesmo eu sendo a única pessoa que consegue descryptar (facilmente)
as mensagem que foram encryptadas com minha chave pública
\emph{qualquer pessoa} tem como encryptar qualquer mensagem.
Como que eu posso saber que a mensagem que termina com
\wq{Abraço, Alice} foi escrita mesmo por Alice?

%%}}}

\endsection
%%}}}

%%{{{ Funções hash 
\section Funções hash.
%%%{{{ meta 
%%%}}}

\TODO Elaborar e terminar.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[babybm: \S\S1.6--1.9].

\cite[elements],
\cite[disquisitiones].

\cite[andrewsnumber].

\cite[nivennumbers],
\cite[hardywright].

Se os vários sistemas de numerais te deixaram com vontade de conhecer e analisar
mais, veja no \cite[taocp2: \S4.1].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Recursion_induction 
\chapter Recursão; indução.
%%%{{{ meta 
\label Recursion_induction
%%%}}}

\TODO limpar, terminar, organizar.

%%{{{ intro: we define Nats, not the natural numbers 
\chapintro
Vou começar definindo formalmente os naturais.
Na verdade, não vou definir os próprios números naturais.
Não: os \emph{números} estão lá nas núvens do nosso coração.
Não vamos nos preocupar com a questão \wq{o que \emph{é} o número cinco?}.
Vamos começar definindo uns possíveis \emph{numerais} para tais números,
que vou chamá-los de \dterm{Nats}, e a gente vai estudá-los e ver o que
podemos definir, calcular, e demonstrar sobre eles.
%%}}}

%%{{{ The Nats 
\section Os Nats.
%%%{{{ meta 
\label Nats_formally
%%%}}}

%%{{{ df: Nat 
\definition Nat.
%%%{{{ meta 
\label Nat
\defines
    * Nat
    ;;
%%%}}}

Definimos o tipo de dados {$\Nat$} com uma definição inductiva:
\tlist:
\li: $\Ze$ é um $\Nat$;
\li: Se $n$ é um $\Nat$, então $\Su \fa n$ é um $\Nat$;
\endtlist
Nada mais é um $\Nat$.

%%}}}

%%{{{ nat_data_forms 
\note Listando as formas.
%%%{{{ meta 
\label nat_data_forms 
%%%}}}

Escrevemos
$$
\dataforms \Nat = {\Ze \dataor \Su \fa \Nat}
$$
e introduzimos assim o tipo $\Nat$ listando todas as formas possíveis que seus
membros podem ter: cada $\Nat$ ou é o $\cons O$, ou é o $\cons S$ de algum $\Nat$.
Pronunciamos o símbolo \symq{$\dataorsymbol$} como \dq{ou}, entendendo que separa
as alternativas formas listadas.

%%}}}

%%{{{ nat_data_cons 
\note Listando os construtores.
%%%{{{ meta 
\label nat_data_cons
%%%}}}

Escrevemos
\data \Nat \\
\co \Ze : \Nat \\
\co \Su : \Nat \to \Nat \\
\enddata
para introduzir o tipo $\Nat$ listando todos os seus \dterm{construtores}
e seus tipos.
Assim sabemos que o $\cons O$ já é um $\Nat$ (ele é um construtor de aridade $0$: não
precisa de argumentos).
Por outro lado, o $\cons S$ \emph{não} é um $\Nat$, mas sim um $\Nat\to\Nat$, ou seja
precisa ser aplicado num $\Nat$, para virar um $\Nat$.

%%}}}

%%{{{ With rules of inference 
\note Com regras de inferência (1/2).
%%%{{{ meta 
%%%}}}

Uma maneira diferente de descrever \emph{a mesma idéia} é com \dterm{regras de inferência}.
Essa abordagem combina bem com as árvores sintácticas:
escrevemos
$$
\PROOFm {
\I0-------------------- {}
    {\cons O \is \Nat}
}
$$
e entendemos isso como
$$
\text{<<(do nada) posso concluir que $0$ é um $\Nat$>>}.
$$
Esse \wq{do nada} aqui quer dizer \wq{sem premissa nenhuma}.
Vamos dar o nome \namedrule{Zero} para essa \emph{regra de inferência},
pois vamos precisar referir a ela depois.
Escrevemos seu nome no lado direito da linha de inferência.
Fica assim:
$$
\PROOFmr {
\I0-------------------- {Zero}
    {\cons O \is \Nat}
}
$$
Olhando pra isso entendemos o seguinte:
a regra \namedrule{Zero}\ nos permite inferir que $0$ é um $\Nat$.

%%}}}

%%{{{ Q: how would you represent... 
\question.
%%%{{{ meta 
%%%}}}

Como tu representaria a segunda regra da~\ref[Nat] como uma regra
de inferência?

%%}}}

\spoiler

%%{{{ nat_data_rules 
\note Com regras de inferência (2/2).
%%%{{{ meta 
\label nat_data_rules 
%%%}}}

\mathcols 2
&
\PROOFmr {
\I0------------------- {Zero}
   {\cons O \is \Nat}
}
&&
\PROOFmr {
\A  {n \is \Nat}
\I1------------------------ {Succ}
   {\cons S \fa n \is \Nat}
}
\endmathcols

%%}}}

%%{{{ x: spot meta vs object on the definitions above 
\exercise.
%%%{{{ meta 
%%%}}}

Identifique variáveis \vs metavariáveis e símbolos da
linguagem-objeto \vs da metalinguagem nas definições acima.

%%}}}

%%{{{ eg: nat_four_check_tree 
\example usando árvores.
%%%{{{ meta 
\label nat_four_check_tree 
%%%}}}

Vamos inferir que $\SuP {\SuP {\SuP {\SuA \Ze}}}$ é um $\Nat$ mesmo.

\solution.
Vamos construir sua árvore \emph{bottom-up}.
O desafio é inferir
$$
\SuP {\SuP {\SuP {\SuA \Ze}}} \is \Nat
$$
e usando a regra \namedrule{Succ} podemos \emph{reduzir} esse problema para
$$
\PROOFmr {
\A     {\SuP {\SuP {\SuA \Ze}} \is \Nat}
\I1------------------------------------------ {Succ}
    {\SuP {\SuP {\SuP {\SuA \Ze}}} \is \Nat}
}
$$
Essa árvore tem afirmações \dq{abertas} então não terminamos ainda.
Usando a mesma regra reduzimos o $\SuP {\SuP {\SuA \Ze}} \is \Nat$ para:
$$
\PROOFmr {
\A        {\SuP {\SuA \Ze} \is \Nat}
  \I1------------------------------------ {Succ}
      {\SuP {\SuP {\SuA \Ze}} \is \Nat}
\I1------------------------------------------ {Succ}
    {\SuP {\SuP {\SuP {\SuA \Ze}}} \is \Nat}
}
$$
e continuando nessa maneira, chegamos finalmente no
$0 \is \Nat$; agora usamos a regra \namedrule{Zero},
fechando assim a única coisa que tava aberta:
$$
\PROOFmr {
            \I0---------------- {Zero}
                {\Ze \is \Nat}
         \I1---------------------- {Succ}
             {\SuA \Ze) \is \Nat}
      \I1----------------------------- {Succ}
          {\SuP {\SuA \Ze} \is \Nat}
   \I1----------------------------------- {Succ}
       {\SuP {\SuP {\SuA \Ze}} \is \Nat}
\I1------------------------------------------- {Succ}
    {\SuP {\SuP {\SuP {\SuA \Ze}}} \is \Nat}
}
$$

%%}}}

%%{{{ x: read the tree bottom-up and top-down 
\exercise.
%%%{{{ meta 
%%%}}}

Leia essa árvore tanto de baixo pra cima, quanto de cima pra baixo!

%%}}}

%%{{{ eg: nat_four_check_words 
\example usando palavras.
%%%{{{ meta 
%%%}}}

Podemos inferir que $\SuA (\SuA (\SuA (\SuA \Ze))) \is \Nat$ usando palavras tambem,
ficando assim mais perto da~\ref[Nat], mas para esse tipo de derivação fica bizarro:
\quote
<<Como $\Ze$ é um Nat (pela primeira cláusula),
logo $\SuA \Ze$ é um Nat (pela segunda com $n\asseq \Ze$).
Logo $\SuA (\SuA \Ze)$ é um Nat, de novo pela segunda cláusula,
essa vez com $n\asseq \SuA \Ze$\dots>>
\endquote
E já cansei de escrever então vou parar aqui.
Espero que apreciamos a laconicidade e clareza das árvores
para esse tipo de inferência.

%%}}}

%%{{{ notation: nat_sugar 
\notation Açúcar sintáctico.
%%%{{{ meta 
\label nat_sugar
%%%}}}

Escrever
\mathcols 5
&\Ze, &
&\SuA \Ze, &
&\SuA (\SuA \Ze), &
&\SuA (\SuA (\SuA \Ze)), &
&\dotsc
\intertext{às vezes pode ser cansativo na mão ou nos olhos.
Vamo introduzir pouco açúcar sintáctico então.
Usarei as palavras}
&0, &
&S0, &
&SS0, &
&SSS0, &
&\dotsc
\intertext{como apelidos desses Nats.
Ainda mais, vou usar os numerais mais populares}
&0, &
&1, &
&2, &
&3, &
&\dotsc
\endmathcols
para denotar os mesmos objetos.
Mas é importante entender que são apenas isso, um nome alternativo
para os nomes \dq{oficiais}; então quando eu peço para calcular,
por exemplo, \wq{quanto é $3\ntimes 2$}, ou \wq{quanto é $SSS0\ntimes SS0$},
o que tu precisas calcular mesmo é o
$$
\SuA (\SuA (\SuA \Ze)) \ntimes \SuA (\SuA \Ze)
$$
e espero que tu chegarás no resultado que eu chamaria de $6$
ou de $SSSSSS0$, ou seja, no $\SuA (\SuA (\SuA (\SuA (\SuA (\SuA \Ze)))))$.
Finalmente, estendemos este açúcar para aplicá-lo até quando temos variáveis envolvidas:
tendo $n \hastype \Nat$, escrevemos, por exemplo,
$$
SS2 + SSSn
$$
como abreviação da
$$
\SuA (\SuA (\SuA (\SuA \Ze))) + \SuA (\SuA (\SuA n)).
$$

%%}}}

%%{{{ A grammar for some abbrevs 
\note Uns apelidos com gramática BNF.
%%%{{{ meta 
%%%}}}

Olhe na sintaxe BNF para descrever a gramática que gera as palavras-apelidos
$0,S0,SS0,SSS0,\dotsc$:
$$
\bnf{Nat} \bnfeq 0 \bnfor S \bnf{Nat}
$$
Note a semelhança com o \ref[nat_data_forms].
Ainda mais, para gerar a palavra $SSSS0$ a partir dessa gramática
procedemos assim:
\mathcol
\bnf{Nat}
&\leadsto S\bnf{Nat} \\
&\leadsto SS\bnf{Nat} \\
&\leadsto SSS\bnf{Nat} \\
&\leadsto SSSS\bnf{Nat} \\
&\leadsto SSSS0.
\endmathcol
Isso corresponde à inferência $\SuA (\SuA (\SuA (\SuA \Ze))) \hastype \Nat$
do \ref[nat_four_check_tree].

%%}}}

%%{{{ eg: 0,1,2,3 ; primes 
\example.
%%%{{{ meta 
%%%}}}

Aqui os numerais de $\Nat$ que correspondem nos primeiros
$5$ números naturais:
$$
0,\quad
S0,\quad
SS0,\quad
SSS0,\quad
SSSS0.
$$
Escrevemos a seqüência de \dq{primos naturais} então assim:
$$
SS0,\quad
SSS0,\quad
SSSSS0,\quad
SSSSSSS0,\quad
SSSSSSSSSSS0,\quad\dots
$$
Ou seja, cada número natural $n$ corresponde numa seqüência
de $n$ cópias de $S$, seguidas por um $0$.

%%}}}

%%{{{ remark: unary numeral system 
\remark.
%%%{{{ meta 
%%%}}}

Esse sistema de numerais é praticamente um sistema unário.
A grande \emph{desvantagem} dele é que o tamanho dos numerais cresce
analogamente com o tamanho de números.
Comparando com os sistemas mais comuns com bases $b > 1$ como o binário
ou o decimal, já parece deficiente nesse sentido.
Mas uma \emph{vantagem} para a gente nesse caso é sua simplicidade
na sua definição recursiva:
\emph{cada Nat ou é o zero, ou o sucessor de um Nat}.
Tudo sobre os Nats é desenvolvido usando apenas essa definição simplíssima.

%%}}}

%%{{{ canonic_nats 
\definition Os Nats canônicos.
%%%{{{ meta 
\label canonic_nats
\defines
    * canônico
    ;;
%%%}}}

Chamamos os termos
$$
\Ze, \quad
\SuA \Ze, \quad
\SuA (\SuA \Ze), \quad
\SuA (\SuA (\SuA \Ze)), \quad
\SuA (\SuA (\SuA (\SuA \Ze))), \quad
\dotsc
$$
de \dterm{valores canônicos} ou \dterm{literais} do tipo $\Nat$.

%%}}}

%%{{{ operator_vs_constructor 
\note Operador \vs construtor.
%%%{{{ meta 
\label operator_vs_constructor
\defines
    * construtor
    ;;
%%%}}}

Logo vamos definir operações nos Nats ($(+)$, $(\ntimes)$, etc.)
e vamos ter, por exemplo, que
$$
S(SS0 + (SSS0 \ntimes SS0)) \is \Nat
$$
também, mas obviamente faz sentido perguntar
\quote
<<Quanto é $S(SS0 + (SSS0 \ntimes SS0))$?>>
\endquote
e a resposta deve ser $SSSSSSSSS0$.
Mas não faz sentido perguntar
\quote
<<Quanto é $SS0$?>>
\endquote
Ou seja: esse $S$ (que vem da palavra ``sucessor'') não representa
um operador que deve ser aplicado num argumento e que vai retornar um
resultado com valor.  Não!  Esse $S$ é o que chamamos de \dterm{construtor}
de valores, ou seja, o $SS0$ já é um valor próprio, um valor final,
um valor canônico: sem nada mais para ser calculado.
Por o mesmo motivo não faz sentido perguntar
\quote
<<Quanto é $2$?>>
\endquote
$2$ é $2$ ué.

%%}}}

%%{{{ equality_of_Nat 
\note Igualdade entre Nats.
%%%{{{ meta 
\headerize
\label equality_of_Nat
%%%}}}

Naturalmente consideramos todos os valores canônicos como distintos,
ou seja, para quaisquer $x,y\is\Nat$ temos:
\mathcall
                 & \Ze \neq \SuA x  \called {disjointness} \\
\SuA x = \SuA y  & \implies x = y.  \called {injectiviy}   \\
\intertext{A segunda nos permite \dq{cortar os $\Su$'s} numa igualdade
entre sucessores.  Ela é freqüentemente usada na forma da sua contrapositiva:}
x \neq y         & \implies \SuA x \neq \SuA y.
\endmathcall
Destacamos esses dois como princípios sobre o $\Nat$, que determinam
o que significa $(\eqof \Nat)$.

%%}}}

\endsection
%%}}}

%%{{{ Setup_for_recind 
\section Pouco de setup.
%%%{{{ meta 
\label Setup_for_recind
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já encontramos no \ref[equality_of_Nat] dois princípios sobre seus construtores.
Na verdade, o $\Nat$ não tem nada especial nesse quesito.
Estipulamos os princípios seguintes sobre qualquer tipos de dados definido indutivamente:

%%}}}

%%{{{ principle: datatype_disjointness_of_constructors 
\principle Disjointness of constructors.
%%%{{{ meta 
\label datatype_disjointness_of_constructors
%%%}}}

Construtores distintos constroem valores distintos.

%%}}}

%%{{{ principle: datatype_injectivity_of_constructors 
\principle Injectivity of constructors.
%%%{{{ meta 
\label datatype_injectivity_of_constructors 
%%%}}}

O mesmo construtor aplicado em valores distintos constrói valores distintos.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Veja que os dois princípios listados no \reftag[equality_of_Nat] são,
de fato, apenas as traduções destes princípios para o tipo $\Nat$.

%%}}}

\endsection
%%}}}

%%{{{ Defining functions recursively 
\section Definindo funções recursivamente.
%%%{{{ meta 
%%%}}}

%%{{{ df: nats_double_def 
\definition.
%%%{{{ meta 
\label nats_double_def
%%%}}}

Definimos a $\double$ que retorna o dobro da sua entrada:
\fundef
\double : \Nat \to \Nat \\
\doubleA \Ze        &= \Ze  \\
\doubleP {\SuA n} &= \SuP {\SuP {\doubleA n}}. \\
\endfundef

%%}}}

%%{{{ df: nats_plus_recursive_def 
\definition Adição.
%%%{{{ meta 
\label nats_plus_recursive_def
%%%}}}

Definimos a operação $(+)$ no $\Nat$:
\fundef
(+) : \Nat \to \Nat \to \Nat \\
n + \Ze      &= n  \\
n + (\SuA m) &= \SuA {(n + m)}. \\
\endfundef

%%}}}

%%{{{ implicit_tags 
\note Tags implicitos.
%%%{{{ meta 
\label implicit_tags
%%%}}}

Em vez de ficar dando rótulos para cada \dq{equação}
de definições como a \ref[nats_plus_recursive_def],
adotamos a convenção que usamos a notação \funref[f.i]
para referir à $i$-ésima \dq{equação} da definição da $f$.
Assim, escrevemos \sq{\funref[(+).1]} e \sq{\funref[(+).2]} para referir
às duas equações da \reftag[nats_plus_recursive_def], respeitando
a ordem que elas foram escritas.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Antes de tudo, precisamos aprender bem \emph{como calcular}.
O modelo computacional que seguimos é bem simples:
foque numa subexpressão e a substitua por seu igual.
No exemplo seguinte calculamos e confirmamos que\dots
$3 + 2 = 5$.

%%}}}

%%{{{ eg: three_plus_two_formally 
\example.
%%%{{{ meta 
\label three_plus_two_formally
%%%}}}

Calcule a soma $SSS0 + SS0$.

\solution.
Temos a expressão
$$
SSS0 + SS0.
$$
Qual equação aplica?
Com certeza não podemos aplicar a primeira (na direção ``$\Rightarrow$''),
pois nossa expressão não tem a forma $n + 0$.
Por que não?  O primeiro termo na nossa expressão, o $SSS0$, não é um problema
pois ele pode ``casar'' com o $n$ do lado esquerdo da \funref[(+).1].
Mas nosso segundo termo, o $SS0$,
não pode casar com o $0$, então a \funref[(+).1] não é aplicável.
A segunda equação é sim, pois nossos termos podem casar assim
com as variáveis da \funref[(+).2]:
\compute
{\mubrace{SSS0}n} + {S\mubrace{S0}m} \\
\intertext{Tomando $n\asseq SSS0$ e $m\asseq S0$
substituimos nossa expressão por seu igual seguindo a \funref[(+).2]:}
{\mubrace{SSS0}n} + {S\mubrace{S0}m}
&= S\bigparen{ {\mubrace{SSS0}n} + {\mubrace{S0}m} }  \by {por \funref[(+).2]} \\
\intertext{Depois um passo de cálculo então chegamos na expressão
$S(SSS0 + S0)$.
Como nenhuma equação tem a forma $S(\text{\thole}) = \text{\lthole}$,
olhamos ``dentro'' da nossa expressão para achar nas suas subexpressões
possíveis ``casamentos'' com nossas equações.
Focamos então na subexpressão sublinhada
$S(\underline{SSS0 + S0})$:
vamos tentar substituí-la por algo igual.
Novamente a primeira equação não é aplicavel
por causa do novo segundo termo ($S0$), mas a \funref[(+).2] é:}
S\bigparen{{\mubrace{SSS0}n} + {S\mubrace{0}m}}\\
\intertext{Tomando agora $n\asseq SSS0$ e $m\asseq 0$ substituimos de novo
seguindo a \funref[(+).2]:}
S\tobrace{\bigparen{{\mubrace{SSS0}n} + {S\mubrace{0}m}}}{isso}
&= S\tobrace{S\bigparen{ {\mubrace{SSS0}n} + {\mubrace{0}m} }}{por isso}  \by {por \funref[(+).2]} \\
\intertext{Agora focamos na subexpressão $SS(\underline{SSS0 + 0})$ e podemos finalmente
aplicar a primeira equação:}
SS\bigparen{{\mubrace{SSS0}n} + 0}\\
\intertext{então tomando $n\asseq SSS0$ substituimos}
SS\tobrace{\bigparen{{\mubrace{SSS0}n} + 0}}{isso}
&= SS\tobrace{ {\mubrace{SSS0}n} }{por isso}  \by {por \funref[(+).1]} \\
\endcompute
Finalmente chegamos no resultado: no termo $SSSSS0$.
Nunca mais vamos escrever tudo isso com tanto detalhe!
Esse cálculo que acabamos de fazer, escrevemos curtamente nessa forma:
\compute
SSS0 + SS0
&= S(SSS0 + S0) \by {por \funref[(+).2]} \\
&= SS(SSS0 + 0) \by {por \funref[(+).2]} \\
&= SSSSS0       \by {por \funref[(+).1]} \\
\endcompute
escrevendo apenas em cada linha o que foi usado.

%%}}}

%%{{{ When do I stop? 
\note Quando termino?.
%%%{{{ meta 
%%%}}}

Termino quando chegar num \emph{valor canônico}.
Quando eu peço para calcular quanto é $SSS0 + SS0$ por exemplo,
a idéia é achar seu valor canônico, exatamente como acontece
quando pedimos para uma pessoa achar
\quote
<<Quanto é $2+3$?>>
\endquote
Uma resposta
\quote
<<$2+3=2+3$>>
\endquote
não seria aceitável---mesmo assim, é correta, não é?---pois
a pessoa que perguntamos não achou o valor canόnico (nesse caso $5$).

%%}}}

%%{{{ Is it always possible to terminate? 
\note Dá pra terminar sempre?.
%%%{{{ meta 
%%%}}}

Sempre tem como chegar num valor canônico?
Por enquanto não sabemos!
Realmente a $(+)$ na maneira que foi definida é uma operação
\dterm{total}, ou seja, sempre termina num valor canônico,
mas não é algo que deve se preocupar neste momento.
Estudamos muito esse assunto no~\ref[Computability_theory].

%%}}}

%%{{{ x: zero_plus_four_formally 
\exercise.
%%%{{{ meta 
\label zero_plus_four_formally
%%%}}}

Calcule a soma $0 + SSSS0$.

%%}}}

%%{{{ Evaluation strategy 
\note Estratégias de evaluação.
%%%{{{ meta 
\defines
    * estratégia!de evaluação
    ;;
%%%}}}

Vamos dizer que queremos calcular começando com uma expressão mais complexa,
como por exemplo a
$$
0 + \bigparen{0 + S\bigparen{(SS0 + 0) + 0}}.
$$
Como procedimos?
A expressão inteira não pode ser substituida pois nenhuma das \funref[(+).1]--\funref[(+).2] tem
essa forma, mas aparecem várias subexpressões em quais podemos \emph{focar}
para nosso próximo passo de cálculo:
$$
\align
0 + \underline{\bigparen{0 + S\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com \funref[(+).2]}\\
0 + \bigparen{0 + S\underline{\bigparen{(SS0 + 0) + 0}}},&\quad\text{casando com \funref[(+).1]}\\
0 + \bigparen{0 + S\bigparen{\underline{(SS0 + 0)} + 0}},&\quad\text{casando com \funref[(+).1]}.
\endalign
$$
Podemos seguir uma \dterm{estratégia de evaluação} específica, por exemplo,
focando sempre na expressão que aparece primeira à esquerda; ou podemos
escolher cada vez onde focar aleatoriamente; etc.
No~\ref[three_plus_two_plus_one] tu vai ter que escolher onde focar
várias vezes.

%%}}}

%%{{{ x: three_plus_two_plus_one 
\exercise.
%%%{{{ meta 
\label three_plus_two_plus_one
%%%}}}

Calcule os valores das expressões $SSS0 + (SS0 + S0)$ e $(SSS0 + SS0) + S0$.

\solution
Um caminho para calcular a primeira é o seguinte:
\compute
SSS0 + \underline{(SS0 + S0)}
&= SSS0 + S\underline{(SS0 + 0)} \by {por \funref[(+).2]} \\
&= \underline{SSS0 + SSS0}       \by {por \funref[(+).1]} \\
&= S\underline{(SSS0 + SS0)}     \by {por \funref[(+).2]} \\
&= SS\underline{(SSS0 + S0)}     \by {por \funref[(+).2]} \\
&= SSS\underline{(SSS0 + 0)}     \by {por \funref[(+).2]} \\
&= SSSSSS0                       \by {por \funref[(+).1]} \\
\intertext{e um caminho para calcular a segunda é o:}
\underline{(SSS0 + SS0) + S0}
&= S(\underline{(SSS0 + SS0)} + 0)  \by {por \funref[(+).2]} \\
&= S(S\underline{(SSS0 + S0)} + 0)  \by {por \funref[(+).2]} \\
&= S\underline{(SS(SSS0 + 0) + 0)}  \by {por \funref[(+).2]} \\
&= SSS\underline{(SSS0 + 0)}        \by {por \funref[(+).1]} \\
&= SSSSSS0                          \by {por \funref[(+).1]} \\
\endcompute

%%}}}

%%{{{ Where is the recursion and what don't we have a tijolo problem? 
\note Cadê a recursão e por quê não temos problema tipo tijolo?.
%%%{{{ meta 
%%%}}}

Estamos definindo a própria operação $(+)$, e na segunda linha
da sua definição aparece o $(+)$ tanto no lado esquerdo, quanto no lado direito.
Por isso chamamos a definição recursiva.
Se definimos $(+)$ em termos dele mesmo, por que não temos o problema
tipo \emph{tijolo} que discutimos no \ref[what_is_tijolo]?
(Chegou a hora que tinha prometido no~\reftag[recursive_definitions_teaser].)
Olhando com mais atenção, percebemos que não definimos o que significa
\emph{somar} em termos do que significa \emph{somar} mesmo;
mas definimos sim o que significa \emph{somar os números $n$ e $Sm$}
em termos do que significa \emph{somar os números $n$ e $m$}.
No lado direito, uma coisa nos argumentos da nossa operação está
diminuindo (os $S$'s do segundo argumento) assim evitando o loop
infinito, chegando finalmente na primeira equação \emph{depois duma
quantidade finita} de perguntas <<e o que é\dots?>>.

%%}}}

%%{{{ x: nats_double_def 
\exercise.
%%%{{{ meta 
\label nats_double_def
%%%}}}

Defina (recursivamente), e sem usar a $(+)$, uma função
$\fun{double} : \Nat \to \Nat$ que dobra sua entrada.
Verifique que o dobro de três ($SSS0$) é seis ($SSSSSS0$).

\hint
Pensando fora do $\Nat$:
como podemos calcular o valor de $2(n+1)$, se sabemos como dobrar
qualquer número menor de $n+1$?

\hint
$2(n+1) = 2n + 2$.

\solution
\DefFun double
Definimos:
\fundef
\double : \Nat \to \Nat \\
\doubleA \Ze      &= \Ze \\
\doubleA (\SuA n) &= \SuA (\SuA (\doubleA n)).
\endfundef
Calculamos:
\compute
\doubleA (\SuA (\SuA (\SuA \Ze)))
&= \SuA (\SuA (\doubleA (\SuA (\SuA \Ze))))                 \by {por \funref[double.2]} \\
&= \SuA (\SuA (\SuA (\SuA (\doubleA (\SuA \Ze)))))          \by {por \funref[double.2]} \\
&= \SuA (\SuA (\SuA (\SuA (\SuA (\SuA (\doubleA \Ze))))))   \by {por \funref[double.2]} \\
&= \SuA (\SuA (\SuA (\SuA (\SuA (\SuA \Ze))))).             \by {por \funref[double.1]}
\endcompute

%%}}}

%%{{{ A worse programmer 
\note Um programador pior.
%%%{{{ meta 
%%%}}}

Alguém definiu a adição usando essas quatro equações:
\fundef
(+) : \Nat \to \Nat \to \Nat \\
0  &+ &0  &= 0  \\
Sn &+ &0  &= Sn \\
0  &+ &Sm &= Sm \\
Sn &+ &Sm &= S(Sn + m).
\endfundef
Ou seja, para cada argumento da operação, ele tratou os dois
casos principais separadamente, resultando assim em quatro
equações.
Mas, olhando nas primeiras duas, dá pra ver que ambas são
casos especiais da nossa primeira equação.
No final das contas, nas duas o que acontece é que o primeiro
argumento acaba sendo o resultado da soma, e é exatamente isso
que nossa primeira equação disse.
Nossa definição é bem melhor então, mais elegante e econômica.

%%}}}

%%{{{ x: nats_ntimes_recursive_def 
\exercise.
%%%{{{ meta 
\label nats_ntimes_recursive_def
%%%}}}

Defina a multiplicação no $\nats$.

\hint
Precisa de novo duas equações:
$$
\align
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
A primeira equação é fácil completar:
$$
\align
n \ntimes 0   &= 0
\intertext{talvez ajuda pensar numa outra equação mais simples:}
n \ntimes S0  &= \text{\lthole}
\endalign
$$
Depois?

\hint
Tu tens acesso na operação \symq{$+$} pois já definimos!

\hint
Provavelmente até agora tens:
$$
\align
n \ntimes 0    &= 0 \\
n \ntimes S0   &= n \\
n \ntimes SS0  &= n + n \\
n \ntimes SSS0 &= (n + n) + n \\
               &\eqvdots
\intertext{Observe que o ``valor'' (lado direito) de cada nova linha é o valor
da linha anterior ``$+n$''.  Mas temos um nome para o lado direito da linha
anterior: \emph{seu lado esquerdo!}
Isso deve ser suficiente para achar como escrever a segunda linha da definição:}
n \ntimes 0  &= \text{\lthole}\\
n \ntimes Sm &= \text{\lthole}
\endalign
$$

\hint
Na segunda equação, no seu lado direito, tu tens acesso no valor
$n \ntimes m$, pois é ``mais simples'' do que o $n \ntimes Sm$.
Isso é o poder da recursão: podes considerar o problema que tu
tá tentando resolver (definir a multplicação), como resolvido
para as ``entradas mais simples''.

\solution
$$
\align
n \ntimes 0  &= 0                 \tag{m1}\\
n \ntimes Sm &= (n\ntimes m) + n  \tag{m2}
\endalign
$$

%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule o $2(0+1)$.

%%}}}

%%{{{ x: two_times_three_and_three_times_two 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule os $2 \ntimes 3$ e $3 \ntimes 2$.

%%}}}

%%{{{ x: nats_exp_recursive_def 
\exercise.
%%%{{{ meta 
\label nats_exp_recursive_def
%%%}}}

Defina a exponenciação no $\nats$.

\solution
Definimos:
$$
\align
n \expop 0  &= S0 \\
n \expop Sm &= (n \expop m) \ntimes n.
\intertext{ou, se preferir usar a notação padrão para exponenciação e multiplicação:}
n^0    &= S0 \\
n^{Sm} &= n^m \ntimes n.
\intertext{Também pode ser definida assim:}
n^0    &= S0 \\
n^{Sm} &= n \ntimes n^m.
\endalign
$$
Depois vamos comparar essas duas definições.

%%}}}

%%{{{ x: two_times_zero_plus_one 
\exercise.
%%%{{{ meta 
\label two_times_zero_plus_one
%%%}}}

Calcule o $2^3$.

%%}}}

%%{{{ x: fibonacci_nats 
\exercise.
%%%{{{ meta 
\label fibonacci_nats
%%%}}}

Defina usando equações recursivas a \dterm{seqüência Fibonacci},
como uma função de $\Nat$ para $\Nat$.

%%}}}

%%{{{ x: quot_rem_by_three 
\exercise.
%%%{{{ meta 
\label quot_rem_by_three
%%%}}}

Considere as funções seguintes definidas recursivamente:
\fundefs 2
\fundefed {
q  : \Nat \to \Nat \\
\fA q \Ze                     &= \Ze \\
\fP q {\SuA \Ze}              &= \Ze \\
\fP q {\SuP {\SuA \Ze}}       &= \Ze \\
\fP q {\SuP {\SuP {\SuA n}}}  &= \SuP {\fA q n} \\
} &
\fundefed {
r : \Nat \to \Nat \\
\fA r \Ze                     &= \Ze \\
\fP r {\SuA \Ze}              &= \SuA \Ze \\
\fP r {\SuP {\SuA \Ze}}       &= \SuP {\SuA \Ze} \\
\fP r {\SuP {\SuP {\SuA n}}}) &= \fA r n \\
}
\endfundefs
\tlist:
\li (i):  Re-escreva essas definições numa maneira mais abreviada.
\li (ii): O que cada função calcula?
\endtlist

\hint
Para a (ii), calcule os $\fA q {11}$, $\fA q {12}$, $\fA r {11}$, e $\fA r {12}$.

\solution
(i) Uma maneira bem mais curta para defini-las:
\fundefs 2
\fundefed {
q  : \Nat \to \Nat \\
\fP q {\SuP {\SuP {\SuA \Ze}}}  &= \SuP {\fA q n} \\
\fA q \phole                    &= \Ze \\
} &
\fundefed {
r : \Nat \to \Nat \\
\fP r {\SuP {\SuP {\SuA n}}}) &= \fA r n \\
\fA r n                       &= n \\
}
\endfundefs
(ii) A $q$ calcula o quociente da divisão da sua entrada por $3$, e a $r$ o resto.

%%}}}

\endsection
%%}}}

%%{{{ Proving properties of natural numbers without induction 
\section Demonstrando propriedades de naturais sem indução.
%%%{{{ meta 
\label Proving_properties_of_nats_by_induction
%%%}}}

%%{{{ convention about quantifiers 
\note Convenção.
%%%{{{ meta 
%%%}}}

Nessa secção todos os quantificadores que aparecem \dq{nus}
\emph{quantificam sobre os naturais}.  Por exemplo
$$
\pforall x
\pforall y
\pexists z
\lforall w
         {\phi(x,y,z,w)}
$$
significa
$$
\pforall {x \is \Nat}
\pforall {y \is \Nat}
\pexists {z \is \Nat}
\lforall {w \is \Nat}
         {\phi(x,y,z,w)}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos primeiramente \emph{definir} recursivamente as tres operações de adição,
multiplicação, e exponenciação:

%%}}}

%%{{{ df: natops_rec_defs 
\definition.
%%%{{{ meta 
\label natops_rec_defs
%%%}}}

Definimos as operações de adição, multiplicação, e exponenciação
recursivamente assim:
\fundefs 3
\fundefed {
(+) : \Nat \to \Nat \to \Nat \\
n + 0  &= n \\
n + Sm &= S(n+m)
} &
\fundefed {
(\ntimes) : \Nat \to \Nat \to \Nat \\
n \ntimes 0  &= 0 \\
n \ntimes Sm &= (n \ntimes m) + n
} &
\fundefed {
(\expop) : \Nat \to \Nat \to \Nat \\
n \expop 0  &= S0 \\
n \expop Sm &= (n \expop m) \ntimes n.
}
\endfundefs
Observe que cada uma dessas equações tem um implícito
$\pforall n$ ou $\pforall n \pforall m$ na frente dela.

%%}}}

%%{{{ conventions about precedence and associativity 
\note Convenções.
%%%{{{ meta 
%%%}}}

Seguindo a convenção comum, escrevemos o $x\expop y$ como $x^y$,
mas mesmo assim consideramos isso como um açúcar sintáctico para
a expressão $x \expop y$.  Entendemos então que no $x^y$ temos
uma aplicação duma operação binária (aplicada nos argumentos $x$ e $y$).
Vamos seguir também a convenção que a exponenciação
\dq{pega mais forte} que as outras duas operações,
e que multiplicação pega mais forte que a adição:
$a \ntimes b^c$ escrito sem parênteses significa
$a \ntimes (b \expop c)$ e não $(a \ntimes b) \expop c$;
e $a + b\ntimes c$ significa $a + (b\ntimes c)$.
Graças às associatividades das $(+)$ e $(\ntimes)$
(\ref[natadd_is_associative] e~\ref[natmult_is_associative])
podemos escrever $a + b + c$ e $a \ntimes b \ntimes c$,
mas para a exponenciação que não é associativa escolhemos
a associatividade-direita: $a^{b^c}$ significa $a \expop (b \expop c)$
e não $(a \expop b) \expop c$.

%%}}}

%%{{{ prop: (+) is associative 
\proposition.
%%%{{{ meta 
%%%}}}

A $(+)$ é associativa.

%%}}}

%%{{{ natadd_is_associative_failed_proof_attempt 
\note Tentativa de demonstração.
%%%{{{ meta 
\of natadd_is_associative
\label natadd_is_associative_failed_proof_attempt
%%%}}}

Vamos tentar demonstrar essa proposição.
Primeiramente, o que a afirmação significa?
A adição é essa operação $(+)$ que definimos na~\ref[natops_rec_defs].
Vamos tentar escrever essa afirmação numa maneira mais formal
para expor sua estrutura lógica:
$$
\pforall n
\pforall m
\lforall k
    {(n+m) + k = n + (m+k)}.
$$
Nosso alvo tem a forma
$$
\lforall {x \is \Nat} {\phi(x)}
$$
olhando como
$$
\bforall n
    {\mubrace {\aB{\pforall m \pforall k \quantified{(n+m) + k = n + (m+k)}}}
              {\aB{\phi_1(n)}}}
$$
podemos atacá-la tomando um arbitrario $\Nat$ e mostrando
que ele goza da propriedade $\phi$:
\eop
Seja $a \is \Nat$.
Agora precisamos mostrar que $\phi(a)$, ou seja nosso alvo é
$$
\pforall m
\lforall k
    {(a+m) + k = a + (m+k)}.
$$
Observe que nosso alvo é apenas uma afirmação sobre o natural $a$.
Beleza.
Mas nosso alvo tem a mesma forma,
$$
\mubrace
  {\bforall m
    {\mubrace {\aB{\lforall k {(a+m) + k = a + (m+k)}}}
              {\aB{\phi_2(m)}}}}
  {\phi_1(a)}
$$
então podemos atacar novamente
com a mesma idéia, \dq{sejando} mais um natural.
\eop
Seja $m \is \Nat$.
Preciso demonstrar que
$$
\mubrace
  {\bforall k
    {\mubrace {\aB{(a+m) + k = a + (m+k)}}
              {\aB{\phi_3(k)}}}}
  {\phi_2(m)}.
$$
Atacamos uma última vez com a mesma estratégia:
\eop
Seja $y \is \Nat$.
Agora precisamos demonstrar
$$
\mubrace {(a+m) + y = a + (m+y)}
         {\phi_3(y)}.
$$
E agora?
Como chegamos numa igualdade, precisamos verificar que seus dois lados
realmente denotam o mesmo valor.
Vamos calcular então.
Tomando o lado esquerdo, $(a+m)+y$, tantamos casá-lo com as equações
\funref[(+).1]--\funref[(+).2], mas ele não casa com nenhuma delas, então não tem como
simplificá-lo.\foot
Isso não é exatamente verdade, pois o lado direito
da \funref[(+).1], sendo apenas uma variável, casa com qualquer coisa.
Mas escolhendo qualquer (sub)expressão da $(a+m)+y$, para casar
com $n$, não vamos ter progresso nenhum, pois vamos acabar
adicionando apenas uns ``$+0$'' até cansar, sem nenhuma
mudança na posição das parenteses que nos importam aqui.
\toof

%%}}}

%%{{{ Q: Seems like a dead end---or is it? 
\question.
%%%{{{ meta 
\label not_a_dead_end_without_induction
%%%}}}

Parece que chegamos num ``dead end''.
Tem como continuar?

%%}}}

\spoiler

%%{{{ A: case split 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Tem!
O problema foi que não sabemos nem sobre o $m$ nem sobre o $y$
se são da forma $\Ze$ ou da forma $\SuA \phole$ e por isso não conseguimos
aplicar nenhuma das \funref[(+).1]--\funref[(+).2].
Mas podemos \emph{separar em casos}.
Vamos escolher um desses Nats então, o $y$, e considerar:
\tlist:
\li: \proofcase {Caso} $y = 0$: \dots
\li: \proofcase {Caso} $y = Sy'$ para algum $y'$: \dots
\endtlist
Lembre-se que cada vez que separamos em casos, nosso alvo
tá sendo \emph{copiado e colado} para cada um deles.

%%}}}

%%{{{ x: solve_the_zero_case_of_case_split_of_natadd_is_associative 
\exercise O primeiro caso.
%%%{{{ meta 
\label solve_the_zero_case_of_case_split_of_natadd_is_associative
%%%}}}

Demonstre que
$$
(a+m) + y = a + (m+y)
$$
no primeiro caso.

\hint
Pega um lado e calcule até chegar no outro;
ou se não conseguir chegar no outro lado,
trabalhe no outro lado separadamente até
chegar no mesmo canto.

\hint
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= \dots?
\endcompute

\hint
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= a + m       \by {pela~\funref[(+).1]} \\
\intertext{Se travou aqui, sem problema:
trabalhe no outro lado até chegar em $a + m$:}
a + (m + y) &= \dots? \\
&\eqvdots\\
&= a + m
\endcompute

\solution
Calculamos:
\compute
(a + m) + y
&= (a + m) + 0 \by {hipótese do caso} \\
&= a + m       \by {pela~\funref[(+).1]} \\
a + (m + y)
&= a + (m + 0) \by {hipótese do caso} \\
&= a + m       \by {pela~\funref[(+).1]} \\
\endcompute

%%}}}

%%{{{ The second case 
\note O segundo caso.
%%%{{{ meta 
%%%}}}

Sabemos que $y$ é o sucessor de algum natural,
então vamos escolher um nome pra denotá-lo:
\emph{seja $y'$ natural tal que $y = Sy'$}\fact1.
Calculamos:
\compute
(a + m) + y
&= (a + m) + Sy'       \by {hipótese~\byfact1} \\
&= S\paren{(a+m) + y'} \by {\funref[(+).2], com $n\asseq (a+m)$, $m\asseq y'$} \\
\intertext{e o outro lado}
a + (m + y)
&= a + (m + Sy')   \by {hipótese~\byfact1} \\
&= a + S(m + y')   \by {\funref[(+).2] com $n\asseq m$, $m\asseq y'$} \\
&= S(a + (m + y')) \by {\funref[(+).2] com $n\asseq a$, $m\asseq m+y'$} \\
\endcompute
E agora peguntamos
$$
S((a + m) + y')
\askeq
S(a + (m + y'))
$$
e para resolver isso basta ``cortar os $S$'s'' e demonstrar que
$$
(a+m) + y' = a + (m + y').
$$
\emph{E estamos onde estávamos!}
Só com $a,m,y'$ em vez de $a,m,y$.  E daí?
Podemos separar esse caso em dois subcasos:
\tlist:
\li: \proofcase {Caso $y' = 0$}: \dots
\li: \proofcase {Caso $y' = Sy''$} para algum $y''$: \dots
\endtlist
O primeiro subcaso vamos conseguir matar, pois é igual ao
primeiro caso.  Mas a melhor coisa que conseguimos no segundo
caso seria chegar ate o alvo
$$
(a + m) + y'' \askeq a + (m+y'').
$$
E depois?  Considerar dois casos novamente?
Não importa quantas vezes repetir essa idéia, a gente
sempre vai conseguir matar apenas um dos sub-(sub-sub-\dots)-casos,
e chegar num
$$
(a + m) + y^{\prime\prime\cdots\prime}
\askeq
a + (m + y^{\prime\prime\cdots\prime}).
$$
Obviamente precisamos uma outra técnica para demonstrar esse teorema.

%%}}}

\endsection
%%}}}

%%{{{ Induction 
\section Indução.
%%%{{{ meta 
\label Induction
%%%}}}

%%{{{ Nat_induction_principle 
\principle Indução.
%%%{{{ meta 
\label Nat_induction_principle
\defines
    * indução!para o tipo Nat
    ;;
%%%}}}

Seja $\phi : \Nat \to \Prop$.
Para demonstrar $\lforall {n \is \Nat} {\phi(n)}$, basta demonstrar
$\phi(0)$ e $\lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)}$.

%%}}}

%%{{{ Nat_induction_inference_rule 
\note Indução: regra de inferência.
%%%{{{ meta 
\label Nat_induction_inference_rule
\defines
    * indução!para o tipo Nat
    * indução!base
    * indução!passo indutivo
    * indução!hipótese indutiva
    ;;
\indexes
    * H.I.               see: hipótese indutiva
    * P.I.               see: passo indutivo
    * base               see: indução
    * passo indutivo     see: indução
    * hipótese indutivo  see: indução
    ;;
%%%}}}

Em forma de regra de inferência, o princípio da indução é o seguinte:
$$
\PROOFmr {
     \A {\phi(0)}     \A {\lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)}}
\I2-------------------------------------------------------------------------- {Ind$_\phi$}
                     {\lforall {n \is \Nat} {\phi(n)}}
}
$$
onde chamamos
a proposição $\phi(0)$
de \dterm{base}
e
a $\lforall k {\phi(k) \implies \phi(Sk)}$
de \dterm{passo indutivo}:
$$
\PROOFmr {
\A {\tobrace {\phi(0)}
        {\explanation{Base}}}
                \A {\tobrace {\lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)}}
                                    {\explanation{Passo indutivo}}}
\I2---------------------------------------------------------------- {Ind$_\phi$}
                     {\lforall {n \is \Nat} {\phi(n)}}
}
$$
Mas esses são apenas os apelidos que usamos freqüentemente; nada mais que isso.
Como vamos ver logo, a proposição $\phi(k)$ no esquema acima também tem um apelido:
\dterm{hipótese indutiva (H.I.)}.

%%}}}

%%{{{ induction_as_a_new_attack 
\note Novo ataque.
%%%{{{ meta 
\label induction_as_a_new_attack
%%%}}}

Sabemos que regras de inferência correspondem em \dq{comandos} do nosso low-level
sistema de demonstrações.  Precisamos então um comando para essa, e isso será um pleno
\dq{Por indução.}
Para utilizá-lo, nosso algo \emph{precisa} ter essa forma:
\repls
\maxproof  : \qquad Seja $k \is \Nat$ tal que $\phi(k)$\fact{HI}. ;
\maxgiven  : \qquad k \is \Nat ;
\maxgoal   : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
\hidenum
\repl
\givens
\goals
~    : \lforall {n \is \Nat} {\phi(n)} ;
\endrepl
\repl
~a   : Por indução. ;
\givens
\goals
~a / : \lforall {n \is \Nat} {\phi(n)} ;
~a   : \phi(0) ;
~a   : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Por indução. ;
~a   : \proofpart {Base.} ;
\givens
\goals
~    : \phi(0) ;
~f   : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Por indução. ;
~    : \proofpart {Base.} ;
~a   : \qquad $\vdots$ ;
~a   : \qquad (demonstração de $\phi(0)$) ;
\givens
~a   : \phi(0) ;
\goals
~a / : \phi(0) ;
~    : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Por indução. ;
~    : \proofpart {Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~a   : \proofpart {Passo indutivo.} ;
\givens
~    : \phi(0) ;
\goals
~    : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
\endrepl
\repl
~    : Por indução. ;
~    : \proofpart {Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~    : \proofpart {Passo indutivo.} ;
~a   : \qquad Seja $k \is \Nat$. ;
\givens
~    : \phi(0) ;
~a   : k \is \Nat ;
\goals
~a / : \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)} ;
~a   : \phi(k) \implies \phi(Sk) ;
\endrepl
\repl
~    : Por indução. ;
~    : \proofpart {Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$) ;
~    : \proofpart {Passo indutivo.} ;
~    : \qquad Seja $k \is \Nat$ \alert{tal que $\phi(k)$\fact{HI}.} ;
\givens
~    : \phi(0) ;
~    : k \is \Nat ;
~a   : \phi(k) ;
\goals
~a / : \phi(k) \implies \phi(Sk) ;
~a   : \phi(Sk) ;
\endrepl
\repl
~    : Por indução. ;
~    : \proofpart {Base.} ;
~    : \qquad $\vdots$ ;
~    : \qquad (demonstração de $\phi(0)$). ;
~    : \proofpart {Passo indutivo.} ;
~    : \qquad Seja $k \is \Nat$ tal que $\phi(k)$\fact{HI}. ;
~a   : \qquad $\vdots$ ;
~a   : \qquad (demonstração de $\phi(Sk)$)\qed ;
\givens
~    : \phi(0) ;
~    : k \is \Nat ;
~    : \phi(k) ;
~a   : \phi(Sk) ;
\goals
~a / : \phi(Sk) ;
\endrepl
\endrepls

%%}}}

%%{{{ remark: nothing special about induction once performed 
\remark.
%%%{{{ meta 
%%%}}}

Observe que no momento que escrevemos
\quote
<<Seja $k \is \Nat$ tal que $\phi(k)$\fact{HI}.>>
\endquote
no~\reftag[induction_as_a_new_attack]
não fizemos nada especial relacionado à indução!
Isso é o ``ataque padrão'' duma proposição da forma
$$
\lforall {x \is A} {\phi(x) \implies \psi(x)}
$$
onde juntamos os passos de atacar o \symq{$\forall$} e o \symq{$\impliessymbol$}
numa frase só.
Em geral, podes considerar a indução como um comando que
quando usado transforma um alvo da forma
$$
\lforall {x \is \Nat} {\phi(x)}
$$
para \emph{dois} novos alvos (com nomes chique):
\mathcol
\text{\proofpart {Base}:}\quad           & \phi(0) \\
\text{\proofpart {Passo indutivo}:}\quad & \lforall {k \is \Nat} {\phi(k) \implies \phi(Sk)}
\endmathcol
(exatamente como a regra do~\reftag[Nat_induction_inference_rule]
disse, lida de baixo para cima).
Fora disso, \emph{não tem nada mais mágico} que acontece:
o comando já foi executado e seu efeito já aconteceu.
E depois?
Depois \emph{continuamos normalmente para matar esses dois alvos}.

%%}}}

%%{{{ remark: induction_on_a_variable? 
\remark Indução numa variável?.
%%%{{{ meta 
%%%}}}

No~\ref[induction_as_a_new_attack] escrevemos
\wq{Indução no $n$}.
Como assim \wq{no $n$}?  Quem é esse $n$?
Não tem $n$ no nosso escopo!
Sim, realmente não faz sentido no pé da letra essa frase,
mas ajudamos nosso leitor entender qual quantificador estamos atacando
do nosso alvo, caso que aparecem mais que um.
Talvez ficaria (pouco) mais correto escrever
\wq{Indução no $\forall n$.}
(No final das contas, é o quantificador que estamos atacando.)
De qualquer forma, isso é apenas um modo de falar, e presuponha
que nosso leitor tem acesso no nome da variável ligada que escolhemos
quando escrevemos nosso alvo.  (Muitas vezes isso faz parte do enunciado.)

%%}}}

\endsection
%%}}}

%%{{{ Proving properties with induction 
\section Demonstrando propriedades de naturais com indução.
%%%{{{ meta 
%%%}}}

%%{{{ thm: natadd_is_associative 
\theorem Associatividade da adição.
%%%{{{ meta 
\label natadd_is_associative
%%%}}}

A operação $(+)$ da~\ref[natops_rec_defs] é associativa:
$$
\pforall n \pforall m \lforall k {n + (m + k) = (n + m) + k}.
$$

%%{{{ preproof 
\preproof. 
Vamos demonstrar esse teorema duas vezes.
É importantíssimo entender a diferença e seguir todos os detalhes.
Antes de começar, lembre nossa tentativa~\reftag[natadd_is_associative_failed_proof_attempt] e como e onde exatamente a gente travou:
\repl \hidenum
~    : Seja $n$ natural. ;
~    : Seja $m$ natural. ;
~    : Seja $k$ natural. ;
~    : Separamos em casos: ;
~    : \proofpart {Caso $k=0$:} ;
~    : \quad(resolvido no~\ref[solve_the_zero_case_of_case_split_of_natadd_is_associative]) ;
~    : \proofpart {Caso $k=Sk'$ para algum $k'$:} ;
~    : \quad(caimos num caminho infinito aqui) ;
\givens
~    : n \is \Nat ;
~    : m \is \Nat ;
~    : k \is \Nat ;
\goals
~    : n + (m + k) = (n + m) + k ;
\endrepl
E como caimos num caminho de sempre separar em dois novos casos sem fim,
percebemos que algo deu errado; queremos tentar nossa nova técnica, indução.
Neste momento na nossa prova, podemos atacar nosso alvo por indução?
Não!  Para atacar um alvo por indução ele precisa ter a forma
$$
\lforall {x \is \Nat} {\phi(x)}
$$
e nosso alvo não é um \symq{$\forall$} mas uma igualdade!
Vamos fazer uns ``undo'' então na nossa demonstração e voltar nesse momento:
\repl
~    : Seja $n$ natural. ;
~    : Seja $m$ natural. ;
~    : \strikeout{Seja $k$ natural.} ;
~    : \strikeout{Separamos em casos:} ;
\givens
~    : n \is \Nat ;
~    : m \is \Nat ;
\goals
~    : \bforall k {\mubrace {n {+} (m {+} k) = (n {+} m) {+} k} {\phi(k)}} ;
\endrepl
Agora sim!  Nosso alvo tem uma forma que casa com o padrão que precisamos para aplicar indução.
Bora ver essa demonstração primeiro então.
%%}}}

\proof Primeira demonstração.
Sejam $n, m$ naturais.
Vamos demonstrar por indução no $k$ que
$$
\bforall k
    {\mubrace {n + (m + k) = (n + m) + k} {\phi(k)}}.
$$
\proofpart {Base.}
Precisamos mostrar que
$$
n + (m + 0) = (n + m) + 0.
$$
Calculamos:
\compute
n + (m + 0)
&= n + m    \by {pela \funref[(+).1] com $n \asseq m$} \\
(n + m) + 0
&= n + m    \by {pela \funref[(+).1] com $n \asseq n + m$} \\
\endcompute
\proofpart {Passo indutivo.}
Precisamos mostrar que
$$
\bforall t
    { \mubrace {n + (m + t) = (n + m) + t}
               {\phi(t)}
      \implies
      \mubrace {n + (m + St) = (n + m) + St}
               {\phi(St)} }.
$$
Seja $w$ natural tal que
$$
n + (m + w) = (n + m) + w.  \tag{HI}
$$
Precisamos mostrar que
$$
n + (m + Sw) = (n + m) + Sw.
$$
Calculamos:
\compute
n + (m + Sw)
&= n + S(m + w)     \by {\funref[(+).2]: $n \asseq m$; $m \asseq w$} \\
&= S(n + (m + w))   \by {\funref[(+).2]: $n \asseq n$; $m \asseq m + w$} \\
(n + m) + Sw
&= S((n + m) + w)   \by {\funref[(+).2]: $n \asseq n + m$; $m \asseq w$} \\
\endcompute
Basta então mostrar
$$
S(n + (m + w)) = S((n + m) + w)
$$
que segue pela \byfact{HI}.  (Como?)

%%}}}

%%{{{ x: how 
\exercise.
%%%{{{ meta 
%%%}}}

Como mesmo?

\hint
O \ref[datatype_injectivity_of_constructors] não tem nada a ver com isso.

%%}}}

%%{{{ We need to discuss what just happened. 
\note.
%%%{{{ meta 
%%%}}}

Precisamos discutir o que acabou de acontecer.
Agora bora ver uma demonstração que também usa indução, mas numa maneira bem diferente:
Queremos demonstrar a afirmação
$$
\pforall n \pforall m \lforall k {\psi(n,m,k)}
$$
onde
$$
\psi(x,y,z) \abbriff x + (y + z) = (x + y) + z.
$$
Talvez parece que ela não está no formato $\lforall n {\phi(n)}$
e que não podemos atacá-la diretamente com indução.
Mas, na verdade, reescrevendo como
$$
\pforall n
\mubrace {\pforall m \lforall k {\psi(n,m,k)}} {\phi_1(n)}
$$
já percebemos que tem a forma certa.
E podemos trocar a ordem de quantificadores consecutivos
\emph{do mesmo tipo}, então o que queremos demonstrar é equivalente aos
\mathcols 3
& \pforall n \mubrace {\pforall m \lforall k {\psi(n,m,k)}} {\phi_1(n)}; &
& \pforall m \mubrace {\pforall n \lforall k {\psi(n,m,k)}} {\phi_2(m)}; &
& \pforall k \mubrace {\pforall n \lforall m {\psi(n,m,k)}} {\phi_3(k)};
\endmathcols
etc.~(tem ainda mais três opções que não escrevi),
onde em cada caso o $\phi_i$ tem uma definição diferente,
mas o $\psi$ tem sempre a mesma.
Escolhemos demonstrar a
$$
\pforall k \mubrace {\pforall n \lforall m {\psi(n,m,k)}} {\phi(k)}
$$
por indução.
Vamos ver o que vai acontecer.

%%}}}

%%{{{ proof: natadd_is_associative_second_proof 
\proof Segunda demonstração.
%%%{{{ meta 
\of natadd_is_associative
\headerize
\label natadd_is_associative_second_proof
%%%}}}

Por indução no $k$.
\crproofpart {Base.}
Precisamos demonstrar que
$$
\mubrace {\pforall n \lforall m {n + (m + 0) = (n + m) + 0}} {\phi(0)}.
$$
Sejam $n,m$ naturais.
Calculamos os dois lados:
\compute
\redex{(n+m) + 0} &= n + m \by {\funref[(+).1]} \\
n + \redex{(m+0)} &= n + m \by {\funref[(+).1]} \\
\endcompute
Ou seja, a $\phi(0)$ realmente é válida.
\crproofpart {Passo indutivo.}
Precisamos demonstrar a afirmação:
$$
\lforall t {\phi(t) \implies \phi(St)},
$$
ou seja,
$$
\lforall t
{
\paren{\pforall n \lforall m {(n + m) + t  = n + (m + t)}}
\implies
\paren{\pforall u \lforall v {(u + v) + St = u + (v + St)}}
}
$$
onde escolhi nomes diferentes nas variáveis quantificadas apenas para
enfatizar que são realmente diferentes!
Bora demonstrar isso então.
Seja $w$ natural tal que
$$
\pforall n \lforall m {(n + m) + w = n + (m + w)}. \tag{H.I.}
$$
Preciso mostrar que:
$$
\pforall u \lforall v {(u + v) + Sw = u + (v + Sw)}.
$$
Sejam $u,v$ naturais.
Calculamos:
\compute
\redex{(u + v) + Sw}
&= S(\redex{(u + v) + w})  \by {\funref[(+).2]} \\
&= \redex{S(u + (v + w))}  \by {H.I., com $n := u$, $m := v$} \\
&= u + \redex{S(v + w)}    \by {\funrefrl[(+).2]} \\
&= u + (v + Sw).           \by {\funrefrl[(+).2]} \\
\endcompute
Isso termina nossa demonstração.

%%}}}

%%{{{ Q: How do we choose which forall to attack by induction? 
\question.
%%%{{{ meta 
%%%}}}

Acabamos de escolher para demonstrar por indução no $k$.
Por que $k$?
Faz diferença ou não?
Como escolherias qual dos $\forall$ seria o melhor para atacar por indução?

%%}}}

\spoiler

%%{{{ A: How to choose on which variable to induct 
\note Como escolher a variável da indução.
%%%{{{ meta 
%%%}}}

Como a definição da adição foi recursiva no segundo argumento
da função, vai nos ajudar se a indução é feita numa variável
que aparece mais como segundo argumento da adição do que como primeiro.
Aqui por exemplo, a $k$ aparece duas vezes como argumento da $(+)$,
e as duas vezes ela é o segundo argumento da $(+)$.  Perfeito.
O $n$ no outro lado aparece duas vezes como primeiro argumento,
e o $m$ uma como primeiro e uma como segundo.

%%}}}

%%{{{ thm: natadd_is_commutative 
\theorem Comutatividade da adição.
%%%{{{ meta 
\label natadd_is_commutative
%%%}}}

A operação $(+)$ da~\ref[natops_rec_defs] é comutativa:
$$
\pforall n
\lforall m
    {n + m = m + n}.
$$

\wrongproof.
Demonstramos a
$$
\pforall n
\mubrace {\lforall m {n + m = m + n}}
         {\phi(n)}.
$$
\proofpart {Base.}
Queremos demonstrar o $\phi(0)$, ou seja, o seguinte:
$$
\pforall m
\mubrace {\quantified {0 + m = m + 0}}
         {\psi(m)}.
$$
Vamos demonstrar por indução!
\crproofpart {Sub-base.}
Trivial, pois o que queremos demonstrar é $0 + 0 = 0 + 0$ e os dois lados
são a mesma expressão.
\crproofpart {Sub-passo indutivo.}
Precisamos demonstrar que:
$$
\forall k \Bigbracket{\mubrace {0 + k = k + 0} {\psi(k)}
          \implies \mubrace {0 + Sk = Sk + 0} {\psi(Sk)}}.
$$
Seja $k\in\nats$ tal que
$$
0 + k = k + 0.   \tag{S.H.I.}
$$
Queremos mostrar que
$$
0 + Sk = Sk + 0.
$$
Calculamos:
\compute
0 + Sk
&= S(0 + k)  \by {\funref[(+).2]} \\
&= S(k + 0)  \by {(S.H.I.)} \\
&= Sk        \by {\funref[(+).1]} \\
&= Sk + 0.   \by {\funref[(+).1]} \\
\endcompute
Isso termina nossa base.
\proofpart {Passo indutivo.}
Queremos demonstrar:
$$
\forall k
\Bigbracket {
\mubrace {\forall m \paren{k + m = m + k}}
{\phi(k)}
\implies
\mubrace {\forall m \paren{Sk + m = m + Sk}}
{\phi(Sk)}
}.
$$
Seja $k\in\nats$ tal que
$$
\mubrace {\forall m \paren{k + m = m + k}} {\phi(k)} \tag{H.I.}
$$
então.
Basta demonstrar que
$$
\mubrace {\forall m \paren{Sk + m = m + Sk}} {\phi(Sk)}.
$$
Seja $m\in\nats$.
Calculamos:
\compute
Sk + m
&= S(k+m)   \by {\funref[(+).2]} \\
&= S(m+k)   \by {(H.I.)} \\
&= m + Sk.  \by {\funref[(+).2]} \\
\endcompute
Isso termina nossa demonstração.

%%}}}

%%{{{ x: natadd_is_commutative_find_the_error 
\exercise.
%%%{{{ meta 
\label natadd_is_commutative_find_the_error
%%%}}}

A demonstração do~\ref[natadd_is_commutative] tem um erro!
Ache o erro.

\hint
Está no passo indutivo.

\hint
Está no último cálculo.

\solution
O erro está na primeira equação do último cálculo:
\compute
Sk + m
&= S(k+m). \by {\funref[(+).2]} \\
\endcompute
A \funref[(+).2] não nos permite concluir isso; só o seguinte:
$$
k + Sm = S(k+m).
$$
Se soubessimos que $Sk + m = k + Sm$ seria fácil
terminar essa demonstração corretamente.
Essa propriedade parece razoável para afirmar:
$$
\pforall x \lforall y {Sx + y = x + Sy}.
$$
Bora demonstrar então!

%%}}}

%%{{{ lemma: succx_plus_y_eq_x_plus_succy
\lemma.
%%%{{{ meta 
\label succx_plus_y_eq_x_plus_succy
%%%}}}

A operação $(+)$ satisfaz:
$$
\pforall a
\lforall b
    {Sa + b = a + Sb}.
$$

\proof.
Demonstramos por indução que
$$
\pforall b
\mubrace {\lforall a {Sa + b = a + Sb}} {\phi(b)}.
$$
\proofpart {Base.}
Precisamos demonstrar que
$$
\mubrace {\lforall a {Sa + 0 = a + S0}} {\phi(0)}.
$$
Calculamos:
\compute
Sa + 0 &= Sa        \by {\funref[(+).1]} \\
a + S0 &= S(a + 0)  \by {\funref[(+).2]} \\
       &= Sa.       \by {\funref[(+).1]} \\
\endcompute
\proofpart {Passo indutivo.}
Queremos demonstrar:
$$
\pforall k
\Bigbracket {
    \mubrace
        {\lforall a {Sa + k = a + Sk}}
        {\phi(k)}
    \implies
    \mubrace
        {\lforall a {Sa + Sk = a + SSk}}
        {\phi(Sk)}
}.
$$
Seja $k\is\Nat$ tal que
$$
\mubrace
    {\lforall a {Sa + k = a + Sk}}
    {\phi(k)}.
\tag{H.I.}
$$
Basta mostrar que
$$
\mubrace
    {\lforall a {Sa + Sk = a + SSk}}
    {\phi(Sk)}.
$$
Seja $a\is\Nat$.
Calculamos
\compute
Sa + Sk
&= S(Sa + k)    \by {\funref[(+).2]} \\
&= S(a + Sk)    \by {H.I.~com $a := a$} \\
&= a + SSk.     \by {\funref[(+).2]} \\
\endcompute
Isso termina nossa demonstração, e logo substituindo a
justificativa~\wq{\funref[(+).2]} na demonstração do~\ref[natadd_is_commutative] por
\wq{pelo~\ref[succx_plus_y_eq_x_plus_succy]} ganhamos também o direito de
substituir seu~\symq{\mistakesymbol} por um legítimo~\symq{\qedsymbol}:

%%}}}

\TODO Sketch da comutatividade da adição com indução dupla.

%%{{{ x: natmult_is_associative 
\exercise Associatividade da multiplicação.
%%%{{{ meta 
\label natmult_is_associative
%%%}}}

$
\pforall n
\pforall m
\lforall k
    {(n \ntimes m) \ntimes k = n \ntimes (m \ntimes k)}.
$

\hint
Por indução no $k$.

\hint
Não seria bom ter uma distributividade?

\solution
Por indução no $k$.
\crproofpart {Base: $\forall n \forall m \bigparen{(n \ntimes m) \ntimes 0 = n \ntimes (m \ntimes 0)}$.}
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes 0
&= 0            \by {\funref[(\ntimes).1]} \\
n \ntimes (m \ntimes 0)
&= n \ntimes 0  \by {\funref[(\ntimes).1]} \\
&= 0.           \by {\funref[(\ntimes).1]} \\
\endcompute
\proofpart {Passo indutivo.}
Seja $w$ natural tal que
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes w = n \ntimes (m \ntimes w)}. \tag{H.I.}
$$
Ou seja: ``$w$ na direita associa com todos''.
Queremos demonstrar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \forall m \bigparen{(n \ntimes m) \ntimes Sw = n \ntimes (m \ntimes Sw)}.
$$
Sejam $n,m$ naturais.
Calculamos:
\compute
(n \ntimes m) \ntimes Sw
&= ((n \ntimes m) \ntimes w) + (n \ntimes m)    \by {\funref[(\ntimes).2]} \\
n \ntimes (m \ntimes Sw)
&= n \ntimes ((m \ntimes w) + m)                \by {\funref[(\ntimes).2]} \\
&= (n \ntimes (m \ntimes w)) + (n \ntimes m)    \by {(*)} \\
&= ((n \ntimes m) \ntimes w) + (n \ntimes m).   \by {(H.I.)} \\
\endcompute
Onde devemos para o (*) demonstrar como lemma a distributividade (esquerda) da $(\ntimes)$ sobre a $(+)$ (feito no~\ref[natmult_distributes_over_natadd]).

%%}}}

%%{{{ x: natmult_is_commutative 
\exercise Comutatividade da multiplicação.
%%%{{{ meta 
\label natmult_is_commutative
%%%}}}

$
\pforall n
\lforall m
    {n \ntimes m = m \ntimes n}.
$

\hint
Por indução em qualquer uma das $m,n$.

\hint
Demonstre a base da tua indução com uma sub-indução!

\hint
Teu passo indutivo vai precisar duma sub-indução também!
Alternativamente, tu podes demonstrar outras propriedades
que ajudaria ter (por exemplo distributividade) e usá-las
como lemmas nas tua prova.

\solution
Por indução no $m$.
\crproofpart {Base: $\lforall n {n \ntimes 0 = 0 \ntimes n}$.}
Vamos demonstrar por indução!
\proofpart {Sub-base: $0 \ntimes 0 = 0 \ntimes 0$.}
Trivial!
\crproofpart {Sub-passo indutivo.}
Seja $k\is\Nat$ tal que
$$
k \ntimes 0 = 0 \ntimes k.  \tag{S.H.I.1}
$$
Ou seja, \emph{$k$ é um número que comuta com o $0$}.
Vamos demonstrar que $Sk \ntimes 0 = 0 \ntimes Sk$.
Calculamos:
\compute
Sk \ntimes 0  &= 0  \by {\funref[(\ntimes).1]} \\
0 \ntimes Sk
&= 0 \ntimes k + 0  \by {\funref[(\ntimes).2]} \\
&= 0 \ntimes k      \by {\funref[(+).1]} \\
&= k \ntimes 0      \by {(S.H.I.1)} \\
&= 0.               \by {\funref[(\ntimes).1]} \\
\endcompute
Isso demonstra nossa base.
\proofpart {Passo indutivo.}
Seja $w\in\nats$ tal que
$$
\forall n \paren{n \ntimes w = w \ntimes n}. \tag{H.I.}
$$
Ou seja, \emph{$w$ é um número que comuta com todos}.
Queremos demonstrar que seu sucessor $Sw$ faz a mesma coisa:
$$
\forall n \paren{n \ntimes Sw = Sw \ntimes n}.
$$
Vamos demonstrar por mais uma indução!
\proofpart {Sub-base: $0 \ntimes Sw = Sw \ntimes 0$.}
Calculamos:
\compute
0 \ntimes Sw
&= 0 \ntimes w + 0 \by {\funref[(\ntimes).2]} \\
&= 0 \ntimes w     \by {\funref[(+).1]} \\
&= w \ntimes 0     \by {Base ($0$ comuta com todos) ou (H.I.) ($w$ comuta com todos)} \\
&= 0               \by {\funref[(\ntimes).1]} \\
&= Sw \ntimes 0.   \by {\funref[(\ntimes).1]} \\
\endcompute
\crproofpart {Sub-passo indutivo.}
Seja $p\in\nats$ tal que ele comuta com o $Sw$:
$$
p \ntimes Sw = Sw \ntimes p.    \tag{S.H.I.2}
$$
Vamos demonstrar que $Sp$ também comuta com o $Sw$:
$$
Sp \ntimes Sw = Sw \ntimes Sp.
$$
Calculamos:
\compute
Sp \ntimes Sw
&= Sp \ntimes w + Sp        \by {\funref[(\ntimes).2]} \\
&= w \ntimes Sp + Sp        \by {(H.I.): $w$ comuta com todos} \\
&= (w \ntimes p + w) + Sp   \by {\funref[(\ntimes).2]} \\
&= w \ntimes p + (w + Sp)   \by {associatividade da $(+)$} \\
&= w \ntimes p + S(w + p)   \by {\funref[(+).2]} \\
&= w \ntimes p + S(p + w)   \by {comutatividade da $(+)$} \\
&= w \ntimes p + (p + Sw)   \by {\funref[(+).2]} \\
Sw \ntimes Sp
&= Sw \ntimes p + Sw        \by {\funref[(\ntimes).2]} \\
&= p \ntimes Sw + Sw        \by {(S.H.I.2): $p$ comuta com o $Sw$} \\
&= (p \ntimes w + p) + Sw   \by {\funref[(\ntimes).2]} \\
&= p \ntimes w + (p + Sw)   \by {associatividade da $(+)$} \\
&= w \ntimes p + (p + Sw).  \by {(H.I.): $w$ comuta com todos} \\
\endcompute

%%}}}

%%{{{ x: natmult_distributes_over_natadd 
\exercise Distributividade.
%%%{{{ meta 
\label natmult_distributes_over_natadd
%%%}}}

$
\pforall x
\pforall y
\lforall z
    {x \ntimes (y + z) = (x \ntimes y) + (x \ntimes z)}.
$

\hint
Indução no $z$.

\solution
Demonstramos a afirmação por indução no $z$.
\crproofpart {Base: $\pforall x \lforall y {x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0)}$.}
Sejam $x,y \is \Nat$.
Queremos demonstrar que
$$
x \ntimes (y + 0) = (x \ntimes y) + (x \ntimes 0).
$$
Calculamos:
\compute
x \ntimes (y + 0)
&= x \ntimes y                 \by {\funref[(+).1]} \\
&= x \ntimes y + 0             \by {\funref[(+).1]} \\
&= x \ntimes y + x \ntimes 0.  \by {\funref[(\ntimes).1]} \\
\endcompute
\proofpart {Passo indutivo.}
Seja $k \is \Nat$ tal que
$$
\pforall x
\lforall y
    {x \ntimes (y + k) = (x \ntimes y) + (x \ntimes k)}. \tag{H.I.}
$$
Vamos demonstrar que
$$
\pforall x
\lforall y
    {x \ntimes (y + Sk) = (x \ntimes y) + (x \ntimes Sk)}.
$$
Sejam $x,y\is\Nat$.
Calculamos
\compute
x \ntimes (y + Sk)
&= x \ntimes S(y + k)               \by {\funref[(+).1]} \\
&= (x \ntimes (y + k)) + x          \by {\funref[(\ntimes).2]} \\
&= (x \ntimes y + x \ntimes k) + x  \by {(H.I.) com $x\asseq x$, $y\asseq y$} \\
&= x \ntimes y + (x \ntimes k + x)  \by {associatividade de $(+)$} \\
&= x \ntimes y + x \ntimes Sk.      \by {\funref[(\ntimes).2]} \\
\endcompute

%%}}}

%%{{{ thm: natmult_identity 
\theorem Identidade da multiplicação.
%%%{{{ meta 
\label natmult_identity
%%%}}}

$
\lforall x {x \ntimes S0 = x = S0 \ntimes x}.
$

\proof.
Seja $x\is\Nat$.
Calculamos:
\compute
x \ntimes S0
&= (x \ntimes 0) + x    \by {\funref[(\ntimes).2], $n\asseq x$, $m\asseq 0$} \\
&= 0 + x                \by {\funref[(\ntimes).1]} \\
&= x + 0                \by {$(+)$ comut.~(\reftag[natadd_is_commutative])} \\
&= x.                   \by {\funref[(+).1]} \\
\endcompute
Como já demonstramos a comutatividade da $(\ntimes)$ (\reftag[natmult_is_commutative])
isso termina nossa demonstração.

%%}}}

\TODO easy equivalence of two ways to define exponenciation of~\ref[nats_exp_recursive_def].

\TODO still, there is reason to choose one over the other.

%%{{{ x: law_of_natexp_1 
\exercise Lei de exponenciação 1.
%%%{{{ meta 
\label law_of_natexp_1
%%%}}}

$
\pforall x
\pforall a
\lforall b
    {x^{a + b} = (x^a) \ntimes (x^b)}.
$

\hint
Indução no $b$.

\hint
\proofpart {Base: $\pforall x \lforall a {x^{a+0} = x^a \ntimes x^0}$.}

\hint
\proofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
\pforall x \lforall a {x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Agora precisas demonstrar que
$$
\pforall x \lforall a {x^{a+Sk} = x^a \ntimes x^Sk}.
$$

\solution
Por indução no $b$.
\crproofpart {Base: $\pforall x \lforall a {x^{a+0} = x^a \ntimes x^0}$.}
Sejam $x,a\is\Nat$.
Calculamos:
\compute
x^{a+0}
&= x^a              \by {\funref[(+).1]} \\
&= x^a \ntimes S0   \by {$S0$ identidade (\reftag[natmult_identity])} \\
&= x^a \ntimes x^0. \by {\funref[(\expop).1]} \\
\endcompute
\crproofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
\pforall x \lforall a {x^{a+k} = x^a \ntimes x^k}. \tag{H.I.}
$$
Basta demonstrar que
$$
\pforall x \lforall a {x^{a+Sk} = x^a \ntimes x^{Sk}}.
$$
Sejam $x,a\in\nats$.
Queremos demonstrar $x^{a+Sk} = x^a \ntimes x^{Sk}$.
Calculamos:
\compute
x^{a + Sk}
&= x^{S(a + k)}                 \by {\funref[(+).2]} \\
&= x^{a+k} \ntimes x            \by {\funref[(\expop).2]} \\
&= (x^a\ntimes x^k) \ntimes x   \by {(H.I.)} \\
&= x^a\ntimes (x^k \ntimes x)   \by {assoc.~da~$(\ntimes)$~(\reftag[natmult_is_associative])} \\
&= x^a\ntimes x^{Sk}.           \by {\funref[(\expop).2]} \\
\endcompute

%%}}}

%%{{{ x: law_of_natexp_2 
\exercise Lei de exponenciação 2.
%%%{{{ meta 
\label law_of_natexp_2
%%%}}}

$
\pforall a
\pforall b
\lforall c
    {a^{b \ntimes c} = (a^b)^c}.
$

\hint
Indução no $c$.

\hint
\proofpart {Base: $\pforall a \lforall b { a^{b \ntimes 0} = (a^b)^0 }$.}

\hint
\proofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
\pforall a \lforall b { a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Agora precisas demonstrar que
$$
\pforall a \lforall b { a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$

\solution
Por indução no $c$.
\crproofpart {Base: $\pforall a \lforall b { a^{b \ntimes 0} = (a^b)^0 }$.}
Sejam $a,b\is\Nat$.
Calculamos:
\compute
a^{b \ntimes 0}
&= a^0    \by {\funref[(\ntimes).1]} \\
&= S0     \by {\funref[(\expop).1]} \\
(a^b)^0
&= S0.    \by {\funref[(\expop).1]} \\
\endcompute
\crproofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
\pforall a \lforall b { a^{b \ntimes k} = (a^b)^k }.\tag{H.I.}
$$
Queremos demonstrar que
$$
\pforall a \lforall b { a^{b \ntimes Sk} = (a^b)^{Sk} }.
$$
Sejam $a,b\is\Nat$.
Basta mostrar que $a^{b \ntimes Sk} = (a^b)^{Sk}$.
Calculamos:
\compute
(a^b)^{Sk}
&= (a^b)^k \ntimes (a^b)        \by {\funref[(\expop).2], $n\asseq a^b$, $m\asseq k$} \\
&= a^{b \ntimes k} \ntimes a^b  \by {(H.I.), $a\asseq a$, $b\asseq b$} \\
&= a^{(b \ntimes k) + b}        \by {\reftag[law_of_natexp_1], $x\asseq a$, $a\asseq b \ntimes k$, $b\asseq b$} \\
&= a^{b \ntimes Sk}.            \by {\funref[(\ntimes).2], $n\asseq b$, $m\asseq k$} \\
\endcompute

%%}}}

%%{{{ x: law_of_natexp_3 
\exercise Lei de exponenciação 3.
%%%{{{ meta 
\label law_of_natexp_3
%%%}}}

$
\lforall n {S0^n = S0}
$

\hint
Indução no $n$.

\hint
\proofpart {Base: $S0^0 \askeq S0$}:

\hint
\proofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Agora precisas demonstrar que
$$
S0^{Sk} = S0.
$$

\solution
Por indução no $n$.
\crproofpart {Base: $S0^0 \askeq S0$.}
Imediato pela definição de $S0^0$.
\crproofpart {Passo indutivo.}
Seja $k\is\Nat$ tal que
$$
S0^k = S0.\tag{H.I.}
$$
Basta demonstrar que
$$
S0^{Sk} = S0.
$$
Calculamos:
\compute
(S0)^{Sk}
&= S0 \ntimes S0^k  \by {\funref[(\expop).2],   $n\asseq S0$, $m\asseq k$} \\
&= S0^k             \by {$S0$ é identidade da $(\ntimes)$ (\ref[natmult_identity])} \\
&= S0.              \by {(H.I.)}
\endcompute

%%}}}

%%{{{ x: odd_to_any_power_is_odd 
\exercise.
%%%{{{ meta 
\label odd_to_any_power_is_odd
%%%}}}

Demonstre que para todo $n$, e todo ímpar $x$, $x^n$ é ímpar.\foot
Aqui consideramos a seguinte definição de \wq{ímpar}:
\emph{um $n \is \Nat$ é \dterm{ímpar} sse existe $k$ tal que $n = S(k+k)$.}
\toof

%%}}}

%%{{{ remark: exponentiation as an operation vs defining powers of integers 
\remark.
%%%{{{ meta 
%%%}}}

Parece que o \ref[odd_to_any_power_is_odd_oneliner] é demonstrar esse teorema numa linha só!
Mas não exatamente.  Aqui demonstramos uma propriedade que envolve uma operação nos $\Nat$.
Por outro lado, no \reftag[odd_to_any_power_is_odd_oneliner] demonstramos algo sobre as potências
de certos inteiros.  Veja que definimos as potências $x^n$ para qualquer \emph{inteiro} $x$
e qualquer $n\in\nats$ recursivamente; mas não temos (nem teremos) uma \emph{operação}
entre inteiros de exponenciação.

%%}}}

\endsection
%%}}}

%%{{{ Why accept the induction principle? 
\section Por que aceitar o princípio da indução?.
%%%{{{ meta 
%%%}}}

%%{{{ Intuition 
\note Intuição.
%%%{{{ meta 
%%%}}}

Por que demonstrar $\phi(0)$ e $\lforall {k\in\nats} {\phi(k) \implies \phi(Sk)}$
é suficiente para demonstrar o $\lforall {n\in\nats} {\phi(n)}$?
Estabelecendo esses dois alvos significa que ganhamos como regras de inferência
as seguintes:
$$
\xalignat2
&
\PROOFmr {
\I0------------ {IndZero$_\phi$}
    {\phi(\Ze)}
}
&&
\PROOFmr {
\A  {\phi(n)}
\I1------------ {IndSucc$_\phi$}
    {\phi(\SuA n)}
}
\endxalignat
$$
onde $n$ é uma metavariável pegando valores em todos os naturais,
e onde eu escolhi esses rótulos talvez estranhos para nomear essas regras.
Vamos ver o que podemos demonstrar graças essas duas regras agora:
com certeza temos o próprio $\phi(0)$ pela primeira que não tem
nenhuma premissa.
Mas, agora, usando a segunda com $n\asseq 0$ temos uma demonstração
do $\phi(S0)$:
$$
\PROOFmr {
\I0---------- {IndZero$_\phi$}
   {\phi(0)}
\I1----------- {IndStep$_\phi$}
   {\phi(S0)}
}
$$
Ou seja, ganhamos o $\phi(S0)$.
Então podemos usar a regra \namedrule{IndZero$_\phi$} agora com $n\asseq S0$
para ganhar o $\phi(SS0)$:
$$
\PROOFmr {
\I0---------- {IndZero$_\phi$}
   {\phi(0)}
\I1----------- {IndStep$_\phi$}
   {\phi(S0)}
\I1------------ {IndStep$_\phi$}
   {\phi(SS0)}
}
$$
E por aí vai!
Olhando para as duas regras 
\mathcols 2
&
\PROOFmr {
\I0------------ {IndZero$_\phi$}
   {\phi(\Ze)}
}
&&
\PROOFmr {
\A {\phi(n)}
\I1------------ {IndSucc$_\phi$}
   {\phi(\SuA n)}
}
\intertext {observamos que são bem parecidas com as}
&
\PROOFmr {
\I0-------------- {Zero}
   {\Ze \is \Nat}
}
&&
\PROOFmr {
\A    {n \is \Nat}
\I1----------------- {Succ}
   {\SuA n \is \Nat}
}
\endmathcols
e logo dado qualquer natural $n$, o desafio de estabelecer que $n$ tem
a propriedade $\phi$, acaba sendo o mesmo com o ``desafio'' de estabelecer
que $n$ é um natural mesmo!
Em outras palavras, assim que demonstrar os dois alvos da indução para
matar o $\lforall {n\in\nats} {\phi(n)}$, temos:
$$
n \is \Nat \implies \phi(n).
$$
Ou seja: \emph{todos os naturais têm a propriedade $\phi$ mesmo}.

%%}}}

%%{{{ Does this blah-blah mean anything? 
\note Esse bla-bla presta mesmo?.
%%%{{{ meta 
%%%}}}

O leitor alerto justamente ficaria com dúvidas sobre o texto acima.
Realmente faz sentido essa descripção e essa intuição, mas todo esse
``bla-bla'' serve como uma demonstração mesmo do princípio da indução?
Serve não.  E por isso que o chamamos de \dterm{princípio}, ou seja
axioma!  Mas calma:
dependendo na fundação de matemática que trabalhamos,
o princípio pode virar teorema mesmo!  No~\ref[Set_theory]
por exemplo, vamos \emph{demonstrar mesmo} o princípio da indução
para os naturais.  Mas por enquanto não temos as ferramentas
nem a maturidade que precisamos para entender essas idéias;
então paciência.
O que podes mesmo fazer desde já é demonstrar a equivalência
desse princípio com um outro, que também é facilmente aceitável:
o princípio da boa ordem (\ref[WOP_iff_PFI]).

%%}}}

\endsection
%%}}}

%%{{{ Order in the naturals 
\section Ordem nos naturais.
%%%{{{ meta 
%%%}}}

%%{{{ df: natleq 
\definition.
%%%{{{ meta 
\label natleq
\defines
    * ordem!nos naturais
    ;;
%%%}}}

Definimos a relação de ordem $(\leq)$ nos Nats pela:
$$
n \leq m \defiff \lexists {k \is \Nat} {n + k = m}.
$$

%%}}}

%%{{{ x: natleq_bottom 
\exercise Bottom.
%%%{{{ meta 
\label natleq_bottom
%%%}}}

$\lforall x { \Ze \leq x }$.

%%}}}

%%{{{ lemma: natleq_lemma 
\lemma.
%%%{{{ meta 
\label natleq_lemma
%%%}}}

Para quaisquer $n,m \is \Nat$,
$$
n \leq \SuA m
\iff
n \leq m  \mlor  n = \SuA m.
$$

\proof.
Sejam $n,m$ naturais.
\crproofpart {\lrdir:}
Suponha $n \leq S m$.
Logo seja $u$ tal que $n + u = Sm$.
Separamos em casos.
\proofcase {Caso $u=0$.}
Logo $Sm = n+u = n+0 = n$ e temos o que queremos demonstrar.
\proofcase {Caso $u=Su'$ para algum $u'$.}
Logo $Sm = n + Su' = S(n + u')$.
Agora, como $Sm = S(n + u')$, logo $m = n + u'$.
Ou seja, $n \leq m$.
\crproofpart {\rldir:}
Tua: \ref[natleq_lemma_rldir].

%%}}}

%%{{{ x: natleq_lemma_rldir 
\exercise.
%%%{{{ meta 
\label natleq_lemma_rldir
%%%}}}

Demonstre que
$$
\pforall n \lforall m {n \leq \SuA m  \iff  n \leq m  \mlor  n = \SuA m}.
$$

\hint
Use a hipótese (que é uma disjunçaõ) para separar em casos.

\solution
\rldir:
Suponha $n \leq m$ ou $n = Sm$.
Vamos demonstrar que $n \leq Sm$.
Separamos em casos.
\proofcase {Caso $n \leq m$}.
Logo seja $u$ tal que $n + u = m$.
Logo $S(n + u) = Sm$.
E pela \funref[(+).1] temos $n + Su = Sm$, e logo $n \leq Sm$.
\proofcase {Caso $n = Sm$}.
Nesse caso imediatamente $n + 0 = Sm$ (pois $n + 0 = n$ pela \funref[(+).2])
e logo $n \leq Sm$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nos exercícios seguintes vamos demonstrar que $(\leq)$ é uma \dterm{ordem linear}, i.e., $(\leq)$ é\dots

%%}}}

%%{{{ x: natleq_refl 
\exercise Reflexiva.
%%%{{{ meta 
\label natleq_refl
%%%}}}

$\lforall x { x \leq x }$.

%%}}}

%%{{{ x: natleq_trans 
\exercise Transitiva.
%%%{{{ meta 
\label natleq_trans
%%%}}}

$\pforall x \pforall y \lforall z {x \leq y  \mland  y \leq z  \implies  x \leq z}$.

%%}}}

%%{{{ x: natleq_antisym 
\exercise Antissimétrica.
%%%{{{ meta 
\label natleq_antisym
%%%}}}

$\pforall x \lforall y {x \leq y  \mland  y \leq x  \implies  x = y}$.

%%}}}

%%{{{ x: natleq_total 
\exercise Total.
%%%{{{ meta 
\label natleq_total
%%%}}}

$\pforall x \lforall y {x \leq y  \mlor  y \leq x}$.

\hint
Uma idéia é usar um legalzão em vez dum legalzinho.
Outra é usar um legalzinho mesmo, mas aproveitar o \ref[natleq_lemma].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na verdade, $(\leq)$ é ainda mais legal: olhe no~\ref[natleq_woset].

%%}}}

%%{{{ blah 
\blah De uma ordem para outra.
%%%{{{ meta 
%%%}}}

Simplesmente trocando a $(+)$ pela $(\ntimes)$ na definição (\reftag[natleq])
de $(\leq)$ obtemos uma definição (\reftag[natdiv]) duma outra relação de ordem
(parcial) nos Nats:

%%}}}

%%{{{ df: natdiv 
\definition.
%%%{{{ meta 
\label natdiv
\defines
    * divide!nos naturais
    ;;
%%%}}}

Definimos a relação de ordem $(\divides)$ nos Nats pela:
$$
n \divides m \defiff \lexists {k \is \Nat} {n \ntimes k = m}.
$$
que, naturalmente\foot
pun intended
\toof
chamamos de \dterm{divide}.

%%}}}

%%{{{ x: natdiv_order 
\exercise.
%%%{{{ meta 
\label natdiv_order
%%%}}}

Verifique que a relação $(\divides) : \Nat \times \Nat \to \Prop$ é uma relação de ordem parcial,
ou seja, ela é: reflexiva, transitiva, antissimétrica.  Ela não é total.

%%}}}

%%{{{ x: natdiv_bottom_top 
\exercise.
%%%{{{ meta 
\label natdiv_bottom_top
%%%}}}

O $\Nat$ possui bottom~(mínimo) \emph{e} top~(máximo) com a ordem $(\divides)$ (quais são?),
enquanto ordenado pela $(\leq)$ só tem bottom (\ref[natleq_bottom]).

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ df: ackermann_function 
\definition Ackermann.
%%%{{{ meta 
\label ackermann_function
\credits
    * Ackermann
    ;;
\defines
    * recursão!aninhada
    ;;
\indexes
    * aninhada!recursão   see: recursão
    ;;
%%%}}}

Seja $\ack$ a função definida por \dterm{recursão aninhada} pelas:
\fundef
\ack : \Nat \to \Nat \to \Nat \\
\ack &\Ze            &x                 &= \SuA x \\
\ack &\paren{\SuA n} &\Ze               &= \ackAA n 1 \\
\ack &\paren{\SuA n} &\paren{\SuA x}    &= \ackAP n {\ackPA {\SuA n} x}. \\
\endfundef
A função $\ack$ é conhecida como função de Ackermann,
e vamos encontrá-la novamente bem depois, no~\ref[Computability_theory].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Aqui um pequeno tira-gosto: implemente a definição $\ack$ na tua linguagem de
programação favorita e use teu programa para calcular uns valores dela.
O que percebes?

%%}}}

%%{{{ prob: ackermann_function 
\problem Ackermann.
%%%{{{ meta 
\label ackermann_function
\credits
    * Ackermann
    ;;
\defines
    * recursão!aninhada
    ;;
\indexes
    * aninhada!recursão   see: recursão
    ;;
%%%}}}

Investigue a função $\ack$:
\tlist:
\li (i):    Calcule o valor $\ackAA 3 2$, indicando para cada passo qual equação foi usada.
\li (ii):   Demonstre que $\ackA 1 = \fsec + 2$, ou seja, que para todo $x\is\Nat$, $\ackAA 1 x = x + 2$.
\li (iii):  Demonstre que para todo $x\is\Nat$, $\ackAA 2 x = 2x + 3$.
\li (iv):   Demonstre que $\ack$, vista como função binária, é estritamente crescente no seu segundo argumento.
\li (v):    Conclua que $\ackAA n x \geq x$,
\li (vi):   Mostre que $\ack$ é estritamente crescente no seu primeiro argumento também.
\li (vii):  Mostre que $(\ackA n)^2$ é pointwise-(<) que $\ackP {n+2}$.
\li (viii): Demonstre que para todo $x\is\Nat$, $\ackAA 2 x = 2x + 3$.
\endtlist

%%}}}

%%{{{ prob: tetration 
\problem.
%%%{{{ meta 
\label tetration
\defines
    * tetração
    ;;
%%%}}}

Definimos as operações binárias de adição, multiplicação, e exponenciação no $\Nat$.
Descubra um ``padrão'' nas definições dessas operações, e defina a próxima operação, \dterm{tetração}, nessa seqüência de operações.

%%}}}

%%{{{ prob: products_in_disguise 
\problem.
%%%{{{ meta 
\label products_in_disguise
%%%}}}

Defina recursivamente as funções $t : (\nats \to \nats) \to \nats \to \nats$
e $T : (\nats \to \nats) \to \nats\times\nats \to \nats$ que satisfazem:
\mathcol
t \fa h \fa n     &= h(0)h(1)\dotsb h(n-1)     = \Prod\limits_{i=0}^{n-1} h(i);\\
T \fa h \fa (m,n) &= h(m)h(m+1)\dotsb h(m+n-1) = \Prod\limits_{i=m}^{m+n-1} h(i).
\endmathcol

\hint
Depois de definir confira tuas definições seguindo elas para calcular uns valores.
Por exemplo, $t \fa h\fa 2$ e $T \fa h \fa (5,2)$ devem dar os resultados
\mathcols 2
t \fa h \fa 2     &= (h \fa 0)(h \fa 1) &
T \fa h \fa (5,2) &= (h \fa 5)(h \fa 6).
\endmathcols

\hint
Mesmo que a função $T$ tem aridade 2, escolhendo bem,
tu não precisarás escrever 4 equações, mas apenas 2.

\solution
Definimos
\mathcols 2
t      &\eqtype \nats\to\nats   &  T        &\eqtype \nats^2\to\reals\\
t(0)   &= 1                     &  T(m,0)   &= 1                     \\
t(n+1) &= h(n) \ntimes t(n)     &  T(m,k+1) &= h(m+k) \ntimes T(m,k).  
\endmathcols
Tendo definido primeiro a $T$, podemos definir a $t$ simplesmente assim:
$$
t \fa h \fa n = T \fa h \fa (0,n).
$$

%%}}}

%%{{{ prob: victors_mistake 
\problem.
%%%{{{ meta 
\label victors_mistake
%%%}}}

Tentando resolver o~\ref[products_in_disguise],
% STUDENT: Victor
um aluno definiu corretamente a $t$ e depois a usou
na sua definição de $T$, assim:
$$
T(m,n) = {t(m+n)}/{t(m)}.
$$
Qual o problema com essa definição?
(Suponha como conhecida uma definição recursiva da
operação $/$ de divisão inteira.)

\hint
Qual é o codomínio da $h$?

\hint
$0\in\nats$.

\hint
O que acontece se $h(i) = 0$ para algum $i \in \nats$?

\solution
Se $h(i) = 0$ para algum $i \in \nats$,
o $t(j)=0$ para todo $j>i$.
Assim, a expressão
${t(m+n)}/{t(m)}$ não é definida para qualquer $m>i$.
Observe que a solução seria certa se tivéssemos alguma garantia que
$h$ não mapeia ninguém ao $0$.

%%}}}

%%{{{ prob: natleq_woset 
\problem.
%%%{{{ meta 
\label natleq_woset
\defines
    * bem-ordem
    ;;
%%%}}}

Demonstre por indução que a $(\leq)$ (definida na~\ref[natleq])
é uma bem-ordem, i.e.,
$$
\text{para todo habitado $A\is\SetA \Nat$,\quad $A$ tem membro mínimo}.
$$
Dizemos que $m$ é um \dterm{membro mínimo de $A$} sse $m \in A$ e
$\lforall {a \in A} {m \leq a}$.

\hint
Reductio ad absurdum.

\hint
Para chegar num absurdo suponha que existe $C \subset \nats$ não vazio
tal que $C$ não possui mínimo.
Vamos demonstrar que para todo $n\in\nats$, $C$ não possui membros $c \leq n$.
Isso é suficiente para garantir que $C$ é vazio.

\hint
Agora indução.

\hint
\proofcase {Base: $C$ não possui membros $c \leq 0$.}
Imediato, pois o único natural $n \leq 0$ é o próprio $0$ que é o menor
membro do $\nats$.  Sabemos então que $0 \nin C$ pois caso contrário
o $C$ teria um mínimo.

\hint
\proofcase {Passo Indutivo.}
Seja $k$ tal que $C$ não possui membros $c \leq k$.
Basta demonstrar que $C$ não possui membros $c \leq k+1$.

\solution
Usamos reductio ad absurdum.
Para chegar num absurdo suponha que existe $C \subset \nats$ não vazio
tal que $C$ não possui mínimo.
Vamos demonstrar que para todo $n\in\nats$, $C$ não possui membros $c \leq n$.
Isso é suficiente para garantir que $C$ é vazio.
\proofcase {Base: $C$ não possui membros $c \leq 0$.}
Imediato, pois o único natural $n \leq 0$ é o próprio $0$ que é o menor
membro do $\nats$.  Sabemos então que $0 \nin C$ pois caso contrário
o $C$ teria um mínimo.
\proofcase {Passo Indutivo.}
Seja $k$ tal que $C$ não possui membros $c \leq k$.
Basta demonstrar que $C$ não possui membros $c \leq k+1$.
Suponha então que $C$ possui $c_0 \leq k+1$.
Logo $c_0 < k+1$ ou $c_0 = k+1$.
O caso $c_0 < k+1$ é eliminado pela (HI).
No outro caso temos $k+1 \in C$.
% TODO: finish this

%%}}}

%%{{{ prob: nat_even_or_odd 
\problem.
%%%{{{ meta 
\label nat_even_or_odd
%%%}}}

Qualquer Nat é par ou ímpar.

\hint
Indução!

%%}}}

\endproblems
%%}}}

%% CURRENT WORK

%%{{{ Abusing_types_and_their_inhabitants  
\section Abusando tipos e seus habitantes.
%%%{{{ meta 
\label Abusing_types_and_their_inhabitants
%%%}}}

%%{{{ x: ev_od_from_Nat_to_Nat 
\exercise Par ou ímpar.
%%%{{{ meta 
\label ev_od_from_Nat_to_Nat
%%%}}}

Implemente funções $\ev, \od : \Nat \to \Nat$ que
poderiam ser usadas para decidir se um $\Nat$ é par ou ímpar.

%%}}}

%%{{{ x: int_implemented_as_type_synonym_to_pairnat
\exercise Os inteiros como nats.
%%%{{{ meta 
\label int_implemented_as_type_synonym_to_pairnat
%%%}}}

Implemente o tipo de inteiros $\Int$ como type synonym do $\Nat\times\Nat$.

%%}}}

\endsection
%%}}}

%%{{{ Bool_type 
\section Os Bools.
%%%{{{ meta 
\label Bool_type
%%%}}}

%%{{{ df: Bool 
\definition Bool.
%%%{{{ meta 
\label Bool
\defines
    * Bool
    ;;
%%%}}}

Definimos o tipo de dados {$\Bool$}:
\data \Bool \\
\co \False : \Bool \\
\co \True  : \Bool \\
\enddata

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo $\Bool$, definimos as $\ev, \od$, agora sem abusos.
Encontramos aqui três diferentes maneiras de definí-las, a primeira
sendo efetivamente a mesma que fizemos no \ref[ev_od_from_Nat_to_Nat],
só nos livrando do seu abuso:

%%}}}

%%{{{ x: ev_od_from_Nat_to_Nat 
\exercise Par ou ímpar.
%%%{{{ meta 
\label ev_od_from_Nat_to_Nat
%%%}}}

Implemente funções $\ev, \od : \Nat \to \Bool$,
poderiam ser usadas para decidir se um $\Nat$ é par ou ímpar.

%%}}}

\endsection
%%}}}

%%{{{ Internalization_of_concepts 
\section Internalização de conceitos.
%%%{{{ meta 
\label Internalization_of_concepts
%%%}}}

%%{{{ df: natleq_rec_def 
\definition leq.
%%%{{{ meta 
\label natleq_rec_def
%%%}}}

Com o que temos já definido podemos definir recursivamente a função
\fundef
\fleq : \Nat \to \Nat \to \Bool \\
\fleqCC 0  m  &= \True \\
\fleqCC Sn 0  &= \False \\
\fleqCC Sn Sm &= \fleqAA n m. \\
\endfundef

%%}}}

%%{{{ eg: two_leq_four_but_four_notleq_two 
\example.
%%%{{{ meta 
\label two_leq_four_but_four_notleq_two
%%%}}}

Calcule os $\fleqAA {SS0} {SSSS0}$ e $\fleqAA {SSSS0} {SS0}$.

\solution.
Calculamos:
\poemcomputes 2
\poemcomputed {
\fleqSS SS0 SSSS0 \\
  = \fleqSS S0 SSS0 \by {\funref[\fleq.3]} \\
  = \fleqSS 0  SS0  \by {\funref[\fleq.3]} \\
  = \True.          \by {\funref[\fleq.1]} \\
}
&
\poemcomputed {
\fleqSS SSSS0 SS0 \\
  = \fleqSS SSS0 S0 \by {\funref[\fleq.3]} \\
  = \fleqSS SS0  0  \by {\funref[\fleq.3]} \\
  = \False.         \by {\funref[\fleq.2]} \\
}
\endpoemcomputes

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos demonstrar que $\fleq$ \dq{é uma ordem linear},
demonstrando cada uma das propriedades como fizemos sobre a
$(\leq)$ nos exercícios
(\reftag[natleq_refl],
\reftag[natleq_antisym],
\reftag[natleq_trans],
\reftag[natleq_total])
mas uma maneira melhor que vai nos permitir ganhar
bem mais resultados de graça é demonstrar que $(\leq)$
e $\fleq$ são na verdade a mesma relação.
Ou seja, as definições~\reftag[natleq]
e~\reftag[natleq_rec_def] são equivalentes.
Tu demonstrarás isso no~\ref[natleq_internal].

%%}}}

%%{{{ x: natleq_internal 
\exercise internal-leq.
%%%{{{ meta 
\label natleq_internal
%%%}}}

Na~\ref[natleq] definimos a ordem $(\leq)$ nos naturais.
Na~\ref[natleq_rec_def] definimos a relação $(\preceq)$ nos naturais.
Obviamente não podemos dar duas definições diferentes para a mesma coisa.
Demonstre que as duas definições sempre concordam:
$$
\text{para todo $n,m\in\nats$, \quad $n \leq m \iff n \preceq m$.}
$$

%%}}}

%%{{{ x: nateq_internal 
\exercise internal-eq.
%%%{{{ meta 
\label nateq_internal
%%%}}}

Internalize a relação $(=)$ entre Nats.

\hint
Precisa definir uma $\feq : \Nat \times \Nat \to \Bool$
e demonstrar que, de fato, corresponde à igualdade $(=)$ entre Nats.

\hint
Definimos a internalização da $(=)$, $\feq$, assim:
\fundef
\feq : \Nat \times \Nat \to \Bool \\
\feqA {(\Ze, \Ze)}         &= \True \\
\feqA {(\Ze, \SuA \phole)} &= \False \\
\feqA {(\SuA \phole, \Ze)} &= \False \\
\feqA {(\SuA m, \SuA n)}   &= \feqA {(m,n)}. \\
\endfundef

%%}}}

\endsection
%%}}}

%%{{{ Unit_type 
\section O Unit.
%%%{{{ meta 
\label Unit_type
%%%}}}

%%{{{ df: Unit 
\definition Unit.
%%%{{{ meta 
\label Bool
\defines
    * Bool
    ;;
%%%}}}

Definimos o tipo de dados {$\Unit$}:
\data \Unit \\
\co \star : \Unit \\
\enddata

%%}}}

%%{{{ x: unit_type_in_and_out 
\exercise.
%%%{{{ meta 
\label unit_type_in_and_out
%%%}}}

Defina funções saindo do e entrando no tipo $\Unit$, ou seja, funções que tem tipos
$$
\Unit \to \beta
\qqtext{e}
\alpha \to \Unit.
$$
O que percebes?

%%}}}

\endsection
%%}}}

%%{{{ Empty_type 
\section O Empty.
%%%{{{ meta 
\label Empty_type
%%%}}}

%%{{{ df: Empty 
\definition Empty.
%%%{{{ meta 
\label Bool
\defines
    * Bool
    ;;
%%%}}}

Definimos o tipo de dados {$\Empty$}:
\data \Empty \\
\enddata
Sim.  Não tem nenhum construtor, e logo não tem nenhum habitante!

%%}}}

%%{{{ x: empty_type_in_and_out 
\exercise.
%%%{{{ meta 
\label empty_type_in_and_out
%%%}}}

Defina funções saindo do e entrando no tipo $\Empty$, ou seja, funções que tem tipos
$$
\Empty \to \beta
\qqtext{e}
\alpha \to \Empty.
$$
O que percebes?

%%}}}

\endsection
%%}}}

%%{{{ ListNat_type 
\section O ListNat.
%%%{{{ meta 
\label ListNat_type
%%%}}}

%%{{{ df: ListNat 
\definition ListNat.
%%%{{{ meta 
\label ListNat
\defines
    * ListNat
    ;;
%%%}}}

Definimos o tipo de dados {$\ListNat$}:
\data \ListNat \\
\co \Nil   : \ListNat \\
\co \Cons  : \Nat \to \ListNat \to \ListNat \\
\enddata

%%}}}

%%{{{ df: length_ListNat 
\definition length.
%%%{{{ meta 
\label length_ListNat
\defines
    * \length {~\ell}  -- o tamanho da ListNat $\ell$
    ;;
%%%}}}

\fundef
\length : \ListNat \to \Nat \\
\lengthA \Empty           &= \Ze \\
\lengthA (\ConsAA n {ns}) &= \SuA (\lengthA {ns}).
\endfundef

%%}}}

%%{{{ x: sum_and_product_ListNat 
\exercise.
%%%{{{ meta 
\label sum_and_product_ListNat
%%%}}}

Defina as funções:
$
\sum,
\product
\is \ListNat \to \Nat.
$

%%}}}

%%{{{ x: map_prequel 
\exercise.
%%%{{{ meta 
\label map_prequel 
%%%}}}

Defina as funções:
$
\addNat,
\mulNat,
\expNat,
\powNat
\is \Nat \to \ListNat \to \ListNat.
$

%%}}}

%%{{{ x: pw_prequel 
\exercise.
%%%{{{ meta 
\label pw_prequel
%%%}}}

Defina as funções:
$$
\pwAdd,
\pwMul,
\pwExp
\is \ListNat \to \ListNat \to \ListNat.
$$
O \wq{pw} vem de \dterm{pointwise},
a idéia sendo que aplicamos uma certa operação \dterm{ponto a ponto}
numa lista inteira, chegando numa nova lista.
Exemplos de input--output:
\funio
\pwAddCC \list{3,6,2}   \list{100,500,7} &= \list{103, 506, 9}  \\
\pwAddCC \list{1,2,3,4} \list{100,40}    &= \list{101, 42}      \\
\pwMulCC \list{1,2,3,4} \list{100,40,50} &= \list{100, 80, 150} \\
\pwExpCC \list{5,2,3,4} \list{2,8,3}     &= \list{25, 256, 27}. \\
\endfunio

%%}}}

%%{{{ x: stretch_countdown 
\exercise.
%%%{{{ meta 
%%%}}}

Defina as funções
\mathcols 2
&\stretch \is \Nat \to \ListNat \to \ListNat &
&\countdown \is \Nat \to \ListNat
\intertext {com exemplos de input--output}
&\funcoleqs {
\stretchCC 3 \list{2,8}      &= \list{2,2,2,8,8,8}     \\
\stretchCC 2 \list{1,9,8,3}  &= \list{1,1,9,9,8,8,3,3} \\
} &
&\funcoleqs {
\countdownC 4  &= \list{4,3,2,1,0} \\
\countdownC 1  &= \list{1,0}. \\
}
\endmathcols

%%}}}

\endsection
%%}}}

%%{{{ Structural_induction_principle 
\section Princípio da indução estrutural.
%%%{{{ meta 
\label Structural_induction_principle
%%%}}}

%%{{{ induction_on_ListNat 
\note Indução no ListNat.
%%%{{{ meta 
\label induction_on_ListNat
%%%}}}

O que nos permite usar recursão e indução nos naturais é sua definição inductiva.
Ou seja, podemos usar essas ferramentas em qualquer tipo que foi definido assim.

%%}}}

%%{{{ ListNat_induction_inference_rule 
\note Com de inferência.
%%%{{{ meta 
\label ListNat_induction_inference_rule
\defines
    * indução!para o tipo $\ListNat$
    ;;
%%%}}}

Em forma de regra de inferência, o princípio da indução do $\ListNat$ é o seguinte:
$$
\PROOFmr {
\A {\tobraceb {\phi(\Nil)}
              {\explanation {$\Nil$ preserva a $\phi$}}}
                      \A {\tobraceb {\lforall {\ks \is \ListNat}
                                              {\phi(\ks)
                                                 \implies \lforall {k \is \Nat}
                                                                   {\phi(\ConsAA k \ks)}}}
                                    {\explanation {$\Cons$ preserva a $\phi$}}}
\I2---------------------------------------------------------------------------- {Ind$^{\ListNat}_\phi$}
                  {\lforall {\ns \is \ListNat} {\phi(\ns)}}
}
$$

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: listnat_implemented_as_type_synonym_to_nat
\problem Listas de nats como nats.
%%%{{{ meta 
\label listnat_implemented_as_type_synonym_to_nat
%%%}}}

Implemente o tipo de listas-de-nats $\ListNat$ como type synonym do $\Nat$.

%%}}}

%%{{{ prob: pairnat_implemented_as_type_synonym_to_nat
\problem Os PairNats como Nats.
%%%{{{ meta 
\label pairnat_implemented_as_type_synonym_to_nat
%%%}}}

Implemente o tipo de parzinhos-de-nats $\Nat\times\Nat$ como type synonym do $\Nat$.

%%}}}

\endproblems
%%}}}

%%{{{ List_types 
\section Listas.
%%%{{{ meta 
\label List_types
%%%}}}

%%{{{ df: List 
\definition List.
%%%{{{ meta 
\label List
\defines
    * \ListA {~\alpha}  -- o tipo de dados $\ListA \alpha$
    ;;
%%%}}}

Para qualquer $\alpha \is \Type$, definimos o tipo de dados {$\ListA \alpha$}:
\data \ListA \alpha \\
\co \Nil   : \ListA \alpha \\
\co \Cons  : \alpha \to \ListA \alpha \to \ListA \alpha \\
\enddata
Note que $\List \is \Type \to \Type$.
O contexto permitindo, podemos abreviar o $\ListA \alpha$ por $\fA {\type L} \alpha$.

%%}}}

%%{{{ List_induction_inference_rule 
\note List-induction.
%%%{{{ meta 
\label List_induction_inference_rule
\defines
    * indução!para o tipo $\ListA \alpha$
    ;;
%%%}}}

Em forma de regra de inferência, o princípio da indução do $\List \alpha$ é o seguinte:
$$
\PROOFmr {
\A {\tobraceb {\phi(\lnil)}
              {\explanation {$\lnil$ preserva a $\phi$}}}
                       \A {\tobraceb {\lforall {\xs \is \ListA \alpha} {\phi(\xs) \implies \lforall {x \is \alpha} {\phi(x \lcons \xs)}}}
                                     {\explanation {$(\lcons)$ preserva a $\phi$}}}
\I2-------------------------------------------------------------------------------- {Ind$^{\ListA \alpha}_\phi$}
                       {\lforall {\ns \is \Nat} {\phi(\ns)}}
}
$$

%%}}}

%%{{{ df: length_fundef 
\definition Length.
%%%{{{ meta 
\headerize
\label length_fundef
\defines
    * \length {~\ell}  -- o tamanho da lista $\ell$
    ;;
%%%}}}

Definimos a versão polimófica da $\length$:
\fundef
\length : \ListA \alpha \to \Nat \\
\lengthA \lnil        &= \Ze \\
\lengthP {x\lcons\xs} &= \SuP {\lengthA \xs}.
\endfundef

%%}}}

%%{{{ df: reverse_fundef 
\definition Reverse.
%%%{{{ meta 
\headerize
\label reverse_fundef
\defines
    * \reverseA {~\ell}  -- a reversa da lista $\ell$
    ;;
%%%}}}

Definimos a função $\reverse$:
\fundef
\reverse : \ListA \alpha \to \ListA \alpha \\
\reverseA \lnil         &= \lnil \\
\reverseS (x\lcons\xs)  &= \reverseA \xs \concat \list {x}.
\endfundef

%%}}}

%%{{{ df: concat_fundef 
\definition Concat.
%%%{{{ meta 
\headerize
\label concat_fundef
\defines
    * {~{\ell_1}} \concat {~{\ell_2}}  -- a concatenação da lista $\ell_1$ com a $\ell_2$
    ;;
%%%}}}

Definimos a função $(\concat)$:
\fundef
(\concat) : \ListA \alpha \to \ListA \alpha \to \ListA \alpha \\
\lnil        \concat \ys &= \ys    \\
(x\lcons\xs) \concat \ys &= x \lcons (\xs \concat \ys).
\endfundef

%%}}}

\TODO Terminar.

\endsection
%%}}}

%%{{{ Destructors 
\section Destrutores.
%%%{{{ meta 
\label Destructors
%%%}}}

%%{{{ Whose is the destructor?
\remark De quem é o destrutor?.
%%%{{{ meta 
%%%}}}

Mesmo que às vezes dá para ver $\head$ e $\tail$ sendo referidos como
\dq{destrutores do tipo $\ListA \alpha$}, isso é um abuso pesado de linguagem.
Não são os tipos que têm destrutores, mas sim os seus construtores!
E quantos destrutores tem, cada construtor?
Tantos quantos argumenos ele precisa para construir um habitante do tipo!
Olhando ao tipo $\ListA \alpha$ como exemplo, ele tem $2$ construtores:
\mathcol
\Nil  &\is \ListA \alpha \\
\Cons &\is \alpha \to \ListA \alpha \to \ListA \alpha. \\
\endmathcol
Deles, o $\Nil$ tem aridade $0$ e logo $0$ destrutores também;
mas o $\Cons$ tem aridade $2$ e voilá: $2$ destrutores.
Considere uma lista $\ell \is \ListA \alpha$ que foi construida pelo $\Cons$.
Isso significa que no processo de construí-la duas informações entraram nela:
uma de tipo $\alpha$, e uma de tipo $\ListA \alpha$, já que esses são os tipos
dos argumentos do seu construtor $\Cons$.
Cada destruidor é responsável para extrair a correspondente inforação:
aqui o $\head : \ListA \alpha \parto \alpha$ é responsável para extrair a primeira
e o $\tail : \ListA \alpha \parto \ListA \alpha$ extrai a segunda.
Os nomes que escolhemos para eles são indicativos sobre o que e como pensamos
sobre os objetos construidos por tal construtor: o que acabam sendo essas informações
que o construtor coloca dentro do objeto construido, para o próprio objeto?
No exemplo atual, os visualizamos como cabeça e rabo da lista construida,
e logo os nomes.

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Recursion_induction_same_coin 
\section Dois lados da mesma moeda.
%%%{{{ meta 
\label Recursion_induction_same_coin
%%%}}}

\TODO conectar 3-eq defs com 3-pattern induction, match-with, etc.

\TODO quais são os presentes numa dessas; teaser wf-induction.

%%{{{ inductive_definition 
\note Definição inductiva.
%%%{{{ meta 
\label inductive_definitions
%%%}}}

Definimos o tipo $\Nat$ listando suas formas (\reftag[nat_data_forms]) assim:
$$
\dataforms \alert{\Nat} = {\Ze \dataor \Su \fa \alert{\Nat}}
$$
Note o $\Nat$ que aparece no lado direito também;
é nesse sentido podemos dizer que essa foi uma definição recursiva.
Alternativamente, optando para listar seus construtores (\reftag[nat_data_cons]) foi assim:
\data \alert{\Nat} \\
\co \Ze : \Nat \\
\co \Su : \alert{\Nat} \to \Nat \\
\enddata
Aqui note o $\alert{\Nat}$ que reaparece \emph{como argumento}
para um dos seus próprios construtores.
Esse tipo de definição chamamos de \dterm{definição inductiva}.
Ela libera duas ferramentas poderosas:
definir operações e relações por recursão;
e demonstrar propriedades por indução.
Na verdade se trata da mesma ferramenta;
dois lados da mesma moeda.

%%}}}

%%{{{ inductive_vs_recursive_definitions 
\beware.
%%%{{{ meta 
\label inductive_vs_recursive_definitions
%%%}}}

Muitas vezes \emph{definição inductiva} acaba sendo chamada \emph{definição recursiva}.
Vários autores, dependendo da área que estão trabalhando adoptam um uso ou
o outro, ou ambos, ou até diferenciando o que cada um significa.
Tradicionalmente o slogan é:
\standout
\wq{defina por recursão; demonstre por indução}.
\endstandout

%%}}}

%%{{{ the_gift_of_recursion 
\note O presente da recursão.
%%%{{{ meta 
\label the_gift_of_recursion
%%%}}}

Estamos tentando \emph{definir algo por recursão},
por exemplo a operação de multiplicação
(\ref[nats_ntimes_recursive_def]).
Escrevemos já
$$
\align
n \ntimes 0  &= 0 \\
n \ntimes Sm &= \text{\lthole}
\endalign
$$
e estamos pensando em como completar nossa definição.
E a Recursão chega e nos oferece um presente:
\quote
<<Para definir o $n \ntimes Sm$, considere o valor do $n \ntimes m$ como dado,
de graça por mim; e veja se tu consegues definir o valor de $n \ntimes Sm$ com isso.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da recursão}.

%%}}}

%%{{{ the_gift_of_induction 
\note O presente da indução.
%%%{{{ meta 
\label the_gift_of_induction
%%%}}}

Estamos tentando \emph{demonstrar algo por indução}
por exemplo a associatividade da adição.
Já demonstramos a base (o $\phi(0)$), e queremos
demonstrar o $\phi(Sn)$.
E a Indução chega e nos oferece um presente:
\quote
<<Para demonstrar a $\phi(Sn)$, considere a $\phi(n)$ como dado, de graça por mim;
e veja se tu consegues demonstrar a $\phi(Sn)$ com isso agora.>>
\endquote
E é exatamente o que fizemos.
É isto o \dterm{poder da indução}.
Compare com nossa primeira tentativa de demonstrar a associatividade da adição
(sem indução) onde nossa única maneira de andar era separar em casos,
mas cada vez que conseguimos matar o \dq{caso 0}, o \dq{caso sucessor} tava
sempre gerando mais dois subcasos: um novo \dq{caso 0} e um novo \dq{caso sucessor}.
E nossos dados continuavam insuficientes para matar o segundo.

%%}}}

%%{{{ Where is recursion's principle? 
\note E a recursão?  Não tem princípio não?.
%%%{{{ meta 
%%%}}}

Se recursão e indução são dois lados da mesma moeda mesmo,
e já encontramos e enunciamos o princípio da indução;
a gente não deveria ter analogamente um princípio da recursão
também?
Tem sim, e temos o usado repetidamente cada vez que definimos
uma função por recursão.
Dependendo de quais são os fundamentos matemáticos em cima
de quais estamos trabalhando e do contexto também,
os \dq{dois} princípios podem ser, de fato, apenas um e o mesmo,
ou pode ser que um tem papel de princípio e o outro é demonstrável
a partir dele (e vice versa), ou que ambos acabam sendo teoremas.
Encontramos essas situações mais pra frente:
no \ref[Functions] voltamos a esse assunto de justificar definições recursivas
(\ref[Recursive_definitions_as_systems]);
no \ref[Posets_Lattices] obtemos resultados que garantam e mostram como computar
funções assim definidas (\ref[Fixpoints_in_posets]);
no \ref[Set_theory]
demonstramos o teorema da indução dos naturais (\ref[Constructing_the_natural_numbers])
e o teorema da recursão dos naturais (\ref[Recursion_theorems]).
Sugiro paciência pois precisamos mais ferramentas e maturidade.
O ponto, agora, é que não precisamos nada disso para conseguir trabalhar
em forma correta com demonstrações indutivas e definições recursivas.

%%}}}

\endsection
%%}}}

%%{{{ Some_higher_order_functions 
\section Umas funções de ordem superior.
%%%{{{ meta 
\label Some_higher_order_functions
%%%}}}

%%{{{ df: map_fundef 
\definition map.
%%%{{{ meta 
\label map_fundef
%%%}}}

Definimos a função $\fmap$:
\fundef
\fmap : (\alpha \to \beta) \to (\ListA \alpha) \to (\ListA \beta) \\
\fmapAA f \lnil         &= \lnil \\
\fmapSS f (x\lcons\xs)  &= \fA f x : \fmapAA f \xs \\
\endfundef

%%}}}

%%{{{ df: filter_fundef 
\definition filter.
%%%{{{ meta 
\label filter_fundef
%%%}}}

Definimos a função $\ffilter$:
\fundef
\ffilter : (\alpha \to \Bool) \to (\ListA \alpha) \to (\ListA \alpha) \\
\ffilterAA p \lnil &= \lnil \\
\ffilterSS p (x\lcons\xs) &= \IF p\fa x
                             \THEN x \lcons \ffilterAA p \xs
                             \ELSE \ffilterAA p \xs \FI\\
\endfundef
Ou, usando \dterm{guards},
\fundef
\ffilter : (\alpha \to \Bool) \to (\ListA \alpha) \to (\ListA \alpha) \\
\ffilterAA p \lnil &= \lnil \\
\ffilterSS p (x\lcons\xs) \\
\guards
p \fa x    &= x \lcons \ffilterAA p \xs \\
\otherwise &= \ffilterAA p \xs \\
\endguards
\endfundef

%%}}}

%%{{{ x: filter_fundef_DRY 
\exercise DRY.
%%%{{{ meta 
\label filter_fundef_DRY
%%%}}}

Elimine a repetição na \ref[filter_fundef].

\hint
Nos dois branches a expressão retornada é algo aplicado ao $\ffilterAA p \xs$.

\solution
\fundef
\ffilter : (\alpha \to \Bool) \to (\ListA \alpha) \to (\ListA \alpha) \\
\ffilterAA p \lnil &= \lnil \\
\ffilterSS p (x\lcons\xs) &= \PIF p\fa x \THEN {\fsec x \lcons} \ELSE \fid \FIP \fap {\ffilterAA p \xs}
\endfundef

%%}}}

%%{{{ thm: filter_map 
\theorem.
%%%{{{ meta 
\label filter_map
%%%}}}

$$
\pforall {f : \alpha \to \beta}
\lforall {p : \beta \to \Bool}
    {\ffilterA p \of \fmapA f = \fmapA f \of \ffilterA {(p \of f)}}.
\stag[filter-map]
$$

\proof.
Sejam $f : \alpha \to \beta$ e $p : \beta \to \Bool$.
Para demonstrar
$$
{\ffilterA p \of \fmapA f = \fmapA f \of \ffilterA {(p \of f)}}
$$
pela definição de igualdade entre funções, preciso demonstrar
$$
\lforall {\ell : \ListA \alpha}
    {\paren{\ffilterA p \of \fmapA f} \fa \ell = \paren{\fmapA f \of \ffilterA {(p \of f)}} \fa \ell}
$$
Por indução no $\ell$.
\crproofcase {Caso $\lnil$.}
Precisamos demonstrar:
$$
\paren{\ffilterA p \of \fmapA f} \fa \lnil
\askeq
\paren{\fmapA f \of \ffilterA {(p \of f)}} \fa \lnil.
$$
Calculamos os dois lados:
\poemcomputes 2
\poemcomputed {
(\ffilterA p \of \fmapA f) \fa \lnil \\
  = \ffilterAA p (\fmapAA f \lnil)
                        \by {\funref[(\of).1]} \\
  = \ffilterAA p \lnil  \by {\funref[\fmap.1]} \\
  = \lnil               \by {\funref[\ffilter.1]} \\
} &
\poemcomputed {
(\fmapA f \of \ffilterA {(p \of f)}) \fa \lnil \\
  = \fmapAA f {(\ffilterAA {(p \of f)} \lnil)} \by {\funref[(\of).1]} \\
  = \fmapAA f \lnil  \by {\funref[\ffilter.1]} \\
  = \lnil.           \by {\funref[\fmap.1]}    \\
}
\endpoemcomputes
\proofcase {Caso $(x \lcons \xs)$.}
Aqui temos a hipótese indutiva
$$
\paren{\ffilterA p \of \fmapA f} \fa \xs
=
\paren{\fmapA f \of \ffilterA {(p \of f)}} \fa \xs.
$$
Separamos em casos:
\crproofcase {Caso $(p \of f) \fa x = \True$}, e logo $p \fa (f \fa x) = \True$.
Calculamos:
\poemcompute
(\ffilterA p \of \fmapA f) \fa (x \lcons \xs) \\
  = \ffilterAA p {(\fmapAA f {(x \lcons \xs)})}                  \by {\funref[(\of).1]} \\
  = \ffilterAA p {(\fA f x \lcons \fmapAA f \xs)}                \by {\funref[\fmap.2]} \\
  = \fA f x \lcons \ffilterAA p {(\fmapAA f \xs)}                \by {\funref[\ffilter.2] e HC} \\
  = \fA f x \lcons (\ffilterA p \of \fmapA f) \fa \xs            \by {\funref[(\of).1]} \\
  = \fA f x \lcons (\fmapA f \of \ffilterA {(p \of f)}) \fa \xs  \by {HI} \\
  = \fA f x \lcons (\fmapAA f {(\ffilterAA {(p \of f)} \xs)})    \by {\funref[(\of).1]} \\
  = \fmapAA f {(x \lcons \ffilterAA {(p \of f)} \xs)}            \by {\funref[\fmap.2]} \\
  = \fmapAA f {(\ffilterAA {(p \of f)} {(x \lcons \xs)}))}       \by {\funref[\ffilter.2] e HC} \\
  = (\fmapA f \of {\ffilterA {(p \of f)}}) \fa (x \lcons \xs)    \by {\funref[(\of).1]} \\
\endpoemcompute
\crproofcase {Caso $(p \of f) \fa x = \False$}, e logo $p \fa (f \fa x) = \False$.
\poemcompute
(\ffilterA p \of \fmapA f) \fa (x \lcons \xs) \\
  = \ffilterAA p {(\fmapAA f {(x \lcons \xs)})}    \by {\funref[(\of).1]} \\
  = \ffilterAA p {(\fA f x \lcons \fmapAA f \xs)}  \by {\funref[\fmap.2]} \\
  = \ffilterAA p {(\fmapAA f \xs)}                 \by {\funref[\ffilter.2] e HC} \\
  = (\ffilterA p \of \fmapA f) \fa \xs             \by {\funref[(\of).1]} \\
  = (\fmapA f \of \ffilterA {(p \of f)}) \fa \xs   \by {HI} \\
  = \fmapAA f {(\ffilterA {(p \of f)} \fa \xs}                 \by {\funref[(\of).1]} \\
  = \fmapAA f {(\ffilterAA {(p \of f)} {(x \lcons \xs)}}       \by {\funref[\ffilter.2] e HC} \\
  = (\fmapA f \of \ffilterA {(p \of f)}) \fa {(x \lcons \xs)}  \by {\funref[(\of).1]} \\
\endpoemcompute

%%}}}

%%{{{ ifthenelse_instead_of_splitting 
\note.
%%%{{{ meta 
\label ifthenelse_instead_of_splitting 
%%%}}}

Na demonstração do \ref[filter_map], escolhi separar em casos, para evitar
carregar a expressão com o if-then-else nas costas.
Sem separar em casos, este cálculo ficaria assim:
\funcompute
        (\ffilterA p \of \fmapA f) \fa (x \lcons \xs)
\does = \by {\funref[(\of).1]} \\
        \ffilterAA p {(\fmapAA f {(x \lcons \xs)})}
\does = \by {\funref[\fmap.2]} \\
        \ffilterAA p {(\fA f x \lcons \fmapAA f \xs)}
\does = \by {\funref[\ffilter.2]} \\
        \IF \fA p {(\fA f x)} \THEN \fA f x \lcons \ffilterAA p {(\fmapAA f \xs)}
                              \ELSE \ffilterAA p {(\fmapAA f \xs)} \FI
\does = \by {\funref[(\of).1]} \\
        \IF \fA p {(\fA f x)} \THEN \fA f x \lcons (\ffilterA p \of \fmapA f) \fa \xs
                              \ELSE (\ffilterA p \of \fmapA f) \fa \xs \FI
\does = \by {HI} \\
        \IF \fA p {(\fA f x)} \THEN \fA f x \lcons (\fmapA f \of \ffilterA {(p \of f)}) \fa \xs
                              \ELSE (\fmapA f \of \ffilterA {(p \of f)}) \fa \xs \FI
\does = \by {\funref[(\of).1]} \\
        \IF (p \of f) \fa x \THEN \fA f x \lcons (\fmapAA f {(\ffilterAA {(p \of f)} \xs)})
                            \ELSE \fmapAA f {(\ffilterA {(p \of f)} \fa \xs)} \FI
\does = \by {\funref[\fmap.2]} \\
        \IF (p \of f) \fa x \THEN \fmapAA f {(x \lcons \ffilterAA {(p \of f)} \xs)}
                            \ELSE \fmapAA f {(\ffilterA {(p \of f)} \fa \xs)} \FI
\does = \by {ifthenelse-distr} \\
        \fmapAA f {(\IF (p \of f) \fa x \THEN x \lcons \ffilterAA {(p \of f)} \xs
                                        \ELSE \ffilterAA {(p \of f)} \xs \FI)}
\does = \by {\funref[(\of).1]} \\
        \fmapAA f {(\IF (p \of f) \fa x \THEN \ffilterAA {(p \of f)} {(x \lcons \xs)}
                                        \ELSE \ffilterAA {(p \of f)} \xs \FI)}
\does = \by {\funref[\ffilter.2]} \\
        \fmapAA f {(\ffilterAA {(p \of f)} {(x \lcons \xs)})}
\does = \by {\funref[(\of).1]} \\
        (\fmapA f \of \ffilterA {(p \of f)}) \fa (x \lcons \xs).
\endfuncompute

%%}}}

%%{{{ x: ifthenelse_distr 
\exercise ifthenelse-distr.
%%%{{{ meta 
\label ifthenelse_distr
%%%}}}

Enuncie e demonstre o (ifthenelse-distr) citado acima.

%%}}}

%%{{{ df: folds_fundef 
\definition folds.
%%%{{{ meta 
\label listfolds_fundef
%%%}}}

Definimos as funções $\foldl$ e $\foldr$:
\fundefs 2
\fundefed {
\foldl : (\beta \to \alpha \to \beta) \to \beta \to (\ListA \alpha \to \beta) \\
\foldlAAA f z \lnil         &= z \\
\foldlAAP f z {x \lcons xs} &= \foldlAPA f {\fAA f z x} xs \\
} &
\fundefed {
\foldr : (\alpha \to \beta \to \beta) \to \beta \to (\ListA \alpha \to \beta) \\
\foldrAAA f z \lnil         &= z \\
\foldrAAP f z {x \lcons xs} &= \fAP f x {\foldrAAA f z {xs}} \\
}
\endfundefs
Ou, reescrevendo usando \emph{where}, e trocando uns nomes:
\fundefs 2
\fundefed {
\foldl : (\beta \to \alpha \to \beta) \to \beta \to (\ListA \alpha \to \beta) \\
\foldlAAA f v \lnil         &= v \\
\foldlAAP f v {x \lcons xs} &= \foldlAAA f {v'} xs \\
\where
v'  &= \fAA f z x \\
\endwhere
} &
\fundefed {
\foldr : (\alpha \to \beta \to \beta) \to \beta \to (\ListA \alpha \to \beta) \\
\foldrAAA c n \lnil         &= n \\
\foldrAAP c n {x \lcons xs} &= \fAA c x t  \\
\where
t  &= \foldrAAA c n {xs} \\
\endwhere
}
\endfundefs


%%}}}

\TODO Elaborar.

\endsection
%%}}}

%%{{{ Polymorphism 
\section Polimorfísmo.
%%%{{{ meta 
\label Polymorphism
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Sums_and_products_done_right 
\section Somatórios e produtórios.
%%%{{{ meta 
\label Sums_and_products_done_right 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: inhabited_list_type 
\problem IList.
%%%{{{ meta 
\label inhabited_list_type
%%%}}}

Defina o construtor de tipos $\IList \is \Type \to \Type$, que construa
tipos de listas \emph{habitadas}.
Defina também funções $\head$ e $\tail$ pare este tipo, e uma função
$$
\toList \is \IList \to \List.
$$

%%}}}

%%{{{ prob: evenlist_and_oddlist 
\problem EList, OList.
%%%{{{ meta 
\label evenlist_and_oddlist 
%%%}}}

Defina \emph{usando recursão mútua} os construtores de tipos $\EList, \OList \is \Type \to \Type$,
que construam tipos de listas de tamanhos garantidamente par (a $\OList$) e ímpar (a $\EList$).
Defina também funções $\head$ e $\tail$ para cada uma dessas listas, e funções
$\toList$.

%%}}}

%%{{{ prob: injectivity_of_succ_proof_fail 
\problem.
%%%{{{ meta 
\label injectivity_of_succ_proof_fail
%%%}}}

No \ref[Functions] aprendemos que conseguir uma função $(\of)$-L-inversa
duma função $f : \alpha \to \beta$, i.e., uma $f' : \alpha \from \beta$
tal que
$$
f' \of f = \idof \alpha
$$
é suficiente para garantir que $f$ é \dterm{injetiva:}
$$
\lforall {a, a' \is \alpha} {\fA f a = \fA f {a'} \implies a = a'}.
$$
Dado isso,
% STUDENT: Hannah
uma aluna tentou demonstrar a $\Su$-injetividade assim:
\quote
\proofpart{Injetividade de $\Su$.}
Considere a $\pred : \Nat \from \Nat$.
Basta mostrar que ela é uma $(\of)$-L-inversa da $\Su$:
$
(\pred \of \Su) \fa n
= \predP {\SuA n}
= n
= \id n
$.
\endquote
A demonstração é válida?
Se não, especifique o erro;
senão, por que estipulamos tal injetividade como princípio em vez de consegui-la como teorema?

\hint
A demonstração compila sim, mas mesmo assim ela não pode ser usada para
nos livrar da estipulação da injetividade como princípio para o $\Nat$.
Por que não?

\hint
A demonstração depende desse mesmo princípio que está demonstrando, e logo
acaba sendo uma demonstração trivial (tendo já o princípio),
ou incompilável (não o tendo).
O desafio é perceber onde que tal princípio foi usado nesta demonstração.

\hint
A demonstração usa a $\pred$, mas como ela foi definida mesmo?

\solution
A demonstração usa a $\pred$, mas para sua definição \emph{funcionar}
já precisamos da injetividade de $\Su$; sem ela, a $\pred$, recebendo seu argumento $n$,
não teria como aproveitar o pattern-matching para obter acesso \emph{àquele}
$n'$ tal que $n = \SuA {n'}$, para conseguir retorná-lo.
Se tivesse outro (distinto) $n''$ tal que $n = \SuA {n''}$, qual dos $n', n''$
a $\pred$ retornaria?
\eop
O que acontece se tentar resolver isso escolhendo um específico deles para retornar
(por exemplo, o menor)?  Note que a $\pred$ viraria, de fato, função.
E agora: com esse ajuste, a demonstração compila e pode ser usada
para conseguir o princípio como teorema?

%%}}}

%%{{{ prob: injectivity_of_succ_proof_fail_again 
\problem.
%%%{{{ meta 
\label injectivity_of_succ_proof_fail_again 
%%%}}}

(Apenas depois de resolver o \ref[injectivity_of_succ_proof_fail].) \CR
Responda na pergunta surgida no fim da minha resolução de \ref[injectivity_of_succ_proof_fail].

\hint
Não dá.  Agora a demonstração não compila por outro motivo.

\solution
A nova versão de $\pred$ não é mais um $(\circ)$-L-inverso.
Considere tais $n' \neq n''$ com $\SuA {n'} = n = \SuA {n''}$,
e com $n'$ o menor tal $\Nat$ (e logo o retornado pela $\pred$ recebendo $n$).
Assim temos
$$
\predP {\SuA {n''}} = \predA n = n' \neq n''
$$
e logo $\pred$ não é uma inversa esquerda da $\Su$.

%%}}}

\endproblems
%%}}}

%%{{{ Maybe_types 
\section Tipos de Maybe.
%%%{{{ meta 
\label Maybe_types
%%%}}}

%%{{{ df: Maybe 
\definition Maybe.
%%%{{{ meta 
\label Maybe
\defines
    * \MaybeA {~\alpha}  -- o tipo de dados $\MaybeA \alpha$
    ;;
%%%}}}

Definimos o construtor de tipos $\Maybe$ assim:
\data \Maybe \is (\alpha \is \Type) \to \Type \\
\co \Nothing : \MaybeA \alpha \\
\co \Just    : \alpha \to \MaybeA \alpha \\
\enddata
Podemos abreviar o $\MaybeA \alpha$ por $\fA {\type M} \alpha$ quando o contexto permite,
a seus construtores também, por $\cons N$ e $\cons J$ respectivamente.

%%}}}

\TODO Gambiarra (1): $\safeHead_1 \is \ListNat \to \ListNat$.

\TODO Gambiarra (2): $\fpf {junkHead} \is \ListNat \to \Bool \times \Nat$.

\TODO Gambiarra (3): $\fpf {defaultHead} \is \Nat \to \ListNat \to \Nat$.

\TODO Terminar.

\endsection
%%}}}

%%{{{ Either_types 
\section Tipos de Either.
%%%{{{ meta 
\label Either_types
%%%}}}

%%{{{ df: Either 
\definition Either.
%%%{{{ meta 
\label Either
\defines
    * \EitherAA {~\alpha} {~\beta}  -- o tipo de dados $\EitherAA \alpha \beta$
    ;;
%%%}}}

Para quaisquer $\alpha, \beta \is \Type$, definimos o tipo de dados {$\EitherAA \alpha \beta$}:
\data \EitherAA \alpha \beta \\
\co \Left  : \alpha \to \EitherAA \alpha \beta \\
\co \Right : \beta  \to \EitherAA \alpha \beta \\
\enddata
Note que $\Either \is \Type \to \Type \to \Type$.
Como esperado, quando o contexto permite
podemos abreviar os $\Either$, $\Left$, $\Right$ por $\type E$, $\cons L$,
$\cons R$ respectivamente.\foot
o meio ambiente agradece
\toof

%%}}}

\TODO Terminar.

\endsection
%%}}}

%%{{{ Products_sums_etc_types 
\section Produtos, somas, {etc.}.
%%%{{{ meta 
\label Products_sums_etc_types
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

\TODO Add problems.

\endproblems
%%}}}

%%{{{ Functors_recind 
\section Functors.
%%%{{{ meta 
\label Functors_recind
%%%}}}

%%{{{ spec: functor_spec_recind 
\specification Functor.
%%%{{{ meta 
\label functor_spec_recind
\defines
    * functor
    * lei!de functor
    ;;
%%%}}}

Considere os
\mathcol
F       &\is \Type \to \Type \\
\fmap_F &\is (\alpha\to\beta) \to (\fA F \alpha \to \fA F \beta)
\endmathcol
Dizemos que o $F$ com a $\fmap_F$ é um \dterm{functor} sse
as duas \dterm{leis de functor} são satisfeitas:
\mathcol
\fA {\fmap_F} \fid        &= \fid \stag[functor-id] \\
\fA {\fmap_F} {(f \of g)} &= \fA {\fmap_F} f \of \fA {\fmap_F} g. \stag[functor-comp] \\
\endmathcol
Escrevemos apenas $\fmap$ quando o $F$ é inferível pelo contexto.

%%}}}

%%{{{ thm: List_functor 
\theorem List-functor.
%%%{{{ meta 
\label List_functor
%%%}}}

O $\List \is \Type \to \Type$ com sua
$\fmap \is (\alpha\to\beta) \to (\ListA \alpha \to \ListA \beta)$
é um functor.

\proof.
Precisamos demonstrar as duas leis de functors.
A primeira é pra ti (\ref[List_functor_first_law_proof]),
e a segunda, i.e.,
$$
\noflex
\lforall {\alpha \toby g \beta \toby f \gamma}
         {\fmapA {(f \of g)} = \fmapA f \of \fmapA g},
$$
pra mim.
Sejam $\alpha \toby g \beta \toby f \gamma$.
Agora, pela definição da igualdade sobre funções, preciso demonstrar
$$
\lforall {\ell \is \ListA \alpha}
         { \fmapPA {f \of g} \ell
             =
           \fA {(\fmapA f \of \fmapA g)} \ell }.
$$
Seja $\ell \is \ListA \alpha$.
Por indução.
\crproofcase {Caso $\lnil$.}
Calculamos:
\compute
\fmapPA {f \of g} \lnil
  &= \lnil                         \by {\funref[\fmap.1]} \\
\fA {(\fmapA f \of \fmapA g)} \lnil
  &= \fmapAP f {\fmapAA g \lnil} \by {\funref[(\of).1]} \\
  &= \fmapAA f \lnil             \by {\funref[\fmap.1]} \\
  &= \lnil.                      \by {\funref[\fmap.1]}
\endcompute
\proofcase {Caso $(x \lcons \xs)$.}
Calculamos os dois lados:
\poemcomputes 2
\poemcomputed {
\fmapPP {f \of g} {x \lcons \xs} \\
  = \fA {(f \of g)} x \lcons \fmapPA {f \of g} \xs              \by {\funref[\fmap.2]} \\
  = \fA {(f \of g)} x \lcons (\fmapAA f \xs \of \fmapAA g \xs)  \by {HI} \\
  = {\fP f {\fA g x}} \lcons (\fmapAA f \xs \of \fmapAA g \xs)  \by {\funref[(\of).1]} \\
  = {\fP f {\fA g x}} \lcons \fmapAP f {\fmapAA g \xs}          \by {\funref[(\of).1]} \\
} &
\poemcomputed {
\fP {(\fmapA f \of \fmapA g)} {x \lcons \xs} \\
  = \fmapAP f {\fmapAA g {(x \lcons \xs)}}              \by {\funref[(\of).1]} \\
  = \fmapAP f {\fA g x \lcons \fmapAA g \xs}            \by {\funref[\fmap.2]} \\
  = {\fP f {\fA g x}} \lcons \fmapAP f {\fmapAA g \xs}  \by {\funref[\fmap.2]} \\
}
\endpoemcomputes

%%}}}

%%{{{ x: List_functor_first_law_proof 
\exercise.
%%%{{{ meta 
\label List_functor_first_law_proof
%%%}}}

Demonstre a primeira lei de functor para o $\List$ com sua $\fmap$.

%%}}}

%%{{{ x: type_ops_functor_check 
\exercise.
%%%{{{ meta 
\label type_ops_functor_check
%%%}}}

Para cada um dos
$$
\fsec \alpha +, \quad
\fsec + \beta, \quad
\fsec \alpha \times, \quad
\fsec \times \beta, \quad
\fsec \gamma \to, \quad
\fsec \to \delta \quad
\is \Type \to \Type
$$
verifique se pode fazer parte dum functor:
se pode, defina correspondente $\fmap$ que satisfaz as leis de functor
(assim satisfazendo a \ref[functor_spec_recind]); senão, explique o porquê.

\hint
Com uma exeção, todos têm como atender a especificação de functor.

%%}}}

%%{{{ How about lists of maybes or similar types? 
\note.
%%%{{{ meta 
%%%}}}

E os $\Nat$, $\Bool$, $\ListA \Nat$, etc.?
Será que são functors também?
A resposta imediata nesse momento deve ser que até a pergunta tem um
type error, pois, pela especificação de functor (\reftag[functor_spec_recind])
apenas coisas de tipo $\Type \to \Type$ tem chances de ser functor (sim, junto
com uma $\fmap$ apropriada), mas esses bichos que botei na mesa na minha pergunta
todos são tipos, ou seja, tem tipo $\Type$, ou seja, não tem como eles serem
considerados functors.
Ou tem?
Lembre que o $0 \is \Nat$ também não é uma função, como nenhuma constante é,
mas podemos considerá-la como se fosse, com o simples hackinho de considerar a
$0 \is \Unit \to \Nat$ em vez do próprio $0 \is \Nat$.
Podemos fazer algo parecido com os tipos e aproveitar uma maneira de considerá-los
como possíveis functors.  Diga \wq{bem vindo} ao functor-constante:

%%}}}

%%{{{ df: Konst_type 
\definition Konst.
%%%{{{ meta 
\label Konst_type
\defines
    * \KonstA {~\kappa}   -- o functor constante $\kappa$
    ;;
%%%}}}

Dado qualquer tipo $\kappa$, o $\KonstA \kappa \is \Type \to \Type$ simplesmente ignora
seu argumento e retorna o próprio $\kappa$:
\fundef
\Konst : \Type \to \Type \to \Type \\
\KonstAA \kappa \alpha &\defeq \kappa.
\endfundef

%%}}}

%%{{{ blah: Konst κ : Type → Type
\blah.
%%%{{{ meta 
%%%}}}

Observe o tipo do próprio $\Konst \is \Type \to \Type \to \Type$; o aplicando
(parcialmente) a um tipo $\kappa$, obtemos o $\KonstA \kappa \is \Type \to \Type$,
e esse tem o tipo certo para ter chances de fazer parte dum functor!
Será que ele faz?

%%}}}

%%{{{ x: Konst_functor 
\exercise Konst-functor.
%%%{{{ meta 
\label Konst_is_a_functor
%%%}}}

Faz sim!

%%}}}

%%{{{ x: Id_type 
\exercise Id.
%%%{{{ meta 
\label Id_type
\defines
    * \Id   -- o functor identidade
    ;;
%%%}}}

Definimos já o functor constante $\KonstA \kappa : \Type \to \Type$,
agora queremos definir um tal de $\Id : \Type \to \Type$.
Defina.

%%}}}

%%{{{ x: Id_is_a_functor 
\exercise Id-functor.
%%%{{{ meta 
\label Id_is_a_functor
%%%}}}

Preciso enunciar?

%%}}}

% COMPOSING FUNCTORS

%%{{{ x: composing_functors_warmup_1 
\exercise.
%%%{{{ meta 
\label composing_functors_warmup_1
%%%}}}

Ache tipos $\alpha$ e $\beta$ tais que as tipagens seguintes são válidas:
\math
\JustA {\list {5,6,1}}, \quad
\JustA {\list {7}}, \quad
\JustA \lnil, \quad
\Nothing, \quad
\dots \quad
\is \alpha \\
\list {\JustA 3,\JustA 1, \JustA 3}, \quad
\list {\JustA 4}, \quad
\list {\Nothing}, \quad
\list {\JustA 5, \Nothing, \JustA 1}, \quad
\lnil, \quad
\dots \quad
\is \beta
\endmath

%%}}}

%%{{{ x: composing_functors_warmup_1_map 
\exercise.
%%%{{{ meta 
\label composing_functors_warmup_1_map
%%%}}}

Defina funções $\fmap_1, \fmap_2$ tais que para qualquer $f : \Nat \to \gamma$
a $\fmap_1 \fa f$ será aplicável nos objetos da primeira linha
do \ref[composing_functors_warmup_1] retornando
$$
\JustA {\list {\fA f 5,\fA f 6,\fA f 1}}, \quad
\JustA {\list {\fA f 7}}, \quad \dots
$$
e a $\fmap_2 \fa f$ nos objetos da segunda retornando
$$
\list {\JustP {\fA f 3}, \JustP {\fA f 1}, \JustP {\fA f 3}}, \quad
\list {\fA f 4}, \quad \dots
$$

\hint

%%}}}

%%{{{ x: composing_functors_warmup_2 
\exercise.
%%%{{{ meta 
\label composing_functors_warmup_2
%%%}}}

Escreva uns habitantes dos tipos seguintes:
\mathcol
\dots \quad &\is \ListP {\ListP {\Bool \to \Nat}} \\
\dots \quad &\is \ListP {\EitherAP \Nat {\MaybeP {\ListA \Bool}}}.
\endmathcol

%%}}}

%%{{{ How about lists of maybes or similar types? 
\note.
%%%{{{ meta 
%%%}}}

Considere tipos como os
\mathcols 2
\MaybeP {\ListA \Nat} &\is \Type &
\ListP {\MaybeA \Nat} &\is \Type \\
\ListP {\ListP {\Bool \to \Nat}} &\is \Type &
\ListP {\EitherAP \Nat {\MaybeP {\ListA \Bool}}} &\is \Type.
\endmathcols
e observe que, de fato, todos eles são tipos mesmo.
Uns habitantes desses tipos encontrou nos exercícios
\reftag[composing_functors_warmup_1] e \reftag[composing_functors_warmup_2].
Mesmo que o \ref[composing_functors_warmup_1_map] não foi nada difícil pra
ti---confio no teu potencial---e mesmo que tu gastou pouquíssimas linhas
para definir essas $\fmap$'s que ele pediu, deves concordar que se
conseguir a mesma funcionalidade com $0$ (zero) linhas, seria bem melhor.
Isso que faremos agora, demonstrando apenas um teorema.
Ainda mais, essa método é aplicável para todos os tipos \dq{desse tipo}:
tipos como esses que escrevi acima.
O primeiro passo é conseguir descrever esse tipo de tipo.
O que eles têm em comum mesmo?

%%}}}

\spoiler

%%{{{ A: compositions of functors 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Todos eles são construidos aplicando uns functors em outros tipos, que também foram construidos via functors, e por aí vai.
Ou seja: \emph{são composições de functors} aplicadas num tipo.
Eu vou explicitar as duas primeiras, que são mais simples,
e deixar as outras duas e ainda mais umas pra ti---acho justo:
\mathcols 2
\MaybeP {\ListA \Nat}  &= (\Maybe \of \List) \fa \Nat  &
\ListP  {\MaybeA \Nat} &= (\List \of \Maybe) \fa \Nat.
\endmathcols

%%}}}

%%{{{ x: composing_functors_explicit 
\exercise.
%%%{{{ meta 
\label composing_functors_explicit
%%%}}}

Escreva os tipos seguintes como composições de functors aplicados num tipo só
(tua escolha, se tiver), como eu acabei de fazer:
\mathcols 2
\ListP {\ListP {\Bool \to \Nat}}                    &\is \Type &
\ListP {\EitherAP \Nat {\MaybeP {\ListA \Bool}}}    &\is \Type \\
\Nat \times \ListP {\MaybeA \Nat}                   &\is \Type &
\EitherAP \Weekday {\Nat \times \Bool}              &\is \Type. \\
\endmathcols

\hint
Não esqueça os functors que descubriu no \ref[type_ops_functor_check].

\solution
\mathcols 2
\ListP {\ListP {\Bool \to \Nat}}
&= \paren{\List \of \List \of {\fsec \Bool \to}} \fa \Nat \\
\ListP {\EitherAP \Nat {\MaybeP {\ListA \Bool}}}
&= \paren{\List \of (\EitherA \Nat) \of \Maybe \of \List} \fa \Bool \\
\Nat \times \ListP {\MaybeA \Nat}
&= \paren{{\fsec \Nat \times} \of \List \of \Maybe} \fa \Nat \\
\EitherAP \Weekday {\Nat \times \Bool}
&= \paren{\EitherA \Weekday \of {\fsec \times \Bool}} \fa \Nat. \\
\endmathcols

%%}}}

\endsection
%%}}}

%%{{{ Tree_types 
\section Árvores.
%%%{{{ meta 
\label Tree_types
%%%}}}

\TODO Desenhar uns exemplos de árvores.

%%{{{ df: BinTree 
\definition BinTree.
%%%{{{ meta 
\label BinTree
\defines
    * \BinTreeA {~\alpha}   -- o tipo de árvores binárias $\TreeA \alpha$
    ;;
%%%}}}

Para qualquer $\alpha \is \Type$, definimos o tipo
\data \BinTreeA \alpha \\
\co \Tip    : \alpha \to \BinTreeA \alpha \\
\co \Fork   : \BinTreeA \alpha \to \BinTreeA \alpha \to \BinTreeA \alpha \\
\enddata
Chamamos o tipo de \dterm{binary tree}, por causa da quantidade de filhos que cada nó
dele tem (exatamente $2$).

%%}}}

%%{{{ remark: Tree 
\remark Tree.
%%%{{{ meta 
\label Tree
\defines
    * {\Tree}    -- um construtor de tipos de árvores inferível pelo contexto
    ;;
%%%}}}

Economizando minha tinta e teu cansaço visual, vou escrever $\TreeA \alpha$
ou até $\fA {\type T} \alpha$, quando é implicito qual de todas as árvores
está sendo considerada.

%%}}}

%%{{{ x: BinTree_nodes_leaves_depth_def 
\exercise nodes, leaves, depth.
%%%{{{ meta 
\label BinTree_nodes_leaves_depth_def
\defines
    * \nodesA  {~t}   -- a quantidade de nós na árvore $t$
    * \leavesA {~t}   -- a quantidade de folhas na árvore $t$
    * \depthA  {~t}   -- a quantidade de andares (a profundidade) da árvore $t$
    ;;
%%%}}}

Defina as funções
\mathcols 3
\nodes  &\is \TreeA \alpha \to \Nat &
\leaves &\is \TreeA \alpha \to \Nat &
\depth  &\is \TreeA \alpha \to \Nat.
\endmathcols
que contam os nós, as folhas, e os andares duma árvore.

\hint
Recursão!

\hint
Cada uma dessas funções é definida por exatamente duas equações,
uma para cada construtor de $\Tree alpha$.

\hint
Por exemplo, a definição da $\nodes$ tem essa forma:
\fundef
\nodes : \TreeA \alpha \to \Nat \\
\nodesP {\TipA x}         &= \askhole \\
\nodesP {\ForkAA \ell r}  &= \askhole.
\endfundef

\solution
Definimos a $\nodes$ que conta os nós duma árvore
\fundef
\nodes : \TreeA \alpha \to \Nat \\
\nodesP {\TipA \phole}    &= 0 \\
\nodesP {\ForkAA \ell r}  &= 1 + (\nodesA \ell) + (\nodesA r);
\endfundef
a $\leaves$ que conta as folhas
\fundef
\leaves : \TreeA \alpha \to \Nat \\
\leavesP {\TipA \phole}    &= 1 \\
\leavesP {\ForkAA \ell r}  &= (\leavesA \ell) + (\leavesA r).
\endfundef
e a $\depth$ que conta a altura, ou a profundidade (ou os \dq{andares})
\fundef
\depth : \TreeA \alpha \to \Nat \\
\depthP {\TipA \phole}    &= 0 \\
\depthP {\ForkAA \ell r}  &= 1 + (\fmaxPP {\depthA \ell} {\depthA r}).
\endfundef

%%}}}

%%{{{ thm: BinTree_leaves_nodes_thm
\theorem nodes-leaves.
%%%{{{ meta 
\label BinTree_leaves_nodes_thm
%%%}}}

Para toda árvore $t \is \TreeA \alpha$,
$$
\leavesA t = 1 + \nodesA t.
$$

\proof Demonstrarás agora no~\ref[BinTree_leaves_nodes_thm_proof].

%%}}}

%%{{{ x: BinTree_leaves_nodes_thm_proof 
\exercise.
%%%{{{ meta 
\label BinTree_leaves_nodes_thm_proof
%%%}}}

Demonstre o \ref[BinTree_leaves_nodes_thm].

\hint
Indução!

\hint
O formato da indução aqui vai ter dois casos:
\proofcase {Caso $(\TipA t')$}; \proofcase{Caso $(\ForkAA \ell r)$}.
No primeiro não há hipótese indutiva; no segundo temos duas:
uma sobre $\ell$ e uma sobre $r$.

%%}}}

%%{{{ thm: BinTree_leaves_depth_thm 
\theorem leaves-depth.
%%%{{{ meta 
\label BinTree_leaves_depth_thm
%%%}}}

Para toda árvore $t \is \TreeA \alpha$,
$$
\leavesA t \leq 2 \expop \depthA t.
$$

\proof.
Seja $t \is \TreeA \alpha$.
Por induçaõ no $t$.
\crproofcase {Caso $(\TipA x)$}.
Calculamos:
\compute
\leavesP {\TipA x}
&= 1 \by {\funref[\leaves.1]} \\
2 \expop \depthP {\TipA x} &= 2 \expop 0 = 1. \by {\funref[\depth.1]}
\endcompute
\crproofcase {Caso $(\ForkAA \ell r)$}.
Calculamos:
\poemcompute
\leavesP {\ForkAA \ell r} \\
  =    \leavesA \ell + \leavesA r                   \by {\funref[\leaves.2]} \\
  \leq 2 \expop \depthA \ell + \leavesA r           \by {hi-$\ell$} \\
  \leq 2 \expop \depthA \ell + 2 \expop \depthA r   \by {hi-$r$} \\
  \eqvdots                                          \by {\ref[BinTree_leaves_depth_thm_proof]} \\
  =    2 \expop \depthP {\ForkAA \ell r}.           \by {\funref[\depth.2]}
\endpoemcompute

%%}}}

%%{{{ x: BinTree_leaves_depth_thm_proof 
\exercise.
%%%{{{ meta 
\label BinTree_leaves_depth_thm_proof
%%%}}}

Feche o que faltou para fechar na demonstração de \ref[BinTree_leaves_depth_thm].

%%}}}

%%{{{ x: BinTree_subtrees_def 
\exercise subtrees.
%%%{{{ meta 
\label BinTree_subtrees_def
%%%}}}

Defina a $\subtrees : \TreeA \alpha \to \ListP {\TreeA \alpha}$
que retorna uma lista com todas as subárvores da sua entrada.

%%}}}

%%{{{ x: BinTree_flatten_def 
\exercise flatten.
%%%{{{ meta 
\label BinTree_flatten_def
%%%}}}

Defina a $\flatten : \TreeA \alpha \to \ListP {\TreeA \alpha}$
que retorna o \dterm{achatamento} da sua entrada:
uma lista com todos os valores das folhas, na ordem que aparecem
projetando a árvore a um piso horizontal.

%%}}}

%%{{{ x: BinTree_search_fetch 
\exercise search, fetch.
%%%{{{ meta 
\label BinTree_search_fetch
%%%}}}

Queremos definir funções
\mathcols 2
\search &\is \alpha \to \TreeA \alpha \to \ListP {\Path} &
\fetch  &\is \Path  \to \TreeA \alpha \to \MaybeA \alpha
\endmathcols
para árvores.
No caso de listas, a busca da $\search$ retorna uma lista de Nats,
já que cada tal Nat visto como índice é a informação que corresponde numa posição numa lista.
Numa árvore não faz sentido perguntar \wq{quem está na posição $4$?}.
Ou seja, o $\Nat$ não serve como tipo para descrever uma posição.
Cada posição é descrita por um caminho, ou seja, uma lista de direções (esquerda--direita).
Usamos o tipo $\Path$ de caminhos então, que é definido apenas como um sinônimo
$$
\Path \defeq \ListA \Dir
\qqtext{onde}
\dataed { \Dir \\
\cons L : \Dir \\
\cons R : \Dir \\ }
$$
Agora defina as $\search$ e $\fetch$.

\solution
\DefVar ds
\DefFpf lpaths
\DefFpf rpaths
Definimos a $\search$ pelas
\fundef
\search : \alpha \to \TreeA \alpha \to \ListP {\Path} \\
\searchAP w {\TipA x}     &=  \IF w = x \THEN \list\lnil \ELSE \lnil \FI \\
\searchAP w {\ForkAA l r} &=
    \LET (\lpaths,\rpaths) = (\searchAA w l, \searchAA w r)
     \IN \fmapPA {\cons L \lcons} \lpaths \concat \fmapPA {\cons R \lcons} \rpaths
     \TEL
\endfundef
e a $\fetch$ assim:
\fundef
\fetch : \Path \to \TreeA \alpha \to \MaybeA \alpha \\
\fetch &\paren{\cons L \lcons \ds}  &\paren{\ForkAA l \phole} &= \fetchAA \ds \ell \\
\fetch &\paren{\cons R \lcons \ds}  &\paren{\ForkAA \phole r} &= \fetchAA \ds r \\
\fetch &\lnil   &\paren{\TipA x}    &= \JustA x \\
\fetch &\phole  &\phole             &= \Nothing
\endfundef

%%}}}

%%{{{ x: BinTree_subtree_def 
\exercise subtree.
%%%{{{ meta 
\label BinTree_subtree_def
%%%}}}

Defina a $\subtree$ que, dado um caminho e uma árvore retorna
a subárvore que começa a parir do ponto descrito pelo caminho.
Faz parte deste exercício pensar num tipo legal para tal função.

\hint
$\subtree : \BinTreeA \alpha \to \Path \to \MaybeP {\BinTreeA \alpha}$.

%%}}}

%%{{{ x: BinTree_functor 
\exercise functor.
%%%{{{ meta 
\label BinTree_functor
%%%}}}

O $\BinTree : \Type \to \Type$ pode ser um functor?
Se sim, defina o que precisa ser definido e demonstre o que precisa ser demonstrado.
Senão, por que não?

\hint
Pode sim.  Basta definir uma $\fmap$ que atende a \ref[functor_spec_recind]
(demonstrar as duas leis de functor).

\hint
Defina a
\fundef
\fmap : (\alpha \to \beta) \to \TreeA \alpha \to \TreeA \beta \\
\fmapAP f {\TipA x}        &= \TipP {\fA f x} \\
\fmapAP f {\ForkAA \ell r} &= \ForkPP {\fmapAA f \ell} {\fmapAA f r} \\
\endfundef
e demonstre por indução as duas leis:
\mathcol
\fmapA \fid        &= \fid \\
\fmapA {(f \of g)} &= \fmapA f \of \fmapA g.
\endmathcol
Note que, traduzindo essas igualdades, ambas são proposições da forma
$$
\lforall {t \is \TreeA \alpha} {\dots}.
$$

%%}}}

%%{{{ x: LBinTree 
\exercise LBinTree.
%%%{{{ meta 
\label LBinTree
%%%}}}

Defina o $\LBinTree$, capaz de representar árvores binárias com rótulos,
ou seja, que carregam informação tanto nos seus forks, quanto nos seus tips.
Observe que tais informações, em geral, podem ser de tipos diferentes.

%%}}}

%%{{{ x: LBinTree_flatten_def 
\exercise flatten.
%%%{{{ meta 
\label LBinTree_flatten_def
%%%}}}

Adapte a $\flatten$ para funcionar em árvores de tipo $\LBinTreeAA \alpha \alpha$,
projetando as informações tanto dos forks quanto dos tips na mesma lista.
O que faria se quisesse adaptá-la para árvores de tipo $\LBinTreeAA \alpha \beta$ mesmo?

%%}}}

%%{{{ x: GenTree 
\exercise GenTree.
%%%{{{ meta 
\label GenTree
%%%}}}

Defina o $\GenTree$, capaz de representar árvores gerais, que carregam informação nos seus nós
e cada nó pode ter $0$ ou mais filhos (suas folhas são seus nós sem filhos).

%%}}}

\endsection
%%}}}

%%{{{ Sorting 
\section Ordenando.
%%%{{{ meta 
\label Sorting
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ A_touch_of_complexity 
\section Um toque de complexidade.
%%%{{{ meta 
\label A_touch_of_complexity
%%%}}}

%%{{{ intro 
\secintro
Nosso foco tem sido definir funções corretamente e demonstrar suas propriedades,
incluindo a corretude dos nossos programas.
Sem aprofundar nos terrenos da complexidade computational, quero aproveitar o momento
para falar de eficiência.
%%}}}

%%{{{ length_complexity 
\note Length.
%%%{{{ meta 
\label length_complexity
%%%}}}

Lembre a definição da $\length$ (\reftag[length_fundef]):
\fundef
\length : \ListA \alpha \to \Nat \\
\lengthA \lnil        &= \Ze \\
\lengthP {n\lcons\ns} &= \SuP {\lengthA {\ns}}.
\endfundef
Quantos passos precisamos para calcular o valor da $\lengthA {\list{1,2,3,4}}$
ficando fieis na sua definição?
Calculamos:
\poemcompute
\lengthA {\list{1,2,3,4}} \\
  = \SuP {\lengthA {\list{1,2,3}}}
    \by {\funref[\length.2]} \\
  = \SuP {\SuP {\lengthA {\list{1,2}}}}
    \by {\funref[\length.2]} \\
  = \SuP {\SuP {\SuP {\lengthA {\list{1}}}}}
    \by {\funref[\length.2]} \\
  = \SuP {\SuP {\SuP {\SuP {\lengthA \lnil}}}}
    \by {\funref[\length.2]} \\
  = \SuP {\SuP {\SuP {\SuA \Ze}}}.
    \by {\funref[\length.1]}
\endpoemcompute
Precisou $5$ passos: $4$ usos de \funref[\length.2] e $1$ uso de \funref[\length.1].
É fácil perceber a maneira certa de generalizar isso para contar os passos de cálculo
da $\lengthA \ell$, onde $\ell$ é uma lista arbitrária:
vamos precisar $\size{\ell} + 1$ passos, onde $\size{\ell}$ denota o tamanho da lista $\ell$.

%%}}}

%%{{{ x: concat_complexity 
\exercise Concatenação.
%%%{{{ meta 
\label concat_complexity
%%%}}}

Lembre a definição (\reftag[concat_fundef]) da $(\concat)$:
\fundef
(\concat) : \ListA \alpha \to \ListA \alpha \to \ListA \alpha \\
\lnil        \concat \ys &= \ys    \\
(x\lcons\xs) \concat \ys &= x \lcons (\xs \concat \ys).
\endfundef
Quantos passos precisamos para calcular o valor da $\xs \concat \ys$?
Tua resposta deve depender dos tamanhos das listas $\xs$ e $\ys$.

%%}}}

%%{{{ reverse_complexity 
\note Complexidade de Reverse.
%%%{{{ meta 
\label reverse_complexity
%%%}}}

Lembre a definição da $\reverse$.
Quantos passos precisamos para calcular seu valor, ficando fieis na sua definição?
Calculamos:
\poemcompute
\reverseS \list{1,2,3,4,5} \\
  = \reverseS \list{1,2,3,4} \concat \list{5}
    \by {\funref[\reverse.2]} \\
  = (\reverseS \list{1,2,3} \concat \list{5}) \concat \list{4}
    \by {\funref[\reverse.2]} \\
  = ((\reverseS \list{1,2} \concat \list{5}) \concat \list{4}) \concat \list{3}
    \by {\funref[\reverse.2]} \\
  = (((\reverseS \list{1} \concat \list{5}) \concat \list{4}) \concat \list{3}) \concat \list{2}
    \by {\funref[\reverse.2]} \\
  = ((((\reverseS \lnil \concat \list{5}) \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {\funref[\reverse.2]} \\
  = ((((\lnil \concat \list{5}) \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {\funref[\reverse.1]} \\
  \dotseq (((\list{5} \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {\funref[(\concat).2]; \funref[(\concat).1]} \\
  \dotseq ((\list{5,4} \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {\funref[(\concat).2]; \funref[(\concat).1]} \\
  \dotseq (\list{5,4,3} \concat \list{2}) \concat \list{1}
    \by {\funref[(\concat).2]; \funref[(\concat).1]} \\
  \dotseq \list{5,4,3,2} \concat \list{1}
    \by {\funref[(\concat).2]; \funref[(\concat).1]} \\
  \dotseq \list{5,4,3,2,1}.
    \by {\funref[(\concat).2]; \funref[(\concat).1]}
\endpoemcompute
Vamos separar esse cálculo em duas partes.
Na primeira (onde aparecem só $(=)$) cada linha corresponde em exatamente um passo,
em qual aplicamos a definição de $\reverse$ para efetuar uma substituição.
Na segunda (onde aparecem só $(\dotseq)$) cada linha corresponde numa seqüência de passos,
em quais aplicamos repetidamente a $(\concat).2$ até esvasiar a lista à esquerda
para finalmente aplicar a $(\concat).1$.
Queremos contar a quantidade de passos que todo esse cálculo precisou até terminar.
A primeira parte é fácil: de fato, cada $(=)$ é 1 passo, e tem $6$ em total;
então vou escrever
\poemcompute
\reverseS \list{1,2,3,4,5} \\
  \eqtag 6 ((((\lnil \concat \list{5}) \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}.
    \by {$(4\times)$ \funref[\reverse.2]; $(1\times)$ \funref[\reverse.1]}
\endpoemcompute
Agora precisamos contar quantas $(=)$'s estão escondidas atrás de cada uma das $(\dotseq)$'s.
Lembrando que o cálculo de $\ell_1 \concat \ell_2$ precisa de $\size{\ell_1}+1$ passos,
chegamos na conta seguinte:
\poemcompute
\reverseS \list{1,2,3,4,5} \\
  \eqtag 6 ((((\lnil \concat \list{5}) \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {$(5\times)$ \funref[\reverse.2]; $(1\times)$ \funref[\reverse.1]} \\
  \eqtag 1 (((\list{5} \concat \list{4}) \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {$(0\times)$ \funref[(\concat).2]; $(1\times)$ \funref[(\concat).1]} \\
  \eqtag 2 ((\list{5,4} \concat \list{3}) \concat \list{2}) \concat \list{1}
    \by {$(1\times)$ \funref[(\concat).2]; $(1\times)$ \funref[(\concat).1]} \\
  \eqtag 3 (\list{5,4,3} \concat \list{2}) \concat \list{1}
    \by {$(2\times)$ \funref[(\concat).2]; $(1\times)$ \funref[(\concat).1]} \\
  \eqtag 4 \list{5,4,3,2} \concat \list{1}
    \by {$(3\times)$ \funref[(\concat).2]; $(1\times)$ \funref[(\concat).1]} \\
  \eqtag 5 \list{5,4,3,2,1}.
    \by {$(4\times)$ \funref[(\concat).2]; $(1\times)$ \funref[(\concat).1]}
\endpoemcompute
Assim, a primeira parte precisou $6$ passos e a segunda $1 + \dotsb + 5 = 15$ passos,
isto é, $21$ passos para uma lista de tamanho $5$.

%%}}}

\endsection
%%}}}

%%{{{ Efficiency_via_induction 
\section Eficiênia via indução.
%%%{{{ meta 
\label Efficiency_via_induction
%%%}}}

%%{{{ intro 
\secintro
Vamos ver como podemos usar a teoria que temos elaborado aqui para ganhar
versões bem mais eficientes dumas funções com quais nos sofreríamos se iríamos
trabalhar com suas versões originais.
%%}}}

%%{{{ Don't think too hard 
\note Melhor não pensar tanto.
%%%{{{ meta 
%%%}}}

Descubrimos (\ref[reverse_complexity]) que nossa $\reverse$ tem complexidade de tempo $O(n^2)$:
para reverter uma lista de tamanho $n$ ela precisa $\frac 1 2 n^2 + \frac 3 2 n + 1$ passos.
Uma alternativa sensata agora seria pensar criativamente para achar uma nova definição
de $\reverse$, mais eficiente.  Mas com o que temos estudado até agora, dá para evitar
esse processo, limitando a inspiração necessária.  Vamos ver como aproveitar nossa
experiência com indução e usá-la como guia para chegar quase gratuitamente numa
nova definição de $\reverse$ que vai acabar sendo \emph{muito} mais eficiente!

%%}}}

%%{{{ What went wrong?  What would be nice? 
\note O que deu errado?  O que seria legal?.
%%%{{{ meta 
%%%}}}

O problema visto na \ref[reverse_complexity] é que temos dois trabalhos acontecendo
e gastando tempo: reverter e concatenar.
Que tal imaginar uma função $\revcat$ que retornaria seu primeiro argumento revertido
e já concatenado com seu segundo?  Tipo assim:
\math
\revcat : \ListA \alpha \to \ListA \alpha \to \ListA \alpha \\
\lforall {\xs, \ys : \ListA \alpha}
         {\revcatAA \xs \ys = \reverseA \xs \concat \ys}.
\endmath
Note que isso não é uma definição, mas sim uma especificação que tal desejada $\revcat$
precisa atender.
Vamos fingir por um momento que alguém já definiu uma tal função, e que ela é rápida.
Observe que tendo uma tal $\revcat$, podemos definir nossa $\reverse$ para ser simplesmente
uma aplicação parcial da $\revcat$:
$$
\reverseA \xs \defeq \revcatAA \xs \lnil.
$$
Então basta definir uma eficiente $\revcat$.  Bora.

%%}}}

%%{{{ revcat_via_induction 
\note Revcat via indução.
%%%{{{ meta 
\label revcat_via_induction
%%%}}}

Por que não usar simplesmente sua especificação como definição mesmo?
Se tentar definir
$$
\revcatAA \xs \ys = \reverseA \xs \concat \ys
$$
onde $\reverse$ e $(\concat)$ são nossas funções já definidas, a $\revcat$
vai ser lenta, mas isso nem é o maior problema: queremos usar a $\revcat$
para definir a $\reverse$ na maneira escrita acima, e se tentar usar
essas duas definições mesmo, vamos ter uma tijolada.
Mesmo que não serve como definição, a especificação precisa ser satisfeita
por qualquer implementação de $\revcat$, e logo temos sim as igualdades
\mathcol
\revcatAA \lnil \ys        &= \reverseA \lnil \concat \ys \\
\revcatPA {x\lcons\xs} \ys &= \reverseP {x\lcons\xs} \concat \ys.
\intertext {Basta substituir cada uma delas por algo igual que não envolve
nem $\reverse$ nem $(\concat)$:}
\revcatAA \lnil \ys        &\defeq {\alert?} \quad (= \reverseA \lnil \concat \ys) \\
\revcatPA {x\lcons\xs} \ys &\defeq {\alert?} \quad (= \reverseP {x\lcons\xs} \concat \ys).
\endmathcol
A parte criativa que queremos evitar é pensar nesses {\alert ?} aí.
Usaremos indução como guia para chegar em tal definição, sem pecisar pensar muito.
Começa fingindo que estamos tentando demonstrar por indução que, de fato,
$$
\pforall {\xs : \ListA \alpha}
\lforall {\ys : \ListA \alpha}
         {\revcatAA \xs \ys = \reverseA \xs \concat \ys}.
$$
Seja $\xs : \ListA \alpha$ então.  Por indução no $\xs$.
\crproofpart{Caso $\lnil$.}
Seja $\ys : \ListA \alpha$.
$$
\revcatAA \lnil \ys \askeq \reverseA \lnil \concat \ys.
$$
Não tendo como trabalhar no lado esquerdo, trabalhamos no lado direito:
\poemcompute
\reverseA \lnil \concat \ys \\
  = \lnil \concat \ys \by {\funref[\reverse.1]} \\
  = \ys               \by {\funref[(\concat).1]}
\endpoemcompute
E assim a \dq{base da indução} nos fornece a primeira das duas linhas que precisamos
para definir a desejada $\revcat$:
$$
\revcatAA \lnil \ys \defeq \ys.
$$
Agora falta o \dq{passo indutivo} nos fornecer a segunda linha.
\crproofpart{Caso $(x\lcons\xs)$.}
Nossa \dq{hipótese indutiva} aqui é que a lista $\xs$ é \emph{legalzona}, ou seja:
$$
\lforall {\ell : \ListA \alpha}
         {\revcatAA \xs \ell = \reverseA \xs \concat \ell}.
$$
Vamos brincar de demonstradores de
$$
\lforall {\ys : \ListA \alpha}
         {\revcatPA {x\lcons\xs} \ys = \reverseP {x\lcons\xs} \concat \ys}.
$$
Seja $\ys : \ListA \alpha$.
Calculamos novamente no lado direito:
\poemcompute
\revcatPA {x\lcons\xs} \ys \\
  \bangeq \reverseP {x\lcons\xs} \concat \ys             \by {especificação da $\revcat$} \\
  = (\reverseA \xs \concat \list{x}) \concat \ys         \by {\funref[\reverse.2]} \\
  = \reverseA \xs \concat (\list{x} \concat \ys)         \by {$(\concat)$-assoc.} \\
  = \reverseA \xs \concat (x \lcons (\lnil \concat \ys)) \by {\funref[(\concat).2]} \\
  = \reverseA \xs \concat (x \lcons \ys)                 \by {\funref[(\concat).1]} \\
  = \revcatAP \xs {x\lcons\ys}                           \by {h.i.~com $\ell \asseq x \lcons \ys$}
\endpoemcompute
finalmente chegando numa expressão que não envolve nem $\reverse$ nem $(\concat)$,
que usamos para completar nossa definição de $\revcat$, cuja versão final fica assim:

%%}}}

%%{{{ df: revcat_reverse_fundef 
\definition revcat.
%%%{{{ meta 
\label revcat_reverse_fundef
\defines
    * \revcat {~{\ell_1}} {~{\ell_2}}  -- a reversa da $\ell_1$, concatenada na $\ell_2$
    ;;
%%%}}}

\fundefs 2
\fundefed {
\reverse : \ListA \alpha \to \ListA \alpha \\
\reverseA \xs &= \revcatAA \xs \lnil \\
\vphantom {\revcatPA {x\lcons\xs} \ys} \\
}
& \fundefed {
\revcat : \ListA \alpha \to \ListA \alpha \to \ListA \alpha \\
\revcatAA \lnil        \ys &= \ys \\
\revcatPA {x\lcons\xs} \ys &= \revcatAP \xs {x\lcons\ys}.
}
\endfundefs

%%}}}

%%{{{ reverse_new_complexity 
\note Reverse: new and improved.
%%%{{{ meta 
\label reverse_new_complexity
%%%}}}

Quantos passos precisamos para calcular o valor da $\reverse {\list{1,2,3,4,5}}$ com
nossa nova \ref[revcat_reverse_fundef]?
Calculamos:
\poemcompute
\reverseS \list{1,2,3,4,5} \\
  = \revcatAA {\list{1,2,3,4,5}}  {\lnil} \by {\funref[\reverse.1]} \\
  = \revcatAA {\list{2,3,4,5}} {\list{1}} \by {\funref[\revcat.2]} \\
  = \revcatAA {\list{3,4,5}} {\list{2,1}} \by {\funref[\revcat.2]} \\
  = \revcatAA {\list{4,5}} {\list{3,2,1}} \by {\funref[\revcat.2]} \\
  = \revcatAA {\list{5}} {\list{4,3,2,1}} \by {\funref[\revcat.2]} \\
  = \revcatAA {\lnil}  {\list{5,4,3,2,1}} \by {\funref[\revcat.2]} \\
  = \list{5,4,3,2,1}.                     \by {\funref[\revcat.1]}
\endpoemcompute
Precisou $7$ passos: $1$ no início para chamar a $\revcat$, $5$ chamadas da \funref[\revcat.2], e finalmente $1$ chamada da \funref[\revcat.1].
Em forma geral, sendo aplicada numa lista de tamanho $n$, vai precisar apenas $n+2$ passos.
Ou seja conseguimos uma implementação de tempo $O(n)$, em vez da velha e lenta versão que precisa $O(n^2)$.

%%}}}

\endsection
%%}}}

%%{{{ Efficiency_via_algebra 
\section Eficiênia via álgebra.
%%%{{{ meta 
\label Efficiency_via_algebra
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Folding 
\section Folding.
%%%{{{ meta 
\label Folding
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: unfold 
\problem Unfolding.
%%%{{{ meta 
\label unfold
%%%}}}

\TODO Escrever.

%%}}}

\endproblems
%%}}}

%% LEFTOVERS TO BE TIDIED UP
\TODO Leftovers to be tidied up, expanded upon, and complemented.

%%{{{ BNF_notation 
\section A notação BNF.
%%%{{{ meta 
\label BNF_notation
\defines
    * gramática!BNF
    ;;
\indexes
    * Backus--Naur form    see: BNF
    * BNF    see: gramática
    ;;
%%%}}}

%%{{{ A first try 
\note Uma primeira tentativa.
%%%{{{ meta 
\label BNF_a_first_try
\credits
    * Backus : BNF
    * Naur   : BNF
    ;;
%%%}}}

Vamos começar diretamente com um exemplo de uso da
notação~\dterm{BNF} (Backus--Naur form),
para descrever uma linguagem de expressões aritméticas:

%%}}}

%%{{{ ArEx_bnf_1 
\note ArEx (1).
%%%{{{ meta 
\label ArEx_bnf_1
%%%}}}

$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} + \bnf{ArEx})                  \tag{2}
\endalign
$$

%%}}}

%%{{{ Explanation 
\blah.
%%%{{{ meta 
%%%}}}

O que tudo isso significa?
A primeira linha, é uma regra dizendo:
uma expressão aritmética pode ser um dos
$0$, $1$, $2$, $3$, \dots.
A segunda linha é mais interessante: uma expressão aritmética pode começar
com o símbolo~\symq{(},
depois ter uma expressão aritmética,
depois o símbolo~\symq{+},
depois mais uma expressão aritmética,
e finalmente o símbolo~\symq{)}.
A idéia é que o que aparece com ângulos é algo que precisa ser substituido,
com uma das opções que aparecem no lado direito de alguma regra que começa com ele.
\eop
Começando com o $\bnf{ArEx}$ ficamos substituindo até não aparece mais nada em ângulos.
Et voilà: neste momento temos criado uma expressão aritmética.

%%}}}

%%{{{ eg: BNF_first_example 
\example.
%%%{{{ meta 
\label BNF_first_example
%%%}}}

Use as regras (1)--(2) da~\ref[ArEx_bnf_1] acima para criar
duas expressões aritmética.

\solution.
Começando usando a regra (2), temos:
$$
\align
\underline{\bnf{ArEx}}
&\leadstoby {(2)} (\bnf{ArEx} + \underline{\bnf{ArEx}})\\
&\leadstoby {(1)} (\underline{\bnf{ArEx}} + 3)\\
&\leadstoby {(2)} ((\underline{\bnf{ArEx}} + \bnf{ArEx}) + 3)\\
&\leadstoby {(1)} ((128 + \underline{\bnf{ArEx}}) + 3)\\
&\leadstoby {(1)} ((128 + 0) + 3)
\intertext{Começando usando a regra (1), temos:}
\underline{\bnf{ArEx}}
&\leadstoby {(1)} 17
\endalign
$$
Isto sendo nosso primeiro exemplo de uso de BNF,
em cada expressão que fica na parte esquerda dum \symq{$\leadsto$}
sublinhei o foco atual (o que escolhi para ser substituido nesse passo).
Em geral, não vamos fazer isso.

%%}}}

%%{{{ x: BNF_with_goal 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre como usar a~\ref[ArEx_bnf_1] para gerar a expressão aritmética
$((1 + (2 + 2)) + 3)$.

\solution
Uma solução é a seguinte:
$$
\align
\bnf{ArEx}
&\leadstoby {(2)} (\bnf{ArEx} + \bnf{ArEx})\\
&\leadstoby {(1)} (\bnf{ArEx} + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + \bnf{ArEx}) + 3)\\
&\leadstoby {(2)} ((\bnf{ArEx} + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (\bnf{ArEx} + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + \bnf{ArEx})) + 3)\\
&\leadstoby {(1)} ((1 + (2 + 2)) + 3)
\endalign
$$

%%}}}

%%{{{ beware: bnf_not_variables_bnfeq_not_eq 
\beware.
%%%{{{ meta 
\label bnf_not_variables_bnfeq_not_eq
%%%}}}

Essa coisinha aí, a \sq{$(\bnf{ArEx} + \bnf{ArEx})$} que parece no
lado direito da \ref[ArEx_bnf_1] pode dar a impressão errada que
só podemos criar expressões de aritmética onde a soma é aplicada nos
mesmos termos, por exemplo, $(1+1)$, $(5+5)$, $((1+1)+(1+1))$, etc.
\emph{Não é o caso!}
Isso deve ser óbvio já pelo~\ref[BNF_first_example].
Não pense então nos \symq{$\bnf{Bla}$} como variáveis,
nem no \symq{$\bnfeq$} como igualdade.
Numa expressão como a \sq{$y = x + x$} o termo \sq{$x$} deve denotar
o mesmo objeto em ambas as suas instâncias.

%%}}}

%%{{{ Q: problems_of_first_BNF
\question.
%%%{{{ meta 
%%%}}}

Quais são uns defeitos dessa primeira tentativa?
O que podemos fazer para a melhorar?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Umas deficiências são:
\elist:
\li: A linguagem gerada por essa gramática não é suficiente para representar expressões que envolvem outras operações, como $-$, $(\ntimes)$, $\div$, etc.
\li: A regra (1) tem uma infinitade de casos (graças aos \symq{$\dotsb$}).
\li: As regras e os nomes escolhidos não refletem bem nossa idéia.
\endelist

%%}}}

%%{{{ x: solve_first_problem_of_ArEx 
\exercise.
%%%{{{ meta 
\label solve_first_problem_of_ArEx
%%%}}}

Apenas alterando a segunda regra da~\ref[ArEx_bnf_1], resolva a primeira deficiência.

\hint
Falta só adicionar 3 mais casos na segunda regra,
imitando para os outros operadores o caso do $(+)$.

\solution
Temos:
$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx}
&\bnfeq (\bnf{ArEx} + \bnf{ArEx})\tag{2}\\
&\bnfOR (\bnf{ArEx} - \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \ntimes \bnf{ArEx})\\
&\bnfOR (\bnf{ArEx} \div \bnf{ArEx})
\endalign
$$

%%}}}

%%{{{ A second try 
\note Uma segunda tentativa.
%%%{{{ meta 
%%%}}}

A solução que encontramos no~\ref[solve_first_problem_of_ArEx]
não é a coisa mais elegante do mundo.
Tem muita repetição que podemos evitar, definindo uma nova regra em nossa gramática:

%%}}}

%%{{{ grammar: ArEx_bnf_2 
\grammar ArEx (2).
%%%{{{ meta 
\label ArEx_bnf_2
%%%}}}

$$
\align
\bnf{ArEx} &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1}\\
\bnf{ArEx} &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})\tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div\tag{3}
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bem melhor!
Mas ainda a gramática não refleta bem nossa idéia.
Podemos melhorá-la, com mais regras e com nomes melhores
que deixam mais claras nossas intenções:

%%}}}

%%{{{ grammar: ArEx_bnf_3 
\grammar ArEx (3).
%%%{{{ meta 
\label ArEx_bnf_3
%%%}}}

$$
\align
\bnf{ArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx}                 \tag{0}\\
\bnf{Num}   &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb  \tag{1}\\
\bnf{OpEx}  &\bnfeq (\bnf{ArEx} \bnf{BinOp} \bnf{ArEx})         \tag{2}\\
\bnf{BinOp} &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div       \tag{3}
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Falta achar um jeito para remover esses \sq{$\dotsb$} ainda,
mas vamos deixar isso para depois (\ref[remove_dots_from_ArEx_bnf]).

%%}}}

%%{{{ beware: BNF_without_angle_brackets 
\beware.
%%%{{{ meta 
\label BNF_without_angle_brackets
%%%}}}

Como conseguimos separar o que é sintaxe da linguagem que estamos
definindo a partir duma gramática da sintaxe da \emph{metalinguagem}
que usamos para descrever essa gramática?
Por exeplo, na~(2) da~\ref[ArEx_bnf_3], na sua parte
direita,temos uma expressão cujo primeiro caracter é o \symq{$($}
e depois\dots continua com o caracter \symq{$\langle$}?
Claro que não, e parece que necessitamos esses ângulos na nossa
metalinguagem para tirar essa ambigüidade.
Mas muitas vezes não existe esse perigo, pois podemos inferir
se algo é para ser substituido ou se é sintaxe da linguagem-objeto
mesmo: \emph{caso que aparece no lado esquerdo de alguma das
regras da nossa gramática, é para ser substituido}.
Aqui um exemplo duma gramática escrita nesse jeito que define
uma linguagem importantíssima que vamos amar bastante,
logo no~\ref[Recursion_induction]:

%%}}}

%%{{{ Nat_bnf 
\grammar N, de \wq{Não vou dizer}.
%%%{{{ meta 
\label Nat_bnf
%%%}}}

$$
N \bnfeq \mathrm O \bnfor \mathrm S N
$$

%%}}}

%%{{{ x: generate_some_nats_from_bnf 
\exercise.
%%%{{{ meta 
\label generate_some_nats_from_bnf
%%%}}}

Quais são umas das palavras que podes gerar com a~\ref[Nat_bnf]?
Podes pensar de algum uso para essa linguagem?

\solution
\ref[Recursion_induction].

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: remove_dots_from_ArEx_bnf 
\problem.
%%%{{{ meta 
\label remove_dots_from_ArEx_bnf
%%%}}}

Usando BNF, defina uma gramática para a linguagem de todos os
numerais que representam os naturais no sistema decimal.
A embuta na gramática das expressões aritméticas~\ref[ArEx_bnf_3]
chegando assim numa gramática que gera a mesma linguagem, mas sem usar
``$\dotsb$``.

%%}}}

%%{{{ prob: ArEx_fact_bnf 
\problem.
%%%{{{ meta 
\label ArEx_with_factorial
%%%}}}

Aumente tua gramática do~\ref[remove_dots_from_ArEx_bnf] para
gerar expressões aritméticas que usam o operador unitário (e postfixo)
do factorial, que denotamos com $!$, escrevendo por exemplo
$8!$ para o factorial de $8$.
Note que não usamos parenteses para aplicar o factorial:
$$
((2 + 3!)! \ntimes 0!!)
$$

%%}}}

%%{{{ prob: ArEx_fact_vars_bnf 
\problem.
%%%{{{ meta 
\label ArEx_fact_vars_bnf
%%%}}}

Aumenta tua gramática do~\ref[ArEx_with_factorial] para
gerar expressões aritméticas que usam as variáveis
$$
x,y,z,
x',y',z',
x'',y'',z'',
x''',y''',z''',
\dotsc
$$

%%}}}

%%{{{ prob: polish_notation 
\problem Notação polonesa.
%%%{{{ meta 
\label polish_notation
\indexes
    * Polonesa!notação    seealso: Łukasiewicz
    ;;
\defines
    * Polonesa!notação
    ;;
\credits
    * Lukasiewicz : notação
    ;;
%%%}}}

Demonstre que não podemos simplesmente apagar as parenteses
da nossa gramática de $\bnf{ArEx}$ sem perder uma propriedade
importantíssima da nossa linguagem (qual?).
Experimente com a gramática
\mathcol
\bnf{PolArEx}  &\bnfeq \bnf{Num} \bnfor \bnf{OpEx}                \tag{0} \\
\bnf{Num}      &\bnfeq 0 \bnfor 1 \bnfor 2 \bnfor 3 \bnfor \dotsb \tag{1} \\
\bnf{OpEx}     &\bnfeq \bnf{BinOp} \bnf{PolArEx} \bnf{PolArEx}    \tag{2} \\
\bnf{BinOp}    &\bnfeq + \bnfor - \bnfor \ntimes \bnfor \div      \tag{3}
\endmathcol
Escreva uns dos seus termos.
Supondo que cada símbolo de $\bnf{Num}$ é apenas um símbolo
(por exemplo o \symq{$15$} é um símbolo atômico e não algo composto
dos \symq{$1$} e \symq{$5$}),
observe que com essa notação (chamada \dterm{notação Polonesa} ou
\dterm{notação Łukasiewicz}) não precisamos de parenteses!
Como escreverias nessa linguagem as expressões correspondentes às:
$$
1 + 2;
\qquad
3\ntimes(2 + 4) + 6;
\qquad
2 \ntimes 3 + 3 \ntimes (7 + 8\ntimes 2)\,?
$$

%%}}}

%%{{{ prob: lang_Polish 
\problem.
%%%{{{ meta 
\label lang_Polish
%%%}}}

Defina linguagens: uma de logica proposicional e uma de
lógica de predicados que usam notação Polonesa
(\ref[polish_notation]).
Faça um bom trabalho, definindo açúcares sintácticos
e abreviações.
E sobre precedências e associatividades sintácticas?

%%}}}

\endproblems
%%}}}

%%{{{ A language of binary numerals 
\section Uma linguagem de numerais binários.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Exp_types 
\section Tipos de expressões.
%%%{{{ meta 
\label Exp_types
%%%}}}

%%{{{ eg: bincon_count 
\example.
%%%{{{ meta 
\label bincon_count
%%%}}}

Defina uma função $f : \zolang \to \nats$ que calcula o número
de conectivos binários que aparecem na sua entrada.
Use-lá para calcular os conectivos binários da expressão
$$
\lnot(P_4 \limplies (P_9 \land \lnot P_9)).
$$

\solution.
Seguindo a definição de $\zolang$, cada um dos seus elementos
é formado por uma de certas regras.  Basta escrever então como
calcular o número desejado para cada um desses casos:
$$
\alignat2
f(p)                &= 0,          &\quad&\text{($p\in \mathrm{Pvar}$)} \tag{BC$_{P}$}\\
f(\lnot A)          &= f(A),            &&\text{($A\in \zolang$)}       \tag{BC$_{\lnot}$}\\
f((A \limplies B))  &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\limplies}$}\\
f((A \land B))      &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\land}$}\\
f((A \lor B))       &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$)}     \tag{BC$_{\lor}$}\\
\intertext{Preguiçosamente, podemos condensar as três últimas equações em úma só, assim:}
f((A \heartop B)) &= f(A) + 1 + f(B), &&\text{($A,B\in \zolang$, e $\heartop \in \set{\limplies,\land,\lor}$)}
\endalignat
$$
Aplicando nossa função na fórmula dada calculamos:
\compute
f( \lnot(P_4 \limplies (P_9 \land \lnot P_9)) )
&= f( (P_4 \limplies (P_9 \land \lnot P_9)) )   \by {por BC$_{\lnot}$} \\
&= f( P_4 ) + 1 + f( (P_9 \land \lnot P_9) )    \by {por BC$_{\limplies}$} \\
&= 0 + 1 + f( (P_9 \land \lnot P_9) )           \by {por BC$_{P}$} \\
&= 0 + 1 + ( f( P_9 ) + 1 + f ( \lnot P_9 ) )   \by {por BC$_{\land}$} \\
&= 0 + 1 + ( 0 + 1 + f ( \lnot P_9 ) )          \by {por BC$_{P}$} \\
&= 0 + 1 + ( 0 + 1 + f ( P_9 ) )                \by {por BC$_{\lnot}$} \\
&= 0 + 1 + ( 0 + 1 + 0 )                        \by {por BC$_{P}$} \\
&= 2
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ A little programming language 
\section Uma pequena linguagem de programação.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Induction_on_such_and_such 
\section Indução em tal coisa.
%%%{{{ meta 
\label Induction_on_such_and_such
%%%}}}

%%{{{ induction_on_such_and_such 
\note Indução em tal coisa.
%%%{{{ meta 
\label induction_on_such_and_such
%%%}}}

Até agora usamos indução para demonstrar proposições da forma
$$
\text{para todo $x \is \alpha$, $\phi(x)$}
$$
onde $\alpha$ sempre é um tipo que definimos indutivamente
ou da forma
$$
\text{para todo $x \in S$, $\phi(x)$}
$$
onde $S$ é um conjunto como o dos inteiros positivos, sobre qual
temos demonstrado um teorema de induç
ou um 
Também já encontramos como \dq{hackear a regra} escolhendo um apropriado
$\phi(\dhole)$, conseguindo assim demonstrar proposições que variaram
um pouco do padrão original.
Bora hackear pouco mais!

%%}}}

%%{{{ on the size of sets 
\note Todo conjunto finito.
%%%{{{ meta 
%%%}}}

Vamos supor que estamos tentando demostrar algo da forma
$$
\text{para todo conjunto $S$, $\phi(S)$}.
$$
Podemos usar indução?  Parece que estamos bem longe do padrão permitido,
essa mudança de \wq{todo inteiro positivo} para \wq{todo conjunto} não vai ser tão
fácil de hackear como quando mudamos para conseguir um \wq{todo natural maior que $\ell$}.
E se for realmente \wq{todo conjunto} podemos esquecer a indução
que aprendemos até agora; mas se for \wq{todo conjunto \emph{finito}}?
Tipo assim:
$$
\text{para todo conjunto finito $S$, $\phi(S)$}.
$$

%%}}}

%%{{{ Q: how can we use induction now? 
\question.
%%%{{{ meta 
%%%}}}

Agora podemos usar indução sim, mas em que?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Indução \emph{no tamanho de $S$}.

%%}}}

%%{{{ x: why_standard_induction_on_size_does_not_prove_WOP 
\exercise.
%%%{{{ meta 
\label why_standard_induction_on_size_does_not_prove_WOP
%%%}}}

Podemos demonstrar o princípio da boa ordem usando
indução no tamanho do subconjunto $A$?

\solution
Não, isso nos levaria dum resultado apenas
para os subconjuntos finítos de $A$.
O princípio da boa ordem aplica para qualquer
subconjunto habitado de $\nats$, até para os infinitos.

%%}}}

%%{{{ df: cardinality_of_finite_set 
\definition Cardinalidade.
%%%{{{ meta 
\label cardinality_of_finite_set
%%%}}}

Definimos a cardinalidade $\card A$ dum conjunto finito e habitado $A$ pelas:
\mathcol
\card A = 1      & \iff \text{$A$ é um singleton} \\
\card A = n + 1  & \iff
\pexists {a \in A}
\lexists {A' \subset A}
         { a \nin A'
           \mland \card {A'} = n
           \mland \mubrace {\lforall {x \in A} {\text{$x = a$ ou $x \in A'$}}}
                               {A \subset \set{a} \union A'}
         }
\endmathcol
Se existe $n \in \nats$ tal que $\card A = n$ dizemos que $A$ é \dterm{finito}.

%%}}}

%%{{{ lemma: finite_numbersets_have_min 
\lemma.
%%%{{{ meta 
\label finite_numbersets_have_min
%%%}}}

Qualquer conjunto finito de números $A$ habitado, possui mínimo.

\sketch.
Por indução no tamanho do conjunto.
A base é trivial: um conjunto com apenas um membro $a$, tem o $a$ como mínimo.
Seja $k \geq 1$ tal que
$$
\text{todos os conjuntos de tamanho $k$ possuem mínimo.} \tag{HI}
$$
Considere um conjunto $A$ de tamanho $k+1$, ou seja,
$$
A = \set {a_1, \dotsc, a_k, a_{k+1}}.
$$
Pela hipótese indutiva sabemos que $\set{a_1,\dotsc,a_k}$ possui mínimo $m$.
Agora o menor membro do $A$ é o menor dos $m$ e $a_{k+1}$.

\proof.
Por indução no tamanho do conjunto $A$ demonstramos que
$$
\pforall {x \geq 1}
\lforall {\text{$A$ conjunto}}
         {\card A = x \implies \text{$A$ possui mínimo}}.
$$
Observe que agora nossa indução virou \dq{indução original}.
\crproofpart {Base:}
demonstrar que \emph{se $\card A = 1$ então $A$ possui mínimo}.
Suponha $\card A = 1$.
Logo temos que $A$ é um singleton e pronto: seu único membro é seu mínimo.
\proofpart {Passo Indutivo.}
Seja $k \geq 1$ tal que para qualquer conjunto $H$
$$
         {\card H = k \implies \text{$H$ possui mínimo}}.
         \tag{H.I.}
$$
Preciso demonstrar que para qualquer conjunto $A$
$$
         {\card A = k + 1 \implies \text{$A$ possui mínimo}}.
$$
Seja $A$ conjunto de inteiros tal que $\card A = k + 1$.
Basta verificar que $A$ possui mínimo.
Como $\card A = k + 1$, temos:
$$
\pexists {a \in A}
\lexists {A' \subset A}
         { a \nin A'
           \mland \card {A'} = k
           \mland \lforall {x \in A} {\text{$x = a$ ou $x \in A'$}}
         }
$$
e logo sejam $m \in A$, $A' \subset A$, tais que
$$
\tubrace {m \nin A'} {(1a)}
\mland \tubrace {\card {A'} = k} {(1b)}
\mland \tubrace {\lforall {x \in A} {\text{$x = m$ ou $x \in A'$}}} {(1c)}.
\tag {1}
$$
Usamos a (HI) agora com $H \asseq A'$, e já que $\card {A'} = k$ (pela (1b)) temos que
$A'$ possui mínimo.
Seja $m' = \min A'$ então.
Seja $m_*$ o menor dos $m,m'$.
Afirmo que $\min A = m_*$.
Basta verificar, ou seja, mostrar que $m_*$ é menor de qualquer membro de $A$.
Seja $x \in A$ então.
Novamente pela escolha dos $m,A'$ temos que $x = m$ ou $x \in A'$.
Tem cada subcaso vou demonstrar que $m_* \leq x$.
\proofcase {Subcaso $x = m$.}
Imediato pois pela escolha de $m_* \leq m = x$.
\proofcase {Subcaso $x \in A'$.}
Pela escolha dos $m_*$ e $m'$ respectivamente temos
$m_* \leq m' \leq x$.

%%}}}

%%{{{ x: finite_numbersets_have_min_quantifier_check 
\exercise.
%%%{{{ meta 
\label finite_numbersets_have_min_quantifier_check
%%%}}}

Faria sentido trocar o \sq{$\pexists {a \in A}$} por \sq{$\pforall {a \in A}$}
na fim do \ref[finite_numbersets_have_min]?

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: concat_iterations_equivalent 
\problem.
%%%{{{ meta 
\label concat_iterations_equivalent
%%%}}}

Denotamos a operação de concatenação de strings por $(\concat)$.
Dois alunos definiram com as maneiras seguintes a ``exponenciação'':
$$
\xxalignat4
\text{(L1)} && \lexp s 0 &= \epsilon                 & \rexp s 0 &= \epsilon                   && \text{(R1)}\\
\text{(L2)} && \lexp s n &= \lexp s {n-1} \concat s  & \rexp s n &= s \concat \rexp s {n-1} && \text{(R2)}
\endxxalignat
$$
onde $\epsilon$ é o string vazio ``\,'', que é uma \dterm{identidade}
da concatenação, ou seja, que satisfaz:
$$
\lforall s {\epsilon \concat s = s = s \concat \epsilon}. \tag{E}
$$
Demonstre que as duas definições são equivalentes, ou seja,
que para todo string $s$ e todo $n \geq 0$, $\lexp s n = \rexp s n$.
Cuidado: a operação $\concat$ é associativa mas não comutativa:
\sq{oimundo} e \sq{mundooi} são palavras diferentes!

\hint
Tome um string arbitrário $s$, e demonstre por indução
que \emph{para todo $n\in\nats$, $\lexp s n = \rexp s n$}.

\hint
Uma base não é suficiente:
demonstre para $n \asseq 0,1$.

\hint
Para teu passo indutivo, tu terás um $k\geq 2$ tal que
$\lexp s {k-1} = \rexp s {k-1}$\fact{HI1} e
$\lexp s {k-2} = \rexp s {k-2}$\fact{HI2}.
E com essas duas hipoteses indutivas basta demonstrar
$
\lexp s k = \rexp s k.
$

\solution
Seja $s$ string.
Vamos demonstrar por indução (com duas bases) que
\emph{para todo $n\in\nats$, $\lexp s n = \rexp s n$}.
Primeiramente verificamos que para $n \asseq 0$ e $n \asseq 1$,
realmente temos $\lexp s n = \rexp s n$.
\crproofpart {Base ($n \asseq 0$).}
Calculamos:
$$
\lexp s 0 \eqlabel{L1} \epsilon \eqlabel{R1} \rexp s 0.
$$
\crproofpart {Base ($n \asseq 1$).}
Calculamos:
$$
\computed {
\lexp s 1 &= \lexp s 0 \concat s \by {def.~$\lexp s 1$} \\
             &= \epsilon     \concat s \by {def.~$\lexp s 0$} \\
             &= s                      \by {E} \\
}
\qqqquad
\computed {
\rexp s 1 &= s \concat \rexp s 0  \by {def.~$\rexp s 1$} \\
             &= s \concat \epsilon      \by {def.~$\rexp s 0$} \\
             &= s.                      \by {E} \\
}
$$
Logo $\lexp s 1 = \rexp s 1$.
\crproofpart {Passo indutivo.}
Seja $k\geq 2$ tal que
$\lexp s {k-1} = \rexp s {k-1}$\fact{HI1} e
$\lexp s {k-2} = \rexp s {k-2}$\fact{HI2}.
Vou demonstrar que
$
\lexp s k = \rexp s k.
$
Calculamos:
\compute
\lexp s k
&= \lexp s {k-1} \concat s               \by {L1} \\
&= \rexp s {k-1} \concat s               \by {HI1} \\
&= (s \concat \rexp s {k-2}) \concat s   \by {R2} \\
&= (s \concat \lexp s {k-2}) \concat s   \by {HI2} \\
&= s \concat (\lexp s {k-2}  \concat s)  \by {Assoc.} \\
&= s \concat \lexp s {k-1}               \by {L2} \\
&= s \concat \rexp s {k-1}               \by {HI1} \\
&= \rexp s k.                            \by {R2} \\
\endcompute

%%}}}

\endproblems
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Recursão e indução vamos ficar usando o tempo todo.
Mais pra frente vamos mergulhar na teoria desses
assuntos; mas sugiro paciência por enquanto,
e \emph{ganhar experiência trabalhando} com recursão e indução.

Sobre o princípio da boa ordem e indução,
dê uma olhada no~\cite[babybm: \S\S1.4--1.5].

Neste capítulo tivemos nosso primeiro contato com
\emph{programação funcional}.
Para o ansioso e animado-para-programar leitor recomendo
se jogar no \cite[birdwadlerfp].
Além disso, obviamente brincar com uma
linguagem puramente funcional é essencial; sobre
programação funcional em \tool{Haskell}: \cite[birdthinking],
\cite[huttonhaskell], \cite[birdfphaskell], \cite[lyah].
% TODO: Remove PureScript from fmcrefs?

\TODO Divulgar Lean and SML.

Vale muito a pena investir em trabalhar com uma implementação
como a \tool{Agda} ou o \tool{Coq}.  Ambos podem ser vistos tanto como uma
linguagem de programação funcional, quanto como um \emph{proof assistant}.
Dois textos excelentes para inciantes que meu leitor é muito recomendado
começar desde já estudar são os \cite[piercesf1] (que usa Coq)
e o \cite[wadlerplfa] (que usa Agda).

Para aprofundar ainda mais em recursão e indução consulte os
\cite[aczelinductive] e \cite[ynminduction],
mas sugiro fazer isso bem depois, pois podem aparecer pesados
demais neste momento.

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Enumerative_combinatorics 
\chapter Combinatória enumerativa.
%%%{{{ meta 
\label Enumerative_combinatorics
%%%}}}

\TODO terminar e arrumar.

%%{{{ Counting principles 
\section Princípios de contagem.
%%%{{{ meta 
%%%}}}

%%{{{ Informally 
\note Informalmente.
%%%{{{ meta 
%%%}}}

Queremos contar todas as maneiras possíveis para algo acontecer,
certas configurações, certos objetos ser escolhidos, ou ordenados, etc.
Baseamos nossas idéias em dois princípios de contagem:
da \emph{adição} e da \emph{multiplicação}.
\eop
{O princípio da adição, informalmente:}
Se podemos agrupar todos esses objetos em grupos \emph{distintos},
tais que cada objeto pertence em \emph{exatamente um} grupo,
o número total dos objetos é igual o somatório dos tamanhos dos grupos.
\eop
{O princípio da multiplicação, informalmente:}
Se cada configuração pode ser descrita completamente em $n$ passos,
onde para o primeiro passo temos $a_1$ opções,
para o segundo passo temos $a_2$ opções, etc., e
\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores},
então existem em total $a_1a_2\dotsb a_n$ configurações possíveis.

%%}}}

%%{{{ principle: principle_of_addition 
\principle Princípio da adição.
%%%{{{ meta 
\headerize
\label principle_of_addition
\defines
    * princípio!da adição
    ;;
%%%}}}

Seja $A$ conjunto finito, e $A_1,\dotsc,A_n$ subconjuntos dele tais que cada elemento $a\in A$, pertence em \emph{exatamente} um dos $A_i$.
Logo,
$$
|A| = \Sum_{i=1}^n |A_i|.
$$

%%}}}

%%{{{ principle: principle_of_multiplication 
\principle Princípio da multiplicação.
%%%{{{ meta 
\headerize
\label principle_of_multiplication
\defines
    * princípio!da multiplicação
    ;;
%%%}}}

Sejam $A_1,\dotsc,A_n$ conjuntos finitos.
Logo
$$
|A_1\times\dotsb\times A_n| = |A_1|\dotsb|A_n|.
$$

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string de tamanho $3$\dots
\tlist:
\li (i): Usando o alfabeto
$\set{\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z}$?
\li (ii): Usando o mesmo alfabeto, mas proibindo o mesmo caractere se repetir no string?
\endtlist

\solution.
Consideramos a formação de cada string em passos, caractere a caractere.
Temos 3 posições para colocar os caracteres:
$
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
\underline{\phantom{\txt Z}}
\;
$.
\eop
Para a questão (i), temos:
$26$ maneiras para escolher o primeiro caractere,
$26$ para o segundo, e
$26$ para o último:
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;.
$$
A escolha em cada passo não é afeitada por as escolhas dos passos anteriores.
Logo, pelo princípio da multiplicação tem
$$
26\ntimes 26\ntimes 26 = 26^3
$$
strings possíveis.
\eop
Para a questão (ii), temos:
$26$ maneiras para escolher o primeiro caractere,
$25$ para o segundo (todos menos aquele que escolhemos no passo anterior), e
$24$ para o último (similarmente):
$$
\underbrace{
\underline{\phantom{\txt Z}}
}_{26}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{25}
\;
\underbrace{
\underline{\phantom{\txt Z}}
}_{24}
\;.
$$
Agora a escolha em cada passo realmente \emph{é afeitada} por as escolhas
dos passos anteriores!
Por exemplo, se no primeiro passo escolher o caractere $\txt C$, para
o segundo passo as opções incluem o caractere $\txt A$; 
mas se no primeiro passo escolher o caractere $\txt A$, as opções para o segundo
mudam: não temos essa opção mais.
\emph{Mesmo assim, podemos usar o princípio da multiplicação!}
Por quê?
As escolhas dos passos anteriores afeitam \emph{quais} são as escolhas do passo atual,
mas não afeitam \emph{quantas} elas são!
Por isso, chegamos no resultado aplicando mais uma vez o princípio da multiplicação:
temos
$$
26\ntimes 25\ntimes 24
$$
maneiras possíveis.

%%}}}

%%{{{ x: 4 gifts for 3 kids 
\exercise.
%%%{{{ meta 
%%%}}}

Temos $4$ presentes e queremos dar para $3$ crianças tal que cada criança vai
receber apenas um presente.
\tlist:
\li (i): De quantas maneiras podemos disribuir os presentes para as crianças?
\li (ii): O que muda se as crianças são $4$?  Explique.
\endtlist

%%}}}

%%{{{ x: in how many ways can we write strings of length 2 using ABCD 
\exercise.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever strings de tamanho $2$ usando o alfabeto
$$
\set{\txt A, \txt B, \txt C, \txt D},
$$
tais que as letras aparecem em ordem que concorda com a do alfabeto?
Por exemplo os string $\txt A \txt C$, $\txt B \txt B$, e $\txt C \txt D$ são aceitáveis,
mas os $\txt D \txt C$ e $\txt B \txt A$, não.

\hint
Cuidado: aqui a \emph{quantidade} das opções da segunda escolha, depende sim na escolha
anterior!

\hint
Separa os strings possíveis em colecções e conta os strings de cada colecção separadamente,
somando no final (princípio de adição) para achar o resultado.

%%}}}

\endsection
%%}}}

%%{{{ Permutations and combinations 
\section Permutações e combinações.
%%%{{{ meta 
\label Permutations_and_combinations
%%%}}}

%%{{{ Q: in how many ways can we choose r from n? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escolher $r$ objetos de $n$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essa questão é bastante ambígua;
por exemplo:
Os $n$ objetos são todos distintos?
Podemos repetir o mesmo objeto na nossa escolha?

%%}}}

%%{{{ df: comb_perm_totperm 
\definition.
%%%{{{ meta 
\label comb_perm_totperm
\defines
    * \comb {~n} {~r}  -- o número de $r$-combinações de $n$ objetos
    * \perm {~n} {~r}  -- o número de $r$-permutações de $n$ objetos
    * \totperm {~n}    -- o número de permutações (totais) de $n$ objetos
    ;;
%%%}}}

Usamos os símbolos:
$$
\align
\totperm n &:\quad\text{o número de permutações totais de $n$ objetos}\\
\perm n r  &:\quad\text{o número de $r$-permutações de $n$ objetos}\\
\comb n r  &:\quad\text{o número de $r$-combinações de $n$ objetos}
\endalign
$$
Onde entendemos que:
\elist i:
\li: os $n$ objetos são distíntos;
\li: não podemos repeti-los.
\endelist
Observe que as permutações totais são apenas casos especiais de $r$-permutações.
Na literatura encontramos $r$-permutações também com o nome \dterm{arranjos},
mas nós vamos evitar esse termo aqui para evitar confusão.

%%}}}

%%{{{ prop: total_permutations 
\proposition Permutações totais.
%%%{{{ meta 
\label total_permutations
\defines
    * permutação!total
    ;;
\indexes
    * arranjo    see: permutação
    ;;
%%%}}}

$$
\totperm n = {n!}.
$$

%%}}}

%%{{{ prop: permutations 
\proposition Permutações.
%%%{{{ meta 
\defines
    * permutação
    ;;
%%%}}}

$$
\perm n r = \frac {n!} {(n-r)!}.
$$

%%}}}

%%{{{ prop: combinations 
\proposition Combinações.
%%%{{{ meta 
\defines
    * combinação
    ;;
%%%}}}

$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$

%%}}}

%%{{{ eg: 10_friends_car_trip 
\example.
%%%{{{ meta 
\label 10_friends_car_trip
%%%}}}

$10$ amigos têm vontade viajar com um carro de $5$ vagas.
De quantas maneiras diferentes $5$ deles podem entrar no carro?
Considere que o que diferencia mesmo a configuração são apenas a posição
do motorista e do copiloto.

\solution.
Vamos ver dois jeitos diferentes para contar essas configurações:
\crtabproofalt{Jeito 1:}
Escrevendo
$$
\comb {10} 1
\ntimes
\comb 9 1
\ntimes
\comb 8 3
$$
já é meio auto-explicativo: formamos cada configuração em passos:
{(i)}      escolher o motorista;
{(ii)}     escolher o copiloto;
{(iii)}    escolher os passangeiros de trás.
\crtabproofalt{Jeito 2:}
Outra método para formar cada configuração seria:
{(i)}      escolher os 5 que vão entrar no carro;
{(ii)}     escolher qual vai ser o motorista;
{(iii)}    escolher qual vai ser o copiloto.
pensando assim chegamos no cálculo
$$
\tubrace{\comb {10} 5} {(i)}
\ntimes
\tubrace{\comb 5 1} {(ii)}
\ntimes
\tubrace{\comb 4 1} {(iii)}.
$$
\eop
Olhando para os dois cálculos
$$
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
\askeq
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
$$
não é óbvio que seus valores são iguais.
Calculamos
$$
\alignat2
\comb {10} 1 \ntimes \comb 9 1 \ntimes \comb 8 3
&= 10 \ntimes 9 \ntimes \frac {8!} {5!\stimes3!}
&&= \frac {10!} {5!\stimes3!}
\\
\comb {10} 5 \ntimes \comb 5 1 \ntimes \comb 4 1
&= \frac {10!} {5!\stimes 5!} \ntimes 5 \ntimes 4
&&= \frac {10!} {5!\stimes 3!}
\endalignat
$$
e respondemos (felizmente) que em total temos
$$
\frac {10!} {5!\stimes3!}
= \frac{10 \ntimes 9 \ntimes 8\ntimes7\ntimes6} { 3! }
= 10 \ntimes 9 \ntimes 8\ntimes7
= 5040
$$
configurações diferentes.

%%}}}

\endsection
%%}}}

%%{{{ Permutations in a circle 
\section Permutações cíclicas.
%%%{{{ meta 
%%%}}}

%%{{{ eg: circle_dance_of_8 
\example.
%%%{{{ meta 
\label circle_dance_of_8
%%%}}}

$8$ pessoas querem dançar uma dança em qual
todos precisam formar um ciclo pegando as mãos
(e olhando para o interior do ciclo).
Em quantas configurações diferentes essa dança pode começar?

\solution.
Vamos resolver esse problema seguindo duas idéias bem diferentes:
\crtabproofalt{Idéia~1.}
Consideramos primeiro a questão:
``\emph{de quantas maneiras podemos permutar as $8$ pessoas numa ordem?}''
Respondemos $8!$, o número das permutações totais de $8$ objetos
(sabendo que hipercontamos para o problema original).
Mas podemos calcular \emph{exatamente quanto} hipercontamos:
cada resposta do problema original corresponde em exatamente
$8$ respostas do problema novo (uma para cada ``circular shift'').
Então basta só dividir a ``hiperconta'' por $8$, e chegamos
no resultado final: $8! / 8$, ou seja, $7!$.
\crtabproofalt{Idéia~2.}
\emph{Fixamos uma pessoa como ``determinante'' da configuração;}
a idéia sendo que para comparar duas configurações nós vamos
começar com o determinante, e depois comparar em ordem fixa
o resto da configuração
(por exemplo indo cada vez de uma pessoa
para quem tá no lado direito dela).
Assim, para cada permutação total das 7 outras pessoas,
temos uma permutação circular das 8 e vice-versa,
ou seja, a resposta final é $7!$.

%%}}}

%%{{{ fig for circle_dance_of_8 
\midinsert
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{p_0}$};
\node[circle,fill=white] at (a0)   {$p_0$};
\node[circle,fill=white] at (a45)  {$p_1$};
\node[circle,fill=white] at (a90)  {$p_2$};
\node[circle,fill=white] at (a135) {$p_3$};
\node[circle,fill=white] at (a180) {$p_4$};
\node[circle,fill=white] at (a225) {$p_5$};
\node[circle,fill=white] at (a270) {$p_6$};
\node[circle,fill=white] at (a315) {$p_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=white] at (a315)  {$p_0$};
\node[circle,fill=white] at (a0)    {$p_1$};
\node[circle,fill=white] at (a45)   {$p_2$};
\node[circle,fill=white] at (a90)   {$p_3$};
\node[circle,fill=white] at (a135)  {$p_4$};
\node[circle,fill=white] at (a180)  {$p_5$};
\node[circle,fill=white] at (a225)  {$p_6$};
\node[circle,fill=white] at (a270)  {$p_7$};
\endtikzpicture
%%}}}
\hfil
\eop\centerline{Uma configuração do~\reftag[circle_dance_of_8] representada em dois jeitos diferentes no papel.}
\endinsert
%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando concluimos que:

%%}}}

%%{{{ prop: permutations_in_circle 
\proposition.
%%%{{{ meta 
\label permutations_in_circle
%%%}}}

As configurações circulares diferentes de $n$ objetos, $n>0$ são
$$
(n-1)!.
$$

%%}}}

%%{{{ x: circle_dance_of_8_inorout 
\exercise.
%%%{{{ meta 
\label circle_dance_of_8_inorout
%%%}}}

O que mudará na contagem do~\ref[circle_dance_of_8],
se cada dançador pode olhar ou para o interior ou para o exterior do círculo?

\hint
Começando com a mesma resposta ($7!$) do~\ref[circle_dance_of_8],
claramente nos hipocontamos---mas quanto?

\hint
Considere uma configuração do~\ref[circle_dance_of_8].
Com quantas configurações do problema atual ela corresponde?

%%}}}

%%{{{ x: circle_dance_of_8_couples 
\exercise.
%%%{{{ meta 
\label circle_dance_of_8_couples
%%%}}}

O que mudará na contagem do~\ref[circle_dance_of_8],
se temos $4$ mulheres e $4$ homens e as regras da dança
mandam alternar os sexos na configuração?

\hint
Construa cada configuração em passos.

\hint
Primeiramente, esqueça os homens (ou as mulheres)
e coloca as $4$ mulheres (ou os $4$ homens)
num ciclo.
De quantas maneiras pode escolher o resto para
entrar no círculo?

%%}}}

%%{{{ x: 8_bead_bracelet 
\exercise.
%%%{{{ meta 
%%%}}}

Temos $8$
miçangas
diferentes, e queremos pôr todas
numa
corrente
para criar uma pulseira.
Quantas maneiras diferentes temos para o criar?

\hint
Se tu achar o problema igual com o~\ref[circle_dance_of_8],
tu hipercontarás\dots Quanto?

\hint
Veja a figura.
Pode explicar por que as três representações
correspondem na mesma configuração?
\topinsert
\centerline{
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a0)   {$a_0$};
\node[circle,fill=green!33]     at (a45)  {$a_1$};
\node[circle,fill=blue!33]      at (a90)  {$a_2$};
\node[circle,fill=cyan!33]      at (a135) {$a_3$};
\node[circle,fill=magenta!33]   at (a180) {$a_4$};
\node[circle,fill=yellow!33]    at (a225) {$a_5$};
\node[circle,fill=orange!33]    at (a270) {$a_6$};
\node[circle,fill=brown!33]     at (a315) {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a0)    {$a_1$};
\node[circle,fill=blue!33]      at (a45)   {$a_2$};
\node[circle,fill=cyan!33]      at (a90)   {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a180)  {$a_5$};
\node[circle,fill=orange!33]    at (a225)  {$a_6$};
\node[circle,fill=brown!33]     at (a270)  {$a_7$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[scale=0.8]%%{{{
\draw (0,0) circle (2cm);
\foreach \t in {0,45,90,135,180,225,270,315}
    \node[circle,fill=white] (a\t) at (\t:2cm) {$\phantom{a_0}$};
\node[circle,fill=red!33]       at (a315)  {$a_0$};
\node[circle,fill=green!33]     at (a270)  {$a_1$};
\node[circle,fill=blue!33]      at (a225)  {$a_2$};
\node[circle,fill=cyan!33]      at (a180)  {$a_3$};
\node[circle,fill=magenta!33]   at (a135)  {$a_4$};
\node[circle,fill=yellow!33]    at (a90)   {$a_5$};
\node[circle,fill=orange!33]    at (a45)   {$a_6$};
\node[circle,fill=brown!33]     at (a0)    {$a_7$};
\endtikzpicture
%%}}}
}
\botcaption{}
\emph{Apenas uma} das configurações da pulseira, representada em três desenhos.
\endcaption
\endinsert

%%}}}

\endsection
%%}}}

%%{{{ Together or separated 
\section Juntos ou separados.
%%%{{{ meta 
%%%}}}

%%{{{ x: dinner_of_8_with_couple 
\example.
%%%{{{ meta 
\label dinner_of_8_with_couple
%%%}}}

Suponha que $8$ pessoas $A,B,C,D,E,F,G,H$ querem sentar num bar
mas $C$ e $D$ querem sentar juntos.
De quantas maneiras isso pode acontecer?

\solution.
\emph{Vamos imaginar que $C$ e $D$ são uma pessoa, chamada $CD$.}
Nos perguntamos de quantas maneiras as 7 pessoas $A,B,CD,E,F,G,H$ podem sentar
numa mesa de bar com $7$ banquinhos.
A resposta é os permutações totais de tamanho 7, ou seja, $7!$.
Mas para cada configuração desse problema,
correspondem \emph{duas} configurações do problema original, porque os
$C$ e $D$ podem sentar em duas ordens diferentes juntos.
A resposta final:
$7! \ntimes 2$.

%%}}}

%%{{{ x: 8_persons_are_sitting_on_a_bar 
\exercise.
%%%{{{ meta 
% TODO: fix reflabs 
%%%}}}

Suponha que 8 pessoas $A,B,C,D,E,F,G,H$ querem jantar numa mesa de bar.
Em quantas configurações diferentes eles podem sentar se\dots:
\tlist:
\li (1): os $C$ e $D$ e $E$ querem sentar juntos;
\li (2): os $F$ e $G$ não podem sentar juntos;
\li (3): as duas restricções (1) e (2).
\endtlist

\hint
\tlist:
\li (1): Como no \ref[dinner_of_8_with_couple],
         considere o problema onde $C$, $D$, e $E$ são uma pessoa só.
\li (2): Conte o complementar e subtraia do total sem restricção;
\li (3): Conte as configurações em quais $C$, $D$, e $E$ sentam juntos e subtraia
         as configurações onde, além disso, $F$ e $G$ também sentam juntos.
\endtlist

\solution
(1) Como no \ref[dinner_of_8_with_couple], traduzimos o problema para um onde
$C$, $D$, e $E$, são uma pessoa---vamos chamá-la de $CDE$---e as
$6$ pessoas $A,B,CDE,F,G,H$ querem jantar numa mesa de bar com 6 banquinhos.
Cada solução desse problema corresponde em tantas configurações quantas as $3$ pessoas
$C$, $D$, $E$ podem sentar numa ordem, ou seja $\totperm 3$ configurações.
A resposta final:
$$
\totperm 6 \ntimes \totperm 3 = 6!\stimes3! = 6!\stimes 6
$$
\eop
(2) Contamos o complementar:
todas as maneiras onde $F$ e $G$ sentam juntos ($7!\ntimes 2$),
e o tiramos de todas as maneiras sem restricção ($8!$):
$$
\totperm 8 - \totperm 7 \ntimes \totperm 2
= 8! - 7!\ntimes 2! = 7!(8 - 2)
= 7!\stimes 6
$$
(3) Já achamos quantas maneiras tem onde $C$, $D$, e $E$ sentam juntos: $6!\stimes6$.
Disso, precisamos subtrair as configurações onde $F$ e $G$ também sentam juntos:
para satisfazer as duas restricções, consideramos as $5$ ``pessoas''
$A,B,CDE,FG,H$, quais podem sentar numa mesa de bar de tamanho $5$ de
$$
\totperm 5 \stimes \totperm 3 \stimes \totperm 2
= 5! \stimes 3! \stimes 2!
= 5! \stimes 6 \stimes 2
= 6! \stimes 2
$$
maneiras.
A resposta final então é
$$
6!\stimes6 - 6!\stimes2 = 6!(6-2) = 6! \stimes 4.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando:

%%}}}

%%{{{ prop: total_permutations_with_consecutives_restriction 
\proposition.
%%%{{{ meta 
\label total_permutations_with_consecutives_restriction
%%%}}}

O número das permutações totais de $m$ objetos distintos com a restricção que
certos $c$ deles tem que estar consecutivos é
$$
(m-c+1)! \stimes c!.
$$

%%}}}

\endsection
%%}}}

%%{{{ Permutations of things not all distinct 
\section Permutações de objetos não todos distintos.
%%%{{{ meta 
%%%}}}

%%{{{ Q: in how many ways can we permute n not-all-distinct objects? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos permutar $n$ objetos se
eles não são todos distíntos?

%%}}}

%%{{{ eg: pessimissimo 
\example.
%%%{{{ meta 
\label pessimissimo
%%%}}}

Conte todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}.
$$

\solution.
Vamos contar em dois jeitos diferentes:
\crproofalt{Idéia 1:}
Construimos cada palavra possível ``em passos'',
usando o princípio da multplicação para achar o número total.
$$
\alignat 2
\text{Começamos com 12 espaços:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
\\
\text{escolhemos onde colocar o ${\txt P}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
\underline{\phantom {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {12} 1$ opções;}
\\
\text{depois o ${\txt E}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {11} 1$ opções;}
\\
\text{depois os 4 ${\txt S}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
\underline{\phantom {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb {10} 4$ opções;}
\\
\text{depois os 3 ${\txt I}$:}
\qquad&
\underline{\phantom {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
\underline{\phantom {\txt M}}
&\qquad&
\text{tivemos $\comb 6 3$ opções;}
\\
\text{depois os 2 ${\txt M}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
\underline{\phantom {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 3 2$ opções;}
\\
\text{e finalmente o ${\txt O}$:}
\qquad&
          {         {\txt M}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt S}} \ 
          {         {\txt S}} \ 
          {         {\txt I}} \ 
          {         {\txt P}} \ 
          {         {\txt O}} \ 
          {         {\txt E}} \ 
          {         {\txt M}}
&\qquad&
\text{tivemos $\comb 1 1$ opção.}
\endalignat
$$
Pelo princípio da multiplicação, a resposta é o produto
$$
\align
\underbrace{\comb {12} 1}_{\dsize {\txt P}}
\underbrace{\comb {11} 1}_{\dsize {\txt E}}
\underbrace{\comb {10} 4}_{\dsize4{\txt S}}
\underbrace{\comb {6}  3}_{\dsize3{\txt I}}
\underbrace{\comb {3}  2}_{\dsize2{\txt M}}
\underbrace{\comb {1}  1}_{\dsize {\txt O}}
&=
\frac
{12!}
{\cancel{11!}\stimes 1!}
\frac
{\cancel{11!}}
{\cancel{10!}\stimes 1!}
\frac
{\cancel{10!}}
{\cancel{6!}\stimes 4!}
\frac
{\cancel{6!}}
{\cancel{3!}\stimes 3!}
\frac
{\cancel{3!}}
{\cancel{1!}\stimes 2!}
\frac
{\cancel{1!}}
{0!\stimes 1!}\\
&=
\frac
{12!}
{1!
\stimes 1!
\stimes 4!
\stimes 3!
\stimes 2!
\stimes 1!
}
=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$
\crproofalt{Idéia 2:}
Contamos as maneiras como se todas as letras fossem distintas,
por exemplo marcando cada letra com índices:
$$
{\txt P}_1\ 
{\txt E}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_1\ 
{\txt M}_1\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt M}_2\ 
{\txt O}_1\,.
$$
Sabemos que são $12!$ e que
assim temos \emph{hipercontado} para nosso problema.
Por exemplo, a palavra 
$
{\txt M}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt S}
{\txt S}
{\txt I}
{\txt P}
{\txt O}
{\txt E}
{\txt M}
$
corresponde em várias palavras do problema novo;
escrevemos três delas aqui como exemplos:
$$
{\txt M}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt S}\ 
{\txt S}\ 
{\txt I}\ 
{\txt P}\ 
{\txt O}\ 
{\txt E}\ 
{\txt M}
\ 
\transto
\ 
\brace{
\gathered
{\txt M}_1\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_2
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_1\ 
{\txt S}_2\ 
{\txt I}_2\ 
{\txt S}_3\ 
{\txt S}_4\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
{\txt M}_2\ 
{\txt I}_1\ 
{\txt S}_4\ 
{\txt S}_3\ 
{\txt I}_2\ 
{\txt S}_2\ 
{\txt S}_1\ 
{\txt I}_3\ 
{\txt P}_1\ 
{\txt O}_1\ 
{\txt E}_1\ 
{\txt M}_1
\\
\vdots
\endgathered
\quad\qquad
}
\ \text{\dots quantas?}
$$
Mas é fácil calcular quanto hipercontamos:
\emph{cada} palavra do problema original corresponde em exatamente tantas palavras
quantas as maneiras de permutar cada grupo de letras ``subindicadas'' entre si,
ou seja:
$$
\underbrace{1!}_{{\txt P}} \ntimes
\underbrace{1!}_{{\txt E}} \ntimes
\underbrace{4!}_{{\txt S}} \ntimes
\underbrace{3!}_{{\txt I}} \ntimes
\underbrace{2!}_{{\txt M}} \ntimes
\underbrace{1!}_{{\txt O}}
$$
maneiras.
Para responder então, basta dividir o número da ``hipercontagem'' por esse:
$$
\frac
{12!}
{4!\stimes 3!\stimes 2!}.
$$
Pronto.

%%}}}

%%{{{ x: choices_may_depend_on_past_ones_but_not_their_quantity 
\exercise.
%%%{{{ meta 
\label choices_may_depend_on_past_ones_but_not_their_quantity
%%%}}}

Escolhendo outra ordem de colocar as letras
na \proofstylize{Idéia 1} do~\ref[pessimissimo]
nossas opções em cada passo seriam diferentes.
Explique porque podemos usar o princípio da multiplicação mesmo assim.

\hint
Presta atenção na frase
``\emph{em cada passo a quantidade das opções disponíveis
não depende nas escolhas anteriores}''.

\solution
O imporante é que em cada passo, qual das nossas disponíveis opções
será escolhida, não vai afeitar a quantidade das nossas opções no passo seguinte.
Isso é realmente válido nesse caso.
Se escolher colocar as letras em outra ordem, por exemplo a
$
{\txt S},
{\txt E},
{\txt I},
{\txt P},
{\txt O},
{\txt M}
$, teriamos quantidades diferentes para cada passo sim,
\emph{mas}\/:
cada uma das nossas escolhas, não afeitaria a quantidade das escolhas próximas.
Com essa ordem, chegamos no mesmo resultado (com um cálculo que de longe aparece diferente):
$$
\align
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
&=
\frac
{12!}
{\cancel{8!}\stimes 4!}
\frac
{\cancel{8!}}
{\cancel{7!}\stimes 1!}
\frac
{\cancel{7!}}
{\cancel{4!}\stimes 3!}
\frac
{\cancel{4!}}
{\cancel{3!}\stimes 1!}
\frac
{\cancel{3!}}
{\cancel{2!}\stimes 1!}
\frac
{\cancel{2!}}
{0!\stimes 2!}\\
\vphantom{
\underbrace{\comb {12} 4}_{\dsize4{\txt S}}
\underbrace{\comb {8}  1}_{\dsize {\txt E}}
\underbrace{\comb {7}  3}_{\dsize3{\txt I}}
\underbrace{\comb {4}  1}_{\dsize {\txt P}}
\underbrace{\comb {3}  1}_{\dsize {\txt O}}
\underbrace{\comb {2}  2}_{\dsize2{\txt M}}
}
&=
\frac
{12!}
{4!
\stimes 1!
\stimes 3!
\stimes 1!
\stimes 1!
\stimes 2!
}\\
&=
\frac
{12!}
{
4!
\stimes 3!
\stimes 2!
}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Number of subsets 
\section Número de subconjuntos.
%%%{{{ meta 
\label Number_of_subsets
%%%}}}

%%{{{ Q: how many subsets of a finite set? 
\question.
%%%{{{ meta 
%%%}}}

Quantos subconjuntos dum conjunto finito existem?

%%}}}

%%{{{ Idea 1: subset_count_using_strings 
\note Idéia 1.
%%%{{{ meta 
\label subset_count_using_strings
%%%}}}

Começamos com um exemplo de um conjunto $A$ de tamanho 6:
$$
A = \set{a, b, c, d, e, f}.
$$
Uns subconjuntos de $A$ são os:
$$
\set{a,d,e},
\qquad
\emptyset,
\qquad
\set{a},
\qquad
\set{b,c,e,f},
\qquad
A,
\qquad
\set{f},
\qquad
\dotsc
$$
Queremos contar todos os subconjuntos de $A$.
Vamos \emph{traduzir o problema} de contar os subconjuntos do $A$
para um problema que envolve $n$-tuplas de dois símbolos ``0'' e ``1'', ``sim'' e ``não'', ``$\in$'' e ``$\nin$'', etc.
(Obviamente \emph{quais} são esses símbolos não afeita nada; o que importa é
que são dois símbolos distintos.)
Podemos associar agora cada dessas tuplas (ou strings) de tamanho $n$ para um
subconjunto de $A$, e vice-versa, chegando numa correspondência entre as duas
colecções de objetos.
Naturalmente associamos, por exemplo,
$$
\def\Y{1}
\def\N{0}
\underbrace{
\matrix
a  & b  & c  & d  & e  & f \\
\Y & \N & \N & \Y & \Y & \N\\
\N & \N & \N & \N & \N & \N\\
\Y & \N & \N & \N & \N & \N\\
\N & \Y & \Y & \N & \Y & \Y\\
\Y & \Y & \Y & \Y & \Y & \Y\\
\N & \N & \N & \N & \N & \Y\\
\vdots&
\vdots&
\vdots&
\vdots&
\vdots&
\vdots
\endmatrix
}_{\text{Strings de tamanho 6 do alfabeto $\set{\N,\Y}$}}
\quad\bitrans\quad
\underbrace{
\matrix
\format
\c\\
\\
\set{a,d,e}\\
\emptyset\\
\set{a}\\
\set{b,c,e,f}\\
A\\
\set{f}\\
\vdots
\endmatrix
}_{\text{Subconjuntos de $A$}}
$$
e verificamos que realmente cada configuração do problema original de subconjuntos
corresponde exatamente numa configuração do problema novo dos strings e vice-versa.
\eop
\emph{O que ganhamos?}
Sabemos como contar todos esses strings: são $2^6$.
Concluimos que os subconjuntos do $A$ são $2^6$ também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Generalizando essa idéia chegamos no resultado:

%%}}}

%%{{{ prop: number_of_subsets_of_finite_set_as_power 
\proposition.
%%%{{{ meta 
\label number_of_subsets_of_finite_set_as_power
%%%}}}

Seja $A$ conjunto finito.
$$
\card{\pset A} = 2^{\card A}.
$$

%%}}}

%%{{{ Idea 2: subset_count_by_grouping 
\note Idéia 2.
%%%{{{ meta 
\label subset_count_by_grouping
%%%}}}

Um outro jeito para contar todos os subconjuntos dum dado conjunto $A$, seria
os separar em grupos baseados no seu tamanho.
Assim, percebos que esses subconjuntos são naturalmente divididos em $n+1$ colecções:
subconjuntos com $0$ elementos, com $1$ elemento, \dots, com $n$ elementos.
\eop
\emph{O que ganhamos?}
Sabemos como contar os elementos de cada uma dessas colecções:
para formar um subconjunto de tamanho $r$, precisamos escolher $r$ dos $n$ elementos,
ou seja, existem $\comb n r$ subconjuntos de tamanho $r$.
Agora, pelo princípio da adição basta apenas somar:
são
$\Sum_{i=0}^n \comb n i$.
\eop
\emph{Qual o problema?}
Comparando essa solução com a do item~\reftag[subset_count_using_strings],
aqui temos a dificuldade de realmente calcular todos os $n$ números $\comb n i$
para os somar.
O~\ref[sum_of_all_binomial_coefficients] mostre que na verdade,
não é nada dificil calcular o somatório diretamente sem nem
calcular nenhum dos seus termos separadamente!

%%}}}

%%{{{ prop: number_of_subsets_of_finite_set_as_sum 
\proposition.
%%%{{{ meta 
\label number_of_subsets_of_finite_set_as_sum
%%%}}}

Seja $A$ conjunto finito.
$$
\card{\pset A} = \Sum_{i=0}^n \comb n i,\qquad\text{onde $n = \card A$}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Combinando as duas proposições chegamos num resultado interessante:

%%}}}

%%{{{ cor: sum_of_binom_coefs 
\corollary.
%%%{{{ meta 
\label sum_of_binom_coefs
%%%}}}

Para todo $n\in\nats$,
$$
\Sum_{i=0}^n \binom n i
= \binom n 0 + \binom n 1 + \dotsb + \binom n {n-1} + \binom n n
= 2^n
$$

%%}}}

%%{{{ x: sum_of_all_binomial_coefficients 
\exercise.
%%%{{{ meta 
\label sum_of_all_binomial_coefficients
%%%}}}

Esqueça o corolário e demonstre que:
$$
\alignat 2
\Sum_{i=0}^n \binom n i
&= \binom n 0 + \binom n 1 + \binom n 2 + \dotsb + \binom n n
&&= 2^n\\
\Sum_{i=0}^n (-1)^i \binom n i
&=\binom n 0 - \binom n 1 + \binom n 2 - \dotsb + (-1)^n \binom n n
&&= 0
\endalignat
$$

\hint
Teorema binomial~\reftag[binomial_theorem].

\hint
Cada somatório é apenas um caso especial do teorema binomial.

\hint
Toma $x,y \asseq 1$ no teorema para resolver o primeiro.

\hint
Toma $x \asseq 1$ e $y \asseq -1$ para resolver o segundo.

%%}}}

\endsection
%%}}}

%%{{{ Pascal's triangle 
\section O triângulo de Pascal.
%%%{{{ meta 
%%%}}}

%%{{{ The first powers of the binomial 
\note As primeiras potências do binomial.
%%%{{{ meta 
%%%}}}

Calculamos:
\mathcol
(x+y)^0 &= 1 \\
(x+y)^1 &= 1 x   + 1 y \\
(x+y)^2 &= 1 x^2 + 2 x   y + 1      y^2 \\
(x+y)^3 &= 1 x^3 + 3 x^2 y + 3  x   y^2 + 1      y^3 \\
(x+y)^4 &= 1 x^4 + 4 x^3 y + 6  x^2 y^2 + 4  x   y^3  + 1      y^4 \\
(x+y)^5 &= 1 x^5 + 5 x^4 y + 10 x^3 y^2 + 10 x^2 y^3  + 5  x   y^4  + 1      y^5 \\
(x+y)^6 &= 1 x^6 + 6 x^5 y + 15 x^4 y^2 + 20 x^3 y^3  + 15 x^2 y^4  + 6  x   y^5 + 1      y^6 \\
(x+y)^7 &= 1 x^7 + 7 x^6 y + 21 x^5 y^2 + 35 x^4 y^3  + 35 x^3 y^4  + 21 x^2 y^5 + 7  x   y^6 + 1   y^7 \\
(x+y)^8 &= 1 x^8 + 8 x^7 y + 28 x^6 y^2 + 56 x^5 y^3  + 70 x^4 y^4  + 56 x^3 y^5 + 28 x^2 y^6 + 8 x y^7 + 1 y^8.
\endmathcol

%%}}}

%%{{{ pascal_triangle 
\note O triângulo de Pascal.
%%%{{{ meta 
\label pascal_triangle
\defines
    * triângulo!de Pascal
    ;;
\credits
    * Pascal : triângulo
    ;;
%%%}}}

Tomando os coeficientes acima criamos o triângulo seguinte,
conhecido como \dterm{triângulo de Pascal}:%
$$
\matrix
\format
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\;&
\;\c\; \\
1 \\
1 & 1 \\
1 & 2 & 1 \\
1 & 3 & 3  & 1 \\
1 & 4 & 6  & 4  & 1 \\
1 & 5 & 10 & 10 & 5  & 1 \\
1 & 6 & 15 & 20 & 15 & 6  & 1 \\
1 & 7 & 21 & 35 & 35 & 21 & 7  & 1 \\
1 & 8 & 28 & 56 & 70 & 56 & 28 & 8 & 1 \\
\;\vdots\;&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\phantom{00}&
\ddots
\endmatrix
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observando o triângulo, percebemos que com umas exceções---quais?---cada
número é igual à soma de dois números \emph{na linha em cima}:
aquele que fica na mesma posição, e aquele que fica na posição anterior.
(Consideramos os ``espaços'' no triângulo como se fossem $0$'s.)

%%}}}

%%{{{ x: write this formally 
\exercise.
%%%{{{ meta 
%%%}}}

Escreva essa relação formalmente.

\hint
O $\binom a b$ está na linha $a$, na posição $b$
(começando contar com 0).

\solution
Temos as equações:
$$
\rightbrace {
\aligned
\binom 0 0          &= 1\\
\binom 0 r          &= 0\\
\binom n r          &= \binom {n-1} r + \binom {n-1} {r-1}
\endaligned
}
\quad
\text{equivalentemente}
\quad
\leftbrace {
\aligned
\binom 0     0      &= 1\\
\binom 0     {r+1}  &= 0\\
\binom {n+1} {r+1}  &= \binom n {r+1} + \binom n r.
\endaligned
}
$$

%%}}}

%%{{{ thm: combinations_recursive_equation 
\theorem.
%%%{{{ meta 
\label combinations_recursive_equation
%%%}}}

Para todos inteiros positivos $n$ e $r$ temos:
$$
\comb n r = \comb {n-1} r + \comb {n-1} {r-1}.
$$

\sketch.
Lembramos que $\comb n r$ é o número das maneiras que podemos
escolher $r$ de $n$ objetos.
Fixe um dos $n$ objetos e o denote por $s$,
para agir como \dq{separador de maneiras}:
separamos as maneiras de escolher em dois:
aquelas que escolhem (entre outros) o $s$ e aquelas que não o escolhem.
Contamos cada colecção separadamente e somamos (princípio da adição)
para achar o resultado:
$$
\comb n r
= \tubrace {\comb {n-1} r}     {escolhas sem $s$}
+ \tubrace {\comb {n-1} {r-1}} {escolhas com $s$}.
$$

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre o~\ref[combinations_recursive_equation] para todos os $n,r\in\nats$
com $0 < r < n$, usando como definição do símbolo $\comb n r$ a
$$
\comb n r = \frac {n!} {(n-r)!\stimes r!}.
$$

\hint
Demonstre diretamente usando apenas a definição de fatorial.

\solution
Sejam $r,n\in\nats$ com $0<r<n$.
Calculamos:
$$
\alignat 4
\intertext{$\comb n r = \comb {n-1} r + \comb {n-1} {r-1}$}
&\iff\quad& \frac {n!} {(n-r)!\stimes r!} &= \frac {(n-1)!} {(n-1-r)!\stimes r!}              &\!\!{}+{}\ & \frac {(n-1)!} {(n-1-(r-1))!\stimes (r-1)!} &\qquad&\qquad\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r-1)!\stimes r!}                  &\!\!{}+{}\ & \frac {(n-1)!\stimes(n-r)!\stimes r!} {(n-r)!\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)!\stimes\cancel{r!}} {(n-r-1)!\stimes \cancel{r!}} &\!\!{}+{}\ & \frac {(n-1)!\stimes\cancel{(n-r)!}\stimes r!} {\cancel{(n-r)!}\stimes (r-1)!}\\
&\iff\quad& n! &= \frac {(n-1)!\stimes(n-r)\!\cancel{\stimes!\stimes}} {\cancel{(n-r-1)!}}    &\!\!{}+{}\ & \frac {(n-1)!\stimes r\cancel{\stimes!\stimes}} {\cancel{(r-1)!}}\\
&\iff\quad& n! &= {(n-1)!\stimes(n-r)} &\!\!{}+{}\ & {(n-1)!\stimes r} \\
&\iff\quad& n! &= {(n-1)!\stimes((n-r) + r)}\\
&\iff\quad& n! &= {(n-1)!\stimes n}\\
&\iff\quad& n! &= n!
\endalignat
$$

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

\emph{Redefina} o símbolo $\comb n r$ para todo $n,r\in\nats$
recursivamente com
\mathcol
\comb 0 0  &= 1\\
\comb 0 r  &= 0\\
\comb n r  &= \comb {n-1} r + \comb {n-1} {r-1},
\endmathcol
e demonstre que para todo $n,r\in\nats$,
$\comb n r = \dfrac {n!} {(n-r)!\stimes r!}$\,.

\hint
Indução.

%%}}}

%%{{{ remark: intro to Singmaster's conjecture 
\remark Axiomas mais fortes do que precisamos.
%%%{{{ meta 
\label axioms_stronger_than_needed
%%%}}}

Para cada inteiro positivo, quantas vezes aparece no triângulo de Pascal?
É imediato que o $1$ aparece uma infinidade de vezes.
Além disso, qualquer inteiro $x > 1$ só pode aparecer nas primeiras $x$ linhas
do triângulo---e de fato aparece pelo menos uma vez na própria $x$-ésima linha---algo
que garanta também que nenhum outro inteiro pode aparecer uma infinidade de vezes.
Até o momento que esta parágrafo foi escrita, o número com a maioria de ocorrências
que conhecemos é o $3003$, que ocorre $8$ vezes:
$$
3003
= \binomS 3003 1
= \binomS 78   2
= \binomS 15   5
= \binomS 14   6
= \binomS 14   8
= \binomS 15   10
= \binomS 78   76
= \binomS 3003 2
.
$$
Para qualquer $x > 0$, denote por $m(x)$ a quantidade de vezes que $x$ aparece no triângulo
de Pascal até a $x$-ésima linha; assim
$$
m(1) = 3, \quad
m(2) = 1, \quad
m(3) = 2, \quad
m(4) = 2, \quad
m(5) = 2, \quad
$$
e, visto como uma seqüência $\seqn m x$, seus primeiros valores são\foot
A no(ta)ção de seqüências é introduzida pela \ref[sequence_of_reals].
\toof
$$
\seqn m x = 3, 1, 2, 2, 2, 3, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 3, 4, 2, 2, 2, \dots
$$
Singmaster conjecturou que existe uma cota superior para o conjunto dos seus valores
$\seqnset m x$ e até este momento continua aberta.
Sabemos apenas que $1,2,3,4,6,8 \in \seqnset m x$.

%%}}}

%%{{{ conjecture: singmaster_conjecture 
\conjecture Singmaster.
%%%{{{ meta 
\label singmaster_conjecture
\credits
    * Singmaster : conjectura
    ;;
%%%}}}

A $\seqn m x$ é cotada por cima, ou seja:
$$
\lexists {b > 0}
         {\seqnset m x \leq b},
\qqtext{ou seja,}
\pexists {b > 0}
\lforall {x > 0}
         {m_x \leq b}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Counting recursively 
\section Contando recursivamente.
%%%{{{ meta 
%%%}}}

%%{{{ x: sequences_of_twos_and_threes 
\exercise.
%%%{{{ meta 
\label sequences_of_twos_and_threes
%%%}}}

Defina uma função $f : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada.
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $17$?

\hint
Recursão.

\hint
Separe as seqüências em dois grupos: aquelas que começam com 2, e aquelas que começam com 3.

\hint
Cuidado com a ``base'' $f(0)$.  Quantas seqüências de 2 e 3, somam em $0$?

\hint
Para calcular o valor de $f(17)$, \emph{não} use a definição recursiva ``top-down'',
mas ``bottom-up'': calcule os valores em seqüência linear
$f(0), f(1), f(2), \dotsc$ até o valor desejado.

%%}}}

%%{{{ x: sequences_of_twos_and_threes_restricted 
\exercise.
%%%{{{ meta 
\label sequences_of_twos_and_threes_restricted
%%%}}}

Defina uma função $g : \nats\to\nats$ que conta as seqüências feitas por os números 2 e 3 com soma sua entrada, em quais aparecem os dois números (2 e 3).
Quantas seqüências de $2$'s e $3$'s existem cujos termos somam em $18$?

\hint
Use a $f$ do~\ref[sequences_of_twos_and_threes].

\hint
Quando $g(n) \neq f(n)$?

\hint
Considere os casos:
(1) $n$ não pode ser escrito nem como $n = 2 + 2 + \dotsb + 2$, nem como $n = 3 + 3 + \dotsb + 3$;
(2) $n$ pode ser escrito como $n = 2 + 2 + \dotsb + 2$, e como $n = 3 + 3 + \dotsb + 3$ também;
(3) nenhum dos casos (1)--(2).

\hint
$
g(n) =
\knuthcases {
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}\cr
\cdots\vphantom{f(n)}
}
$

%%}}}

%%{{{ x: infinite_city_1 
\exercise Dirigindo na cidade infinita (sem destino).
%%%{{{ meta 
\label infinite_city_1
%%%}}}

No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 3 opções:
virar esquerda; dirigir reto; virar direita.
No seu depósito tem $a$ unidades de combustível,
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
(Veja na figura, dois caminhos possíveis com $a=12$.)
\noi
\midinsert
\noi
\centerline{
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (0,1) -- (0,2) -- (-1,2) -- (-1,1) -- (-1,0) -- (-1,-1) -- (-2,-1) -- (-3,-1) -- (-3,0) -- (-3,1) -- (-2,1) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (1,0) -- (2,0) -- (3,0) -- (3,1) -- (3,2) -- (3,3) -- (3,4) -- (4,4) -- (4,3) -- (4,2) -- (3,2) -- (2,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
%
\endtikzpicture
%%}}}
\hfill
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {-4,-3,-2,-1,0,1,2,3,4}
  \draw [-] (\i,-2.5) -- (\i,4.5);
\foreach \j in {-2,-1,0,1,2,3,4}
  \draw [-] (-4.5,\j) -- (4.5,\j);
\draw[rounded corners,line width=2mm,color=blue!40] (0,0) -- (-1.8,0) -- (-1.8,2);
\draw[rounded corners,line width=2mm,color=cyan!60] (0,0) -- (4,0) -- (4,2) -- (-3, 2) -- (-3,3) -- (-2,3) -- (-2,2);
\draw[rounded corners,line width=2mm,color=green!40] (0,0) -- (0,-1) -- (-2.1,-1) -- (-2.1,2);
\node[circle,fill=gray!20] (CR)  at (0,0) {$C$};
\node[circle,fill=gray!20] (DN)  at (-2,2) {$D$};
%
\endtikzpicture
%%}}}
\hfill
}
%\caption{Fig.~1}
\eop\centerline{Caminhos possíveis para os exercícios~\reftag[infinite_city_1] e~\reftag[infinite_city_2] respectivamente.}
%\endcaption
\endinsert

\hint
Sem recursão!

\hint
Em cada intersecção tem $3$ opções: $\mathtt L$, $\mathtt F$, $\mathtt R$.

\solution
Em cada das $a$ intersecções que ele encontra ele tem $3$ opções.
Logo, ele pode seguir $3^a$ caminhos diferentes dirigindo até seu combustível acabar.

%%}}}

%%{{{ x: infinite_mountain 
\exercise Dirigindo na montanha infinita.
%%%{{{ meta 
\label infinite_mountain
%%%}}}

No ``meio'' duma montanha de altura infinita, tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir subindo (gasta $4$ unidades de combutível);
dirigir descendo (gasta $1$);
dirigir na mesma altura clockwise (gasta $2$);
dirigir na mesma altura counter-clockwise (gasta $2$).
No seu depósito tem $a$ unidades de combistível.
De quantas maneiras diferentes ele pode dirigir até seu combustível acabar?
\ignore{
\midinsert
\tikzpicture[scale=2]
\axis[
hide axis,
domain=0:1,
y domain=0:-2*pi,
xmin=-1.5, xmax=1.5,
ymin=-1.5, ymax=1.5, zmin=-1.2, zmax=-1.2,
samples=10,
samples y=40,
z buffer=sort,
]
\addplot3[mesh,gray]
({1.1*x*cos(deg(y))},{1.1*x*sin(deg(y))},{-x});
\endaxis
\endtikzpicture
\endinsert
}

\hint
Recursão.

\hint
Seja $f(a)$ o número de caminhos diferentes que o motorista pode seguir com $a$ unidades de combustível.

\hint
Separa todos os caminhos possíveis em 3 grupos, dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

%%}}}

%%{{{ x: infinite_city_2 
\exercise Dirigindo na cidade infinita (com destino).
%%%{{{ meta 
\label infinite_city_2
%%%}}}

No ``meio'' duma ``cidade infinita'', tem um motorista no seu carro.
Seu carro tá parado numa intersecção onde tem 4 opções:
dirigir na direção do norte; do leste; do sul; do oeste.
No seu depósito tem $c$ unidades de combustível
e sempre gasta $1$ para dirigir até a próxima intersecção.
De quantas maneiras diferentes ele pode dirigir até chegar no seu destino,
que fica numa distância $y$ unidades para norte e $x$ para leste?
Considere que números negativos representam descolamento para a direção oposta.
(Veja na figura onde o carro $C$ tem destino $D$, ou seja, seu descolamento
desejado é de $x=-2$, $y=2$.)

\hint
Recursão.

\hint
Seja $f(a,x,y)$ o número de caminhos diferentes que acabam com
descolamento total de $y$ unidades para norte e $x$ para leste,
para um motorista que tem $a$ unidades de combustível no seu carro.

\hint
Separa todos os caminhos possíveis em 4 grupos,
dependendo na primeira escolha do motorista.
Conta o número de caminhos em cada grupo separadamente (recursivamente!),
e e use o princípio da adição para contar quantos são todos.

%%}}}

\endsection
%%}}}

%%{{{ Solutions of equations in integers 
\section Soluções de equações em inteiros.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Combinations with repetitions 
\section Combinações com repetições.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The inclusion--exclusion principle 
\section O princípio da inclusão--exclusão.
%%%{{{ meta 
\label Inclusion_exclusion_principle
%%%}}}

%%{{{ x: 42_passengers_on_a_plane 
\exercise.
%%%{{{ meta 
\label 42_passengers_on_a_plane
%%%}}}

$42$ passangeiros estão viajando num avião.
\tlist:
\li: 11 deles não comem beef.
\li: 10 deles não comem peixe.
\li: 12 deles não comem frango.
\li: Os passangeiros que não comem nem beef nem frango são 6.
\li: O número de passangeiros que não comem nem beef nem peixe, é o mesmo com o número de passangeiros que não comem nem peixe nem frango.
\li: Os passangeiros que não comem nada disso são 3.
\li: Os passangeiros que comem tudo são 22.
\endtlist
Quantos são os passangeiros que não comem nem beef nem peixe?

%%}}}

\endsection
%%}}}

%%{{{ Elementary probability 
\section Probabilidade elementar.
%%%{{{ meta 
%%%}}}

%%{{{ x: russian_roulette 
\exercise Roleta russa.
%%%{{{ meta 
\label russian_roulette
%%%}}}

(Não tente isso em casa; vai acordar os vizinhos.)
No jogo da roleta russa, uma única bala é posicionada num
revolver de 6~balas e logo após o moinho é girado com força
em tal forma que a posição da bala é desconhecida e ``justa'',
ou seja, cada posição é igualmente provável de ter a bala.
A partir disso, o jogador 1 pega a arma e atira na sua própria cabeça.
Caso que sobreviveu, o jogador 2 faz a mesma coisa, e o jogo continua
assim alterando esse processo até um jogador acaba se matando.
Logo, a duração desse jogo é de 1 a 6 rodadas.
Supondo que ambos os jogadores querem viver, algum dos dois
tem vantagem?

%%}}}

%%{{{ x: russian_roulette_alt 
\exercise.
%%%{{{ meta 
\label russian_roulette_alt
%%%}}}

O que muda se os jogadores giram o moinho do revolver antes
de cada rodada e não apenas no começo do jogo?

%%}}}

\endsection
%%}}}

%%{{{ Derrangements 
\section Desarranjos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The pigeonhole principle 
\section O princípio da casa dos pombos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Generating functions and recurrence relations 
\section Funções geradoras e relações de recorrência.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Uma turma de 28 alunos tem 12 mulheres e 16 homens.
\elist a:
\li:
De quantas maneiras podemos escolher 5 desses alunos,
para formar um time de basquete?
(Considere que as posições de basquete não importam).
\li:
De quantas maneiras podemos escolher 6 desses alunos,
para formar um time de volei, tal que o time tem pelo menos 4 homens?
(Considere que as posições de volei não importam).
\li:
De quantas maneiras podemos escolher 11 desses alunos,
para formar um time de futebol, tal que o time tem exatamente 3 mulheres,
e um homem goleiro?
(Considere que a única posição de futebol que importa é do goleiro.)
\li:
De quantas maneiras podemos escolher 3 times, um para cada esporte,
sem restricção de sexo?
\endelist

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Uma noite, depois do treino 3 times (uma de basquete, uma de vólei, e uma de
futebol), foram beber num bar que foi reservado para eles.
Como os jogadores de cada time querem sentar juntos,
o dono arrumou duas mesas cíclicas, uma com 5 e outra com 6 cadeiras, e 11 cadeiras no bar.
\eop
De quantas maneiras diferentes eles podem sentar?
(Considere que nas mesas cíclicas o que importa é apenas quem tá no lado de quem, mas no bar o que importa é a posição da cadeira mesmo.)

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Considere os inteiros $1,2,\dotsc, 30$.
Quantas das suas $30!$ permutações totais têm a propriedade que
não aparecem múltiplos de $3$ consecutivamente?

\hint
Construa cada configuração em passos e use o princípio da multiplicação.

\hint
Coloque os não-múltiplos de $3$ primeiramente numa ordem, deixando espaços entre-si
para os múltiplos de $3$.

\hint
Escolhe 10 dos 21 lugares possíveis para colocar os múltiplos de $3$.

\solution
Primeiramente vamos esquecer os múltiplos de $3$.
O resto dos (20) números pode ser permutado de $20!$ maneiras.
Para qualquer dessa maneira, temos $\comb {21} {10}$
opções para escolher em quais $10$ das $20+1$ possíveis posições
vamos colocar os múltiplos de $3$,
e para cada escolha, correspondem $10!$ diferentes permutações
dos múltiplos de 3 nessas $10$ posições.
Finalmente,
$$
\tubrace {\vphantom(20!}
         {(ordenar os não-múltiplos)}
\ntimes
\tubrace {\,\comb {21} {10}\,}
         {(escolher as posições dos múltiplos)}
\ntimes
\tubrace {\vphantom(10!}
         {(escolher a ordem dos múltiplos)}
$$
das $30!$ permutações têm a propriedade desejada.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Numa turma de $28$ alunos
precisamos formar duas comissões de $5$ e $6$ membros.
Cada comição tem seu presidente, seu vice-presidente, e seus membros normais.
De quantas maneiras podemos formar essas comissões\dots
\elist a:
\li: \dots sem restricções (cada um aluno pode participar nas duas comissões simultaneamente)?
\li: \dots se nenhum aluno pode participar simultaneamente nas duas comissões?
\li: \dots se os dois (únicos) irmãos entre os alunos não podem participar na mesma comissão,
e cada aluno pode participar simultaneamente nas duas?
\endelist

%%}}}

%%{{{ prob: {abc}* without ab 
\problem.
%%%{{{ meta 
\pdefs
    \pdef a {{\mathtt a}}
    \pdef b {{\mathtt b}}
    \pdef c {{\mathtt c}}
    ;;
%%%}}}

Do alfabeto $\set{\a,\b,\c}$ desejamos formar strings de tamanho $\ell$
onde não aparece o substring $\a\b$.
Em quantas maneiras podemos fazer isso?

%%}}}

%%{{{ prob: domino 2×n 
\problem.
%%%{{{ meta 
%%%}}}

Conte em quantas maneiras podemos cobrir um tabuleiro de dimensão
$2\times n$ com peças-dominô (ou seja, peças de dimensão $2\times 1$).

\hint
Recursão.

\hint
O quadradinho na posição $(1,1)$ pode ser coberto em apenas duas maneiras:
(A) por uma peça ocupando as posições $(1,1)$--$(1,2)$;
(B) por uma peça ocupando as posições $(1,1)$--$(2,1)$.

\solution
Seja $f(n)$ a quantidade de maneiras que podemos cobrir
um tabuleiro de tamanho $2 \times n$.
Começamos observando que para um tabuleiro $2 \times 0$
temos exatamente uma maneira de cobrir todos os quadradinhos:
fazendo nada.
Vamos pular outros casos específicos e voltar caso que precisar.
O quadradinho na posição $(1,1)$ pode ser coberto em apenas duas maneiras:
(A) por uma peça ocupando as posições $(1,1)$--$(2,1)$;
(B) por uma peça ocupando as posições $(1,1)$--$(1,2)$.
No caso (A), para cobrir o resto que é um tabuleiro
de $2 \times (n-1)$, temos $f(n-1)$ maneiras.
No caso (B), observe que tendo a peça cobrindo os $(1,1)$--$(1,2)$,
o quadradinho $(2,1)$ só pode ser coberto por uma peça no $(2,1)$--$(2,2)$.
Agora basta cobrir o resto que é um tabuleiro de $2 \times (n-2)$,
e logo temos $f(n-2)$ maneiras de fazer isso.
Agora percebemos que precisamos mais uma base (por causa do $n-2$).
Obviamente para cobrir um tabuleiro de tamanho $2 \times 1$ temos
exatamente uma maneira.
Temos então:
\mathcol
f(0) &= 1 \\
f(1) &= 1 \\
f(n) &= \tubrace {f(n-1)} {(A)} + \tubrace {f(n-2)} {(B)}.
\endmathcol

%%}}}

%%{{{ prob: nikos 
\problem.
%%%{{{ meta 
\label nikos
%%%}}}

Na figura abaixo temos um mapa (as linhas correspondem em ruas).
Nikos quer caminhar do ponto $A$ para o ponto $B$, \emph{o mais rápido possível}.
\elist:
\li: De quantas maneiras ele pode chegar?
\li: Se ele precisa passar pelo ponto $S$?
\li: Se ele precisa passar pelo ponto $S$ mas quer evitar o ponto $N$?
\endelist
\midinsert
\noi
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\tikzpicture[scale=0.666]%%{{{
%
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \foreach \j in {0,1,2,3,4,5,6,7,8}
    \node (a\i) at (\i,\j) {};
\foreach \i in {0,1,2,3,4,5,6,7,8,9}
  \draw [-] (\i,0) -- (\i,8);
\foreach \j in {0,1,2,3,4,5,6,7,8}
  \draw [-] (0,\j) -- (9,\j);
\draw [rounded corners,line width=2mm,color=red!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (5,4) -- (5,5) -- (7,5) -- (7,7) -- (8,7) -- (8,8) -- (9,8);
\node[circle,fill=gray!20] (SW)  at (-0.3,-0.3) {$A$};
\node[circle,fill=gray!20] (NE)  at (9.3,8.3) {$B$};
\node[circle,             inner sep=2pt,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
\node[star,star points=17,inner sep=2pt,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
\eop\centerline{Um caminho aceitável e um inaceitável no caso (3) do \ref[nikos].}
\endinsert

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

Num jogo de lotéria, tem os números de $1$ até $60$:
$$
\matrix
    01&02& 03 &04 &05 &06 &07 &08 &09 &10\\
    11&12& 13 &14 &15 &16 &17 &18 &19 &20\\
    21&22& 23 &24 &25 &26 &27 &28 &29 &30\\
    31&32& 33 &34 &35 &36 &37 &38 &39 &40\\
    41&42& 43 &44 &45 &46 &47 &48 &49 &50\\
    51&52& 53 &54 &55 &56 &57 &58 &59 &60
\endmatrix
$$
Os organizadores do jogo, escolhem aleatoriamente 6 números
deles (sem repetições).
Esses 6 números são chamados ``a megasena''.
Um jogador marca pelo menos 6 números na sua
lotéria e se conseguir ter marcados todos os 6 da megasena, ganha.

(Marcando mais que 6 números,
as chances do jogador aumentam, mas o preço da lotéria aumenta também.)

(1)
Um jogador marcou $6$ números.
Qual a probabilidade que ele ganhe?

(2)
Uma jogadora marcou $9$ números.
Qual a probabilidade que ela ganhe?

(3)
Generalize para um jogo com $N$ números, onde $w$ deles são escolhidos,
e com um jogador que marcou $m$ números, sendo $w\leq m \leq N$.

\solution
(1)
Apenas uma escolha é a certa, então a probabilidade de ganhar é:
    $$
    \dfrac 1 {\comb {60} 6}
    = \dfrac{6!\stimes 54!} {60!}
    = \dfrac {6!} {55 \ntimes 56 \ntimes 57 \ntimes 58 \ntimes 59 \ntimes 60}
    = \dfrac {1} {11\ntimes 14\ntimes 19\ntimes 29\ntimes 59\ntimes 10}
    = \dfrac 1 {50063860}\,.
    $$
(2)
Para ganhar, com certeza acertamos nos 6 números da megasena,
então temos que contar todas as maneiras de escolher os 3 outros números dos 9 que escolhemos:
    $$
    \dfrac {\comb {60-6} {9-6}} {\comb {60} 9}
    = \dfrac {\comb {54} 3} {\comb {60} 9}
    = \dfrac {54!\stimes \cancel{51!}\stimes 9!} {\cancel{51!} \stimes 3!\stimes 60!}
    = \dfrac {4\ntimes 5 \ntimes 6 \ntimes 7 \ntimes 8 \ntimes 9} {55\ntimes 56\ntimes 57\ntimes 58\ntimes 59 \ntimes 60}
    = \dfrac 3 {1787995}\,.
    $$
(3)
Generalizando a solução do (2), a probabilidade é
$$
\align
\frac
{\comb {N-w} {m-w}}
{\comb N m}
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N-w)-(m-w))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes (N-m)! \stimes m!}
{((N\cancel{{}-{}w}-m\cancel{{}+w}))! \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes \cancel{(N-m)!} \stimes m!}
{\cancel{(N-m)!} \stimes (m-w)! \stimes N!}\\
&=
\frac
{(N-w)! \stimes m!}
{(m-w)! \stimes N!}\\
&=
\Prod_{i=0}^{w-1}
\frac
{m-i}
{N-i}\,.
\endalign
$$

%%}}}

%%{{{ prob: aleco_bego 
\problem.
%%%{{{ meta 
\label aleco_bego
%%%}}}

Aleco e Bego são dois sapos.
Eles estão na frente de uma escada com 11 degraus.
No 6o degrau, tem Cátia, uma cobra, com fome.
Aleco pula 1 ou 2 degraus para cima.
Bego, 1, 2 ou 3.  E ele é tóxico: se Cátia comê-lo, ela morre na hora.
\midinsert
% TODO: this should be on a separate file
\tikzpicture[scale=0.666]%%{{{
%
\node[star,star points=17,fill=red!30,inner sep=3pt]    (boom) at (6.75,6.25) {\phantom{\niness C}};
\node[                                             ]    (catia) at (6.666,6.333) {{\niness C}};
\node[circle,fill=green!40]  (aleco) at (-0.333,0.5) {{\niness A}};
\node[circle,fill=blue!30]   (bego)  at (-1.75,0.5) {{\niness B}};
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=70] (2.333,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=66] (1.666,1);
\draw [->,color=green!50,line width=1mm] (aleco) to [bend left=60] (1.333,1);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=62] (2.666,2);
\draw [->,color=blue!50,line width=1mm] (bego)  to [bend left=60] (3.5,3);
\foreach \i in {1,2,3,4,5,6,7,8,9,10,11} {
  \path[fill=gray!10]
    (\i,\i) -- (\i,\i-1) -- (15,\i-1) -- (15,\i) -- (\i,\i);
  \node[circle,fill=black,inner sep=0pt] (b\i) at (\i,\i)   {};
  \node[circle,fill=black,inner sep=0pt] (e\i) at (\i+1,\i) {};
  \node[circle,fill=black,inner sep=0pt] (d\i) at (\i,\i-1) {};
  \node[                  inner sep=0pt] (s\i) at (\i+0.5,\i) {};
  \draw [-,line width=0.2mm] (b\i) -- (e\i);
  \draw [-,line width=0.2mm] (b\i) -- (d\i);
  \node[                  inner sep=0pt] (t\i) at (\i+0.5,\i-0.3) {\i};
}
\draw [-] (-3,0) -- (1,0);
\draw [-] (12,11) -- (15,11);
%\foreach \j in {0,1,2,3,4,5,6,7,8}
%  \draw [-] (0,\j) -- (9,\j);
%  \draw [line width=2mm,color=green!50] (0,0) -- (0,2) -- (3,2) -- (3,4) -- (7,4) -- (7,5) -- (8,5) -- (8,7) -- (9,7) -- (9,8);
%\node[circle,fill=gray!20]  (SW)    at (-0.3,-0.3) {$A$};
%\node[circle,fill=gray!20]  (NE)    at (9.3,8.3)   {$B$};
%\node[circle,fill=green!30] (nice)  at (3,2.5)     {{\niness S}};
%\node[circle,fill=red!30]   (boom)  at (6.5,5)     {{\niness N}};
%
\endtikzpicture
%%}}}
%\caption{Fig.~2}
\eop\centerline{Os dois sapos do~\ref[aleco_bego] e suas possibilidades para começar.}
%\endcaption
\endinsert
\tlist:
\li (1): Por enquanto, Cátia está dormindo profundamente.
         \tlist:
         \li a.:  De quantas maneiras Aleco pode subir a escada toda?
         \li b.:  De quantas maneiras Bego pode subir a escada toda?
         \endtlist
\li (2): Cátia acordou!
         \tlist:
         \li a.:  De quantas maneiras Aleco pode subir a escada toda?
         \li b.:  De quantas maneiras Bego pode subir a escada toda?
         \endtlist
\li (3): Bego começou subir a escada\dots{}
         Qual é a probabilidade que Cátia morra?
         (Considere que antes de começar, ele já decidiu seus
         saltos e não tem percebido a existência da cobra.)
\ignore{% TODO
\li (4): O que muda na questão (3) se ao invés de decidir seu caminho desde o
         início, Bega decida cada vez aleatoriamente (com probabilidades iguais)
         qual dos 3 possíveis saltos ele vai fazer?
\li (5): Generalize o problema (4)~para o caso onde a escada
         tem uma infinidade de degraus e Cátia fica no degrau $k$.
}
\endtlist

\hint
Recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.

\hint
Grupe as maneiras em colecções (para aplicar o princípio da adição),
olhando para o primeiro salto.

\solution
Sejam $a(n)$ e $b(n)$ o número de maneiras que Aleco e Bego
podem subir uma escada de $n$ degraus, respectivamente.
Cada maneira do Aleco pode começar com 2 jeitos diferentes:
salto de $1$ degrau, ou salto de $2$ degraus.
Cada maneira do Bego pode começar com 3 jeitos diferentes:
salto de $1$, de $2$, ou de $3$ degraus.
Observe que, por exemplo, se Bego começar com um pulo de $2$
degraus, falta subir uma escada de $n-2$ degraus.
Pelo princípio da adição então, temos as equações recursivas:
\mathcols 2
a(n) &= a(n-1) + a(n-2)                & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\intertext{válidas para $n\geq 2$ e $n \geq 3$ respectivamente.
Devemos definir os casos básicos de cada função recursiva:
$n=0,1$ para a $a(n)$, e $n=0,1,2$ para a $b(n)$:}
     &                                 & b(0) &= 1 \qquad\explanation{fica} \\
a(0) &= 1 \qquad\explanation{fica}     & b(1) &= 1 \qquad\explanation{pula $1$} \\
a(1) &= 1 \qquad\explanation{pula $1$} & b(2) &= 2 \qquad\explanation{pula $1+1$; ou pula $2$} \\
a(n) &= a(n-1) +  a(n-2)               & b(n) &= b(n-1) +  b(n-2) +  b(n-3)
\endmathcols
Calculamos os $11$ primeiros valores:
$$
\matrix
a:\quad& \overbrace {1}^{a(0)}, & 1, & 2, & 3, & 5, & \phantom08,  & 13, & 21, & 34, & \phantom055,  & \phantom089,  & \overbrace {144}^{a(11)}, &\dotsc\\
b:\quad& \underbrace{1}_{b(0)}, & 1, & 2, & 4, & 7, & 13,          & 24, & 44, & 81, & 149, & 274, & \underbrace{504}_{b(11)}, &\dotsc
\endmatrix
$$
Agora temos tudo que precisamos para responder facilmente às questões do problema.
\eop
{(1)}  Precisamos apenas os valores $a(11)$ e $b(11)$:
{(1a)} De $a(11) = 144$ maneiras.
{(1b)} De $b(11) = 504$ maneiras.
\eop
{(2)} Usamos \dq{$n\to m$} para \wq{pula diretamente do degrau $n$ para o degrau
$m$} e \dq{$n\transto m$} para \wq{vai do degrau $n$ para o degrau $m$ pulando
num jeito}.
{(2a)} Para conseguir subir, Aleco necessariamente precisa chegar no degrau
$5$, saltar até o degrau $7$, e depois continuar até o degrau $11$.
Formamos cada maneira então em passos, e usando o princípio da multiplicação
achamos que Aleco tem
$$
\mubrace {a(5)}        {0 \transto 5} \ntimes
\mubrace {\vphantom(1} {5 \to 7}      \ntimes
\mubrace {a(4)}        {7 \transto 11}
= 8 \ntimes 1 \ntimes 5
= 40
$$
maneiras de subir a escada toda.
{(2b)}
Para o Bego a situação não é tão simples, porque ele pode evitar a cobra de vários jeitos.
Vamos agrupá-los assim:
\tlist:
\li (i):   aqueles onde ele pulou a cobra com salto de tamanho 2;
\li (ii):  aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 5;
\li (iii): aqueles onde ele pulou a cobra com salto de tamanho 3 desde o degrau 4.
\endtlist
Contamos as maneiras em cada grupo como na questão anterior, e no final as somamos (princípio da adição) para achar a resposta final: Bego tem
$$
\tobrace {
\mubrace {b(5)}         {0 \transto 5}  \ntimes
\mubrace {\vphantom(1}  {5 \to 7}       \ntimes
\mubrace {b(4)}         {7 \transto 11}
} {grupo (i)}
+
\tobrace {
\mubrace {b(5)}         {0 \transto 5}  \ntimes
\mubrace {\vphantom(1}  {5 \to 8}       \ntimes
\mubrace {b(3)}         {8 \transto 11}
} {grupo (ii)}
+
\tobrace {
\mubrace {b(4)}         {0 \transto 4}  \ntimes
\mubrace {\vphantom(1}  {4 \to 7}       \ntimes
\mubrace {b(4)}         {7 \transto 11}
} {grupo (iii)}
= 13 \ntimes 7 + 13 \ntimes 4 + 7 \ntimes 7
= 192
$$
maneiras de subir a escada toda.
\eop
{(3)}
Pela definição, a probabilidade que Cátia morra é a fracção
$$
\frac
{\text{todas as maneiras em quais Bego pisou no degrau 6}}
{\text{todas as maneiras possíveis}}\,,
$$
ou seja,
$$
\frac {504-192} {504}
= \frac {312} {504}
= \frac {156} {252}
= \frac {78} {126}
= \frac {39} {63}
= \frac {13} {21}
\,.
$$

%%}}}

%%{{{ prob: band_maker 
\problem.
%%%{{{ meta 
\label band_maker
%%%}}}

Temos $6$ músicos disponíveis, onde cada um toca:
\ttable
\hfil##  & ##\hfil                 & \quad\hfil## & ##\hfil \cr
Alex:    & violão, guitarra, baixo & Daniel:      & guitarra \cr
Beatriz: & bateria                 & Eduardo:     & piano, teclado, violão, fláuto \cr
Cynthia: & saxofone, clarineto     & Fagner:      & guitarra, baixo, teclado \cr
\endttable
(Considere que uma banda precisa \emph{pelo menos um membro},
todos os membros duma banda \emph{precisam tocar pelo menos algo na banda},
e que cada banda é diferenciada pelos músicos e
suas funções.
Por exemplo: uma banda onde Alex toca o violão (apenas) e Beatriz a bateria,
é diferente duma banda onde
Alex toca o violão \emph{e} a guitarra, e Beatriz a bateria,
mesmo que seus membros são os mesmos.
\tlist:
\li (1):
Quantas bandas diferentes podemos formar?
\li (2):
Quantas bandas diferentes podemos formar com a restricção que nenhum
músico tocará mais que um instrumento na banda (mesmo se em geral sabe tocar mais)?
\li (3):
Quantas bandas diferentes podemos formar onde todos os
músicos fazem parte da banda?
\endtlist

\solution
\proofpart {(1):}
$2^{14}-1$: para cada músico e cada instrumento, temos 2 opções: ``sim'' ou ``não''.
Tiramos $1$ porque hipercontamos (a ``banda vazia'').
\crproofpart {(2):}
Cada músico que toca $i$ instrumentos tem $i+1$ opções
(a extra $+1$ corresponde no ``não participar na banda''):
podemos formar $4 \ntimes 2 \ntimes 3 \ntimes 2 \ntimes 5 \ntimes 4 - 1$ bandas,
onde de novo tiramos 1 para excluir a ``banda vazia''.
\crproofpart {(3):}
Cada músico que toca $i$ instrumentos tem $2^i - 1$ opções
(tirando a opção de ``não tocar nada'').
Então podemos formar $7\ntimes 1 \ntimes 3 \ntimes 1 \ntimes 15 \ntimes 7$ bandas.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string ternário
(usando o alfabeto $\set{0, 1, 2}$)
de tamanho 7,
tais que \emph{não aparece neles o substring $00$}.
\eop
Por exemplo:
$$
\align
0112220                                           &\qquad\text{é um string aceitável;}\\
2\underline{00}1\underline{0\overline0}\overline0 &\qquad\text{não é.}
\endalign
$$

\hint
Recursão.

\hint
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.

\hint
Defina a $a(n)$ e depois calcule o $a(7)$, calculando em ordem os
$a(0),a(1),\dotsc,a(7)$.

\solution
Seja $a(n)$ o número dos strings ternários de tamanho $n$ tais que não aparece
neles o substring ${00}$.
Queremos achar o $a(7)$.
\eop
Observe que:
$$
\align
    a(0) &= 1 \qqqquad\explanation{o string vazio: ``$\,$''} \\
    a(1) &= 3 \qqqquad\explanation{os strings: ``$0$'', ``$1$'', e ``$2$''} \\
    a(n) &=
      \underbrace{a(n-1)}_{1\ldots}
    + \underbrace{a(n-1)}_{2\ldots}
    + \underbrace{a(n-2)}_{{01}\ldots}
    + \underbrace{a(n-2)}_{{02}\ldots}\\
         &= 2a(n-1) + 2a(n-2)\\
         &= 2(a(n-1) + a(n-2))
\endalign
$$
Então calculamos os primeiros $8$ termos da seqüência:
$$
1,\quad 3,\quad 8,\quad 22,\quad 60,\quad 164,\quad 448,\quad \underbrace{1224}_{a(7)}.
$$

%%}}}

%%{{{ prob: pessimissimo 
\problem.
%%%{{{ meta 
\label pessimissimo
%%%}}}

Contar todas as palavras feitas por permutações das 12 letras da palavra
$$
\txt{PESSIMISSIMO}
$$
onde\dots
% TODO: fix reflabs
\tlist:
\li (1): a palavra começa com $\txt P$;
\li (2): todos os $\txt I$ aparecem \emph{juntos}\/;
\li (3): os $\txt M$ aparecem \emph{separados}\/;
\li (4): nenhum dos $\txt S$ aparece ao lado de outro $\txt S$.
\endtlist

\hint
Para o (4), seria diferente se a restricção fosse
``os $\txt S$ não aparecem todos juntos''.

\solution
(1):
Como somos obrigados começar a palavra com ${\txt P}$,
precisamos apenas contar as permutações das letras da palavra
$
\txt{ESSIMISSIMO}
$,
que sabemos que são
$$
\frac
{11!}
{4!\stimes3!\stimes 2!}.
$$
\eop\medskip\noi
(2):
Podemos considerar que temos apenas um $I$:
$
\dfrac
 {10!}
 {4!\stimes  2!}
$
\eop\medskip\noi
(3):
Contamos em quantas palavras eles aparecem juntos,
e usando princípio da adição, os subtraimos das permutações sem restricção.
$$
\underbrace{
\,
\dfrac
 {12!}
 {4!\stimes  3!\stimes  2!}
\,
}_{\text{todas}}
 -
\underbrace{
\,
\dfrac
 {11!}
 {4!\stimes  3!}
\,
}_{\text{$\txt M$ juntos}}
$$
\eop\medskip\noi
(4):
Construimos cada dessas palavras em passos.
Primeiramente escolhemos uma das permutações da palavra sem os ${\txt M}$'s:
$$
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}*
\phantom{\underline{\phantom{{\txt M}}}}
$$
(temos 
$
\dfrac
{8!}
{3!\stimes 2!}
$
opções).
\eop
\medskip
No próximo passo escolemos em qual das $9$ posições possíves colocamos os $M$:
$$
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}*
\underline{\phantom{{\txt M}}}
$$
Pelo princípio da multiplicação então, temos
$
\dfrac
{8!}
{3!\stimes 2!}
\cdot
\comb 9 4
$
palavras que satisfazem essa restricção.

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
% TODO: fix reflabs
%%%}}}

De quantas maneiras podemos escrever um string usando o alfabeto
de 26 letras
$$
\txt A, \txt B, \txt C, \dotsc, \txt X, \txt Y, \txt Z,
$$
tais que as vogais aparecem na ordem estrita alfabética,
e as consoantes na ordem oposta?
(As vogais sendo as letras $\txt A$, $\txt E$, $\txt I$, $\txt O$,
$\txt U$, $\txt Y$.)
{Por exemplo:}
$$
\align
\txt{TEDUCY}    &\qquad\text{é um string aceitável};\\
\txt{DETUCY}    &\qquad\text{não é ($\txt D \not> \txt T$)};\\
\txt{TEDUCA}    &\qquad\text{não é ($\txt U \not< \txt A$)}.
\endalign
$$
\tlist:
\li (1): \dots se os strings são de tamanho 26 e os vogais aparecem todos juntos;
\li (2): \dots se os strings são de tamanho 12 e aparecem todos os vogais;
\li (3): \dots se os strings são de tamanho 3;
\li (4): \dots se os strings são de tamanho $\ell$, com $0\leq\ell\leq 26$.
\endtlist

\solution
(1)
Como a ordem das consoantes e das vogais é predeterminada e as vogais devem aparecer juntas,
a única escolha que precisamos fazer é onde colocar as vogais, e temos $21$ possíveis posições.
Então existem $21$ tais strings.
\eop\medskip\noi
(2)
$$
\tubrace {\comb {20} 6} {consoantes},
\tubrace {\comb {12} 6} {suas posições}.
$$
\eop\medskip\noi
(3)
Separamos todos os strings que queremos contar em quatro grupos e contamos cada um separadamente:
$$
{
\tobrace {
\tubrace {\comb {20} 3} {as c.}
} {3 c., 0 v.}
}
+
{
\tobrace {
\tubrace {\comb {20} 2} {as c.}
\tubrace {\comb 6 1} {a v.}
\tubrace {\comb 3 2} {pos.~c.}
} {2 c., 1 v.}
}
+
\tobrace {
\tubrace {\comb {20} 1} {a c.}
\tubrace {\comb 6 2} {as v.}
\tubrace {\comb 3 1} {pos.~c.}
} {1 c., 2 v.}
+
\tobrace {
\tubrace {\comb 6 3} {as v.}
} {0 c., 3 v.}.
$$
Podemos descrever o resultado numa forma mais uniforme e mais fácil para generalizar:
$$
\Sum_{i=0}^3
\tubrace {\comb {20} {3-i}} {as $3-i$ c.}
\tubrace {\comb 6 i} {as $i$ v.}
\tubrace {\comb 3 i} {pos.~v.}
=
\Sum\submath{c+v=3\\c,v\in\nats}
\tubrace {\comb {20} c} {as c.}
\tubrace {\comb 6 v} {as v.}
\tubrace {\comb 3 v} {pos.~v.}
$$
\eop\medskip\noi
(4)
Seguindo a última forma do (3), temos
$$
\Sum_{i=0}^{\ell}
\tubrace {\comb {20} {\ell-i}} {as $\ell-i$ c.}
\tubrace {\comb 6 i} {as $i$ v.}
\tubrace {\comb {\ell} i} {pos.~v.}
$$
maneiras.  O somatório pode ser escrito também assim:
$$
\Sum
\bigg\{
\tubrace {\comb {20} c} {as c.}
\tubrace {\comb 6 v} {as v.}
\tubrace {\comb {\ell} v} {pos.~v.}
\ \Big|\ 
c+v=\ell, \ 0\leq c \leq 20, \ 0\leq v \leq 6, \ c,v\in\nats
\bigg\}.
$$
Note que como o conjunto acima é finito,
a adição é comutativa e associativa; logo, nosso somatório é bem-definido.

%%}}}

%%{{{ prob: roulette_multiple_balls 
\problem.
%%%{{{ meta 
\label roulette_multiple_balls
%%%}}}

Numa roleta dum cassino tem ``pockets'' (ou ``casas'') numerados com:
$$
00, 0, 1, 2, \dotsc, 36
$$
e cada um deles é suficientemente profundo para caber até 8 bolinhas.
O crupiê joga 8 bolinas na roleta no mesmo tempo.
De quantas maneiras elas podem cair nos pockets se\dots
\tlist:
\li (i):  \dots as bolinhas são distintas e não importa sua ordem dentro um pocket.
\li (ii): \dots as bolinhas são todas iguais.
\endtlist

\solution
\tlist:
\li (i):  Permutações com repetições: $38^8$.
\li (ii): Combinações com repetições: $\comb {38 + 8 - 1} 8 = \comb {45} 8$.
\endtlist

%%}}}

%%{{{ prob 
\problem.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos escrever um string usando
letras do alfabeto $\set{\txt A, \txt B, \txt C, \txt D}$,
tais que \emph{cada letra é usada exatamente duas vezes
mas não aparece consecutivamente no string}?
Por exemplo:
$$
\align
\txt{ABADCDBC}                      &\qquad\text{é um string aceitável;}\\
\txt{ABAC$\underline{\txt{DD}}$BC}  &\qquad\text{não é.}
\endalign
$$

\hint
Inclusão--exclusão.

\hint
Considere as propriedades:
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$

\solution
Seja $N$ o número de permutações totais das létras
e defina as 4 propriedades
$$
\xalignat 4
 \alpha  &: \text{aparece o $\txt{AA}$}
&\beta   &: \text{aparece o $\txt{BB}$}
&\gamma  &: \text{aparece o $\txt{CC}$}
&\delta  &: \text{aparece o $\txt{DD}$}.
\endxalignat
$$
Procuramos o número dos strings de tamanho 8 que não tenham nenhuma dessas 4 propriedades.
Assim que calcular os $N(\alpha),\dotsc,N(\alpha,\beta,\gamma,\delta)$
o princípio da inclusão--exclusão, vai nos dar o número que procuramos.
\eop
Observamos que
$$
\gather
N(\alpha) =N(\beta) =N(\gamma) =N(\delta)\\
N(\alpha,\beta) =N(\alpha,\gamma) = \dotsb = N(\gamma,\delta)\\
N(\alpha,\beta,\gamma) = \dotsb = N(\beta,\gamma,\delta).
\endgather
$$
\eop
Calculamos os
$$
\align
N
&= \frac {8!} {2!\stimes 2!\stimes 2!\stimes 2!} = 2520\\
N(\alpha)
&= \frac {7!} {2!\stimes 2!\stimes 2!} = \frac {7!} 8 = 7\ntimes 6 \ntimes 5 \ntimes 3 = 630\\
N(\alpha,\beta)
&= \frac {6!} {2!\stimes 2!} = \frac {6!} 4 = 180 \\
N(\alpha,\beta,\gamma)
&= \frac {5!} {2!} = \frac {5!} 2 = 60 \\
N(\alpha,\beta,\gamma,\delta)
&= {4!} = 24.
\endalign
$$
\eop
Para responder, temos
$$
\multline
    N
    - \comb 4 1 N(\alpha)
    + \comb 4 2 N(\alpha,\beta)
    - \comb 4 3 N(\alpha,\beta,\gamma)
    + N(\alpha,\beta,\gamma,\delta)\\
    =
    2520 - 4\ntimes 630 + 6\ntimes 180 - 4\ntimes 60 + 24
    =
    864
\endmultline
$$
tais permutações.

%%}}}

%%{{{ prob: parity_respecting_strings_mutual_recursion 
\problem.
%%%{{{ meta 
\label parity_respecting_strings_mutual_recursion
%%%}}}

De quantas maneiras podemos escrever um string binário
(usando o alfabeto $\set{0, 1}$) de tamanho 12,
tais que: 
\elist i:
\li: os $0$'s aparecem apenas em grupos maximais de tamanho par;
\li: os $1$'s aparecem apenas em grupos maximais de tamanho ímpar.
\endelist
Por exemplo:
$$
\align
{000000111001}                         &\qquad\text{é um string aceitável;}\\
{100\underline{11}001\underline{000}1} &\qquad\text{não é.}
\endalign
$$

\hint
Separe os strings em dois grupos,
aqueles que terminam em $0$ e aqueles que terminam em $1$,
e conta os strings de cada grupo usando recursão.

\hint
Sejam $a(n)$ e $b(n)$ o número de strings binários de tamánho $n$
que terminam em $0$ e em $1$ respectivamente.

%%}}}

%%{{{ prob: xyzzy_lemmings 
\problem.
%%%{{{ meta 
\label xyzzy_lemmings
\pdefs
    \pdef FB {{\mathtt F}}
    \pdef MM {{\mathtt M}}
    \pdef ST {{\mathtt B}}
    ;;
%%%}}}

Xÿźźÿ o Mago Bravo decidiu matar todos os lemmings que ele guarda no seu quintal.
Seus feitiços são os:
\tlist:
\li: ``magic missile'', que mata 2 lemmings simultaneamente, e gasta 1 ponto ``mana'';
\li: ``fireball'', que mata 3 lemmings simultaneamente, e gasta 2 pontos mana.
\endtlist
Além dos feitiços, Xÿźźÿ pode usar seu bastão para matar
os lemmings (que não custa nada, e mata 1 lemming com cada batida).
\eop
Suponha que o mago \emph{nunca} lançará um feitiço que mataria mais lemmings do
que tem (ou seu quintal vai se queimar).
Ele tem $m$ pontos mana e existem $n$ lemmings no seu quintal.
Em quantas maneiras diferentes ele pode destruir todos os lemmings se\dots
\elist i:
\li: os lemmings são indistinguíveis?
\li: os lemmings são distinguíveis?
\li: os lemmings são distinguíveis e cada vez que Xÿźźÿ mata um usando seu bastão,
ele \emph{ganha} um ponto de mana?
\endelist
(Para os casos que os lemmings são distinguíveis,
o mago escolhe também \emph{quais} dos lemmings ele matará cada vez.)

\hint
Recursão.

\hint
Seja $f(m,n)$ o número de maneiras que Xÿźźÿ pode matar todos os $n$ lemmings,
começando com $m$ pontos de mana.

%%}}}

\endproblems
%%}}}

%%{{{ History 
\history.

Pascal não foi o primeiro de estudar o ``triângulo aritmético'',
cuja existência e sua relação com o teorema binomial já eram
conhecidas desde uns séculos antes do seu nascimento.
Mesmo assim, seu estudo
\emph{``Traité du triangle arithmétique,
avec quelques autres petits traitez
sur la mesme matière''},
publicado no ano \yearof{1654} (depois da sua morte)
popularizou o triângulo e suas diversas aplicações e
propriedades~(\cite[pascaltriangle]).

\endhistory
%%}}}

%%{{{ Further reading 
\further.

Veja o~\cite[nivencount].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: The_reals 
\chapter Os reais.
%%%{{{ meta 
\label The_reals
\pdefs
    \pdef Pos {\mathord{\mathrm{Pos}}}
    \pdef Neg {\mathord{\mathrm{Neg}}}
    ;;
%%%}}}

\TODO limpar, terminar, organizar.

%%{{{ intro 
\chapintro
Os reais formam um \emph{corpo ordenado completo}.
Neste capítulo vamos estudar o que isso significa e investigar
umas conseqüências dos axiomas dos reais.
Além disso, vamos definir e estudar os conceitos fundamentais
de limites e séries.
%%}}}

%%{{{ Constructing_the_rationals 
\section Construindo os racionais.
%%%{{{ meta 
\label Constructing_the_rationals
%%%}}}

\TODO x to Q.

%%{{{ x: canonical_representation_with_int_exponents 
\exercise.
%%%{{{ meta 
\label canonical_representation_with_int_exponents
%%%}}}

O que acontece se relaxar a restricção nos exponentes ainda mais?:
$a_i\in\ints$.\foot
Essa pergunta é para o leitor que já viu algo que não encontramos ainda aqui.
\toof

%%}}}

\endsection
%%}}}

%%{{{ Back to Ancient Greece: irrationals 
\section De volta pra Grécia antiga: racionais e irracionais.
%%%{{{ meta 
%%%}}}

%%{{{ √2 is not rational 
\note O √2 não é racional.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ But √2 surely is a number 
\note Mas o √2 com certeza é um número.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Irrational numbers 
\note Números irracionais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ √3 is irrational 
\note O √3 é irracional.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ A lemma 
\note Um lemma.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ What happens with √4 and √5 
\note O que acontece com √4 e √5.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ A generalization theorem 
\note Um teorema de generalização.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ More irrational numbers 
\note Mais números irracionais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Algebraic and transcendental numbers 
\note Números algébricos e transcendentais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ The_real_line 
\section A reta real.
%%%{{{ meta 
\label The_real_line
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ First steps 
\section Primeiros passos.
%%%{{{ meta 
%%%}}}

%%{{{ spec: real_spec_1 
\specification Os reais (1/3).
%%%{{{ meta 
\label real_spec_1
\defines
    * reais
    ;;
%%%}}}

Usamos $\Real$ para denotar um tipo cujos membros chamamos de (números) reais
e onde temos os seguintes componentes primitivos:
\mathcols 3
(+), (\ntimes)  &\is \Real \times \Real \to \Real &
0, 1            &\is \Real &
(-)             &\is \Real \to \Real.
\endmathcols
Estipulamos as proposições seguintes como axiomas:
\mathcol
\cforall {a,b,c}  {(a + b) + c = a + (b + c)}   \stag[RA-Ass]\\
\cforall {a}      {0 + a = a = a + 0}           \stag[RA-Id]\\
\cforall {a,b}    {a + b = b + a}               \stag[RA-Com]\\
\cforall {a}      {(-a) + a = 0 = a + (-a)}     \stag[RA-Inv]\\
\\
\cforall {a,b,c}  {a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c}
                                                \stag[RM-Ass]\\
\cforall {a}      {1\ntimes a = a = a\ntimes 1} \stag[RM-Id]\\
\cforall {a,b}    {a\ntimes b = b \ntimes a}    \stag[RM-Com]\\
\cforall {a}      {a\neq 0 \implies
                   \lexists {a'} {a' \ntimes a = 1 = a \ntimes a'}}
                                                \stag[RM-Inv*]\\
\\
\cforall {d,a,b}  {d \ntimes (a+b) = (d \ntimes a) + (d \ntimes b)
	    \mland (a+b) \ntimes d = (a \ntimes d) + (b \ntimes d)}
	                                        \stag[R-Dist]\\
\\
&{0 \neq 1}.                                    \stag[R-NZero]
\endmathcol

%%}}}

%%{{{ remark: axioms_stronger_than_needed
\remark Axiomas mais fortes do que precisamos.
%%%{{{ meta 
\label axioms_stronger_than_needed
%%%}}}

Observe que tanto sobre as identidades quanto sobre os inversos,
optamos para incluir nos axiomas \dq{ambos os lados}.
Compare isso com os axiomas que tivemos sobre os inteiros,
onde \emph{demonstramos como teorema} que $0$ é uma
$(+)$-identidade-L, e as demais versões esquerdas
(\ref[int_left_versions_as_theorems]).
A demonstração foi simplíssima, graças às comutatividades
das operações, que aqui também temos.
Ou seja, a gente poderia ter escolhido uma abordagem parecida aqui,
mas não é sempre tão importante se obsecar economizando
nos axiomas.  Listados na maneira que tenho acima, tem
uma outra vantagem: não passam uma informação falsa sobre nossa
pretenção, e, além disso, seria mais facil se perguntar
<<o que acontece se apagar comutatividade de tal lista?>>,
sem precisar nos preocupar para adicionar explicitamente
as identidades e inversos esquerdos.

%%}}}

%%{{{ Syntactic considerations 
\note Considerações sintácticas.
%%%{{{ meta 
\defines
    * associatividade!sintáctica
    ;;
%%%}}}

Atribuimos as mesmas \dterm{associatividades sintácticas} e as mesmas
\dterm{precedências sintácticas} nas operações $(+)$ e $(\ntimes)$
que atribuimos no \ref[The_integers] (\ref[int_syntactic_associativities],
\ref[int_syntactic_precedence], \ref[int_juxtaposition_notation]).
Similarmente usamos as abreviações
\mathcols 4
2 &\eqtype \Real  & 3 &\eqtype \Real  & 4 &\eqtype \Real &~&\cdots \\
2 &\defeq  1 + 1  & 3 &\defeq  2 + 1  & 4 &\defeq  3 + 1 &~&\cdots \\
\endmathcols
como fizemos no \ref[int_numerals_and_powers].

%%}}}

%%{{{ df: real_subtraction_as_syntactic_sugar 
\definition Açúcar sintáctico: subtração.
%%%{{{ meta 
\label real_subtraction_as_syntactic_sugar
\indexes
    * notação!sobrecarregar   see: sobrecarregamento
    * sobrecarregamento!notação
    ;;
\defines
    * subtração!nos reais
    ;;
%%%}}}

Como nos inteiros (\ref[int_subtraction_as_syntactic_sugar]),
definimos a operação \emph{binária}
\mathcol
(-) &\eqtype \Real \times \Real \to \Real \\
\endmathcol
de subtração pela
\mathcol
a - b &\defeq a + (-b).
\endmathcol
Novamente o símbolo \sq{$-$} tá sendo \dterm{sobrecarregado} mas
o contexto sempre deixa claro qual das
\mathcols 2 (-{\uhole})         &\eqtype \Real \to \Real  &
({\uhole}-{\uhole}) &\eqtype \Real \times \Real \to \Real
\endmathcols
está sendo usada.

%%}}}

%%{{{ x: real_uniqueness_of_additive_identity 
\exercise Unicidade da identidade aditiva.
%%%{{{ meta 
\label real_uniqueness_of_additive_identity
%%%}}}

Existe único $z$ tal que para todo $x$, $z + x = x = x + z$.

\solution
Demonstrado no \ref[int_uniqueness_of_additive_identity], pois
tal demonstração precisou apenas axiomas que temos aqui também.

%%}}}

%%{{{ x: real_uniqueness_of_additive_inverses 
\exercise Unicidade dos inversos aditivos.
%%%{{{ meta 
\label real_uniqueness_of_additive_inverses
%%%}}}

Para todo $x$, existe único $x'$ tal que $x' + x = 0 = x + x'$.

\solution
Demonstrado no \ref[int_uniqueness_of_additive_inverses], pois
tal demonstração precisou apenas axiomas que temos aqui também.

%%}}}

%%{{{ x: real_uniqueness_of_solutions 
\exercise Unicidade de resoluções.
%%%{{{ meta 
\label real_uniqueness_of_solutions
%%%}}}

Para quaisquer $a,b$, existe único $x$ tal que $a + x = b$
e existe único $y$ tal que $y + a = b$.

\solution
Utilizamos a mesma demonstração do \ref[int_uniqueness_of_solutions_proof],
já que ela não precisou nenhum axioma que não temos aqui.

%%}}}

%%{{{ x: real_neg_of_neg 
\exercise Negação de negação.
%%%{{{ meta 
\label real_neg_of_neg
%%%}}}

Para todo $x$, $-(-x) = x$.

\solution
Veja o \ref[int_neg_of_neg]: não precisou nenhum axioma que não temos.

%%}}}

%%{{{ x: real_neg_of_sum 
\exercise Negação de soma.
%%%{{{ meta 
\label real_neg_of_sum
%%%}}}

Para quaisquer $a,b$, temos $-(a-b) = b - a$ e $-(a+b) = -a-b$.

%%}}}

% enter multiplication

%%{{{ x: real_cancellation_law_for_addition
\exercise Lei de cancelamento aditivo.
%%%{{{ meta 
\label real_cancellation_law_for_addition
%%%}}}

Temos:
\mathcol
\cforall {a,b,c}  {\paren {c + a = c + b \implies a = b} \mland
                   \paren {a + c = b + c \implies a = b}}. \stag[RA-Can] \\
\endmathcol

\solution
Feito no \ref[int_cancellation_law_for_addition_proof].

%%}}}

%%{{{ x: real_zero_annihilator 
\exercise Anulador.
%%%{{{ meta 
\label real_zero_annihilator
%%%}}}

Demonstre que $0$ é um $(\ntimes)$-anulador:
\mathcol
\cforall {a}      {0 \ntimes a = 0 = a \ntimes 0}.   \stag[R-Ann] \\
\endmathcol

%%}}}

%%{{{ x: real_zero_has_no_multipliative_inverse 
\exercise.
%%%{{{ meta 
\label real_zero_has_no_multipliative_inverse
%%%}}}

Demonstre que $0$ não possui $(\ntimes)$-inverso.

%%}}}

%%{{{ x: real_neg_is_mult_neg_unit 
\exercise.
%%%{{{ meta 
\label real_neg_is_mult_neg_unit
%%%}}}

Para todo $a$ real, $-a = (-1)a$.

\solution
Seja $a$ real.
Calculamos:
\compute
a + a(-1)
&= a1 + a(-1)   \by {\reftag[RM-Id]} \\
&= a(1 + (-1))  \by {\reftag[R-Dist]} \\
&= a0           \by {\reftag[RA-Inv]} \\
&= 0.           \by {\reftag[R-Ann]}
\endcompute
Como $a + (-a) = 0$ (pela (RA-Inv)), logo $-a = a(-1)$ pela (R-ResR).

%%}}}

%%{{{ x: real_product_and_neg 
\exercise.
%%%{{{ meta 
\label real_product_and_neg
%%%}}}

$\lforall {a,b} {(-a)b = -(ab) = a(-b)}$.

%%}}}

%%{{{ x: real_product_with_two_minuses 
\exercise.
%%%{{{ meta 
\label real_product_with_two_minuses
%%%}}}

Para quaisquer $a,b$, $(-a)(-b) = ab$.

%%}}}

%%{{{ x: real_uniqueness_of_multiplicative_identity 
\exercise Unicidade da identidade multiplicativa.
%%%{{{ meta 
\label real_uniqueness_of_multiplicative_identity
%%%}}}

Existe único $u$ tal que para todo $x$, $ux = x = xu$.

\solution
Demonstrado no \ref[int_uniqueness_of_multiplicative_identity], pois
tal demonstração precisou apenas axiomas que temos aqui também.

%%}}}

%%{{{ x: real_uniqueness_of_multiplicative_inverses 
\exercise Unicidade dos inversos multiplicativos.
%%%{{{ meta 
\label real_uniqueness_of_multiplicative_inverses
%%%}}}

Para todo $x\neq 0$, existe único $x'$ tal que $x'x = 1 = xx'$.

\solution
Seja $x \neq 0$ e sejam $x', x''$ $(\ntimes)$-inversos de $x$.
Preciso demonstrar que $x' = x''$.
Calculamos:
\compute
x'
&= x'1       \by {$1$ é uma $(\ntimes)$-identidade-R} \\
&= x'(xx'')  \by {$x''$ é um $(\ntimes)$-inverso-R de $x$} \\
&= (x'x)x''  \by {$(\ntimes)$-assoc.} \\
&= 1x''      \by {$x'$ é um $(\ntimes)$-inverso-L de $x$} \\
&= x''.      \by {$1$ é uma $(\ntimes)$-identidade-R}
\endcompute

%%}}}

% enter inverses

%%{{{ notation: real_inv_notation 
\notation Inverso multiplicativo.
%%%{{{ meta 
\label real_inv_notation
\defines
    * {{~a}^{-1}}  -- o inverso multiplicativo do real $a$
    ;;
%%%}}}

Seja $a \neq 0$.
Denotamos por $a^{-1}$ o seu $(\ntimes)$-inverso, ou seja,
o único real $a'$ tal que $a'a = 1 = aa'$.

%%}}}

%%{{{ x: real_cancellation_law_for_multiplication 
\exercise Lei de cancelamento multiplicativo.
%%%{{{ meta 
\label real_cancellation_law_for_multiplication
%%%}}}

Temos:
\mathcol
\cforall {c,a,b}  {c \neq 0 \implies \paren{ca = cb \implies a = b} \mland \paren{ac = bc \implies a = b}}. \stag[R-Can] \\
\endmathcol

%%}}}

%%{{{ x: real_inv_of_inv 
\exercise Inverso de inverso.
%%%{{{ meta 
\label real_inv_of_inv
%%%}}}

Para todo $x\neq 0$, $\minvp {\minv x} = x$.

%%}}}

%%{{{ x: real_inv_of_prod 
\exercise Inverso de produto.
%%%{{{ meta 
\label real_inv_of_prod
%%%}}}

Para quaisquer $a,b \neq 0$, $\minvp {ab} = \minv a \minv b$.

%%}}}

%%{{{ x: real_nzd 
\exercise R-NZD.
%%%{{{ meta 
\label real_nzd
%%%}}}

$\lforall {a,b} {ab = 0 \implies a = 0 \mlor b = 0}$.

%%}}}

% enter fractions

%%{{{ df: real_fraction_as_syntactic_sugar
\definition Açúcar sintáctico: fracção.
%%%{{{ meta 
\label real_fraction_as_syntactic_sugar
\defines
    * fracção!nos reais
    ;;
%%%}}}

Dados $a,b$ com $b\neq0$, escrevemos $a/b$ ou $\frac a b$ como
açúcar sintáctico para o produto $a\ntimes b^{-1}$.
Note que as notações $1/b$ e $\frac 1 b$ são casos especiais disso.

%%}}}

%%{{{ x: real_product_of_fractions 
\exercise Produto de fracções.
%%%{{{ meta 
\label real_product_of_fractions
%%%}}}

Para quaisquer $a,b,c,d$ com $b,d \neq 0$, temos:
$$
\frac a b \ntimes \frac c d = \frac {a \ntimes c} {b \ntimes d}.
$$

%%}}}

%%{{{ x: real_sum_of_fractions 
\exercise Soma de fracções.
%%%{{{ meta 
\label real_sum_of_fractions
%%%}}}

Para quaisquer $a,b,c,d$ com $b,d \neq 0$, temos:
$$
\frac a b + \frac c d = \frac {a \ntimes d + b \ntimes c} {b \ntimes d}.
$$

%%}}}

%%{{{ x: real_fraction_of_fractions
\exercise Fracção de frações.
%%%{{{ meta 
\label real_fraction_of_fractions
%%%}}}

Para quaisquer $a,b,c,d$ com $b,c,d \neq 0$, temos:
$$
\frac {~\frac a b~} {~\frac c d~} = \frac {ad} {bc}.
$$

%%}}}

% enter powers

%%{{{ df: real_natural_powers 
\definition Potências naturais.
%%%{{{ meta 
\label real_natural_powers
%%%}}}

Já que agora possuimos mesmo o tipo $\Nat$, podemos definir
mesmo as potências naturais de qualquer real $x$, recursivamente,
como uma operação de tipo:
$$
(\expop) \is \Real \to \Nat \to \Real
$$
definida pelas
\mathcol
x^0     &\defeq 1 \\
x^{n+1} &\defeq x \ntimes x^n. \\
\endmathcol
Como acabemos de fazer aqui, denotamos a aplicação da $(\expop)$ nos argumentos
$a,b$ por $a^b$.

%%}}}

%%{{{ x: real_natural_powers_left_assoc 
\exercise.
%%%{{{ meta 
\label real_natural_powers_left_assoc
%%%}}}

Uma alternativa para definir as potências naturais dum real $x$ seria a seguinte:
\mathcol
x^0     &\defeq 1 \\
x^{n+1} &\defeq x^n \ntimes x. \\
\endmathcol
Demonstre que essas duas definições são equivalentes.  Mas cuidado!
Duas definições alternativas usando a mesma notação não ajuda em demonstrar
que são equivalentes.  Tu vai acabar escrevendo que precisa demonstrar que $x^n = x^n$,
parecendo algo trivial (por reflexividade), só que não é o caso, pois
num lado o $x^n$ é para seguir uma definição, e no outro outra!
Por isso precisamos alterar a notação da definição alternativa.
Sugiro assim:
\mathcol
\lexp x 0     &\defeq 1 \\
\lexp x {n+1} &\defeq \lexp x n \ntimes x. \\
\endmathcol
Agora sim, o que precisas demonstrar é fácil de escrever:
$$
\pforall {x \is \Real} \lforall {n \is \Nat} {\lexp x n = \rexp x n}.
$$

%%}}}

%%{{{ x: real_natural_powers_properties 
\exercise.
%%%{{{ meta 
\label real_natural_powers_properties
%%%}}}

Sejam $a$ real e $n,m$ naturais.
Logo:
\mathcol
a^{n+m} &= a^n \ntimes a^m \\
a^{n\ntimes m} &= (a^n)^m.
\endmathcol

%%}}}

%%{{{ remark: real_integral_powers_choice 
\remark Potências integrais: qual definição escolher?.
%%%{{{ meta 
\label real_integral_powers_choice
%%%}}}

Tendo o tipo dos inteiros $\Int$ gostariamos de estender
as potências dum real $x$ para permitir expoentes inteiros.
Parece que temos dois significados razoáveis para atribuir ao $x^{-n}$:
$$
x^{-n} \askeq
\paths
\paren{x^{-1}}^n & (o inverso de $x$, elevado ao natural $n$) \\
\pathween {\dots\orword\dots}
(x^n)^{-1}       & (o inverso de $x^n$)
\endpaths
$$
Felizmente as duas alternativas são equivalentes,
e logo não importa tanto qual das duas vamos escolher.
Demonstrarás isso agora no \ref[real_integral_powers_choices_are_equivalent],
e logo depois (\ref[real_integral_powers]) eu vou escolher uma para ser a definição mesmo.

%%}}}

%%{{{ x: real_integral_powers_choices_are_equivalent 
\exercise.
%%%{{{ meta 
\label real_integral_powers_choices_are_equivalent
%%%}}}

Demonstre que as duas interpretações da \ref[real_integral_powers_choice]
são equivalentes.

%%}}}

%%{{{ df: real_integral_powers 
\definition Potências integrais.
%%%{{{ meta 
\label real_integral_powers
%%%}}}

Definimos
$$
x^{-n} \defeq (x^n)^{-1}.
$$

%%}}}

% enter recursion and induction

%%{{{ x: sum_of_negative_powers_of_two_formula 
\exercise.
%%%{{{ meta 
\label sum_of_negative_powers_of_two_formula
%%%}}}

Observando os valores de:
$$
\align
    1
    +
    \frac 1 2
    &= 2 - \frac 1 2\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    &= 2 - \frac 1 4\\
    1
    +
    \frac 1 2
    +
    \frac 1 4
    +
    \frac 1 8
    &= 2 - \frac 1 8,
\intertext{adivinhe uma fórmula geral para o somatório}
    1 + \frac 1 2 + \frac 1 4 + \cdots + \frac 1 {2^n} &= \text{?}
\endalign
$$
e demonstre que ela é válida para todo $n\in\nats$.

%%}}}

\endsection
%%}}}

%%{{{ Notable_subsets 
\section Subconjuntos notáveis e inaceitáveis.
%%%{{{ meta 
\label Notable_subsets_of_reals 
%%%}}}

%%{{{ df: real_notable_subsets 
\definition.
%%%{{{ meta 
\label real_notable_subsets
\defines
    * real!inteiro
    * real!racional
    * real!irracional
    * real!algébrico
    * real!transcendental
    ;;
%%%}}}

Definimos os subconjuntos de reais seguintes:
\mathcols 2
&\text{os reais naturais:}   & \natreals &\pseudodefeq \set { 0, 1, 2, 3, \dotsc } \\
&\text{os reais inteiros:}   & \intreals &\alethodefeq \natreals \union \setst {-n} {n \in \natreals} \\
&\text{os reais racionais:}  & \ratreals &\alethodefeq \setst {m/n} {m \in \intreals, n \in {\reals_{\ints_{>0}}}} \\
&\text{os reais algébricos:} & \algreals &\alethodefeq \setstt {x} {$x$ é raiz dum polinómio com coeficientes inteiros}. \\
\endmathcols
Definimos também os \dterm{reais irracionais} $\reals \setminus \ratreals$
e os \dterm{reais transcendentais} $\reals \setminus \algreals$.
Quando pelo contexto é inferível que estamos referindo a um conjunto de reais,
é conveniente abusar a notação e escrever $\nats,\ints,\rats,\algs$ em vez de
$\natreals, \intreals, \ratreals, \algreals$, respectivamente.

%%}}}

%%{{{ beware: numerical_sets_are_incomparable 
\beware Um mal-entendido comum.
%%%{{{ meta 
\label numerical_sets_are_incomparable
%%%}}}

É comum ouvir e ler a seguinte bobagem matemática:
$$
\nats  \subset
\ints  \subset
\rats  \subset
\reals \subset
\complex
$$
e outras bizarrices similares.
Tais inclusões de conjuntos não fazem sentido.
Todos os números seguintes são pronunciados do mesmo jeito, \wq{zero},
e denotados pelo mesmo símbolo, \sq{$0$}:
\mathcols 5
0 &\is \Nat     &
0 &\is \Int     &
0 &\is \Rat     &
0 &\is \Real    &
0 &\is \Complex.
\endmathcols
Mas seria errado pensar que se trata do mesmo objeto, já que são objetos de tipos
diferentes e logo sequer faz sentido formular a pergunta se são iguais!
Por outro lado, no conjunto $\ints$ de inteiros existe um subconjunto dele
que serve como \emph{representação do conjunto dos naturais},
e que chamamos de \dterm{inteiros naturais:}
$$
\ints_\nats \defeq \setst {x \in \ints} {x \geq 0}.
$$
E agora sim temos $\ints_\nats \subset \ints$.
Similarmente, dentro do conjunto dos racionais, encontramos um subconjunto
para representar os inteiros, e logo herdamos também seu subconjunto como representante
dos naturais também:
$$
\rats_\nats \subset
\rats_\ints \subset
\rats.
$$
E nos reais temos
$$
\natreals \subset
\intreals \subset
\ratreals \subset
\reals.
$$
Mas sobre os
$$
\nats, \quad
\ints, \quad
\rats, \quad
\reals,
$$
o que podemos afirmar mesmo?
E o que nos permite abusar a notação e a linguagem os tratando como se fossem
subconjuntos mesmo?
O que temos mesmo são \emph{embutimentos que respeitam as estruturas}
$$
\nats \embto
\ints \embto
\rats \embto
\reals
$$
mas para entender o que essa frase significa vamos precisar de pouca paciência pois
as ferramentas necessárias encontraremos nos \ref[Functions], \ref[Group_theory],
e \ref[Algebraic_structures].
A situação vai ser esclarecida ainda mais no \ref[Set_theory] onde vamos
\emph{construir} mesmo todos esses conjuntos numéricos, em vez de tratá-los axiomaticamente,
como fazemos neste capítulo por exemplo sobre os reais,
e no \ref[The_integers] sobre os inteiros.
O contexto de tal construção é de fundamentos sem tipos (a teoria dos conjuntos),
então as perguntas são perguntáveis e mesmo assim todas vão acabar sendo refutáveis
com nossas construções:
$$
\nats \nsubset
\ints \nsubset
\rats \nsubset
\reals
$$
teremos testemunhas para cada uma dessas $(\nsubset)$:
membros do conjunto à esquerda que não pertencem ao conjunto à direita.

%%}}}

\endsection
%%}}}

%%{{{ Order_and_positivity_reals 
\section Ordem e positividade.
%%%{{{ meta 
\label Order_and_positivity_reals
%%%}}}

%%{{{ remark: alternative_specification_of_ordered_fields 
\remark Axiomatização alternativa.
%%%{{{ meta 
\label alternative_specification_of_ordered_fields
%%%}}}

Como discutimos no \ref[int_positivity_intro], podemos optar
para adicionar um predicado de positividade como noção primitiva,
e \emph{definir} as relações binárias $(<),(\leq),(>),(\geq)$,
ou escolher uma das relações binárias como primitiva e definir o resto.
Nos inteiros escolhemos a primeira abordagem.
Para variar, vamos tomar a $(>)$ como primitiva nos reais.
Mas, realmente, tanto faz.

%%}}}

%%{{{ spec: real_spec_2 
\specification Os reais (2/3).
%%%{{{ meta 
\label real_spec_2
\indexes
    * abuso notacional
    ;;
\defines
    * reais
    ;;
%%%}}}

Aumentamos a estrutura dos reais para
$$
\sset \reals {0,1,+,-,\ntimes,>}
$$
adicionando um predicado binário:
$$
(>) \is \Real \times \Real \to \Prop.
$$
Estipulamos os axiomas seguintes:
\mathcol
\cforall  {a,b,c} {a > b \mland b > c \implies a > c}     \stag[RO-Trans] \\
\cforallt {a,b}   {e.u.d.: $a > b$; $a = b$; $b > a$}
                                                          \stag[RO-Tri] \\
\cforall  {a,b,c} {a > b \implies a + c > b + c}          \stag[RO-A]   \\
\cforall  {a,b,c} {a > b \mland c > 0 \implies ac > bc}.  \stag[RO-M]   \\
\endmathcol
onde lembramos que <<e.u.d.>>~significa \emph{exatamente uma das}.

%%}}}

%%{{{ df: real_gt_related_notions
\definition.
%%%{{{ meta 
\label gt_in_ordered_fields
%%%}}}

Definimos as relações binárias $(<),(\leq),(\geq)$ pelas
\mathcols 3
x < y &\defiff y > x &
x \geq y &\defiff x > y \mlor x = y &
x \leq y &\defiff y \geq x,
\endmathcols
e o predicado unário $\Pos \is \Real \to \Prop$ pela
$$
\Pos(x) \defiff x > 0.
$$

%%}}}

%%{{{ x: real_sum_ineqs 
\exercise.
%%%{{{ meta 
\label real_sum_ineqs
%%%}}}

$\lforall {a,b,c,d} {a > b \mland c > d \implies a + c > b + d}$.

%%}}}

%%{{{ x: real_negation_of_pos_is_neg 
\exercise.
%%%{{{ meta 
\label real_negation_of_pos_is_neg
%%%}}}

$\lforall a {a > 0 \implies -a < 0}$.

%%}}}

%%{{{ x: real_negation_of_neg_is_pos 
\exercise.
%%%{{{ meta 
\label real_negation_of_neg_is_pos
%%%}}}

$\lforall a {a < 0 \implies -a > 0}$.

%%}}}

%%{{{ x: real_order_change_side 
\exercise.
%%%{{{ meta 
\label real_order_change_side
%%%}}}

$\lforall {a,b} {a > b \implies a - b > 0}$.

%%}}}

%%{{{ x: real_product_of_negs_is_pos 
\exercise.
%%%{{{ meta 
\label real_product_of_negs_is_pos
%%%}}}

$\lforall {a,b} {a < 0 \mland b < 0 \implies ab > 0}$.

%%}}}

%%{{{ x: real_square_of_nonzero_is_positive 
\exercise.
%%%{{{ meta 
\label real_square_of_nonzero_is_positive
%%%}}}

Se $a\neq 0$ então $a^2 > 0$.

%%}}}

%%{{{ x: real_square_of_small_is_smaller 
\exercise.
%%%{{{ meta 
\label real_square_of_small_is_smaller
%%%}}}

$\lforall a {0 < a < 1 \implies 0 < a^2 < a < 1}$.

%%}}}

%%{{{ x: real_one_is_positive 
\exercise.
%%%{{{ meta 
\label real_one_is_positive
%%%}}}

$1 > 0$.

%%}}}

%%{{{ x: real_plus_pos_increases 
\exercise.
%%%{{{ meta 
\label real_plus_pos_increases
%%%}}}

$\lforall {a,b} {b > 0 \implies a + b > a}$.

%%}}}

%%{{{ x: real_trichotomy_of_positivity 
\exercise Tricotomia da positividade.
%%%{{{ meta 
\label real_trichotomy_of_positivity
%%%}}}

Para todo $a$, exatamente uma das:
$a$ é positivo; $a = 0$; $-a$ é positivo.

%%}}}

%%{{{ x: real_pos_is_closed_under_addition 
\exercise.
%%%{{{ meta 
\label real_pos_is_closed_under_addition 
%%%}}}

O conjunto $\Pos$ é $(+)$-fechado.

%%}}}

%%{{{ x: real_pos_is_closed_under_multiplication 
\exercise.
%%%{{{ meta 
\label real_pos_is_closed_under_multiplication 
%%%}}}

O conjunto $\Pos$ é $(\ntimes)$-fechado.

%%}}}

%%{{{ x: real_times_negative_c_antimonotone 
\exercise.
%%%{{{ meta 
\label real_times_negative_c_antimonotone
%%%}}}

Se $a < b \mland c < 0$ então $ac > bc$.

%%}}}

%%{{{ x: real_negate_is_antimonotone 
\exercise.
%%%{{{ meta 
\label real_negate_is_antimonotone
%%%}}}

Se $a < b$ então $-a > -b$.

%%}}}

%%{{{ x: real_product_positive_means_samesign 
\exercise.
%%%{{{ meta 
\label real_product_positive_means_samesign
%%%}}}

Se $ab > 0$ então $a,b$ são ou ambos positivos ou ambos negativos.

%%}}}

%%{{{ x: real_squaring_preserves_and_reflects_orders 
\exercise.
%%%{{{ meta 
\label real_squaring_preserves_and_reflects_orders
\defines
    * ordem!preservar
    * ordem!refletir
    ;;
%%%}}}

A função $(\uhole^2)$ \dterm{preserve} e \dterm{reflete} a $(\leq)$ no $\nonnegs\reals$:
\mathcall
\cforall {a,b \geq 0} {a \leq b \implies a^2 \leq b^2}; \called {$(\uhole^2)$ preserve a $(\leq)$} \\
\cforall {a,b \geq 0} {a \leq b \impliedby a^2 \leq b^2}. \called {$(\uhole^2)$ reflete a $(\leq)$}
\endmathcall
E a mesma coisa sobre as outras ordens que temos definido até agora: $(<), (\geq), (>)$.

%%}}}

%%{{{ x: real_sum_of_squares 
\exercise.
%%%{{{ meta 
\label real_sum_of_squares
%%%}}}

Para todo $a,b$, temos $a^2 + b^2 \geq 0$.
Ainda mais: $a^2 + b^2 = 0$ sse $a = b = 0$.

%%}}}

%%{{{ x: complex_cannot_be_ordered_in_disguise 
\exercise.
%%%{{{ meta 
\label complex_cannot_be_ordered_in_disguise
%%%}}}

Não existe $x$ tal que $x^2 + 1 = 0$.

%%}}}

% inverses and fractions

%%{{{ x: real_inv_does_not_affect_positivity 
\exercise.
%%%{{{ meta 
\label real_inv_does_not_affect_positivity
%%%}}}

$\lforall a {a > 0 \iff a^{-1} > 0}$.

%%}}}

%%{{{ x: real_inv_is_antitone_for_pos 
\exercise.
%%%{{{ meta 
\label real_inv_is_antitone_for_pos
%%%}}}

$\lforall {a,b} {0 < a < b \implies 0 < b^{-1} < a^{-1}}$.

%%}}}

%%{{{ x: real_midpoint 
\exercise.
%%%{{{ meta 
\label real_midpoint
%%%}}}

$\lforall {a,b} {a < b \implies a < \frac 1 2 (a + b) < b}$.

%%}}}

%%{{{ x: real_halving_decreases_pos 
\exercise.
%%%{{{ meta 
\label real_halving_decreases_pos
%%%}}}

$\lforall a {0 < a \implies 0 < \frac 1 2 a < a}$.

%%}}}

% induction

%%{{{ x: one_minus_sum_of_1_over_n_formula 
\exercise.
%%%{{{ meta 
\label one_minus_sum_of_1_over_n_formula
%%%}}}

Calculando os valores de:
$$
    \paren{1 - \frac 1 2},
   \qquad
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3},
   \qquad
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4},
$$
adivinhe uma fórmula geral para o produtório
$$
\Prod_{i=2}^n\paren{ 1 - \frac 1 i}
=
    \paren{1 - \frac 1 2}
    \paren{1 - \frac 1 3}
    \paren{1 - \frac 1 4}
\dotsb
    \paren{1 - \frac 1 n}
$$
e demonstre que ela é válida para todo inteiro $n \geq 2$.

%%}}}

%%{{{ x: n_over_succ_n_formula 
\exercise.
%%%{{{ meta 
\label n_over_succ_n_formula
%%%}}}

Demonstre que para todo inteiro $n \geq 1$,
$$
    \frac 1 {1 \cdot 2} +
    \frac 1 {2 \cdot 3} +
    \frac 1 {3 \cdot 4} + \cdots +
    \frac 1 {n (n+1)}
    =
    \frac n {n+1}.
$$

%%}}}

%%{{{ x: bernoulli_ineq_0 
\exercise desigualdade Bernoulli (0).
%%%{{{ meta 
\label bernoulli_ineq_0
\credits
    * Bernoulli : desigualdade
    ;;
%%%}}}

Demonstre usando o teorema binomial que para todo real $x \geq 0$, e todo $n \geq 0$, temos
$$
(1 + x)^n \geq 1 + xn.
$$

\solution
Seja $n \in \nats$.
Pelo \ref[binomial_theorem] temos
\compute
(1+x)^n
&=    \Sum_{i=0}^n \binom n i 1^{n-i} x^i \noby \\
&=    \binom n 0 1^n x^0
      + \binom n 1 1^{n-1} x^1
      + \mobrace {\Sum_{i=2}^n \binom n i 1^{n-i} x^i} {(\geq 0)} \\
&\geq \binom n 0 1^n x^0
      + \binom n 1 1^{n-1} x^1 \\
&=    1 + nx.
\endcompute

%%}}}

%%{{{ x: bernoulli_ineq_1 
\exercise desigualdade Bernoulli (1).
%%%{{{ meta 
\label bernoulli_ineq_1
\credits
    * Bernoulli : desigualdade
    ;;
%%%}}}

Demonstre por indução que para todo real $x > -1$, e todo $n \geq 1$,
$
(1 + x)^n \geq 1 + xn.
$

%%}}}

%%{{{ x: bernoulli_ineq_2 
\exercise desigualdade Bernoulli (2).
%%%{{{ meta 
\label bernoulli_ineq_2
\credits
    * Bernoulli : desigualdade
    ;;
%%%}}}

Demonstre por indução que para todo real $x > -2$, e todo $n \geq 0$,
$
(1 + x)^n \geq 1 + xn.
$

\hint
Duas bases.

%%}}}

\endsection
%%}}}

%%{{{ Absolute_value_reals 
\section Valor absoluto.
%%%{{{ meta 
\label Absolute_value_reals
%%%}}}

%%{{{ df: real_abs 
\definition.
%%%{{{ meta 
\label real_abs
%%%}}}

Definimos a operação $\abs{\dhole} : \Real \to \Real$
$$
\abs x \defeq \cased {
x,  & caso $x \geq 0$; \\
-x, & caso $x < 0$. \\
}
$$

%%}}}

%%{{{ x: real_abs_properties_zero 
\exercise.
%%%{{{ meta 
\label real_abs_properties_zero
%%%}}}

$
\abs a = 0 \iff a = 0; \quad
\abs a \geq 0.
$

%%}}}

%%{{{ x: real_abs_lemma 
\exercise.
%%%{{{ meta 
\label real_abs_lemma
%%%}}}

$
\abs x \leq a
\iff
-a \leq x \leq a.
$

\hint
Para a \lrdir, obtenha $-a \leq \abs x$, bote tudo junto e observe que o $x$ só pode ser $\abs x$ ou $-\abs x$.
Para a \rldir, separe em casos sobre o $x$ logo; em cada caso teu alvo segue facilmente por uma das duas partes da hipótese.

\solution
\proofpart {\lrdir}:
Como $\abs x \leq a$, logo $-a \leq -\abs x$.
Temos então $-a \leq -\abs x \leq x \leq \abs x \leq a$.
\crproofpart {\rldir}:
Separamos em casos:
\proofcase {$x \geq 0$}:
Temos $\abs x = x \leq t$.
\proofcase {$x < 0$}:
Observe que como $-a \leq x$, logo $-x \leq -(-a) = a$.
Logo $\abs x = -x \leq a$.

%%}}}

%%{{{ x: real_abs_properties_ops 
\exercise.
%%%{{{ meta 
\label real_abs_properties_ops
%%%}}}

$
\abs {-a} = \abs a; \quad
\abs {a \ntimes b} = \abs a \ntimes \abs b; \quad
\abs {a + b} \leq \abs a + \abs b; \quad
\abs {a - b} \leq \abs a + \abs b.
$

%%}}}

%%{{{ x: real_abs_properties_bounds 
\exercise.
%%%{{{ meta 
\label real_abs_properties_bounds
%%%}}}

Sejam $a,b$ reais.
Logo:
$$
\gather
\bigabs {\abs a - \abs b} \leq \abs {a + b} \leq \abs a + \abs b; \\
\bigabs {\abs a - \abs b} \leq \abs {a - b} \leq \abs a + \abs b. \\
\endgather
$$

%%}}}

%%{{{ x: real_abs_properties_triangular 
\exercise.
%%%{{{ meta 
\label real_abs_properties_triangular
%%%}}}

Sejam $a,b,c$ reais.
Logo:
$$
\abs {a - c} \leq \abs {a - b} + \abs {b - c}.
$$

%%}}}

%%{{{ x: real_abs_properties_ball 
\exercise.
%%%{{{ meta 
\label real_abs_properties_ball
%%%}}}

Sejam $c,r,x$ reais com $r > 0$.
Logo:
$$
\abs {x - c} < r
\iff
c - r < x < c + r
$$

%%}}}

%%{{{ x: real_abs_and_signs 
\exercise.
%%%{{{ meta 
\label real_abs_and_signs
%%%}}}

Sejam $a \is \Real$, $x \is \Int$.
$$
{\abs a}^x = \abs {a^x} =
\cases
a^x,    & $x$ par; \\
a^x,    & $x$ ímpar, $a \geq 0$; \\
-a^x,   & $x$ ímpar, $a < 0$. \\
\endcases
$$

%%}}}

%%{{{ remark: distance from 0 
\remark.
%%%{{{ meta 
%%%}}}

Uma maneira de interpretar o valor absoluto dum real $x$ é
como uma medida de quão distante é o $x$ do real $0$.
Ainda mais, podemos \emph{usar} o valor absoluto para
falar sobre \emph{distâncias} entre quaisquer dois reais.
Fazemos isso na \ref[Distance_on_reals].

%%}}}

\endsection
%%}}}

%%{{{ Sets_reals 
\section Conjuntos de reais.
%%%{{{ meta 
\label Sets_reals
%%%}}}

%%{{{ intro 
\secintro
Conjuntos e seqüências mesmo, em forma geral, vamos estudar no \ref[Collections].
Aqui vamos só usar um pouco uns conjuntos e logo depois umas seqüências \emph{de reais}
\mathcols 2
\SetA \Real &\is \Type &
\SeqA \Real &\is \Type
\intertext {e uns conjuntos e umas seqüências \emph{de conjuntos de reais}}
\SetP {\SetA \Real} &\is \Type &
\SeqP {\SetA \Real} &\is \Type
\endmathcols
e, acho que pronto, parou!
Nada mais profundo que isso.
%%}}}

% SETS OF REALS

%%{{{ to_know_a_set_of_reals 
\note Saber um conjunto de reais.
%%%{{{ meta 
\label to_know_a_set_of_reals
%%%}}}

O que precisamos fazer para ter o direito de dizer que \dterm{definimos} um conjunto de reais $A$?
Precisamos definir o que significa \emph{pertencer ao conjunto $A$}.
Se, e somente se, para qualquer $x$ real sabemos o que significa a afirmação $x \in A$,
temos o direito de falar que sabemos quem é o $A$.
E para falar que entendemos o que significa conjunto mesmo, precisamos saber
o que significa a afirmação $A = B$, para quaisquer conjuntos $A,B$.
Vamos lembrar isso agora:
$$
A = B
\defiff
\lforall x {x \in A \iff x \in B}.
$$
E para formar (definir) um conjunto $A$, o que precisamos fazer?
Simplesmente definir o que $x \in A$ significa:
$$
x \in A \defiff \dotsc
$$
pois saber o que $x \in A$ significa, é saber o que $A$ significa.

%%}}}

%%{{{ set_builder_in_reals
\note Set-builder.
%%%{{{ meta 
\label set_builder_in_reals
\defines
    * set-builder
    * conjunto!indexado
    * conjunto!gerado
    * gerador!de conjunto
    ;;
\indexes
    * indexado!conjunto   see: conjunto
    * gerado!conjunto     see: conjunto
    * gerado!conjunto     seealso: indexado
    ;;
%%%}}}

Quando o conjunto tem uma quantidade finita de membros, podemos simplesmente
listar todos eles entre chaves:
$$
A \defeq \set {5,7,2}.
$$
Com essa definição definimos sim a proposição $x \in A$ para qualquer $x$ real
para ser a seguinte:
$$
x \in A \intiff x = 5 \mlor x = 7 \mlor x = 2.
$$
Usamos a notação \dterm{set-builder}
$$
\setst {x\in\reals} {\phi(x)}
$$
para denotar o conjunto de todos os reais $x$ tais que $\phi(x)$.
Dado qualquer real $a$, então, a proposição
$$
a \in \setst {x\in\reals} {\phi(x)}
$$
reduz-se à proposição $\phi(a)$.
Dado um conjunto de reais $D$, escrevemos
$$
\setst {x \in D} {\phi(x)}
$$
para referir ao conjuto de todos os membros de $D$ que, ainda mais,
possuem a propriedade $\phi$.
Todos os usos até agora dessa notação usam apenas uma variável na sua parte
esquerda, mas podemos escrever termos mais interessantes.  Por exemplo
$$
\setst {2^n + 1} {n \in \nats}
= \set { 2^0 + 1
       , 2^1 + 1
       , 2^2 + 1
       , 2^3 + 1
       , \dotsc }
= \set { 2, 3, 5, 9, \dotsc }.
$$
Quando um conjunto é definido nesta forma dizemos que é \dterm{indexado},
aqui pelo conjunto $\nats$.
Isso significa que para solicitar membros arbitrários deste conjunto
basta solicitar indices arbitrários do conjunto de índices.
Escrevendo \wq{Sejam $i,j \in \nats$}, então, querendo ou não,
temos acesso em dois membros arbitrários do nosso conjunto:
$2^i + 1, 2^j + 1$.
O conjunto $\nats$ nesse exemplo também é chamado de \dterm{gerador},
visto como um fornecedor de valores para a variável $n$ que aparece
na parte esquerda, para formar os membros do conjunto mesmo.
Podemos usar mais que um gerador, e quando isso acontece a idéia é
que para cada escolha de membro por cada gerador fornece um membro
do nosso conjunto.
Por exemplo:
\mathcol
\setst {n^2 + 2m} {n \in \nats, m \in \set {10,20}}
&= \set { 0^2 + 2 \ntimes 10
        , 0^2 + 2 \ntimes 20
        , 1^2 + 2 \ntimes 10
        , 1^2 + 2 \ntimes 20
        , \dotsc } \\
&= \set { 20, 40, 21, 41, 24, 44, \dotsc }.
\endmathcol

%%}}}

%%{{{ df: intervals_of_reals 
\definition Intervalos.
%%%{{{ meta 
\label intervals_of_reals
\defines
    * intervalos!de reais
    ;;
%%%}}}

Sejam $a,b$ reais.
Definimos os conjuntos de reais seguintes, que chamamos de \dterm{intervalos:}
\mathcols 2
(a, b) &\defeq \setst {x} {a < x < b} &
[a, b] &\defeq \setst {x} {a \leq x \leq b} \\
(a, b] &\defeq \setst {x} {a < x \leq b} &
[a, b) &\defeq \setst {x} {a \leq x < b}. \\
\itext
Pronunciamos as parentêses de \utter{aberto} e os colchetes de \utter{fechado}.
Definimos também:
\enditext
(\minfty, b) &\defeq \setst {x} {x < b} &
(a, \pinfty) &\defeq \setst {x} {a < x} \\
(\minfty, b] &\defeq \setst {x} {x \leq b} &
[a, \pinfty) &\defeq \setst {x} {a \leq x}.
\endmathcols
É conveniente também definir
$
\smash {(\minfty, \pinfty) \defeq \reals}.
$

%%}}}

%%{{{ beware: infties_not_reals 
\beware.
%%%{{{ meta 
\label infties_not_reals
%%%}}}

Não definimos os $\minfty,\pinfty$ como objetos matemáticos aqui.
Por enquanto fazem parte de notação, e com certeza \emph{não} se trata de
números reais.

%%}}}

\endsection
%%}}}

%%{{{ Minima_and_maxima_on_reals 
\section Mínima e máxima.
%%%{{{ meta 
%%%}}}

%%{{{ df: real_min_max_binary 
\definition.
%%%{{{ meta 
\label real_min_max_binary
%%%}}}

Definimos as funções:
\mathcols 2
\min &\eqtype \Real \times \Real \to \Real &
\max &\eqtype \Real \times \Real \to \Real \\
\min (a,b) &\defeq \cased { a,  & se $a\leq b$; \\
                            b,  & senão; } &
\max (a,b) &\defeq \cased { b,  & se $a\leq b$; \\
                            a,  & senão. }
\endmathcols

%%}}}

%%{{{ x: real_min_max_formulas 
\exercise.
%%%{{{ meta 
\label real_min_max_formulas
%%%}}}

Sejam $a,b$ reais.
Logo
\mathcols 2
\min(a,b) &= \frac {a + b - \abs {b-a}} 2 &
\max(a,b) &= \frac {a + b + \abs {b-a}} 2.
\endmathcols

%%}}}

%%{{{ x: real_max_addition 
\exercise.
%%%{{{ meta 
\label real_max_addition
%%%}}}

Sejam $a,b,c,d$ reais.
Logo
$$
\max(a+c, b+d) \leq \max(a,b) + \max(c,d).
$$

%%}}}

%%{{{ x: real_min_addition 
\exercise.
%%%{{{ meta 
\label real_min_addition
%%%}}}

Qual a correspondente afirmação que podes demonstrar sobre a $\min$?

%%}}}

%%{{{ df: real_min_max_of_set 
\definition.
%%%{{{ meta 
\label real_min_max_of_set
%%%}}}

Sejam $A$ um conjunto de reais e $x$ um real.
Dizemos que:
\mathcol
\text{$m$ é um mínimo de $A$} &\defiff m \in A \mland m \leq A \\
\text{$m$ é um máximo de $A$} &\defiff m \in A \mland m \geq A.
\endmathcol

%%}}}

%%{{{ x: real_uniqueness_of_min_and_max 
\exercise Unicidades de máxima e mínima.
%%%{{{ meta 
\label real_uniqueness_of_min_and_max
%%%}}}

Seja $A$ conjunto de reais.
Se $A$ possui um mínimo membro $m$, então $m$ é o único mínimo membro de $A$.
Similarmente sobre os máxima.

%%}}}

%%{{{ notation: real_min_max_of_set_notation 
\notation.
%%%{{{ meta 
\label real_min_max_of_set_notation
%%%}}}

Quando um conjunto $A$ de reais possui mínimo, denotamos por
$\min A$ o seu único membro mínimo.
Similarmente, quando $A$ possui máximo, o denotamos por $\max A$.

%%}}}

%%{{{ x: real_is_unbounded 
\exercise.
%%%{{{ meta 
\label real_is_unbounded
%%%}}}

O $\reals$ não tem nem mínimo, nem máximo.

%%}}}

%%{{{ x: every_finite_set_of_reals_has_min_and_max 
\exercise.
%%%{{{ meta 
\label every_finite_set_of_reals_has_min_and_max
%%%}}}

Todo conjunto finito e habitado de reais possui membro mínimo e membro máximo.

\solution
Tudo que precisamos dos inteiros para demonstrar o
\ref[every_finite_set_of_ints_has_min_and_max] temos aqui nos reais também.

%%}}}

%%{{{ df: real_ceil_and_floor 
\definition piso, teto.
%%%{{{ meta 
\label real_ceil_and_floor
%%%}}}

Seja $a$ real.
Associamos com $a$ dois reais inteiros, que chamamos de \dterm{piso} e
\dterm{teto} de $a$ e denotamos por $\floor a$ e $\ceil a$ respectivamente.
Suas definições:
\mathcols 2
\floor a &\defeq \max \setst {x\in\intreals} {x \leq a} &
\ceil a  &\defeq \min \setst {x\in\intreals} {a \leq x}.
\endmathcols

%%}}}

%%{{{ x: real_ceil_and_floor_dangerous_def 
\exercise.
%%%{{{ meta 
\label real_ceil_and_floor_dangerous_def
%%%}}}

A definição \ref[real_ceil_and_floor] é potencialmente perigosa.
Qual o perigo?
Identifique e demonstre que não há tal perigo mesmo.

%%}}}

%%{{{ eg: ceil and floor examples 
\example.
%%%{{{ meta 
%%%}}}

Temos:
\mathcols 5
\ceil  4  &= 4 & \ceil  {1/2} &= 1 & \ceil  {-3/2} &= -1 & \ceil  {0.99} &= 1& \ceil  {0.999\dots} &= 1  \\
\floor 4  &= 4 & \floor {1/2} &= 0 & \floor {-3/2} &= -2 & \floor {0.99} &= 0& \floor {0.999\dots} &= 1. \\
\endmathcols
As duas últimas colunas envolvem \emph{numerais de reais em notação decimal},
algo que não temos discutido ainda, mas encontraremos daqui a pouco, neste mesmo capítulo.
Inclui essas duas colunas aqui para o leitor que já é acostumado com eles.

%%}}}

%%{{{ x: real_ceil_of_floor_and_floor_of_ceil 
\exercise.
%%%{{{ meta 
\label real_ceil_of_floor_and_floor_of_ceil
%%%}}}

Adivinhe os \sq{$\askdots$} e demonstre:
\mathcols 2
\cforall {x\in\reals} {\floor {\ceil  x} = \askdots} &
\cforall {x\in\reals} {\ceil  {\floor x} = \askdots}. \\
\endmathcols

%%}}}

%%{{{ x: real_ceil_and_floor_of_plus_k 
\exercise.
%%%{{{ meta 
\label real_ceil_of_floor_of_plus_k
%%%}}}

Adivinhe os \sq{$\askdots$} e demonstre:
\mathcols 2
\pforall {x\in\reals} \cforall {k\in\intreals} {\floor {x+k} = \askdots} &
\pforall {x\in\reals} \cforall {k\in\intreals} {\ceil  {x+k} = \askdots}. \\
\endmathcols

%%}}}

\endsection
%%}}}

%%{{{ Seq_reals 
\section Seqüências.
%%%{{{ meta 
\label Seq_reals
%%%}}}

% SEQS OF REALS

%%{{{ df: sequence_of_reals 
\definition seqüência.
%%%{{{ meta 
\label sequence_of_reals
\defines
    * seqüência!de reais
    ;;
%%%}}}

Considere que temos definido os reais
$$
x_0, x_1, x_2, x_3, \dotsc
$$
Temos então, para cada $n \in \nats$, determinado um certo real $x_n$.
Dizemos que temos uma \dterm{seqüência de reais}, que denotamos por
qualquer uma das
\mathcols 5
&\seqft {x_n} n 0 \infty &
&\seq   {x_n} {n \in \nats} &
&\seqst {x_n} {n \in \nats} &
&\seqst {x_n} {n \geq 0} &
&\seqn  x n,
\endmathcols
dependendo de quanta informação podemos deixar implicita sem haver confusão ou ambigüidade.
Dizemos que o $x_i$ é o $i$-ésimo \dterm{componente} ou \dterm{termo} da seqüência $\seqn x n$.
A pergunta primitiva que podemos fazer numa seqüência é a seguinte: \wq{qual é teu $i$-ésimo componente?}.
Consideramos duas seqüências como \dterm{iguais} sse concordam em todas as posições, ou seja:
$$
\seqn x n = \seqn y n \defiff \lforall n {x_n = y_n}.
$$

%%}}}

%%{{{ beware: seqs_are_not_sets 
\beware Seqüências não são conjuntos.
%%%{{{ meta 
\label seqs_are_not_sets
%%%}}}

Mesmo que uma seqüência tem componentes (um para cada \dq{posição} dela)
reservamos o verbo \wq{pertencer} e o símbolo $(\in)$ apenas para \emph{conjuntos}:
\mathcol
(\in) &\is \Object \times \Set \to \Prop \\
\intertext{ou, até melhor, trabalhando numa maneira mais cuidadosa com tipagens
para cada tipo $\alpha$ teremos um $(\in_\alpha)$:}
(\in_\alpha) &\is \alpha \times \Set \fa \alpha \to \Prop.
\endmathcol
De qualquer forma, seria um \emph{type error} escrever $1 \in \seqn x n$.
Aquele \emph{tão errado que nem chega a ser falso}.  Simplesmente sem significado.

%%}}}

%%{{{ seqs_as_sets_type_coercion 
\note Type coercion: seqüências como conjuntos.
%%%{{{ meta 
\label seqs_as_sets_type_coercion
%%%}}}

Mesmo assim, é comum ver uma seqüência aparecendo num lugar onde pelo contexto
é inferível que deveria aparecer um conjunto.
Provavelmente o que tá sendo referido nesses casos não é a seqüência em si
mas sim o \emph{conjunto do seus termos:}
$$
\seq {x_n} {n\in\nats}
\qquad\leadsto\qquad
\setst {x_n} {n\in\nats},
\qquad
\text{que também denotamos por $\seqnset x n$.}
$$

%%}}}

%%{{{ eg: some sequences of reals and their first terms 
\example.
%%%{{{ meta 
%%%}}}

Aqui umas seqüências e seus primeiros componentes:
\mathcols 2
\seqft {1/2^n}                 n 0 \infty   &=   1, 1/2, 1/4, 1/8, \dotsc &
\seq    {3n + 1}                n            &=   1,   4,   7,  10, \dotsc \\
\seq    1                       {n\in\nats}  &=   1,   1,   1,   1, \dotsc &
\seqft {(-1)^n}                n 8 \infty   &=   1,  -1,   1,  -1, \dotsc \\
\seq    {n (-1)^n}              {n \geq 3}   &=  -3,   4,  -5,   6, \dotsc &
\seqft {\frac {n + 1} n}       n 1 \infty   &=   2, \frac 3 2, \frac 4 3, \frac 5 4, \dotsc \\
\seqft {x_{2n}}                n 0 \infty   &= x_0, x_2, x_4, x_6, \dotsc &
\seqft {y_n z_{n+1}^2}         n 1 \infty   &= y_1z_2^2, y_2z_3^2, y_3z_4^2, y_4z_5^2, \dotsc \\
\seq    {a_{n_i}}               i            &=   a_{n_0}, a_{n_1}, a_{n_2}, a_{n_3}, \dotsc &
\seq    {a_{n^2}}               n            &= a_0, a_1, a_4, a_9, \dotsc \\
\seq    {\Prod_{i=2}^{n-1} a_i} {n \geq 1}   &=   1,   1, a_2, a_2a_3, \dotsc &
\seqft {\Sum_{n=1}^3 n}        n 0 \infty   &=   6,   6,   6,   6, \dotsc \\
\endmathcols

%%}}}

%%{{{ eg: a seq tending to 1 
\example.
%%%{{{ meta 
%%%}}}

Definimos a seqüência de reais $\seqn b n$ pela:
\mathcol
b_n     &\defeq 1 + 1/n.
\endmathcol
Observe que aqui consideramos como primeiro termo da seqüência o $b_1$, e não o $b_0$.
Se, por motivos religiosos, queremos defini-la em tal forma que seu primeiro termo
é o $b_0$ mesmo, basta definir pela $b_n \defeq 1 + 1/(n+1)$.

%%}}}

%%{{{ eg: a recursively defined seq 
\example.
%%%{{{ meta 
%%%}}}

Definimos a seqüência de reais $\seqn a n$ recursivamente pelas:
\mathcol
a_0     &\defeq 0 \\
a_{n+1} &\defeq 1 - a_n.
\endmathcol

%%}}}

%%{{{ eg: a_recursively_defined_real_seq 
\example.
%%%{{{ meta 
\label a_recursively_defined_real_seq
%%%}}}

Definimos a seqüência de reais $\seqn x n$ recursivamente pelas:
\mathcol
x_0     &\defeq 0 \\
x_{n+1} &\defeq (1/2)x_n + 1.
\endmathcol
Seus primeiros termos então são os:
\mathtightcols 5
&0,     \quad &
&1,     \quad &
&1+1/2, \quad &
&1+3/4, \quad &
&1+7/8, \quad \dotsc \\
\intertext{ou, igualmente,}
&0,       \quad &
&1,       \quad &
&2 - 1/2, \quad &
&2 - 1/4, \quad &
&2 - 1/8, \quad \dotsc \\
\endmathtightcols

%%}}}

%%{{{ x: prove increasing 
\exercise.
%%%{{{ meta 
\defines
    * seqüência!crescente
    ;;
\indexes
    * crescente     see: seqüência
    ;;
%%%}}}

Demonstre que a $\seqn x n$ definida no \ref[a_recursively_defined_real_seq] é \dterm{crescente}, i.e.:
$$
\lforall n {x_n \leq x_{n+1}}.
$$

%%}}}

%%{{{ beware: increasing_nimplies_unbounded 
\beware Crescente não implica ilimitada.
%%%{{{ meta 
\label increasing_nimplies_unbounded
%%%}}}

Mesmo sabendo que cada termo duma seqüência é \emph{estritamente menor}
que o próximo, não podemos inferir que a seqüência não é cotada por cima:
pode ser que existe um real $M$, tal que todos os termos dela são menores que $M$.

%%}}}

%%{{{ x: prove bounded 
\exercise.
%%%{{{ meta 
%%%}}}

Ache um tal $M$ para essa mesma seqüência do \ref[a_recursively_defined_real_seq],
e demonstre que realmente serve.

%%}}}

%%{{{ x: one more sequence 
\exercise.
%%%{{{ meta 
%%%}}}

Agora considere a seqüência $\seqn x n$ definida pelas
\mathcol
x_0     &\defeq 1 \\
x_{n+1} &\defeq (3x_n + 4)/4. \\
\endmathcol
Resolva sobre esta as mesmas duas questões: ela é crescente? ela é cotada?

%%}}}

% √ TEASERS

%%{{{ x: square_root_of_small_reals_seq_bounded_above 
\exercise.
%%%{{{ meta 
\label square_root_of_small_reals_seq_bounded_above
%%%}}}

Seja $\theta$ um real pequeno: $0 < \theta < 1$.
Definimos a seqüência $\seqn t n$ pelas
\mathcol
t_0     &\defeq 0; \\
t_{n+1} &\defeq t_n + \frac 1 2 (\theta - t_n^2).
\endmathcol
Demonstre que $\seqn t n$ é cotada por cima.

\solution
Vou mostrar que $\seqn t n \leq 1$.
Seu primeiro termo é o $0 < 1 \leq 1$.
Seja $k$ natural.  Temos:
\compute
t_{k+1}
    &= t_k + \frac 1 2 (\theta - t_k^2) \\
    &= \frac 1 2 (\theta + 2t_k - t_k^2) \\
    &= \frac 1 2 (\theta - (t_k^2 - 2t_k)) \\
    &= \frac 1 2 (\theta - (t_k^2 - 2t_k + 1 - 1)) \\
    &= \frac 1 2 (\theta - (t_k^2 - 2t_k + 1) + 1) \\
    &= \frac 1 2 ((\theta + 1) - (t_k^2 - 2t_k + 1)) \\
    &= \frac 1 2 ((\theta + 1) - (t_k - 1)^2) \\
    &\leq \frac 1 2 (\theta + 1) \\
    &\leq 1.
\endcompute

%%}}}

%%{{{ x: square_root_of_small_reals_seq_increasing 
\exercise.
%%%{{{ meta 
\label square_root_of_small_reals_seq_increasing
%%%}}}

Demonstre que a mesma seqüência é crescente.

\solution
Basta mostrar por indução que para todo $n$, temos $t_{n+1} - t_n \geq 0$.
A base é trivial.
Seja $k\geq 1$ tal que $t_k - t_{k-1} \geq 0$.
Calculamos:
\compute
t_{k+1} - t_k
&= (t_k + \frac 1 2 (\theta - t_k^2)) - (t_{k-1} + \frac 1 2 (\theta - t_{k-1}^2)) \\
&= (t_k - t_{k-1}) + \frac 1 2 \paren{(\theta - t_k^2) - (\theta - t_{k-1}^2)} \\
&= (t_k - t_{k-1}) - \frac 1 2 \paren{t_k^2 - t_{k-1}^2} \\
&= (t_k - t_{k-1}) - \frac 1 2 \paren{t_k + t_{k-1}}\paren{t_k - t_{k-1}} \\
&= \mubrace {\vphantom{\paren{\frac 0 0}}(t_k - t_{k-1})} {\geq 0} \mubrace{\paren{1 - \frac 1 2 \paren{t_k + t_{k-1}}}} {\geq 0} \\
&\geq 0
\endcompute
onde no último passo usamos a (HI) e que a $\seqn t n \leq 1$ (e logo $t_i + t_j \leq 2$ para quaisquer $i,j$).

%%}}}

\endsection
%%}}}

%%{{{ Unions_and_intersections_reals 
\section Uniões e interseções.
%%%{{{ meta 
\label Unions_and_intersections_reals
%%%}}}

% UNIONS AND INTERSECTIONS OF COLLECTIONS OF REALS

%%{{{ union_inter_of_sets_of_reals 
\note União e interseção de colecções de conjuntos.
%%%{{{ meta 
\label union_inter_of_sets_of_reals
\defines
    * união!de conjuntos de reais
    * intersecção!de conjuntos de reais
    ;;
\pdefs
    \pdef A {{\cal A}}
    ;;
%%%}}}

Tendo uns conjuntos de reais queremos definir a \dterm{união} e a \dterm{intersecção} deles;
ou seja: definir o que significa \emph{pertencer à união deles}
e o que significa \emph{pertencer à interseção deles}.
Caso que a quantidade dos conjuntos é apenas $2$, vamos dizer $A_1,A_2$, já conhecemos
até uma notação para sua união e sua interseção: $A_1 \union A_2$ e $A_1 \inter A_2$
respectivamente.
Lembramos as suas definições:
\mathcol
x \in A_1 \union A_2 &\defiff x \in A_1 \mlor  x \in A_2 \\
x \in A_1 \inter A_2 &\defiff x \in A_1 \mland x \in A_2.
\endmathcol
Mas se temos mais que dois conjuntos?
As definições acima não são aplicáveis nesse caso.  Precisamos generalizá-las.
Se temos uma quantidade finita de conjuntos para unir ou para intersectar,
até que dá para fazer aproveitando as $(\union)$ e $(\inter)$---e faremos
isso no \ref[Collections] mesmo---mas aqui não nos interessa, pois não será suficiente
considerar colecções de \emph{apenas} $8$, $84$, ou $4208$ conjuntos.
Freqüentemente teremos uma infinidade de conjuntos,
ou arrumada assim
$$
A_1, A_2, A_3, \dotsc
$$
numa seqüência $\seqn A n$, ou até sem sequer ter nomes legais para esses conjuntos:
considere que temos uma colecção (possivelmente infinita) $\A$ de conjuntos de reais.
Dizemos que
\mathcol
\text{$x$ pertence à união de uns conjuntos}      &\defiff \text{$x$ pertence àlgum deles} \\
\text{$x$ pertence à interseção de uns conjuntos} &\defiff \text{$x$ pertence a todos eles} \\
\intertext{Denotando a colecção de tais conjuntos por $\A$:}
\text{$x$ pertence à união dos conjuntos da $\A$}        &\defiff \lexists {A \in \A} {x \in A} \\
\text{$x$ pertence à interseção dos conjuntos da $\A$}   &\defiff \lforall {A \in \A} {x \in A} \\
\intertext{E se temos nomes indexados de tais conjuntos $A_0, A_1, A_2, \dotsc$:}
\text{$x$ pertence à união dos $A_0, A_1, A_2, \dotsc$}      &\defiff \lexists {i \in \nats}  {x \in A_i} \\
\text{$x$ pertence à interseção dos $A_0, A_1, A_2, \dotsc$} &\defiff \lforall {i \in \nats}  {x \in A_i}. \\
\endmathcol
Para referir à união ou à interseção de uma colecção de conjuntos usamos os símbolos $\Union$ e $\Inter$, assim:
\mathcol
\Union \A &\defeq \text{a união dos conjuntos da colecção $\A$} \\
\Inter \A &\defeq \text{a interseção dos conjuntos da colecção $\A$} \\
\Union_{n\in\nats} A_n \defeq \Union_{i=0}^\infty A_i &\defeq \text{a união dos conjuntos $A_0,A_1,A_2,\dotsc$} \\
\Inter_{n\in\nats} A_n \defeq \Inter_{i=0}^\infty A_i &\defeq \text{a interseção dos conjuntos $A_0,A_1,A_2,\dotsc$}.
\intertext{Quando é claro pelo contexto quais são \dq{os $A_n$'s} que estamos unindo ou intersetando escrevemos apenas}
\Unionl_n A_n &\defeq \text{a união dos $A_n$'s} \\
\Interl_n A_n &\defeq \text{a interseção dos $A_n$'s}.
\endmathcol

%%}}}

%%{{{ blah: sequences of sets of reals 
\blah Seqüências de conjuntos.
%%%{{{ meta 
%%%}}}

Toda a notação e terminologia sobre seqüências de reais que elaboramos aqui
aplica \emph{mutatis mutandis} para seqüências de \emph{conjuntos de reais}.

%%}}}

%%{{{ x: fun with sequences of sets (1) 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos de reais, tal que
$$
A_1 \supset A_2 \supset A_3 \supset \dotsb
$$
e tal que cada um deles possui uma infinidade de membros.
Podemos concluir que sua intersecção
$$
A_1 \inter A_2 \inter A_3 \inter \dotsb
$$
também possui uma infinidade de reais?

%%}}}

%%{{{ x: fun with sequences of sets (2) 
\exercise.
%%%{{{ meta 
%%%}}}

E se, em vez de infinito, cada um dos $A_i$ é finito e habitado, podemos concluir
que a interseção também é finita e habitada?

%%}}}

%%{{{ x: running_intervals_on_reals 
\exercise.
%%%{{{ meta 
\label running_intervals_on_reals
%%%}}}

Para $n=1,2,3,\dotsc$ defina os intervalos de reais
\mathcols 2
F_n &= \ival[ {-1+\frac1n \,,\; 1-\frac1n} ] &
G_n &= \ival( {-1-\frac1n \,,\; 1+\frac1n} ).
\endmathcols
Calcule os conjuntos $\Union_n F_n$ e $\Inter_n G_n$.

\hint
Use as definições!

\solution
Temos
$$
\align
x \in \Unionl_n F_n
&\iff \lexists {n\in \nats} {x\in F_n}
\iff x \in (-1,1) \\
x \in \Interl_n G_n
&\iff \lforall {n\in \nats} {x\in G_n}
\iff x \in [-1,1].
\endalign
$$
Ou seja: $\Union_n F_n = (-1,1)$ e $\Inter_n G_n = [-1,1]$.

%%}}}

%%{{{ x: epsilon-dependent and n-dependent intersections 
\exercise.
%%%{{{ meta 
%%%}}}

Para todo real $\epsilon > 0$ e todo $n\in\nats$,
sejam os intervalos de reais
\mathcols 3
I_\epsilon &= [0,1 + \epsilon) &
J_n        &= [0,1 + 1/n] &
U_n        &= [n,+\infty).
\endmathcols
Calcule os conjuntos:
(i) $\Inter \setst {I_\epsilon} {\epsilon>0}$;
(ii) $\Inter_{n=0}^{\infty} J_n$;
(iii) $\Inter_{n=2}^{\infty} U_n$.

\solution
(i) $[0,1]$;
(ii) $[0,1]$;
(iii) $\emptyset$.

%%}}}

\endsection
%%}}}

%%{{{ Operations_and_relations_between_seqs 
\section Operações e relações entre seqüências.
%%%{{{ meta 
\label Operations_and_relations_between_seqs
%%%}}}

% OPERATIONS BETWEEN SEQS OF REALS

% ORDER BETWEEN SEQS OF REALS

%%{{{ df: leq_between_seqs 
\definition ordem pointwise.
%%%{{{ meta 
\label leq_between_seqs
\defines
    * seqüência!ordem
    ;;
\indexes
    * pointwise
    ;;
%%%}}}

Aproveitando as ordens que já temos nos reais, as elevamos para definir
correspondentes ordens entre seqüências de reais, em forma \dterm{pointwise:}
$$
\seqn a n \leq \seqn b n
\defiff
\lforall n {a_n \leq b_n},
$$
e similarmente para as outras ordens que definimos: $(<)$, $(\geq)$, etc.

%%}}}

%%{{{ beware: leq_between_seqs_vs_between_sets 
\beware.
%%%{{{ meta 
\label leq_between_seqs_vs_between_sets 
%%%}}}

Antes da \ref[leq_between_seqs], a expressão
$$
\seqn a n \leq \seqn b n
$$
seria interpretada através de \emph{type coercion} como
$$
\seqnset a n \leq \seqnset b n
$$
pois temos estabelecido já o que $A \leq B$ significa para conjuntos de reais $A,B$:
$$
A \leq B
\intiff \lforall {a \in A} {a \leq B}
\intiff \pforall {a \in A} \lforall {b \in B} {a \leq b}.
$$
Mas a partir da \ref[leq_between_seqs] a expressão
$$
\seqn a n \leq \seqn b n
$$
já ganhou seu próprio significado, e logo não entra mais nenhum \emph{type coercion}
nesse processo.
Mas será que as duas interpretações acabam sendo equivalentes?

%%}}}

%%{{{ x: leq_between_seqs_vs_between_sets
\exercise.
%%%{{{ meta 
\label leq_between_seqs_vs_between_sets_wa
%%%}}}

Será?

\hint
Não.

\solution
Não.  Considere como contraxemplo as seqüências
\mathcols 2
\seq n     n &= 0, 1, 2, \ldots &
\seq {n+1} n &= 1, 2, 3, \ldots
\endmathcols
e veja que temos
$\seq n n \leq \seq {n+1} n$
mas
$\seqset n n \nleq \seqset {n+1} n$.

%%}}}

\endsection
%%}}}

%%{{{ The_natural_reals 
\section Os reais naturais.
%%%{{{ meta 
\label The_natural_reals
%%%}}}

%%{{{ df: real_inductive 
\definition naturalmente indutivo.
%%%{{{ meta 
\defines
    * indutivo!naturalmente
    ;;
\indexes
    * conjunto!naturalmente indutivo  see: indutivo
    ;;
%%%}}}

Seja $A$ um conjunto de reais.
Chamamos o $A$ de (naturalmente) \dterm{indutivo} sse:
(i) $A$ é $0$-fechado: $0 \in A$;
(ii) $A$ é $(+1)$-fechado: $\lforall {a} {a \in A \implies a + 1 \in A}$.

%%}}}

%%{{{ eg: real_inductive_sets 
\example.
%%%{{{ meta 
%%%}}}

O próprio conjunto $\reals$ com certeza é indutivo.
Os conjuntos $\reals_{\geq 0}, \reals_{\geq -1}$ também.
Os conjuntos
\mathcol
H &\defeq \set { \dotsc -3,
-\frac 5 2,
-2,
-\frac 3 2,
-1,
-\frac 1 2,
0,
\frac 1 2,
1,
\frac 3 2,
2,
\frac 5 2,
3, \dotsc } \\
H_{\geq 0} &\defeq \setst {h \in H} {h \geq 0}
\endmathcol
também.

%%}}}

%%{{{ noneg: real_non_inductive_sets 
\nonexample.
%%%{{{ meta 
%%%}}}

Nenhum dos conjuntos seguintes é indutivo:
$$
\set {0},
\quad \set {0,1,2,3,\dotsc,83},
\quad \reals_{\neq 0},
\quad \reals_{\leq 0},
\quad \reals_{> 0},
\quad \reals_{\neq -1}.
$$

%%}}}

%%{{{ x: real_non_inductive_sets_why 
\exercise.
%%%{{{ meta 
\label real_non_inductive_sets_why
%%%}}}

Por quê?

%%}}}

%%{{{ df: natreals 
\definition Os reais naturais.
%%%{{{ meta 
\label natreals
\defines
    * real!natural
    ;;
\pdefs
    \pdef I {{\cal I}}
    ;;
%%%}}}

Seja $\I$ a colecção de todos os conjuntos indutivos de reais.
Sabemos que $\reals \in \I$.
Considere a interseção de todos os conjuntos indutivos de reais,
ou seja, o conjunto
$$
\natreals \defeq \setstt {x \in \reals} {$x$ pertence a todo conjunto indutivo de reais}
$$
que denotaremos por $\natreals$ e cujos membros chamamos de
\dterm{reais naturais}.
Seus membros são os
$$
\natreals = \set {0, 1, 2, 3, 4, \dotsc }.
$$

%%}}}

%%{{{ thm: natreals_is_inductive 
\theorem.
%%%{{{ meta 
\label natreals_is_inductive
%%%}}}

O conjunto $\natreals$ é indutivo.

\proof.
Precisamos verificar que:
(i) $0 \in \natreals$;
(ii) $\lforall {x} {x \in \natreals \implies x + 1 \in \natreals}$.
Lembre-se que para demonstrar que um real $a$ pertence ao $\natreals$
basta demonstrar que $a$ pertence a todos os conjuntos indutivos, já que
$\natreals$ foi definido como interseção de todos eles.
\eop
(i) Seja $I$ conjunto indutivo de reais.  Logo $0 \in I$.
(ii) Seja $x \in \natreals$, ou seja, $x$ pertence em qualquer conjunto indutivo.
Preciso mostrar que $x + 1 \in \natreals$.
Para conseguir isso, seja $I$ um conjunto indutivo de reais.
Logo $x \in I$.  Como $I$ é indutivo, $x+1 \in I$, que é o que precisava mostrar.

%%}}}

%%{{{ cor: natreals_is_least 
\corollary.
%%%{{{ meta 
\label natreals_is_least
%%%}}}

O conjunto $\natreals$ é o $(\subset)$-menor conjunto indutivo, i.e.,
$$
\ltforall {$I$ indutivo} {\natreals \subset I}.
$$

\proof.
Seja $I$ indutivo e $n \in \natreals$.
Logo $n \in I$.

%%}}}

%%{{{ remark: the importance of this 
\remark.
%%%{{{ meta 
%%%}}}

É muito fácil subestimar ou até descartar o que acabamos de obter (tão facilmente)
sem perceber sua importância: \emph{ele é o princípio da indução} para o $\natreals$!
Compare com o \ref[ints_principle_of_induction_set_form] dos inteiros.

%%}}}

%%{{{ blah: from the natural reals we gain the rest 
\blah.
%%%{{{ meta 
%%%}}}

Tendo finalmente definido os reais naturais $\natreals$,
ganhamos o resto dos subconjuntos da \ref[real_notable_subsets].

%%}}}

%%{{{ x: real_inductive_numeric_sets 
\exercise.
%%%{{{ meta 
\label real_inductive_numeric_sets
%%%}}}

Os $\intreals,\ratreals,\algreals$ são conjuntos indutivos.

%%}}}

%%{{{ x: naturally_inductive_sets_of_ints_and_rats 
\exercise.
%%%{{{ meta 
\label naturally_inductive_sets_of_ints_and_rats
%%%}}}

Daria certo utilizar a mesma idéia para definir os inteiros naturais $\natints \subset \ints$?
Os racionais naturais $\natrats \subset \rats$?

\hint
Daria, mas não faria sentido essa abordagem, pois seria complicada demais.
Tanto para os inteiros, quanto para os racionais, existem maneiras bem mais fáceis
para definir seus correspondentes conjuntos naturais.  Como?

\solution
Daria, mas não faria sentido essa abordagem, pois seria complicada demais.
Poderíamos simplesmente definir esses conjuntos assim:
\mathcols 2
\natints &\defeq \set{0} \union \Pos &
\natrats &\defeq \setst {\frac x 1} {x \in \natints}.
\endmathcols

%%}}}

\endsection
%%}}}

%%{{{ On models 
\section Sobre modelos.
%%%{{{ meta 
\label On_models_of_reals
%%%}}}

%%{{{ Models 
\note Modelos.
%%%{{{ meta 
\defines
    * modelo
    ;;
%%%}}}

Qualquer $\sset X {0,1,+,-,\ntimes,>}$ com
\mathcols 4
0, 1            &\is X &
(+), (\ntimes)  &\is X \times X \to X &
(-)             &\is X \to X &
(>)             &\is X \times X \to \Prop
\endmathcols
que satisfaz todos os axiomas que temos estipulado até agora
neste capítulo sobre os reais é chamado um \dterm{corpo ordenado}.
Ou seja: até agora temos exigido que o $\sset \reals {0,1,+,-,\ntimes,>}$
é \emph{um} corpo ordenado.
Conhecendo o conjunto $\rats$ dos \dterm{racionais},
percebemos que o $\sset \rats {0,1,+,-,\ntimes,>}$ também
é um corpo ordenado.
Em palavras mais formais, tanto os reais quanto os racionais são o que
a gente chama de \dterm{modelos} de corpos ordenados.
O que temos estipulado então, não é suficiente para
\dterm{determinar os reais}, pois nem consegue diferenciá-los
dos racionais.

%%}}}

%%{{{ Q: how_can_we_separate_reals_from_rats 
\question.
%%%{{{ meta 
\label how_can_we_separate_reals_from_rats
%%%}}}

Podemos adicionar alguma lei capaz de separar os reais dos racionais?
Ou seja, chegar numa lista de leis mais exigentes, tais que
os reais vão ser um modelo, mas os racionais não.

%%}}}

\spoiler

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A verdade é que falta só um axioma que realmente vai determinar os reais.
Mas conseguir enxergá-lo neste momento é um grande desafio.\foot
Vai desistir de pensar em alguma resposta por causa disso?
\toof
Pelo menos já estamos prontos para conhecer o que falta para
a pergunta virar mais fácil:
o \emph{supremum} e seu conceito dual, o \emph{infimum}.
Conhecemos logo (\reftag[Infimum_and_supremum_on_reals])
para finalmente chegar numa resposta (\reftag[Completeness_of_reals]).
Mas antes de tudo isso, vamos falar de distâncias.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

\TODO Add problems.

\endproblems
%%}}}

%%{{{ Infimum_and_supremum_on_reals 
\section Infimum e supremum.
%%%{{{ meta 
\label Infimum_and_supremum_on_reals
%%%}}}

%%{{{ df: lower_and_upper_bounds_reals 
\definition cotas.
%%%{{{ meta 
\label lower_and_upper_bounds_reals
\defines
    * ~A \leq ~x  -- $x$ é uma cota superior de $A$
    * ~x \leq ~A  -- $x$ é uma cota inferior de $A$
    * bounded!below
    * bounded!above
    * bound!lower
    * bound!upper
    * cotado!superiormente
    * cotado!inferiormente
    * cota!superior
    * cota!inferior
    ;;
\indexes
    * limitante     see: cota
    ;;
%%%}}}

Seja $A\subset \reals$.
Dizemos que $c$ é uma \dterm{cota inferior} (ou \dterm{lower bound}) de $A$ sse $c \leq A$; e,
\emph{dualmente}, $c$ é uma \dterm{cota superior} (ou \dterm{upper bound}) de $A$ sse $c \geq A$:
\mathcol
\text{$c$ é uma cota inferior de $A$} &\defiff c \leq A \intiff \lforall {a\in A} {c \leq a}; \\
\text{$c$ é uma cota superior de $A$} &\defiff A \leq c \intiff \lforall {a\in A} {a \leq c}.
\endmathcol
Denotamos o conjunto de todas as cotas inferiores de $A$ por $(\leq A)$ ou $(A \geq)$
e dualmente usamos $(A \leq)$ ou $(\geq A)$ para o conjunto de todas as suas cotas superiores:
\mathcol
(\leq A) &\defeq \setst {x} {x \leq A}; \\
(A \leq) &\defeq \setst {x} {A \leq x}.
\endmathcol
Se um conjunto $A$ tem pelo menos uma cota inferior,
dizemos que $A$ é \dterm{cotado inferiormente} (ou, \dterm{bounded below});
e se tem pelo menos uma cota superior, ele é \dterm{cotado superiormente}
(ou, \dterm{bounded above}).
Chamamos um conjunto de \dterm{cotado} se é cotado inferiormente e superiormente;
senão, ele é um conjunto \dterm{ilimitado}.\foot
O que chamamos aqui de \dterm{cota} e de \dterm{cotado} são também chamados
\dterm{limitante} e \dterm{limitado}, mas vou evitar esses termos por causa
da conexão etimológica que essas palavras têm com a palavra \wq{limite}.
\toof

%%}}}

%%{{{ df: inf_sup_reals 
\definition infimum; supremum.
%%%{{{ meta 
\label inf_sup_reals
\defines
    * \glb {~A}  -- o greatest lower bound de $A\subset\reals$
    * \lub {~A}  -- o least upper bound de $A\subset\reals$
    * \inf {~A}  -- o infimum de $A\subset\reals$
    * \sup {~A}  -- o supremum de $A\subset\reals$
    * {\xreals}  -- os reais estendidos: $\set{\minfty}\union\reals\union\set{\pinfty}$
    * greatest lower bound!reais
    * infimum!reais
    * least upper bound!reais
    * reais!estendidos
    * supremum!reais
    ;;
%%%}}}

A \dterm{melhor cota inferior} é chamada \dterm{ínfimo} ou \dterm{infimum}, e
a \dterm{melhor cota superior} é chamada \dterm{supremo} ou \dterm{supremum}:
\mathcol
\text{$c$\/ é um infimum  de $A$} &\defiff
\tobrace {c \leq A}
         {\clap{cota inferior}} \mland
\tobrace {\lforall {c' \leq A} {c \geq c'}}
         {a melhor}; \\
\text{$c$\/ é um supremum de $A$} &\defiff
\tubrace {c \geq A}
         {\clap{cota superior}} \mland
\tubrace {\lforall {c' \geq A} {c \leq c'}}
         {a melhor}.
\endmathcol
Escrevemos $c = \inf A$ e $c = \sup A$ respectivamente, mas, como o leito deve
ter suspeitado, \emph{não se tratam literamente de igualdades,} pois suas partes direitas
sequer foram definidas \dq{em isolação} mesmo---veja mais sobre essa possibilidade no
\ref[inf_and_sup_are_partial_on_reals].
As tipagens corretas aqui então são as:
\mathcols 2
\uhole = \inf \uhole &\is \Real \cross \SetA \Real \to \Prop &
\uhole = \sup \uhole &\is \Real \cross \SetA \Real \to \Prop.
\endmathcols

%%}}}

%%{{{ x: inf_sup_what_must_we_prove_to_justify_notation 
\exercise.
%%%{{{ meta 
\label inf_sup_what_must_we_prove_to_justify_notation
%%%}}}

O que \emph{devemos} demonstrar agora para justificar esse abuso notacional
que criou essas \dq{conjunções desfarçadas com roupas de igualdades}?

\hint
O que fizemos sobre mínima e máxima tanto estudando inteiros, quanto estudando reais?

\solution
Devemos demonstrar a unicidade dos infima e dos suprema.

%%}}}

%%{{{ thm: inf_and_sup_are_unique 
\theorem Unicidade de inf e sup.
%%%{{{ meta 
\label inf_and_sup_are_unique
\indexes
    * dual
    ;;
%%%}}}

Seja $A \is \SetA \Real$.
Se $A$ tem infimum, ele é único.
Dualmente, se $A$ tem supremum, ele é único.

\proof.
Por fight club: suponha $\ell, \ell'$ são infima, logo $\ell \leq \ell'$
pois $\ell'$ é maior que qualquer cota inferior, e $\ell$ é uma cota inferior.
No outro lado $\ell' \leq \ell$ pois $\ell$ é maior que qualquer cota inferior,
e $\ell'$ é uma cota inferior.  Logo $\ell \leq \ell'$ e $\ell' \leq \ell$
e pela antissimetria da $(\leq)$ temos $\ell = \ell'$.
\eop
A unicidade dos supremos é \dterm{dual.}\foot
Finja que leu a palavra \emph{similar} aqui.
\toof

%%}}}

%%{{{ notation: nat_sugar 
\notation Açúcar sintáctico.
%%%{{{ meta 
\label nat_sugar
%%%}}}

Com as unicidades estabelecidas podemos introduzir realmente os símbolos
\mathcols 2
\inf A &\defeq \max (\leq A) &
\sup A &\defeq \min (\geq A).
\intertext{Outros nomes (e notações correspondentes) desses dois conceitos
são muito comuns e vamos ficar os usando também:
o infimum é chamado também de \dterm{greatest lower bound} e o supremum
de \dterm{least upper bound}, e denotados por $\glb$ e $\lub$ respectivamente:}
\glb A &\defeq \inf A &
\lub A &\defeq \sup A.
\endmathcols
E olha que no~\ref[Posets_Lattices] encontramos ainda mais nomes e notações!

%%}}}

%%{{{ beware: inf_and_sup_are_partial_on_reals 
\beware.
%%%{{{ meta 
\label inf_and_sup_are_partial_on_reals
%%%}}}

Assim, $\inf$ e $\sup$ não são operações totais nos reais,
mas sim \emph{parciais:}
$$
\inf,\sup \is \SetA \Real \parto \Real.
$$
Ou seja, ninguém garanta que para qualquer
$A \is \SetP\Real$ existe mesmo um real $x$ que satisfaz as
condições das definições acima, traduzidas aqui assim:
\mathcol
\inf A &\defeq \text{o único infimum de $A$, se existe}; \\
\sup A &\defeq \text{o único supremum de $A$, se existe}.
\endmathcol

%%}}}

%%{{{ extended_reals 
\note Os reais estendidos.
%%%{{{ meta 
\label extended_reals
%%%}}}

Agora, se $A$ não é cotado inferiormente e se $A$ não é cotado superiormente escrevemos
$$
\inf A = \minfty
\qqtext{e}
\sup A = \pinfty
$$
respectivamente.
Isso é bem justificável se pensar no $\reals$ apenas como um conjunto
ordenado sendo enriquecido por dois novos objetos distintos que denotamos por
\sq{$\minfty$} e \sq{$\pinfty$} chegando assim no conjunto
$$
\set{\minfty}\union\reals\union\set{\pinfty}
$$
que ordenamos assim:
$$
\minfty < x < \pinfty, \quad\text{para todo $x\in\reals$}.
$$
Chamamos os membros do $\reals\union\set{\minfty,\pinfty}$
de \dterm{reais estendidos} e denotamos esse conjunto por
$\xreals$ e $[\minfty,\pinfty]$ também.
Então podemos considerar ambas as operações agora como
$$
\inf,\sup \eqtype \SetA \Real \parto [\minfty,\pinfty].
$$

%%}}}

%%{{{ remark: ExtReal is a new type 
\remark Type errors?.
%%%{{{ meta 
%%%}}}

Meu leitor alerto talvez teve uns suspeitos de type errors na \ref[extended_reals].
De fato tem, mas felizmente são todos resolvíveis
com uns type castings.  Tecnicamente precisamos de um novo tipo $\ExtReal$ de dados
para os reais extendidos, e umas funções para os trabalhos burocráticos que
precisam ser feitos quando ocorre real num contexto onde esperamos real estendido
e vice versa.  O \ref[extended_reals_details] é dedicado a isso:

%%}}}

%%{{{ x: extended_reals_details 
\exercise.
%%%{{{ meta 
\label extended_reals_details
%%%}}}

Defina um tipo de $\ExtReal$ e mostra como ler a \ref[extended_reals] sem
cair em type errors.

\hint
Defina $\ExtReal \defeq 1 + \Real + 1$; quais (nomes de) coprojeções tu escolheria?

%%}}}

%%{{{ x: inf_in_set_implies_min 
\exercise.
%%%{{{ meta 
\label inf_in_set_implies_min
%%%}}}

Seja $A \subset \reals$.
Demonstre que:
(i) se $\inf A \in A$ então $\inf A = \min A$;
(ii) a dual da (i).

%%}}}

%%{{{ x: lbs_and_ubs_are_empty_or_infinite 
\exercise.
%%%{{{ meta 
\label lbs_and_ubs_are_empty_or_infinite
%%%}}}

Seja $A \subset \reals$.
Demonstre que $(\leq A)$ é vazio ou infinito, e a mesma coisa sobre o $(A \leq)$.

%%}}}

%%{{{ x: sup_subset_leq_reals 
\exercise.
%%%{{{ meta 
\label sup_subset_leq_reals
%%%}}}

Demonstre ou refute:
para quaisquer $A,B$ habitados e sup-cotados,
$$
A \subset B \implies \sup A \leq \sup B.
$$
O que podemos dizer se remover a hipotese de habitados?  E de cotados?

%%}}}

%%{{{ x: inf_subset_leq_reals 
\exercise.
%%%{{{ meta 
\label inf_subset_leq_reals
%%%}}}

O sobre o $\inf$?

%%}}}

%%{{{ x: a_set_with_nats_as_limit_points 
\exercise.
%%%{{{ meta 
\label a_set_with_nats_as_limit_points
%%%}}}

Considere o conjunto
$$
A = \setlst {m + \frac 1 {2^n}} {m \in \nats, n \in \nats_{>0}}.
$$
(i) Visualize o $A$ na linha dos reais, e rascunhe seu desenho.
(ii) Ache o $\inf A$ e $\sup A$ se existem.

%%}}}

%%{{{ x: inf_sup_reals_extreme_cases 
\exercise.
%%%{{{ meta 
\label inf_sup_reals_extreme_cases
%%%}}}

Pode acontecer que para algum $A\subset\reals$ temos\dots
\tlist:
\li (i):  $\inf A = \sup A$?
\li (ii): $\inf A > \sup A$?
\endtlist
Se sim, quando?
Se não, por que não?

%%}}}

%%{{{ x: metric_slang_teaser 
\exercise.
%%%{{{ meta 
\label metric_slang_teaser
%%%}}}

No \ref[Metric_spaces] aumentaremos nosso vocabulário do nível-coração com bem mais gírias
relacionadas às distâncias.
Por enquanto tente adivinhar as definições dos conceitos seguintes:
distância entre dois conjuntos de reais;
distância entre um real e um conjunto de reais;
diâmetro dum conjunto de reais;
ponto isolado;
ponto interior;
ponto exterior;
ponto de borda;
conjunto cotado (esta última noção deve acabar sendo extensionalmente mas não
intensionalmente equivalente à noção de conjunto inferiormente e superiormente fechado).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E agora\dots
Será que podes pensar numa resposta para
a~\ref[how_can_we_separate_reals_from_rats]?
A resposta demora pouco ainda (\reftag[Completeness_of_reals]),
mas este ponto é um ponto bom para formar uma tentativa boa de palpite.  Tente!

%%}}}

\endsection
%%}}}

%%{{{ Epsilons 
\section Epsilons.
%%%{{{ meta 
\label Epsilons
\defines
    * epsilon
    ;;
%%%}}}

%%{{{ thm: only_zero_is_leq_pos 
\theorem.
%%%{{{ meta 
\label only_zero_is_leq_pos
%%%}}}

Seja $x$ real tal que para todo $\epsilon > 0$, $0 \leq x < \epsilon$.
Logo $x = 0$.

\proof.
Como $x \geq 0$, basta eliminar o caso $x > 0$ (\ref[only_zero_is_leq_pos_proof]).

%%}}}

%%{{{ x: only_zero_is_leq_pos_proof 
\exercise.
%%%{{{ meta 
\label only_zero_is_leq_pos_proof
%%%}}}

Elimine!

\hint
Use a hipótese com $\epsilon := x$, já que $x > 0$ neste caso.

\solution
Basta eliminar o \proofcase {caso $x>0$:}
Mas neste caso, usamos o próprio $x$ na hipótese obtendo $0 \leq x < x$, que é uma contradição.

%%}}}

%%{{{ cor: real_ltlt_to_eq 
\corollary.
%%%{{{ meta 
\label real_ltlt_to_eq
%%%}}}

Sejam $a,b$ reais tais que para todo $\epsilon > 0$,
$a - \epsilon < b < a + \epsilon$.
Logo $a=b$.

\proof.
Tua: \ref[real_ltlt_to_eq_proof].

%%}}}

%%{{{ x: real_ltlt_to_eq_proof 
\exercise.
%%%{{{ meta 
\label real_ltlt_to_eq_proof
%%%}}}

Demonstre.

\hint
Resolveu o \ref[real_abs_properties_ball], né?

%%}}}

%%{{{ x: real_lt_to_leq 
\exercise.
%%%{{{ meta 
\label real_lt_to_leq
%%%}}}

Sejam $a,b$ reais.
Se para todo $\epsilon > 0$, $a < b + \epsilon$, então $a \leq b$.

\solution
Basta eliminar o caso $a > b$.
Neste caso, $a - b > 0$.
Logo $a < b + (a - b) = a$, contradição.

%%}}}

\endsection
%%}}}

%%{{{ Distance_on_reals 
\section Distância.
%%%{{{ meta 
\label Distance_on_reals
%%%}}}

%%{{{ spec: metric_reals 
\specification distância.
%%%{{{ meta 
\label metric_reals
\defines
    * distância
    * métrica
    * pré-distância
    * pré-métrica
    ;;
\indexes
    * pseudométrica         see: pré-métrica
    * métrica           seealso: distância
    * distância         seealso: métrica
    ;;
%%%}}}

Seja $d : \alpha \times \alpha \to \Real$.
Dizemos que $d$ é uma \dterm{distância} (ou \dterm{métrica}) no $\alpha$
sse todas as propriedades seguintes são satisfeitas:
\mathcall
& \dist d x y \geq 0                          \called {positividade (1)}  \stag[D-Range]  \\
& \dist d x y = \dist d y x                   \called {simetria}          \stag[D-Sym]    \\
& \dist d x y \leq \dist d x w + \dist d w y  \called {triangular}        \stag[D-Tri]    \\
& \dist d x x = 0                             \called {positividade (2)}  \stag[D-EqZero] \\
& \dist d x y = 0 \implies x = y.             \called {positividade (3)}  \stag[D-ZeroEq] \\
\endmathcall
Chamamos a $d$ de \dterm{pré-distância} (ou \dterm{pré-métrica}, ou \dterm{pseudométrica})
sse ela satisfaz as primeiras quatro dessas propriedades.

%%}}}

%%{{{ remark: variations and observations on metric_reals 
\remark.
%%%{{{ meta 
%%%}}}

Qual propriedade exatamente está sendo referida pelo termo \wq{positividade} varia
na literatura, mas costuma ser uma ou uma combinação das (1)--(3) anotadas acima;
eu vou evitar esse termo aqui.
A \mref[D-EqZero] é equivalente à recíproca da \mref[D-ZeroEq], e por isso às vezes são
juntadas em uma proposição só:
\mathcol
& \dist d x y = 0 \iff x = y. \\
\intertext {A contrapositiva da \mref[D-ZeroEq], graças à \mref[D-Range] acaba sendo equivalente à}
& x \neq y \implies \dist d x y > 0. \\
\endmathcol
que deixa mais clara a escolha do seu rótulo; em muitos textos é apresentada assim---aqui não.
A \mref[D-Tri] é conhecida como \dterm{desigualdade triangular}, um nome melhor justificado
quando consideramos distâncias num plano, onde corresponde à idéia que o melhor (mais curto)
caminho entre dois pointos é aquele que vai direto de um ($x$) para o outro ($y$);
medindo via terceiros pontos ($w$), em geral, pode aumentar a distância.

%%}}}

%%{{{ df: euclidean_metric_reals 
\definition distância euclideana.
%%%{{{ meta 
\label euclidean_metric_reals
%%%}}}

Chamamos a função
\mathcol
d &\eqtype \Real \times \Real \to \Real \\
\dist d a b &\defeq \abs{a - b}.
\endmathcol
de \dterm{distância eulideana}.

%%}}}

%%{{{ df: discrete_metric_reals 
\definition distância discreta.
%%%{{{ meta 
\label discrete_metric_reals
%%%}}}

Chamamos a função
\mathcol
d_0 &\eqtype \Real \times \Real \to \Real \\
\dist {d_0} a b
&\defeq \cased { 0,   & se $a = b$; \\
                 1,   & se $a \neq b$. }
\endmathcol
de \dterm{distância discreta}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Decidir chamar uma função de \wq{distância} não signifia que, de fato é.
Precisamos verificar que ela atende a \ref[metric_reals].
\wq{Precisamos}?  Quis dizer, precisas.  Agora.

%%}}}

%%{{{ x: euclidean_metric_justify_reals 
\exercise.
%%%{{{ meta 
\label euclidean_metric_justify_reals
%%%}}}

Justifique: a distância euclideana, de fato, é uma distância, ou seja, atende
a \ref[metric_reals].

%%}}}

%%{{{ x: discrete_metric_justify_reals 
\exercise.
%%%{{{ meta 
\label discrete_metric_justify_reals
%%%}}}

A distância discreta também.

%%}}}

%%{{{ Which metric? 
\note Qual distância?.
%%%{{{ meta 
%%%}}}

O estudo abstrato de distâncias, viz., a teoria dos espaços métricos, é o assunto
do \ref[Metric_spaces].
Para meus propósitos neste capítulo vamos concordar que quando é envolvida
uma métrica ou mencionada a palavra distância na conversa, sempre será a distância euclideana
(\reftag[euclidean_metric_reals]) exceto se especificamente mencionar outra.
No que segue, $d$ denota uma métrica, ou seja, uma função que satisfaz a \ref[metric_reals].

%%}}}

%%{{{ df: epsilon_close_reals 
\definition ε-perto.
%%%{{{ meta 
\label epsilon_close_reals
\defines
    * perto!$\epsilon$-, de um real
    ;;
%%%}}}

Seja $x,y$ reais e $\epsilon > 0$.
Dizemos que
$$
\text{o $x$ é $\epsilon$-perto do $y$}
\defiff
\dist d x y < \epsilon.
$$
Observe que a relação é simétrica (\ref[epsilon_close_is_symmetric])
e logo podemos escrever também:
$$
\text{os $x,y$ são $\epsilon$-perto (entre si)}.
$$

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Os $1$ e $2/3$ são $1/2$-perto (com a distância euclideana, mas não com a distância discreta).

%%}}}

%%{{{ x: epsilon_close_is_reflexive 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_reflexive
%%%}}}

Dado $\epsilon > 0$, seja $(\sim_\epsilon)$ a relação definida pela
$$
x \sim_\epsilon y
\defiff
\text{$x$ é $\epsilon$-perto do $y$}.
$$
Demonstre que $(\sim_\epsilon)$ é reflexiva.

\hint
$\abs{x - x} = 0$.

%%}}}

%%{{{ x: epsilon_close_is_symmetric 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_symmetric
%%%}}}

Dado $\epsilon > 0$, a $(\sim_\epsilon)$
do~\ref[epsilon_close_is_reflexive] é simétrica,
e logo podemos escrever frases como
$$
\textwq{os $x,y$ são $\epsilon$-perto (entre si)}.
$$

\solution
Precisamos demonstrar
$$
\dist d x y < \epsilon \iff
\dist d y x < \epsilon
$$
que segue imediatamente pela simetria da distância $d$ (\mref[D-Sym]).

%%}}}

%%{{{ x: epsilon_close_is_not_an_equivalence_relation 
\exercise.
%%%{{{ meta 
\label epsilon_close_is_not_an_equivalence_relation
%%%}}}

Existe algum $\epsilon > 0$ para qual
a $(\sim_\epsilon)$ do~\ref[epsilon_close_is_reflexive]
é uma relação \dterm{transitiva}?
$$
\text{$(\sim_\epsilon)$ é transitiva} \intiff \lforall {a,b,c} {a \sim_\epsilon b \mland b \sim_\epsilon c \implies a \sim_\epsilon c}.
$$

\hint
Não!
Por quê?

%%}}}

%%{{{ df: epsilon_ball_reals 
\definition ε-bola.
%%%{{{ meta 
\label epsilon_ball_reals
\defines
    * \ball {~\epsilon} {~{x_0}}  -- a $\epsilon$-bola do $x_0$
    * bola!$\epsilon$-, de real
    ;;
%%%}}}

Dado um ponto $c$, chamamos o conjunto de todos os pontos que
são $\epsilon$-perto do $c$ de \dterm{$\epsilon$-bola do $c$}:
$$
\ball \epsilon c
\defeq
\setstt {x} {$x$ é $\epsilon$-perto de $c$}.
$$
Também chamamos de \dterm{bola com centro $c$ e raio $\epsilon$}.

%%}}}

%%{{{ eg: couple of balls 
\example.
%%%{{{ meta 
%%%}}}

A $1/3$-bola do $7$ é o intervalo $(7 - 1/3, 7 + 1/3)$ e a $2$-bola do $0$ o $(-2,2)$.

%%}}}

%%{{{ x: same balls but now discrete 
\exercise.
%%%{{{ meta 
%%%}}}

Ache as mesmas bolas mas considerando como distância a discreta.

\solution
A $1/3$-bola do $7$ é o intervalo $(7 - 1/3, 7 + 1/3)$ e a $2$-bola do $0$ o $(-2,2)$.

%%}}}

%%{{{ lemma: balls_are_intervals_reals 
\lemma bolas nos reais.
%%%{{{ meta 
\label balls_are_intervals_reals
%%%}}}

Nos reais, bolas são intervalos da forma $(u,v)$ (com $u,v$ reais) e vice-versa.

\proof.
Associamos cada bola com um intervalo e vice versa
(quase isso: \ref[balls_are_intervals_reals_remark]).
\crproofpart {De bola $\ball r c$ para intervalo $(\uhole,\uhole)$.}
A bola $\ball r c$ é o intervalo $(c-r, c+r)$:
\compute
\ball r c
&= \setst {x} {\dist d x c < r} \noby \\
&= \setst {x} {\abs {x - c} < r}      \\
&= \setst {x} {c - r < x < c + r}     \\
&= (c - r, c + r).
\endcompute
\proofpart {De intervalo $(u,v)$ para bola $\ball \uhole \uhole$.}
Essa parte é tua (\ref[balls_are_intervals_reals_proof]).

%%}}}

%%{{{ x: balls_are_intervals_reals_proof 
\exercise.
%%%{{{ meta 
\label balls_are_intervals_reals_proof
%%%}}}

Termine a demonstração do \ref[balls_are_intervals_reals].

\hint
Precisa escolher qual será o centro $c$ e qual o raio $r$ da bola associada ao $(u,v)$,
e verificar que $\ball r c = (u,v)$ com tua escolha.

\solution
O intervalo $(u,v)$ de reais é a bola com centro
$c = (u + v) / 2$ e raio o $r = (v - u)/2$:
\compute
x \in \ball r c
&\iff \dist d x c < r \noby \\
&\iff \abs {x - c} < r      \\
&\iff c - r < x < c + r     \\
&\iff x \in (c - r, c + r)  \\
&\iff x \in \paren{\tfrac 12 (u+v) - \tfrac 1 2 (v-u), \tfrac 12 (u+v) + \tfrac 12 (v-u)} \\
&\iff x \in (u,v).
\endcompute

%%}}}

%%{{{ remark: balls_are_intervals_reals_remark 
\remark.
%%%{{{ meta 
\label balls_are_intervals_reals_remark
%%%}}}

Efetivamente definimos funções
$$
\cdopt{sep=2cm}
\Real \times \Real \ar[r, bend left=30, "\fpf {toInterval}"] \|
\Real \times \Real \ar[l, bend left=30, "\fpf {toBall}"]
\endcd
$$
entre centros-raios (de bolas) e inícios-fins (de intervalos),
e tais funções são inversas entre si (são?---\reftag[balls_are_intervals_reals_proof_detail_questions]).
Note que esses nomes não são exatamente honestos:
bolas e intervalos são conjuntos de reais, não parzinhos de reais.
Cada um desses conjuntos (tanto bola quanto intervalo), se é habitado,
tem uma única representação como parzinho de centro-raio, e uma única
representação como parzinho de início-fim.
Essas funções efetivamente traduzem entre tais representações.
E uma bola vazia?  E um intervalo vazio?
Ambos são o mesmo conjunto: o $\emptyset \is \SetA \Real$;
só que, visto como bola, ele tem uma infinidade de representações
(quais?---\reftag[balls_are_intervals_reals_proof_detail_questions])~e visto como intervalo,
também (quais?---\reftag[balls_are_intervals_reals_proof_detail_questions]).
As traduções estabelecidas mantêm a correspondência até entre tais representações,
algo que nem seria necessário para o objetivo de demonstrar o \ref[balls_are_intervals_reals].

%%}}}

%%{{{ x: balls_are_intervals_reals_proof_detail_questions 
\exercise.
%%%{{{ meta 
\label balls_are_intervals_reals_proof_detail_questions
%%%}}}

São?  Quais?  Quais?

\solution
A bola vazia e o intervalo vazio são representados pelos parzinhos dos conjuntos
\mathcols 2
&\setst {(c,r)} { r \leq 0 } &
&\setst {(v,u)} { u \leq v }
\endmathcols
respectivamente.

%%}}}

%%{{{ df: diam_in_reals 
\definition diâmetro.
%%%{{{ meta 
\label diam_in_reals
\defines
    * \diam {~A}    -- a diâmetro do conjunto de reais $A$
    * diâmetro
    ;;
%%%}}}

Seja $A$ um conjunto de reais.
Se o conjunto de todas as possíveis distâncias entre seus membros
$$
\setst {\dist d a b} {a, b \in A}
$$
possui supremum, o chamamos de \dterm{diâmetro} de $A$.
Ou seja,
$$
s = \diamA A \defiff s = \sup \setst {\dist d a b} {a, b \in A}
$$
escrevendo também
\mathcols 2
\diamA A = \minfty &\defiff \sup A = \minfty; &
\diamA A = \pinfty &\defiff \sup A = \pinfty.
\endmathcols
Aproveitando a ordem dos reais estendidos escrevemos
$$
\diamA A < \pinfty
$$
quando $\diamA A = \minfty$ ou quando para algum real $s$ temos $s = \diamA A$.

%%}}}

%%{{{ df: bounded_in_reals 
\definition cercado.
%%%{{{ meta 
\label bounded_in_reals
\defines
    * cercado
    ;;
%%%}}}

Chamamos um conjunto de reais de \dterm{cercado} sse ele está contido numa bola:
$$
\text{$A$ cercado}
\defiff
\pexists c
\lexists M
         {A \subset \ball M c}.
$$

%%}}}

%%{{{ x: bounded_vs_fenced_in_reals 
\exercise.
%%%{{{ meta 
\label bounded_vs_fenced_in_reals
%%%}}}

Seja $A$ conjunto de reais.
$$
\text{$A$ cotado}
\askiff
\text{$A$ cercado}.
$$

%%}}}

%%{{{ x: bounded_vs_fenced_in_reals_other_metrics 
\exercise.
%%%{{{ meta 
\label bounded_vs_fenced_in_reals_other_metrics
%%%}}}

No \ref[bounded_vs_fenced_in_reals] a resposta depende da métrica escolhida?
Justifique tua resposta com um contraexemplo ou com uma demonstração,
dependendo de se foi \wq{sim} ou \wq{não}.
Lembre-se que implicitamente munimos os reais com a métrica euclideana
(\ref[euclidean_metric_reals]).

\solution
Considere a distância discreta e o conjunto $\reals$.
Ele não é cotado; mas $\reals$ está contido na bola $\ball 2 0$;
de fato: $\ball 2 0 = \reals$.

%%}}}

\endsection
%%}}}

%%{{{ Limits_reals_before_completeness 
\section Limites.
%%%{{{ meta 
\label Limits_reals_before_completeness
%%%}}}

%%{{{ df: for_sufficiently_large_values_of 
\definition {pvsgd}.
%%%{{{ meta 
\label for_sufficiently_large_values_of
%%%}}}

Sejam $\phi : \Real \to \Prop$ um predicado sobre reais e $\seqn a n$ uma seqüência de reais.
Dizemos que \dterm{para valores suficientemente grandes de} $n$,
$\phi(a_n)$
sse a partir de um natural $N$ \dq{todos os $a_\phole$'s} satisfazem a $\phi$,
ou seja, sse
$$
\pexists N
\lforall {n \geq N}
         {\phi(a_n)}.
$$

%%}}}

%%{{{ eg: fslvo_eg_complexity_and_leap_years 
\example.
%%%{{{ meta 
\label fslvo_eg_complexity_and_leap_years 
%%%}}}

Para valores suficientemente grandes de $n$, $2^n > n^4 > 8n$.
Por outro lado, não é o caso que para valores suficientemente grandes de $n$,
o ano $n$ é bissexto.

%%}}}

%%{{{ df: eventually 
\definition eventualmente.
%%%{{{ meta 
\label eventually
%%%}}}

Seja um predicado $\phi \is \SeqA \Real \to \Prop$ sobre seqüências de reais,
e seja $\seqn a n$ uma seqüência de reais.
Dizemos que a $\seqn a n$ \dterm{eventualmente} satisfaz o $\phi$
sse para algum $N$, a subseqüência $\seq {a_n} {n \geq N}$ satisfaz o $\phi$,
ou seja,
$$
\text{eventualmente $\fP \phi {\seqn a n}$}
\defiff
\lexists {N}
         {\fP \phi {\seq {a_n} {n \geq N}}}.
$$

%%}}}

%%{{{ eg: eventually_eg_
\example.
%%%{{{ meta 
%%%}}}

A seqüência $\seq {\floor {2^8 / n}} n$ é eventualmente constante
(ainda mais, ela é eventualmente $0$).
Para qualquer $\epsilon > 0$, ela não está eventualmente contida no $(\epsilon, \pinfty)$;
ainda mais, ela fica eventualmente fora dele!

%%}}}

%%{{{ cor: cool_implies_eventually_cool 
\corollary.
%%%{{{ meta 
\label cool_implies_eventually_cool
%%%}}}

Seja $\seqn a n$ uma seqüência legal (qualquer coisa que isso significa).
Logo $\seqn a n$ é eventualmente legal.

\proof.
Basta escolher $N \asseq 0$,
já que a subseqüência $\seq {a_n} {n \geq 0}$ é a própria seqüência $\seqn a n$.

%%}}}

%%{{{ remark: nothing special about Seq Real here 
\remark.
%%%{{{ meta 
%%%}}}

Usamos as mesmas gírias sobre $\SeqA \alpha$; nada especial sobre o $\Real$ aqui.

%%}}}

%%{{{ df: limit_of_sequence_of_reals 
\definition limite.
%%%{{{ meta 
\label limit_of_sequence_of_reals
\defines
    * ~{\seqn a n} \tends ~\ell    -- a seqüência $\seqn a n$ tende ao $\ell$
    * ~{\seqn a n} \tends \pinfty  -- a seqüência $\seqn a n$ tende ao $\pinfty$
    * ~{\seqn a n} \tends \minfty  -- a seqüência $\seqn a n$ tende ao $\minfty$
    * limite!reais
    * seqüência!convergente
    * seqüência!divergente
    * tende
    ;;
\indexes
    * convergente   see: seqüência
    * divergente    see: seqüência
    ;;
%%%}}}

Sejam $\seqn a n$ uma seqüência de reais e $\ell$ um real.
Dizemos que $\seqn a n$ \dterm{tende ao} $\ell$
(ou \dterm{converge ao} $\ell$)
sse para qualquer bola de $\ell$,
a seqüência $\seqn a n$ eventualmente fica dentro dela.
Escrevemos $\seqn a n \tends \ell$;
ou seja, definimos o
$$
\uhole \tends \uhole \is \SeqA \Real \times \Real \to \Prop
$$
assim:
\mathcol
\seqn a n \tends \ell
&\defiff \text {qualquer bola de $\ell$ eventualmente contem a seqüência $\seqn a n$} \\
&\intiff
\lforallt {\epsilon > 0}
          {$\seqn a n$ está eventualmente contida na $\ball \epsilon \ell$} \\
&\intiff
\lforallt {\epsilon > 0}
          {$\seqn a n$ eventualmente fica $\epsilon$-perto de $\ell$} \\
&\intiff
\lforallt {\epsilon > 0}
          {para valores suficientemente grandes de~$n$, $a_n$ é $\epsilon$-perto de $\ell$} \\
&\intiff
\pforall  {\epsilon > 0}
\lexists  {N}
          {\seq {a_n} {n \geq N} \subset \ball \epsilon \ell} \\
&\intiff
\pforall  {\epsilon > 0}
\lexistst {N}
          {a partir de $N$, todos os $a_n$'s são $\epsilon$-perto de $\ell$} \\
&\intiff
\pforall  {\epsilon > 0}
\pexists  {N}
\lforallt {n \geq N}
          {$a_n$ é $\epsilon$-perto de $\ell$} \\
&\intiff
\pforall  {\epsilon > 0}
\pexists  {N}
\lforall  {n \geq N}
          {\dist d {a_n} \ell < \epsilon}.
\endmathcol
Escrevemos também
$$
\liml_n a_n = \ell
\qqtext{ou}
\lim \seqn a n = \ell
$$
como sinônimo de $\seqn a n \tends \ell$, e caso que isso aconteça
referimos a tal $\ell$ como um \dterm{limite} da $\seqn a n$.
Dizemos que uma seqüência é \dterm{convergente} sse ela converge àlgum real:
$$
\text{$\seqn a n$ é convergente}
\defiff
\lexists {\ell} {\seqn a n \tends \ell}.
$$
Senão, ela é \dterm{divergente}.
Destacamos um especial de seqüência divergente:
dizemos que $\seqn a n$ \dterm{diverge ao $\pinfty$} (ou até \dterm{tende ao $\pinfty$})
sse para qualquer $M > 0$ ela eventualmente fica acima do $M$, ou seja definimos o
$$
\uhole \tends \pinfty \is \SeqA \Real \to \Prop
$$
assim:
\mathcol
\seqn a n \tends \pinfty
&\defiff \text {a seqüência $\seqn a n$ eventualmente supera qualquer $M > 0$} \\
&\intiff
\lforallt {M > 0}
          {eventualmente $\seqn a n > M$} \\
&\intiff
\pforall  {M > 0}
\lexists  {N}
          {\seq {a_n} {n \geq N} > M} \\
&\intiff
\pforall  {M > 0}
\pexists  {N}
\lforall  {n \geq N}
          {a_n > M}.
\endmathcol
Escrevemos também
$$
\liml_n a_n = \pinfty
\qqtext{ou}
\lim \seqn a n = \pinfty.
$$
Similarmente definimos o $\uhole \tends \minfty \is \SeqA \Real \to \Prop$.

%%}}}

%%{{{ remark: n nought 
\remark.
%%%{{{ meta 
%%%}}}

É muito comum usar o nome \symq{$n_0$}
onde usei o \symq{$N$} nessas definições.
O \symq{$n_0$} é freqüêntemente lido \wq{$n$ nought} em inglês.

%%}}}

%%{{{ eg: examples of convergent/divergent/divergent-to-infty 
\example.
%%%{{{ meta 
%%%}}}

Dizemos que:
\mathtightcols 3
&\text {a seqüência} \quad& \seq 1 n            &= 1, 1, 1, \dotsc                          &\quad&\text {tende ao $1$}; \\
&\text {a seqüência}      & \seq {\sfrac 1 n} n &= 1, \sfrac 1 2, \sfrac 1 3, \sfrac 1 4, \dotsc &&\text {tende ao $0$}; \\
&\text {a seqüência}      & \seq {(-1)^n} n     &= 1, -1, 1, -1, \dotsc                          &&\text {diverge}; \\
&\text {a seqüência}      & \seq n n            &= 0, 1, 2, 3, \dotsc                            &&\text {diverge ao $\pinfty$}. \\
\endmathtightcols

%%}}}

%%{{{ x: limit_of_sequence_of_reals_uniqueness_needed 
\exercise.
%%%{{{ meta 
\label limit_of_sequence_of_reals_uniqueness_needed
%%%}}}

Uma notação introduzida na \ref[limit_of_sequence_of_reals]
é problemática; qual o problema e o que devemos fazer para resolvê-lo?

\hint
O problema fica na $\liml_n a_n = \ell$.
Qual é?

\solution
Devemos demonstrar pelo menos a unicidade dos limites para usar
a notação que envolve o símbolo \symq{$=$}.
Pois, se uma seqüência tendesse a dois reais distintos
$$
\seqn a n \tendsto \ell \neq \ell' \tendsfrom \seqn a n
$$
então escrevendo isso com as notações alternativas
\mathcols 2
\liml_n a_n &= \ell &
\liml_n a_n &= \ell'
\endmathcols
inferíamos (confundindo tal notação com igualdade) $\ell = \ell'$
contradizendo nossa hipótese.

%%}}}

%%{{{ alternating_quantifiers 
\note Quantificadores alternantes.
%%%{{{ meta 
\label alternating_quantifiers
\defines
    * matemalhar
    ;;
%%%}}}

Provavelmente essa foi a primeira definição que tu encontraste
que necessitou três alternações de quantificadores:
$$
\forall\dots\exists\dots\forall\dots
$$
Para cada alteração de quantificação que seja adicionada
numa afirmação, o processo de digeri-la naturalmente fica
mais complicado para nossa mente!
Com experiência, \dterm{matemalhando}, essas definições
com três quantificadores ficarão mais e mais digeríveis.
Mesmo com essa experiência, num momento vamos encontrar
uma afirmação com \emph{quatro} quantificações alternantes,
e a dificuldade vai voltar e te lembrar dessa dificuldade
que talvez sentes agora.
Felizmente, temos duas ferramentas indispensáveis que deixam o processo
bem mais tranqüilo do que talvez parece:
(i) \emph{as ferramentas formais dos fundamentos matemáticos} que nos permitem
trabalhar com proposições sem necessariamente digeri-las completamente;
(ii) \emph{as ferramentas informais das gírias} que estamos desenvolendo com
e para nosso coração matemático que nos ajudam entender, visualizar,
e pensar sobre as noções e proposições sobre quais estamos trabalhando.
(Divulguei isso na \ref[Heart_level_and_slang] mas provavelmente era
cedo demais para ser devidamente entendido e apreciado.)

%%}}}

%%{{{ quantifier_games 
\note Jogos e estratégias.
%%%{{{ meta 
\label quantifier_games
\defines
    * jogo!de quantificadores
    * estratégia vencedora
    ;;
%%%}}}

Considere que quero demonstrar que $\seqn a n \tends 4$.
Meu alvo então, olhando na última linha da \ref[limit_of_sequence_of_reals], é
$$
\pforall  {\epsilon > 0}
\pexists  {N}
\lforall  {i \geq N}
          {\dist d {a_i} 4 < \epsilon}.
$$
Considere um jogo, onde eu estou jogando contra meu inimigo, o jogador-($\exists$)
debatendo a vericidade dessa proposição.  (Eu sou o jogador-($\forall$).)
Cada troca de tipo-de-quantificador corresponde em troca de jogador para jogar.
O jogo começa então com o ($\forall$) escolhendo um $\epsilon > 0$:
vamos dizer o $\sfrac 1 2$; interpretamos seu movimento como um desafio.
Respondemos a ele escolhendo um $N$ (vamos dizer o $6$) e agora novamente
é a vez do ($\forall$) jogar.  Ele precisa escolher um $i \geq 6$, e ele escolhe
o $8$.  Agora acabaram os quantificadores, e logo podemos olhar na proposição
formada por essas escolhas:
$$
\dist d {a_8} 4 < \sfrac 1 2.
$$
Se ela é válida, ganhei.
Senão, perdi.
O dialogo desta jogada ficou assim:
\dialogue
\say Duvido que para o $\sfrac 1 2 > 0$ tu consegue escolher um $N$ que serve.
\say Escolho o $6$.
\say Escolho o $8$ (posso pois $8 \geq 6$).
\enddialogue
Note que não podemos inferir a corretude duma proposição dessas a partir
duma partida.  Talvez eu perdi só porque fui burro enquanto se tivesse
jogado melhor eu teria ganhado.  Mas também talvez ganhei só porquê meu inimigo
foi burro, e jogando contra um jogador melhor eu ia perder.
O que podemos de fato usar (para inferir em forma correta que uma tal proposição
é válida) é a existência duma \dterm{estratégia vencedora} para mim, ou seja,
uma estratégia que determina como eu preciso jogar contra qualquer
possível movimento do meu inimigo e chegar numa vitória.

%%}}}

%%{{{ eg: ones tends to one 
\example.
%%%{{{ meta 
%%%}}}

A seqüência $1, 1, 1, \dotsc$ tende a $1$.

\solution.
Seja $\epsilon>0$.
O desafio é achar um $N$ tal que a partir de $N$,
todos os membros da seqüência são $\epsilon$-perto de $1$.
Tome $N \asseq 0$, e seja $n \geq N$.
Obviamente o $n$-ésimo termo da seqüência é $\epsilon$-perto do $1$,
pois ele é igual ao $1$ mesmo, e logo a distância deles é $0$, e logo menor que $\epsilon$.
Observe que qualquer escolha de $N$ aqui funcionaria para fechar a demonstração.

%%}}}

%%{{{ x: eventually_conv_iff_conv 
\exercise.
%%%{{{ meta 
\label eventually_conv_iff_conv
%%%}}}

$
\text{$\seqn a n$ eventualmente convergente}
\iff
\text{$\seqn a n$ convergente}.
$

%%}}}

%%{{{ x: const_implies_conv_in_reals 
\exercise.
%%%{{{ meta 
\label const_implies_conv_in_reals
%%%}}}

$
\text{$\seqn a n$ constante}
\implies
\text{$\seqn a n$ convergente}.
$

\solution
Seja $\seqn a n$ constante.
Logo seja $c$ tal que $\lforall n {a_n = c}$.
Basta demonstrar que $\seqn a n \to c$.
Seja $\epsilon > 0$.
Basta demonstrar: $\lforall {n \geq 0} {\dist {a_n} c < \epsilon}$.
Seja $m \geq 0$.
Calculamos
\compute
\dist d {a_m} c
&= \dist d c c  \by {escolha de $c$} \\
&= 0            \by {\mref[D-EqZero]} \\
&< \epsilon.
\endcompute

%%}}}

%%{{{ x: eventually_const_implies_conv_in_reals 
\exercise.
%%%{{{ meta 
\label eventually_const_implies_conv_in_reals
%%%}}}

$
\text{$\seqn a n$ eventualmente constante}
\implies
\text{$\seqn a n$ convergente}.
$

\solution
Seja $\seqn a n$ eventualmente constante.
Logo seja $M$ tal que $\pexists c \lforall {n \geq M} {a_n = c}$.
Logo seja $c$ tal que $\lforall {n \geq M} {a_n = c}$.
Vou demonstrar que $\seqn a n \to c$.
Seja $\epsilon > 0$.
Basta demonstrar: $\lforall {n \geq M} {\dist d {a_n} c < \epsilon}$. 
Seja $m \geq M$.
Temos $\dist d {a_m} c = \dist d c c = 0 < \epsilon$.

%%}}}

%%{{{ x: diverges_to_infty_diverges 
\exercise.
%%%{{{ meta 
\label diverges_to_infty_diverges
%%%}}}

Toda seqüência que diverge ao $\pinfty$, diverge.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Como tu já resolveste o~\ref[limit_of_sequence_of_reals_uniqueness_needed]---né?---tu
sabes que precisamos demonstrar a unicidade dos limites.
E a existência?
A existência não é garantida (vamos descobrir isso agora
no~\ref[alternating_zero_one_does_not_have_a_limit]),
então precisamos tomar os mesmos cuidados com o símbolo $\lim$
que tomamos com os $\sup$, $\min$, etc.;
e precisando vê-lo como operador, é um operador \emph{parcial}.

%%}}}

%%{{{ eg: alternating_zero_one_does_not_have_a_limit 
\example.
%%%{{{ meta 
\label alternating_zero_one_does_not_have_a_limit
%%%}}}

A seqüência $0,1,0,1,\dotsc$, definida pela
$$
a_n \defeq \cased { 0, & se $n$ par; \\
                    1, & caso contrário; }
$$
é divergente.

\solution Demonstração.
Primeiramente: o que precisamos demonstrar?
Que para qualquer possível limite $\ell$,
$$
\seqn a n \ntendsto \ell.
$$
Seja $\ell$ tal que $\seqn a n \tends \ell$.
O que isso significa?
$$
\seqn a n \tends \ell
\heartiff
\pforall  {\epsilon > 0}
\lexistst {N}
          {$N$ garanta que a partir dele todos são $\epsilon$-perto de $\ell$}.
$$
Para conseguir usar esse dado (um $(\forall)$),
basta aplicá-lo em qualquer real positivo que queremos, e ele vai fornecer
de volta um novo dado.
Por exemplo, o aplicando no $1$ (que de fato é positivo: \reftag[real_one_is_positive])
obtemos o novo dado
$$
\lexistst {N}
          {$N$ garanta que a partir dele todos os $a_i$'s são $1$-perto de $\ell$}.
$$
Para aproveitar esse novo dado agora, solicitamos tal $N$.
Seja $N$ tal que
$$
\lforallt {n \geq N} {$a_n,\ell$ são $1$-perto}.
$$
Novamente um $(\forall)$; essa vez para utilizá-lo precisamos o aplicar
em naturais a partir do $N$.
Agora a idéia é conseguir dois membros da seqüência que são suficientemente longe
entre si para garantir que não tem como ambos estar $1$-perto de $\ell$.
\eop
Refletindo pouco deve parecer óbvio que não temos como conseguir isso.
Nossa seqüência só pega os valores $0,1$, cuja distância é $1$, e logo
considerando o $\frac 1 2$ como um possível $\ell$ percebemos que 
ambos conseguem ficar $1$-perto dele.
Qual foi o problema?
\eop
Nossa escolha de $\epsilon > 0$ foi grande demais.
A gente poderia ter escolhido um epsilonzinho melhor,
como por exemplo o $\sfrac 1 2$ ou o $\sfrac 1 4$.
Precisamos um tal que, para qualquer candidato $\ell$,
a $\epsilon$-bola dele vai ser tão pequena que
seria impossível possuir dois membros com distança $1$,
como os únicos membros da nossa seqüência tem ($\dist d 0 1 = 1$).
Aqui poderíamos escolher o $\sfrac 1 2$, e daria certo,
mas não existe motivo de ser tão dramáticos.
Vamo escolher algo menor ainda; que tal $\sfrac 1 3$.
Obtemos assim um novo $N$, essa vez garantindo que a partir dele
todos os membros da seqüência são $\sfrac 1 3$-perto de $\ell$.
Como $2N, 2N+1 \geq N$, logo os $a_{2N}$ e $a_{2N+1}$ ambos são
$\sfrac 1 3$-perto de $\ell$.
Calculamos:
\compute
\dist d {a_{2N}} {a_{2N+1}}
&= \dist d 0 1
 = \abs{0 - 1}
 = 1;
\intertext {mas também:}
\dist d {a_{2N}} {a_{2N+1}}
&\leq \dist d {a_{2N}} \ell + \dist d \ell {a_{2N+1}}  \by {$(\leq)$-triangular} \\
&< \sfrac 1 3 + \dist d \ell {a_{2N+1}} \\
&< \sfrac 1 3 + \sfrac 1 3 \\
&= \sfrac 2 3,
\endcompute
chegando assim na contradição $1 < \frac 2 3$.

%%}}}

%%{{{ thm: uniqueness_of_limits_of_reals 
\theorem unicidade de limites.
%%%{{{ meta 
\label uniqueness_of_limits_of_reals
%%%}}}

Seja $\seqn a n$ seqüência de reais tal que
\mathcols 2
\seqn a n &\tends \ell_1 &
\seqn a n &\tends \ell_2.
\endmathcols
Logo $\ell_1 = \ell_2$.

\proof.
Graças ao~\ref[only_zero_is_leq_pos] basta demonstrar
que $\dist d {\ell_1} {\ell_2} < \epsilon$ para todo $\epsilon > 0$.
Seja $\epsilon > 0$ então, e agora observe que para quaisquer
$\epsilon_1,\epsilon_2>0$ podemos escolher $N_1,N_2$ tais que:
\mathcols 2
\cforall {i \geq N_1} {\dist d {a_i} {\ell_1} < \epsilon_1} &
\cforall {i \geq N_2} {\dist d {a_i} {\ell_2} < \epsilon_2}.
\endmathcols
Seja $N = \max\set{N_1, N_2}$.
Logo
\mathcols 2
\dist d {a_N} {\ell_1} &< \epsilon_1 &
\dist d {a_N} {\ell_2} &< \epsilon_2.
\endmathcols
Calculamos
\compute
\dist d {\ell_1} {\ell_2}
&\leq \dist d {\ell_1} {a_N} + \dist d {a_N} {\ell_2} \by {\mref[D-Tri]} \\
&= \dist d {\ell_1} {a_N} + \dist d {\ell_2} {a_N}    \by {\mref[D-Sym]} \\
&< \epsilon_1 + \epsilon_2.                           \by {escolha dos $\epsilon_1,\epsilon_2$} \\
\intertext {Lembre-se que isso é válido para quaisquer $\epsilon_1,\epsilon_2>0$,
então basta selecioná-los para satisfazer $\epsilon_1+\epsilon_2\leq\epsilon$
(tome por exemplo ambos (menores ou) iguais ao $\epsilon/2$).
Assim demonstramos que para todo $\epsilon > 0$,}
0 \leq \dist d {\ell_1} {\ell_2} &< \epsilon,         \by {a $(0 \leq)$ vem pela \mref[D-Range]}
\endcompute
e logo $\dist d {\ell_1} {\ell_2} = 0$ (pelo \ref[only_zero_is_leq_pos]),
e portanto $\ell_1 = \ell_2$ (pela \mref[D-ZeroEq]).

%%}}}

%%{{{ teaser: directed set preview 
\teaser conjuntos dirigidos.
%%%{{{ meta 
\defines
    * dominar
    * conjunto!dirigido
    ;;
\indexes
    * dirigido      see: conjunto
    ;;
%%%}}}

Com a linha
\quote
\wq{Seja $N = \max\set{N_1, N_2}$.}
\endquote
eu apenas escolhi um nome (\sq{$N$}) para referir ao $\max(N_1, N_2)$---só
para facilitar minha escrita mesmo.
Note que esta linha \emph{não foi} uma solicitação feita
usando um dado existencial $(\exists)$.\foot
Essa parte já foi feita quando definimos (\reftag[real_min_max_binary])
\emph{a função} $\max$.
\toof
Mas a única propriedade que precisei desse $N$ na demonstração
foi a $N \geq \set{N_1,N_2}$ e logo eu poderia ter usado a linha
\quote
\wq{Seja $N$ tal que $N \geq \set{N_1, N_2}$.},
\endquote
essa vez usando mesmo um teoreminha que garanta tal existência.
Considere um conjunto habitado $D \is \SetA \Nat$ e membros dele $d_1,d_2 \in D$.
O mundo dos naturais já garanta que, sem precisar saber nada mais sobre o $D$
nem sobre os $d_1,d_2$, existe membro $d \in D$ que \dterm{domina} ambos:
um $d$ tal que $d_1 \leq d$ e $d_2 \leq d$, uma cota superior deles dentro do próprio $D$.
Como conseguir tal $d$?
Simplesmente tome o máximo dos $d_1,d_2$, aproveitando que a ordem dos naturais
é total e, o máximo sendo um dos dois, com certeza é um membro do $D$.
Note que a mesma coisa vale sobre conjuntos de inteiros, de reais, e em geral
conjuntos munidos com uma ordem total.  E se não tiver essa totalidade aí?
Muitas vezes basta saber a existência dum bicho no $D$ com essa propriedade do $d$
sem precisar ser o máximo, nem (menos forte) a melhor cota superior (o supremum),
mas apenas (ainda menos forte) \emph{uma cota superior} deles.
Conjuntos como o $D$, cuja ordem garanta essa existência, são chamados \dterm{dirigidos}
(ou \dterm{directed}) e seu papel vai acabar sendo critical mais que uma vez neste texto.

%%}}}

%%{{{ x: seq_of_intreal_conv_implies_eventually_const 
\exercise.
%%%{{{ meta 
\label seq_of_intreal_conv_implies_eventually_const
%%%}}}

Ache algo interessante para o \wq{\askdots} e demonstre sua afirmação:
$$
\text{$\seqn a n$ convergente}
\mland
\text{eventualmente $\seqn a n \subset \intreals$}
\implies
{\askdots}
$$

\hint
$
\text {$\seqn a n$ convergente}
\mland
\text {eventualmente $\seqn a n \subset \intreals$}
\implies
\text {$\seqn a n$ é eventualmente constante}.
$

%%}}}

%%{{{ x: eventually_const_implies_bounded_in_reals 
\exercise.
%%%{{{ meta 
\label eventually_const_implies_bounded_in_reals
%%%}}}

$
\text{$\seqn a n$ eventualmente constante}
\implies
\text{$\seqn a n$ cotada}.
$

%%}}}

%%{{{ thm: conv_implies_fenced_in_reals 
\theorem.
%%%{{{ meta 
\label conv_implies_fenced_in_reals
%%%}}}

Toda seqüência de reais convergente é cercada.

\proof.
Seja $\seqn a n$ convergente e logo seja $\ell$ seu limite.
Logo, usando $\epsilon \asseq 1$ seja $N$ tal que a partir do $a_N$
todos os $a_n$'s são $1$-perto de $\ell$, ou seja,
$\seq {a_n} {n \geq N} \subset \ball 1 \ell$.
Possivelmente precisamos um raio maior que $1$ para conseguir conter
a seqüência inteira.
Observe que o conjunto $\setst {\dist d \ell {a_i}} {i \leq N}$
das distâncias entre o $\ell$ e seus primeiros termos (até o $N$-ésimo) é finito e habitado,
e logo (pelo \ref[every_finite_set_of_reals_has_min_and_max]) seja
$M$ seu máximo.
$$
M = \max \setst {\dist d \ell {a_i}} {i \leq N}.
$$
Agora só basta verificar que a bola $\ball {M+1} \ell$ cerca a seqüência inteira
(\ref[conv_implies_fenced_in_reals_proof]).

%%}}}

%%{{{ x: conv_implies_fenced_in_reals_proof 
\exercise.
%%%{{{ meta 
\label conv_implies_fenced_in_reals_proof
%%%}}}

Feche a demonstração do \ref[conv_implies_fenced_in_reals].

%%}}}

%%{{{ cor: conv_implies_bounded_in_reals 
\corollary.
%%%{{{ meta 
\label conv_implies_bounded_in_reals
%%%}}}

Toda seqüência convergente é cotada.

\proof.
Graças à equivalência entre cercada e cotada (\ref[bounded_vs_fenced_in_reals])
seque imediatamente pelo \ref[conv_implies_fenced_in_reals].

%%}}}

%%{{{ x: conv_implies_bounded_in_reals_from_scratch 
\exercise.
%%%{{{ meta 
\label conv_implies_bounded_in_reals_from_scratch
%%%}}}

Demonstre o \ref[conv_implies_bounded_in_reals] em forma
direta, adaptando o que precisa na demonstração do
\ref[conv_implies_fenced_in_reals].

\solution
Seja $\seqn a n$ tal que $\seqn a n \tends \ell$.
Logo, usando $\epsilon \asseq 1$ seja $N$ tal que a partir do $a_N$
todos os $a_n$'s são $1$-perto de $\ell$.
Observe que o conjunto $\set{a_0, \dotsc, a_N}$
é finito e habitado, e logo (\ref[every_finite_set_of_reals_has_min_and_max])
possui mínimo $m$ e máximo $M$:
$$
m \leq a_0, \dotsc, a_N \leq M.
$$
Agora, observe que a seqüência é cotada por baixo pelo
$\min \set{ m , \ell - 1 }$ e cotada por cima pelo
$\max \set{ M , \ell + 1 }$.

%%}}}

\endsection
%%}}}

%%{{{ Limits_and_structure_of_reals_before_completeness 
\section Limites e a estrutura atual.
%%%{{{ meta 
\label Limits_and_structure_of_reals_before_completeness
%%%}}}

%%{{{ lim_respect
\note Comportamento respeituoso.
%%%{{{ meta 
\label lim_respectful_behaviour_reals 
%%%}}}

Nossa estrutura atual de reais tem uma parte algébrica $(0, 1, +, \ntimes, -)$
e uma parte relacional $(>)$.
Estabelecemos agora que os limites se comportam bem (de forma \dterm{respeituosa})
com ambas as partes.
Vamo começar com a parte algébrica.

%%}}}

% ALGEBRAIC STRUCTURE

%%{{{ x: algebraic_limit_theorem_for_reals_map_add_c 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_for_reals_map_add_c 
%%%}}}

Sejam $\seqn a n$ seqüência de reais e $a$ tal que $\seqn a n \tends a$.
Seja $c$ real.
Logo:
$$
\seq {c + a_n} n \tends c + a.
$$

%%}}}

%%{{{ x: algebraic_limit_theorem_for_reals_map_mult_c 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_for_reals_map_mult_c 
%%%}}}

Sejam $\seqn a n$ seqüência de reais e $a$ tal que $\seqn a n \tends a$.
Seja $c$ real.
Logo:
$$
\seq {ca_n} n \tends ca.
$$

\solution
\proofcase {Caso $c = 0$:}
já demonstrado, pois acaba sendo reduzido à convergência $\seq 0 n \to 0$ (\ref[const_implies_conv_in_reals]).
\crproofcase {Caso $c \neq 0$:}
Seja $\epsilon > 0$.
Como $\seqn a n \tends a$, logo seja $N$ tal que
$$
\lforall {n \geq N} {d(a_n,a) < \epsilon/\abs{c}}.
$$
Asserção: $\lforall {n \geq N} {d(ca_n, ca) < \epsilon}$.
Seja $n \geq N$.
Logo $d(a_n,a) < \epsilon/\abs{c}$ (pela escolha de $N$).
Calculamos:
\compute
\dist d {ca_n} {ca}
&= \abs{ca_n + ca} \noby \\
&= \abs{c(a_n - a)} \\
&= \abs{c}\abs{a_n - a} \\
&= \abs c d(a_n,a) \\
&= \abs c \frac \epsilon {\abs c} \\
&< \epsilon.
\endcompute

%%}}}

%%{{{ x: algebraic_limit_theorem_for_reals_pw_add 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_for_reals_pw_add
%%%}}}

Sejam $\seqn a n, \seqn b n$ seqüências de reais e $a,b$ tais que
$\seqn a n \tends a$ e $\seqn b n \tends b$.
Logo:
$$
\seq {a_n + b_n} n \tends a + b.
$$

\solution
Seja $\epsilon > 0$.
Pelas escolhas de $a,b$, sejam $N_a$ e $N_b$ tais que
    $$
    \lforall {n \geq N_a} {d(a_n,a) < \epsilon/2}
    \qquad\mland\qquad
    \lforall {n \geq N_b} {d(b_n,b) < \epsilon/2}.
    $$
Seja $N \geq \set {N_a,N_b}$.
Preciso demonstrar que $\lforall {n \geq N} {d(a_n + b_n, a + b) < \epsilon}$.
Seja $n \geq N$.
Logo $n \geq N_a$ e $n \geq N_b$ (pela escolha de $N$).
Logo $d(a_n,a) < \epsilon/2$ e $d(b_n,b) < \epsilon/2$ (pelas escolhas de $N_a$ e $N_b$).
Calculamos:
\compute
    d(a_n + b_n, a + b)
    &=    \abs{(a_n + b_n) - (a + b)} \noby \\
    &=    \abs{(a_n - a) + (b_n - b)}       \\
    &\leq \abs{a_n - a} + \abs{b_n - b}     \\
    &=    d(a_n,a) + d(b_n,b)               \\
    &<    \epsilon/2 + \epsilon/2           \\
    &=    \epsilon.
\endcompute

%%}}}

\TODO analisar o próximo exercício.

%%{{{ x: algebraic_limit_theorem_for_reals_pw_mult 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_for_reals_pw_mult
%%%}}}

Sejam $\seqn a n, \seqn b n$ seqüências de reais e $a,b$ tais que
$\seqn a n \tends a$ e $\seqn b n \tends b$.
Logo:
$$
\seq {a_n b_n} n \tends a b.
$$

\solution
Vou demonstrar $\sequence {a_nb_n} n \to ab$.
Seja $\epsilon > 0$.
Como $\seqn a n$ é cotada, seja $M_a > 0$ uma cota dela.
Pelas escolhas de $a,b$, sejam $N_a$ e $N_b$ tais que
\mathcols 3
\cforall {n \geq N_a} {d(a_n,a) < \frac \epsilon {2|b|+1}} & \mland &&
\cforall {n \geq N_b} {d(b_n,b) < \frac \epsilon {2M_a}}.
\endmathcols
Seja $N = \max(N_a,N_b)$.
Calculamos:
\compute
    d(a_n b_n, a b)
    &=    \abs{(a_n b_n) - (a b)} \noby \\
    &=    \abs{(a_n b_n) - a_n b + a_n b - (a b)} \\
    &=    \abs{a_n (b_n- b) + (a_n - a) b} \\
    &\leq \abs{a_n (b_n- b)} + \abs{(a_n - a) b} \\
    &\leq \abs{a_n} \abs{b_n- b} + \abs{a_n - a}\abs{b} \\
    &\leq M_a \abs{b_n- b} + \abs{a_n - a}\abs{b} \\
    &<    M_a \frac \epsilon {2M_a} + \frac \epsilon {2\abs{b}+1}\abs{b} \\
    &<    \epsilon/2 + \epsilon/2 \\
    &=    \epsilon.
\endcompute

%%}}}

%%{{{ x: algebraic_limit_theorem_for_reals_pw_div 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_reals_pw_div
%%%}}}

Sejam $\seqn a n, \seqn b n$ seqüências de reais e $a,b$ tais que
$\seqn a n \tends a$ e $\seqn b n \tends b$.
Considere a proposição:
$$
\seq {a_n / b_n} n \tends a/b.
$$
Enuncie uma hipótese adicional necessária para sua demonstração e demonstre.

%%}}}

%%{{{ thm: algebraic_limit_theorem_pw_add 
\theorem.
%%%{{{ meta 
\label algebraic_limit_theorem_pw_add
%%%}}}

Sejam $\seqn a n, \seqn b n$ seqüências de reais convergentes.
Logo
\mathcols 2
&\lim_n (a_n + b_n)        =  \lim_n a_n + \lim_n b_n; &
&\lim_n (- a_n)            = -\lim_n a_n; \\
&\lim_n (a_n \ntimes b_n)  =  \lim_n a_n \ntimes \lim_n b_n; &
&\lim_n (\minv {b_n})      =  \minvp {\lim_n b_n}; \\
&\lim_n (a_n / b_n)        =  \lim_n a_n / \lim_n b_n. \\
\endmathcols
onde nas duas últimas supomos adicionalmente que todos os $b_n$'s são não nulos, e o $b$ também.

%%}}}

%%{{{ algebraic_limits_reals_commutative_diagram 
\note Diagramas comutativos.
%%%{{{ meta 
\label algebraic_limits_reals_commutative_diagram
\defines
    * diagrama!comutativo
    ;;
\indexes
    * função!parcial
    ;;
%%%}}}

Podemos expressar o teorema
$$
\PROOFmn {
   \A {\seqn a n \tends a}
                           \A {\seqn b n \tends b}
\I2-----------------------------------------------
     {\seqn a n \oplus \seqn b n \tends a + b}
}
$$
(que acabei de expressar em forma de regra de inferência aqui)
em forma dum \dterm{diagrama comutativo}, assim:
$$
\cdopt{sep=2cm}
\SeqA \Real \times \SeqA \Real
\ar[r, harpoon, "\lim \times \lim"]
\ar[d, "(\oplus)"']          \| \Real \times \Real
                                \ar[d, "(+)"]         \\
\SeqA \Real
\ar[r, harpoon, "\lim"]      \| \Real
\endcd
$$
Mas o que significa que o diagrama acima comuta?
Observe que temos duas maneiras de começar na esquina superior-esquerda
e chegar na esquina inferior-direita:
(i) atravessar à direita, e depois descer; ou
(ii) descer, e depois atravessar.
Observe que cada um desses caminhos determina uma função de tipo
$$
\cdopt{sep=2cm}
\SeqA \Real \times \SeqA \Real
\ar[dr, harpoon, out=east,  in=north,
    "\tobrace {{(+)} \of {(\lim \times \lim)}} {a soma dos limites}"]
\ar[dr, harpoon, out=south, in=west,
    "\tubrace {{\lim} \of {(\oplus)}} {o limite das somas}"']
    \| \\
    \| \Real
\endcd
$$
e, afirmando que \dterm{o diagrama comuta}, afirmamos que esses caminhos
correpondem em funções iguais.\foot
Lembre que usamos o $(\parto)$ quando se trata e função \emph{parcial},
possivelmente não conseguindo retornar um valor do seu codomínio.
\toof
Nesse diagrama, atravessar à direita corresponde em \dq{pegar limites},
enquanto descer corresponde em \dq{somar}.
Note que não são exatamete as mesmas funções as correspondem no
\wq{atravessar à direita}: tendo um par de seqüências, denotamos por
\mathcol
\lim \times \lim &\eqtype \SeqA \Real \times \SeqA \Real \parto \Real \times \Real
\itext
a função que aplica a $\lim$ em cada componente da sua entrada e retorna
o par das saidas:
\enditext
(\lim \times \lim) \fa (\seqn a n, \seqn b n) &\defeq (\lim \seqn a n, \lim \seqn b n).
\itext
E sobre o \wq{descer} também não é exatamente a mesma coisa nos dois lados:
descer no lado direito é a soma $(+)$ entre reais,
mas descer no lado esquerdo é a soma pointwise $(\oplus)$
entre seqüências de reais:
\enditext
(\oplus) &\eqtype \SeqA \Real \times \SeqA \Real \to \SeqA \Real \\
(\oplus) &\defeq \pwA {(+)}.
\endmathcol

%%}}}

% RELATIONAL STRUCTURE

%%{{{ blah: from algebraic to relational
\blah.
%%%{{{ meta 
%%%}}}

Tendo investigado a parte algébrica da estrutura dos reais
tornamos agora para investigar a parte relacional.

%%}}}

%%{{{ x: order_limit_theorem_reals 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_reals
%%%}}}

Sejam $\seqn a n, \seqn b n$ seqüências de reais e $a,b$ tais que
$\seqn a n \tends a$ e $\seqn b n \tends b$.
Adivinhe algo interessante que podemos inferir se $a<b$; enuncie e demonstre.

\hint
Seria errado inferir que $\seqn a n < \seqn b n$.

\hint
Mas eventualmente?

\hint
Demonstre que eventualmente $\seqn a n < \seqn b n$, ou seja, que
$$
\pexists N
\lforall {n \geq N}
         {a_n < b_n}.
$$

%%}}}

%%{{{ x: order_limit_theorem_reals_converse 
\exercise.
%%%{{{ meta 
\label algebraic_limit_theorem_reals_converse
%%%}}}

E o recíproco?

%%}}}

%%{{{ thm: sandwich_limit_theorem_reals 
\theorem Teorema Sanduíche.
%%%{{{ meta 
\headerize
\label sandwich_limit_theorem_reals
\defines
    * teorema!sanduíche
    ;;
\indexes
    * teorema!squeeze   see: sanduíche
    ;;
%%%}}}

Sejam $\seqn a n, \seqn b n, \seqn c n \is \SeqA \Real$ tais que
$$
\seqn a n \leq \seqn b n \leq \seqn c n.
$$
Logo se $\seqn a n$ e $\seqn c n$ tendem ao mesmo real $\ell$,
então $\seqn b n$ também tende ao $\ell$.

\proof Demonstrarás agora no~\ref[sandwich_limit_theorem_reals_proof].

%%}}}

%%{{{ x: sandwich_limit_theorem_reals_proof
\exercise.
%%%{{{ meta 
\label sandwich_limit_theorem_reals_proof
%%%}}}

Demonstre o~\ref[sandwich_limit_theorem_reals].

%%}}}

%%{{{ dotted_arrows_in_diagrams_reals 
\question.
%%%{{{ meta 
\label dotted_arrows_in_diagrams_reals
%%%}}}

No diagrama seguinte as setas denotam o \wq{$\uhole$ tende a $\uhole$}:
$$
\cdopt{sep=0.333cm}
\seqn a n
\ar[ddrr, bend right=15] \| \leq \| \seqn b n \ar[dd, dotted] \| \leq \| \seqn c n
                                                                         \ar[ddll, bend left=15] \\
                         \|      \|                           \|      \|           \\
                         \|      \| \ell                      \|      \|           \\
\endcd
$$
Qual tua acha que é a interpretação da seta pontilhada?

%%}}}

\spoiler

%%{{{ dotted_arrows_in_diagrams_reals_answer 
\note Setas pontilhadas.
%%%{{{ meta 
\label dotted_arrows_in_diagrams_reals_answer 
\defines
    * diagrama!linha pontilhada
    ;;
%%%}}}

A idéia é ler esses diagramas em dois tempos.
No primeiro tempo ignore as setas pontilhadas: o que fica é o contexto, os dados, e as hipoteses.
Leia isso como um \wq{se a gente tem tudo isso\dots}.
As setas pontilhadas entram no segundo tempo, completando a implicação assim:
\wq{\dots então temos essas setas (pontilhadas) também.}.

%%}}}

%%{{{ thm: powers_of_small_tends_to_zero 
\theorem.
%%%{{{ meta 
\label powers_of_small_tends_to_zero
%%%}}}

Seja $0 < \theta < 1$.
Logo $\seq {\theta^n} n \tends 0$.

\proof.
Como $\theta < 1$, logo $1/\theta > 1$,
e logo seja $\delta > 0$ tal que $1/\theta = 1 + \delta$.
Seja $n \in \nats$.
Usando a desigualdade Bernoulli obtemos
$$
0
\leq
\theta^n
=
\frac 1 {(1+\delta)^n}
\relby {\leq} {\reftag[bernoulli_ineq_0]}
\frac 1 {1 + n\delta}.
$$
Temos então
$$
\seq 0 n
\leq
\seq {\theta^n} n
\leq
\seq {\dfrac 1 {1 + n\delta}} n
$$
com as seqüências à esquerda e à direita tendendo ao mesmo limite $0$,
e logo a $\seq {\theta^n} n$ que fica no meio também tende ao $0$
pelo \ref[sandwich_limit_theorem_reals].

%%}}}

\endsection
%%}}}

%%{{{ Autoconvergent_sequences 
\section Seqüências autoconvergentes.
%%%{{{ meta 
\label Autoconvergent_sequences
\credits
    * Cauchy : seqüências autoconvergentes
    ;;
%%%}}}

%%{{{ df: Cauchy_sequence_of_reals 
\definition autoconvergente.
%%%{{{ meta 
\label Cauchy_sequence_of_reals
\defines
    * seqüência!autoconvergente
    ;;
\indexes
    * Cauchy!seqüência    see: autoconvergente
    * seqüência!Cauchy    see: autoconvergente
    * autoconvergente     see: seqüência
    ;;
\credits
    * Cauchy : seqüência
    ;;
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Dizemos que $\seqn a n$ é \dterm{autoconvergente}
(ou \dterm{Cauchy}) sse para qualquer $\epsilon > 0$ existe
um membro da seqüência tal que a partir dele, todos os seus
membros são $\epsilon$-perto entre si (dois a dois).
Formalmente:
\mathcol
\text{$\seqn a n$ autoconvergente}
&\defiff 
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i,j \geq N}
{$a_i,a_j$ são $\epsilon$-perto}.
\endmathcol

%%}}}

%%{{{ thm: conv_implies_Cauchy_in_reals 
\theorem.
%%%{{{ meta 
\label conv_implies_Cauchy_in_reals
%%%}}}

Toda seqüência de reais convergente é autoconvergente.

\sketch.
Seja $\seqn a n$ convergente com limite $\ell$.
Dado um desafio $\epsilon>0$, precisamos achar $N$
tal que a partir de $N$ os membros da $\seqn a n$ ficam $\epsilon$-perto entre si.
A idéia é obter um índice tal que a partir dele todos os membros dá $\seqn a n$
são $\frac \epsilon 2$-perto de $\ell$.
Assim quaisquer dois deles não podem ter distância maior
que $\frac \epsilon 2 + \frac \epsilon 2$.

%%}}}

%%{{{ thm: Cauchy_implies_fenced_in_reals 
\theorem.
%%%{{{ meta 
\label Cauchy_implies_fenced_in_reals
%%%}}}

Toda seqüência de reais autoconvergente é cercada.

\sketch.
Suponha $\seqn a n$ autoconvergente.
Logo seja $N$ tal que a partir de $N$, todos os $a_n$'s ficam $1$-perto entre si.
Ou seja: $\lforall {i,j \geq N} {d(a_i,a_j) < 1}$.
Vou achar uma bola para cercar a seqüência.
Basta determinar seu centro e seu raio.
Como centro, tome o $a_N$.
Observe (\reftag[Cauchy_implies_fenced_in_reals_proof]) que a bola $\ball 1 {a_N}$ contem todos os membros da $\seq {a_n} {n \geq N}$,
mas não garanta nada sobre os $a_0, \dotsc, a_{N-1}$.
Como $\seqset {a_i} {i \leq N}$ é finito e habitado,
logo seja $r = \max \setst {\dist d {a_N} {a_i}} {i \leq N} + 1$.
Observe (\reftag[Cauchy_implies_fenced_in_reals_proof]) que a bola $\ball r {a_N}$ contem todos os membros do $\seqset {a_i} {i < N}$
mas não garanta nada sobre os $a_N, a_{N+1}, \dotsc$.
Basta então considerar a bola com raio o maior dos dois raios $M = \max(1, r)$
e verificar (\reftag[Cauchy_implies_fenced_in_reals_proof])
que, de fato, $\seqn a n \subset \ball M {a_N}$.

%%}}}

%%{{{ x: Cauchy_implies_fenced_in_reals_proof 
\exercise.
%%%{{{ meta 
\label Cauchy_implies_fenced_in_reals_proof
%%%}}}

\dq{Observe} o que ficou para observar, e verifique o que ficou para verificar
na demonstração do \ref[Cauchy_implies_fenced_in_reals].

%%}}}

%%{{{ cor: Cauchy_implies_bounded_in_reals 
\corollary.
%%%{{{ meta 
\label Cauchy_implies_bounded_in_reals
%%%}}}

Toda seqüência de reais autoconvergente é cotada.

\proof.
Imediato pois já demonstramos que nos reais cotada e cercada são
noções equivalentes (\ref[bounded_vs_fenced_in_reals]).

%%}}}

%%{{{ x: Cauchy_implies_bounded_in_reals_from_scratch 
\exercise.
%%%{{{ meta 
\label Cauchy_implies_bounded_in_reals_from_scratch
%%%}}}

Demonstre o \ref[Cauchy_implies_bounded_in_reals] em forma
direta, adaptando o que precisa na demonstração do
\ref[Cauchy_implies_fenced_in_reals].

\solution
Suponha $\seqn a n$ autoconvergente.
Logo seja $N$ tal que a partir de $N$, todos os $a_n$'s ficam $1$-perto entre si.
Ou seja: $\lforall {i,j \geq N} {d(a_i,a_j) < 1}$.
Vou achar uma cota $M_1$ para os $\set{a_n}_{n < N}$
e uma cota $M_2$ para os $\set{a_n}_{n \geq N}$.
Assim a seqüência inteira é cotada pelo $\max\set{M_1,M_2}$.
Seja $M_1 = \max\set{\abs{a_n}}_{n < N}$,
definido pois $\set{\abs{a_n}}_{n < N}$ é um conjunto habitado e finito.
Bastra mostrar que para qualquer $n \geq N$, $a_n \leq |a_N| + 1$.
Temos
$$
\abs{a_n} - \abs{a_N} \leq \abs{a_n - a_N} = d(a_n, a_N) < 1.
$$
Logo $\abs{a_n} < \abs{a_N} + 1$.

%%}}}

%%{{{ blah: new proof as corollary 
\blah.
%%%{{{ meta 
%%%}}}

Tendo demonstrado as implicações
$$
\text{convergente}
\impliesbecause{\reftag[conv_implies_Cauchy_in_reals]}
\text{autoconvergente}
\mathcoled {
&\impliesbecause{\reftag[Cauchy_implies_fenced_in_reals]}  \text{cercada} \\
&\impliesbecause{\reftag[Cauchy_implies_bounded_in_reals]} \text{cotada}
}
$$
obtemos novas demonstrações dos
$$
\text{convergente}
\mathcoled {
&\impliesbecause{\reftag[conv_implies_fenced_in_reals]}  \text{cercada} \\
&\impliesbecause{\reftag[conv_implies_bounded_in_reals]} \text{cotada}.
}
$$

%%}}}

%%{{{ x: Cauchy_implies_convergent_in_intreals 
\exercise.
%%%{{{ meta 
\label Cauchy_implies_convergent_in_intreals
%%%}}}

Demonstre: toda seqüência autoconvergente de reais inteiros é convergente.

%%}}}

%%{{{ df: subsequence_of_real_seq 
\definition Subseqüência.
%%%{{{ meta 
\label subsequence_of_real_seq
%%%}}}

Seja $\seqn a n \is \SeqA \Real$.
Dada qualquer estritamente crescente $\seqn n i \is \SeqA \Nat$,
chamamos a $\seq {a_{n_i}} i$ de \dterm{subseqüência} da $\seqn a n$.
Equivalentemente, dizemos que uma seqüência $\seqn b n$ é uma subseqüência
da $\seqn a n$ sse existem
$$
n_0 < n_1 < n_2 < \dotsc
$$
tais que para todo $i$, temos $b_i = a_{n_i}$.

%%}}}

%%{{{ x: conv_implies_every_subseq_conv 
\exercise.
%%%{{{ meta 
\label conv_implies_every_subseq_conv
%%%}}}

Sejam $\seqn a n \tends \ell$.
Logo toda subseqüência de $\seqn a n$ também tende ao $\ell$.

%%}}}

%%{{{ x: bounded_implies_Cauchy_subseq_in_reals.
\exercise.
%%%{{{ meta 
\label bounded_implies_Cauchy_subseq_in_reals
%%%}}}

Verifique: toda seqüência cotada possui subseqüência autoconvergente.

%%}}}

%%{{{ autoconv vs conv  
\note Autoconvergente \vs convergente.
%%%{{{ meta 
%%%}}}

Demonstramos no \ref[conv_implies_Cauchy_in_reals] que
\mathcol
\text{autoconvergente}
&\impliedby \text{convergente}.
\itext
Por enquanto não conseguimos demonstrar a recíproca
\enditext
\text{autoconvergente}
&\askimplies \text{convergente}
\endmathcol
mas também não conseguimos encontrar nenhum contraexemplo.
Agora vamos investigar o que acontece se acrescentar a hipótese que
a seqüência possui subseqüência convergente e vamos pelo menos
conseguir a implicação
$$
\rightbrace
{ \mathed {  \text{autoconvergente}
             \\ +
             \\ \text{subseqüência convergente} }
}
\implies \text{convergente}:
$$

%%}}}

%%{{{ thm: Cauchy_with_conv_subseq_implies_convergent_in_reals 
\theorem.
%%%{{{ meta 
\label Cauchy_with_conv_subseq_implies_convergent_in_reals
%%%}}}

Toda seqüência autoconvergente que possui subseqüência convergente é convergente.

\proof.
Seja $\seqn a n$ autoconvergente e seja uma subseqüência convergente dela $\seq {a_{k_i}} i$,
e logo seja $\ell$ seu limite.
Vou demonstrar que $\seqn a n \tends \ell$.
Seja $\epsilon > 0$.
Como $\seqn a n$ autoconvergente, seja $N$ tal que
\mathcol
\cforall {m,n \geq N} {\dist d {a_m} {a_n} < \epsilon_1}.
\intertext {Como $\seq {a_{k_i}} i \tends \ell$, seja $I$ tal que}
\cforall {i \geq I} {\dist d {a_{k_i}} \ell < \epsilon_2}.
\endmathcol
Seja $J \geq I$ tal que $k_J \geq N$.  (Justifique!)
Vou demonstrar que a partir do $k_J$-ésimo termo da $\seqn a n$,
todos os seus termos ficam $\epsilon$-perto do $\ell$.
Seja $n \geq k_J$ então, e logo $n \geq N$ também.
Calculamos:
\compute
\dist d {a_n} \ell
&\leq \dist d {a_n} {a_{k_J}} + \dist d {a_{k_J}} \ell  \by {\mref[D-Tri]} \\
&< \epsilon_1 + \dist d {a_{k_J}} \ell                  \by {pois $n,k_J \geq N$} \\
&< \epsilon_1 + \epsilon_2                              \by {pois $J \geq I$} \\
&= \epsilon.
\endcompute

%%}}}

%%{{{ thm: real_monotone_subseq_thm 
\theorem.
%%%{{{ meta 
\label real_monotone_subseq_thm
%%%}}}

Toda seqüência de reais tem subseqüência crescente ou decrescente.

\proof.
Introduzimos o conceito de posição de pico de seqüência:
dizemos que $P$ é uma \dterm{posição de pico} para a $\seqn a n$
sse $a_P \geq \seq {a_n} {n \geq P}$.
Para achar uma subseqüência desejada, separamos em casos a partir
da quantidade de posições de pico da $\seqn a n$.
\crproofcase {Caso finita:}
teu (\ref[real_monotone_subseq_thm_proof_finitely_many_peaks]).
\crproofcase {Caso contrário:}
também teu (\ref[real_monotone_subseq_thm_proof_infinitely_many_peaks]).

%%}}}

%%{{{ x: real_monotone_subseq_thm_proof_finitely_many_peaks 
\exercise.
%%%{{{ meta 
\label real_monotone_subseq_thm_proof_finitely_many_peaks
%%%}}}

Feche o primeiro caso.

\hint
Aqui dá para conseguir uma subseqüência crescente.

%%}}}

%%{{{ x: real_monotone_subseq_thm_proof_infinitely_many_peaks 
\exercise.
%%%{{{ meta 
\label real_monotone_subseq_thm_proof_infinitely_many_peaks
%%%}}}

E o segundo.

\hint
Aqui dá para conseguir uma subseqüência decrescente.

%%}}}

\TODO Terminar.

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Última chance:
será que podes pensar numa resposta para
a~\ref[how_can_we_separate_reals_from_rats]?

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

\TODO Add problems.

%%{{{ prob: exp_over_factorial_limit 
\problem.
%%%{{{ meta 
\label exp_over_factorial_limit
%%%}}}

(i) Demonstre que
$$
\lim_n \frac {2^n} {\fac n} = 0.
$$
(ii) Podemos trocar esse \sq{$2$} por quais números mantendo esse limite?

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\dotsb
$$

\hint
$$
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{1 \ntimes 2 \ntimes 3 \ntimes 4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac
{2 \ntimes 2 \ntimes 2}
{1 \ntimes 2 \ntimes 3}
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
=
\frac 4 3
\ntimes
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 5 \ntimes 6 \ntimes 7 \ntimes \dotsb}
\leq
\frac
{2 \ntimes 2 \ntimes 2 \ntimes 2 \ntimes \dotsb}
{4 \ntimes 4 \ntimes 4 \ntimes 4 \ntimes \dotsb}
$$
e agora?

%%}}}

%%{{{ prob: extended_reals_metric 
\problem.
%%%{{{ meta 
\label extended_reals_metric
%%%}}}

Tem como definir uma distância no $\ExtReal$ com qual
o sigificado de $\seqn a n \tends \pinfty$ acabaria sendo simplesmente
o significado de $\seqn a n \tends \ell$ para o $\ell \asseq \pinfty$?

%%}}}

%%{{{ prob: three_subseqs_that_guarantee_conv_reals 
\problem.
%%%{{{ meta 
\label three_subseqs_that_guarantee_conv_reals
\indexes
    * metademonstração
    ;;
%%%}}}

Seja $\seqn a n$ tal que suas subseqüências $\seq {a_{2n}} n$, $\seq {a_{2n+1}} n$,
e $\seq {a_{3n}} n$ são todas convergentes.
\tlist:
\li (i):   Demonstre que as três subseqüências convergem ao mesmo limite $\ell$.
\li (ii):  (Meta)demonstre que apagando qualquer uma das três hipoteses
           o~(i)~vira indemonstrável.
\li (iii): Demonstre que $\seqn a n \tends \ell$.
\endtlist

%%}}}

\endproblems
%%}}}

%%{{{ Completeness_of_reals 
\section Completude.
%%%{{{ meta 
\label Completeness_of_reals
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora temos tudo que precisamos para responder
à~\ref[how_can_we_separate_reals_from_rats].
Nossa resposta com palavras de rua é
\standout
\emph{a linha dos reais não tem ``buracos''}
\endstandout
mas precisamos formalizar essa proposição.\foot
No~\ref[Cantors_paradise] encontraremos uma outra
resposta à~\ref[how_can_we_separate_reals_from_rats],
de natureza diferente.  Paciência!
\toof
A idéia é exigir que \emph{não falta nenhum supremum}---ou, dualmente,
nenhum infimum, pois é a mesma coisa:
uma afirmação acaba implicando a outra.
Mas o que significa dizer que não falta nenhum supremum?
E, nenhum mesmo?  Não.
Um conjunto que nem é bounded above não tem chances de ter supremum.
Um conjunto vazio, também não.
Vamos exigir suprema para todos os outros então:

%%}}}

%%{{{ spec: real_spec_3 
\specification Os reais (3/3).
%%%{{{ meta 
\label real_spec_3
\defines
    * reais
    ;;
%%%}}}

Estipulamos um último axioma:
\mathcol
\cforall {A \isubset \reals}
         {\text{$A$ cotado por cima} \implies \text{$A$ tem supremum}}.
\stag[R-Compl-lub]
\endmathcol

%%}}}

%%{{{ blah: the rest of this chapter is a teaser to calculus/analysis 
\blah.
%%%{{{ meta 
%%%}}}

Terminamos com este a lista de todos os axiomas que vamos estipular
sobre os números reais.  As conseqüências desses axiomas, ou seja, a
\dterm{teoria dos números reais} é o que estudamos em
\dterm{calculus} e \dterm{análise real}.
O resto deste capítulo é um teaserzinho dessa teoria linda;
e, como sempre, no fim tenho ponteiros na literatura para mergulhar mais.
No~\ref[Metric_spaces] voltamos nessa investigação de análise real,
pois estudamos a teoria dos \emph{espaços métricos}:
conjuntos equipados com uma noção de distância, ou seja,
uma função binária \emph{com valores reais}, satisfazendo certas leis.

%%}}}

%%{{{ cor: bounded_below_subsets_have_infima 
\corollary.
%%%{{{ meta 
\label bounded_below_subsets_have_infima
%%%}}}

Seja $A$ conjunto habitado de reais, cotado por baixo.
Logo $A$ possui infimum.

\proof Demonstrarás agora no~\ref[bounded_below_subsets_have_infima_proof].

%%}}}

%%{{{ x: bounded_below_subsets_have_infima_proof 
\exercise.
%%%{{{ meta 
\label bounded_below_subsets_have_infima_proof
%%%}}}

Demonstre o~\ref[bounded_below_subsets_have_infima].

\hint
Tu vai precisar usar a lei de completude.

\hint
Procure definir um subconjunto de $\reals$
que será garantido ter um supremum, e use
esse supremum para definir o infimum de $A$.

%%}}}

%%{{{ remark: now inf and sup are total operations on extended reals 
\remark.
%%%{{{ meta 
%%%}}}

Assim as operações $\inf$ e $\sup$ viram totais nos reais estendidos:
$$
\inf,\sup \is \SetA \ExtReal \to \ExtReal.
$$

%%}}}

%%{{{ x: sup_and_inf_of_unions_reals 
\exercise.
%%%{{{ meta 
\label sup_and_inf_of_unions_reals
%%%}}}

Sejam $A,B$ habitados e cotados.  Logo $A\union B$ também é, e
\mathcols 2
\sup (A \union B) &= \max \set {\sup A, \sup B} &
\inf (A \union B) &= \min \set {\inf A, \inf B}.
\endmathcols

%%}}}

%%{{{ x: sup_and_inf_commute_with_plus_reals 
\exercise.
%%%{{{ meta 
\label sup_and_inf_commute_with_plus_reals
%%%}}}

Sejam $A,B$ habitados e cotados.  Logo $A + B$ também é, e
\mathcols 2
\sup (A + B) &= \sup A + \sup B &
\inf (A + B) &= \inf A + \inf B.
\endmathcols

%%}}}

%%{{{ x: sup_and_inf_commute_with_plus_reals_investigate 
\exercise.
%%%{{{ meta 
\label sup_and_inf_commute_with_plus_reals_investigate
%%%}}}

E se não são habitados?  Ou cotados?

%%}}}

%%{{{ x: sup_and_inf_commute_with_plus_reals_commutative_diagrams 
\exercise.
%%%{{{ meta 
\label sup_and_inf_commute_with_plus_reals_commutative_diagrams
%%%}}}

Expresse essas leis usando apenas diagramas comutativos.

%%}}}

%%{{{ x: sup_and_inf_commute_with_times_check_reals 
\exercise.
%%%{{{ meta 
\label sup_and_inf_commute_with_times_check_reals
%%%}}}

Sejam $A,B$ habitados e cotados.
Mostre que, em geral, não são garantidas as
Demonstre:
\mathcols 2
\sup (A \ntimes B) &= \sup A \ntimes \sup B &
\inf (A \ntimes B) &= \inf A \ntimes \inf B
\endmathcols
mas, adicionando uma hipotese interessante demonstre que ambas são válidas.

\hint
Adicione a hipotese que $A,B > 0$, ou seja, que todos os seus membros são positivos.

%%}}}

\endsection
%%}}}

%%{{{ MCT_NIP_CCC_BW 
\section MCT, NIP, CCC, B--W.
%%%{{{ meta 
\label MCT_NIP_CCC_BW
%%%}}}

%%{{{ thm: monotone_convergence_thm 
\theorem Monotone Convergence Theorem.
%%%{{{ meta 
\aka MCT.
\headerize
\label monotone_convergence_thm
%%%}}}

Toda seqüência monótona e cotada é convergente:
$$
\text{monótona} \mland \text{cotada} \implies \text{convergente}. \stag[MCT]
$$

\proof.
Seja $\seqn a n$ seqüência crescente e sup-cotada.
Logo $\seqnset a n$ sup-cotado e logo seja $s$ o seu supremum.
Vou demonstrar que $\seqn a n \tends s$.
Seja $\epsilon > 0$.
Pela escolha de $s$, $s - \epsilon$ não pode ser sup-cota da $\seqn a n$,
e logo seja $N$ tal que $a_N > s - \epsilon$.
Temos então $s - \epsilon < a_N < s$.
Como $\seqn a n$ crescente, temos $s - \epsilon < \seq {a_n} {n \geq N} < s$.
Logo $\seq {a_n} {n \geq N} \subset \ball \epsilon s$.

%%}}}

%%{{{ x: powers_of_small_tends_to_zero_mct_proof 
\exercise.
%%%{{{ meta 
\label powers_of_small_tends_to_zero
%%%}}}

Seja $0 < \theta < 1$.
Demonstre que $\seq {\theta^n} n \tends 0$
(já demonstrado no~\ref[powers_of_small_tends_to_zero]),
mas essa vez construa uma nova demonstração,
para obtê-lo como corolário simples do \ref[monotone_convergence_thm].

\hint
Mostre que $\seq {\theta^n} n$ é decrescente e inf-cotada (por quem mesmo?).

\hint
Pelo (MCT), seja $\ell$ o limite da $\seq {\theta^n} n$.

\hint
Calcule o $\ell$ para chegar no $\ell = \theta\ell$, e obtenha $\ell = 0$ a partir disso.

\hint
Em geral, $\lim_n a n = \lim_n {a_{n+1}}$, onde entendemos esta igualdade como:
ou ambas as seqüências convergem no mesmo limite, ou ambas as seqüências divergem.

\solution
Primeiramente vou mostrar que $\seq {\theta^n} n$ é inf-cotada e decrescente,
assim garantido que é convergente; depois vou garantir que tal limite só pode ser o $0$.
\eop
Vou mostrar por indução que $\seq {\theta^n} n \geq 0$.
Temos $\theta^0 = 1 \geq 0$, estabelecendo a base da indução.
Seja $k$ natural tal que $\theta^k \geq 0$.
Temos:
$$
\theta^{k+1}
  =    \theta^k\theta
  \geq 0
$$
como produto de não-negativos.
\eop
Vou mostrar que $\seq {\theta^n} n$ é decrescente.
Seja $k$ natural.
Calculamos:
$$
\theta^{k+1}
= \theta^k \theta
< \theta^k.
$$
Pelo (MCT), seja $\ell = \lim_n {\theta^n}$.
Basta mostrar $\ell = 0$.
Usando o \ref[algebraic_limit_theorem_for_reals_map_mult_c], calculamos:
$$
\ell
= \lim_n {\theta^n}
= \lim_n {\theta^{n+1}}
= \lim_n {\theta^n \theta}
= \theta \lim_n {\theta^n}
= \theta \ell.
$$
Logo $\ell = 0$, pois caso $\ell\neq0$ poderiamos aplicar o cancelamento multiplicativo para obter $\theta = 1$, contradizendo nossa hipótese sobre $\theta$.

%%}}}

%%{{{ thm: Bolzano_Weierstrass_theorem 
\theorem Teorema Bolzano--Weierstrass.
%%%{{{ meta 
\aka B--W.
\headerize
\label Bolzano_Weierstrass_theorem
\credits
    * Bolzano : --Weierstrass, teorema
    * Weierstrass : Bolzano--, teorema
    ;;
%%%}}}

Toda seqüência cotada de reais tem subseqüência convergente:
$$
\text{cotada}
\implies
\text{subseqüência~convergente}.
\stag[B--W]
$$

\proof.
\proofsteps
\steptnb {Seja $\seqn a n$ cotada.}
\steptby {Logo $\seqn a n$ possui subseqüência monótona (e cotada) $\seq {a_{n_i}} i$.}
         {\ref[real_monotone_subseq_thm]}
\steptby {Logo a subseqüência $\seq {a_{n_i}} i$ é convergente.}
         {\ref[monotone_convergence_thm]}
\endproofsteps

%%}}}

%%{{{ thm: nested_interval_theorem_reals 
\theorem Nested Intervals Property (Cantor).
%%%{{{ meta 
\aka NIP.
\headerize
\label nested_interval_theorem_reals
\credits
    * Cantor : intervalos aninhados
    ;;
\defines
    * teorema!de intervalos aninhados de Cantor
    ;;
%%%}}}

Seja $\seqn I n$ seqüência aninhada de intervalos fechados, cotados, e habitados, ou seja,
tais que
$$
I_0 \supset I_1 \supset I_2 \supset I_3 \supset \dotsb
$$
Logo, a interseção deles é um intervalo fechado e habitado.
Ainda mais, se $\seq {\diam(I_n)} n \tends 0$, então a interseção é um singleton.

\proof.
Sejam, para cada $i$, $a_i, b_i$ os reais tais que $I_i = [a_i, b_i]$.
Como os intervalos da $\seq I n$ são aninhados, temos
$$
a_0 \leq a_1 \leq a_2 \leq a_3 \leq \dotsb \leq b_3 \leq b_2 \leq b_1 \leq b_0.
$$
Considere a seqüência $\seqn a n$.
Ela é crescente e sup-cotada (pelo $b_0$).
Logo seja $a_\omega = \sup_n a_n = \lim_n a_n$.
Similarmente, seja $b_\omega = \inf_n b_n = \lim_n b_n$.
Graças a ti (que tu vai fechar esses detalhes no \ref[nested_interval_theorem_reals_proof])
temos:
$$
\seqn a n \leq a_\omega \leq b_\omega \leq \seqn b n
\qqtext{e}
\Inter_n I_n = [a_\omega, b_\omega]
$$
e logo habitado pois $a_\omega \leq b_\omega$.
Supondo que $\seq {\diam I_n} n \tends 0$, calculamos:
\compute
\dist d {a_\omega} {b_\omega}
&= b_\omega - a_\omega  \noby \\
&= \lim_n b_n - \lim_n a_n \\
&= \lim_n (b_n - a_n) \\
&= \lim_n \dist d {a_n} {b_n} \\
&= \lim_n \diam(I_n) \\
&= 0
\endcompute
e logo $a_\omega = b_\omega$.
Logo $\Inter_n I_n = [a_\omega, b_\omega]$ é o singleton $\set {a_\omega = b_\omega}$.

%%}}}

%%{{{ x: nested_interval_theorem_reals_proof 
\exercise.
%%%{{{ meta 
\label nested_interval_theorem_reals_proof
%%%}}}

Feche o que faltou para fechar na demonstração do \reftag[nested_interval_theorem_reals].

%%}}}

%%{{{ x: nested_interval_theorem_reals_necessary_hypotheses 
\exercise.
%%%{{{ meta 
\label nested_interval_theorem_reals_necessary_hypotheses
%%%}}}

Demonstre que as hipoteses do~\ref[nested_interval_theorem_reals] sobre os
intervalos serem fechados e cotados são \emph{necessárias}.

%%}}}

%%{{{ thm: Cauchy_iff_convergent_in_reals 
\theorem Cauchy Convergence Criterion.
%%%{{{ meta 
\aka CCC.
\headerize
\label Cauchy_iff_convergent_in_reals
%%%}}}

Toda seqüência de reais autoconvergente é convergente:
$$
\text{autoconvergente} \implies \text{convergente}. \stag[CCC]
$$

\proof.
\proofsteps
\steptnb {Seja $\seqn a n$ autoconvergente.}
\steptby {Logo $\seqn a n$ cotada.}
         {\ref[Cauchy_implies_bounded_in_reals]}
\steptby {Logo $\seqn a n$ possui subseqüência convergente.}
         {\ref[Bolzano_Weierstrass_theorem]}
\steptby {Logo $\seqn a n$ convergente.}
         {\ref[Cauchy_with_conv_subseq_implies_convergent_in_reals]}
\endproofsteps

%%}}}

\TODO finish.

\endsection
%%}}}

%%{{{ Archimedean_properties_reals 
\section Propriedades arquimedeanas.
%%%{{{ meta 
\label Archimedean_properties_reals
\defines
    * propriedade!archimedeana
    ;;
\credits
    * Archimedes : propriedade
    ;;
%%%}}}

\TODO fix.

%%{{{ 6 properties 
\note.
%%%{{{ meta 
%%%}}}

Considere as proposições seguintes sobre o conjunto dos reais positivos:
\mathcols 3
&\mathcoled { &\text {$\natreals$ não é cotado} \\
              &\lforallt {\epsilon} {$\epsilon \natreals$ não é cotado} } &
&\mathcoled { &\pforall  {\epsilon} \lexists {n\in\natreals} { 1/n < \epsilon } \\
              &\pforall  {\epsilon} \lexists {n\in\natreals} { n \epsilon > 1 } } &
&\mathcoled { &\pforall  {s} \pforall {b} \lexists {n\in\natreals} { b/n < s } \\
              &\pforall  {b} \pforall {s} \lexists {n\in\natreals} { n s > b }. }
\endmathcols
Há diferença entra as duas da última coluna?
Como chamarias cada uma no «nível coração»?

%%}}}

%%{{{ df: infinitely_small_or_big 
\definition infinitamente pequeno ou grande.
%%%{{{ meta 
\label infinitely_small_or_big
\defines
    * infinitamente!pequeno
    * infinitamente!grande
    ;;
\indexes
    * grande     see: infinitamente
    * pequeno    see: infinitamente
    ;;
%%%}}}

Sejam $u,v$ reais positivos.
Dizemos que:
\mathcol
\text{$u$ alcança subindo o $v$}  &\defiff \lexists {n\in\natreals} {u n > v}; \\
\text{$u$ alcança descendo o $v$} &\defiff \lexists {n\in\natreals} {u/n < v}.
\endmathcol
Sejam $b,s$ reais positivos.
Chame $b$ de \dterm{infinitamente grande}
sse existe positivo $u$ que não alcança subindo o $b$;
Chame $s$ de \dterm{infinitamente pequeno}
sse existe positivo $u$ que não alcança descendo o $s$.

%%}}}

%%{{{ blah: from algebraic to relational
\blah.
%%%{{{ meta 
%%%}}}

Com essa terminologia, as últimas duas proposições acima viram pronunciáveis assim:
\mathcols 2
&\pforall {s} \tobrace {\pforall {b} \tubrace {\lexists {n\in\natreals} { b/n < s }}
                                              {$b$ alcança descendo o $s$} }
                       {$s$ não é infinitamente pequeno} &
&\pforall {b} \tobrace {\pforall {s} \tubrace {\lexists {n\in\natreals} { ns > b }}
                                              {$s$ alcança subindo o $b$} }
                       {$b$ não é infinitamente grande}.
\endmathcols

%%}}}

%%{{{ thm: natreals_is_not_bounded 
\theorem.
%%%{{{ meta 
\label natreals_is_not_bounded
%%%}}}

O $\natreals$ não é cotado.

\proof.
Suponha que $\natreals$ cotado, e logo seja $s = \sup \natreals$ (pelo axioma da completude, pois $\natreals$ habitado também).
Considere o $s - 1$.
Temos $s - 1 < s$, e logo $s - 1$ não é uma sup-cota do $\natreals$.
Logo seja $n \in \natreals$ tal que $s - 1 < n$.
Como $\natreals$ é $(+1)$-fechado, logo $n + 1 \in \natreals$.
Mas $s < n + 1$, contradizendo que $s > \natreals$.

%%}}}

%%{{{ cor: natreals_beat_epsilons 
\corollary.
%%%{{{ meta 
\label natreals_beat_epsilons
%%%}}}

$\pforall {\epsilon > 0} \lexists {N} {\frac 1 n < \epsilon}$.

%%}}}

%%{{{ cor: epsilon_natreals 
\corollary.
%%%{{{ meta 
\label epsilon_natreals
%%%}}}

$\lforallt {\epsilon > 0} {$\epsilon\natreals$ não é cotado por cima}$.

%%}}}

%%{{{ thm: reals_is_archimedean 
\theorem.
%%%{{{ meta 
\label reals_is_archimedean
\defines
    * archimedeano
    ;;
%%%}}}

O $\reals$ é \dterm{arquimedeano}, ou seja:
para todo $x,y\in\reals$,
$$
x > 0
\implies
\lexists {n \in \natreals} {xn > y}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Roots_reals 
\section Raizes.
%%%{{{ meta 
\label Roots_reals
%%%}}}

%%{{{ thm: square_root_of_small_reals 
\theorem.
%%%{{{ meta 
\label square_root_of_small_reals
%%%}}}

Seja $0 \leq a \leq 1$.
Logo a seqüência de reais $\seqn a n$ definida pelas
\mathcol
a_0 &= 0 \\
a_{n+1} &= a_n + \frac 1 2 {(a - a_n^2)}
\endmathcol
converge ao $\sqrt a$.

\proof.
Primeiramente demonstramos que a $\seqn a n$ é crescente e sup-cotada (\ref[square_root_of_small_reals_proof]).
Logo ela é convergente, e logo seja $\ell = \lim_n a_n$.
Basta calcular que $\ell^2 = 2$:
\compute
\ell^2
&= (\lim_n a_n)^2 \by {escolha de $\ell$} \\
&\eqvdots \by {\ref[square_root_of_small_reals_proof]} \\
&= 2.
\endcompute

%%}}}

%%{{{ x: square_root_of_small_reals_proof 
\exercise.
%%%{{{ meta 
\label square_root_of_small_reals_proof
%%%}}}

Feche a demonstração do \reftag[square_root_of_small_reals]:
(i)~$\seqn a n$ é crescente;
(ii)~$\seqn a n$ é sup-cotada;
(iii)~$\ell^2 = 2$.

\hint
Para a parte (iii), lembre como demonstramos o \ref[powers_of_small_tends_to_zero].

%%}}}

%%{{{ thm: square_root_of_two_is_real 
\theorem.
%%%{{{ meta 
\label square_root_of_two_is_real
%%%}}}

Existe real $h$ tal que $h^2 = 2$.

\proof.
Seja $A = \setst x {x^2 < 2}$.
Como $A$ é habitado (\reftag[square_root_of_two_is_real_proof_inhab])
e sup-cotado (\reftag[square_root_of_two_is_real_proof_bounded_above]),
logo seja $h = \sup A$, pelo \mref[R-Compl-lub].
Para demonstrar que $h^2 = 2$, basta eliminar os outros dois casos:
$h^2 < 2$; $h^2 > 2$.
\crproofcase {Caso $h^2 < 2$.}
Para eliminar este caso, acharemos um membro de $A$, maior que $h$,
assim contradizendo a escolha de $h$ como sup-cota ($h \geq A$).
A esperança é que vamos conseguir aumentar $h$ um tiquinho
tão pequeno que seu quadrado vai continuar sendo menor que $2$.
Vamos apelar tal real de $h_+$.
Teremos então $h_+ > h$ e $h_+^2 < 2$;
e isso implicaria $h_+ \in A$ (pela definição de $A$):
$$
h < h_+ \in A
$$
e logo $h \ngeq A$, e teremos nossa contradição.
Como $h^2 < 2$, logo seja $\theta > 0$ tal que
$$
h^2 + \theta < 2.
$$
Basta achar $\epsilon > 0$ pequeno o suficiente para que
$h+\epsilon$ serve ser nosso desejado $h_+$:
$$
\paren{\,\smash {\mubrace {h + \epsilon} {h_+}}\,}^2 < h^2 + \theta < 2.
$$
Seja $\epsilon = \smash {\dfrac {\theta} {2h + 1}}$.
Calculamos:
\compute
\paren{h + \epsilon}^2
&= h^2 + 2h\epsilon + \epsilon^2 \\
&< h^2 + 2h\epsilon + \epsilon  \by {pelo \ref[real_square_of_small_is_smaller]} \\
&= h^2 + (2h + 1)\epsilon \\
&= h^2 + (2h + 1) \smash {\frac \theta {2h + 1}}  \by {pela escolha de $\epsilon$} \\
&= h^2 + \theta \\
&< 2.  \by {pela escolha de $\theta$} \\
\endcompute
\crproofcase {Caso $h^2 > 2$.}
Para eliminar este caso, vamos achar uma cota superior $h_-$ de $A$,
melhor (menor) que $h$, assim contradizendo a escolha de $h$ como \emph{melhor} sup-cota.
Essa parte é toda tua (\reftag[square_root_of_two_is_real_proof_ngt]).

%%}}}

%%{{{ x: square_root_of_two_is_real_proof_inhab
\exercise.
%%%{{{ meta 
\label square_root_of_two_is_real_proof_inhab
%%%}}}

Mostre que o $A$ da demonstração do \reftag[square_root_of_two_is_real] é habitado\dots

\hint
$1 \in A$.  Por quê?

\solution
(i) $A$ é habitado, pois $1^2 < 2$, ou seja, $1 \in A$.

%%}}}

%%{{{ x: square_root_of_two_is_real_proof_bounded_above 
\exercise.
%%%{{{ meta 
\label square_root_of_two_is_real_proof_bounded_above
%%%}}}

\dots e sup-cotado também\dots

\hint
Uma sup-cota é o $2$.  Por quê?

\hint
Lembre do \ref[real_squaring_preserves_and_reflects_orders].

\solution
Vou mostrar que $2$ é uma sup-cota de $A$.
Seja $a \in A$, ou seja, $a^2 < 2$, e logo $a^2 < 4$,
ou seja, $a^2 < 2^2$.
Logo $a < 2$ pois $(\uhole^2)$ reflete a $(<)$ no $\nonnegs\reals$.

%%}}}

%%{{{ x: square_root_of_two_is_real_proof_ngt 
\exercise.
%%%{{{ meta 
\label square_root_of_two_is_real_proof_ngt
%%%}}}

\dots e mostre que $h^2 \ngt 2$, para eliminar o caso que deixei pra tu,
fechando assim tudo que ficou aberto na demonstração do \ref[square_root_of_two_is_real].

\solution
Aqui a idéia é diminuir o $h$ um tiquinho tão pequeno
que ele continuaria sendo uma sup-cota do $A$.
Ou seja: procuramos um $h_-$ tal que
$$
A \leq h_- < h.
$$
Como $h^2 > 2$, logo seja $\theta > 0$ tal que
$$
h^2 - \theta > 2.
$$
Basta achar $\epsilon > 0$ pequeno o suficiente para que $h - \epsilon$
serve ser nosso desejado $h_-$:
$$
\paren{\,\smash {\mubrace {h - \epsilon} {h_-}}\,}^2 > h^2 - \theta > 2.
$$
Seja $\epsilon = \smash {\dfrac {\theta} {2h}}$.
Calculamos:
\compute
\paren{h - \epsilon}^2
&= h^2 - 2h\epsilon + \epsilon^2 \\
&> h^2 - 2h\epsilon \\
&= h^2 - 2h \smash {\frac \theta {2h}}  \by {pela escolha de $\epsilon$} \\
&= h^2 - \theta \\
&> 2.  \by {pela escolha de $\theta$} \\
\endcompute

%%}}}

%%{{{ cor: rats_is_not_a_complete_ordered_field 
\corollary.
%%%{{{ meta 
\label rats_is_not_a_complete_ordered_field
%%%}}}

Os racionais não satisfazem a especificação dos reais.

\proof.
Imediato pois já demonstramos que não existe racional $q$ com $q^2 = 2$.

%%}}}

\endsection
%%}}}

%%{{{ Densities_reals 
\section Densidades.
%%%{{{ meta 
\label Densities_reals
\defines
    * conjunto!denso nos reais
    ;;
%%%}}}

%%{{{ thm: rats_dense_in_reals 
\theorem.
%%%{{{ meta 
\label rats_dense_in_reals
%%%}}}

Os racionais são densos nos reais, ou seja:
para todo $x,y\in \reals$,
$$
x < y
\implies
\lexists {q \in \rats} {x < q < y}.
$$

%%}}}

%%{{{ thm: irrats_dense_in_reals 
\theorem.
%%%{{{ meta 
\label irrats_dense_in_reals
%%%}}}

Os irracionais são densos nos reais, ou seja:
para todo $x,y\in \reals$,
$$
x < y
\implies
\lexists {i \notin \rats} {x < i < y}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Infinite_cardinalities 
\section Cardinalidades infinitas.
%%%{{{ meta 
\label Infinite_cardinalities
\credits
    * Cantor
    ;;
%%%}}}

%%{{{ thm: rats_countable 
\theorem Cantor.
%%%{{{ meta 
\label rats_countable
\credits
    * Cantor!primeira demonstração de incontabilidade
    ;;
%%%}}}

Existe seqüência $\seqn q n$ tal que $\seqnset q n = [0,1]\inter\ratreals$.

\proof.
Seja
$$
\seqn q n
\pseudodefeq
\frac 0 1, \; \frac 1 1, \;
\frac 0 2, \; \frac 1 2, \; \frac 2 2, \;
\frac 0 3, \; \frac 1 3, \; \frac 2 3, \; \frac 3 3, \;
\frac 0 4, \; \frac 1 4, \; \frac 2 4, \; \frac 3 4, \; \frac 4 4,
\dots
$$
(Formalmente definir essa seqüência é o \ref[rats_countable_formal_def].)

%%}}}

%%{{{ thm: reals_uncountable_first_proof_of_Cantor 
\theorem Cantor.
%%%{{{ meta 
\label reals_uncountable_first_proof_of_Cantor
\credits
    * Cantor!primeira demonstração de incontabilidade
    ;;
%%%}}}

Não existe seqüência $\seqn t n$ tal que $\seqnset t n = [0,1]$.
Equivalentemente:
para qualquer seqüência $\seqn t n$, e quaisquer reais $a < b$,
existe $w \in [a,b]$ tal que $w \notin \seqnset t n$.
Ou seja, nenhuma seqüência consegue \dq{cobrir} um intervalo:
tem habitates que nunca serão contados pela seqüência; conseguem escapar dela.

\sketch.
Sejam $a,b$ reais com $a < b$ e $\seqn t n$ seqüência de reais.
Construimos um real $w \in [a,b]$ tal que
$$
\lforall n {t_n \neq w}.
$$
Caso que a seqüência $\seqn t n$ nunca entra no $[a,b]$,
seja $w \in [a,b]$ e temos nosso testemunha e acabou.
Caso que a seqüência só pega um valor $t \in [a,b]$, seja
$w \in [a,b] \setminus \set t$, e acabou.
Caso contrário, a seqüência pega pelo menos dois distintos valores no $[a,b]$.
Chame $\ell_1$ o menor deles, e $r_1$ o maior.
Como $\ell_1 < r_1$, seja $I_1 = [\ell_1, r_1]$.
Repetimos a mesma idéia no $I_1$ para obter ou um testemunha $w$
(nos dois primeiros casos), assim acabando com a demonstração;
ou dois distintos reais $\ell_2 < r_2$ no $[\ell_1, r_1]$ definindo assim o $I_2 = [\ell_2, r_2]$.
Continuando assim acabamos definindo ou $N$ intervalos chegando num último intervalo $I_N$
pois não tem mais dois distintos membros nele contados pela seqüência para continuar,
ou uma seqüência de intervalos $\seqn I n$;
e note que são aninhados, fechados, e habitados, e logo sua interseção $\Inter_n I_n$
é habitada.
No primero caso acabamos com
$$
a = \ell_0 < \ell_1 < \ell_2 < \dotsb < \ell_N \quad < \quad r_N < \dotsb < r_2 < r_1 < r_0 = b;
$$
no segundo com
$$
a = \ell_0 < \ell_1 < \ell_2 < \dotsb \mathrel{\phantom<} \phantom{\ell_N} \quad \mathrel{\phantom<} \quad \phantom{r_N} \mathrel{\phantom<} \dotsb < r_2 < r_1 < r_0 = b;
$$
Note que a $\seqn I n$ é uma seqüência de intervalos aninhados, fechados, e habitados
e logo $\Inter_n I_n$ é habitada também e qualquer habitante dela serve como testemunha.

%%}}}

%%{{{ remark 
\remark.
%%%{{{ meta 
\defines
    * conjunto!incontável
    ;;
%%%}}}

A importância desse teorema é assustadora---algo comprovado pelos eventos históricos
logo depois de tal descoberta de Cantor.  Dedicamos um capítulo inteiro (\ref[Cantors_paradise])
no assunto---onde também encontramos uma outra demonstração (também de Cantor) muito mais
elegante---mas por enquanto basta apreciar que temos um primeiro toque de \emph{cardinalidades
infinitas distintas e comparáveis: uma estritamente maior que a outra!}
Num lado, temos a cardinalidade do $\nats$, que é nosso conjunto de índices,
e mesmo podendo ter um real para cada tal índice, o intervalo $[a,b]$ é tão populoso
que não tem como \emph{contar} todos os seus membros usando nossa seqüência.
Tais conjuntos chamamos de \dterm{incontáveis}.

%%}}}

\endsection
%%}}}

%%{{{ Geometric_representation_of_reals 
\section Representação geométrica.
%%%{{{ meta 
\label Geometric_representation_of_reals
%%%}}}

\TODO Expansão como instruções.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: rats_countable_formal_def 
\problem.
%%%{{{ meta 
\label rats_countable_formal_def
%%%}}}

Defina mesmo a seqüência $\seqn q n$ que eu \dq{pseudodefini} no \ref[rats_countable].

%%}}}

%%{{{ thm: ramsey_for_real_monotone_subseq_theorem 
\theorem Ramsey.
%%%{{{ meta 
\label ramsey_for_monotone_subseq_theorem
\credits
    * Ramsey
    ;;
%%%}}}

Seja $\pset_n A \defeq \setst { S \subset A } {\card{A} = n}$.
Sejam $A,B,N$ tais que $\pset_2 N = A \union B$.
Logo existe $M \subset N$ tal que:
(i) $M$ é infinito; e
(ii) $M \subset A$ ou $M \subset B$.

%%}}}

%%{{{ prob: ramsey_implies_real_monotone_subseq_thm 
\problem.
%%%{{{ meta 
\label ramsey_implies_real_monotone_subseq_thm
%%%}}}

Dado o teorema acima, demonstre o \ref[real_monotone_subseq_thm] como corolário.

%%}}}

\endproblems
%%}}}

%%{{{ Liminf_and_limsup_reals 
\section Liminf e limsup.
%%%{{{ meta 
\label Liminf_and_limsup_reals
%%%}}}

%%{{{ df: liminf_and_limsup_in_reals 
\definition.
%%%{{{ meta 
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Definimos
\mathcols 2
\liminf_n a_n &\defeq \sup_n\inf_{i\geq n} a_i &
\limsup_n a_n &\defeq \inf_n\sup_{i\geq n} a_i.
\endmathcols
Usamos também $\ulim_n$ para o $\liminf_n$ e
similarmente $\olim_n$ para o $\limsup_n$.

%%}}}

\TODO elaborar e adicionar desenhos sobre os $\limsup$ e $\liminf$.

%%{{{ remark 
\remark.
%%%{{{ meta 
%%%}}}

Seja $\seqn a n$ seqüência bounded e seja
$$
M \asseq \limsup_n a_n = \lim_n \sup \setst {a_k} {k \geq n}.
$$
Logo
$$
\pforall {\epsilon > 0}
\pexists {N \in \nats}
\lforall {n \geq N}
  {M - \epsilon < \sup\setst{a_k}{k \geq n} < M + \epsilon}.
$$

%%}}}

%%{{{ criterion: limsup_liminf_criteria 
\criterion.
%%%{{{ meta 
\label limsup_liminf_criteria
%%%}}}

Seja $\seqn a n$ bounded.
Logo
$$
\align
M = \limsup_n a_n
&\iff
\pforall {\epsilon > 0}
\bracket{
\aligned
&\text{$a_n < M + \epsilon$ eventualmente para todos os $n$'s} \\
&\text{$a_n > M - \epsilon$ para uma quantidade infinita de $n$'s}
\endaligned
}; \\
m = \liminf_n a_n
&\iff
\pforall {\epsilon > 0}
\bracket{
\aligned
&\text{$a_n > m - \epsilon$ eventualmente para todos os $n$'s} \\
&\text{$a_n < m + \epsilon$ para uma quantidade infinita de $n$'s}
\endaligned
}.
\endalign
$$

%%}}}

\TODO demonstrar.

\TODO elaborar e conectar com os equivalentes operadores em conjuntos.

\endsection
%%}}}

%%{{{ Series 
\section Séries.
%%%{{{ meta 
%%%}}}

%%{{{ df: series_of_reals 
\definition.
%%%{{{ meta 
\label series_of_reals
%%%}}}

Seja $\seqn a n$ uma seqüência de reais.
Considere os números
\mathcol
s_0 &= 0 \\
s_1 &= a_0 \\
s_2 &= a_0 + a_1 \\
s_3 &= a_0 + a_1 + a_2 \\
    &\eqvdots \\
s_n &= \Sum_{i=0}^{n-1} a_i \\
    &\eqvdots
\endmathcol
dos \dterm{somatórios parciais} (ou \dterm{iniciais})
da $\seqn a n$.
Escrevemos
$$
\Sum_{n=0}^{\infty} a_n
\qqtext{como sinônimo de}
\mubrace
  {\liml_n \paren{\Sum_{i=0}^{n-1} a_i}}
  {\liml_n s_n}
$$
e naturalmente usamos frases como
\wq{a \dterm{série $\Sum_n a_n$ converge}}, etc.
Dizemos que a série $\Sum_n a_n$ \dterm{diverge} sse $\seqn s n$ diverge.

%%}}}

%%{{{ x: binary_expansion_series 
\exercise expansão binária.
%%%{{{ meta 
\label binary_expansion_series
\defines
    * expansão!binária de $1$
    ;;
%%%}}}

$\Sum_{n=1}^{\infty} \frac 1 {2^n} = 1$.

%%}}}

%%{{{ x: harmonic_series_diverges 
\exercise série harmônica.
%%%{{{ meta 
\label harmonic_series_diverges
\defines
    * série!harmônica
    ;;
\credits
    * Mengoli : divergência da série harmônica
    * Bernoulli : divergência da série harmônica
    * Euler : divergência da série harmônica
    ;;
%%%}}}

Oresme, Mengoli (uns 300 anos depois),
e Bernoulli (uns 40 anos depois de Mengoli, no ano \yearof{1682}),
independentemente demonstraram que
a \dterm{série harmônica} ($\Sum_{n=1}^{\infty} \frac 1 n$) diverge.
Entre no clube deles fazendo a mesma coisa (uns poucos séculos depois):
$$
\Sum_{n=1}^{\infty} \frac 1 n = \pinfty.
$$

%%}}}

\TODO add hints.

%%{{{ x: series_one_over_n_squared_converges 
\exercise.
%%%{{{ meta 
\label series_one_over_n_squared_converges
\credits
    * Bernoulli : convergêcia de série
    * Euler : resolução de Basel
    ;;
\indexes
    * Basel!problema de
    ;;
%%%}}}

Bernoulli demonstrou que $\Sum_{n=0}^{\infty} \frac 1 {n^2}$ converge.
Faça a mesma coisa.

%%}}}

\TODO add hints.

%%{{{ Basel_problem 
\note Problema de Basel.
%%%{{{ meta 
\label Basel_problem
\credits
    * Mengoli : problema de Basel
    * Euler : resolução de Basel
    ;;
\indexes
    * coprimos
    * probabilidade
    * forma fechada
    * Basel
    * problema!de Basel
    ;;
%%%}}}

Achar uma \dq{forma fechada} para o limite desta série era
o famoso \dterm{problema de Basel}, enunciado pelo Mengoli no ano \yearof{1650}.
Bernoulli não conseguiu resolver este problema, que acabou ganhando seu apelido
pela cidade \emph{Basel}, na Suiça, em qual Bernoulli nasceu.
E quem mais nasceu na mesma cidade?
Euler, que conseguiu resolver o problema no ano \yearof{1734}, demonstrando que
$$
\Sum_{n=0}^{\infty} \frac 1 {n^2} = \frac {\pi^2} 6.
$$
Inesperadamente, essa resolução é relacionada à probabilidade que dois aleatórios números
grandes são coprimos: escolhendo aleatoriamente inteiros no $\set {1, \dotsc, n}$
a seqüência das correspondentes probabilidades tende ao reciproco do limite acima:
$6/\pi^2$.
Tudo isso é fora do nosso foco aqui, mas confio que tu achou, no mínimo, interessante.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: euler_constant 
\problem constante (e).
%%%{{{ meta 
\label dualize_and_prove_Inter_of_supsets_supset
\defines
    * e -- constante de Euler
    * constante!$e$, de Euler
    ;;
\credits
    * Bernoulli : constante $e$ \dq{de Euler}
    * Euler : constante $e$
    ;;
%%%}}}

Podemos definir o número $e$, conhecido como \dterm{constante de Euler}
(mas introduzido por Bernoulli) por qualquer uma das
\mathcols 2
e &\defeq \Sum_{n=0}^\infty \frac 1 {k!} &
e &\defeq \lim_n \paren{1 + \frac 1 n}^n.
\endmathcols
(i)~Demonstre que a série acima converge;
(ii)~demonstre que a seqüência acima converge;
(iii)~mostre que $\Sum_{n=0}^\infty \frac 1 {k!} = \lim_n \paren{1 + \frac 1 n}^n$;
(iv)~$\lforall {n \geq 1} {0 < e - s_n < \frac 1 {n! n}}$, onde $\seqn s n$ é a seqüência dos somatórios parciais da série;
(v)~conclua que $e$ é um número irracional.

%%}}}

\endproblems
%%}}}

%%{{{ Real_functions 
\section Funções reais.
%%%{{{ meta 
\label Real_functions
%%%}}}

\TODO Elaborar.

%%{{{ df: continuous_real_function 
\definition função real contínua.
%%%{{{ meta 
\label continuous_real_function
%%%}}}

Sejam $X,Y\subset \reals$, $f : X \to Y$, e $x_0 \in X$.
Chamamos
$$
\multline
\text{$f$ contínua no $x_0$}
\defiff
\pforall {\epsilon > 0}
\pexists {\delta > 0} \\
\lforall {x \in X}
{
\text{$x,x_0$ são $\delta$-perto}
\implies
\text{$f x, f x_0$ são $\epsilon$-perto}
}.
\endmultline
$$
Dizemos que $f$ é \dterm{contínua} sse ela é contínua em
cada ponto do seu domínio.

%%}}}

%%{{{ Continuity as a game 
\note Continuidade como jogo.
%%%{{{ meta 
\label continuity_game
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ lemma: continuous_functions_preserve_sign 
\lemma preservação de sinal.
%%%{{{ meta 
\label continuous_functions_preserve_sign
%%%}}}

Seja $f : A \to \reals$ contínua no $a$ com $fa \neq 0$.
Logo existe $\ball \delta a$ tal que $f$ não muda sinal nela.

\sketch.
\proofpart {Caso $fa > 0$.}
Usamos a continuidade da $f$ no $a$ com $\epsilon \asseq fa$,
assim ganhando um $\delta > 0$ tal que
todos os $\delta$-perto de $a$ são mapeados $\epsilon$-perto
de $fa$.  Logo todos são positivos.
\crproofpart {Caso $fa < 0$:} similar.

%%}}}

%%{{{ thm: Bolzano_theorem 
\theorem Bolzano.
%%%{{{ meta 
\label Bolzano_theorem
\credits
    * Bolzano : teorema de função real contínua
    ;;
%%%}}}

Seja $f : A \to \reals$ contínua em todo ponto dum intervalo
$[a,b]$ tal que $(fa),(fb)$ têm sinais opostos.
Logo existe $w \in (a,b)$ tal que $fw = 0$.

\sketch.
\proofpart {Caso $fa < 0 < fb$.}
Observe que podem exisir vários $w \in (a,b)$ com $fw = 0$;
a gente precisa achar um tal $w$.
Seja
$$
L = \setst {x \in [a,b]} {f x \leq 0}.
$$
Observe $L \neq \emptyset$ (pois $a \in L$) e ele é
bounded above (por $b$), e logo possui supremum:
seja $w \asseq \sup L$.
Basta demonstrar que (i) $fw = 0$; (ii) $a < w < b$.
(i) Pela tricotomía da ordem basta eliminar as possibilidades
$fw > 0$ e $fw < 0$.
Fazemos isso usando a continuidade da $f$ e
o~\ref[continuous_functions_preserve_sign].
supondo a primeira chegamos na contradição de achar um
upper bound de $L$ menor que $w$;
supondo a segunda chegamos na contradição que o $w$
não é um upper bound.
(ii) Temos $w \in [a,b]$, basta eliminar as possibilidades
de $w = a$ e $w = b$: imediato pois $fw = 0$ e $fa,fb\neq 0$.
\crproofpart {Caso $fb < 0 < fa$:} similar.

%%}}}

%%{{{ df: preserves_limits_in_reals 
\definition preserva limites.
%%%{{{ meta 
\label preserves_limits_in_reals
%%%}}}

Seja $f : A \to \reals$.
Dizemos que \dterm{$f$ preserva os límites} sse
para toda seqüência convergente $\seqn a n$
$$
f\funparen{ \liml_n a_n } = \liml_n (f a_n).
$$

%%}}}

%%{{{ criterion: continuous_iff_preserves_limits_in_reals 
\criterion.
%%%{{{ meta 
\label continuous_iff_preserves_limits_in_reals
%%%}}}

Seja $f : A \to \reals$.
$$
\text{$f$ contínua}
\iff
\text{$f$ preserva os limítes}.
$$

%%}}}

\TODO Demonstrar.

\endsection
%%}}}

%%{{{ Pointwise convergence 
\section Convergência pointwise (ponto a ponto).
%%%{{{ meta 
%%%}}}

%%{{{ df: pointwise_conv_reals 
\definition pointwise.
%%%{{{ meta 
\label pointwise_conv_reals
\defines
    * convergência!pointwise
    ;;
\indexes
    * pointwise     seealso: convergência
    ;;
%%%}}}

Seja $\seqn f n \is \SeqP {\alpha \to \Real}$ uma seqüência \emph{de funções} reais.
Observe que para cada $x \is A$, é determinada uma seqüência \emph{de reais}
pelos valores das $f_n$'s nesse ponto: $\seq {f_n \fa x} n$.
Se cada uma delas e convergente, definimos o \dterm{limite pointwise} da $\seqn f n$ para
ser a função $f : \alpha \to \reals$ definida pela
$$
f \fa x = \liml_n {(f_n x)}.
$$
Dizemos que $\seqn f n$ \dterm{converge pointwise}
(ou \dterm{ponto a ponto}) à $f$:
\mathcol
\seqn f n \tends f
&\defiff \lforall x {\seq {f_n \fa x} n \tends f \fa x} \\
&\intiff
\pforall x
\pforall {\epsilon > 0}
\pexists N
\lforall {n \geq N}
         {\dist d {f_n \fa x} {f \fa x} < \epsilon} \\
&\iff
\pforall {\epsilon > 0}
\pforall x
\pexists N
\lforall {n \geq N}
         {\dist d {f_n \fa x} {f \fa x} < \epsilon}.
\endmathcol

%%}}}

%%{{{ x: pointwise_limit_eg_monomials 
\exercise.
%%%{{{ meta 
\label pointwise_limits_eg_monomials
%%%}}}

Seja $\seqn f n \is \SeqP {[0,1] \to \Real}$ a seqüência
definida pelas
\mathcol
f_n       &\eqtype [0,1] \to \Real \\
f_n \fa x &= x^n.
\endmathcol
A $\seqn f n$ converge àlguma função pointwise?

%%}}}

%%{{{ df: uniform_conv_reals 
\definition uniformemente.
%%%{{{ meta 
\label uniform_conv_reals
\defines
    * convergência!uniforme
    * tende!uniformemente
    ;;
\indexes
    * uniformemente     seealso: convergência
    ;;
%%%}}}

Sejam $\seqn f n \is \SeqP {\alpha \to \Real}$ e $f \is \alpha \to \Real$.
Definimos
\mathcol
\seqn f n \unito f
&\defiff
\pforall {\epsilon > 0}
\pexists N
\pforall x
\lforall {n \geq N}
         {\dist d {f_n \fa x} {f \fa x} < \epsilon}.
\endmathcol
Dizemos que $\seqn f n$ \dterm{converge uniformemente} à $f$.

%%}}}

%%{{{ x: pointwise_vs_uniform_conv_reals 
\exercise.
%%%{{{ meta 
\label pointwise_vs_uniform_conv_reals
%%%}}}

Compare as duas noções de convergência: pointwise (\reftag[pointwise_conv_reals]) e uniforme (\reftag[uniform_conv_reals]).

%%}}}

%%{{{ x: pointwise_uniform_autoconv_reals 
\exercise.
%%%{{{ meta 
\label pointwise_uniform_autoconv_reals
%%%}}}

Defina as noções de \dterm{pointwise autoconvergente}
e \dterm{uniformemente autoconvergente}.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

\TODO Add problems.

\endproblems
%%}}}

%%{{{ The_complex 
\section Os complexos.
%%%{{{ meta 
\label The_complex
%%%}}}

\TODO elaborar.

\endsection
%%}}}

%%{{{ The_surreals 
\section Os surreais.
%%%{{{ meta 
\label The_surreals
%%%}}}

\TODO elaborar.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: transcendentality_of_one_of_epluspi_etimespi 
\problem.
%%%{{{ meta 
\label transcendentality_of_one_of_epluspi_etimespi
%%%}}}

Dado que ambos os $e,\pi$ são transcendentais,
mostre que pelo menos um dos $e+\pi$, $e\pi$ é transcendental.

\hint
Reductio ad absurdum.

\hint
Para chegar num absurdo, suponha que ambos os
$$
\xalignat2
S &= e + \pi &
P &= e\pi
\endxalignat
$$
são algébricos.
Se conseguir achar um polinómio com coeficientes algébricos
tal que $e,\pi$ são raizes dele então acabou!

\solution
Demonstramos usando reductio ad absurdum.
Suponha então que ambos são algébricos e
vamos chamá-los assim:
$$
\xalignat2
S &= e + \pi &
P &= e\pi.
\endxalignat
$$
Agora considere o polinômio
$$
f(x) = x^2 - Sx + P
$$
e observe que $e,\pi$ são raizes dele:
$$
\align
f(e)   &= e^2   - (e + \pi)e + e\pi   = 0 \\
f(\pi) &= \pi^2 - (e + \pi)\pi + e\pi = 0.
\endalign
$$
Chegamos assim na contradição que $e,\pi$
são algébricos, pois os coeficientes do $f$ são.

%%}}}

%%{{{ prob: alternative_specification_of_ordered_fields_prob 
\problem.
%%%{{{ meta 
\label alternative_specification_of_ordered_fields_prob
%%%}}}

Na~\ref[alternative_specification_of_ordered_fields] afirmei que
as duas formalizações são equivalentes.
O que isso significa mesmo?
Enuncie e demonstre.

%%}}}

%%{{{ prob: complex_cannot_be_ordered 
\problem.
%%%{{{ meta 
\label complex_cannot_be_ordered
%%%}}}

Demonstre que não tem como definir uma ordem no corpo dos
complexos em tal forma que ele vira um corpo ordenado.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[abbottunderstanding],
\cite[spivakcalculus],
\cite[apostol1],
\cite[taoanalysis1],
\cite[hardypuremath],
\cite[loomissternberg].
\cite[knuthsurreals].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Types 
\chapter Tipos.
%%%{{{ meta 
\label Types
%%%}}}

%%{{{ Product_types 
\section Tipos produto.
%%%{{{ meta 
\label Product_types
%%%}}}

%%{{{ spec: binary_product_type 
\specification Produto binário.
%%%{{{ meta 
\label binary_product_type
\defines
    * produto!binário de tipos
    ;;
%%%}}}

A partir de quaisquer tipos $\alpha$ e $\beta$ podemos formar
o tipo do seu produto que denotamos por $\alpha\times\beta$:
$$
\PROOFmn {
   \A {\alpha \is \Type}    \A {\beta \is \Type}
\I2---------------------------------------------
         {\alpha\times\beta \is \Type}
}
\mtag[product-form=($\times$)-Form]
$$
Há duas maneiras de utilizar um habitante $w \is \alpha\times\beta$,
ou seja, duas perguntas que podemos fazer: «qual teu componente esquerdo?»
e «qual teu componente direito?».  Assim:
\mathcols 2
&\PROOFmn {
   \A {w \is \alpha\times\beta}
\I1-----------------------------
    {\project w.l \is \alpha}
} &
&\PROOFmn {
   \A {w \is \alpha\times\beta}
\I1-----------------------------
    {\project w.r \is \beta}
}
\mtag[product-elim=($\times$)-Elim]
\endmathcols
Para construir um habitante do tipo $\alpha\times\beta$
precisamos fornecer tais duas informações, sendo uma de tipo
$\alpha$ e outra de tipo $\beta$:
$$
\PROOFmn {
   \A {a \is \alpha}    \A {b \is \beta}
\I2-------------------------------------
    {\tup{a,b} \is \alpha\times\beta}
}
\mtag[product-intro=($\times$)-Intro]
$$
Aqui termina a descrição da parte \dterm{estática}.
A parte \dterm{dinâmica} (computacional) é determinada
pelas equações abaixo que governam os habitantes deste tipo.
Separamos tais equações nas
\mathcols 2
\project \tup{a,b}.l &= a &
\project \tup{a,b}.r &= b
\mtag[product-beta=($\times$)-β]
\endmathcols
que estabelecem o que acontece se tentar introduzir (construir)
e logo depois eliminar (usar);
e na
$$
\tup {\project w.l, \project w.r} = w.
\mtag[product-eta=($\times$)-η]
$$
que estabelecem o que acontece se construir algo a partir do
que obtemos apenas usando uma tal tupla.

%%}}}

%%{{{ remark: meaning_of_beta_and_eta_equations 
\remark.
%%%{{{ meta 
\label meaning_of_beta_and_eta_equations
%%%}}}

As equações (β) estão dando uma alma computacional aos habitantes
de $\alpha\times\beta$, especialmente quando são lidas de forma direcionada
onde as expressões mais complexas (à esquerda) são substituidas pelas
expressões mais simples (à direita) durante um cálculo.
As equações (η) também, e correspondem em garantias de unicidade e de
\emph{ausência de lixo}.
Como exemplo, considere a \mref[product-eta]:
se o $w$ carregasse mais informação (lixo) além das duas que podemos obter
a partir da interface que temos (eliminadores), formando o
$\tup {\project w.l, \project w.r}$ não seria garantido de criar o próprio $w$.

%%}}}

%%{{{ Q: How would you generalize to n-ary products? 
\question.
%%%{{{ meta 
%%%}}}

Tendo definido produtos $2$-ários, como generalizarias para
definir produtos $n$-ários para qualquer $n \geq 0$?

%%}}}

\spoiler

%%{{{ spec: finite_product_type 
\specification Produto finito.
%%%{{{ meta 
\label finite_product_of_types
\defines
    * produto!finito de tipos
    ;;
%%%}}}

Precisávamos $2$ tipos para formar o tipo de produto binário (deles),
agora para o produto $n$-ário precisamos $n$ tipos:
dados $\alpha_1, \dotsc, \alpha_n$
podemos formar o tipo do seu produto que
denotarei por $\FinProd(\alpha_1,\dotsc,\alpha_n)$:
$$
\PROOFmn {
   \A {\alpha_1 \is \Type}    \A {\cdots}    \A {\alpha_n \is \Type}
\I3-----------------------------------------------------------------
            {\FinProd(\alpha_1,\dotsc,\alpha_n) \is \Type}
}
\mtag[finproduct-form=$\FinProd$-Form]
$$
Tivemos $2$ maneiras de utilizar habitantes do produto $2$-ário,
logo temos $n$ maneiras de utilizar habitantes do produto $n$-ário:
$$
\PROOFmn {
\A   {w \is \FinProd(\alpha_1,\dotsc,\alpha_n)}
\I1----------------------------------------------
           {\project w.1 \is \alpha_1}
}
\qquad\cdots\qquad
\PROOFmn {
\A   {w \is \FinProd(\alpha_1,\dotsc,\alpha_n)}
\I1----------------------------------------------
           {\project w.n \is \alpha_n}
}
\mtag[finproduct-elim=$\FinProd$-Elim]
$$
Precisavamos $2$ informações para construir habitantes do produto $2$-ário
(uma de cada tipo envolvido), logo precisamos $n$ informações para construir
habitantes do produto $n$-ário:
$$
\PROOFmn {
   \A {a_1 \is \alpha_1}    \A {\cdots}    \A {a_n \is \alpha_n}
\I3---------------------------------------------------------------
    {\tup{a_1,\dotsc,a_n} \is \FinProd(\alpha_1,\dotsc,\alpha_n)}
}
\mtag[finproduct-intro=$\FinProd$-Intro]
$$
A parte computacional da $2$-ária tinha $2$ equações-(β), portanto temos $n$
para a $n$-ária: para cada $i = 1,\dotsc,n$, a seguinte:
$$
\project \tup{a_1, \dotsc, a_n}.i = a_i.
\mtag[finproduct-beta=$\FinProd$-β]
$$
E similarmente sobre (η):
$$
\tup {\project w.1, \dotsc, \project w.n} = w.
\mtag[finproduct-eta=$\FinProd$-η]
$$

%%}}}

%%{{{ Q: What do we get for n = 0 ? 
\question.
%%%{{{ meta 
%%%}}}

Tendo definido produtos $n$-ários para qualquer $n \geq 0$,
como parece o caso especial de produtos $0$-ários?

%%}}}

\spoiler

%%{{{ nullary_product_type 
\note Produto nulário.
%%%{{{ meta 
\label nullary_product_of_types
\defines
    * produto!nulário de tipos
    ;;
%%%}}}

A partir do nada podemos formar o tipo do produto nulário que denotamos por $\One$:
$$
\PROOFmn {
\I0--------------------
     {\One \is \Type}
}
\mtag[nullproduct-form=$\One$-Form]
$$
Temos $0$ (nenhuma) pergunta que podemos fazer aos habitantes de $\One$:
$$
\mtag[nullproduct-elim=$\One$-Elim]
$$
Correspondentemente, precisamos $0$ informações para construir um habitante
de produto $0$-ário:
$$
\PROOFmn {
\I0------------------------
      {\tup {} \is \One}
}
\mtag[nullproduct-intro=$\One$-Intro]
$$
(Nenhuma informação foi incluida nessa construção, e logo nenhuma informação pode ser extraida.)
A parte computacional do $2$-ário tinha $2$ equações-(β), portanto temos $0$
para o $0$-ário:
$$
\mtag[nullproduct-beta=$\One$-β]
$$
Mesmo assim temos algo interessantíssimo parte de (η):
$$
\tup {} = w
\mtag[nullproduct-beta=$\One$-η]
$$
que garanta que este tipo tem um único habitante, o $\tup{}$.

%%}}}

\endsection
%%}}}

%%{{{ Sum_types 
\section Tipos soma.
%%%{{{ meta 
\label Sum_types
%%%}}}

%%{{{ spec: binary_sum_type 
\specification Soma binária.
%%%{{{ meta 
\label binary_sum_of_types
\defines
    * soma!binária de tipos
    ;;
%%%}}}

A partir de quaisquer tipos $\alpha$ e $\beta$ podemos formar
o tipo da sua soma que denotamos por $\alpha+\beta$:
$$
\PROOFmn {
   \A {\alpha \is \Type}    \A {\beta \is \Type}
\I2---------------------------------------------
         {\alpha+\beta \is \Type}
}
\mtag[sum-form=($+$)-Form]
$$
Temos duas maneiras de construir um habitante do tipo $\alpha + \beta$:
uma embute nele uma informação do tipo $\alpha$, e a outra uma do tipo $\beta$:
\mathcols 2
&\PROOFmn {
\A         {a \is \alpha}
\I1---------------------------------
     {\sumin l.a \is \alpha+\beta}
} &
&\PROOFmn {
\A          {b \is \beta}
\I1---------------------------------
     {\sumin r.b \is \alpha+\beta}
}
\mtag[product-intro=($\times$)-Intro]
\endmathcols
Tendo mais que um construtor, o uso de tais habitantes é por um
case-analises, e necessita uma função-receita para cada possibilidade:
$$
\PROOFmn {
   \A {w \is \alpha+\beta}
   \A {f \is \alpha\to\gamma}
   \A {g \is \beta\to\gamma}
\I3-----------------------------
    {\caseofed w {
        \ca l.x -> f \fa x \\
        \ca r.y -> g \fa y \\
     } \is \gamma}
}
\mtag[sum-elim=($+$)-Elim]
$$
Aqui termina a parte estática.
A parte computacional consiste das equações:
\mathcols 2
\caseofed {\sumin l.a} {
    \ca l.x -> f \fa x \\
    \ca r.y -> g \fa y \\
} &= f \fa a &
\caseofed {\sumin r.b} {
    \ca l.x -> f \fa x \\
    \ca r.y -> g \fa y \\
} &= g \fa b.
\mtag[sum-beta=($+$)-β]
\endmathcols
$$
\caseofed w {
    \ca l.x -> \sumin l.x \\
    \ca r.y -> \sumin r.y \\
} = w
\mtag[sum-eta=($+$)-η]
$$

%%}}}

%%{{{ spec: finite_sum_type 
\specification Soma finita.
%%%{{{ meta 
\label finite_sum_of_types
\defines
    * soma!finita de tipos
    ;;
%%%}}}

Precisávamos $2$ tipos para formar o tipo de soma binária (deles),
agora para a soma $n$-ária precisamos $n$ tipos:
dados $\alpha_1, \dotsc, \alpha_n$
podemos formar o tipo do sua soma que
denotarei por $\FinSum(\alpha_1,\dotsc,\alpha_n)$:
$$
\PROOFmn {
   \A {\alpha_1 \is \Type} \A {\cdots} \A {\alpha_n \is \Type}
\I3-----------------------------------------------------------
          {\FinSum(\alpha_1,\dotsc,\alpha_n) \is \Type}
}
\mtag[finsum-form=$\FinSum$-Form]
$$
Tivemos $2$ maneiras de construir habitantes da soma $2$-ária,
logo temos $n$ maneiras de construir habitantes da soma $n$-ária:
$$
\PROOFmn {
\A       {a_1 \is \alpha_1}
\I1--------------------------------
    {\sumin 1.w \is \alpha+\beta}
}
\qquad \cdots \qquad
\PROOFmn {
\A        {a_n \is \alpha_n}
\I1---------------------------------
    {\sumin n.w \is \alpha+\beta}
}
\mtag[finsum-intro=$\FinSum$-Intro]
$$
Além do habitante $w$ que queríamos usar precisávamos $2$ funções-auxiliares
com o mesmo codomínio $\gamma$ e nosso uso com o case-of teve $2$ linhas-casos;
agora precisamos $n$ funções-auxiliares e o case-of tem $n$ linhas-casos:
$$
\PROOFmn {
\A   {w \is \FinSum(\alpha_1,\dotsc,\alpha_n)}
\A   {f_1 \is \alpha_1\to\gamma}
\A   {\cdots}
\A   {f_n \is \alpha_n\to\gamma}
\I4-------------------------------------
    {\caseofed w {
        \ca 1.x_1 -> f_1 \fa x_1 \\
        \vdots \\
        \ca n.x_n -> f_n \fa x_n \\
     } \is \gamma}
}
\mtag[finsum-elim=$\FinSum$-Elim]
$$
A parte computacional da $2$-ária tinha $2$ equações-(β), portanto temos $n$
para a $n$-ária: para cada $i = 1,\dotsc,n$, a seguinte:
$$
\caseofed {\sumin i.a_1} {
    \ca 1.x_1 -> f_1 \fa x_1 \\
    \vdots \\
    \ca n.x_n -> f_n \fa x_n \\
} = f_i \fa a_i.
\mtag[finsum-beta=$\FinSum$-β]
$$
E similarmente sobre (η):
$$
\caseofed w {
    \ca 1.x_1 -> \sumin 1.x_1 \\
    \vdots \\
    \ca n.x_n -> \sumin n.x_n \\
} = w.
\mtag[finsum-eta=$\FinSum$-η]
$$

%%}}}

%%{{{ Q: What do we get for n = 0 ? 
\question.
%%%{{{ meta 
%%%}}}

Tendo definido somatórios $n$-ários para qualquer $n \geq 0$,
como parece o caso especial de produtos $0$-ários?
Tendo definido o produtório $0$-ário, como deveria ser o somatório $0$-ário?

%%}}}

\spoiler

%%{{{ nullary_sum_type 
\note Soma nulária.
%%%{{{ meta 
\label nullary_sum_of_types
\defines
    * soma!nulária de tipos
    ;;
%%%}}}

Precisávamos $2$ tipos para formar o tipo de soma binária (deles),
agora para a soma $0$-ária precisamos $0$ tipos, ou seja nada:
a partir do nada podemos formar
o tipo da soma nulária que denotamos por $\Zero$:
$$
\PROOFmn {
\I0-------------------
      {\Zero \is \Type}
}
\mtag[nullsum-form=$\Zero$-Form]
$$
Tivemos $2$ maneiras de construir habitantes da soma $2$-ária,
logo temos $0$ maneiras de construir habitantes da soma $0$-ária:
$$
\mtag[nullsum-intro=$\Zero$-Intro]
$$
Além do habitante $w$ que queríamos usar precisávamos $2$ funções-auxiliares
com o mesmo codomínio $\gamma$ e nosso uso com o case-of teve $2$ linhas-casos;
agora precisamos $0$ funções-auxiliares e o case-of tem $0$ linhas-casos:
$$
\PROOFmn {
   \A      {w \is \Zero}
\I1-----------------------------
    {\caseofed w {} \is \gamma}
}
\mtag[nullsum-elim=$\Zero$-Elim]
$$
A parte computacional da $2$-ária tinha $2$ equações-(β), portanto temos $0$
para a $0$-ária:
$$
\mtag[sum-beta=$\Zero$-β]
$$
Mesmo assim temos algo na parte de (η):
$$
\caseofed w {} = w
\mtag[sum-eta=$\Zero$-η]
$$

%%}}}

\endsection
%%}}}

%%{{{ Unit_type 
\section O tipo Unit.
%%%{{{ meta 
\label Unit_type
%%%}}}

%%{{{ unit_type
\specification Unit.
%%%{{{ meta 
\label unit_type
\defines
    * {\Unit}  -- o tipo $\Unit$
    ;;
%%%}}}

A partir do nada podemos formar o tipo $\Unit$:
$$
\PROOFmn {
\I0-------------------
      {\Unit \is \Type}
}
\mtag[unit-form=$\Unit$-Form]
$$
Temos só uma maneira de construir habitantes do tipo $\Unit$:
$$
\PROOFmn {
\I0---------------------
     {\star \is \Unit}
}
\mtag[unit-intro=$\Unit$-Intro]
$$
Nenhuma informação entrou no processo de construção, e logo não
temos nenhuma maneira de extrair informação:
$$
\mtag[unit-elim=$\Unit$-Elim]
$$
Sem maneiras de utilizar não temos também equações (β):
$$
\mtag[sum-beta=$\Unit$-β]
$$
Finalmente a (η) expressa que $\star$ é o único habitante do $\Unit$:
$$
\star = w.
\mtag[sum-eta=$\Unit$-η]
$$

%%}}}

\endsection
%%}}}

%%{{{ Empty_type 
\section O tipo Empty.
%%%{{{ meta 
\label Empty_type
%%%}}}

%%{{{ empty_type
\specification Empty.
%%%{{{ meta 
\label empty_type
\defines
    * {\Empty}  -- o tipo $\Empty$
    ;;
%%%}}}

$\Empty$ é um tipo:
$$
\PROOFmn {
\I0--------------------
    {\Empty \is \Type}
}
\mtag[empty-form=$\Empty$-Form]
$$
Não há maneiras de construir habitantes do tipo $\Empty$:
$$
\mtag[empty-intro=$\Empty$-Intro]
$$
Assim, tendo um habitante de $\Empty$ podemos solicitar
habitantes de qualquer tipo $\gamma$:
$$
\PROOFmn {
\A           {w \is \Empty}
\I1-----------------------------------
    {\boom_{\gamma} \fa w \is \gamma}
}
\mtag[empty-elim=$\Empty$-Elim]
$$
Sem maneiras de utilizar não temos também equações (β):
$$
\mtag[sum-beta=$\Empty$-β]
$$
Finalmente a (η) do $\Empty$:
$$
\boom_{\Empty} \fa w = w.
\mtag[sum-eta=$\Empty$-η]
$$

%%}}}

\endsection
%%}}}

%%{{{ Function_types 
\section Tipos função.
%%%{{{ meta 
\label Function_types
%%%}}}

%%{{{ spec: function_type
\specification Função.
%%%{{{ meta 
\label function_type
\defines
    * função!tipo de
    ;;
%%%}}}

A partir de quaisquer tipos $\alpha$ e $\beta$ podemos formar
o tipo de funções de $\alpha$ para $\beta$ que denotamos por $\alpha\to\beta$:
$$
\PROOFmn {
   \A {\alpha \is \Type}    \A {\beta \is \Type}
\I2---------------------------------------------
         {\alpha\to\beta \is \Type}
}
\mtag[fun-form=($\to$)-Form]
$$
Este tipo é caraterizado pela sua eliminação.
Temos uma única maneira de usar uma função $f : \alpha \to \beta$
para extrair uma informação dela: aplicá-la em algo de tipo $\alpha$;
e o que obtemos é algo de tipo $\beta$:
$$
\PROOFmn {
\A   {f \is \alpha\to\beta}
\A   {a \is \alpha}
\I2-----------------------
     {f \fa a \is \beta}
}
\mtag[fun-elim=($\to$)-Elim]
$$
Chegamos no ponto onde precisamos explicitar a informação dos contextos:
$$
\PROOFmn {
\A          {\Gamma, x \is \alpha \infers b \is \beta}
\I1------------------------------------------------------------
     {\Gamma \infers \lam x b \is \alpha\to\beta}
}
\mtag[fun-intro=($\to$)-Intro]
$$
Aqui termina a parte estática.
A parte computacional consiste do passo computacional chamado (β)-redução:
$$
\plam x b \fa a \bstep \subst b[x := a]
\mtag[fun-beta=($\to$)-β]
$$
e da (η)-conversão:
$$
\lam x {f \fa x} \estep f
\mtag[fun-eta=($\to$)-η]
$$

%%}}}

\endsection
%%}}}

%%{{{ Type_implementations 
\section Implementações de tipos.
%%%{{{ meta 
\label Type_implementations
%%%}}}

%%{{{ note: what is this business with implementations 
\note.
%%%{{{ meta 
%%%}}}

Por enquanto aceitamos apenas que nosso sistema de tipos possui (nos permite formar)
somas finitas e produtos finitos---note que isso inclui os $\Zero$ e $\One$ como
casos especiais---e também tipos de funções.
Nesta secção vamos ver como podemos \dterm{implementar} uns tipos desejados,
como os booleanos e os $\MaybeA \alpha$ que conhecemos no \ref[Recursion_induction].
Começamos com a especificação do tipo dos booleanos:

%%}}}

%%{{{ bool_type 
\specification Bool.
%%%{{{ meta 
\label bool_type
\defines
    * {\Bool}  -- o tipo $\Bool$
    ;;
%%%}}}

$\Bool$ é um tipo:
$$
\PROOFmn {
\I0--------------------
    {\Bool \is \Type}
}
\mtag[bool-form=$\Bool$-Form]
$$
Há duas maneiras de construir habitantes de $\Bool$, ambas sem precisar mais informação:
\mathcols 2
&\PROOFmn {
\I0------------------
    {\FF \is \Bool}
} &
&\PROOFmn {
\I0------------------
    {\TT \is \Bool}
}
\mtag[bool-intro=$\Bool$-Intro]
\endmathcols
Utilizamos booleans com o \emph{if-then-else}, para qual precisamos
fornecer dois valores do mesmo tipo:
$$
\PROOFmn {
    \A {b \is \Bool}  \A {u \is \gamma}  \A {v \is \gamma}
\I3--------------------------------------------------------
            {\ifthenelseed b u v \is \gamma}
}
\mtag[bool-elim=$\Bool$-Elim]
$$
Computamos com os booleanos assim:
\mathcols 2
\ifthenelseed \FF u v &= v &
\ifthenelseed \TT u v &= u.
\mtag[bool-beta=$\Bool$-β]
\endmathcols
E a (η) do $\Bool$:
$$
\ifthenelseed b \TT \FF = b.
\mtag[bool-eta=$\Bool$-η]
$$

%%}}}

%%{{{ imp: bools_as_sum 
\implementation Bool.
%%%{{{ meta 
\label bools_as_sum
%%%}}}

Definimos:
\mathcol
\Bool &\defeq \One + \One
\intertext {que significa que nossos booleanos serão representados por
habitantes do tipo $\One + \One$, mas isso não é suficiente: precisamos
definir os $\FF, \TT$, que definimos assim:}
\FF  &\defeq \sumin l.\star \\
\TT  &\defeq \sumin r.\star \\
\intertext {
mas ainda não terminamos.  Falta implementar o if-then-else:}
\ifthenelseed b u v
&\defeq \caseofed b {
            \ca l.x -> v \\
            \ca r.x -> u \\
        }
\endmathcol
Ainda precisamos mostrar que todas essas construções são de fato factíveis
com as mesmas premissas (nenhuma no caso da formação e da introdução,
e três no caso da eliminação).
Farás isso no \ref[bools_as_sum_verify_constructions].
E ainda mais, falta verificar que as equações (β) e (η) são satisfeitas
(\ref[bools_as_sum_verify_eqs]).

%%}}}

%%{{{ x: bools_as_sum_verify_constructions 
\exercise.
%%%{{{ meta 
\label bools_as_sum_verify_constructions
%%%}}}

Verifique que as construções envolvidas na \ref[bools_as_sum] são de fato factíveis
a partir das premissas de cada uma.

%%}}}

%%{{{ x: bools_as_sum_verify_eqs 
\exercise.
%%%{{{ meta 
\label bools_as_sum_verify_eqs
%%%}}}

Verifique que a \ref[bools_as_sum] satisfaz as equações (β) e (η).

%%}}}

\endsection
%%}}}

%%{{{ Types_have_logic 
\section Tipos têm lógica.
%%%{{{ meta 
\label Types_have_logic
%%%}}}

\endsection
%%}}}

%%{{{ Type_arithmetic 
\section Aritmética de tipos.
%%%{{{ meta 
\label Type_arithmetic
%%%}}}

%%{{{ df: isomorphic_types 
\definition Tipos isomórficos.
%%%{{{ meta 
\label isomorphic_types
%%%}}}

Sejam $\alpha, \beta$ tipos.  Dizemos que $\alpha,\beta$ são \dterm{isômorfos}
ou \dterm{isomórficos} sse existem funções
$$
\cd
\alpha \ar[r, bend left=12, "f"] \|
\beta  \ar[l, bend left=12, "g"]
\endcd
$$
tais que
\mathcols 2
g \of f &= \idof \alpha &
f \of g &= \idof \beta.
\endmathcols
Escrevemos $\alpha \iso \beta$.

%%}}}

%%{{{ x: type_arith_plus_com 
\exercise.
%%%{{{ meta 
\label type_arith_plus_com
%%%}}}

$(+)$-comutatividade

%%}}}

%%{{{ x: type_arith_plus_identity 
\exercise.
%%%{{{ meta 
\label type_arith_plus_identity
%%%}}}

$(+)$-identidade.

%%}}}

%%{{{ x: type_arith_plus_assoc 
\exercise.
%%%{{{ meta 
\label type_arith_plus_assoc
%%%}}}

$(+)$-associatividade

%%}}}

%%{{{ x: type_arith_times_identity 
\exercise.
%%%{{{ meta 
\label type_arith_times_identity
%%%}}}

$(\times)$-identidade.

%%}}}

%%{{{ x: type_arith_times_assoc 
\exercise.
%%%{{{ meta 
\label type_arith_times_assoc
%%%}}}

$(\times)$-associatividade

%%}}}

%%{{{ x: type_arith_times_com 
\exercise.
%%%{{{ meta 
\label type_arith_times_com
%%%}}}

$(\times)$-comutatividade

%%}}}

%%{{{ x: type_arith_distr 
\exercise.
%%%{{{ meta 
\label type_arith_distr
%%%}}}

distributividade: $\delta(\alpha+\beta) \iso \delta\alpha + \delta\beta$

%%}}}

%%{{{ x: type_arith_anih 
\exercise.
%%%{{{ meta 
\label type_arith_anih
%%%}}}

anulador: $\alpha \cdot \Zero \iso \Zero$

%%}}}

%%{{{ x: type_arith_square 
\exercise.
%%%{{{ meta 
\label type_arith_square
%%%}}}

$\alpha^2 \iso \alpha\cdot\alpha$

%%}}}

%%{{{ x: type_arith_zero_exp_zero 
\exercise.
%%%{{{ meta 
\label type_arith_zero_exp_zero
%%%}}}

$0^0 \iso {?}$

%%}}}

%%{{{ x: type_arith_zero_exp 
\exercise.
%%%{{{ meta 
\label type_arith_zero_exp
%%%}}}

$0^\alpha \iso {?}$

%%}}}

%%{{{ x: type_arith_one_exp 
\exercise.
%%%{{{ meta 
\label type_arith_one_exp
%%%}}}

$1^\alpha \iso 1$

%%}}}

%%{{{ x: type_arith_exp_one 
\exercise.
%%%{{{ meta 
\label type_arith_exp_one
%%%}}}

$\alpha^1 \iso \alpha$

%%}}}

%%{{{ x: type_arith_exp_zero 
\exercise.
%%%{{{ meta 
\label type_arith_exp_zero
%%%}}}

$\alpha^0 \iso 1$

%%}}}

%%{{{ x: type_arith_curry 
\exercise.
%%%{{{ meta 
\label type_arith_curry
%%%}}}

$(\gamma^\beta)^\alpha \iso \gamma^{\beta\cdot\alpha}$

%%}}}

%%{{{ x: type_arith_exp_plus 
\exercise.
%%%{{{ meta 
\label type_arith_exp_plus
%%%}}}

$\delta^{\alpha+\beta} \iso \delta^\alpha \cdot \delta^\beta$

%%}}}

%%{{{ x: type_arith_binomial 
\exercise.
%%%{{{ meta 
\label type_arith_binomial
%%%}}}

$(\alpha+\beta)^2 \iso {?}$

%%}}}

\endsection
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Collections 
\chapter Coleções.
%%%{{{ meta 
\label Collections
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo estudamos uns tipos de dados fundamentais para matemática.
Começamos com o \emph{conjunto}, e logo depois encontramos seus tipos-amigos:
\emph{tuplas}, \emph{seqüências}, e \emph{famílias indexadas}.
Note que já temos encontrado esses tipos de dados, e até trabalhado com eles
nos capítulos anteriores mas agora é a sua vez de virar o foco do nosso estudo.
Como nós vamos apreciar no~\ref[Set_theory],
a linguagem e teoria dos conjuntos oferecem (podem servir como)
\emph{fundamentos de matemática},
mas por enquanto nos importa apenas nos acostumar com esses tipos,
seus habitantes, suas operações e relações; aprender usá-los e nada mais!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

%%{{{ Q: what_is_a_set 
\question.
%%%{{{ meta 
\label what_is_a_set
%%%}}}

O que significa ser conjunto?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Cantor deu a seguinte resposta:

%%}}}

%%{{{ pseudodf: set 
\pseudodefinition.
%%%{{{ meta 
\label set_pseudodefinition
\defines
    * conjunto!definição intuitiva
    ;;
\credits
    * Cantor : descrição de conjunto
    ;;
%%%}}}

Um \dterm{conjunto} $A$ é a colecção numa totalidade
de certos objetos (definidos e separados) da nossa intuição ou mente,
que chamamos de \dterm{elementos} de $A$.

%%}}}

%%{{{ x: set_pseudodefined 
\exercise.
%%%{{{ meta 
%%%}}}

Qual é o problema principal com a definição acima?

\solution
O que é significa \wq{colecção (numa totalidade)}?
Cuidado: para responder nessa pergunta
tu não podes usar a palavra \wq{conjunto}, pois assim teria uma
definição circular.
Em outras palavras, definimos a palavra \wq{conjunto} em termos da palavra
\wq{colecção}, que no final das contas, é algo sinónimo na nossa
metalinguagem.  Não dá.

%%}}}

%%{{{ not_what_it_is_but_what_can_we_do_with_it 
\note Mudar a pergunta.
%%%{{{ meta 
\label not_what_it_is_but_what_can_we_do_with_it
%%%}}}

A \reftag[what_is_a_set] é a pergunta errada para perguntar aqui---é uma pergunta
para quem quer \emph{implementar} conjuntos responder.
As perguntas certas são:
(i) o que podemos fazer com um conjunto;
(ii) o que precisamos fazer para construir um conjunto; e
(iii) o que significa igualdade entre conjuntos.
Ou seja, precisamos abordar, como sempre, atravez de uma \emph{especificação}.

%%}}}

%%{{{ collection_vs_set 
\note Colleção vs conjunto.
%%%{{{ meta 
\label collection_vs_set
%%%}}}

O uso da palavra \dterm{conjunto} pode variar de contexto para contexto mas
destacamos antes de tudo uma propriedade linguística que aplicará sempre
estamos falando de um conjunto $S$: está propriamente referido usando
o modo \emph{singular}.  A idéia é que ele existe como um (um!)~objeto
de estudo na nossa mesa, visível no nosso mundo matemático.
Tal $S$ da nossa mesa, costuma representar ou corresponder a uma coleção
de outros objetos (também visíveis e existentes no nosso mundo).
Usaremos aqui a palavra \dterm{coleção} sempre na metalinguagem para referir
a uma pluraridade de objetos.  Nesse caso o uso do modo singular é
apenas um modo de falar e sempre deve ser visto como uma abreviação
de uma frase em modo plural, referindo aos membros de tal coleção.
Mesmo quando damos um nome (como $C,D$) para uma coleção, falamos dos seus membros
usando esse $C$ mesmo e no plural:
\wq{todos os $C$ são legais, mas uns dos $D$ não são}.
Cuidado pois podemos referir a uma coleção $C$ no singular como no
\wq{os membros da $C$ são legais} mas isso não presuponha que existe um
objeto $C$ na nossa mesa mesmo, acessível pelo nosso sistema de definições
e demonstrações.  É apenas uma ferramenta (meta)linguística.

%%}}}

%%{{{ notation: set_notation 
\notation.
%%%{{{ meta 
\label set_notation
\defines
    * conjunto!heterogêneo
    * conjunto!homogêneo
    * conjunto!notação
    * heterogeneidade
    * homogeneidade
    ;;
\pdefs
    \pdef Natal  {{\mathrm{Natal}}}
    \pdef Thanos {{\mathrm{Thanos}}}
    ;;
%%%}}}

A notação mais simples para denotar um conjunto é usar
\dterm{chaves} (os símbolos~\symq{$\{$}~e~\symq{$\}$}) e listar todos
os seus elementos dentro, os escrevendo numa ordem da nossa escolha.
Por exemplo:
\mathcols 2
A &=\set {0,1}                         &  E &=\set {2,3,\set{5,7}, \set{\set{2}}} \\
B &=\set {\nats, \ints, \rats, \reals} &  F &=\set {\Thanos} \\
C &=\set {2}                           &  G &=\set {1,2,4,8,16,31,A,B,\nats} \\
D &=\set {2,3,5,7}                     &  H &=\set {\Thanos, \Natal, \set{E,\set{F,G}}}
\endmathcols

%%}}}

%%{{{ homogeneous_and_heterogeneous_sets 
\note.
%%%{{{ meta 
\label homogeneous_and_heterogeneous_sets
%%%}}}

Em muitos textos os conjuntos cujos elementos são ``do mesmo tipo'' são chamados
\dterm{homogêneos}, e os outros \dterm{heterogêneos}.
Deixamos sem explicação o que significa ``do mesmo tipo'', mas, naturalmente,
consideramos os $A, B, C, D, F$ da~\ref[set_notation] homogêneos
e os $E, G, H$ heterogêneos.
Até o $\set{ \set{1,2}, \set{\set{2,3}, \set{3,4}} }$ acaba heterogêneo
se olhar bem: um dos seus membros é conjunto \emph{de números},
mas o outro é conjunto \emph{de conjuntos de números}.

%%}}}

%%{{{ Dealing with more complicated sets 
\blah.
%%%{{{ meta 
%%%}}}

Todos os conjuntos que acabamos de escrever aqui são \emph{finitos},
seus elementos são conhecidos, e ainda mais são poucos e conseguimos listar todos eles.
Nenhuma dessas três propriedades é garantida!
Se não temos a última fica impráctico listar todos elementos,
e quando não temos uma das duas primeiras, é plenamente impossível.
Considere por exemplo os conjuntos seguintes:
$$
\align
X &= \text{o conjunto de todos os números reais entre 0 e 1}\\
Y &= \text{o conjunto dos assassinos do Richard {\Montague}Montague}\\
Z &= \text{o conjunto de todos os números naturais menores que $2^{256!}$}.
\endalign
$$

%%}}}

%%{{{ notation: set_builder 
\notation Set builder.
%%%{{{ meta 
\label set_builder
\indexes
    * set!comprehension    seealso: set builder
    * definitiva               see: condição
    ;;
\defines
    * \setst {~x : ~\alpha} {~{\phi(x)}}  -- o conjunto de todos os $x : \alpha$ tais que $\phi(x)$
    * condição definitiva
    * set builder
    * set comprehension
    ;;
%%%}}}

Uma notação diferente e bem útil é chamada
notação \dterm{set builder} (ou \dterm{set comprehension}),
onde escrevemos
$$
\setst {x \is \alpha} {\dotswith x} \is \SetA \alpha
$$
para denotar <<o conjunto de todos os habitantes $x$ do tipo $\alpha$ tais que $\phi(x)$>>.\foot
Na literatura aparecem também os símbolos~\symq{$:$}~e~\symq{$;$}~em
vez do~\symq{$\st$}~que usamos aqui.
\toof
Entendemos que no lado direito escrevemos o \dterm{filtro},
uma \emph{condição definitiva},
e não algo ambíguo ou algo subjectivo.
Por exemplo, não podemos escrever algo do tipo
$$
\setst {p \is \Person} { \text{$p$ é uma pessoa linda} }.
$$
Mas como podemos formalizar o que é uma \dterm{condição definitiva}?
Bem, concordamos escrever apenas algo que podemos (se precisarmos e se quisermos)
descrever na linguagem que temos usado para denotar proposições
onde possivelmente aparece a variável $x$.\foot
A situação fica pouco diferente no uso da teoria dos conjuntos como fundamentos
de matemática: ela não é sozinha mas vem acompanhando uma lógica (muitas vezes
lógica da primeira ordem (FOL)) e nesse caso o que permitimos como filtro varia
de acordo com isso (\ref[fol_filter_by_fraenkel_and_skolem]).
\toof
Tendo qualquer $\phi : \alpha \to \Prop$ então, podemos formar o conjunto
$$
\setst {x \is \alpha} {\phi(x)}
$$
que é o conjunto definido pela
$$
a \in \setst {x \is \alpha} {\phi(x)}
\defiff
\phi(a).
$$
A notação set builder é bem mais poderosa do que acabamos de mostrar,
pois nos permite utilizar expressões mais complexas na sua parte esquerda,
e não apenas uma variável.
Vamos investigar isso e mais variações logo na~\ref[full_setbuilder].

%%}}}

%%{{{ remark: variable_binder_in_set_builder 
\remark.
%%%{{{ meta 
\label variable_binder_in_set_builder
\defines
    * variável!ligada
    * variável!livre
    ;;
%%%}}}

Na notação
$$
\setstt {\alert x} {\thole$x$\thole}
$$
temos um \emph{ligador de variável}, pois o $\alert x$ no lado esquerdo
liga todos os $x$'s que aparecem no lado direito livres (e assim viram ligados).
Por exemplo, o conjunto
$$
\setst x {x^2 < xy}
$$
depende do $y$ (mas não do $x$).

%%}}}

%%{{{ beware: variable_capturing_in_set_builder 
\beware Capturação de variável.
%%%{{{ meta 
\label variable_capturing_in_set_builder
\indexes
    * variável!capturada
    * variável!dummy
    ;;
\defines
    * variável!capturada
    ;;
%%%}}}

Podemos trocar o ``dummy'' $x$ por qualquer variável
\emph{que não aparece livre na parte direita},
tomando cuidado para renomear as ligadas também.
Por exemplo
$$
\setst {\alert x} {\alert x^2 < \alert x y} \inteq
\setst {\alert z} {\alert z^2 < \alert z y}
$$
Mas
$$
\setst {\alert x} {\alert x^2 < \alert x y} \intneq
\setst {\alert y} {\alert y^2 < \alert y \alert y}
$$
pois o $y$ que tava livre no ``filtro'' acabou sendo
\emph{capturado} pelo ligador no set builder:
dentro dos $\set{\dots}$ perdemos o
acesso no objeto denotado por $y$ fora.
O $\setst y {y^2 < yy}$ não depende mais do $y$.

%%}}}

%%{{{ set_synonyms_and_fonts 
\note Sinônimos e fontes.
%%%{{{ meta 
\label set_synonyms_and_fonts
\defines
    * colecção
    * família
    ;;
%%%}}}

Às vezes usamos os termos \dterm{família} e \dterm{colecção}
como sinónimos da palavra \wq{conjunto}---mas veja a \ref[collection_vs_set] também.
Seguindo uma práctica comum, quando temos conjuntos de conjuntos
dizemos \emph{família de conjuntos}, e depois
\emph{colecção de famílias}, etc., pois soam melhor e ajudam raciocinar.
Com o mesmo motivo (de agradar ou facilitar nossos olhos,
ouvidos, ou cerebros humanos), às vezes mudamos (``elevamos'')
a fonte que usamos para denotar esses conjuntos:
de $A,B,C,\dots$
para $\cal A, \cal B, \cal C, \dots$
para $\scr A, \scr B, \scr C, \dots$
por exemplo, dependendo de quantos ``níveis de conjuntamentos aninhados''
temos.
Para ilustrar, imagine que já temos definido uns conjuntos $A_1, A_2, A_3, B, C$
e agora queremos falar sobre os conjuntos $\set{A_1, A_2, A_3}$ e $\set{B,C}$
e dar nomes para eles.
Uma escolha razoável seria usar $\scr A$ e $\scr B$ para denotá-los:
\mathcols 2
\scr A &= \set{A_1, A_2, A_3} &
\scr B &= \set{B,C}
\endmathcols
mas isso é apenas questão de costume.  Nada profundo aqui.

%%}}}

%%{{{ remark: collection_vs_set 
\remark.
%%%{{{ meta 
\label collection_vs_set
\defines
    * colecção
    ;;
%%%}}}

Eu vou tentar usar a palavra \dterm{colecção} principalmente
com seu significado intuitivo e informal que suponho que
tu entendes; deixando assim as outras duas (\emph{conjunto}
e \emph{família}) para usar na matemática.

%%}}}

%%{{{ teaser: collection_vs_set_teaser 
\teaser.
%%%{{{ meta 
\label collection_vs_set_teaser
%%%}}}

Em geral um conjunto (matemático) realmente representa
uma colecção (a dos seus membros), mas como veremos
no~\ref[Set_theory] isso não é sempre o caso.
Encontramos \emph{colecções que não podem ser representadas
por conjunto nenhum} (o motivo mais comum sendo que são
grandes demais, algo que deve parecer estranho já que
temos \emph{conjuntos infinitos}); mas pode ter outros
motivos também!

%%}}}

%%{{{ warning: set_synonyms_warning 
\warning.
%%%{{{ meta 
\label set_synonyms_warning
\defines
    * classe
    * espaço
    ;;
\credits
    * Euclid
    * Cantor
    * Baire
    * Borel
    * Hilbert
    * Banach
    * Hausdorff
    * Frechet
    * Stone
    ;;
%%%}}}

Mais duas palavras que às vezes são usadas como sinônimos da \wq{conjunto}
são as \emph{classe} e \emph{espaço}.
Evitarei seu uso aqui por motivos diferentes para cada uma.
A primeira (viz.~\dterm{classe}) é usada em teorias de fundamentos
matemáticos, como teorias axiomáticas de conjuntos,
(\ref[Set_theory]) e seu papel é exatamente isso:
diferenciar o conceito que ela denota por aquele de conjunto!
A segunda, (viz.~\dterm{espaço}) dá a idéia que tal conjunto
tem ``algo mais'' do que \emph{apenas}
seus membros: um certo tipo de \emph{estrutura} (\ref[Structured_sets]):
talvez alguma relação, e/ou operações, etc.:
\wq{\dots mais que conjuntos: espaços!}
Temos espaços:
métricos (\ref[Metric_spaces]),
topológicos (\reftag[Topology]),
vetoriais (\reftag[Vector_spaces]),
sóbrios(!),
poloneses,
projetivos,
afim,
de Euclides,
de Cantor,
de Baire,
de Borel,
de Hibert,
de Banach,
de Hausdorff,
de Fréchet,
de Stone,
e muitos mais de\dots muita gente boa!
E mesmo assim, não temos uma definição matemática do que significa
a palavra (\emph{espaço}) sozinha!
Note também que em linguagens naturais \emph{grupo} é mais uma palavra que
pode servir como sinônimo de \wq{conjunto} mas em matemática não:
no~\ref[Group_theory] definimos o que essa palavra significa \wq{grupo}
em matemática e estudamos sua linda teoria: a teoria dos grupos.

%%}}}

%%{{{ What we need to specify for each new type 
\note Tipos.
%%%{{{ meta 
%%%}}}

Cada vez que introduzimos um novo tipo de objetos,
devemos especificar:
\elist i:
\li: Como podemos formar (construir) habitantes desse tipo?
\li: Como podemos usar (desconstruir) habitantes desse tipo?
\li: Quando dois objetos desse tipo são \emph{iguais}?
\endelist

%%}}}

%%{{{ Black boxes 
\note Black boxes.
%%%{{{ meta 
\label blackbox_set
\indexes
    * black box    seealso: white box
    * white box    seealso: black box
    * conjunto!como black box    see: black box
    ;;
\defines
    * black box
    * black box!de conjunto
    * white box
    ;;
%%%}}}

O conceito de \dterm{black box} (ou \dterm{caixa preta}) é uma ferramenta muito
útil para descrever tipos.
A idéia é que queremos descrever o que realmente determina um objeto desse tipo,
e \emph{esconder} os detalhes ``de implementação'', apresentando apenas seu
``interface''.
Podemos então pensar que um conjunto $A$ é um black box que tem apenas uma
``entrada'' onde podemos botar qualquer objeto $x$ que desejamos, e tem também
uma luz que pode piscar ``sim'' ou ``não'' (correspondendo nos casos
$x\in A$ e $x\nin A$ respectivamente).
\Tikzi blackboxset;
Usamos o termo \emph{black} box para enfatizar que não temos como ``olhar dentro''
desse aparelho, dessa caixa, e ver o que acontece assim que botar uma entrada;
nossa única informação será a luz da caixa que vai piscar ``sim'' ou ``não''.
Quando temos acesso nos ``internals'' da caixa a gente chama de \dterm{white box}
ou \dterm{transparent box}; mas não vamos precisar o uso desse conceito agora.
\eop
A única \emph{estrutura interna} de um conjunto é a capabilidade de
\emph{decidir se dois elementos $x,y$ do conjunto são iguais ou não}.

%%}}}

%%{{{ Q: When are two sets equal? 
\question.
%%%{{{ meta 
%%%}}}

Quando dois conjuntos são iguais?

%%}}}

\spoiler

%%{{{ pseudodf: set_eq_pseudodefinition 
\pseudodefinition.
%%%{{{ meta 
\label set_eq_pseudodefinition
%%%}}}

Consideramos dois conjuntos $A,B$ \dterm{iguais} sse não tem como diferenciar
eles como black boxes.  Em outras palavras, para cada objeto $x$
que vamos dar como entrada para cada um deles, eles vão concordar:
ou ambos vão piscar ``sim'', ou ambos vão piscar ``não''.
O ``slogan'' aqui é:
$$
\text{\emph{um conjunto é determinado por seus membros}}.
$$

%%}}}

%%{{{ df: set_eq 
\definition Igualdade de conjuntos.
%%%{{{ meta 
\label set_eq
%%%}}}

Dois conjuntos são iguais sse têm exatamente os mesmos membros.
Em símbolos,
$$
A = B \defiff \lforall x {x\in A \iff x\in B}.
$$

%%}}}

%%{{{ defining_sets 
\note Definindo conjuntos.
%%%{{{ meta 
\label defining_sets
\indexes
    * condição definitiva
    ;;
%%%}}}

Para determinar então um conjunto $A$ precisamos dizer exatamente
o que significa pertencer ao $A$, ou seja, dizer
quando um objeto arbitrário $x$ pertence ao $A$.
As notações que vimos até agora realmente deixam isso claro;
mas um outro jeito muito útil para \emph{definir} um certo conjunto $A$,
seria apenas preencher o
$$
x \in A  \defiff  \text{\xlthole}
$$
com alguma condição definitiva
(veja~\ref[set_builder]).
\eop
Concluimos que as duas formas seguintes de definir um conjunto $A$,
são completamente equivalentes:
$$
\xalignat2
x &\in A \defiff \text{\lthole}
&
A &\defeq \setst x {\text{\lthole}}.
\endxalignat
$$
As duas afirmações tem exatamente o mesmo efeito:
definir o mesmo conjunto $A$.
Qual das duas usamos, será mais questão de gosto ou de contexto.

%%}}}

%%{{{ remark: what_is_being_defined_really_sets 
\remark O que tá sendo definido mesmo?.
%%%{{{ meta 
\label what_is_being_defined_really_sets
%%%}}}

Definindo um conjunto $A$ pela
$$
x \in A \defiff \xlthole
$$
o que estamos definindo diretamente não é o \sq{$A$} mas o \sq{$x \in A$}.
Só que: o $A$, sendo conjunto, ele é \emph{determinado por seus membros}
(lembra a~\ref[set_eq_pseudodefinition]) ou seja, sabendo
o que $x \in A$ significa para todo $x$, sabemos \emph{quem é} o $A$.

%%}}}

%%{{{ order_and_multiplicity 
\note Ordem e multiplicidade.
%%%{{{ meta 
\label order_and_multiplicity
\indexes
    * conjunto!multiplicidade
    * conjunto!ordem de membros
    ;;
%%%}}}

Considere os conjuntos seguintes:
\mathcols 3
A &=\set{2,3}, &
B &=\set{3,2}, &
C &=\set{3,2,2,2,3}.
\endmathcols
Observe que $A = B = C$.
Ou seja, esses não são três conjuntos, mas apenas \emph{um} conjunto
denotado por três jeitos diferentes.
O ``dispositivo'' conjunto não sabe nem de \dterm{ordem}
nem de \dterm{multiplicidade} dos seus membros.
Não podemos perguntar a um conjunto
<<qual é teu \emph{primeiro} elemento?>>, nem 
<<\emph{quantas vezes} o tal elemento pertence a ti?>>.
Lembre o conjunto como black box!
Sua única interface aceita qualquer objeto,
e responde apenas com um pleno sim ou não.
Logo encontraremos outros tipos de ``recipientes'',
onde as informações de ordem e de multiplicidade são preservadas
(e perguntáveis):
multisets~(\reftag[Multisets]), tuplas~(\reftag[Tuples]), e seqüências~(\reftag[Sequences]).
Bem depois vamos estudar \emph{conjuntos ordenados} (\ref[Posets_Lattices]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por enquanto temos apenas duas relações entre conjuntos:
igualdade $(=)$---que sempre temos para qualquer tipo de objetos---e
essa \dq{nova} de pertencer $(\in)$;
Logo vamos definir mais;
mas antes disso, bora discutir sobre dois conceitos de igualdade diferentes
que mencionei já na~\ref[Intension_vs_extension].\foot
Vai que não ficou claro lá, ou que tu pulou
o \ref[Introductions]---mas tu nunca faria isso, né?
\toof

%%}}}

\endsection
%%}}}

%%{{{ Intension_vs_extension_in_sets 
\section Intensão \vs extensão.
%%%{{{ meta 
\label Intension_vs_extension_in_sets
%%%}}}

%%{{{ Consider four extensionally equal sets 
\note.
%%%{{{ meta 
%%%}}}

Condidere os conjuntos
$$
\align
P &= \setst d {\text{$d$ é um divisor primo de $2^{256!}$}}\\
Q &= \setst p {\text{$p$ é primo e par}}\\
R &= \setst x {\text{$x$ é raiz real do polinómio $x^3 - 8$}}\\
S &= \set {2}.
\endalign
$$

%%}}}

%%{{{ Q: what_are_the_extensions_of_these_four_sets} 
\question.
%%%{{{ meta 
\label what_are_the_extensions_of_these_four_sets
%%%}}}

Quais são os membros de cada um dos conjuntos acima?


%%}}}

%%{{{ A: thinking a bit, they're all the same set 
\blah Resposta.
%%%{{{ meta 
%%%}}}

\emph{Pensando um pouco} percebemos que esses quatro conjuntos
consistem em exatamente os mesmos membros, viz.~o número $2$ e nada mais.
Lembrando na idéia de black box, realmente não temos como diferenciar
entre esses black boxes.
Começando com o $S$, é direto que ele responda ``sim'' apenas no número $2$
e ``não'' em todos os outros objetos.
Continuando com o $P$, realmente temos que o único objeto que satisfaz
seu filtro é o número $2$.  Mesma coisa sobre os $Q$ e $R$.

%%}}}

%%{{{ intension_description 
\note.
%%%{{{ meta 
\label intension_description
\defines
    * extensão!de conjunto
    * igualdade!extensional
    * igualdade!intensional
    * intensão!de conjunto
    ;;
%%%}}}

Como comporta o $S$?
Recebendo sua entrada $a$, ele a compara com o $2$ para ver se $a=2$ ou não,
e responde ``sim'' ou ``não'' (respectivamente) imediatamente.
E o $R$?
Recebendo sua entrada $a$, ele verifica se $a$ é uma raiz do $x^3 - 8$.
Substituindo então o $x$ por $a$, elevando o $a$ ao $3$ e subtraindo $8$,
se o resultado for $0$ responda ``sim''; caso contrário, ``não''.
E o $Q$?
Recebendo sua entrada $a$, ele verifica se $a$ é primo, e se $a$ e par.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
E o $P$?
Recebendo sua entrada $a$, ele verifica se $a \divides 2^{256!}$ e se $a$ é
um número primo.
Se as duas coisa acontecem, ele responda ``sim''; caso contrário, ``não''.
\eop
Acabamos de descrever a \dterm{intensão} de cada conjunto.
Mas, sendo black boxes, dados esses conjuntos $P,Q,R,S$,
não conseguimos diferenciá-los, pois a única interação que sua interface
permite é botar objetos $a$ como entradas, e ver se pertencem ou não.
Falamos então que \dterm{extensionalmente} os quatro conjuntos
são iguais, mas \dterm{intensionalmente}, não.
Usamos os termos \dterm{igualdade extensional} e \dterm{igualdade intensional}.
E para abusar a idéia de black box:
provavelmente o black box $Q$ demora mais para responder, ou fica mais quente,
ou faz mais barulho, etc., do que o $S$.
\eop
Quando definimos um conjunto simplesmente listando todos os seus membros,
estamos escrevendo sua \dterm{extensão}.  E nesse caso, a intensão é a mesma.
Quando usamos a notação builder com um filtro, estamos mostrando a \dterm{intensão}
do conjunto.  Nesse caso as duas noções podem ser tão diferentes, que nem
sabemos como achar sua extensão!

%%}}}

%%{{{ eg: number_theory_conjectures_set_intension 
\example.
%%%{{{ meta 
\label number_theory_conjectures_set_intension
\indexes
    * conjectura
    ;;
\credits
    * Collatz : conjectura
    ;;
%%%}}}

Revise a~\ref[Conjectures_in_number_theory] e considere os conjuntos
\mathcol
T &\defeq \setstt p {$p$ e $p+2$ são prímos} \\
L &\defeq \setstt n {$n \in \nats_{>0}$ e não existe primo entre $n^2$ e $(n+1)^2$} \\
G &\defeq \setstt n {$n \in \nats_{>1}$ e $2n=p+q$ para alguns primos $p,q$} \\
C &\defeq \setstt n {$n \in \nats_{>0}$ e a seqüência Collatz começando com $n$ nunca pega o valor $1$}.
\endmathcol
Sobre o $T$ não sabemos se é finito ou não!
Sobre o $G$, não sabemos se $G = \nats_{>1}$ ou não!
E, sobre os $L$ e $C$ nem sabemos se eles têm elementos ou não,
ou seja, não sabemos nem se $L=\emptyset$ nem se $C=\emptyset$!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Fechando essa secção lembramos que em conjuntos (e em matemática em geral)
usamos igualdade \symq{$=$} como igualdade extensional.

%%}}}

\endsection
%%}}}

%%{{{ Relations between sets and how to define them 
\section Relações entre conjuntos e como defini-las.
%%%{{{ meta 
%%%}}}

%%{{{ df: subconjunto 
\definition.
%%%{{{ meta 
\label subconjunto
\defines
    * ~A \subset ~B  -- $A$ é um subconjunto de $B$
    * subconjunto
    * subconjunto!próprio
    ;;
%%%}}}

O conjunto $A$ é um \dterm{subconjunto} de $B$ sse todos os membros de
$A$ pertencem ao $B$.
Em símbolos:
$$
A \subset B
\defiff
\lforall {x\in A} {x\in B}.
$$
Se $B$ tem elementos que não pertencem ao $A$, chamamos o $A$
um \dterm{subconjunto próprio} de $B$, e escrevemos $A \psubset B$.

%%}}}

%%{{{ warning: psubset_vs_nsubset_notation 
\warning.
%%%{{{ meta 
\label psubset_vs_nsubset_notation
%%%}}}

Naturalmente escrevemos $A \nsubset B$ para a negação da $A \subset B$,
que é diferente da afirmação $A \psubset B$:
$$
\align
A \nsubset B &\intiff \text{$A$ não é um subconjunto de $B$}; \\
A \psubset B &\intiff \text{$A$ é um subconjunto próprio de $B$}.
\endalign
$$
E se quiser dizer que $A$ não é um subconjunto próprio de $B$?
Escreva isso mesmo, ou traduza para seu equivalente
(\wq{$A \nsubset B$ ou $A = B$})
pois ninguém merece ler algo do tipo \sq{$A \smartnot\psubset B$}.

%%}}}

%%{{{ x: eq_implies_subset 
\exercise.
%%%{{{ meta 
\label eq_implies_subset
%%%}}}

$A = B \implies A \subset B$.

\solution
Suponha $A = B$.
Vamos mostrar que $A \subset B$.
Seja $x \in A$.
Mas como $A = B$, logo $x \in B$ também; que foi o que queremos demonstrar.

%%}}}

%%{{{ x: eq_using_subsets 
\exercise.
%%%{{{ meta 
\label eq_using_subsets
%%%}}}

$A = B \iff A \subset B \mland B \subset A$

\solution
\proofpart {\lrdir}:
Imediata pelo~\ref[eq_implies_subset] (pois a igualdade é simétrica).
\crtabproofpart {\rldir}.
Suponha $A \subset B$ e $B \subset A$.
Vamos mostrar que $A = B$.
Seja $x$ um objeto arbitrário.
Calculamos:
\compute
x \in A &\implies x \in B \by {def.~$A \subset B$} \\
x \in B &\implies x \in A \by {def.~$B \subset A$} \\
\endcompute
Ou seja,
$$
x \in A \iff x \in B
$$
que foi o que queremos demonstrar.

%%}}}

%%{{{ x: define_subsetneq 
\exercise.
%%%{{{ meta 
\label define_subsetneq
%%%}}}

Defina com uma fórmula o $A\psubset B$.

\hint
Já definimos o $(\subset)$, então podemos usá-lo!

\solution
$
A \psubset B
\defiff
A \subset B \land A \neq B.
$
\quad
(Lembre-se que $A \neq B \abbreq \lnot(A = B)$.)

%%}}}

%%{{{ beware: notation of subsets 
\beware.
%%%{{{ meta 
%%%}}}

O uso dos símbolos $\knuthsubseteq$, $\knuthsubset$, e $\knuthsubsetneq$ não é muito
padronizado: encontramos textos onde usam $\knuthsubseteq$ e $\knuthsubset$ para
``subconjunto'' e ``subconjunto próprio'' respectivamente;
outros usam $\knuthsubset$ e $\knuthsubsetneq$.
Assim o símbolo $\knuthsubset$ é usado com dois significados diferentes.
Por isso usamos $\subset$ e $\proper$ aqui, evitando completamente
o uso do ambíguo $\knuthsubset$.

%%}}}

%%{{{ notation: supset_sugar 
\note Notação.
%%%{{{ meta 
\label supset_sugar
%%%}}}

Seguindo uma práctica comum que envolve símbolos ``direcionais'' de relações
binárias como os $(\rightarrow)$, $(\leq)$, $(\subset)$, etc., introduzimos os:
\mathcols 2
A \supset    B & \defiff B \subset  A &
A \supsetneq B & \defiff B \psubset A.
\endmathcols

%%}}}

\endsection
%%}}}

%%{{{ Empty, universal, singletons 
\section Vazio, universal, singletons.
%%%{{{ meta 
%%%}}}

%%{{{ df: empty 
\definition Vazio.
%%%{{{ meta 
\label empty
\defines
    * vazio
    ;;
%%%}}}

Um conjunto é \dterm{vazio} sse ele não contem nenhum elemento.
Formalmente, definimos o predicado unário
$$
\Empty(A) \defiff \lforall x {x \nin A}.
$$

%%}}}

%%{{{ df: singleton 
\definition Singleton.
%%%{{{ meta 
\label singleton
%%%}}}

Um conjunto é \dterm{singleton} (ou \dterm{unitário}) sse ele contem
exatamente um elemento.
Formulamente,
$$
\Singleton(A)
\defiff
\lunique x {x \in A}.
$$

%%}}}

%%{{{ x: compare_altdef_of_singleton 
\exercise.
%%%{{{ meta 
\label compare_altdef_of_singleton
%%%}}}

Decida se o seguinte pode servir como definição de singleton:
$$
\Singleton(A)
\askiff
\lexists a
{ a \in A \mland \lforall x { x \in A \limplies x = a } }.
$$

\hint
Substitua a fórmula longa com uma equivalente aproveitando
uns açúcares sintácticos dos quantificadores $\forall, \exists$.

\hint
Escrevemos a fórmula
$$
\exists a
\paren{ a \in A \land \forall x \paren{ x \in A \limplies x = a } }
$$
como
$$
\pexists {a \in A}
\lforall {x \in A} { x = a }.
$$

%%}}}

%%{{{ df: emptyset 
\definition.
%%%{{{ meta 
\label emptyset_symbol
\defines
    * \emptyset  -- o conjunto vazio
    ;;
%%%}}}

Denotamos o conjunto vazio por $\emptyset$.
\mistake

%%}}}

%%{{{ x: what_is_wrong_with_the_emptyset_definition 
\exercise.
%%%{{{ meta 
\label what_is_wrong_with_the_emptyset_definition
%%%}}}

Na~\ref[emptyset_symbol] roubamos!
Resolva o crime.

\hint
``o''

\solution
Como não demonstramos a unicidade do vazio não podemos usar o artigo
definido ``o'', e conseqüentemente, não podemos usar um símbolo
para \emph{o} denotar.  Seria mal-definido.

%%}}}

%%{{{ Parallelism with Singleton(-) to emphasize error 
\note.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Para apreciar ainda mais a gravidade do erro acima:
se apenas a definição de $\Empty(\dhole)$ fosse suficiente
para introduzir a notação $\emptyset$ para denotar ``o conjunto vazio'',
poderiamos também escolher um símbolo para denotar ``o conjunto unitário'':
$$
\align
\text{$\Empty(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto vazio por $\emptyset$.>>}\\
\text{$\Singleton(\dhole)$ definido}
&\quad\leadsto\quad \text{<<Denotamos o conjunto unitário por $\cancel{1}$.>>}
\endalign
$$
Qual de todos---quantos são?---os conjuntos unitários seria o $\cancel{1}$?
Essa ambigüidade não é permitida em matemática.\foot
Se ainda não tá convencido, bota o artigo definido \wq{o} na frase
similar \wq{seja $x$ (um) inteiro}.
O que significaria se fosse \wq{seja $x$ \emph{o} inteiro}?!
\toof

%%}}}

%%{{{ x: how_many_singletons 
\exercise.
%%%{{{ meta 
\label how_many_singletons
%%%}}}

Quantos são mesmo?

\solution
Infinitos!  Pois, para cada objeto $x$ já temos um singleton $\set{x}$.
E agora o singleton dele $\set{\set{x}}$, e dele, e dele, \dots

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então precisamos demonstrar existência e unicidade.
Faça isso agora nos exercícios seguintes.

%%}}}

%%{{{ x: naive_existence_of_emptyset 
\exercise Existência do vazio.
%%%{{{ meta 
\label naive_existence_of_emptyset
%%%}}}

Usando as ferramentas que temos desenvolvido, construa um conjunto vazio.

\hint
Use o set builder.

\hint
Basta achar um filtro que garante que nenhum objeto ``passa'':
$$
\setst x {\asklhole}
$$

\solution
O conjunto $\setst x {x \neq x}$ é um conjunto vazio.

%%}}}

%%{{{ x: naive_uniqueness_of_emptyset 
\exercise Unicidade do vazio.
%%%{{{ meta 
\label naive_uniqueness_of_emptyset
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

Supondo que existe pelo menos um conjunto vazio, mostre sua unicidade.
Não use reductio ad absurdum.

\hint
Em outras palavras, demonstre que:
$$
\text{se $A,B$ são vazios, então $A = B$.}
$$

\hint
Suponha que $A,B$ são vazios.
Qual é teu alvo agora, e o que ele significa mesmo?

\hint
Teu alvo é mostrar que $A = B$.
Para fazer isso é necessário lembrar a definição de $(=)$ nos conjuntos (\reftag[set_eq]).

\solution
Suponha que $A,B$ são vazios.
Preciso mostrar $A=B$, ou seja, que $\forall x( x\in A \liff x \in B )$.
Seja $x$ um objeto arbitrário.
Pela definição de vazio, as duas afirmações $x \in A$ e $x \in B$ são
falsas, e logo a equivalência $(x\in A \liff x\in B)$ verdadeira,
que foi o que queremos demonstrar.

%%}}}

%%{{{ x: naive_uniqueness_of_emptyset_absurdum 
\exercise.
%%%{{{ meta 
\label naive_uniqueness_of_emptyset_absurdum
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

Ache uma demonstração diferente, essa vez usando reductio ad absurdum.

\hint
Suponha que $A,B$ são vazios.
Queremos mostrar que $A = B$.
Então suponha o contrário ($A \neq B$) pera chegar num absurdo.

\hint
Qual é teu alvo agora?
Achar um absurdo qualquer!
Como podemos usar o fato de $A \neq B$?
Lembre-se que $A \neq B$ é apenas uma abreviação para $\lnot(A = B)$.

\solution
Suponha que $A,B$ são vazios.
Queremos demonstrar que $A = B$.
Para chegar num absurdo, suponha que $A \neq B$.
Logo, pela definição da igualdade, temos
que existe $x$ tal que:
$x \in A$ mas $x \nin B$; ou $x \in B$ mas $x \nin A$.
As duas alternativas chegam num absurdo:
a primeira pois $A$ é vazio e logo $x \nin A$, e similarmente
a segunda pois $B$ é vazio e logo $x \nin B$.

%%}}}

%%{{{ df: universal 
\definition Universal.
%%%{{{ meta 
\label universal
\indexes
    * universo    seealso: universal
    ;;
\defines
    * universal!conjunto
    ;;
%%%}}}

Um conjunto é \dterm{universal} sse todos os objetos pertencem nele.
Formalmente,
$$
\Universal(A) \defiff \forall x(x \in A).
$$

%%}}}

%%{{{ x: naive_uniqueness_of_universet 
\exercise Existência e unicidade do universal.
%%%{{{ meta 
\label naive_uniqueness_of_universet
\indexes
    * unicidade!do universal
    ;;
%%%}}}

Demonstre a existência e unicidade do conjunto universal.

\hint
Já demonstrou a existência (\ref[naive_existence_of_emptyset]) e a unicidade
(\ref[naive_uniqueness_of_emptyset] ou
\reftag[naive_uniqueness_of_emptyset_absurdum])
do vazio?

%%}}}

%%{{{ df: universet 
\definition.
%%%{{{ meta 
\label universet_symbol
\defines
    * \universet  -- o conjunto universal
    ;;
%%%}}}

Denotamos o conjunto universal por $\universet$.

%%}}}

%%{{{ Q: How do we use a fact that a set is nonempty? 
\question.
%%%{{{ meta 
\label how_do_we_use_nonempty
%%%}}}

Como podemos usar um fato do tipo $D\neq \emptyset$ em nossas demonstrações?
O que ganhamos realmente?

%%}}}

\spoiler

%%{{{ A: We can pick an element from it! 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Ganhamos o direito de escrever ``Seja $d\in D$.''
Em outras palavras: de tomar um elemento arbitrário de $D$;
de declarar uma variável (não usada) para denotar um membro de $D$.

%%}}}

%%{{{ warning: letting_in_empty_like_division_by_0 
\warning.
%%%{{{ meta 
\label letting_in_empty_like_division_by_0
%%%}}}

Quando temos um conjunto $A$, escrever ``seja $x \in A$''
seria errado se não sabemos que $A \neq \emptyset$.
É um erro parecido quando dividimos uma expressão de aritmética
por $x$, ou apenas escrever uma expressão como a $a/x$,
sem saber que $x\neq 0$.
Como em aritmética precisamos separar em casos
(caso $x = 0$ e caso $x\neq 0$) e os tratar em formas diferentes,
precisamos fazer a mesma coisa trabalhando com conjuntos:
caso $A \neq \emptyset$, achamos uma demonstração onde podemos
realmente declarar uma variável não-usada para declarar
um elemento de $A$;
caso $A = \emptyset$, achamos uma demonstração
diferente---e na maioria das vezes esse caso vai ser trivial
para demonstrar.

%%}}}

\endsection
%%}}}

%%{{{ Eight simple propositions 
\section Oito proposições simples.
%%%{{{ meta 
%%%}}}

%%{{{ x: yes_no_depends_emptyset_arbitraryset 
\exercise.
%%%{{{ meta 
\label yes_no_depends_emptyset_arbitraryset
%%%}}}

Seja $A$ um conjunto.
Responda para cada uma das afirmações abaixo com
{``sim''},
{``não''}, ou
{``depende''}:
$$
\xalignat4
\emptyset &\subset \emptyset;& \emptyset &\in \emptyset; \\
\emptyset &\subset A        ;& \emptyset &\in A        ; \\
A         &\subset \emptyset;& A         &\in \emptyset; \\
A         &\subset A        ;& A         &\in A        .
\endxalignat
$$

\solution
Temos:
$$
\xalignat5
\emptyset &\subset \emptyset& &\text{(sim)}    &\qqqquad&&\emptyset &\in \emptyset&&\text{(não)} \\
\emptyset &\subset A        & &\text{(sim)}    &        &&\emptyset &\in A        &&\text{(depende)} \\
A         &\subset \emptyset& &\text{(depende)}&        &&A         &\in \emptyset&&\text{(não)} \\
A         &\subset A        & &\text{(sim)}    &        &&A         &\in A        &&\text{(depende)}.
\endxalignat
$$

%%}}}

%%{{{ beware: claiming yes/no/depends without proof isn't much 
\beware.
%%%{{{ meta 
%%%}}}

Nossa intuição muitas vezes nos engana, e por isso apenas responder no jeito
que o~\ref[yes_no_depends_emptyset_arbitraryset] pediu não vale muita coisa.
Precisamos demonstrar todas essas respostas.  Para cada uma das oito afirmações
então, precisamos dizer:
\tlist:
\li: \wq{Sim} e \emph{demonstrar} a afirmação;
\li: \wq{Não} e \emph{refutar} a afirmação;
\li: \wq{Depende} e \emph{mostrar} (pelo menos) dois casos:
um onde a afirmação é verdadeira, e outro onde ela é falsa.
\endtlist
Idealmente nesse último caso queremos determinar quando a afirmação é verdadeira,
achando condições \emph{suficientes} e/ou \emph{necessárias}.
Vamos fazer tudo isso agora.

%%}}}

%%{{{ x: attack_order 
\exercise.
%%%{{{ meta 
\label attack_order
%%%}}}

Em qual ordem tu escolharia ``atacar'' essas afirmações?

%%}}}

%%{{{ property: A_notin_emptyset 
\property.
%%%{{{ meta 
\label A_notin_emptyset
%%%}}}

Para todo conjunto $A$, $A \nin \emptyset$.

\proof.
Seja $A$ conjunto.  Agora diretamente pala definição de vazio
tomando $x\asseq A$, temos $A \nin \emptyset$.

%%}}}

%%{{{ cor: emptyset_notin_emptyset 
\corollary.
%%%{{{ meta 
\label emptyset_notin_emptyset
%%%}}}

$\emptyset \nin \emptyset$.

\proof.
Essa afirmação é apenas um \emph{caso especial} de~\ref[A_notin_emptyset]:
tome $A \asseq \emptyset$.

%%}}}

%%{{{ x: emptyset_notin_emptyset_direct_proof 
\exercise.
%%%{{{ meta 
\label emptyset_notin_emptyset_direct_proof
%%%}}}

Demonstre o~\ref[emptyset_notin_emptyset] diretamente, sem usar a~\ref[A_notin_emptyset].

\hint
Quais noções são envolvidas nessa afirmação?
Quais são as definições delas?

%%}}}

%%{{{ property: A_subset_A 
\property.
%%%{{{ meta 
\label A_subset_A
%%%}}}

Para todo conjunto $A$, temos $A \subset A$.

\proof.
Seja $A$ conjunto.  Suponha que $a \in A$.
Agora precisamos mostrar $a\in A$, algo que já temos.

%%}}}

%%{{{ x: A_subset_A_quickest_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Pode achar uma demonstração com menos passos?

\solution
A fórmula que queremos demonstrar é uma tautologia lógica!

%%}}}

%%{{{ cor: emptyset_subset_emptyset 
\corollary.
%%%{{{ meta 
\label emptyset_subset_emptyset
%%%}}}

$\emptyset\subset\emptyset$.

\proof.
Caso especial da~\ref[A_subset_A] tomando $A\asseq \emptyset$,
pois $\emptyset$ é um conjunto.

%%}}}

%%{{{ property: emptyset_subset_A 
\property.
%%%{{{ meta 
\label emptyset_subset_A
%%%}}}

Para todo conjunto $A$, temos $\emptyset \subset A$.

\sketch.
Para chegar num absurdo suponha que tem um contraexemplo:
um conjunto $A$ tal que $\emptyset\nsubset A$.
Daí achamos rapidamente o absurdo desejado lembrando a definição de $\nsubset$.
Sem usar reductio ad absurdum, vamos acabar querendo demonstrar que uma implicação é verdadeira.
Mas cuja premissa é falsa, algo que garanta a veracidade da implicação!

%%}}}

%%{{{ x: emptyset_subset_A_does_not_imply_A_subset_A_and_vv 
\exercise.
%%%{{{ meta 
\label emptyset_subset_A_does_not_imply_A_subset_A_and_vv
%%%}}}

Podemos ganhar a~\ref[A_subset_A] como corolário da~\reftag[emptyset_subset_A]
ou vice-versa?  Explique.

\solution
Não; nenhuma das duas proposições implica a outra.
Da $A\subset A$ não podemos substituir o $A$ com nenhum conjunto para chegar na $\emptyset\subset A$.
Nem como o $\emptyset$, pois ele teria sido substituito selectivamente em apenas na sua primeira instância, algo que obviamente não podemos fazer.
(Similarmente $x = x$ para todos os números $x$ mas não podemos concluir disso que $0 = x$ para todos os $x$.)
Da $\emptyset\subset A$ não podemos chegar na $A \subset A$, pois precisamos substituir a constante $\emptyset$ pela variável $A$.
(Similarmente $0 + x = x$ para todos os números $x$, mas não podemos concluir que $x + x = x$.)

%%}}}

%%{{{ prop: emptyset_in_A_sometimes 
\proposition.
%%%{{{ meta 
\label emptyset_in_A_sometimes
%%%}}}

Existe uma infinidade de conjuntos $A$ que satisfazem a $\emptyset \in A$
e uma infinidade de conjuntos $A$ que não a satisfazem.

%%}}}

%%{{{ property: A_subset_emptyset_iff_A_eq_emptyset 
\property.
%%%{{{ meta 
\label A_subset_emptyset_iff_A_eq_emptyset
%%%}}}

O único subconjunto do $\emptyset$ é ele mesmo.
Em outras palavras:
$$
A \subset \emptyset
\iff
A = \emptyset.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora falta apenas uma afirmação para examinar: $A \in A$?

%%}}}

%%{{{ x: can_you_find_an_irregular_set 
\exercise.
%%%{{{ meta 
\label can_you_find_an_irregular_set
%%%}}}

Consegues mostrar algum conjunto com a propriedade que ele pertence nele mesmo?
Ou seja, podes achar um conjunto $A$ tal que $A\in A$?

%%}}}

\endsection
%%}}}

%%{{{ More set builder 
\section Mais set builder.
%%%{{{ meta 
\label full_setbuilder
%%%}}}

%%{{{ blah section intro 
\blah.
%%%{{{ meta 
%%%}}}

Já encontramos a versão mais simples de set comprehension
(ou notação set builder) que nos permite escrever
$$
\setstt { x } {\thole$x$\thole}
$$
onde $x$ é uma variável, e $\text{\thole$x$\thole}$
uma afirmação onde pode aparecer essa variável $x$.
Essa notação é bem mais flexível que isso.
Por exemplo
$$
\setst {p^n + x} {\text{$p$ é primo, $n$ é ímpar, e $x\in[0,1)$}}
$$
seria o conjunto de todos os números reais que podem ser escritos na forma
$p^n + x$ para algum primo $p$, algum ímpar $n$, e algum real $x$ com $0 \leq x < 1$.
\eop
Finalmente, mais uma extensão dessa notação é que usamos
$$
\setstt {x \in A} {\thole$x$\thole}
\defeq
\setst {x} {x \in A \mland \text{\thole$x$\thole}}.
$$

%%}}}

%%{{{ x: why_treat_x_in_A_sugar_separately 
\exercise.
%%%{{{ meta 
\label why_treat_x_in_A_sugar_separately
%%%}}}

Por que a notação
$$
\setst {x \in A} {\text{\thole$x$\thole}}
$$
não é apenas um caso especial da notação que nos permite escrever
termos na parte esquerda de set builder?

\hint
O ``$x \in A$'' é um termo?

\solution
Pois o ``$x \in A$'' não é um termo, mas uma proposição (afirmação).

%%}}}

%%{{{ x: div_mul_pow_of_12_and_m_setbuilder_practice 
\exercise.
%%%{{{ meta 
\label div_mul_pow_of_12_and_m_setbuilder_practice
%%%}}}

Usando a notação set builder defina os conjuntos
$D_{12}$, $M_{12}$, e $P_{12}$
de todos os divisores, todos os múltiplos, e todas as potências de $12$.
Generalize para um inteiro $m$.
Identifique quais variáveis que aparecem na tua resposta são livres e quais são ligadas.

\solution
$$
\xalignat2
D_{12} &\defeq \setst {n \in \ints} {n \divides 12}  &
D_m    &\defeq \setst {n \in \ints} {n \divides m}   \\
M_{12} &\defeq \setst {12n}  {n \in \ints}           &
M_m    &\defeq \setst {mn}   {n \in \ints}           \\
P_{12} &\defeq \setst {12^n} {n \in \nats}           &
P_m    &\defeq \setst {m^n}  {n \in \nats}
\endxalignat
$$
Onde aparece a variável \symq{$m$}, ela está livre, e
onde aparece a variável \symq{$n$}, ela está ligada.

%%}}}

%%{{{ x: set_builder_map_size_limit 
\exercise.
%%%{{{ meta 
\label set_builder_map_size_limit
%%%}}}

Seja $T = \set{u,v}$ um conjunto com dois elementos $u,v$.
Definimos um conjunto $A$ pela
$$
A \defeq \setst {f(n,m)} {n,m \in T}
$$
Quantos elementos tem o $A$?

\hint
Primeiramente calcule a extensão do $A$:
$$
A = \set{ \dots?\dots }.
$$

\solution
Calculando a extensão de $A$ achamos:
$$
A = \set{ f(u,u), f(u,v), f(v,u), f(v,v) }.
$$
Então o $A$ tem \emph{no máximo} $4$ elementos---mas pode acontecer que tem menos (veja~\ref[set_builder_map_exercise]).

%%}}}

%%{{{ x: set_builder_map_exercise 
\exercise.
%%%{{{ meta 
\label set_builder_map_exercise
%%%}}}

Escreva a extensão do conjunto
$$
B \defeq \setst {n^2 + m^2} {n,m \in \set{1,3}}.
$$

\solution
Calculamos:
$$
\align
B
&= \setst {n^2 + m^2} {n,m \in \set{1,3}}\\
&= \set{ 1^2 + 1^2, 1^2 + 3^2, 3^2 + 1^2, 3^2 + 3^2 }\\
&= \set{ 2, 10, 10, 18 }\\
&= \set{ 2, 10, 18 }.
\endalign
$$

%%}}}

%%{{{ x: rich_set_builder_sugar 
\exercise.
%%%{{{ meta 
\label rich_set_builder_sugar
%%%}}}

Mostre como a notação ``mais rica'' de
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
$$
pode ser definida como açúcar sintáctico se temos já a notação de
comprehensão que permite apénas uma variável no lado esquerdo.
Aqui considere que o $t(x_1,\dotsc, x_n)$ é um termo que pode ser
bem complexo, formado por outros termos complexos, etc., e onde
possivelmente aparecem as variáveis $x_1,\dotsc,x_n$.

\hint
Precisa descrever (definir) o conjunto
$$
\align
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)} &\\
\intertext{com uma notação que já temos:}
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
&\defeq
\dots?
\endalign
$$

\hint
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x {\text{\thole?\thole}}
$$

\solution
$$
\setst {t(x_1, \dotsc, x_n)} {\phi(x_1,\dotsc,x_n)}
\defeq
\setst x { \exists x_1\dotsb\exists x_n \paren{ x = t(x_1,\dotsc,x_n) \land \phi(x_1,\dotsc,x_n)}}.
$$

%%}}}

%%{{{ beware: variable-binding in set builder 
\beware.
%%%{{{ meta 
\indexes
    * ligador
    ;;
%%%}}}

As variáveis que aparecem na parte esquerda de set builder,
são \emph{ligadores} que ligam com as correspondentes variáveis livres
que aparecem na afirmação na parte direita (filtro).
Então cuidado com o uso dessas variáveis pois é fácil escrever
algo que mesmo que realmente determina um conjunto,
não é o conjunto desejado!

%%}}}

%%{{{ x: variable_binding_in_setbuilder_exercise 
\exercise.
%%%{{{ meta 
\label variable_binding_in_setbuilder_exercise
%%%}}}

Para cada um dos conjuntos abaixo,
decida se sua definição realmente é correta.
Caso que sim, determina a extensão do conjunto definido.
Caso que não, explique qual é o problema com a definição.
Em todas elas, considere que nosso universo é o $\reals$.
$$
\align
A &= \setstt x {$\sqrt{x^2 + 2} \mland x \in \reals$}\\
B &= \setstt x {$\sqrt{x^2 + 2}$ para algum $x\in \reals$}\\
C &= \setstt t {$\sqrt{x^2 + 2} = t$ para algum $x\in \reals$}\\
D &= \setstt x {$\sqrt{x^2 + 2} = x$ para algum $x\in \reals$}\\
E &= \setstt x {$\sqrt{x^2 + 2} = x$ para todo $x\in \reals$}\\
F &= \setstt x {$\sqrt{t^2 + 2} = x$ para todo $t\in \reals$}\\
G &= \setstt x {$\sqrt{t^2 + 2} = x$ para algum $t\in \reals$}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Operations on sets and how to define them 
\section Operações entre conjuntos e como defini-las.
%%%{{{ meta 
%%%}}}

%%{{{ Operações 
\note Operações.
%%%{{{ meta 
%%%}}}

Lembramos que uma operação num tipo de objetos
mapeia certos objetos desse tipo (suas entradas)
para \emph{exatamente um} objeto desse tipo (sua saída).

%%}}}

%%{{{ Definindo operações 
\note Definindo operações.
%%%{{{ meta 
%%%}}}

Então como podemos \emph{definir uma operação} nos conjuntos?
O que precisamos deixar claro?
\standout
\emph{Um operador é determinado por seu comportamento.}
\endstandout
Então se a ``saída'' (ou o ``resultado'') duma operação
é um conjunto, basta determinar esse conjunto para quaisquer entradas
aceitáveis pela operação.
E como determinamos um conjunto?
Para começar, podemos usar um dos jeitos que já encontramos para definir um conjunto $A$:
\mathcols 2
A       &\defeq \setst x {\text{\thole$x$\thole}} &
x \in A &\defiff \text{\thole$x$\thole}.
\endmathcols
Bora definir umas operações conhecidas para aquecer.

%%}}}

%%{{{ df: union_def 
\definition.
%%%{{{ meta 
\label union_def
\defines
    * ~A \union ~B  -- a união dos $A$ e $B$
    * união
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos
$$
A \union B \defeq \setst x {\text{$x \in A$ ou $x\in B$}}
$$
Alternativamente, podemos definir a mesma operação na seguinte forma equivalente:
$$
x \in A \union B \defiff \text{$x \in A$ ou $x\in B $}.
$$
Chamamos o $A \union B$ a \dterm{união} dos $A$ e $B$.

%%}}}

%%{{{ remark: from_x_in_A_union_B_to_A_union_B_to_union 
\remark.
%%%{{{ meta 
\label from_x_in_A_union_B_to_A_union_B_to_union
%%%}}}

Primeiramente esquematicamente:
$$
\align
\alert{x \in A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in \alert{A \union B}           &\alertdefiff \text{$x \in A$ ou $x \in B$} \\
x \in A \mathbin{\alert{\union}} B &\alertdefiff \text{$x \in A$ ou $x \in B$}.
\endalign
$$
onde colorifiquei três maneiras de entender o que é que tá sendo definido mesmo.
\eop
E agora com palavras:
se eu determinar o que significa que um $x$ arbitrário pertence ao
$A \union B$, então eu determinei o $A \union B$, pois ele é um conjunto e
\emph{um conjunto é determinado por seus membros;}
e como eu fiz isso para quaisquer conjuntos $A,B$ (arbitrários),
então eu determinei o $\union$, pois ele é um operador e
\emph{um operador é determinado por seu comportamento}.
Vamos voltar nesse assunto nos capítulos~\reftag[Functions]
e~\reftag[Set_theory] onde estudamos funções e teoria dos
conjuntos respectivamente.

%%}}}

%%{{{ df: inter_def 
\definition.
%%%{{{ meta 
\label inter_def
\defines
    * ~A \inter ~B  -- a intersecção dos $A$ e $B$
    * intersecção
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos
$$
x \in A \inter B \defiff x \in A \mland x\in B.
$$
Chamamos o $A\inter B$ a \dterm{intersecção} dos $A$ e $B$.

%%}}}

%%{{{ x: inter_altdef
\exercise.
%%%{{{ meta 
\label inter_altdef
%%%}}}

Defina a operação $\inter$ usando a notação set builder.

\solution
Sejam $A,B$ conjuntos.
Qualquer uma das definições seguintes serve:
$$
\align
A \inter B &\defeq \setst {x} {x \in A \mland x\in B}\\
A \inter B &\defeq \setst {x\in A} {x\in B}\\
A \inter B &\defeq \setst {x\in B} {x\in A}
\endalign
$$

%%}}}

%%{{{ df: disjoint_sets 
\definition.
%%%{{{ meta 
\label disjoint_sets
\defines
    * disjuntos
    ;;
%%%}}}

Chamamos dois conjuntos \dterm{disjuntos}
sse não têm nenhum elemento em comum.
Em símbolos,
$$
\text{$A,B$ disjuntos} \defiff A \inter B = \emptyset.
$$

%%}}}

%%{{{ beware: type_errors 
\beware type errors.
%%%{{{ meta 
\label type_errors
%%%}}}

Não confunda o uso dos \symq{$\defeq$} e \symq{$\defiffsymbol$} (nem dos \symq{$=$} e~\symq{$\iffsymbol$}).
Usamos o \symq{$=$} para denotar \emph{igualdade} entre dois \emph{objetos},
e usamos o \symq{$\iffsymbol$} para denotar que as \emph{afirmações} que
aparecem nos dois lados são \emph{equivalentes}.
No mesmo jeito que não podemos escrever
$$
\xalignat3
2 + 3 &\iff 5 &&\text{nem} & (x \leq y) &\;=\; (x + 1 \leq y + 1)\\
\intertext{não podemos escrer também}
A \setminus B &\iff A \inter \compl B &&\text{nem} & (A \psubset B) &\;=\; (A \subset B \mland A \neq B).\\
\intertext{O que queríamos escrever nesses casos seria:}
2 + 3 &= 5                           &&& x \leq y &\iff x+1 \leq y + 1\\
A \setminus B &= A \inter \compl B &&& A \psubset B &\iff A \subset B \mland A \neq B.
\endxalignat
$$
Caso que tudo isso não foi óbvio, sugiro revisitar o~\ref[Introductions]:
\reftag[Propositions_vs_objects], \reftag[Type_errors], \reftag[Intension_vs_extension]).

%%}}}

%%{{{ remark: The rich language of sets 
\remark A linguagem rica dos conjuntos.
%%%{{{ meta 
%%%}}}

Observe que conseguimos traduzir a frase
``os $A,B$ não têm nenhum elemento em comum''
como uma igualdade entre dois conjuntos, o $A\inter B$
e o $\emptyset$:
$$
\textwq{os $A,B$ não têm nenhum elemento em comum}
\quad\leadsto\quad
A\inter B = \emptyset.
$$
A linguagem de conjuntos é realmente muito expressiva,
algo que vamos começar a apreciar ainda mais,
na~\reftag[Translating_from_and_to_the_language_of_sets].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Continuamos com mais operações, incluindo nossa primeira operação unária.

%%}}}

%%{{{ df: complement_def 
\definition.
%%%{{{ meta 
\label complement_def
\defines
    * \compl{~A}  -- o complemento de $A$
    * complemento
    ;;
%%%}}}

Seja $A$ conjunto.  Definimos
$$
\compl A \defeq \setst x {x\nin A}
$$
Chamamos o $\compl A$ o \dterm{complemento} de $A$.

%%}}}

%%{{{ df: setminus_def 
\definition.
%%%{{{ meta 
\label setminus_def
\defines
    * ~A \setminus ~B  -- o complemento relativo de $B$ no $A$
    * complemento!relativo
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
$$
A \setminus B
\defeq
\setst { x\in A } {x \nin B}
$$
Chamamos o conjunto $A\setminus B$ o \dterm{complemento relativo} de $B$ no $A$,
e pronunciamos o $A\setminus B$ como \utter{$A$ menos $B$} ou
\utter{$A$ fora $B$}.

%%}}}

%%{{{ x: setminus_practice 
\exercise.
%%%{{{ meta 
\label setminus_practice
%%%}}}

Calcule (a extensão d)os conjuntos:
% TODO: fix reflabs
\elist:
\li: $\set{0,1,2,3,4} \setminus \set{4,1}$
\li: $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3}$
\li: $\set{0,1,2} \setminus \nats$
\li: $\nats \setminus \set{0,1,2}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{0,1,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}}$
\li: $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}}$
\li: $\set{7,\emptyset} \setminus \emptyset$
\li: $\set{7,\emptyset} \setminus \set{\emptyset}$
\li: $\reals \setminus 0$
\li: $\reals \setminus \set{0}$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{\set{1}}}$
\endelist
Cuidado: um leitor \dq{mal-tipado} daria respostas diferentes em umas dessas.

\hint
Não siga tua intuição; siga fielmente a definição!

\solution
\elist:
\li: $\set{0,1,2,3,4} \setminus \set{4,1} = \set{0,2,3}$
\li: $\set{0,1,2,3,4} \setminus \set{7,6,5,4,3} = \set{0,1,2}$
\li: $\set{0,1,2} \setminus \nats = \emptyset$
\li: $\nats \setminus \set{0,1,2} = \set{3,4,5,6,\dotsc} = \setst {n \in \nats} {n \geq 3}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{0,1,2} = \set{\set{0,1}, \set{1,2}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}, \set{0,2}} \setminus \set{\set{1,2}} = \set{\set{0,1}, \set{0,2}}$
\li: $\set{\set{0,1}, \set{1,2}} \setminus \set{\set{1}} = \set{\set{0,1}, \set{1,2}}$
\li: $\set{7,\emptyset} \setminus \emptyset = \set{7,\emptyset}$
\li: $\set{7,\emptyset} \setminus \set{\emptyset} = \set{7}$
\li: $\reals \setminus 0 = \reals$
\li: $\reals \setminus \set{0} = (-\infty,0)\union(0,+\infty)$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus 1 = \set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}}$
\li: $\set{1,\set{1}, \set{\set{1}}, \set{\set{\set{1}}}} \setminus \set{\set{\set{1}}} = \set{1,\set{1}, \set{\set{\set{1}}}}$
\endelist

%%}}}

%%{{{ x: setminus_equalities_practice 
\exercise.
%%%{{{ meta 
\label setminus_equalities_practice
%%%}}}

Sejam $A,B$ conjuntos.
Considere as afirmações:
$$
\xalignat3
(1)  \quad& \emptyset \setminus \emptyset = \emptyset       &
(5)  \quad& A \setminus A = A                               &
(9)  \quad& A \setminus B = B                               \\
(2)  \quad& A \setminus \emptyset         = A               &
(6)  \quad& A \setminus A = \emptyset                       &
(10) \quad& A \setminus B                   = B \setminus A \\
(3)  \quad& \emptyset \setminus A         = \emptyset       &
(7)  \quad& A \setminus B = \emptyset                       &
(11) \quad& A \setminus \set{B}             = A             \\
(4)  \quad& \set{\emptyset} \setminus A   = \emptyset       &
(8)  \quad& A \setminus B = A                               &
(12) \quad& \set{A,B} \setminus (A\union B) = \emptyset     
\endxalignat
$$
Para cada uma delas:
demonstre, se é verdadeira;
refuta, se é falsa; mostre um exemplo e um contraexemplo,
se sua veracidade depende dos $A,B$ (e tente determinar
exatamente quando é verdadeira).

%%}}}

%%{{{ df: symdiff_def 
\definition.
%%%{{{ meta 
\label symdiff_def
\defines
    * ~A \symdiff ~B  -- a diferença simétrica dos $A$ e $B$
    * diferença simétrica
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Sua \dterm{diferença simétrica}
é o conjunto de todos os objetos que pertencem a exatamente um dos $A,B$.
O denotamos por $A \symdiff B$:
$$
x \in A \symdiff B \defiff \text{$x$ pertence a exatamente um dos $A,B$}.
$$

%%}}}

%%{{{ eg: symdiff_example 
\example.
%%%{{{ meta 
\label symdiff_example
%%%}}}

Calculamos (as extensões d)os conjuntos:
\tlist:
\li: $\set{0,1,2,3} \symdiff \set{1,2,4,8} = \set{0,3,4,8}$;
\li: $\set{\set{0,1}, \set{1,2}} \symdiff \set{0,1,2} = \set{ \set{0,1}, \set{1,2}, 0, 1, 2 }$;
\li: $\set{\set{0,1}, \set{1,2}} \symdiff \set{\set{0,1},\set{0,2}} = \set{ \set{0,2}, \set{1,2} }$;
\li: $(-2,1) \symdiff (-1,2) = (-2,-1] \union [1,2)$
\endtlist
(Veja a~\ref[intervals_of_reals] caso que não reconheceu
a notação de intervalos que aparece no último exemplo.)

%%}}}

%%{{{ x: what_is_A_symdiff_A_and_A_symdiff_emptyset 
\exercise.
%%%{{{ meta 
\label what_is_A_symdiff_A_and_A_symdiff_emptyset
%%%}}}

Dado $A$ conjunto, calcule os conjuntos $A\symdiff A$ e $A \symdiff \emptyset$.

%%}}}

%%{{{ Q: How would you call symdiff's members? 
\question.
%%%{{{ meta 
%%%}}}

O que interessante (e característico) têm os membros de $A \symdiff B$?
Como os chamarias com palavras de rua?

%%}}}

\spoiler

%%{{{ A: symdiff_heart 
\note Resposta.
%%%{{{ meta 
\label symdiff_heart
\indexes
    * testemunha
    ;;
%%%}}}

Pensando pouco nas definições de
$$
A \symdiff B
\qqqqtext{e}
A = B
$$
concluimos que a diferença simétrica de dois conjuntos tem exatamente
todas as \dterm{testemunhas} que mostram que
os conjuntos são diferentes:
$$
x \in A \symdiff B
\heartiff
\text{$x$ é um testemunha que $A,B$ são diferentes.}
$$
O que podes concluir então assim que souberes que $A \symdiff B = \emptyset$?
(Isso é o~\ref[when_A_symdiff_B_is_empty], que resolverás logo.)

%%}}}

%%{{{ Venn_diagrams 
\note Diagramas de Venn.
%%%{{{ meta 
\label Venn_diagrams
\defines
    * diagrama de Venn
    ;;
%%%}}}

O leitor provavelmente já encontrou os \dterm{diagramas de Venn}{\Venn} na sua vida,
uma ferramenta muito útil para descrever operações e ajudar em raciocinar sobre
relações de conjuntos.
Por exemplo, podemos visualizar as quatro operações binárias que definimos até agora
assim:
$$
\xalignat4
A\union B:
&\quad
\gathered
\tikzpicture
\tikzi venn2union;
\endtikzpicture
\endgathered
&
A\inter B:
&\quad
\gathered
\tikzpicture
\tikzi venn2inter;
\endtikzpicture
\endgathered
\\
A \setminus B:
&\quad
\gathered
\tikzpicture
\tikzi venn2setminus;
\endtikzpicture
\endgathered
&
A \symdiff B:
&\quad
\gathered
\tikzpicture
\tikzi venn2symdiff;
\endtikzpicture
\endgathered
\endxalignat
$$
E a única operação unária, o complemento, assim:
$$
\align
\compl A:
&\quad
\gathered
\tikzpicture
\tikzi venn1compl;
\endtikzpicture
\endgathered
\endalign
$$

%%}}}

%%{{{ Venn_diagrams_limitations 
\beware Limitações de Venn.
%%%{{{ meta 
%%%}}}

Assim que tiver mais que três conjuntos os diagramas de
Venn perdem sua clareza e logo sua utilidade.

%%}}}

%%{{{ x: Venn_4_what_is_wrong 
\exercise.
%%%{{{ meta 
\label Venn_4_what_is_wrong
%%%}}}

Um aluno desenhou o seguinte diagrama Venn para representar todas as
possíveis maneiras que $4$ conjuntos $A,B,C,D$ podem intersectar entre si:
$$
\tikzpicture
\tikzi venn4wrong;
\endtikzpicture
$$
Qual o problema com esse diagrama?

\hint
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Contamos $14$ regiões.
Qual o problema?

\solution
Temos $4$ conjuntos; e como cada objeto pode ou pertencer ou não pertencer
a cada um deles, temos no total $2^4=16$ distintas configurações.
Mas no diagrama do aluno aparecem apenas $14$:
$$
\tikzpicture
\tikzi venn4wrongmarked;
\endtikzpicture
$$
Logo tem duas configurações então que não são representadas por nenhuma parte do diagrama.
São essas:
$$
\gather
x \in A \mland x \nin B \mland x \in C \mland x \nin D \\
x \nin A \mland x \in B \mland x \nin C \mland x \in D.
\endgather
$$

%%}}}

\endsection
%%}}}

%%{{{ Proving equalities and inclusions 
\section Demonstrando igualdades e inclusões.
%%%{{{ meta 
%%%}}}

%%{{{ x: simple_inclusion_practice_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \subset B \mland A \subset C$ então $A \subset B \inter C$}.
$$

\solution
Vou demonstrar a afirmação.
\eop
Suponha que $A \subset B$ e $A \subset C$.
Tome um $a \in A$.  Precisamos mostrar que $a \in B \inter C$.
Como $a \in A$ e $A \subset B$, temos $a \in B$;
e como $a \in A$ e $A \subset C$, temos $a \in C$.
Logo $a \in B\inter C$, pela definição de $B\inter C$.

%%}}}

%%{{{ x: simple_inclusion_practice_refutation 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todos os conjuntos $A,B,C$,
se $A \psubset B \mland A \psubset C$, então $A \psubset B \inter C$.}
$$

\solution
Vou refutar a afirmação com um contraexemplo.
Tome
$$
\align
A &\asseq \set { 2 }\\
B &\asseq \set { 1,2 }\\
C &\asseq \set { 2,3 }.
\endalign
$$
Realmente $A \psubset B$ e $A \psubset C$, mas mesmo assim $A = B\inter C$.

%%}}}

%%{{{ prop: set_de_morgan 
\proposition De Morgan para conjuntos.
%%%{{{ meta 
\label set_de_morgan
%%%}}}

{\DeMorgan[leis para conjuntos]}%
Para quaisquer conjuntos $A,B,C$,
$$
\align
C \setminus (A \union B) &= (C \setminus A) \inter (C \setminus B)\\
C \setminus (A \inter B) &= (C \setminus A) \union (C \setminus B).
\endalign
$$

\proof.
Sejam $A,B,C$ conjuntos.
Vamos demonstrar a primeira igualdade e deixar a segunda como
exercício~(\reftag[set_de_morgan_exercise]).
Mostramos as duas inclusões separadamente:
\eop
\lrdirset:
Tome $x \in C \setminus (A \union B)$.
Daí $x \in C$ e $x \nin (A \union B)$, ou seja $x\nin A$ e $x \nin B$.
Como $x \in C$ e $x\nin A$, temos $x\in C\setminus A$, e,
similarmente $x\in C\setminus B$.
Logo chegamos no desejado $x\in (C\setminus A) \inter (C\setminus B)$.
\eop
A inclusão inversa \rldirset\ é similar.

%%}}}

%%{{{ x: set_de_morgan_exercise 
\exercise.
%%%{{{ meta 
\label set_de_morgan_exercise
%%%}}}

Demonstre a segunda igualdade da~\ref[set_de_morgan].

%%}}}

%%{{{ warning: set_de_morgan_using_formulas 
\warning Não escreva assim!.
%%%{{{ meta 
\label set_de_morgan_using_formulas
\indexes
    * dualidade
    ;;
%%%}}}

Uma outra maneira de demonstrar a~\ref[set_de_morgan],
é calcular usando fórmulas e leis de lógica:
\compute
x \in C \setminus (A \union B)
&    \iff x \in C \land \lnot (x \in A \union B)                       \by {def.~$C \setminus (A \union B)$} \\
&    \iff x \in C \land \lnot (x \in A \lor x \in B)                   \by {def.~$\union$} \\
&    \iff x \in C \land (x \nin A \land x \nin B)                  \by {De~Morgan} \\
&\dotsiff (x \in C \land x \nin A) \land (x \in C \land x \nin B)  \by {idemp.,~assoc.,~comut.~de~$\land$} \\
&    \iff (x \in C \setminus A) \land (x \in C \setminus B)            \by {def.~$\setminus$} \\
&    \iff x \in (C \setminus A) \inter (C \setminus B).                \by {def.~$\inter$} \\
\endcompute
Logo
$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B)
$
pela definição da igualdade de conjuntos.
E a demonstração da outra igualdade é de graça,
pois é a sua proposição \emph{dual}:
trocamos apenas os $\union$ com os $\inter$, e os $\lor$ com os $\land$!
\emph{Mas não fique muito empolgado com essa demonstração--cálculo:}
uma demonstração duma proposição é um texto, legível, que um humano consegue
seguir, entender, e verificar;
exatamente como fizemos na~\ref[set_de_morgan].

%%}}}

%%{{{ prop: symdiff_altdef1 
\proposition.
%%%{{{ meta 
%%%}}}

Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \setminus B) \union (B \setminus A).
$$

\sketch.
Antes de começar, traduzimos os dois lados:
<<em exatamente um dos dois>> na esquerda,
<<no primeiro mas não no segundo ou no segundo mas não no primeiro>> na direita.
Faz sentido que os dois conjuntos são iguais, pois as duas frases são equivalentes!
Mas para demonstrar formalmente a afirmação, mostramos as duas direções
$$
\xalignat3
A \symdiff B &\subset (A \setminus B) \union (B \setminus A) && \mland &
A \symdiff B &\supset (A \setminus B) \union (B \setminus A)
\endxalignat
$$
separadamente, usando as definições de $(\subset)$ e $(\supset)$.

%%}}}

%%{{{ prop: symdiff_altdef2 
\proposition.
%%%{{{ meta 
%%%}}}

Sejam $A,B$ conjuntos.  Logo,
$$
A \symdiff B
=
(A \union B) \setminus (A \inter B).
$$

\sketch.
Novamente, começamos pensando nos dois lados e suas intensões:
<<em exatamente um dos dois>> na esquerda;
<<em pelo menos um dos dois, mas não nos dois>> na direita.
As duas frases são equivalentes, mas vamos mostrar formalmente
a igualdade desses conjuntos, mostrando novamente as
{\lrdirset} e {\rldirset} separadamente.

%%}}}

%%{{{ remark: we could have defined symdiff elsehow 
\remark.
%%%{{{ meta 
%%%}}}

No~\reftag[symdiff_def] eu dei uma definição elementária,
para determinar o conjunto $A\symdiff B$.
De fato, seria até melhor \emph{definir} a operação $\symdiff$ usando uma das
duas expressões que encontramos acima.

%%}}}

%%{{{ x: when_A_symdiff_B_is_empty 
\exercise.
%%%{{{ meta 
\label when_A_symdiff_B_is_empty
%%%}}}

Demonstre ou refute a afirmação:
$$
\text{para todo conjunto $A,B$,
se $A\symdiff B = \emptyset$,
então $A = B$}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Cardinality 
\section Cardinalidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: naive_cardinality 
\definition.
%%%{{{ meta 
\label naive_cardinality
\defines
    * \card {~A}  -- a cardinalidade de $A$
    * cardinalidade!ingenuamente
    ;;
%%%}}}

Seja $A$ um conjunto.
A \dterm{cardinalidade} de $A$ é a quantidade de elementos de $A$.
A denotamos por $\size A$:
$$
\size A \defeq \knuthcases {
    n,      & se $A$ é finito com exatamente $n$ membros distintos\cr
    \infty, & se $A$ é infinito.
}
$$
Às vezes usamos a notação $\nsize A$ quando o $A$ é finito,
mas mesmo nesses casos evitarei essa notação.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nos capítulos~\reftag[Cantors_paradise] e~\reftag[Set_theory]
vamos \emph{refinar} essa notação pois como {\Cantor}Cantor percebeu,
o segundo caso na~\ref[naive_cardinality] é \emph{bem}, \emph{bem}, \emph{bem}
mais rico do que aparece!

%%}}}

%%{{{ property: size_of_union 
\property.
%%%{{{ meta 
\label size_of_union
%%%}}}

Sejam $A,B$ conjuntos finitos.
Logo
$$
\size {A\union B} \leq \size A + \size B.
$$

\proof.
Pelo princípio da inclusão--exclusão
(\reftag[Inclusion_exclusion_principle])
temos
$$
\size {A\union B} = \size A + \size B - \size {A \inter B}
$$
e como uma cardinalidade não pode ser negativa, segue a desigualdade desejada.

%%}}}

%%{{{ x: size_of_union_of_disjoint 
\exercise.
%%%{{{ meta 
\label size_of_union_of_disjoint
%%%}}}

Determine quando temos \symq{$=$} na desigualdade
da~\ref[size_of_union].

\solution
Exatamente quando $A,B$ são disjuntos.
Em símbolos,
$$
\size {A\union B} = \size A + \size B
\iff
A \inter B = \emptyset.
$$

%%}}}

\endsection
%%}}}

%%{{{ Powerset 
\section Powerset.
%%%{{{ meta 
\label Powerset
%%%}}}

%%{{{ df: powerset_def 
\definition.
%%%{{{ meta 
\label powerset_def
\indexes
    * conjunto!de partes    see: powerset
    ;;
\defines
    * \pset{~A}         -- o powerset de $A$ (conjunto de partes)
    * \psetfin{~A}      -- o powerset finito de $A$
    * ~Α \finsubset ~B  -- $A$ é um subconjunto finito de $B$
    * powerset
    ;;
%%%}}}

Seja $A$ conjunto.
Chamamos o \dterm{powerset} (ou \dterm{conjunto de partes}, ou
\dterm{conjunto potência}) de $A$,
denotado por $\pset A$, é o conjunto de todos os subconjuntos de $A$.
Formalmente:
$$
X \in \pset A \defiff X \subset A.
$$
O \dterm{powerset finito} de $A$, que denotamos por $\psetfin A$,
é o conjunto de todos os subconjuntos \emph{finitos} de $A$:
$$
X \in \psetfin A \defiff X \finsubset A.
$$

%%}}}

%%{{{ x: size_of_pset 
\exercise justificativa do nome.
%%%{{{ meta 
\label size_of_pset
%%%}}}

Seja $A$ conjunto finito.  Qual a cardinalidade do $\pset A$ em termos
da cardinalidade do $A$?

\solution
Já resolvemos isso na~\ref[Number_of_subsets]!
Concluimos que:
$$
\size {\pset A} = 2^{\size A}.
$$

%%}}}

%%{{{ df: subset_setbuilder 
\definition Mais set builder.
%%%{{{ meta 
\label subset_setbuilder
%%%}}}

Dado conjunto $A$, introduzimos a notação
$$
\setst {X \subset A} { \phi(X) }
\defeq
\setst {X \in \pset A} { \phi(X) }.
$$

%%}}}

%%{{{ x: calculating_powersets 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule (ache a extensão d)os conjuntos seguintes:
$$
\pset\set{1, 2}
\qquad \pset\set{a,b,\set{a,b}},
\qquad \pset\set{\emptyset,\set{\emptyset}},
\qquad \pset\set{\nats}.
$$

%%}}}

%%{{{ x: iterate_pset_on_emptyset 
\exercise.
%%%{{{ meta 
\label iterate_pset_on_emptyset
%%%}}}

Calcule os conjuntos seguintes:
$$
\pset\emptyset,
\qquad
\pset\pset\emptyset,
\qquad
\pset\pset\pset\emptyset.
$$

\solution
Calculamos pela definição de $\pset$:
$$
\align
\pset\emptyset &= \set { \emptyset }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset} }\\
\pset\pset\emptyset &= \set { \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\emptyset, \set{\emptyset}} }
\endalign
$$

%%}}}

%%{{{ x: powersingletons 
\exercise.
%%%{{{ meta 
%%%}}}

Defina usando duas maneiras diferentes um operador unário $\pset_1$
que forma o conjunto de todos os \emph{singletons} feitos por membros
da sua entrada.

\solution
Qualquer uma das duas definições serve:
$$
\align
\pset_1 A &\defeq \setst {\set{a}} {a \in A} \\
\pset_1 A &\defeq \setst {X \subset A} {\Singleton(X)}.
\endalign
$$

%%}}}

\endsection
%%}}}

%%{{{ Big_union_Big_intersection 
\section União grande; intersecção grande.
%%%{{{ meta 
\label Big_union_Big_intersection
%%%}}}

%%{{{ intro 
\blah.
%%%{{{ meta 
%%%}}}

Generalizamos agora as operações binárias de união e intersecção para suas
versões arbitrárias, as operações unitárias $\Union\dhole$ e $\Inter\dhole$.
Antes de dar uma definição, mostramos uns exemplos.
Esses operadores são mais interessantes e úteis quando são aplicados em
conjunto cujos membros são conjuntos também, pois---coloquialmente
falando---eles correspondem na união e na intersecção dos seus membros.

%%}}}

%%{{{ eg: Union_Inter_example 
\example.
%%%{{{ meta 
\label Union_Inter_example
%%%}}}

Aplicamos as operações $\Union$ e $\Inter$ nos conjuntos seguintes:
\mathcol
\Union \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{0,1,2,4,6,8,10}\\
\Inter \set{ \set{1,2,4,8}, \set{0,2,4,6}, \set{2,10} } &= \set{2}\\
\Union \set{ \nats, \ints, \rats, \reals }              &= \reals\\
\Inter \set{ \nats, \ints, \rats, \reals }              &= \nats\\
\Union \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \set{4,5,6}\\
\Inter \set{ 2, 3, \set{4,5}, \set{4,6} }               &= \emptyset
\endmathcol

%%}}}

%%{{{ from_binary_connectives_to_quantifiers 
\note De conectivos binários para quantificadores.
%%%{{{ meta 
\label from_binary_connectives_to_quantifiers
%%%}}}

Considere a afirmação:
$$
\text{<<Alex comeu manga ou Babis comeu manga.>>}
$$
Naturalmente essa proposição corresponde numa disjunção:
$$
\mubraceb {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceb {\text{ou}} {\lor}
\mubraceb {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
Dualmente (trocando o ``ou'' por ``e'') chegamos numa conjunção:
$$
\mubraceb {\text{Alex comeu manga}} {\phi(\mathrm{Alex})}
\mubraceb {\text{e}} {\land}
\mubraceb {\text{Babis comeu manga}} {\phi(\mathrm{Babis})}.
$$
E agora a pergunta:

%%}}}

%%{{{ Q: How can you express those with exists and forall? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos descrever cada uma das
$$
\xalignat2
&\phi(A) \lor  \phi(B) &
&\phi(A) \land \phi(B)
\endxalignat
$$
(que são uma disjunção e uma conjunção) como uma fórmula
que começa com quantificador?

%%}}}

\spoiler

%%{{{ A: like this 
\note Resposta.
%%%{{{ meta 
%%%}}}

Assim!:
$$
\align
\phi(A) \lor  \phi(B) & \iff \lexists {x \in \set{A,B}} {\phi(x)} \\
\phi(A) \land \phi(B) & \iff \lforall {x \in \set{A,B}} {\phi(x)}.
\endalign
$$
Com palavras pouco mais humanas:
$$
\gather
\text{<<Alguém dos $A,B$ comeu manga.>>} \\
\text{<<Todos os $A,B$ comeram manga.>>}
\endgather
$$

%%}}}

%%{{{ Q: How would you define Union and Inter? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias as $\Union$ e $\Inter$ formalmente então?
Podes adivinhar definições que concordam com todos esses exemplos no
\reftag[Union_Inter_example]?

%%}}}

\spoiler

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observe que pela definição de $\union$ temos
$$
\align
x \in A \union B
&\iff x \in A \mlor  x \in B \\
&\iff \text{$x$ pertence àlgum dos $A, B$} \\
&\iff \lexists {X \in \set{A,B}} {x \in X}
\intertext{e dualmente para a intersecção:}
x \in A \inter B
&\iff x \in A \mland x \in B \\
&\iff \text{$x$ pertence a cada um dos $A, B$} \\
&\iff \lforall {X \in \set{A,B}} {x \in X}.
\endalign
$$
Chegamos assim na resposta formal:

%%}}}

%%{{{ df: Union_Inter_def 
\definition.
%%%{{{ meta 
\label Union_Inter_def
\defines
    * \Inter ~{\scr A}  -- a intersecção de $\scr A$
    * \Union ~{\scr A}  -- a união de $\scr A$
    * intersecção!grande
    * união!grande
    ;;
%%%}}}

Seja $\scr A$ um conjunto.
$$
\align
x \in \Union \scr A
&\defiff
\text{$x$ pertence àlgum dos membros do $\scr A$}\\
x \in \Inter \scr A
&\defiff
\text{$x$ pertence a todos os membros do $\scr A$}.
\intertext{Equivalentemente com fórmulas,}
x \in \Union \scr A
&\defiff
\lexists {A \in \scr A} {x \in A}\\
x \in \Inter \scr A
&\defiff
\lforall {A \in \scr A} {x \in A}.
\endalign
$$
Chamamos o $\Union\scr A$ a \dterm{união} de $\scr A$, e o $\Inter\scr A$
a \dterm{intersecção} de $\scr A$.

%%}}}

%%{{{ x: union_and_inter_from_Union_and_Inter_sugar 
\exercise.
%%%{{{ meta 
\label union_and_inter_from_Union_and_Inter_sugar
%%%}}}

Defina os operadores binários $\union$ e $\inter$ como açúcar sintáctico
definido pelos operadores unários $\Union$ e $\Inter$ respectivamente.

\solution
Sejam $A,B$ conjuntos.
Botamos
$$
\xalignat2
A \union B &\defeq \Union\set{A,B} &
A \inter B &\defeq \Inter\set{A,B}.
\endxalignat
$$

%%}}}

%%{{{ x: iterate_Union_on_emptyset 
\exercise.
%%%{{{ meta 
\label iterate_Union_on_emptyset
%%%}}}

Calcule os conjuntos:
$\Union \emptyset$;
$\Union\Union \emptyset$.

%%}}}

%%{{{ x: Inter_emptyset 
\exercise.
%%%{{{ meta 
\label Inter_emptyset
%%%}}}

Calcule o $\Inter\emptyset$.

\hint
Siga a definição e nada mais!

\solution
Por enquanto a resposta correta é $\Inter\emptyset = \universet$.
Mas ``stay tuned'' pois isso vai mudar no~\ref[Set_theory].
Em geral $\universet$ não é o que queremos, então vamo tomar cuidado
para verificar que uma família de conjuntos não é vazia antes de
considerar sua intersecção!

%%}}}

%%{{{ x: Inter_universet 
\exercise.
%%%{{{ meta 
\label Inter_universet
%%%}}}

Calcule o $\Inter\universet$.

\hint
Siga a definição e nada mais!

\hint
$\Inter\universet = \emptyset$.
Por quê?

%%}}}

%%{{{ x: Union_and_Inter_of_singleton 
\exercise.
%%%{{{ meta 
\label Union_and_Inter_of_singleton
%%%}}}

Seja $A$ conjunto.
Calcule os $\Union\set{A}$ e $\Inter\set{A}$.

%%}}}

%%{{{ x: Inter_of_supsets_supset 
\exercise.
%%%{{{ meta 
\label Inter_of_supsets_supset
%%%}}}

Sejam $C$ conjunto e $\scr A$ família de conjuntos tais que todos
contêm o $C$ (ou seja, $C$ é um subconjunto de cada membro da $\scr A$).
Demonstre que $C \subset \Inter \scr A$.

\solution
Seja $c \in C$.
Para mostrar que $c \in \Inter \scr A$, seja $A \in \scr A$ e agora
basta mostrar que $c \in A$.
Mas pela definição de $\scr A$ sabemos que $A \supset C$.
Logo $c \in A$.

%%}}}

%%{{{ x: Inter_is_contained_in_every_member 
\exercise.
%%%{{{ meta 
\label Inter_is_contained_in_every_member
%%%}}}

Seja $\scr A$ família não vazia de conjuntos.
Demonstre que $\Inter \scr A$ está contido em todo membro da $\scr A$.

\solution
Seja $A \in \scr A$.
Para demonstrar que $\Inter \scr A \subset A$,
tome $x \in \Inter \scr A$\fact1.
Agora basta mostrar que $x \in A$.
Pela \byfact1, $x$ pertence a todos os membros da $\scr A$, e logo $x \in A$ também.

%%}}}

%%{{{ intuition_about_Inter_Union_powerset_and_set_braces 
\note.
%%%{{{ meta 
\label intuition_about_Inter_Union_powerset_and_set_braces
%%%}}}

Bem, bem, bem informalmente podemos dizer que: a operação $\Union$ tire o nível
mais externo de chaves; a $\Inter$ também mas jogando fora bem mais elementos
(aqueles que não pertencem em todos os membros do seu argumento); e o $\pset$
bote todas as chaves em todas as combinações possíveis para ``o nível mais
próximo''.

%%}}}

%%{{{ x: scr_A_might_not_contain_union 
\exercise.
%%%{{{ meta 
\label scr_A_might_not_contain_union
%%%}}}

Sejam $A$ conjunto e $\scr A \subset \pset A$ tal que
$$
\Union \scr A = A.
$$
A afirmação
$$
A \in \scr A
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir,
mostre um exemplo e um contraexemplo.

\hint
Depende: ache um exemplo e contra exemplo.

\solution
\proofpart {Exemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{1, 2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
e que $A \in \scr A$.
\crproofpart {Contraexemplo.}
Tome
$$
\align
A        &= \set {1, 2} \\
\scr A   &= \set {\set{1}, \set{2} } \subset \pset A.
\endalign
$$
Observe que realmente $\Union \scr A = A$
mas mesmo assim $A \nin \scr A$.

%%}}}

%%{{{ x: card_of_set_its_Union_and_its_Inter_comparison 
\exercise.
%%%{{{ meta 
\label card_of_set_its_Union_and_its_Inter_comparison
%%%}}}

Ache conjuntos finitos $A,B$ tais que
$$
\xalignat2
&0 < \card { \Inter A } < \card A < \card { \Union A } &
&0 < \card B < \card { \Inter B } < \card { \Union B }.
\endxalignat
$$

\solution
Tome
$$
\xalignat2
A &\asseq \set{ \set{ 1,2,3 },   \set{ 3,4,5 }   } &&(0 < 1 < 2 < 5)\\
B &\asseq \set{ \set{ 1,2,3,4 }, \set{ 2,3,4,5 } } &&(0 < 2 < 3 < 5).
\endxalignat
$$

%%}}}

%%{{{ x: inter_subset_union_for_nondisjoint_families 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $\scr A, \scr B$ famílias de conjuntos
com $\scr A \inter \scr B \neq \emptyset$.
Demonstre ou refute a afirmação:
$$
\Inter\scr A \subset \Union\scr B.
$$

\hint
A afirmação é verdadeira.  Demonstre!

\hint
O teu alvo é demonstrar que um conjunto está contido em outro.
Como atacamos isso?

\hint
Como usarás a hipótese $\scr A \inter \scr B \neq \emptyset$?

\hint
Use as definições de $\Inter$ e $\Union$.

\solution
Vamos demonstrar a afirmação.
Suponha $x \in \Inter\scr A$\fact1.
Para mostrar que $x \in \Union\scr B$, basta achar um membro da $\scr B$ em que o $x$ pertence.
Seja $W \in \scr A \inter \scr B$ (sabemos que $\scr A \inter \scr B \neq \emptyset$).
Logo $W \in \scr A$\fact2~e $W \in \scr B$ (def.~$\inter$).
Pelas \byfact1,\byfact2 temos $x\in W$,
e como $W \in \scr B$, temos o desejado $x \in \Union\scr B$.
\eop
(Obs.: demonstramos assim um $W$ tal que
$\Inter\scr A \subset W \subset \Union\scr B$.)

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: equal_Union_and_Inter 
\problem.
%%%{{{ meta 
\label equal_Union_and_Inter
%%%}}}

Seja $\scr A$ família de conjuntos tal que
$$
\Union \scr A = \Inter \scr A.
$$
O que podes concluir sobre o $\scr A$?

\solution
Vou demonstrar que $\scr A$ tem exatamente um membro ($\scr A$ é um singleton).
\crtabproofpart {$\scr A$ tem pelo menos um membro.}
Se $\scr A$ fosse vazio não teriamos
$\Union \scr {A} = \Inter \scr {A}$,
pois o primeiro é o vazio e o segundo o universo.
\crtabproofpart {$\scr A$ tem no máximo um membro.}
Sejam $A,B \in \scr A$.
Vou mostrar que $A=B$.
\crproofpart {\lrdirset}:
Para qualquer $x$ temos:
\compute
x \in A
&\implies x \in \Union \scr A   \by {$A \in \scr A$ e def.~$\Union\scr A$} \\
&\implies x \in \Inter \scr A   \by {$\Union \scr A = \Inter \scr A$} \\
&\implies x \in B               \by {$B \in \scr A$ e def.~$\Inter\scr A$} \\
\endcompute
\proofpart {A {\rldirset}} é similar:
\crproofalt{Alternativa usando reductio ad absurdum.}
Para chegar numa contradição suponha que $A \neq B$.
Logo seja $t \in A \symdiff B$, ou seja $t$ pertence a um dos $A,B$ mas não ao outro.
Logo $t \in \Union \scr A$ e $t \nin \Inter \scr A$, absurdo.

%%}}}

%%{{{ prob: dualize_and_prove_Inter_of_supsets_supset 
\problem.
%%%{{{ meta 
\label dualize_and_prove_Inter_of_supsets_supset
%%%}}}

Dualize e demonstre o resultado do~\ref[Inter_of_supsets_supset].

%%}}}

%%{{{ prob: unions_left_adjoint_pset
\problem.
%%%{{{ meta 
\label unions_left_adjoint_pset
%%%}}}

Sejam $A,B$ conjuntos.
Para cada direcção de
$$
\Union A \subset B
\askiff
A \subset \pset B
$$
demonstre ou refute.

%%}}}

%%{{{ prob: arbitrary_finite_symdiff 
\problem.
%%%{{{ meta 
\label arbitrary_finite_symdiff
%%%}}}

Sejam $n\in\nats$ com $n\geq 2$ e $n$ conjuntos
$A_1, A_2, \dotsc, A_n$.
Seja
$$
A = A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n.
$$
Observe que como a operação $\symdiff$ é associativa e comutativa,
o $A$ é bem-definido.
Demonstre que:
$$
A = \setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$

\hint
Introduza uma notação para o conjunto
$$
\setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$
Já que ele depende de $n$, algo do tipo $A_{[n]}$ serve bem aqui.
Assim, basta demonstrar o seguinte:
$$
\lforall {n \in \nats} {\Delta_{i=1}^n A_i = A_{[n]}}.
$$

\hint
Indução.

\solution
Dado qualquer natural $n$, denotamos por
$$
\oddAs n \defeq
\setstt a {$a$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_n$}.
$$
Demonstramos por indução que para todo inteiro $n \geq 2$,
$$
A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_n
= \oddAs n
$$
\proofpart {Base ($n \asseq 2$):}
$x \in A_1 \symdiff A_2 \iff \text{$x$ pertence a uma quantidade ímpar dos $A_1,A_2$}$ (óbvio).
\crtabproofpart {Passo indutivo:}
Seja $k\in\nats$ tal que 
$$
A_1 \symdiff \dotsb \symdiff A_k = \oddAs k. \tag{H.I.}
$$
Precisamos mostrar que:
$$
A_1 \symdiff \dotsb \symdiff A_{k+1}
= \oddAs {k+1}
$$
\proofpart {\lrdirset}:
Suponha que $x\in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_{k+1}$,
ou seja, $x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
Pela definição de $\symdiff$, temos dois casos:
\crtabproofcase {Caso 1:}
$x \in A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\nin A_{k+1}$.\CR
Pela {H.I.}, $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$,
e não ao $A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\crtabproofcase {Caso 2:}
$x \nin A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k \mland x\in A_{k+1}$.\CR
Pela H.I., $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$ e também ao
$A_{k+1}$, então a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
\eop
\bigskip
\eop
\proofpart {\rldirset}:
Suponha que $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_{k+1}$.
Separamos em dois casos:
\crtabproofcase {Caso 1:} $x \in A_{k+1}$.\CR
Logo $x$ pertence a uma quantidade par dos $A_1,\dotsc,A_k$
e logo
$x\nin A_1\symdiff\dotsb\symdiff A_k$ (pela H.I.).
Ou seja,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.
\crtabproofcase {Caso 2:} $x \nin A_{k+1}$.\CR
Nesse caso $x$ pertence a uma quantidade ímpar dos $A_1,\dotsc,A_k$,
ou seja $x \in \oddAs k$,
e pela H.I.~temos que $x\in A_1\symdiff\dotsb\symdiff A_k$.
De novo,
$x \in (A_1 \symdiff A_2 \symdiff \dotsb \symdiff A_k) \symdiff A_{k+1}$.

%%}}}

%%{{{ prob: arbitrary_finite_symdiff_gen 
\problem.
%%%{{{ meta 
\label arbitrary_finite_symdiff_gen
%%%}}}

O que devemos mudar (e como) no~\ref[arbitrary_finite_symdiff] e sua resolução,
se apagar o ``$n \geq 2$''?

\hint
O que significa $A_1\symdiff\dotsb\symdiff A_n$ nesse caso?
Por quê?

\solution
Precisamos verificar que a expressão $A_1\symdiff\dotsb\symdiff A_n$
faz sentido no caso que $n=0$, ou seja, definir razoavelmente a
diferença simétrica de uma seqüência vazia de conjuntos.
Formalmente verificamos que
$\emptyset\symdiff C = C = C\symdiff\emptyset$ para qualquer
conjunto $C$:
$\emptyset$ é o elemento neutro da operação $\symdiff$,
e logo o valor próprio da expressão acima.
\eop
Na prova, a base muda para $n=0$, onde devemos apenas demonstrar que nenhum $a$ pertence numa quantidade ímpar dos (zero) $A_i$'s, que é óbvio.

%%}}}

%%{{{ prob: df: chain_in_sets 
\definition.
%%%{{{ meta 
\label chain_in_sets
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos a $\scr A$ de \dterm{$(\subset)$-chain} sse
$$
\text{para todo $A,B\in \scr A$, temos $A\subset B$ ou $B \subset A$}.
$$

%%}}}

%%{{{ prob: chain_first_encounter 
\problem.
%%%{{{ meta 
\label chain_first_encounter
%%%}}}

Seja $\scr C$ uma $(\subset)$-chain e seja $T = \Union \scr C$.
A afirmação
$$
\text{$\scr C \union \set{T}$ é uma chain}
$$
é verdadeira?
Se sim, demonstre; se não, refute;
se os dados não são suficientes para concluir, mostre um exemplo e um contraexemplo.

\hint
A airmação é verdadeira.  Demonstre.

\solution
Vou demonstrar que $\scr C \union \set {T}$ é uma chain.
\eop
Sejam $A,B \in \scr C \union \set T$.
Preciso mostrar que $A \subset B$ ou $B\subset A$.
Vou separar em casos dependendo de se os $A,B$ pertencem à $\scr C$ ou ao $\set{T}$.
\crproofcase {Caso ambos pertencem à $\scr C$.}
Como $\scr C$ é chain, temos imediatamente $A\subset B$ ou $B \subset A$.
\crproofcase {Caso exatamente um pertence à $\scr C$.}
Chame $C$ aquele que pertence à $\scr C$.
O outro pertence ao $\set{T}$ e logo é o próprio $T = \Union \scr C$.
Vou mostrar que $C \subset T$.
Seja $c \in C$.
Preciso mostrar que $c$ pertence em algum dos membros do $\scr C$,
que acontece pois $C \in \scr{C}$.
\crproofcase {Caso nenhum pertence à $\scr C$.}
Ou seja, ambos pertencem ao $\set{T}$; ou seja $A = B = T$; e logo $A\subset B$
e pronto.

%%}}}

%%{{{ prob: chain_first_encounter_interesting_example 
\problem.
%%%{{{ meta 
\label chain_first_encounter_interesting_example
%%%}}}

Uma chain $\scr C$ que atende as hipotéses do~\ref[chain_first_encounter]
pode ter a propriedade que
$$
\Union\scr C \in \scr C.
$$
Mostre um exemplo duma chain infinita $\scr C$ cujos membros são todos
conjuntos infinitos, e tal que $\Union\scr C \nin \scr C$.
Dá pra garantir (com a mesma $\scr C$) que $\Inter\scr C\nin \scr C$ também?
Demonstre tuas afirmações!

\hint
Procure uma $\scr C \subset \pset \reals$.

\hint
Intervalos não triviais (com pelo menos $2$ membros) de reais
com certeza são infinitos.

\solution
\proofpart {Defino a $\scr C$} pela
$$
\scr C \defeq \setst {(-a,a)} {a \in \reals_{>0}}
$$
onde $(-a,a)$ denota o intervalo aberto de
reais $\setst {x\in\reals} {-a < x < a}$ (veja~\reftag[intervals_of_reals]).
Realmente temos
$$
\xalignat2
\Union\scr C &= \reals    \nin \scr C; &
\Inter\scr C &= \emptyset \nin \scr C.
\endxalignat
$$
\proofpart {Demonstração que $\emptyset,\reals\nin\scr C$.}
Seja $C \in \scr C$, e logo seja $a_C \in \reals$ tal que $C = (-a_C,a_C)$.
Como $a_C+1 \nin C$ e $a_C+1 \in \reals$, temos $C \neq \reals$.
Como $0 \in C$, temos $C \neq \emptyset$.
Demonstrei então que o arbitrário membro da $\scr C$ não pode ser
nem o $\emptyset$ nem o $\reals$ e logo nenhum dos dois pertence à $\scr C$.

%%}}}

%%{{{ prob: Venn_4_correct 
\problem.
%%%{{{ meta 
\label Venn_4_correct
%%%}}}

No~\ref[Venn_4_what_is_wrong] encontramos um desenho errado.
Tem como desenhar um correto?

\hint
Esqueça a idéia de usar $4$ cíclos.

\hint
Começa assim:
$$
\tikzpicture
\tikzi venn4correcthint;
\endtikzpicture
$$

\solution
Uma maneira de dezenhá-lo seria assim:
$$
\tikzpicture
\tikzi venn4correct;
\endtikzpicture
$$
Se tu achou outra e realmente tem todas as $16$ configurações possíveis,
tá tranqüilo!

%%}}}

\endproblems
%%}}}

%%{{{ Tuples 
\section Tuplas.
%%%{{{ meta 
\label Tuples
%%%}}}

%%{{{ intro 
\secintro
Até agora temos trabalhado bastante com conjuntos,
e sabemos que podemos perguntar um conjunto se qualquer
objeto é um membro dele ou não, mas um conjunto não pode
nos dar uma informação de ordem (\ref[order_and_multiplicity]).
Imagine que temos os dois primeiros ganhadores dum campeanato
num conjunto $W$; não temos como saber quem ganhou o
ouro e quem o prata.
Precisamos um outro tipo nesse caso, cuja interface é
perguntar
\emph{<<quem é teu primeiro objeto?>>}~e
\emph{<<quem é teu segundo objeto?>>}~também.
Oi, tuplas!
\eop
Nessa secção vamos estudar a idéia de \dterm{par ordenado},
ou \dterm{dupla}, ou \dterm{$2$-tupla},
ou---por enquanto---apenas \dterm{tupla}.
O que é?
\emph{Dois objetos (não necessariamente distintos)
onde um deles é considerado primeiro e o outro segundo.}
Só isso mesmo!
Vamos denotar o par ordenado dos objetos $a$ e $b$ (nessa ordem)
por $\tupa{a, b}$ ou $\tupp{a, b}$.
%%}}}

%%{{{ tuples_towards_interface_equality_notation 
\note Interface, igualdade, notação.
%%%{{{ meta 
\label tuples_towards_interface_equality_notation
%%%}}}

Precisamos: descrever qual é o ``interface primitivo'' desse novo
tipo, \emph{em tal forma que deixamos claro o que precisamos definir
para determinar uma tupla}.
Tendo isso vamos também definir o que significa $(=)$ entre tuplas.
Pensando em black boxes ajudou nos conjuntos; que tal tentar agora também?

%%}}}

%%{{{ Q: How would you describe a black box for tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como descreverias um black box de tupla?

%%}}}

\spoiler

%%{{{ Black boxes for tuples 
\note Tupla como black box.
%%%{{{ meta 
\label blackbox_tuple
\indexes
    * tupla!como black box    see: black box
    ;;
\defines
    * black box!de tupla
    ;;
%%%}}}

Aqui duas maneiras equivalentes de visualizar uma tupla como black box:
$$
\xalignat2
&\tikzpicture
\tikzi blackboxtuple;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxtuplebuttons;
\endtikzpicture
\endxalignat
$$
O da direita, o black box duma tupla $\tup{a,b}$ tem dois butões, e uma saida,
e cada vez que apertamos um botão cria um objeto: apertando o primeiro
sai o objeto $a$, apertando o segundo sai o $b$.
O da esquerda não tem nenhum botão nem entradas, mas só duas saidas:
na primeira sempre sai o $a$, na segunda o $b$.
Como nos black boxes de conjuntos, os black boxes de tuplas também são
deterministas: apertando o mesmo botão sempre sai o mesmo objeto
(na primeira versão), e olhando para o mesmo cabo-saida sempre sai o mesmo objeto.
Por outro lado, existe uma grande diferença: um black box de conjunto
\emph{recebe} um objeto e \emph{vira uma proposição;} um black box de tupla
\emph{não recebe nenhum objeto} (apenas escolhemos se queremos extrair o
primeiro ou o segundo componente dele, e ele \emph{retorna} mesmo esse
\emph{objeto}.

%%}}}

%%{{{ tuple_interface 
\note Interface.
%%%{{{ meta 
\label tuple_interface
%%%}}}

As operações primitivas de tuplas são as operações unárias
$\proj 0$ e $\proj 1$,
chamadas \dterm{projecções}.
Nada mais!
Para qualquer tupla $t$,
$\proj 0 t$ é seu primeiro componente e
$\proj 1 t$ o seu segundo.

%%}}}

%%{{{ remark: Alternative notations 
\remark Notações alternativas.
%%%{{{ meta 
%%%}}}

Outros nomes para as projecções $\proj 0$ e $\proj 1$ são:
$$
\tproj0,\ \tproj1,\ \dotsc;
\qquad
\pproj0 {\dhole},\ \pproj1 {\dhole},\ \dotsc;
\qquad
\outl,\ \outr;
\qquad
\fst,\ \snd.
$$
Em vez de decorar os símbolos das projecções com índices começando
no $0$, às vezes é mais útil começar no $1$.  Mas não se preocupe
tanto com isso pois pelo contexto vai sempre ser claro qual é a
notação seguida.

%%}}}

%%{{{ Q: How to determine a tuple 
\question.
%%%{{{ meta 
%%%}}}

O que preciso fazer para ter o direito de dizer que eu determinei uma tupla?

%%}}}

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Preciso ter dois objetos, numa ordem.
Querendo ou não, é isto que é uma tupla.
Vamos ver isso em mais detalhe.

%%}}}

%%{{{ tuple_determine 
\note Como determinar.
%%%{{{ meta 
\label tuple_determine
%%%}}}

A partir da interface de tuplas (\reftag[tuple_interface]),
é claro que para determinar uma tupla $\alert t$ precisamos
definir como ela comporta, ou seja, isto:
\quote
Seja $\alert t$ a tupla definida pelas
$$
\xalignat2
\proj 0 \app {\alert t} &\alertdefeq x &
\proj 1 \app {\alert t} &\alertdefeq y.
\endxalignat
$$
\endquote
Observe que aqui os $x$ e $y$ supostamente já são objetos
bem-definidos.
Em vez de escrever tudo isso, usamos diretamente
a notação-construtor de tuplas:

%%}}}

%%{{{ tuple_constructor 
\definition Construtor de tupla.
%%%{{{ meta 
\label tuple_constructor
\defines
    * construtor!de tuplas
    ;;
%%%}}}

Sejam $x,y$ objetos.
Denotamos por $\tup{x,y}$ a tupla definida pelas
$$
\xalignat2
\proj 0 {\tup{x,y}} &= x & \proj 1 {\tup{x,y}} &= y
\endxalignat
$$
Consideramos então o $\tup{\dhole,\dhole}$ como um
\dterm{construtor de tuplas}.

%%}}}

%%{{{ warning: dont_redefine_the_constructor_of_tuples 
\warning.
%%%{{{ meta 
\label dont_redefine_the_constructor_of_tuples
%%%}}}

Acabamos de \emph{definir} o símbolo $\tup{x,y}$ para quaisquer $x,y$.
Não é apenas que <<não precisa>>, ainda mais: é que \emph{não podes}
re-definir isso.  Se tu tens dois objetos $x$ e $y$, não tenta justificar
nem introduzir para teu leitor o que é o $\tup{x,y}$.
Ele já sabe, a partir da \ref[tuple_constructor].
Ele também sabe o que significa somar;
tu não escreverias
\quote
Seja $x+y$ inteiro tal que ele é a soma dos $x$ e $y$.
\endquote
Certo?

%}}}

%%{{{ tuple_fundamental_equations 
\note Equações fundamentais.
%%%{{{ meta 
\label tuple_fundamental_equations
%%%}}}

Considere que temos $x,y$, dois objetos.
Podemos então formar a tupla $\tup{x,y}$ deles,
e depois usar as projecções $\proj 0$ e $\proj 1$ nessa tupla.
O que cada uma delas vai retornar para nos?
$$
\xalignat2
\proj 0 \tup{x,y} &= x &
\proj 1 \tup{x,y} &= y
\endxalignat
$$
Conversamente agora, considere que temos uma tupla $t$.
E nela usamos as projecções $\proj 0$ e $\proj 1$,
e botamos esses valores (e nessa ordem) para construir
uma tupla. Onde chegamos?
Olhe isso; e olhe isso bem:
$$
t = \tup{ \proj 0 \app t , \proj 1 \app t }.
$$

%%}}}

%%{{{ Q: How would you describe equality for tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como definarias igualdade entre tuplas?

%%}}}

\spoiler

%%{{{ A: informal answer 
\blah Resposta informal.
%%%{{{ meta 
%%%}}}

Duas tuplas são iguais sse ``concordam em cada posição''.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Sem aspas, chegamos na seguinte

%%}}}

%%{{{ df: tuples_equality 
\definition Igualdade.
%%%{{{ meta 
\label tuples_equality
%%%}}}

Sejam $s,t$ tuplas.
Definimos
$$
s = t \defiff \proj 0 s = \proj 0 t \mland \proj 1 s = \proj 1 t.
$$
Com a notação que usamos para tuplas, escrevemos o (talvez) mais amigável:
$$
\tup{x,y} = \tup{x',y'}
\defiff
x = x' \mland y = y'.
$$

%%}}}

%%{{{ Do we need bigger tuples? 
\note Precisamos tuplas maiores?.
%%%{{{ meta 
%%%}}}

Introduzimos então esse novo \emph{tipo primitivo} de $2$-tuplas.
E se precisar uma tripla?  Precisamos escolher se vamos aceitar
mais tipos como primitivos ($3$-tuplas (triplas), $4$-tuplas,
(quadruplas), $5$-tuplas (quintuplas), etc., etc.) ou não.
\eop
Caso que sim, vamos precisar uma $n$-tupla para cada $n\in\nats$.
E precisamos definir a igualdade e o intreface para cada um desses tipos,
algo que fazemos facilmente:
$$
\tup{x_1, \dots, x_n}
=
\tup{x'_1, \dots, x'_n}
\defiff
x_1 = x'_1
\mland \cdots \mland
x_n = x'_n
$$
e naturalmente dizemos que uma $n$-tupla $t$ é \emph{determinada
por os objetos em cada uma das suas $n$ posições}.
Então para definir uma $n$-tupla basta só definir as
$$
\projfrom n 0 t,
\projfrom n 1 t,
\dotsc,
\projfrom n {n-1} t.
$$
\eop
E caso contrário?  Será que podemos utilizar apenas as $2$-tuplas
para conseguir o que nossos amigos que trabalham com $n$-tuplas como
tipos primitivos conseguem?
A resposta é sim;
mas vamos primeiro definir uma operação importantíssima entre conjuntos,
o produto!

%%}}}

\endsection
%%}}}

%%{{{ Cartesian_product 
\section Produto cartesiano.
%%%{{{ meta 
\label Cartesian_product
%%%}}}

%%{{{ df: cartesian_product 
\definition.
%%%{{{ meta 
\label cartesian_product
\indexes
    * cross    see: produto
    ;;
\defines
    * ~A \times ~B  -- o produto cartesiano dos $A,B$
    * produto cartesiano
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Definimos o conjunto
$$
A \times B \defeq \setst {\tup{a,b}} {a\in A,\ b\in B}
$$
que chamamos de \dterm{produto cartesiano}
(ou simplesmente \dterm{produto}) dos $A,B$.
Pronunciamos \utter{$A$ cross $B$}.

%%}}}

%%{{{ x: size_of_cartesian_product 
\exercise.
%%%{{{ meta 
\label size_of_cartesian_product
%%%}}}

Justifique a notação $A \times B$, ou seja,
ache uma conexão entre o produto cartesiano e o produto de números.
Suponha que os $A,B$ são finitos.

\solution
Temos $\size {A \times B} = \size A \ntimes \size B$.
Isso \emph{é} o princípio da multiplicação (\reftag[principle_of_multiplication]).

%%}}}

%%{{{ x: times_distributes_over_union_and_inter 
\exercise.
%%%{{{ meta 
\label times_distributes_over_union_and_inter
%%%}}}

Sejam $A,B,C$ conjuntos.
Demonstre que:
$$
\align
A \times (B \union C) &= (A \times B) \union (A\times C)\\
A \times (B \inter C) &= (A \times B) \inter (A\times C).
\endalign
$$

\solution
Vamos demonstrar a
$$
A \times (B \union C) = (A \times B) \union (A\times C).
$$
Mostramos as duas inclusões separadamente:
\crproofpart {\lrdirset:}
Seja $w \in A \times (B\union C)$.
Logo $w = \tup{a,d}$ para algum $a \in A$ e algum $d\in B\union C$ (def.~$\times$).
Logo $d\in B$ ou $d \in C$ (def.~$\union$).
Caso $d \in B$, temos $w = \tup{a,d} \in A \times B$ (def.~$\times$).
Caso $d \in C$, temos $w = \tup{a,d} \in A \times C$ (def.~$\times$).
Nos dois casos concluimos que $w \in (A \times B) \union (A\times C)$ pela definição de $\union$.
\crproofpart {\rldirset:}
Seja $w \in (A \times B) \union (A\times C)$.
Logo $w\in (A\times B)$ ou $w \in (A\times C)$ (def.~$\union$).
Caso $w \in (A \times B)$, temos $w = \tup{a,b}$ para algum $a\in A$ e algum $b\in B$ (def.$\times$).
Logo $b \in B\union C$ (pois $b\in B$) (def.~$\union$).
Logo pela definição de $\times$ temos o desejado $w = \tup{a,b} \in A \times (B\union C)$.
O caso $w \in (A \times C)$ é similar.
\crproofpart {A igualdade}
$$
A \times (B \inter C) = (A \times B) \inter (A\times C)
$$
é demonstrada similarmente.

%%}}}

%%{{{ x: commutativity of AxB doesn't imply A=B 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para todos os conjuntos $A,B$,
$$
A\times B = B \times A \implies A=B.
$$

\hint
Se conseguiu demonstrar, tá errado.
Eu imagino que em algum ponto tu ``sejou'' algum objeto
em algum conjunto que não podia!
Lembra a~\ref[how_do_we_use_nonempty]?

\solution
Como contraexemplo tome $A \asseq \emptyset$ e $B\asseq\nats$
(qualquer $B\neq\emptyset$ serve).
Observe que $A\neq B$, mas mesmo assim
$$
A\times B = B \times A
$$
pois
$$
\emptyset \times \nats = \emptyset = \nats \times \emptyset.
$$

%%}}}

%%{{{ x: when_cartesian_commutes 
\exercise.
%%%{{{ meta 
\label when_cartesian_commutes
%%%}}}

Suponha que $A,B\neq\emptyset$.
Escreva uma demonstração direta (sem usar reductio ad absurdum) do
$A \times B = B\times A \iff A = B$.

\hint
Uma direção é trivial---por quê?

\hint
Como usamos os fatos $A\neq\emptyset$ e $B\neq\emptyset$?

%%}}}

%%{{{ x: when_cartesian_commutes_absurdum 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre usando reductio ad absurdum a direção não-trivial
do~\ref[when_cartesian_commutes].

%}}}

%%{{{ x: calculate_set_extensions 
\exercise.
%%%{{{ meta 
\label calculate_set_extensions
%%%}}}

Calcule as extensões dos conjuntos:
$$
\set{\set{\emptyset}}\cross\pset\emptyset;
\qqqquad
\set{\set{\emptyset}}\symdiff\Union\emptyset
$$

\solution
Calculamos:
$$
\align
\set{\set{\emptyset}}\cross \pset\emptyset &
= \set{\set{\emptyset}}\cross\set{\emptyset}
= \set{(\set{\emptyset},\emptyset)} \\
\set{\set{\emptyset}}\symdiff\Union\emptyset &
= \set{\set{\emptyset}}\symdiff\emptyset
= \set{\set{\emptyset}}
\endalign
$$

%%}}}

%%{{{ remark: let_pair_in_product 
\remark.
%%%{{{ meta 
\label let_pair_in_product
%%%}}}

Sabemos que para ``sejar'' algum membro dum conjunto $A$ (sabendo claramente que $A$ não é vazio)
escrevemos algo do tipo
\quote
Seja $x \in A$.
\endquote
onde precisamos tomar cuidado escolhendo um \emph{nome fresco de variável} para denotar esse objeto.
Como $A \times B$ também é um conjunto, e também supondo que não é vazio, obviamente faz sentido escrever
\quote
Seja $x \in A\times B$.
\endquote
A partir disso, pela definição do $A\times B$, que tipo de objeto é esse $x$?
Uma tupla cujo primeiro componente pertence a $A$, e o segundo ao $B$;
pois todos os membros de $A\times B$ são tais tuplas.
E o que podemos fazer com esse $x$ então?
Bem, é uma 2-tupla, e logo podemos projectar: $\proj 0 x$ e $\proj 1 x$ são objetos já definidos que podemos usar.
O que mais podemos fazer?
Lembrando a notação de set builder que permite termos (\reftag[full_setbuilder]),
percebemos que a \ref[cartesian_product] do próprio
$A \times B$ usou tal set builder:
$$
A \times B \defeq \setst {\tup{a,b}} {a\in A,\ b\in B}.
$$
A partir da definição dessa notação (\ref[rich_set_builder_sugar]) temos
$$
x \in A \times B \intiff \pexists {a \in A} \lexists {b \in B} {x = \tup{a,b}}.
$$
Para voltar na nossa pergunta de \wq{o que podemos fazer com esse $x$} então:
\quote
Seja $x \in A\times B$.\CR
Logo sejam $a\in A$ e $b \in B$ tais que $x = \tup{a,b}$.
\endquote
Tudo bem até agora.
Mas essa declaração do $x$ parece inútil.
Pra que poluir nosso escopo com esse objeto
se a único coisa que planejamos fazer com ele
é extrair seus componentes para usá-los?
Não seria melhor escrever
\quote
Seja $\tup{a,b} \in A\times B$.
\endquote
assim ganhando diretamente os $a,b$ sem o bobo $x$?
Seria, mas\dots
já aprendemos que declaramos apenas variáveis (\ref[only_declare_variables]), né?
\eop
Mas já que $\tup{\dhole,\dhole}$ é um \emph{construtor} de tuplas
podemos considerar a linha
\quote
Seja $\tup{a,b} \in A\times B$.
\endquote
Como abreviação das linhas
\quote
Seja $a \in A$.
Seja $b \in B$.
\endquote
E sobre o $\tup{a,b}$?  Como que vamos introduzí-lo para usá-lo?
Nem precisamos nem podemos!
Como já temos agora os objetos $a,b$, querendo ou não a tupla $\tup{a,b}$
já é definida e podemos usá la.
Isso vai ficar ainda mais claro daqui a pouco
(no~\ref[picking_elements_from_indexed_sets])
onde discutimos o que significa
\emph{tomar um arbitrário membro dum conjunto indexado}.

%%}}}

\endsection
%%}}}

%%{{{ Type_implementation_triples 
\section Implementação de tipo: triplas.
%%%{{{ meta 
\label Type_implementation_triples
%%%}}}

%%{{{ intro 
\secintro
Nessa secção temos nosso primeiro contato com a idéia
fundamental---literalmente---de \emph{implementação}.
Nosso objetivo aqui é só isso: brincar um pouco para entender o conceito.
Bem depois, no~\ref[Set_theory] vamos mergulhar mais profundamente.
%%}}}

%{{{ friend_with_triples 
\note Um amigo com triplas.
%%%{{{ meta 
\label friend_with_triples
%%%}}}

Tudo ótimo até agora neste capítulo (né?):
Introduzimos dois \emph{tipos primitivos:} conjuntos e tuplas
junto com operações neles, e tudo mais.
chega nosso amigo da outra turma que mostra para nos um tipo primitivo deles,
a tripla:
\quote
<<Cara, triplas têm $3$ projecções em vez de $2$, que denotamos por
$$
\projfrom 3 0, \quad
\projfrom 3 1, \quad
\projfrom 3 2.
$$
A própria tupla $t$ com
$$
\projfrom 3 0 \app t = x, \quad
\projfrom 3 1 \app t = y, \quad
\projfrom 3 2 \app t = z
$$
denotamos por $\tup{x,y,z}$,
e definimos igualdade pela
$$
\tup{x,y,z} = \tup{x',y',z'}
\defiff
x=x'
\mland
y=y'
\mland
z=z'
$$
e as equações fundamentais são as óbvias.
Lembra da conversa no começo da~\ref[Tuples]?
Com triplas consigo saber quem ganhou o bronze também!>>
\endquote

%%}}}

%%{{{ triple_interface 
\note Interface.
%%%{{{ meta 
\label triple_interface
%%%}}}

O interface duma tripla, consiste em $3$ projecções:
$\projfrom 3 0$, $\projfrom 3 1$, $\projfrom 3 2$.

%%}}}

%%{{{ x: fundamental_equations_triple 
\exercise.
%%%{{{ meta 
\label fundamental_equations_triple
%%%}}}

Quais são essas <<óbvias>> equações fundamentais do amigo
do~\ref[friend_with_triples]?

\hint
Inspire-se a roubar o~\ref[tuple_fundamental_equations].

\solution
As projecções e o construtor $\tup{\dhole,\dhole,\dhole}$
devem satisfazer:
$$
\xalignat3
\projfrom3 0 \tup{x,y,z} &= x &
\projfrom3 1 \tup{x,y,z} &= y &
\projfrom3 2 \tup{x,y,z} &= z;
\endxalignat
$$
$$
t = \tup{ \projfrom 3 0 t , \projfrom 3 1 t , \projfrom 3 2 t }.
$$

%%}}}

%%{{{ implementation_of_primitive_type 
\note Implementação de tipo primitivo.
%%%{{{ meta 
\label implementation_of_primitive_type
\indexes
    * tipo!primitivo
    ;;
%%%}}}

Nosso amigo nos apresentou esse tipo primitivo dele:
descreveu seu interface, introduziu sua notação, definiu igualdade,
e pronto.  Podemos copiar essa idéia e fazer a mesma coisa.
Em vez disso, vamos tentar algo diferente:
\dterm{implementar} o tipo de triplas!
O que significa mesmo ``implementar''?
Vamos tratar tudo que ele falou como uma \dterm{especificação}
dum tipo desejado, que nos vamos \emph{definir} em termos de outros
tipos já conhecidos.
Cuidado: nossa implementação deve \dterm{atender a especificação}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então \emph{implementamos}---ou seja, definimos mesmo---as triplas assim:

%%}}}

%%{{{ imp: triple_implementation 
\implementation Tripla.
%%%{{{ meta 
\label triple_implementation
%%%}}}

Sejam $x,y,z$ objetos.
Definimos a tripla
$$
\tup{x,y,z} \defeq \tup {x, \tup{y,z}}.
$$
Ou seja, a tripla dos objetos $x,y,z$ nessa ordem
é a tupla cujo primeiro componente é o $x$
e cujo segundo componente é a tupla $\tup{y,z}$.
Definimos igualdade entre triplas pela
$$
\tup{x,y,z} = \tup{x',y',z'}
\defiff x = x' \mland y = y' \mland z = z'.
$$
\mistake

%%}}}

%%{{{ Q: We just cheated!  How?
\question.
%%%{{{ meta 
%%%}}}

Acabamos de roubar.  Como?

%%}}}

\spoiler

%%{{{ beware: thou_shalt_not_redefine 
\beware Não redefinirás.
%%%{{{ meta 
\label thou_shalt_not_redefine
%%%}}}

A partir do momento que \emph{definimos} triplas
(pra ser certas 2-tuplas) não temos o direito de
\emph{redefinir} igualdade entre triplas, pois,
simplesmente, agora triplas \emph{são} 2-tuplas,
e a igualdade entre 2-tuplas já foi definida,
e logo a igualdade
$$
\tup{x,y,z} = \tup{x',y',z'}
$$
já tem significado: os objetos nos seus dois
lados são 2-tuplas, e logo a igualdade acima
\emph{realmente é} a seguinte:
$$
\tup{x,y,z} = \tup{x',y',z'}
\means
\tup{x,\tup{y,z}} = \tup{x',\tup{y',z'}}.
$$

%%}}}

%%{{{ implementator_duties 
\note Deveres do implementador.
%%%{{{ meta 
\label implementor_duties
%%%}}}

O que \emph{devemos} fazer para implementar mesmo um tipo
dada uma especificação?
Devemos demonstrar que nossa implementação atende a especificação.
E note que nossa implementação não é completa ainda, pois
precisamos \emph{definir} o interface também.
Para nosso amigo as operações $\projfrom30, \projfrom31, \projfrom32$
são \emph{primitivas}.  Ele não as definiu, pelo contrario:
determinado seus comportamentos, ele determina uma tripla.
Mas aqui queremos implementar as triplas, então devemos definir
essas projecções!
Bora terminar esses deveres agora.

%%}}}

%%{{{ x: implement_triple_interface 
\exercise.
%%%{{{ meta 
\label implement_triple_interface
%%%}}}

Complete a implementação de triplas: defina as três projecções.

\hint
Já que definimos triplas em termos de duplas,
para definir o interface de triplas vamos precisar
usar o interface de duplas, ou seja, as projecções
$\proj0,\proj1$.

\hint
Seja $t$ tripla.  Definimos
$$
\xalignat3
\projfrom30 t &= \askdots &
\projfrom31 t &= \askdots &
\projfrom32 t &= \askdots
\endxalignat
$$

\solution
Seja $t$ tripla.
Definimos
$$
\xalignat3
\projfrom30 t &= \proj0 t &
\projfrom31 t &= \proj0 \paren{\proj1 t} &
\projfrom32 t &= \proj1 \paren{\proj1 t}.
\endxalignat
$$

%%}}}

%%{{{ x: tuples_of_size_2_are_good_for_3 
\exercise.
%%%{{{ meta 
\label tuples_of_size_3_are_good_for_3
%%%}}}

Mostre que com a definição de
$$
\tup{x,y,z} \defeq \tup{x,\tup{y,z}}
$$
conseguimos a igualdade \emph{desejada}
$$
\tup{x,y,z} = \tup{x',y',z'}
\iff x = x' \mland y = y' \mland z = z'.
$$
Mais uma vez, cuidado: é um \symq{$\iffsymbol$} acima,
não um \symq{$\defiffsymbol$}!
Ou seja, definindo as $3$-tuplas nessa maneira, querendo
ou não, a igualdade entre seus objetos já é definida!
Não temos o direito de redefini-la!

\solution
Calculamos
\compute
\tup{x,y,z} = \tup{x',y',z'}
&\sugariff \tup{x,{y,z}} = \tup{x',\tup{y',z'}} \\
&\iff x = x' \mland \tup{y,z} = \tup{y',z'}     \by {def.~de~$(=)$~para $2$-tuplas} \\
&\iff x = x' \mland y = y' \mland z = z'.       \by {def.~de~$(=)$~para $2$-tuplas} \\
\endcompute
que é exatamente o que desejamos mostrar!

%%}}}

%%{{{ cartesian_product_ternary 
\note Produto ternário.
%%%{{{ meta 
\label cartesian_product_ternary
\indexes
    * produto cartesiano!tripla
    ;;
%%%}}}

Uma das mais interessantes coisas que fizemos assim começamos trabalhar
com as duplas foi definir o produto cartesiano duma dupla de conjuntos!
Agora que definimos as triplas, naturalmente queremos considerar o produto
cartesiano duma tripla de conjuntos.
Parece então que temos uma operação ternaria,
que para quaisquer conjuntos $A,B,C$
$$
A \times B \times C \defeq \setst {\tup{a,b,c}} {a \in A,\ b\in B,\ c\in C}.
$$

%%}}}

%%{{{ beware: implementation_agnostic 
\beware Implementação agnóstico.
%%%{{{ meta 
\label implementation_agnostic
\indexes
    * implementação!agnóstico    see: agnóstico
    * implementação
    ;;
\defines
    * agnóstico!implementação
    ;;
%%%}}}

\emph{Definimos} o que significa $\tup{x,y,z}$,
e \emph{definimos} as projecções $\projfrom30,\projfrom31,\projfrom32$.
Dada uma tripla $\tup{x,y,z}$, podemos chamar a $\proj1$ nela?
Intuitivamente, alguém pensaria que não, pois parece ter um ``type error''
essa aplicação: a projecção $\proj1$ funciona com $2$-tuplas,
e $\tup{x,y,z}$ é uma tripla, então só podemos chamar as
$\projfrom30,\projfrom31,\projfrom32$ nela.
Certo?
Errado!
Podemos sim, pois, pela nossa definição,
a tripla $\tup{x,y,z}$ \emph{é} a dupla $\tup{x,\tup{y,z}}$.
Ou seja, temos:
\compute
\proj1 \tup{x,y,z}
&\inteq \proj1 \tup{x,\tup{y,z}}    \by {def.~$\tup{x,y,z}$} \\
&= \tup{y,z}                        \by {def.~$\tup{x,\tup{y,z}}$} \\
\endcompute
O fato que \emph{podemos} não significa que \emph{devemos}.
O que estamos fazendo nesse caso é \emph{usar os detalhes da implementação
em vez do seu interface}.
Tudo que vamos construir a partir desse abuso vale apenas para \emph{nossa}
implementação.  Nosso amigo que usa triplas como tipo primitivo não pode
aproveitar dos nossos cálculos e das nossas teorias.  Nem alguém que escolheu
implementar triplas em outra maneira.  A moral da estória é o seguinte:
precisamos ficar \dterm{implementação agnósticos}, ou seja,
esquecer os detalhes da nossa implementação, usando apenas o interface
dos nossos objetos.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Não faz sentido nenhum se limitar em 2-tuplas e 3-tuplas.
Partiu $n$-tuplas para qualquer $n\in\nats$!

%%}}}

\endsection
%%}}}

%%{{{ More_tuples 
\section n-tuplas.
%%%{{{ meta 
\label More_tuples
%%%}}}

%%{{{ n_tuples_interface_notation 
\note Interface e notação.
%%%{{{ meta 
\label n_tuples_interface_notation
%%%}}}

Nossa única interface dada uma tupla de tamanho $n$, é que podemos
pedir seu $i$-ésimo elemento, onde $0 \leq i < n$.
Conversamente, para definir uma tupla de tamanho $n$, basta
determinar todos os objetos (distintos ou não) nas suas $n$ posições.
Usamos as notações $\tupa{a_0, a_1, \dotsc, a_{n-1}}$
e~$\tupp{a_0, a_1, \dotsc, a_{n-1}}$ para tuplas de tamanho~$n$.
Às vezes é mais legível usar índices começando com $1$---tanto faz.
Quando queremos enfatizar o tamanho da tupla, falamos de
\dterm{$n$-tupla}.
Em geral, para tuplas de tamanho $n$, usamos a notação
$\projfrom n i$ para a $i$-ésima projecção.
Por exemplo:
$$
\xalignat4
\projfrom 2 1 \tup{x,y}                 &= y ; &
\projfrom 3 1 \tup{x_1,x_2,x_3}         &= x_2 ; &
\projfrom 5 4 \tup{x_2,x_3,y_1,x_8,y_0} &= y_0 ; &
\text{etc.}                             &
\endxalignat
$$
Quando o $n$ é implícito pelo contexto, não se preocupamos
com ele.  Obviamente então $\proj 1$ da \symq{$\proj 1 \tup{x,y,z}$}
denota a $\projfrom 3 1$ mesmo, mas a $\proj 1 $ da \symq{$\proj 1 \tup{x,y}$}
denota a $\projfrom 2 1$.
Até agora temos chamado de ``tupla'' o par ordenado.
Na verdade, um par ordenado é uma $2$-tupla.
\eop
Às vezes escolhemos como nome duma tupla uma variável
decorada com uma setinha em cima dela, e usando a mesma
letra com índices para seus membros, por exemplo
$\vec x = \tup{x_0,x_1,\dotsc,x_n}$, $\vec w = \tup{w_1,w_2}$, etc.
Outra convençao comum é usar uma fonte em ``negrito'', por exemplo
$\mathbf{a} = \tup{a_1,a_2,a_3}$, $\mathbf{u} = \tup{u_0,u_1}$, etc.

%%}}}

%%{{{ pseudodf: set_exp 
\pseudodefinition.
%%%{{{ meta 
%%%}}}

Sejam $A$ conjunto e $n\in\nats$ com $n\geq 2$.
$$
A^n \pseudodefeq \setstt {\tup{a_1,\dotsc,a_n}} {$a_i \in A$ para todo $1\leq i\leq n$}.
$$

%%}}}

%%{{{ messy quantifier 
\note.
%%%{{{ meta 
%%%}}}

Na definição acima aparece a frase \wq{para todo $1\leq i\leq n$}.
Qual é a variável ligada com esse \wq{para todo}?
Bem, $1$ é um constante, e $n$ já foi declarado, então entendemos que a
frase corresponde na quantificação:
$$
\lforall {i\in\nats} {1\leq i \leq n \implies a_i \in A}.
$$

%%}}}

%%{{{ df: set_exp_first_recursive_definition 
\definition.
%%%{{{ meta 
\label set_exp_first_recursive_definition
%%%}}}

Seja $A$ conjunto.
Para $n\in\nats$ com $n\geq 1$ definimos as \dterm{potências} de $A$ recursivamente pelas:
$$
\align
A^1 &= A\\
A^n &= A^{n-1} \times A \qquad \text{(para $n \geq 2$)}.
\endalign
$$

%%}}}

%%{{{ Comparison with numbers (I) 
\note Comparação com números (I).
%%%{{{ meta 
%%%}}}

A semelhança entre a definição de potências de conjuntos e de números é gritante.
Vamos investigar.
Na~\ref[set_exp_first_recursive_definition] das duas equações recursivas
$$
\xalignat3
A^n &= A^{n-1} \times A &
A^n &= A \times A^{n-1}.
\intertext{escolhemos a primeira.  Por quê?
Observe que no caso de números, para a equação recursiva, as duas opções óbvias}
a^n &= a^{n-1} \ntimes a &
a^n &= a \ntimes a^{n-1} 
\intertext{servem e são equivalentes.
Uma explicação disso usa apenas o fato que a multiplicação de números é comutativa,
então imediatamente temos $a^{n-1} \ntimes a = a \ntimes a^{n-1}$.
Infelizmente não podemos contar nessa propriedade no caso de conjuntos,
pois já sabemos que a $\times$ não é comutativa~(\ref[when_cartesian_commutes]).
Mas as duas equações correspondem nas expressões}
a^n &= \paren{\paren{\paren{\paren{\dotsb\paren{a\ntimes a}\ntimes a}\ntimes a} \dotsb} \ntimes a} &
a^n &= \paren{a\ntimes \paren{\dotsb\paren{a\ntimes\paren{a\ntimes\paren{a \ntimes a}\dotsb}}}} &
\endxalignat
$$
que são iguais agora por causa da \emph{associatividade} da operação $(\ntimes)$.

%%}}}

%%{{{ Q: is times associative? 
\question.
%%%{{{ meta 
%%%}}}

O produto cartesiano é associativo?

%%}}}

\spoiler

%%{{{ A: answer with another question 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Respondemos nessa pergunta com outra:
\emph{as tuplas}
$$
\tup{a_0, \tup{a_1, a_2}}
\qquad
\tup{\tup{a_0, a_1}, a_2}
\qquad
\tup{a_0, a_1, a_2}
$$
\emph{são iguais?}
Não, pois já temos uma maneira de observar comportamento
diferente usando o interface dessas 2-tuplas.
Mas também depende:
podemos considerá-las \emph{como se fossem iguais}, pois
qualquer uma delas serve para satisfazer a especificação de tuplas:
podemos definir as $i$-ésimas projecções para cada uma,
e a especificação vai acabar sendo atendida usando uma delas
sse é atendida usando qualquer uma das outras.
Pense na idéia sobre a \emph{informação} que uma tupla carrega com ela.
Agora tente ler as três tuplas acima:
$$
\gather
\text{<<Primeiro o objeto $a_0$, e depois temos: primeiro o $a_1$ e depois o $a_2$.>>}\\
\text{<<Primeiro temos: primeiro o objeto $a_0$ e depois o $a_1$; e depois temos o $a_2$.>>}\\
\text{<<Primeiro temos o objeto $a_0$ e depois o $a_1$ e depois o $a_2$.>>}
\endgather
$$
Mas esse ponto de visto é confundindo implementação com interface.
Como enfatisei no~\ref[implementation_agnostic], quando queremos referir
a uma tripla de objetos, usamos a notação $\tup{a_0, a_1, a_2}$,
e não alguma que corresponde na nossa implementação peculiar.
Assim, se escrever $\tup{a_0, \tup{a_1,a_2}}$ deve ser porque tu tá
considerando a 2-tupla mesmo, cujo primeiro componente é o $a_0$
e cujo segundo o $\tup{a_1,a_2}$.
Para resumir: depende do contexto, e do objetivo de cada conversa.

%%}}}

%%{{{ Comparison with numbers (II) 
\note Comparação com números (II).
%%%{{{ meta 
%%%}}}

Uma diferença entre as definições de potências de números e de conjuntos
é que no caso de conjuntos definimos o $A^n$ para todo $n \geq 1$,
mas no caso de números naturais conseguimos uma definição mais geral,
definindo o $a^n$ para todo $n \geq 0$.
Nossa base da recursão então foi $a^0 = 1$.
Por que $1$?

%%}}}

%%{{{ Unit 
\note Unit.
%%%{{{ meta 
%%%}}}

Se é para generalizar bem a definição de potências de números para o caso de
conjuntos, procuramos nosso $1$, ou seja, uma \dterm{unidade}
(também \dterm{identidade}, ou \dterm{elemento neutro})
da nossa ``multiplicação'', $\times$.
Essa unidade é chamada \dterm{unit}, e muito usada em linguagens de programação.
Vamos usar o $\tup{}$ para denotá-la.
Isso é um abuso notacional, pois $\tup{}$ também denota a tupla vazia,
que é o único membro da unit;
mas o contexto é em geral suficiente para tirar a ambigüidade.
Caso contrário, use $\set{\tup{}}$, ou introduza alguma outra notação,
por exemplo $I$.

%%}}}

%%{{{ df: equality_of_n_tuples 
\definition igualdade.
%%%{{{ meta 
\label equality_of_n_tuples
%%%}}}

Seja $n\in\nats$ e sejam $s,t$ $n$-tuplas.
Definimos
$$
\align
s = t
&\defiff \lforall {1 \leq i \leq n} {\projfrom n i s = \projfrom n i t},
\intertext{ou, usando a notação $\tup{\dhole,\dotsc,\dhole}$, temos:}
\tup{s_1,\dotsc,s_n} = \tup{t_1,\dotsc,t_n}
&\defiff \text{para todo $i\in\set{1,\dotsc,n}$, $s_i=t_i$.}
\endalign
$$

%%}}}

%%{{{ Q: How would you define $n$-tuples for n > 2, given 2-tuples? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias os tipos de $n$-tuplas para $n>2$, dado um tipo
de $2$-tuplas?

%%}}}

\spoiler

%%{{{ pseudodf: n_tuples_based_on_2_tuples 
\pseudodefinition.
%%%{{{ meta 
\label n_tuples_based_on_2_tuples
%%%}}}

Seja $n\in\nats$ com $n > 2$.
Dados $n$ objetos $x_1,x_2,\dotsc,x_n$ definimos a $n$-tupla
$$
\tup{x_1, x_2, \dotsc, x_n}
\defeq
\tup{x_1, \tup{x_2, \dotsc, x_n}}.
$$

%%}}}

%%{{{ Tuples of extreme sizes 
\note Tuplas de tamanhos extremos.
%%%{{{ meta 
%%%}}}

O que seria uma $1$-tupla?
E, pior ainda, o que seria uma $0$-tupla?
E uma tupla infinita?
Vamos responder apenas na primeira pergunta agora.
Os outros dois casos vamos discutir logo depois:
sobre a(s?)\ $0$-tupla(s?) aqui mesmo;
e sobre tuplas infinitas nas \reftag[Sequences] e
\reftag[Indexed_families] onde conhecemos \emph{seqüências}
e \emph{famílias indexadas} respectivamente.

%%}}}

%%{{{ df: tuples_of_size_1 
\definition Tuplas de tamanho 1.
%%%{{{ meta 
\label tuples_of_size_1
%%%}}}

Observe que escolhendo definir a $1$-tupla como
$$
\tup{x} \defeq x
$$
atendemos nossas exigências:
$$
\tup{x} = \tup{y} \iff
x = y
$$
que é exatamente a igualdade desejada.
Ou seja, para nossos objectivos podemos \emph{identificar os objetos}
$\tup{x}$ e $x$.
A partir disso, faz sentido considerar que o produto cartesiano
dum conjunto só é o próprio conjunto, e logo ter $A^1 = A$

%%}}}

%%{{{ Q: what about 0-tuples? 
\question.
%%%{{{ meta 
%%%}}}

E sobre 0-tuplas?  Faz sentido considerar esse tipo?
Teria ``habitantes'', ou seja, objetos desse tipo?
Se sim, quantos, e quais são?  Se não, por que não?

%%}}}

\spoiler

%%{{{ zero_tuple 
\note A 0-tupla.
%%%{{{ meta 
\label zero_tuple
\defines
    * tupla!zero
    ;;
%%%}}}

Seguindo nossa intuição com as tuplas dos outros tamanhos,
o que seria uma $0$-tupla?
Bem, para determinar um objeto $\vec t$ desse tipo, precisamos
definir suas\dots $0$ projecções.
Vamos fazer isso aqui:
$$
~
$$
Pronto.
Acabei de definir as\dots $0$ coisas que precisava definir.
Logo existe uma única $0$-tupla, que denotamos por $\tup{}$ mesmo.
E qual seria o produto cartesiano $0$-ário, duma---na verdade,
da única---$0$-tupla de conjuntos?

%%}}}

%%{{{ cartesian_product_nullary 
\note O produto cartesiano 0-ário.
%%%{{{ meta 
\label cartesian_product_nullary
%%%}}}

Dados\dots $0$ conjuntos, seu produto cartesiano deve ser
o conjunto de todas as $0$-tuplas cujo $i$-ésimo componente
pertence ao $i$-ésimo dos $0$ conjuntos.
Mas só tem uma $0$-tupla e ela satisfaz essa condição, então
o produto cartesiano de 0 conjuntos, é o singleton $\set{\tup{}}$.
Logo devemos definir
$$
A^0 \defeq \set{\tup{}}
$$
e consideramos o $\set{\tup{}}$ como identidade (elemento neutro)
da $\times$, identidicando, por exemplo, as tuplas
$$
\tup{\tup{}, \tup{x,y}} \qqqtext{e} \tup{x,y}
$$
nesse contexto.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E agora, prontos para tamanho infinito: seqüências.

%%}}}

\endsection
%%}}}

%%{{{ Sequences 
\section Seqüências.
%%%{{{ meta 
\label Sequences
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A generalização de tuplas para seqüências é bem simples.
Uma $n$-tupla $\tup{a_0,\dotsc,a_{n-1}}$ tem um componente para cada uma das
$n$ posições $i = 0, \dotsc, n-1$, e nada mais.

%%}}}

%%{{{ prim: sequence 
\primitive seqüência.
%%%{{{ meta 
\label sequence
\defines
    * \sequence {~{a_n}} n  -- a seqüência $a_0,a_1,a_2,\dotsc$
    * seqüência
    ;;
%%%}}}

Uma \dterm{seqüência} tem um componente para cada natural $i \in \nats$.
Usamos a notação $\seqn a n$ para denotar a seqüência cujos primeiros termos são
$$
a_0, a_1, a_2, a_3, \dotsc
$$
O interface de seqüências então é uma infinidade de perguntas-projecções,
uma para cada natural, que costumamos denotar apenas por índices subscritos mesmo,
como fizemos em cima.

%%}}}

%%{{{ remark: variable_binder_in_sequences 
\remark Ligador de variável.
%%%{{{ meta 
\label variable_binder_in_sequences
%%%}}}

Na notação $\sequence {a_n} {\alert n}$ o $\alert n$
é um \emph{ligador} da variável $n$.

%%}}}

%%{{{ remark: seq = infinite; finite seq = tuple 
\remark.
%%%{{{ meta 
%%%}}}

O que chamamos de seqüência é também conhecido como \dterm{seqüência infinita}.
Uma \dterm{seqüência finita} é apenas uma $n$-tupla, para algum $n\in\nats$.

%%}}}

%%{{{ warning: notational abuse 
\warning abuso notacional.
%%%{{{ meta 
%%%}}}

Quando escrevemos uma seqüência $\seqn a n$ onde pelo contexto
esperamos ver um conjunto, a entendemos como uma denotação do
conjunto $\setst {a_n} {n \in \nats}$.
Por exemplo, escrevemos
$$
\seqn a n \subset A \abuseiff \setst {a_n} {n \in \nats} \subset A,
\qquad
\frac 1 2 \in \seqn a n \abuseiff \frac 1 2 \in \setst {a_n} {n \in \nats},
$$
etc.

%%}}}

%%{{{ beware: ambiguous notations for sequences 
\beware.
%%%{{{ meta 
%%%}}}

Em certos textos aparece a notação $a_n$ ou $\set{a_n}$ para denotar
uma inteira seqüência.
Aqui não vamos usar nenhuma dessas, pois introduzem ambigüidades
possivelmente perigosas:
\tlist:
\li: Se encontrar a expressão \symq{$a_n$}, é a seqüência inteira ou apenas o $n$-ésimo membro dela?
\li: Se encontrar a expressão \symq{$\set{a_n}$}, ele denota a seqüência inteira,
o singleton cujo único membro é a seqüência inteira, ou o singleton cujo único
membro é o $n$-ésimo membro da seqüência?
\endtlist

%%}}}

%%{{{ Q: how_would_you_define_equality_of_sequence 
\question.
%%%{{{ meta 
\label how_would_you_define_equality_of_sequence
%%%}}}

Como definarias igualdade para seqüências?

%%}}}

\spoiler

%%{{{ df: sequences_equality 
\definition Igualdade.
%%%{{{ meta 
\label sequences_equality
%%%}}}

Sejam
$\seqn a n$,
$\seqn b n$
seqüências.
Definimos sua igualdade por
$$
\seqn a n = \seqn b n
\defiff \lforall {n\in\nats} {a_n = b_n}.
$$

%%}}}

%%{{{ Limits of sequences 
\note Seqüências e limites.
%%%{{{ meta 
%%%}}}

No coração de calculus é o estudo de seqüências
de números reais.  No~\ref[The_reals] definimos a noção de \dterm{limite}
de uma seqüência de reais $\seqn a n$, e no~\ref[Metric_spaces]
estendemos essa idéia num contexto mais geral e abstrato, onde
os membros da seqüência não são necessariamente números reais,
mas membros de um \emph{espaço métrico}.
Nada mais por enquanto---paciência!

%%}}}

%%{{{ Sequences of sets 
\note Seqüências de conjuntos.
%%%{{{ meta 
%%%}}}

Mais interessantes para a gente neste momento são \emph{seqüências de conjuntos}.

%%}}}

%%{{{ Q: how_would_you_define_Union_of_sequence 
\question.
%%%{{{ meta 
\label how_would_you_define_Union_of_sequence
%%%}}}

Imagina que temos definido, para cada $n\in\nats$, um conjunto $A_n$.
Como tu definirias os conjuntos
$\Union_{n=0}^{\infty} A_n$
e 
$\Inter_{n=0}^{\infty} A_n$
?

%%}}}

\spoiler

%%{{{ df: Union_Inter_of_sequence 
\definition.
%%%{{{ meta 
\label Union_Inter_of_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os operadores unários
$\Union_{n=0}^{\infty}$ e
$\Inter_{n=0}^{\infty}$ pelas:
$$
\align
x \in \Union_{n=0}^{\infty} A_n &\defiff \lexists {n \in \nats} {x \in A_n} \\
x \in \Inter_{n=0}^{\infty} A_n &\defiff \lforall {n \in \nats} {x \in A_n}.
\endalign
$$
Às vezes usamos as notações mais curtas: $\Union_n A_n$ e $\Inter_n A_n$
respectivamente, mas cuidado:
$\Union A_n$ é a união (grande) do conjunto $A_n$,
que é o $n$-ésimo membro da seqüência de conjuntos $\seqn A n$.
Por outro lado, $\Union_n A_n$ é a união da seqüência,
ou seja o $\Union_{n=0}^{\infty}A_n$.
Mesmo cuidado sobre intersecções.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_1 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_1
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo $n\in\nats$, $A_n \subset B_{n+1}$.}
$$
Demonstre que:
$$
\Union_{n=0}^\infty A_n \subset \Union_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Union_{n=0}^\infty A_n$\fact1.
Preciso mostrar que $x \in \Union_{n=0}^{\infty} B_n$,
ou seja, mostrar que $x$ pertence a pelo menos um dos $B_n$'s.
(Ou seja, procuro um $k\in \nats$ tal que $x \in B_k$.)
Seja $m\in \nats$ tal que $x \in A_m$
(tal $m$ existe pela \byfact1).
Agora pela hipótese (com $n \asseq m$) $A_m \subset B_{m+1}$,
e logo $x \in B_{m+1}$, algo que mostra que
$x \in \Union_{n=0}^{\infty} B_n$, pois $m+1\in\nats$.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_2 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_2
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número par $m$, $A_m \subset B_{m/2}$.}
$$
Demonstre que:
$$
\Inter_{n=0}^\infty A_n \subset \Inter_{n=0}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.
Preciso mostrar que $x \in \Inter_{n=0}^{\infty} B_n$,
ou seja, demonstrar que $x\in B_k$ para todo $k\in\nats$.
Seja $k \in \nats$.
Como $x \in \Inter_{n=0}^{\infty}A_n$, temos $x \in A_{2k}$.
Mas $A_{2k} \subset B_k$, logo $x \in B_k$.

%%}}}

%%{{{ x: sequence_of_sets_inclusions_tricky_indices_3 
\exercise.
%%%{{{ meta 
\label sequence_of_sets_inclusions_tricky_indices_3
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos tais que
$$
\text{para todo número primo $p$, $A_p \subset B_{2p}$.}
$$
Demonstre ou refute:
$$
\Inter_{n=0}^\infty A_n \subset \Union_{n=28}^{\infty} B_n.
$$

\solution
Suponha $x \in \Inter_{n=0}^\infty A_n$.\fact1
Preciso mostrar que $x \in \Union_{n=28}^{\infty} B_n$,
ou seja, achar um inteiro $m\geq 28$ tal que $x\in B_m$.
Pela {\byfact1} temos $x\in A_{17}$; e como $17$ é primo,
$A_{17}\subset B_{34}$ (pela hipótese).
Logo $x \in B_{34}$.
Então realmente $x \in \Union_{n=28}^{\infty} B_n$.

%%}}}

%%{{{ x: Union_Inter_of_sequences_as_sugar 
\exercise.
%%%{{{ meta 
\label Union_Inter_of_sequences_as_sugar
%%%}}}

Na~\ref[Union_Inter_of_sequence] definimos \emph{elementariamente}
as operações $\Union_{n=0}^{\infty}$ e $\Inter_{n=0}^{\infty}$.
Defina-las usando as operações de $\Union$ e $\Inter$.

\solution
Seja $A_n$ uma seqüência de conjuntos.
Defina
$$
\xalignat2
\Union_{n=0}^{\infty} &\defeq \Union\setst {A_n} {n\in\nats} &
\Inter_{n=0}^{\infty} &\defeq \Inter\setst {A_n} {n\in\nats}.
\endxalignat
$$

%%}}}

%%{{{ prop: set_de_morgan_gen 
\proposition.
%%%{{{ meta 
\label set_de_morgan_gen
\indexes
    * dualidade
    ;;
%%%}}}

Para todo conjunto $C$ e cada seqüência de conjuntos $\seqn A n$,
$$
\align
C \setminus {\Union_{n=0}^\infty A_n} &= \Inter_{n=0}^{\infty} \paren{C \setminus A_n}\\
C \setminus {\Inter_{n=0}^\infty A_n} &= \Union_{n=0}^{\infty} \paren{C \setminus A_n}.
\endalign
$$

\proof.
Sejam $C$ conjunto e $\seqn A n$ seqüência de conjuntos.
\eop
Mostramos as duas inclusões da primeira igualdade separadamente:
\crproofpart {\lrdirset}:
Seja $x \in C \setminus \Union_n A_n$, ou seja,
$x \in C$\fact1 e $x\nin \Union_n A_n$\fact2.
Vamos demonstrar que $x \in \Inter_n \paren{C \setminus A_n}$,
ou seja, que para todo $u\in \nats$, $x \in C \setminus A_u$.
Seja $u\in\nats$.
Basta demonstrar então duas coisas: $x \in C$ e $x \nin A_u$.
A primeira já temos (é a~\byfact1).
A segunda é direta conseqüêcia da~\byfact2:
$x$ não pertence a nenhum dos $A$'s, então nem ao $A_u$.
\crproofpart {\rldirset}: Deixo pra ti (\ref[set_de_morgan_gen_exercise_1rl]).
\eop
Temos mais uma igualdade para demonstrar, novamente em duas partes:
\crproofpart {\lrdirset}:
Seja $x \in C \setminus {\Inter_n A_n}$,
ou seja $x \in C$\fact1 e $x \nin {\Inter_n A_n}$\fact2.
Vamos demonstrar que $x \in \Union_n \paren{C \setminus A_n}$,
ou seja procuramos $w$ tal que $x \in C \setminus A_w$,
ou seja, tal que $x \in C$ e $x \nin A_w$.
Observe que nosso primeiro alvo não tem nada a ver com $w$,
e na verdade já temos: é o~\byfact1.
Agora usando a~\byfact2 achamos o desejado natural:
seja $w\in\nats$ tal que $x \nin A_w$.
\crproofpart {\rldirset}: Deixo pra ti também (\ref[set_de_morgan_gen_exercise_2rl]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora terminar a demonstração da~\ref[set_de_morgan_gen]:

%%}}}

%%{{{ x: set_de_morgan_gen_exercise_1rl 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_exercise_1rl
%%%}}}

Demonstre a primeira {\rldirset} que deixamos na demonstração da~\ref[set_de_morgan_gen].

%%}}}

%%{{{ x: set_de_morgan_gen_exercise_2rl 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_exercise_2rl
%%%}}}

E a segunda.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tu provavelmente adivinhaste:
a~\ref[set_de_morgan_gen] é uma generalização
da~\reftag[set_de_morgan], algo que---que surpresa!---tu
demonstrarás no exercício seguinte:

%%}}}

%%{{{ x: set_de_morgan_gen_indeed 
\exercise.
%%%{{{ meta 
\label set_de_morgan_gen_indeed
%%%}}}

O que precisamos fazer para ganhar a~\ref[set_de_morgan] como um corolário
da~\ref[set_de_morgan_gen]?

\hint
Quais são os dados que precisamos ter per aplicar a~\ref[set_de_morgan_gen]?

\solution
Dados conjuntos $A,B,C$, precisamos mostrar que:
$$
C \setminus (A \union B)
=
(C \setminus A) \inter (C \setminus B).
$$
Seja $\set{A_n}_n$ a seqüência $A,B,B,B,\dotsb$, (ou seja, a seqüência definida pelas:
$A_0 = A$; e $A_i = B$ para $i > 0$).
Pela~\ref[set_de_morgan_gen] temos então:
$$
C \setminus \mubrace{\Union_{n=0}^\infty A_n} {A \union B}
=
\mubrace{\Inter_{n=0}^{\infty} (C \setminus A_n)} {(C\setminus A) \inter (C\setminus B)}.
$$

%%}}}

%%{{{ x: set_de_morgan_gen_using_formulas 
\exercise.
%%%{{{ meta 
%%%}}}

Tente escrever uma demonstração da~\ref[set_de_morgan_gen] usando fórmulas
como foi visto---e criticado---no~\ref[set_de_morgan_using_formulas].

\solution
Calculamos
\compute
x \in C \setminus \Unionl_{n=0}^{\infty}A_n
&\iff x \in C \land \lnot \biggparen{x \in \Unionl_{n=0}^{\infty}A_n}  \by {def.~$\setminus$} \\
&\iff x \in C \land \lnot (\exists n\in\nats)[x \in A_n]  \by {def.~$\Unionl_{n=0}^{\infty}$} \\
&\iff x \in C \land (\forall n\in\nats)[x \nin A_n]       \by {De Morgan} \\
&\iff (\forall n\in\nats)[x \in C \land x \nin A_n]       \by {$n$ não livre em $x\in C$} \\
&\iff (\forall n\in\nats)[x \in C \setminus A_n]          \by {def.~$\setminus$} \\
&\iff x \in \Interl_{n=0}^{\infty}(C \setminus A_n).      \by {def.~$\Interl_{n=0}^{\infty}$} \\
\endcompute
(Observe a semelhança entre essa demonstração e a demonstração da~\ref[set_de_morgan],
até nas justificativas de cada passo!)
A demonstração da outra igualdade é de graça pois é sua dual:
é só trocar os $\Union$ com os $\Inter$, e os $\exists$ com os $\forall$!

%%}}}

%%{{{ x: distributivity over a sequence of sets 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute:
para todo conjunto $A$ e toda seqüência de conjuntos $\seqn B n$
$$
A \union \Inter_{n=0}^{\infty} B_n
=
\Inter_{n=0}^\infty \paren{A \union B_n}
$$

\solution
A afirmação é verdadeira.
\crproofpart {\lrdirset}:
Suponha $x \in A \union \Inter_{n=0}^{\infty} B_n$.
Logo $x\in A$ ou $x \in \Inter_{n=0}^{\infty} B_n$.
\proofcase {Caso $x\in A$.}
Temos que para todo $n\in\nats$, $x\in A\union B_n$ (pois $x \in A$), e logo $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
\proofcase {Caso $x\in \Inter_{n=0}^{\infty} B_n$.}
Seja $n\in\nats$.  Preciso mostrar que $x \in A \union B_n$,
que é verdadeiro pois $x \in B_n$ pela hipótese do caso.
\crproofpart {\rldirset}:
Suponha $x \in \Inter_{n=0}^\infty \paren{A \union B_n}$.
Logo $x \in A \union B_n$ para todo $n \in \nats$.
\proofcase {Caso $x\in A$,} o resultado é imediato.
\proofcase {Caso $x\nin A$.}
Seja $m\in \nats$.
Vou mostrar que $x\in B_m$.
Sabemos pela hipótese que $x \in A \union B_m$, e como $x \nin A$, logo $x\in B_m$.
Como o $m$ foi arbitrário, concluimos que para todo $m\in \nats$, $x \in B_m$, que foi
exatamente o que precisamos demonstrar.

%%}}}

%%{{{ x: running_intervals_on_nats
\exercise.
%%%{{{ meta 
\label running_intervals_on_nats
%%%}}}

Para $n\in\nats$, defina os conjuntos de naturais
$$
\xalignat2
A_n &= \setst {i\in\nats} {i \leq n} &
B_n &= \nats \setminus A_n.
\endxalignat
$$
Calcule os conjuntos $\Union_n A_n$ e $\Inter_n B_n$.

\hint
Use as definições e/ou a~\ref[set_de_morgan_gen].

\solution
Temos
$$
\align
a \in \Unionl_n A_n
&\iff \lexists {n\in \nats} {a\in A_n}
\iff a \in \nats \\
b \in \Interl_n B_n
&\iff \lforall {n\in \nats} {b\in B_n}
\iff \False.
\endalign
$$
Ou seja: $\Union_n A_n = \nats$ e $\Inter_n B_n = \emptyset$.
Equivalentemente ganhamos a segunda imediatamente pela primeira
e a~\ref[set_de_morgan_gen].

%%}}}

%%{{{ x: nested_indexed_Inters 
\exercise.
%%%{{{ meta 
\label nested_indexed_Inters
%%%}}}

Seja $\seqn A n$ uma seqüência (infinita) de conjuntos.
A afirmação
$$
\Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m
=
\Inter_{n=0}^{\infty} A_n
$$
é verdadeira?
Se sim, demonstre;
se não, refute;
se os dados não são suficientes para concluir,
mostre um exemplo e um contraexemplo.

\hint
Cuidado com os ligadores de variáveis na notação dos operadores grandes limitados.

\solution
Resposta: sim!
\crproofpart {\lrdirset}:
    Seja $x \in \Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m$.
    Pela hipótese, para todo $n\in\nats$, $x \in \Inter_{m=n}^{\infty} A_m$ (def.~$\Inter_{n=0}^{\infty}$).
    Logo (com $n := 0$) temos o desejado $x \in \Inter_{m=0}^{\infty} A_m$.
\crproofpart {\rldirset}:
    Seja $x\in\Inter_{n=0}^{\infty} A_n$, ou seja, $x$ pertence a todos os $A_n$'s.
    Preciso mostrar que
    $$
    x \in \Inter_{n=0}^{\infty} \Inter_{m=n}^{\infty} A_m.
    $$
    Seja $w \in \nats$ então, e agora basta mostrar que
    $$
    x \in \Inter_{m=w}^{\infty} A_m.
    $$
    Seja $m\geq w$ então.
    Preciso mostrar que $x \in A_m$; que segue imediatamentea pela hipótese (tomando $n := m$).

%%}}}

%%{{{ warning: big_setops_vs_sum 
\warning.
%%%{{{ meta 
\label big_setops_vs_sum
\credits
    * Riemann : teorema de rearranjo
    ;;
%%%}}}

Uma diferença importantíssima entre os operadores ${\Sum}$ e ${\Union}$ e seus índices:
um \dq{somatório infinito} não é nem associativo nem comutativo!
O seguinte teorema de Riemann é bastante impressionante!

%%}}}

%%{{{ thm: riemann_rearrangement 
\theorem Riemann's rearrangement.
%%%{{{ meta 
\label riemann_rearrangement
\credits
    * Riemann : teorema de rearranjo
    ;;
\defines
    * teorema!de rearranjo de Riemann
    ;;
%%%}}}

Se uma série infinita $\Sum a_i$ de reais é \emph{condicionalmente convergente},\foot
Uma série $\Sum a_i$ é \dterm{condicionalmente convergente}
sse ela é convergente, mas a $\Sum |a_i|$ não é.
\toof
então podemos apenas permutando seus termos criar uma nova série infinita que
converga em \emph{qualquer} $x\in[-\infty,\infty]$ que desejamos.

\sketch.
Separe as metas: (i) mostrar como criar uma série que converge num dado número $\ell$;
(ii) mostrar como criar uma série divergente.
\eop
Observe que como $\Sum a_i$ é condicionalmente convergente, ela contem uma infinidade
de termos positivos, e uma infinidade de termos negativos.
Para o (i), fixe um $\ell\in\reals$.
Fique tomando termos positivos da série $a_i$ até seu somatório supera o $\ell$.
Agora fique tomando termos negativos da $a_i$ até seu somatório cai embaixo do $\ell$.
Agora fique tomando termos positivos até superar o $\ell$, etc.~etc.
Continuando assim conseguimos construir uma série feita por termos da
$\Sum a_i$ que converge no $\ell$.
Para o (ii), a idéia é similar.

\proof.
Veja~\cite[apostol1: \S10.21~\&~Teorema~10.22].

%%}}}

%%{{{ Limits of sequences of sets. 
\note Limites de seqüências de conjuntos.
%%%{{{ meta 
%%%}}}

Seja $\sequence {A_n} n$ uma seqüência de conjuntos.
Podemos definir a noção $\lim_n A_n$ de \emph{limite}
dessa seqüência.  Claramente, não todas as seqüências
de conjuntos convergem em algum limite.  Investigamos
isso nos problemas (\ref[set_liminf_limsup_problem]
e~\ref[set_limits]).

%%}}}

\endsection
%%}}}

%%{{{ Multisets 
\section Multisets.
%%%{{{ meta 
\label Multisets
\indexes
    * multiset
    * bag    see: multiset
    ;;
%%%}}}

%%{{{ multiset_description 
\note Descripção.
%%%{{{ meta 
\label multiset_description
%%%}}}

Coloquialmente falando, um \dterm{multiset}
(também \dterm{bag} ou \dterm{sacola}) $M$ é como um conjunto,
só que ele não pode responder apenas em perguntas do tipo
<<o objeto $x$ pertence ao $M$?>>, mas também em
<<\emph{quantas vezes pertence} o $x$ ao $M$?>>.
Seus membros continuam sem ordem, mas agora tem \dterm{multiplicidade}.
Usamos a notação
$\bag{x_0, x_1, \dots, x_n}$
para denotar multisets, ou até
$\set{x_0, x_1, \dots, x_n}$
sobrecarregando a notação $\set{\dots}$ se é claro pelo contexto
que é um multiset e não um conjunto.

%%}}}

%%{{{ multiset_equality 
\note Igualdade.
%%%{{{ meta 
\label multiset_equality
%%%}}}

Consideramos os multisets $M$ e $M'$ iguais sse para todo $x$,
$$
\text{$x$ pertence $n$ vezes ao $M$}
\iff
\text{$x$ pertence $n$ vezes ao $M'$}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Multisets têm muitos usos na ciência da computação: acabam sendo a ferramenta
ideal para (d)escrever muitos algoritmos, e muitas linguagens de programação
já têm esse tipo implementado.
Mas seu uso em matemática é menos comum.
De qualquer forma, fez sentido introduzí-los agora junto com seus tipos-amigos,
pelo menos para saber sobre sua existência na literatura.
Voltamos depois para implementá-los
(\ref[implement_multisets],
\ref[multiset_formally_defined]);
não se preocupe neste momento com eles.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: sequence_of_sets_inclusions_counterexample 
\problem.
%%%{{{ meta 
\label sequence_of_sets_proper_inclusions_counterexample
%%%}}}

Sejam $\seqn A n$ e $\seqn B n$ duas seqüências de conjuntos,
tais que para todo $n\in\nats$,
$A_n \psubset B_n$.
Podemos concluir alguma das afirmações seguintes?:
$$
\xalignat2
\Union_{n=0}^\infty A_n &\psubset \Union_{n=0}^{\infty} B_n &
\Inter_{n=0}^\infty A_n &\psubset \Inter_{n=0}^{\infty} B_n
\endxalignat
$$

\hint
Procure contraexemplos:
para cada afirmação,
defina duas seqüências $\seqn A n$ e $\seqn B n$
que satisfazem a condição do problema, e mesmo assim,
não é válida a conclusão proposta.

\solution
Vamos construir um contraexemplo para cada afirmação.
\eop
Considere as seqüências de conjuntos seguintes:
para todo $n\in\nats$ define
$$
A_n \eqass (-n,n)
\qqqquad
\aligned
B_0     &\asseq \emptyset\\
B_{n+1} &\asseq [-n,n].
\endaligned
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \psubset B_{n+1}$:
$$
A_n = (-n,n) \psubset [-n,n] = B_{n+1}.
$$
Mesmo assim,
$$
\Union_{n=0}^\infty A_n = \reals = \Union_{n=0}^{\infty} B_n.
$$
\eop
Para refutar a segunda afirmação, considere
as seqüências de conjuntos seguintes:
para todo $n\in\nats$ defina
$$
A_n \eqass \setst {k \in \nats}  {k > n}
\qquad\qquad
B_n \eqass \setst {k \in \nats}  {k \geq n}
$$
Observe que, realmente, para todo $n\in\nats$ temos $A_n \psubset B_n$.
Mesmo assim,
$$
\Inter_{n=0}^\infty A_n = \emptyset = \Inter_{n=0}^{\infty} B_n.
$$

%%}}}

%%{{{ prob: bounded_Union_and_Iter_def_and_prop 
\problem.
%%%{{{ meta 
\label bounded_Union_and_Iter_def_and_prop
%%%}}}

Seja $\seqn A n$ seqüência (infinita) de conjuntos.
Defina recursivamente uma seqüência de conjuntos $\seqn D n$
tal que (informalmente):
$$
\text{para todo $k\in\nats$, $D_k = A_0 \union A_1 \union \dotsb \union A_{k-1}$}.
$$
Em outras palavras,
precisas definir formalmente a operação união unária \dterm{limitada}
($\Union_{i=0}^{k-1} \dhole$) para qualquer $k\in\nats$.
Demonstre que para todo $n\in\nats$,
$$
\mubrace {\Union_{i=0}^{n-1} A_i} {D_n} \subset \Union_{m=0}^{\infty} A_m.
$$
O que muda se trocar de uniões para intersecções?

\solution
\proofpart {Definição da $D_n$} por recursão:
$$
\align
D_0     &= \emptyset \\
D_{n+1} &= D_n \union A_n.
\endalign
$$
\proofpart {Demonstração da afirmação} por indução no $n$:
\crtabproofpart {Base:} $D_0 \subset \Union_{m=0}^{\infty} A_m$.
Imediato pois $D_0 = \emptyset$.
\crtabproofpart {Passo indutivo.}
Seja $w \in \nats$ tal que
$$
D_w \subset \Union_{m=0}^{\infty} A_m.    \tag{H.I.}
$$
Preciso demonstrar que
$$
D_{w+1} \subset \Union_{m=0}^{\infty} A_m.
$$
Seja $d \in D_{w+1}$.
Basta mostrar que
$$
d \in \Union_{m=0}^{\infty} A_m,
$$
ou seja, que $d$ pertence àlgum dos $A_m$'s.
Pela definição de $D_{w+1} = D_w \union A_w$, temos
que
$d \in D_w$
ou
$d \in A_w$.
Separo em casos:
\crproofcase {Caso $d \in D_w$.}
Imediatamente pela (H.I.)
$$
d \in D_w \subset \Union_{m=0}^{\infty} A_m.
$$
\proofcase {Caso $d \in A_w$.}
Imediato.
\crproofpart {O que muda trocando de uniões para intersecções:}
(1) a intersecção vazia tem de ser o $\universet$ em vez do $\emptyset$,
pois $\universet$ é a identidade da $\inter$ binária;
(2) o $(\subset)$ da afirmação tem de mudar pra $(\supset)$;
(3) a base da indução também é imediata pois $\universet$
é superconjunto de qualquer conjunto;
(4) o passo indutivo muda numa maneira mais interessante:
nosso alvo é mostrar que um arbitrario membro $a$ que pertence
a intersecção infinita dos $A_i$'s pertence ao $D_{w+1}$ tambem,
dado que qualquer membro dela pertence ao $D_w$;
e temos então ambas as coisas que precisamos
(o $a \in D_w$ pela (H.I.) e o $a \in A_w$
pois $a$ pertence a todos os $A_i$'s).

%%}}}

%%{{{ prob: sandwiching_a_set_sequence 
\problem Sanduichando uma seqüência de conjuntos.
%%%{{{ meta 
\label sandwiching_a_set_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Demonstre que para todo $k\in\nats$,
$$
\Inter_{i=k}^{\infty} {A_i}
\subset
A_k
\subset
\Union_{i=k}^{\infty} {A_i}.
$$
Ou seja, temos:
$$
\matrix
\format
\c      & \;\c\; & \r                                                 & \quad\c\quad & \c     & \quad\c\quad & \r                                                 & \;\c\; & \c  \\
C_0     & \asseq & A_0 \inter A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_0    & \subset    & A_0 \union A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_0 \\
C_1     & \asseq &            A_1 \inter A_2 \inter A_3 \inter \dotsb & \subset    & A_1    & \subset    &            A_1 \union A_2 \union A_3 \union \dotsb & \eqass & D_1 \\
C_2     & \asseq &                       A_2 \inter A_3 \inter \dotsb & \subset    & A_2    & \subset    &                       A_2 \union A_3 \union \dotsb & \eqass & D_2 \\
        & \vdots &                     \ddots \phantom{\inter \dotsb} & \vdots       & \vdots & \vdots       &                     \ddots \phantom{\union \dotsb} &        & \vdots \\
\endmatrix
$$

%%}}}

\endproblems
%%}}}

%%{{{ Indexed_families 
\section Famílias indexadas.
%%%{{{ meta 
\label Indexed_families
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na \reftag[Sequences] vimos como nos livrar da restricção de usar
um conjunto $\set{0,\dotsc,n-1}$ como ``rótulos'' para indexar os
membros duma tupla e, usando o conjunto infinito $\nats$,
chegamos na idéia de \emph{seqüências}.
Agora vamos generalizar os conceitos tanto de tuplas, quanto de
seqüências: oi, famílias indexadas!

%%}}}

%%{{{ Motivation 
\note Motivação.
%%%{{{ meta 
%%%}}}

A idéia que nos motiva é: \emph{por que nos limitar ``acessando''
os membros de uma tupla apenas usando inteiros como índices (rótulos),
enquanto podemos ``liberar'' qualquer objeto para servir como rótulo?}
E é assim que fazemos mesmo.

%%}}}

%%{{{ eg: daughters_of_p 
\example.
%%%{{{ meta 
\label daughters_of_p
%%%}}}

Seja $\cal C$ o conjunto de todos os países do mundo e,
para cada $c \in \cal C$, seja $V_c$ o conjunto de todos os vilarejos do $c$.
Em símbolos,
$$
V_c = \setstt v {$v$ é um vilarejo no país $c$}.
$$
O que acabamos de definir aqui?
Para \emph{cada} país $c\in\cal C$ um novo objeto foi definido:
o conjunto de todos os vilarejos de $c$.
Ou seja, acabamos de definir vários objetos,
\emph{exatamente um para cada membro do $\cal C$}.
Assim que determinar isso, dizemos que temos uma \dterm{família indexada
por $\cal C$}.

%%}}}

%%{{{ df: indexed_family 
\definition família indexada.
%%%{{{ meta 
\label indexed_family
\defines
    * \family {~{a_i}} {~i\in ~{\cal I}}  -- a família indexada dos $a_i$'s
    * conjunto!de índices
    * família!indexada
    * tupla!$\cal I$-tupla
    ;;
\pdefs
    \pdef I {{\cal I}}
    ;;
%%%}}}

Chegamos assim na idéia de \dterm{família indexada} por
algum conjunto $\I$, cuja totalidade denotamos por
$\family {a_i} {i\in\I}$ ou $\famst {a_i} {i\in\I}$,
onde $a_i$ é um determinado objeto para cada $i\in\I$.
Chamamos o $\I$ o \dterm{conjunto de índices} da família,
e quando ele é implícito pelo contexto denotamos a família apenas
com $\family {a_i} i$.
Alternativamente usamos como sinônimo o termo \dterm{$\I$-tupla},
enfatizando assim que o conceito de família indexada é apenas
uma generalização da $n$-tupla.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mais uns exemplos de famílias indexadas:

%%}}}

%%{{{ eg: anscestors_and_children 
\example.
%%%{{{ meta 
\label ancestors_and_children
%%%}}}

Seja $\pers$ o conjunto de todas as pessoas do mundo.
Definimos para cada pessoa $p\in \pers$, os conjuntos $A_p$ e $C_p$ de todos
os ancestrais e todos os filhos de $p$, respectivamente.
Ou seja, acabamos de definir duas \emph{famílias indexadas} de conjuntos:
a $\famil A p \pers$ e a $\famil C p \pers$.

%%}}}

%%{{{ eg: airports_direct_flights 
\example.
%%%{{{ meta 
\label airports_direct_flights
%%%}}}

Seja $\cal A$ o conjunto de todos os aeroportos.
Para cada aeroporto $a\in\cal A$, seja
$$
D_a \defeq \setst { b \in \cal A } { \text{existe vôo direto de $a$ para $b$} }.
$$
Acabamos de definir uma família de conjuntos
$\famst {D_a} {a \in \cal A}$.

%%}}}

%%{{{ eg: books_and_authors 
\example.
%%%{{{ meta 
\label books_and_authors
%%%}}}

Seja $\cal B$ o conjunto de todos os livros.
Para cada livro $b\in\cal B$, sejam
$$
\align
A_b &\defeq \setstt a {$a$ é um autor do livro $b$}\\
W_b &\defeq \setstt w {$w$ é uma palavra que aparece no texto do livro $b$}.
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Sabendo a definição de igualdade entre tuplas, definir
igualdade entre famílias indexadas é fácil.

%%}}}

%%{{{ df: indexed_families_equality 
\definition Igualdade.
%%%{{{ meta 
\label indexed_families_equality
%%%}}}

Sejam
$\family {a_i} {i\in \cal I}$,
$\family {b_i} {i\in \cal I}$
famílias indexadas por um conjunto de índices $\cal I$.
Chamamo-nas iguais sse
$$
\lforall {i\in\cal I} {a_i = b_i}.
$$

%%}}}

%%{{{ Q: How would you define union and intersection of a family?
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias as operações (unárias!) de união e de intersecção
para famílias?

%%}}}

\spoiler

%%{{{ df: Union_Inter_of_family 
\definition.
%%%{{{ meta 
\label Union_Inter_of_family
%%%}}}

Seja $\famil A i {\cal I}$ é uma família de conjuntos indexada por um
conjunto de índices $\cal I$.
Definimos
$$
\xalignat2
x \in \Union_{i\in\cal I} A_i &\defiff \lexists {i\in \cal I} {x \in A_i}&
x \in \Inter_{i\in\cal I} A_i &\defiff \lforall {i\in \cal I} {x \in A_i}.
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Note que em palavras de rua, as definições são igualzíssimas:
um objeto pertence à união da família sse ele pertence a pelo
menos um dos seus membros; e perence à sua intersecção sse ele
pertence a todos os seus membros.

%%}}}

%%{{{ x: intersection_of_indices_of_families_exercise 
\exercise.
%%%{{{ meta 
\label intersection_of_indices_of_families_exercise
%%%}}}

Sejam $I,J$ conjuntos de índices e para cada $k\in I\union J$ seja $A_k$ um conjunto.
A afirmação
$$
\Union_{k\in I\inter J} A_k
=
\Union_{k\in I} A_k \inter
\Union_{k\in J} A_k
$$
é verdadeira?
Responda\dots
(1) \emph{sim}, e demonstre;
(2) \emph{não}, e refute; ou
(3) \emph{depende}, e mostre um exemplo e um contraexemplo.

\hint
Depende.
Agora ache um exemplo e um contraexemplo.

\solution
Depende!
Primeiramente um exemplo onde a afirmação é válida:
$$
\xalignat2
I = J &= \set{1} &
A_1 &= \set{5}
\intertext{\dots e um onde a afirmação é falsa:}
I &=\set{1} &
A_1 = A_2 &= \set{5} \\
J &=\set{2}
\endxalignat
$$
Realmente, verificamos calculando no primeiro exemplo:
$$
\xalignat2
\Union_{k\in I\inter J} A_k &= A_1 &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_1 = A_1
\intertext{\dots e no segundo:}
\Union_{k\in I\inter J} A_k &= \Union_{k\in\emptyset} A_k = \emptyset &
\Union_{k\in I} A_k \inter \Union_{k\in J} A_k &= A_1 \inter A_2 = \set{5}
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixando o \ref[intersection_of_indices_of_families_exercise]
nos guiar, chegamos numa investigação interessante:

%%}}}

%%{{{ x: unions_and_intersections_of_indices 
\exercise.
%%%{{{ meta 
\label unions_and_intersections_of_indices
%%%}}}

Sejam $\cal I$, $\cal J$ conjuntos de índices, e suponha que
para cada membro $k \in \cal I \union \cal J$ um conjunto
$A_k$ é determinado.
O que podemos concluir sobre os conjuntos
$$
\xalignat4
\Union_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \union
\Union_{j\in\cal J} {A_j} &
\Union_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Union_{i\in\cal I} {A_i} \inter
\Union_{j\in\cal J} {A_j} \\
\Inter_{k\in\cal I\union\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \union
\Inter_{j\in\cal J} {A_j} &
\Inter_{k\in\cal I\inter\cal J} {A_k} &\quad\mathrel{(?)}\quad
\Inter_{i\in\cal I} {A_i} \inter
\Inter_{j\in\cal J} {A_j}
\endxalignat
$$
das opções: \symq{$=$}, \symq{$\subset$}, \symq{$\supset$}, etc.
Investigue.

%%}}}

\endsection
%%}}}

%%{{{ Indexed_sets_vs_indexed_families 
\section Conjuntos indexados \vs famílias indexadas.
%%%{{{ meta 
\label Indexed_sets_vs_indexed_families
%%%}}}

%%{{{ df: indexed_set 
\definition Conjuntos indexados.
%%%{{{ meta 
\label indexed_set
\defines
    * conjunto!indexado por conjunto
    ;;
%%%}}}

Quando usamos um conjunto $B$ para ``indexar'' um conjunto $A$,
chamamos o $A$ um \dterm{conjunto indexado por $B$}.
Temos então:
$$
A = \setst {\dots b \dots} {b \in B}.
$$

%%}}}

%%{{{ remark: every_set_can_be_indexed 
\remark.
%%%{{{ meta 
\label every_set_can_be_indexed
%%%}}}

Todo conjunto $A$ pode ser indexado por ele mesmo, pois
$$
A = \setst a {a \in A}.
$$
Em outras palavras, o ``conjunto indexado'' não é um tipo
diferente do tipo ``conjunto''.  Não faz sentido nos perguntar
se um conjunto $A$ é indexado ou não, pois todos são
(pelo menos por eles mesmo).

%%}}}

%%{{{ remark: picking_elements_from_indexed_sets 
\remark Tomando elementos de conjuntos indexados.
%%%{{{ meta 
\label picking_elements_from_indexed_sets
%%%}}}

Suponha que temos um conjunto $A$ indexado
por um conjunto $B\neq\emptyset$:
$$
A = \setst {\bla(b)} {b\in B}.
$$
Como podemos ``tomar um arbitrario membro de $A$''?
Claramente podemos dizer: ``seja $a \in A$'', algo válido
para qualquer conjunto $A \neq \emptyset$.
Mas nesse caso, ``sejando'' um $b\in B$, determinamos
um membro de $A$: o $\bla(b)$.
Assim, se demonstrarmos algo sobre o $\bla(b)$,
isso é suficiente para concluir que todos os elementos
de $A$ satisfazem esse algo.
Imagine então que queremos demonstrar que
$$
A \subset C.
$$
Podemos seguir o caminho padrão, demonstrando
$$
\lforall {a \in A} {a \in C},
$$
mas temos um caminho alternativo que podemos seguir nesse caso:
demonstrar que
$$
\lforall {b \in B} {\bla(b) \in C}.
$$

%%}}}

%%{{{ indexed_sets_equality 
\note Igualdade entre conjuntos indexados.
%%%{{{ meta 
\label indexed_sets_equality
%%%}}}

Para mostrar que dois \emph{conjuntos}
indexados pelo mesmo conjunto são iguais, é \emph{suficiente}
mostrar que são iguais como famílias---mas não \emph{necessário}:
veja~\ref[equal_as_fam_not_necessary_for_equal_as_sets].
\eop
Por exemplo, sejam $A,B$ conjuntos indexados pelo mesmo conjunto $C$:
$$
\xalignat2
A &= \setst {\bla(c)} {c \in C} &
B &= \setst {\blu(c)} {c \in C}.
\endxalignat
$$
Suponha que queremos demonstrar $A=B$.
O caminho orthódoxo seria seguir a definição de igualdade de conjuntos
e demonstrar
$$
\lforall x {x\in A \iff x \in B},
\qqqtext{ou seja,}
A \subset B \mland A \supset B.
$$
Mas, vendo eles como \emph{conjuntos indexados por o $C$},
podemos matar o alvo $A=B$ numa maneira alternativa, aplicando
a definição de igualdade de famílias indexadas.
No final das contas, parecem famílias indexadas por o mesmo conjunto
de índices (o $C$).
Então demonstrando a afirmação
$$
\lforall {c \in C} {\bla(c) = \blu(c)}
$$
é \emph{suficiente} para demonstrar que $A=B$.

%%}}}

%%{{{ beware: equal_as_fam_not_necessary_for_equal_as_sets 
\beware Suficiente mas não necessário!.
%%%{{{ meta 
\label equal_as_fam_not_necessary_for_equal_as_sets
%%%}}}

Observe que mostramos algo ainda mais forte: não é apenas
que $A=B$ como conjuntos, mas como \emph{famílias} indexadas também,
ou seja, \emph{concordam em todo índice}.
Mas: pode ser que como famílias
não são iguais, mas como conjuntos, são, como o exemplo
seguinte mostra:

%%}}}

%%{{{ eg: equal_as_fam_not_necessary_for_equal_as_sets_example 
\example.
%%%{{{ meta 
\label equal_as_fam_not_necessary_for_equal_as_sets_example
%%%}}}

Considere os
$$
\xalignat2
A &= \setst {x + 1} {x \in \ints} &
B &= \setst {x - 1} {x \in \ints}.
\endxalignat
$$
São dois conjuntos indexados pelo mesmo conjunto $\ints$.
Obviamente $A=B$, mas para nenhum índice $x \in \ints$ temos
$x + 1 = x - 1$.

%%}}}

\endsection
%%}}}

%%{{{ Pairwise-disjointness 
\section Disjuntos dois-a-dois.
%%%{{{ meta 
%%%}}}

%%{{{ df: pairwise_disjoint 
\definition.
%%%{{{ meta 
\label pairwise_disjoint
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos seus membros \dterm{disjuntos dois-a-dois} sse nenhum deles
tem elementos em comum com nenhum outro deles.
Em símbolos:
$$
\text{os conjuntos da $\scr A$ são disjuntos dois-a-dois}
\defiff
\lforall {A,B \in \scr A} {A \neq B \implies A\inter B = \emptyset }.
$$
Similarmente para famílias indexadas:
$$
\align
\text{os conjuntos da $\famil A i {\cal I}$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \cal I} {i\neq j \implies A_i \inter A_j = \emptyset}.
\intertext{E logo para seqüências também:}
\text{os conjuntos da $\seqn A n$ são disjuntos dois-a-dois}
&\defiff
\lforall {i,j \in \nats} {i\neq j \implies A_i \inter A_j = \emptyset}.
\endalign
$$

%%}}}

%%{{{ x: disjoint_not_pairwise_disjoint 
\exercise.
%%%{{{ meta 
\label disjoint_not_pairwise_disjoint
%%%}}}

Ache uma família de conjuntos $\scr A$ com $\Inter \scr A = \emptyset$
mas cujos membros não são disjuntos dois-a-dois.

\solution
Tome
$$
\scr A \asseq \set{ \set{0,1}, \set{1,2}, \set{7} }.
$$

%%}}}

\endsection
%%}}}

%%{{{ Coverings_and_partitions 
\section Coberturas e partições.
%%%{{{ meta 
\label Coverings_and_partitions
%%%}}}

\TODO Terminar and include figures.

%%{{{ df: covering_sets 
\definition cobertura.
%%%{{{ meta 
\label covering_sets
\defines
    * covering
    ;;
%%%}}}

Seja $B$ conjunto e $\scr A$ uma família de conjuntos.
Dizemos que $\scr A$ é uma \dterm{cobertura} de $B$ sse a união da família contem o $B$:
$$
\text{$\scr A$ cobre $B$}
\defiff
\Union \scr A \supset B.
$$

%%}}}

%%{{{ df: partition_sets 
\definition partição.
%%%{{{ meta 
\label partition_sets
\defines
    * partição
    ;;
%%%}}}

Seja $B$ conjunto e $\scr A$ uma cobertura de $B$.
Dizemos que $\scr A$ é uma \dterm{partição} de $B$ sse
todos os membros da $\scr A$ são subconjuntos habitados de $B$ e disjuntos dois-a-dois.

%%}}}

%%{{{ x: partitions_of_seven 
\exercise.
%%%{{{ meta 
\label partitions_of_seven
%%%}}}

Seja $A=\set{0,1,2,3,4,5,6}$.
Quais das colecções seguintes são partições do $A$?:
\mathcols 2
\scr A_1 &= \big\{ \set{0,1,3}, \set 2, \set{4,5}, \set 6 \big\} &
\scr A_5 &= \big\{ \set{0,1,2}, \set{2,3,4}, \set{4,5,6} \big\} \\
\scr A_2 &= \big\{ \set{0,1,2,3}, \emptyset, \set{4,5,6} \big\} &
\scr A_6 &= \big\{ \set{1,2}, \set{0,3}, \set 5, \set 6 \big\} \\
\scr A_3 &= \big\{ \set{0,1,2,3,4,5,6} \big\} &
\scr A_7 &= \big\{ \set{0,1,2}, \set 3, \set{4,5,6,7} \big\} \\
\scr A_4 &= \big\{ \set 0, \set 1, \set 2, \set 3, \set 4, \set 5, \set 6 \big\} &
\scr A_8 &= \big\{ \set 0, \set{1,2}, \set{6,5,4,3} \big\}.
\endmathcols

\hint
Quatro delas são, as outras não.

\solution
As $\scr A_1, \scr A_3, \scr A_4, \scr A_8$ são.
As outras não:
\tlist:
\li: a $\scr A_2$ não é: $\emptyset$ é seu membro;
\li: a $\scr A_5$ não é: o $2$ que pertence a dois membros dela;
\li: a $\scr A_6$ não é: $4 \in A$ mas não pertence a nenhum membro dela;
\li: a $\scr A_7$ não é: $7 \nin A$ mas $7 \in \Union \scr A_7$.
\endtlist


%%}}}

\endsection
%%}}}

%%{{{ Translating_from_and_to_the_language_of_sets 
\section Traduzindo de e para a linguagem de conjuntos.
%%%{{{ meta 
\label Translating_from_and_to_the_language_of_sets
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Lembra os exemplos~\reftag[ancestors_and_children],~\reftag[airports_direct_flights],
e~\reftag[books_and_authors]?
Bom.  Vamos practicar nossa fluência em cojuntos usando esses exemplos agora.

%%}}}

%%{{{ x: ancestors_and_children_translations 
\exercise.
%%%{{{ meta 
\label ancestors_and_children_translations
%%%}}}

Para toda pessoa $p\in\pers$ defina $A_p$ e $C_p$ como
no~\ref[ancestors_and_children].
Suponha que $p,q,r$ denotam pessoas.
Traduza as afirmações descritas na linguagem de conjuntos para
linguagem natural e vice versa.
% TODO: fix reflabs
\elist a:
\li: $p$ e $q$ são irmãos;
\li: $C_p \neq \emptyset$;
\li: $p$ é filho único;
\li: $p$ e $q$ são parentes;
\li: $p$ e $q$ são primos de primeiro grau;
\li: $r$ é filho dos $p$ e $q$;
\li: $C_p \inter C_q \neq \emptyset$;
\li: $A_p \subset A_q$;
\li: $\emptyset \psubset C_p \psubset C_q$;
\li: $\lexists {p\in\pers} {p \in C_p}$.
\endelist

\solution
Traduzimos:
$$
\align
\text{$p$ e $q$ são irmãos}                      &: \text{$p\neq q \mland \exists r \paren{\set{p,q}\subset C_r}$} \\
\text{$C_p \neq \emptyset$}                      &: \text{$p$ tem pelo menos um filho} \\
\text{$p$ é filho único}                         &: \text{$\lexists {r\in A_p} {C_r = \set{p}}$} \\
\text{$p$ e $q$ são parentes}                    &: \text{$A_p \inter A_q \neq \emptyset$} \\
\text{$p$ e $q$ são primos de primeiro grau}     &: \text{$\exists r,r'\paren{p\in C_r \mland q \in C_{r'} \mland \text{$r$ e $r'$ são irmãos}}$} \\
\text{$r$ é filho dos $p$ e $q$}                 &: \text{$r \in C_p \inter C_q$} \\
\text{$C_p \inter C_q \neq \emptyset$}           &: \text{$p$ e $q$ têm pelo menos um filho juntos} \\
\text{$A_p \subset A_q$}                         &: \text{$p$ é um anscestor ou irmão de $q$} \\
\text{$\emptyset \psubset C_p \psubset C_q$} &: \text{$q$ tem filho(s) com $p$ mas com outra pessoa também} \\
\text{$\lexists {p\in\pers} {p \in C_p}$}        &: \text{existe pessoa que é seu próprio filho}.
\endalign
$$
(Tuas traduções podem variar, especialmente se tuas definições
dessas palavras são diferentes que aquelas que eu usei aqui.)

%%}}}

\endsection
%%}}}

%%{{{ Generalized_cartesian_product 
\section Produto cartesiano generalizado.
%%%{{{ meta 
\label Generalized_cartesian_product
%%%}}}

%%{{{ idea 
\note.
%%%{{{ meta 
%%%}}}

Vamos começar com
\emph{dois objetos} $a$ e $b$, nessa ordem,
ou seja com uma tupla $\tup{a,b}$.
Já sabemos como generalizar essa idéia para uma \emph{família indexada}
por um conjunto abstrato de índices $\cal I$, chegando assim
na $\famil a i {\cal I}$.
\eop
Agora comece com \emph{dois conjuntos} $A$ e $B$, nessa ordem,
ou seja com uma tupla $\tup{A,B}$.
Podemos formar o \emph{produto cartesiano} dela,
que em vez de escrever $\times\tup{A,B}$ escrevemos com
notação comum e infixa $A\times B$.
$$
\text{produto de $\tup{A,B}$}
= \setst {\tup{a,b}} {a \in A \mland b \in B} 
$$
Com mais detalhes:
o \emph{produto da tupla de conjuntos} $\tup{A,B}$
é \emph{o conjunto de todas as tuplas} $\tup{a,b}$ tais que seu \emph{primeiro}
membro pertence no \emph{primeiro} membro da nossa tupla de conjuntos
$\tup{A,B}$, e seu \emph{segundo} membro pertence no \emph{segundo} membro de
$\tup{A,B}$.

%%}}}

%%{{{ Q: How to generalize from tuples to indexed families? 
\question.
%%%{{{ meta 
%%%}}}

Como generalizar isso de tuplas para famílias indexadas?
Lembre-se que em famílias indexadas não existe mais essa idéia de
\emph{primeiro} e \emph{segundo} membro.
Em vez disso, temos \emph{membro no índice $i$},
um para cada $i\in\cal I$.

%%}}}

\spoiler

%%{{{ In search for a generalization 
\note Procurando uma generalização.
%%%{{{ meta 
%%%}}}

Antes de responder na pergunta, vamos construir nosso caminho
numa forma mais metódica.
$$
\matrix
\format
\c & \quad\c\quad & \c \\
\tup{A,B} & \leadsto & A\times B \\
\famil A i {\cal I} & \leadsto & ??
\endmatrix
$$
Um passo importante é perceber que nessa situação são envolvidos
dois processos: um de ``formar o produto de coisas'',
e outro de ``generalizar de tuplas para famílias indexadas''.
Então uma imagem melhor seria o diagrama
$$
\cdopt{sep=2cm}
\tup{A,B}   \ar[r, "\text{product}"]\ar[d, "\text{generalize}"'] \| A\times B\ar[d, dashed, "\text{generalize}"]\\
\famil A i {\cal I}   \ar[r, dashed, "\text{product}"]           \| ??
\endcd
$$
onde idealmente deveria \dterm{comutar}, que informalmente quis dizer que
os dois caminhos que nos levam de $\tup{A,B}$ para o desejado $??$
vão chegar na mesma coisa.
(Teremos muito mais a falar sobre \dterm{diagramas comutativos} nos próximos
capítulos.)
\eop
Assim fica mais fácil achar o $??$:
$$
\cdopt{column sep=2cm, row sep=6mm}
\tup{A,B}       \ar[r]\ar[d] \| \setst  {\tup{a,b}}     {a\in A \mland b\in B}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setst  {\tup{a_0,a_1}} {a_0\in A_0 \mland a_1\in A_1}\ar[d]\\
\tup{A_0,A_1}   \ar[r]\ar[d] \| \setstt {\tup{a_0,a_1}} {$a_i\in A_i$ para todo $i\in\set{0,1}$}\ar[d, dashed]\\
\famil A i {\cal I}   \ar[r, dashed]                          \| ??
\endcd
$$
A definição correta agora da idéia que estávamos procurando é óbvia:
$$
\text{o produto da $\famil A i {\cal I}$ é o conjunto
$\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}$}.
$$
Só basta achar uma notação legal para esse conjunto, e essa escolha também é fácil.

%%}}}

%%{{{ df: gartesian porduct of an indexed family of sets 
\definition Produto cartesiano de família.
%%%{{{ meta 
\label cartesian_product_generalized
\defines
    * \Prod_{~i\in{~{\cal I}}} {~{A_i}}  -- o produto cartesiano da família indexada de conjuntos $\famil A i {\cal I}$.
    * produto cartesiano!generalizado
    ;;
%%%}}}

Seja $\famil A i {\cal I}$ uma família indexada de conjuntos.
Definimos seu \dterm{produto cartesiano}
$$
\Prod_{i\in\cal I} A_i
\defeq
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}.
$$

%}}}

%%{{{ x: cardinalidade_of_product_of_finite_sets 
\exercise.
%%%{{{ meta 
\label cardinalidade_of_product_of_finite_sets
%%%}}}

Seja $\cal I$ um conjunto finito de índices e para cada
$i \in \cal I$ seja $A_i$ um conjunto finito.
Qual a cardinalidade do $\Prod_i {A_i}$?

\hint
$\card{A\times B} = ?$

%%}}}

%%{{{ choosers_product 
\note Escolhedores.
%%%{{{ meta 
\label choosers_product
\defines
    * escolhedor!produto
    * produto!nívelo coração
    ;;
%%%}}}

Vou tentar dar um ponto de vista ``no nível coração'' sobre o produto duma família.
Vamos começar com o produto cartesiano ``normal'' (ou seja, aquele que forma $n$-tuplas mesmo).
Como exemplo real, vamos considerar os $3$ conjuntos: $A,B,C$
Nesse caso o que seria o $A \cross B \cross C$?
Agora tome um membro $t$ do $A \cross B \cross C$.
O que ele \emph{é}?
Uma tripla, certo.
Com certeza tem a forma
$$
t = \tup{ a, b, c }
$$
para alguns $a\in A$, $b\in B$, e $c \in C$.
Mas o que ele é no meu coração?
Como a gente o chama no meu bairro?
Posso pensar que ele é um \dterm{escolhedor}.
Ele escolhe \emph{exatamente um membro de cada um dos conjuntos $A,B,C$}.
Pense que os $A$, $B$, e $C$ por exemplo são conjuntos de
``starter'', ``main course'', e sobremesa respectivamente
$$
\align
A &= \set{ \textrm{salada}, \textrm{sopa}, \textrm{tzatziki} } \\
B &= \set{ \textrm{pizza}, \textrm{carbonara}, \textrm{pastitsio} } \\
C &= \set{ \textrm{tiramisu}, \textrm{yogurte} }
\endalign
$$
E esse é o menu dum restaurante onde para jantar o cliente (escolhedor)
precisa escolher exatamente uma opção de cada.
O produto cartesiano $A \cross B \cross C$ então, que é o
$$
\align
A \cross B \cross C = {}
   &\{ \tup{\textrm{salada},   \textrm{pizza},     \textrm{tiramisu}} \\
   & , \tup{\textrm{salada},   \textrm{pizza},     \textrm{yogurte}} \\
   & , \tup{\textrm{salada},   \textrm{carbonara}, \textrm{tiramisu}} \\
   & \vdots \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}} \\
   & , \tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{yogurte}} \}.
\endalign
$$
representa todos os possíveis escolhedores.
A tripla
$$
\tup{\textrm{tzatziki}, \textrm{pastitsio}, \textrm{tiramisu}}
$$
então além de ser ``apenas uma tripla'', pode ser vista como
o escolhedor que escolheu:
$$
\align
\textrm{tzatziki}  &\in A \\
\textrm{pastitsio} &\in B \\
\textrm{tiramisu}  &\in C.
\endalign
$$
Observe que a $i$-ésima escolha do escolhedor, pertence ao
$i$-ésimo argumento do produto $A\cross B \cross C$,
onde aqui $i \in \set{0,1,2}$.
\eop
Na mesma maneira então,
dada família indexada de conjuntos $\famil A i {\cal I}$ cada
membro do seu produto cartesiano
$$
\Prod_{i\in\cal I} A_i
=
\setstt {\famil a i {\cal I}} {$a_i \in A_i$ para todo $i\in\cal I$}
$$
é uma família indexada
$$
\text{$\famil a i {\cal I}$
tal que $a_i \in A_i$ para todo $i\in\cal I$},
$$
ou seja, um escolhedor que escolha um membro de cada um
dos membros da família $\famil A i {\cal I}$:
a $i$-ésima escolha $a_i$ do escolhedor $\famil a i {\cal I}$
pertence ao $i$-ésimo argumento $A_i$ do produto $\Prod_{i\in\cal I} A_i$.
Pense nisso.

%%}}}

\TODO Notação: $\Pi_i$ \vs $\Pi$.

\endsection
%%}}}

%%{{{ Structured_sets 
\section Conjuntos estruturados.
%%%{{{ meta 
\label Structured_sets
%%%}}}

\TODO Elaborar.

%%{{{ concept, notation, equality 
\note Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

Já encontramos a idéia de estrutura (interna) dum
conjunto~(foi no~\ref[blackbox_set]).

%%}}}

%%{{{ warning: notational_abuse_structured_sets 
\warning abuso notacional.
%%%{{{ meta 
\label notational_abuse_structured_sets
\pdefs
    \pdef A {{\ssetfont A}}
    ;;
%%%}}}

Suponha $\A = \sset A {\dotsc}$ é algum conjunto estruturado.
Tecnicamente falando, escrever \sq{$a\in \A$} seria errado.
Mesmo assim escrevemos sim \sq{$a\in \A$} em vez de \sq{$a\in A$},
e similarmente falamos sobre \wq{os elementos de~$\A$}
quando na verdade estamos se referendo aos elementos de~$A$,
etc.
Em geral, quando aparece um conjunto estruturado~$\A$ num contexto
onde deveria aparecer algum conjunto, identificamos o~$\A$
com seu \dterm{carrier set}~$A$.
Às vezes usamos até o mesmo símbolo na sua definição, escrevendo
$A = \sset A {\dotsc}$.

%%}}}

%%{{{ Structured sets with constants 
\note Conjuntos estruturados com constantes.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Structured sets with operations 
\note Conjuntos estruturados com operações.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Structured sets with relations 
\note Conjuntos estruturados com relações.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: dictionary_of_operation_properties 
\definition.
%%%{{{ meta 
\label dictionary_of_operation_properties
%%%}}}

Sejam conjunto $A$,
uma operação binária $\ast$ no $A$,
e um $g \in A$.
Dizemos que:
$$
\align
\text{$A$ é $\ast$-fechado}                     &\defiff \lforall {a,b \in A}   {a \ast b \in A}\\
\text{$\ast$ é associativa}                     &\defiff \lforall {a,b,c \in A} {(a \ast b) \ast c = a \ast (b \ast c)}\\
\text{$\ast$ é comutativa}                      &\defiff \lforall {a,b \in A}   {a \ast b = b \ast a}\\
\text{$u$ é uma $\ast$-identidade esquerda}     &\defiff \lforall {a \in A}     {u \ast a = a}\\
\text{$u$ é uma $\ast$-identidade direita}      &\defiff \lforall {a \in A}     {a \ast u = a}\\
\text{$u$ é uma $\ast$-identidade}              &\defiff \lforall {a \in A}     {u \ast a = a = a \ast u}\\
\text{$y$ é um $\ast$-inverso esquerdo de $g$}  &\defiff \text{$y \ast g = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso direito de $g$}   &\defiff \text{$g \ast y = e$, \ onde $e$ é uma $\ast$-identidade}\\
\text{$y$ é um $\ast$-inverso de $g$}           &\defiff \text{$y \ast g = e = g \ast y$, \ onde $e$ é uma $\ast$-identidade}
\endalign
$$
onde não escrevemos os ``$\ast$-'' quando são implícitos pelo contexto.

%%}}}

%%{{{ operating_on_an_empty_list_of_objects 
\note Operando numa lista vazia de objetos.
%%%{{{ meta 
\label operating_on_an_empty_list_of_objects
%%%}}}

Suponha que para algum $k\in\nats$ temos uns objetos
$$
a_0,a_1,\dotsc,a_{k-1}
$$
definidos.  Ou seja, temos $k$ objetos.
O que seria o resultado operando eles entre si?
Isso é algo que denotamos por
$$
a_0 \ast a_1 \ast \dotsb \ast a_{k-1}
\qqqqtext{ou}
a_0 a_1 \dotsb a_{k-1}.
$$
Como \emph{a operação associativa}, essa expressão faz sentido,
assim sem parênteses, para qualquer $k>0$.
E, se \emph{a operação tem identidade}, então ela é definida até
para o caso extremo de $k=0$.
Se $k=0$ temos uma lista de $0$ membros para operar.
E realmente definimos esse resultado para ser a identidade da operação.

%%}}}

%%{{{ df: rel_fechado 
\definition.
%%%{{{ meta 
\label rel_fechado
%%%}}}

Seja $R$ uma relação num conjunto $A$ e $X \subset A$.
Chamamos o $X$ de \dterm{$R$-fechado}
sse para todo $x \in X$, e todo $a \in A$
com $x \rel R a$, temos $a \in X$ também.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\TODO Maybe have a first contact with $\sigma$-rings, $\sigma$-fields, topologies, {etc.}.

%%{{{ prob: set_liminf_limsup_problem 
\problem.
%%%{{{ meta 
\label set_liminf_limsup_problem
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos os conjuntos
\mathcols 2
A_* &= \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
A^* &= \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endmathcols
É verdade que um desses conjuntos é subconjunto do outro?
São iguais?  São disjuntos?

\hint
Podemos demonstrar que $A_* \subset A^*$.

\hint
Use as definições, passo a passo.

\solution
Vamos demonstrar que $A_* \subset A^*$.
\eop
Seja então $x\in A_* = \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j$.
Logo seja $i_0 \in \nats$ tal que $x \in \Inter_{j=i_0}^{\infty} A_j$.
Sabemos então que
$$
\lforall {j \geq i_0} {x \in A_j}.   \tag{*}
$$
Queremos demonstrar que $x\in A^* = \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j$.
Seja então $n_0\in\nats$.
Agora basta demonstrar que
$$
x \in \Union_{j=n_0}^{\infty} A_j.
$$
Em outras palavras, procuramos um $k\in\nats$ que satisfaz: $k \geq n_0$ e $x \in A_k$.
Tome $k \asseq \max\set{i_0, n_0}$ e observe que esse $k$ satisfaz ambas as condições.
Pela escolha de $k$ a primeira condição é satisfeita imediatamente.
Sobre a segunda, como $k \geq i_0$, pela (*) temos que $x \in A_k$,
que foi o que queremos demonstrar.

%%}}}

%%{{{ prob: set_liminf_limsup_problem_heart_level 
\problem Nível coração.
%%%{{{ meta 
\label set_liminf_limsup_problem_heart_level
%%%}}}

Entenda no teu coração o que tu demonstraste no~\ref[set_liminf_limsup_problem].
Como descreverias os elementos dos $A_*$ e $A^*$?
Explique com ``palavras da rua'' justificando o resultado obtenido.

\hint
Comece rascunhando os dois lados, usando \symq{$\dotsb$}, etc.

\hint
Vamos primeiramente analisar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência.
Quais são?

\hint
Os primeiros membros são:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Faça a mesma coisa sobre o $A^* = \Inter_i \Union_{j\geq i} A_j$.

\hint
Cada um desses membros também é uma intersecção ou união duma seqüência.
Escrava cada uma delas como uma expressão que envolve \symq{$\dotsb$}.

\hint
Temos:
$$
\xalignat2
A_* &= \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
A^* &= \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
E agora precisamos \emph{entender} as proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
para enxergar se uma implica a outra, etc.

\hint
O que podemos concluir sobre a \emph{quantidade} dos $A_n$'s que
$x$ pertence, sabendo a primeira?  O que sabendo a segunda?

\hint
Em ambos os casos podemos concluir que $x$ pertence a uma quantidade
infinita de $A_i$'s, então isso não é suficiente para nosso objectivo.
A segunda proposição realmente é \emph{equivalente} a essa afirmação,
ou seja:
$$
x \in A^* \iff \text{$x$ pertence a uma quantidade infinita de $A_n$'s}.
$$
Mas a primeira afirma algo \emph{mais forte}, ou seja, realmente
$$
x \in A_* \implies x \in A^*.
$$
Mas para enxergar isso precisamos entender qual é toda a informação
que a proposição \symq{$x \in A^*$} contem:
$$
x \in A_* \iff \askdots
$$

\hint
Se $x \in A_*$, a quantos dos $A_n$'s pode ser
que o $x$ \emph{não} pertence?
E se $x \in A^*$?

\solution
A idéia é entender o que cada uma das proposições
$$
\xalignat2
x &\in A_* &
x &\in A^*
\endxalignat
$$
quis dizer, para enxergar se uma implica a outra, etc.
Como já demonstramos ``mecanicamente'' no~\ref[set_liminf_limsup_problem]
que $A_* \subset A^*$, queremos então chegar na conclusão que
$$
x \in A_* \implies x \in A^*
$$
num caminho diferente: do coração.
\eop
Vamos primeiramente analisar o $A_* = \Union_i \Inter_{j\geq i} A_j$.
É uma união duma seqüência de conjuntos, então faz sentido observar
pelo menos os primeiros membros dessa seqüência:
$$
\Inter_{j\geq 0} A_j, \quad
\Inter_{j\geq 1} A_j, \quad
\Inter_{j\geq 2} A_j, \quad
\dotsc
$$
Cada um desses membros também é uma intersecção duma seqüência.
Vamos escrever numa maneira que deixa os primeiros termos vizíveis:
$$
\align
\Inter_{j\geq 0} A_j &= A_0 \inter A_1 \inter A_2 \inter \dotsb \\
\Inter_{j\geq 1} A_j &= A_1 \inter A_2 \inter A_3 \inter \dotsb \\
\Inter_{j\geq 2} A_j &= A_2 \inter A_3 \inter A_4 \inter \dotsb \\
&\eqvdots
\endalign
$$
Trabalhando dualmente no $A^*$, chegamos nas:
$$
\xalignat2
x &\in \Union \set{
\aligned
A_0 \inter A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
           A_1 \inter A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                      A_2 \inter A_3 \inter A_4 \inter {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \inter {}} & \\
\endaligned
}
&
x &\in \Inter \set{
\aligned
A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
           A_1 \union A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                      A_2 \union A_3 \union A_4 \union {}           & {} \dotsb \\
                                     \ddots \phantom{A_4 \union {}} & \\
\endaligned
}
\endxalignat
$$
Sabendo a primeira concluimos que $x$ pertence a \emph{pelo menos uma}
das linhas da esquerda, vamos dizer a $u$-ésima, ou seja
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
Logo sabemos que
$$
\text{$x$ pertence a todos os $A_u, A_{u+1}, A_{u+2}, \dotsc$}.
$$
Em outras palavras:
\emph{a partir dum ponto, $x$ pertence a todos os membros da seqüência original}.
Demonstramos então que
$$
x \in A_* \implies \text{a partir dum ponto, $x$ pertence a todos os $A_n$'s}.
$$
Vamos demonstrar o converso agora.
Suponha que a partir dum $u\in\nats$, sabemos que $x$ pertence a todos os
$A_u, A_{u+1}, A_{u+2}, \dotsc$, ou seja,
$$
x \in A_u \inter A_{u+1} \inter A_{u+2} \inter \dotsb
$$
ou seja, achamos uma linha onde $x$ pertence e logo $x \in A_*$.
\eop
Agora a segunda proposição ($x \in A^*$)
concluimos que $x$ pertence a \emph{todas} as linhas
da direita, ou seja:
$$
\alignat 2
x &\in {}& A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
Observe que a $j$-ésima linha afirma que
\emph{mesmo depois de andar $j$ passos na seqüência,
ainda terá $A_n$'s com $x$ neles}.
Sabendo então que cada uma dessas linhas é verdade, podemos concluir
que $x$ pertence a uma infinidade dos $A_n$'s, e vice versa:
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Vamos demonstrar isso.
\eop
\lrdir:
Temos como hipótese todas as
$$
\alignat 2
x &\in {}& A_0 \union A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&            A_1 \union A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
x &\in {}&                       A_2 \union A_3 \union A_4 \union {}    & {} \dotsb \\
  &\eqvdots
\endalignat
$$
e queremos mostrar que $x$ pertence a uma infinidade dos $A_n$'s.
Basta mostrar que para qualquer ``desafio'' $v\in\nats$,
$x$ pertence àlgum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Seja $v\in\nats$ então.
Olha na $v$-ésima linha e é exatamente o que queremos.
\eop
\rldir:
Agora sabendo que $x$ pertence a uma quantidade infinita de $A_n$'s precisamos
mostrar que
$$
\text{para todo $v\in\nats$},
\quad
x \in A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
Seja $v\in\nats$ então.
Para chegar num absurdo, suponha que
$$
x \nin A_v \union A_{v+1} \union A_{v+2} \union \dotsb
$$
ou seja, $x$ não pertence a nenhum dos $A_v, A_{v+1}, A_{v+2}, \dotsc$.
Mas isso quis dizer que $x$ pertence no máximo em $v$ dos $A_n$'s,
contradizendo nossa hipótese que $x$ pertence numa infinidade deles.
\eop
Concluimos então que
$$
x \in A^* \iff \text{$x$ pertence a uma infinidade dos $A_n$'s}.
$$
Como comparam essas afirmações?
\tlist:
\li: $x\in A_*$: a partir dum ponto, $x$ pertence a todos os $A_n$'s;
\li: $x\in A^*$: $x$ pertence a uma infinidade dos $A_n$'s.
\endtlist
Deve ser óbvio que
$$
x \in A_* \implies x \in A^*.
$$
E como já entendemos o que cada proposição quis dizer mesmo,
podemos facilmente demonstrar que o converso não é sempre
válido.
Para um contraexemplo onde
$$
x \in A_* \nimpliedby x \in A^*
$$
considere a seqüência
$$
\align
A_0 &= \set {0} \\
A_1 &= \set {0,1} \\
A_2 &= \set {0} \\
A_3 &= \set {0,1} \\
A_4 &= \set {0} \\
A_5 &= \set {0,1} \\
    &\eqvdots
\endalign
$$
Observe que os $0,1$ são aqueles que pertencem a uma infinidade dos $A_n$'s.
Mas apenas o $0$ pertence a todos os $A_n$'s a partir dum certo ponto.

%%}}}

%%{{{ prob: set_liminf_limsup_problem_not_converse 
\problem.
%%%{{{ meta 
\label set_liminf_limsup_problem_not_converse
%%%}}}

Demonstre que a inclusão conversa não é sempre válida.
Ou seja: construa seqüência de conjuntos $\seqn A n$ tal que
$$
A_* \psubset A^*.
$$
Podes construir uma tal que ambos os $A_*, A^*$ são infinitos
e cada um dos $A_n$'s é um subconjunto finito de $\nats$?

\solution
Sem a restricção uma tal seqüência seria a
$$
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\emptyset,  \quad
\set{1},    \quad
\dotsc
$$
Assim temos $A_* = \emptyset$ e $A^* = \set{1}$.
\eop
Para satisfazer a restricção, considere a seqüência:
$$
A_n =
\knuthcases {
\setstt {k \leq n} {$k$ é primo}, & se $n$ par; \cr
\setstt {k \leq n} {$k$ é ímpar}, & caso contrário.
}
$$
Seus primeiros termos:
$$
\xalignat 2
A_0 &= \emptyset            & A_1 &= \set{1} \\
A_2 &= \set{2}              & A_3 &= \set{1,3} \\
A_4 &= \set{2,3}            & A_5 &= \set{1,3,5} \\
A_6 &= \set{2,3,5}          & A_7 &= \set{1,3,5,7} \\
A_8 &= \set{2,3,5,7}        & A_9 &= \set{1,3,5,7,9} \\
    &\eqvdots               &     &\eqvdots
\endxalignat
$$
Nesse caso,
$$
\alignat2
A_* &= \set{3, 5, 7, 11, 13, 17, \dotsc}      &&= \setstt {n\in\nats} {$n$ é um primo ímpar} \\
A^* &= \set{1, 2, 3, 5, 7, 9, 11, 13, \dotsc} &&= \setstt {n\in\nats} {$n=2$ ou $n$ ímpar}.
\endalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os $A_*$ e $A^*$ do \ref[set_liminf_limsup_problem]
merecem seus próprios nomes!

%%}}}

%%{{{ df: set_limits 
\definition.
%%%{{{ meta 
\label set_limits
\defines
    * \lim_{~n} {~{A_n}}  -- o limite da seqüência $\seqn A n$
    * \liminf_{~n} {~{A_n}}  -- o limite inferior da seqüência de conjuntos $\seqn A n$
    * \limsup_{~n} {~{A_n}}  -- o limite superior da seqüência de conjuntos $\seqn A n$
    * limite!de seqüência de conjuntos
    * limite!de seqüência de conjuntos
    ;;
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Definimos seu \dterm{limite inferior} e seu \dterm{limite superior} pelas:
$$
\xalignat2
\liminf_n A_n &\defeq \Union_{i=0}^{\infty} \Inter_{j=i}^{\infty} A_j &
\limsup_n A_n &\defeq \Inter_{i=0}^{\infty} \Union_{j=i}^{\infty} A_j.
\endxalignat
$$
Note que pelo~\ref[set_liminf_limsup_problem] sabemos se um é subconjunto
de outro ou não.  Mas pode ser que os dois conjuntos são iguais.
Digamos que a seqüência de conjuntos $\seqn A n$ \dterm{converge} sse
$$
\liminf_n A_n = \limsup_n A_n.
$$
Nesse caso, chamamos esse conjunto de \dterm{limite} da $\seqn A n$
e usamos a notação $\lim_n A_n$ para denotá-lo.

%%}}}

%%{{{ df: increasing_decreasing_sequence 
\definition.
%%%{{{ meta 
\label increasing_decreasing_sequence
%%%}}}

Seja $\seqn A n$ uma seqüência de conjuntos.
Dizemos que $\seqn A n$ é uma \dterm{seqüência crescente} sse
$A_i \subset A_{i+1}$ para todo $i\in \nats$.
Similarmente, $\seqn A n$ é uma \dterm{seqüência decrescente} sse
$A_i \supset A_{i+1}$ para todo $i\in \nats$.
Rascunhamente:
$$
\align
\text{$\seqn A n$ crescente}
&\defiff A_0 \subset A_1 \subset A_2 \subset \cdots \\
\text{$\seqn A n$ decrescente}
&\defiff A_0 \supset A_1 \supset A_2 \supset \cdots
\endalign
$$
Uma seqüência é \dterm{monótona} (ou \dterm{monotônica}) sse
ela é crescente ou decrescente.

%%}}}

%%{{{ prob: monotone_sequences_have_limits 
\problem.
%%%{{{ meta 
\label monotone_sequences_have_limits
%%%}}}

Seja $\seqn A n$ uma seqüência monótona.
Demonstre que $\seqn A n$ tem limite.
Qual é?

%%}}}

%%{{{ prob: sandwich_breads_are_monotone_and_optimal 
\problem Os pães do sanduíche são monótonos e ótimos.
%%%{{{ meta 
\label sandwich_breads_are_monotone_and_optimal
%%%}}}

No~\ref[sandwiching_a_set_sequence] definimos duas seqüências
\dq{sanduichando} a $\seqn A n$: uma crescente (a $\seqn C n$)
e uma decrescente (a $\seqn D n$).
Pelo~\ref[monotone_sequences_have_limits] então ambas
têm limites, e realmente temos
$$
\limit_n C_n = \liminf_n A_n \subset \limsup_n A_n = \limit_n D_n.
$$
Ainda mais é verdade:
de todas as seqüências crescentes, $\seqn C n$ é a maior tal que
$C_n\subset A_n$ para todo $n\in\nats$; e similarmente
de todas as decrescentes, $\seqn D n$ é a menor tal que
$A_n\subset D_n$ para todo $n\in\nats$.
Formalize o que significam as palavras ``maior'' e ``menor''
na afirmação acima, e demonstre sua veracidade.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Podes achar boas explicações, dicas, muitos exemplos resovidos,
e exercícios e problemas para resolver no \cite[velleman: \S1.3~\&~\S2.4].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Functions 
\chapter Funções.
%%%{{{ meta 
\label Functions
%%%}}}

% BABY

%%{{{ intro 
\chapintro
Neste capítulo estudamos mais um \emph{tipo} importantíssimo e fundamental em
matemática: a \emph{função}.
Nosso objectivo aqui é familiarizar-nos com funções,
entender como podemos defini-las, usá-las, combiná-las para criar novas,
operar nelas, etc.
\eop
Vamos brincar com a poderosa \emph{notação lambda do λ-calculus}
(\reftag[A_touch_of_lambda]), e com funções de \emph{ordem superior}
(\reftag[Higher_order_functions])
e apreciar que graças a \emph{currificação}~(\reftag[Currying]) nem
precisamos funções de aridades maiores que $1$.
Aqui aprendemos também o que são mesmo os
\emph{diagramas comutativos}~(\reftag[Commutative_diagrams]),
ferramentas que vamos usar constantemente a partir de agora!
Estudamos também o que realmente significa definir funções
\emph{recursivamente}~(\reftag[Recursive_definitions_as_systems]),
algo que temos feito ``sem pensar'', baseados na nossa intuição e no
nosso insticto muitas vezes até agora.
Finalmente~(\reftag[Categories_a_first_taste])
teremos nosso primeiro contato com \emph{categorias}, que oferecem uma abordagem
e linguagem unificativa para diversos cantos de matemática (e mais).
(O~\ref[Category_theory] e dedicádo na teoria das categorias.)
\eop
Bem depois, no~\ref[Set_theory], vamos nos preocupar com
a questão de \emph{como implementar} esse tipo (o tipo de funções),
\emph{como fundamentar} esse conceito---mas esqueça isso por enquanto.
Primeiramente precisamos entender bem o que é uma função e como se comporta.
E muitas ferramentas relevantes.
Bora!
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
\label Function_contept
%%%}}}

%%{{{ unlabeled black box for function 
\note Black boxes.
%%%{{{ meta 
\indexes
    * funcção!como black box    see: black box
    ;;
\defines
    * black box!de funcção
    ;;
%%%}}}

Começamos imaginando funções como black boxes;
parecidos mas diferentes daqueles que usamos para conjuntos
(\reftag[blackbox_set]), pois essas caixas têm uma entrada mas
também uma saída própria:
$$
\tikzpicture
\tikzi blackboxfun;
\endtikzpicture
$$

%%}}}

%%{{{ prim: function_primitive 
\primitive função.
%%%{{{ meta 
\label function_primitive
\indexes
    * domínio!de função    see: função
    * codomínio!de função  see: função
    * target!de função     see: função
    * source!de função     see: função
    ;;
\defines
    * função!definição intuitiva
    * função!domínio
    * função!codomínio
    * função!valor
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos $f$ uma \dterm{função de $A$ para $B$}, sse
para todo $x \in A$, o símbolo $f(x)$ é definido e $f(x)\in B$.
O $f(x)$ é o \dterm{valor} da $f$ no $x$.
O \dterm{domínio} ou \dterm{source} da $f$ é o conjunto $A$,
e seu \dterm{codomínio} ou \dterm{target} é o conjunto $B$.
Consideramos então que a função $f$ associa \emph{para todo} elemento $a \in A$,
\emph{exatamente um} elemento $f(a) \in B$.

%%}}}

%%{{{ df: function_notation 
\definition.
%%%{{{ meta 
\label function_notation
\defines
    * \src {~f}  -- o source da função $f$
    * \tgt {~f}  -- o target da função $f$
    * \dom {~f}  -- o domínio da função $f$
    * \cod {~f}  -- o codomínio da função $f$
    * ~A \toby {~f} ~B  -- $f$ é uma função de $A$ para $B$
    * ~f : ~A \to ~B    -- $f$ é uma função de $A$ para $B$
    * ponto!de conjunto
    ;;
%%%}}}

Escrevemos
$$
f : A \to B
\qqqqtext{e sinonimamente}
A \toby f B
$$
para dizer que \emph{$f$ é uma função de $A$ para $B$},
e escrevemos
$$
x \mapstoby f y
$$
para dizer que \emph{$f$ mapeia o $x$ para o $y$}.
Definimos também as operações $\dom$ e $\cod$
que retornam o domínio e o codomínio do seu argumento.
Resumindo:
$$
f : A \to B
\quad\defiff\quad
\text{$f$ é uma função}
\;\mland\;
\dom f = A
\;\mland\;
\cod f = B.
$$
Escrevemos $\src(f)$ e $\tgt(f)$ como sinônimos
de $\dom(f)$ e $\cod(f)$ respectivamente.
Às vezes o tipo da função aparece olhando para a direção oposta:
$f : B \from A$ em vez de $f : A \to B$.
Escrevemos também $f\app x$ em vez de $f(x)$,
e em certos casos (mais raros) $f_x$ ou $x^f$ ou até $x\app f$.
Podemos referir aos membros do domínio e do codomínio duma
função como \dterm{pontos} desses conjuntos.

%%}}}

%%{{{ remark: explicit_application 
\remark.
%%%{{{ meta 
\defines
    * ~f \at ~x  -- notação explícita para o $f(x)$
    * função!aplicação
    ;;
%%%}}}

Quando escrevemos \sq{$f\app x$} (ou \sq{$f(x)$}),
estamos escrevendo algo que representa a \dterm{aplicação}
da $f$ no $x$.
(E o que estamos denotando é o \dterm{valor} da $f$ no $x$.)
O símbolo da aplicação é invisível, ou seja, a aplicação é denotada
pela justaposição do nome da função (aqui \sq{$f$}) e do nome
do seu argumento (aqui \sq{$x$}).
(já discutimos isso no~\ref[clearer_functional_notation]).
Quando precisamos vê-la mesmo na nossa sintaxe podemos usar
a notação infixa
$$
f \at x \sugeq f (x).
$$

%%}}}

%%{{{ f : A -> B  and  A --f--> B  notations 
\note.
%%%{{{ meta 
%%%}}}

Escrevemos ``sejam $f,g : A \to B$'' e entendemos como:
``sejam funções $f$ e $g$ de $A$ para $B$'', e (abusando) se não temos já
declarados os conjuntos $A,B$, a mesma frase entendemos com um implícito
``sejam conjuntos $A,B$ e funções \dots''.
Do mesmo jeito, a frase
$$
\text{<<{Sejam $A \toby f B \toby g C$.}>>}
$$
pode ser equivalente à frase
$$
\text{<<{Sejam conjuntos $A,B,C$, e funções $f:A\to B$ e $g:B\to C$.}>>}
$$
Espero que dá para apreciar a laconicidade dessa notação.

%%}}}

%%{{{ function vs. application of function 
\note Função \vs aplicação de função.
%%%{{{ meta 
%%%}}}

Em matemática muitas vezes falamos frases como as seguintes:
$$
\gather
\text{<<a função $\sin(x)$ é periódica>>}, \\
\text{<<a função $f(t)$ é monótona>>}, \\
\endgather
$$
etc.  Literalmente estamos falando algo errado!
As funções, nesse exemplo, são as $\sin$ e $f$, não as $\sin(x)$ e $f(t)$.
Denotamos por $\sin(x)$ o \emph{valor} da função $\sin$ no ponto $x$,
e com $f(t)$ o \emph{valor} da função $f$ no ponto $t$.
Claramente, esse ``erro'' é algo que não vai confundir nenhum matemático,
e com a mínima maturidade matemática não vamos encontrar problema nenhum
trabalhando assim.
Entendemos então que é apenas um ``modo de falar'' usado em certos casos.
Mas aqui nosso objectivo é estudar e \emph{fundamentar} bem a idéia e a ``alma''
dos vários tipos matemáticos, e não podemos nos permitir nenhum abuso desse tipo!
Essa distinção vai ficar ainda mais crucial, com a notação de λ-calculus
e com as funções de ordem superior.

%%}}}

%%{{{ The type of a function 
\note O tipo duma função.
%%%{{{ meta 
%%%}}}

Seja $f : A \to B$.
Chamamos o \sq{$A \to B$} o tipo da $f$, e pronunciamos
\utter{função de $A$ para $B$}.

%%}}}

%%{{{ x: what_is_the_type_of_foo_for_C_programmers 
\exercise.
%%%{{{ meta 
\label what_is_the_type_of_foo_for_C_programmers
\indexes
    * C
    * C++
    * Java
    ;;
%%%}}}

Aqui um programa escrito em C:
\sourcecode typefoo.c;
Qual é o tipo desse $\code{x}$ no corpo da $\code{foo}$?
Qual o tipo da $\code{foo}$?
Cuidado: programadores de C (e C++, Java, etc.) tendem errar nessa última questão!

\hint
O tipo de $\code{foo}$ não é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.

\solution
O tipo de $\code{x}$ é $\code{int}$.
O tipo de $\code{foo}$ é: ``função de $\code{int}$ para $\code{int}$''.
Programadores de $C$ muitas vezes erram nessa terminologia, dizendo que o tipo de $\code{foo}$ é $\code{int}$.
Se fosse $\code{int}$ mesmo, o $\code{foo}$ seria um $\code{int}$.
O que eles querem dizer é que o \emph{return type} de $\code{foo}$ é $\code{int}$, e isso tá certo.
Mas a pergunta foi identificar o \emph{tipo} de $\code{foo}$.

%%}}}

%%{{{ a_taste_of_type_inference 
\note Um toque de inferência de tipos.
%%%{{{ meta 
\label a_taste_of_type_inference
%%%}}}

Sabendo que $f : A \to B$ e $x : A$, o que podemos inferir?
A resposta óbvia aqui é essa:
$$
\PROOFmr {
\A {f \is A \to B}    \A {x \is A}
\I2------------------------------- {FunApp}
         {f \fa x \is B}
}
$$
Escolhi chamar essa regra de \namedrule{FunApp} de ``Function Application'',
talvez dando a impressão errada que é uma regra muito original
e nova, que nunca a encontramos antes mas\dots
isso seria mentira:

%%}}}

%%{{{ x: curry_howard_teaser_exercise 
\exercise.
%%%{{{ meta 
\label curry_howard_teaser_exercise
%%%}}}

Bem antes de estudar funções, a gente
encontrou a ``mesma'' regra, só que com
roupas diferentes, mas nem tanto!
De que eu tô falando?

\hint
Já que falei que isso foi bem antes de estudar funções,
apague da
$$
\PROOFm {
\A {f \is A \to B}    \A {x \is A}
\I2------------------------------- {FunApp}
         {f \fap x \is B}
}
$$
as partes que têm a ver com funções:
$$
\PROOFm {
\A {\aR{f \is{}} A \to B}    \A {\aR{x \is {}}A}
\I2----------------------------------------------------- {\aR{FunApp}}
               {\aR{f \fap x \is{}} B}
}
$$

\solution
Esquecendo as partes que têm a ver com funções chegamos na regra
$$
\PROOFm {
\A {A \to B}    \A {A}
\I2-------------------- {ModusPonens?!}
           {B}
}
$$
que é\dots a modus ponens (\ref[modus_ponens]) mesmo?
A regra de como usar implicação?!
Sim.  Continue lendo o texto agora.

%%}}}

%%{{{ teaser: curry_howard_teaser 
\teaser Curry--Howard.
%%%{{{ meta 
\label curry_howard_teaser
\credits
    * Curry : --Howard
    * Howard : --Curry
    ;;
\indexes
    * Curry--Howard!teaser
    ;;
%%%}}}

O que tu acabou de descobrir no~\ref[curry_howard_teaser_exercise]
é uma manifestação duma \emph{conexão muito profunda entre lógica
e computação}, conhecida como \dterm{correspondência Curry--Howard},
ou também \dterm{propositions-as-types and proofs-as-programs interpretation}.
A idéia é que podemos ver tipos de funções como proposições e vice versa.
E nesse caso \emph{definir uma função} de certo tipo e \emph{demonstrar}
a correspondente proposição são ações equivalentes.
Com esse ponto de vista as demonstrações são objetos \emph{bem vivos!}
Podemos executá-las (pois são programas), observar sua execução
e receber a informação que elas retornam.
Espero que isso não é \emph{tão} surpresa, pois já tenho dado muitos
spoilers e elaborado essa dinámica de demonstrações desde os primeiros
capítulos, especialmente no~\ref[Proofs].
Estudando programação funcional, lógica intuicionista, teoria das demonstrações,
e teoria dos tipos, tudo isso vai fazer mais sentido, e essa correspondência
vai acabar sendo um dos assuntos mais importantes do nosso estudo nesse texto!
Por enquanto paciêcia\dots

%%}}}

%%{{{ df: funs_set 
\definition.
%%%{{{ meta 
\label funs_set
\defines
    * \funs {~A} {~B}  -- o conjunto das funções de $A$ para $B$
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Denotamos por $\funs A B$ o conjunto das funções de $A$ para $B$:
$$
f \in \funs A B \defiff {f : A \to B}.
$$
O mesmo conjunto denotamos também por $B^A$.

%%}}}

%%{{{ x: size_of_funs 
\exercise.
%%%{{{ meta 
\label size_of_funs
%%%}}}

Por quê?
Supondo que os $A,B$ são finitos, justifique a notação $B^A$
para o conjunto $\funs A B$.
(Primeiro objetivo desse exercício então é entender o que significa
\emph{justificar uma notação} nesse caso.)

\hint
Cardinalidade.

\hint
Se por acaso $\size{\funs A B} = {\size B}^{\size A}$,
isso seria uma justificativa boa para a notação $B^A$.
(Lembra da $\size{A \times B} = {\size A}\ntimes{\size B}$?)

\solution
Temos $\size A$ coisas para definir até determinar uma função de $A$ para $B$.
Para cada uma delas (para cada $a\in A$) temos $\size B$ opções para mandá-lo
(nossas escolhas não afetam a quantidade de opções que teremos nas próximas).
Logo pelo princípio da multiplicação
$$
\size{\funs A B} = {\size A}^{\size B}.
$$

%%}}}

%%{{{ Conditions: functionhood_conditions 
\note Condições de funcionalidade.
%%%{{{ meta 
\label functionhood_conditions
\defines
    * funcionalidade!condições
    * função!determinabilidade
    * função!totalidade
    ;;
\indexes
    * univocidade    see: determinabilidade
    ;;
%%%}}}

Na~\ref[function_primitive] aparece a frase
\wq{o símbolo $f(x)$ é definido}.
Com isso entendemos que não existe ambigüidade, ou seja, para uma entrada $x$,
a $f$ não pode ter mais que uma saída.
E graças a outra frase, \wq{para todo $x\in A$}, sabemos que tem
\emph{exatamente uma} saída.  Esta saída é o que denotamos por $f(x)$.
Resumindo:
\eop\noi
Para todo $x\in\dom f$,
\tlist:
\li (F-Tot):totality
existe pelo menos um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{totalidade});
\li (F-Det):determinacy
existe no máximo  um $y\in\cod f$ tal que $x \mapstoby f y$ (\dterm{determinabilidade}).
\endtlist
Quando a \ref[totality] acontece dizemos que
\emph{a $f$ é definida em todo o seu domínio}.
Usamos o termo \dterm{univocidade} como sinônimo de determinabilidade.

%%}}}

%%{{{ Arity and tuples 
\note Aridade e tuplas.
%%%{{{ meta 
\indexes
    * aridade
    ;;
%%%}}}

No jeito que ``definimos'' o que é uma função, ela só pode depender
em apenas um objeto, apenas uma entrada.
Isso parece bastante limitante, pois estamos já acostumados
com funções com aridades diferentes.\foot
Lembra-se que \dterm{aridade} é a quantidade de argumentos-entradas.
\toof
Caso que uma função precisa mais que um argumento como entrada,
usamos a notação $f(x_1, \dotsc, x_n)$.
Identificamos isso com uma função que recebe ``apenas um'' objeto
como entrada: a $n$-tupla $\tup{x_1,\dotsc,x_n}$.
Então identificamos as notações
$$
\gather
f(x_1,\dotsc,x_n) = f( \tup{x_1,\dotsc,x_n} ) = f \tup{x_1,\dotsc,x_n}\\
f(x)              = f( \tup{x} )              = f \tup{x} = f \app x\\
f()               = f( \tup{}  )              = f \tup{}
\endgather
$$
onde na última linha às vezes identificamos com o próprio $f$
também---quando não existe possibilidade de confusão---mas vamos evitar
isso aqui.
\eop
Similarmente, se queremos ``retornar'' mais que um objeto,
podemos ``empacotar'' todos eles numa tupla, e retornar apenas essa tupla,
satisfazendo assim a demanda de unicidade de função---cuidado pois isso
tem que ser refletido no codomínio da função!

%%}}}

%%{{{ Synonyms 
\note Sinônimos.
%%%{{{ meta 
\indexes
    * operador        seealso: função
    * operação        seealso: função
    * procedimento    seealso: função
    * mapa            see: função
    * mapeamento      see: função
    * map             see: função
    * transformação   see: função
    ;;
\defines
    * função!sinônimos
    ;;
%%%}}}

Lembra que usamos várias palavras como sinônimos de ``conjunto''?
(Quais?)
Pois é, para funções a situação é parecida.
\emph{Dependendo do contexto e da ênfase},
as palavras seguintes podem ser usadas como
sinônimos de ``função'':
mapeamento,
mapa,
map,
operação,
operador,
transformação,
etc.

%%}}}

%%{{{ Intension vs. extension 
\note Intensão \vs extensão.
%%%{{{ meta 
\label intension_vs_extension_in_functions
%%%}}}

Como nos conjuntos (\ref[Intension_vs_extension_in_sets]),
temos novamente a idéia de \dterm{intensão} e \dterm{extensão} de uma função.
Pensando uma função como uma caixa que dentro dela tem um \emph{programa},
a extensão dela não seria o que ela faz mesmo internalmente (isso seria sua
\emph{intensão}), mas o que ela \emph{consegue}.
Imaginando duas ``caixas pretas'' $f$ e $g$ onde podemos apenas observar
seus comportamentos usando as suas interfaces e nada mais, faz sentido
considerar iguais aquelas que não conseguimos demonstrar nenhum comportamento diferente.
Ou seja: qualquer entrada \emph{aceitável} para uma, deve ser \emph{aceitável}
para a outra também (pois, se não, isso já seria uma diferença observável);
e ainda mais, para a mesma entrada, as funções têm de atribuir o mesmo
valor---novamente: se não, isso já seria um comportamento diferente e
observável.

%%}}}

%%{{{ Programs vs. functions 
\note Programas \vs funções.
%%%{{{ meta 
\label programs_vs_functions
\indexes
    * Python
    ;;
%%%}}}

Considere as duas funções $\code{f}$ e $\code{g}$ implementadas
no programa seguinte em Python:
\sourcecode intext.py;
Suponha que queremos considerar ambas definidas nos inteiros.
A \emph{extensão} da $\code{f}$ é a mesma com a extensão da $\code{g}$.
Ou seja, como funções, temos $f = g$.
Suas \emph{intensões} são diferentes.
A primeira função, dado um número grande vai fazer bem mais operações até
finalmente retornar um valor.
Tente calcular as duas no interpretador de Python e também perceberás uma diferença
no tempo que cada uma precisa: compare os
$\code{f(1000000000)}$ e $\code{g(1000000000)}$.
Os \emph{programas} então são diferentes (pois num programa é a intensão que importa)
mas as funções são iguais.
Note que quando observamos caixas pretas, não podemos nem medir o tempo que
cada uma precisa para responder com seu valor, nem podemos tocar elas para ver
qual ficou mais quente, nem escutar para possíveis barulhos, etc.
Podemos apenas dar uma entrada e observar a saída e nada mais!

%%}}}

%%{{{ What about the codomain? (I) 
\note E o codomínio? (I).
%%%{{{ meta 
\label what_about_the_codomain_1
%%%}}}

Em matemática clássica, e especialmente em teoria de
conjuntos~(\ref[Set_theory]) e análise,
em geral não consideramos que o codomínio duma função ``faz parte dela''.
Ou seja, a mesma função $\sin$, por exemplo, pode ser considerada como
$$
\xalignat3
\sin_1 &: \reals\to\reals     &
\sin_2 &: \reals\to[-1,1]     &
\sin_3 &: \reals\to(-\infty,2).
\endxalignat
$$
Para esse matemático então, \emph{o codomínio não é algo observável:}
como tu vai diferenciar entre as $\sin_1, \sin_2, \sin_3$ acima,
se tua única interface é dando objetos para elas, e observando seus valores (saídas)?
Pois é, não tem como.
Por outro lado, se alterar os domínios isso já é uma diferença demonstrável
(observável) com essa mesma única interface.

%%}}}

%%{{{ x: how? 
\exercise.
%%%{{{ meta 
%%%}}}

Como?

\hint
O que significa que os domínios de duas funções são diferentes?

\solution
Se $f : A \to B$ e $g : C \to D$ são funções com $A\neq C$,
pela definição de igualdade de conjuntos, existe $x \in A\symdiff C$.
Para esse $x$, as funções vão comportar diferentemente.
Se $x \in A$ (e logo $x\nin C$), a $f$ vai aceitar o $x$
e vamos observar sua saída $f(x)$, mas a $g$ não vai aceitar
o $x$, e assim não vamos ver nenhuma saída;
Similarmente, se $x \in C$ (e logo $x\nin A$).

%%}}}

%%{{{ dom_and_cod_recoverable_or_not 
\note Recuperável ou não?.
%%%{{{ meta 
\label dom_and_cod_recoverable_or_not
%%%}}}

Com esse ponto de vista, o domínio é um conjunto \emph{recuperável}
pela própria função $f$, pois podemos definir:
$$
\dom f
\defeq
\setst x {\lexists y {x \mapstoby f y}}.
$$
Mas o codomínio não!

%%}}}

%%{{{ x: cod_wrongdef 
\exercise.
%%%{{{ meta 
\label cod_wrongdef
%%%}}}

Qual o problema com essa suposta definição de codomínio de uma função $f$?:
$$
\cod f
\defeq
\setst y {\lexists x {x \mapstoby f y}}.
$$

\hint
Aplique a $\cod$ nos $\sin_1,\sin_2,\sin_3$ do \ref[what_about_the_codomain_1].

\solution
Aplicando essa definição de $\cod$ nas $\sin_1,\sin_2,\sin_3$ do \ref[what_about_the_codomain_1],
temos que
$$
\cod (\sin_1)
= \cod (\sin_2)
= \cod (\sin_3)
$$
mesmo que claramente não foi essa a nossa intenção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O conjunto definido no~\ref[cod_wrongdef] realmente é interessante
e importante, só que ele não é (necessariamente) o codomínio da
função, mas o que chamamos de range:

%%}}}

%%{{{ df: range 
\definition.
%%%{{{ meta 
\label range
\indexes
    * função!range    seealso: imagem
    ;;
\defines
    * \range {~f}  -- o range (também: imagem) da função $f$
    * função!range
    ;;
%%%}}}

Seja $f : A \to B$ função.
Seu \dterm{range} é o conjunto
$$
\range (f)
\defeq
\setst y {\lexists x {x \mapstoby f y}}.
$$
Observe que $\range(f) \subset B$.

%%}}}

%%{{{ beware: ima 
\beware.
%%%{{{ meta 
\label ima
\indexes
    * função!imagem    seealso: range
    * imagem    see: função, imagem
    ;;
\defines
    * \ima {~f}  -- o range (também: imagem) da função $f$
    * função!imagem
    ;;
%%%}}}

O conjunto que acabamos de definir na~\ref[range]
é também chamado de \dterm{imagem} da~$f$,
e a notação $\ima f$ também é usada para denotá-lo.
Esse conjunto é a imagem \emph{duma função}.
Não confunda isso com a imagem \emph{dum conjunto} (\emph{através} duma função),
algo que estudamos na~\ref[Images_preimages].

%%}}}

%%{{{ x: what about these types for sin? 
\exercise.
%%%{{{ meta 
%%%}}}

Podemos considerar a função $\sin$ como uma função com os tipos seguintes?:
$$
\xalignat4
\sin_4 &: \rats \to \reals &
\sin_5 &: \reals\setminus\rats \to \reals\setminus\rats &
\sin_6 &: \rats \to \rats  &
\sin_7 &: \set{\pi} \to \set{0}
\endxalignat
$$

\solution
É fácil responder sobre as $\sin_4$ e $\sin_7$, pois realmente são
apenas restricções da função $\sin : \reals\to\reals$
(veja~\ref[fresto]).
Mas a situação com as $\sin_5$ e $\sin_6$ é bem mais complicada
que isso!
Sobre a $\sin_5$, supondo que sabemos que $\pi \nin \rats$,
concluimos que o seu tipo está errado,
pois $\sin(\pi) = 0 \nin \reals\setminus\rats$.
Note que para responder nisso precisamos saber a irracionalidade
de $\pi$, algo que não é trivial!
Mesmo sabendo disso, não é fácil responder sobre a $\sin_6$.
Seu tipo é realmente errado, pois
$$
\text{para todo $x \in \rats_{\neq0}$,  $\sin(x) \nin \rats$}
$$
mas a demonstração desse resultado é fora do escopo desse texto.
(Veja~\cite[nivenirrational: Cor.~2.7] para mais detalhes.)
Ou seja, podemos considerar a $\sin$ com tipo
$$
\sin_8 : \rats_{\neq0} \to \reals\setminus\rats.
$$

%%}}}

%%{{{ remark: codomain is any superset of range 
\remark.
%%%{{{ meta 
%%%}}}

Seguindo o ponto de vista do~\reftag[what_about_the_codomain_1],
tendo uma função $f : A \to B$,
podemos considerar ela como uma função com codomínio qualquer superconjunto de
$B$, sem mudar nada observável.
Em símbolos:
$$
f : A \to B  \mland  \range(f) \subset B'  \implies  f : A \to B'.
$$
Esse ponto de vista, identifica funções com gráficos iguais,
mas nem definimos ainda o que é um gráfico de função.
É o seguinte.

%%}}}

%%{{{ df: function_graph 
\definition.
%%%{{{ meta 
\label function_graph
\defines
    * \graph{~f}  -- o gráfico da função $f$
    * função!gráfico
    ;;
%%%}}}

Dado função $f : X\to Y$, o \dterm{gráfico da $f$}, é o conjunto
$$
\graph f \defeq \setst {\tup{x,f(x)}} {x \in X}.
$$
Observe que $\graph f \subset X\times Y$.

%%}}}

%%{{{ What about the codomain? (II) 
\note E o codomínio? (II).
%%%{{{ meta 
\label what_about_the_codomain_2
%%%}}}

Em outras partes de matemática, especialmente em teoria das
categorias~(\ref[Category_theory]),
teoria dos tipos~(\ref[Type_theory]),
e álgebra,
consideramos que o codomínio duma função faz parte dela sim!
Pensando em funções como black boxes então, com essa visão,
temos que imaginar que as caixas pretas tem dois rótulos
impressos: um na sua entrada com o domínio escrito nele,
e um na sua saída com o codomínio.
Assim, a diferença do codomínio vira uma coisa imediatamente
observável: é só olhar no rótulo da saída!

%%}}}

%%{{{ labeled black box for function 
\note Funções como black boxes com rótulos.
%%%{{{ meta 
%%%}}}

Com a idéia (II) de função visualizamos uma função
$f : A \to B$ assim:
$$
\tikzpicture
\tikzi blackboxfuncat;
\endtikzpicture
$$

%%}}}

%%{{{ Equality in functions 
\note Igualdade de funções.
%%%{{{ meta 
%%%}}}

Dependendo qual ponto de vista de função seguimos,
a definição de igualdade para o tipo de função vai ser diferente!
Mostramos primeiramente as definições corretas para
o ponto de vista~(I) e o ponto de vista~(II)
(explicados nos~\reftag[what_about_the_codomain_1]
e~\reftag[what_about_the_codomain_2]).
Depois, escrevendo num jeito diferente, chegamos numa definição que
vamos realmente usar e que é aplicável independente do ponto de vista.
Nesse texto vamos sempre deixar claro para cada função encontrada qual
conjunto consideramos como seu domínio e qual como seu codomínio.\foot
Exceto numas partes onde esclarecemos
qual a noção de função que utilizamos.
\toof
Assim, a escolha de ponto de vista de função não vai nos afetar.

%%}}}

%%{{{ df: f_eq_g_setist 
\definition Igualdade (I): ``Conjuntista''.
%%%{{{ meta 
\label f_eq_g_setist
%%%}}}

Sejam $f,g$ funções.
Digamos que $f=g$ sse \emph{quaisquer duas} das afirmações seguintes são válidas:
\elist 1:
\li: $\dom f = \dom g$;
\li: para todo $x \in \dom f$, $f(x) = g(x)$;
\li: para todo $x \in \dom g$, $f(x) = g(x)$.
\endelist
Equivalentemente,
$$
f = g \defiff \graph f = \graph g.
$$

%%}}}

%%{{{ df: f_eq_g_catist 
\definition Igualdade (II): ``Categorista''.
%%%{{{ meta 
\label f_eq_g_catist
%%%}}}

Sejam $f,g$ funções.
Dizemos que $f=g$ sse 
\elist 1:
\li: $\dom f = \dom g$;
\li: $\cod f = \cod g$;
\li: para todo $x \in \dom f$, $f(x) = g(x)$.
\endelist

%%}}}

%%{{{ Two religions 
\note Duas religiões.
%%%{{{ meta 
\label two_religions
%%%}}}

Podemos pensar então que tem duas religiões, que vamos chamar
aqui de Conjuntista e de Categorista.  Cada um tem sua idéia
do que se trata uma função.
Note que cada um vai ler as notações $f : A \to B$ e $A \toby f B$
numa maneira diferente:
$$
\align
\text {Conjuntista:}\  &
\text{<<$f$ é uma função com domínio $A$, e $\range(f) \subset B$>>}\\
\text {Categorista:}\  &
\text{<<$f$ é uma função com domínio $A$, e codomínio $B$>>}.
\endalign
$$
Vamos escrever agora uma definição de igualdade flexível
para satisfazer os dois:

%%}}}

%%{{{ df: f_eq_g 
\definition Igualdade (agnóstica).
%%%{{{ meta 
\label f_eq_g
%%%}}}

Sejam $f,g : A\to B$ funções.
Definimos
$$
f=g
\defiff
\text{para todo $x \in A$, $f(x) = g(x)$.}
$$

%%}}}

%%{{{ f_eq_g is indeed flexible 
\remark.
%%%{{{ meta 
%%%}}}

Assuma a fé do Conjuntista e leia a~\ref[f_eq_g]:
ela é equivalente à~\reftag[f_eq_g_setist].
Agora assuma a fé do Categorista e leia a~\reftag[f_eq_g]
novamente: ela é equivalente à~\reftag[f_eq_g_catist].

%%}}}

%%{{{ df: endomapping 
\definition.
%%%{{{ meta 
\label endomapping
\indexes
    * função!endomapa
    * endomapa          see: função
    ;;
\defines
    * endomapa
    ;;
%%%}}}

Uma função $f$ é um \dterm{endomapa} no $A$ sse $\dom f = \cod f = A$.

%%}}}

%%{{{ eg: succ and its black box 
\example.
%%%{{{ meta 
%%%}}}

A função $\succ : \nats\to\nats$
que retorna para cada natural $n$ seu sucessor $n+1$.
Dando por exemplo $2$ como entrada nela, observamos o valor
$\succ (2) = 3$:
$$
\tikzpicture
\tikzi blackboxfunsucc;
\endtikzpicture
$$
O $\succ$ é um exemplo de endomapa.

%%}}}

%%{{{ remark: Some notions don't make sense for the Setist 
\remark.
%%%{{{ meta 
\indexes
    * função!endomapa
    ;;
%%%}}}

Observe que a noção de ``ser endomapa'' não faz sentido
para quem escolher definir \emph{função} pela~\ref[f_eq_g_setist]
(ou seja, para o ``Conjuntista'')
pois ele nem sabe dizer qual é o codomínio duma função.
Logo vamos encontrar mais noções que também não fazem
sentido pra ele---fique alerto!

%%}}}

\endsection
%%}}}

%%{{{ Internal_and_external_diagrams 
\section Diagramas internos e externos.
%%%{{{ meta 
\label Internal_and_external_diagrams
%%%}}}

%%{{{ Internal diagrams 
\note Diagramas internos.
%%%{{{ meta 
\defines
    * diagrama!interno
    ;;
%%%}}}

Em certos casos podemos representar toda a informação numa função
usando \dterm{diagramas internos}, ou seja, diagramas que mostram
o interno do domínio e codomínio duma função, e como ela comporta
nele.

%%}}}

%%{{{ eg: internal_diagram_example 
\example.
%%%{{{ meta 
\label internal_diagram_example
%%%}}}

Aqui um diagrama interno de duas funções $A \toby f B \toby g C$:
$$
\tikzpicture
\tikzi internaldiagram;
\endtikzpicture
$$
Aqui o conjunto $A$ tem 2 membros---não importa quais são, ou seja,
os nomes deles---o $B$ tem 3, e o $C$ tem 2 também.

%%}}}

%%{{{ names_of_elements 
\note Nomes de elementos.
%%%{{{ meta 
\label names_of_elements
%%%}}}

É muito comum desenhar esse tipo de diagramas para construir exemplos e
contraexemplos que envolvem funções, e quando os \emph{quais são}
os membros não é importante desenhamos apenas um $\bullet$ para
representar os membros, com o entendimento que pontos distintos
representam membros distintos.
Note que \emph{se} quisermos definir formalmente um exemplo baseado num
desenho, nossa tarefa é trivial: é só escolher nomes para os $\bullet$
e pronto.
Por exemplo, dando esses nomes nos pontos
do~\ref[internal_diagram_example] chegamos no seguinte:
$$
\tikzpicture
\tikzi internaldiagramnames;
\endtikzpicture
$$
E agora para definir isso formalmente na escrita podemos apenas dizer:
Sejam os conjuntos
$$
A = \set{\mathrm a, \mathrm b} \qqqquad
B = \set{\mathrm c, \mathrm d, \mathrm e} \qqqquad
C = \set{\mathrm u, \mathrm v}
$$
e as funções $f : A\to B$ e $g : B\to C$ definidas pelas:
$$
\aligned
f(\mathrm a) &= \mathrm e\\
f(\mathrm b) &= \mathrm d
\endaligned
\qqqquad
\aligned
g(\mathrm c) &= \mathrm u\\
g(\mathrm d) &= \mathrm v\\
g(\mathrm e) &= \mathrm v.
\endaligned
$$
Observe que os $\mathrm a, \mathrm b, \mathrm c$, etc.~\emph{não são variáveis},
mas as próprias letras \symq{a}, \symq{b}, \symq{c}, etc.
Naturalmente escolhemos nomes bem conhecidos, como números, letras, etc.

%%}}}

%%{{{ remark: to what do those barred arrows correspond? 
\remark.
%%%{{{ meta 
%%%}}}

Então em que corresponde cada uma das setinhas barradas do diagrama interno?
Numa das \emph{equações} que definam a correspondente função,
ou seja, num par da forma $\tup{x, f(x)}$.

%%}}}

%%{{{ External diagrams 
\note Diagramas externos.
%%%{{{ meta 
\defines
    * diagrama!externo
    ;;
%%%}}}

Muitas vezes queremos olhar para a ``big picture'' e os detalhes
``internos'' da configuração não nos importam.
Pelo contrário, nos atrapalham: \emph{perdemos a floresta pelas árvores}.
Nesse caso usamos \dterm{diagramas externos}.

%%}}}

%%{{{ eg: external_of_previous_example 
\example.
%%%{{{ meta 
\label external_of_previous_example
%%%}}}

O diagrama externo da configuração do~\ref[internal_diagram_example]
é o seguinte:
$$
A \longtoby f B \longtoby g C.
$$

%%}}}

%%{{{ diagram_of_endomap 
\note Diagramas de endomapas.
%%%{{{ meta 
\label diagram_of_endomap
\indexes
    * função!endomapa
    ;;
%%%}}}

No caso especial que temos um endomapa $f:A\to A$,
podemos desenhar seu diagrama interno
sem usar duas cópias de $A$, mas apenas mostrando os mapeamentos assim
como o exemplo seguinte sugere.

%%}}}

%%{{{ eg: internal_diagram_of_endomap 
\example.
%%%{{{ meta 
%%%}}}

Considere o diagrama interno:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramendo1;
\endtikzpicture
$$
Esse é o diagrama interno da função $f : A \to A$ definida pelas
$$
\xalignat8
f(1) &= 2; &
f(2) &= 1; &
f(3) &= 1; &
f(4) &= 4; &
f(5) &= 5; &
f(6) &= 8; &
f(7) &= 5; &
f(8) &= 5;
\endxalignat
$$
onde $A = \set {1,2,3,4,5,6,7,8}$.
Tecnicamente as setinhas deveriam ter bundas, mas já que é
um diagrama interno só tem esse tipo de setas (as \sq{$\mapsto$})
então não dá pra confundir e o diagrama fica mais fácil de desenhar
sem tanta bunda.

%%}}}

\endsection
%%}}}

%%{{{ Jections: injections, surjections, bijections 
\section Jecções: injecções, sobrejecções, bijecções.
%%%{{{ meta 
\label Jections
%%%}}}

%%{{{ noneg: not_injective 
\nonexample.
%%%{{{ meta 
%%%}}}

Nenhuma dessas funções é injetora:
$$
\xxalignat3
&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw[|->] (a1) -- (b3);
\draw[|->] (a2) -- (b1);
\draw[|->] (a3) -- (b2);
\draw[|->,color=red] (a4) -- (b4);
\draw[|->,color=red] (a5) -- (b4);
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\node[color=red] (a5) at (0,-1)    {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw[|->,color=red] (a1) -- (b3);
\draw[|->]           (a2) -- (b3);
\draw[|->]           (a3) -- (b3);
\draw[|->,color=red] (a4) -- (b3);
\draw[|->]           (a5) -- (b3);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a4) at (0,-.5)   {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\tikzi not_injective0;
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw[|->,color=red] (a1) -- (b2);
\draw[|->,color=red] (a2) -- (b2);
\draw[|->] (a3) -- (b2);
\draw[|->] (a4) -- (b4);
\draw[|->] (a5) -- (b4);
\node[color=red] (a1) at (0,1)     {$\bullet$};
\node[color=red] (a2) at (0,.5)    {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Em cada caso \emph{uma} razão é enfatizada com cor.

%%}}}

%%{{{ noneg: not_surjective 
\nonexample.
%%%{{{ meta 
%%%}}}

E aqui nenhuma dessas funções é sobrejetora:
$$
\xxalignat3
&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$B$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$f$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)    {$\bullet$};
\node (a2) at (0,0)       {$\bullet$};
\node (a3) at (0,-.666)   {$\bullet$};
\node (b1) at (3,1)       {$\bullet$};
\node (b2) at (3.2,.333)  {$\bullet$};
\node (b3) at (3.1,-.333) {$\bullet$};
\node (b4) at (2.8,-1)    {$\bullet$};
\draw[|->] (a1) -- (b1);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b3);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$A$};
\draw (3,2.0) node {$C$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$g$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (a1) at (0,.666)  {$\bullet$};
\node (a2) at (0,0)     {$\bullet$};
\node (a3) at (0,-.666) {$\bullet$};
\node (b1) at (3,1)     {$\bullet$};
\node (b2) at (2.9,.7)  {$\bullet$};
\node (b3) at (3.1,0.1) {$\bullet$};
\node (b4) at (2.8,-.5) {$\bullet$};
\node (b5) at (3,-1)    {$\bullet$};
\node (b6) at (3.2,-0.8){$\bullet$};
\draw[|->] (a1) -- (b2);
\draw[|->] (a2) -- (b2);
\draw[|->] (a3) -- (b5);
\node[color=red] (b4c) at (b4) {$\bullet$};
\endtikzpicture
&&
\tikzpicture
\draw (0,2.0) node {$\emptyset$};
\draw (3,2.0) node {$D$};
\draw[->] (0.5,2.0) -- (2.5,2.0) node[midway,below] {$h$};
\draw (0,0) ellipse (-.85cm and 1.5cm);
\draw (3,0) ellipse (-.85cm and 1.5cm);
\node (b1) at (3.0,.333)  {$\bullet$};
\node (b2) at (3.0,-.333) {$\bullet$};
\node[color=red] (b2c) at (b2) {$\bullet$};
\endtikzpicture
\endxxalignat
$$
Novamente em cada caso \emph{uma} razão é enfatizada com cor.

%%}}}

%%{{{ Q: how would you define injective and surjective? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias os conceitos de função injetora e sobrejetora?

%%}}}

\spoiler

%%{{{ df: jections 
\definition.
%%%{{{ meta 
\label jections
\indexes
    * bijecção     see: função bijectiva
    * injecção     see: função injectiva
    * sobrejecção  see: função sobrejectiva
    ;;
\defines
    * ~f : ~A \bijto ~B  -- $f : A \to B$ bijectiva
    * ~f : ~A \injto ~B  -- $f : A \to B$ injectiva
    * ~f : ~A \surto ~B  -- $f : A \to B$ sobrejectiva
    * função!bijectiva
    * função!injectiva
    * função!sobrecjetiva
    ;;
%%%}}}

Seja $f : A \to B$.
Chamamos a $f$ \dterm{injectiva} (ou \dterm{injetora}) sse
$$
\text{para todo $x,y \in A$, se $f(x) = f(y)$ então $x = y$}.
$$
Chamamos a $f$ \dterm{sobrejectiva} (ou \dterm{sobrejetora}) sse
$$
\text{para todo $b \in B$, existe $a\in A$ tal que $f(a) = b$}.
$$
Chamamos a $f$ \dterm{bijectiva} (ou \dterm{bijetora}, ou \dterm{correspondência}), sse
$f$ é injectiva e sobrejectiva.
Formulamente,
$$
\align
\text{$f$ injectiva}    &\defiff \lforall {x,y \in A} {f(x) = f(y) \implies x = y}; \\
\text{$f$ sobrejectiva} &\defiff \pforall {b \in B} \lexists {a \in A} {f(a) = b}; \\
\text{$f$ bijectiva}    &\defiff \text{$f$ injetora} \mland \text{$f$ sobrejetora}.
\endalign
$$
Usamos as notações
$$
\align
f : A \injto B &\defiff \text{$f:A\to B$ injectiva};\\
f : A \surto B &\defiff \text{$f:A\to B$ sobrejectiva};\\
f : A \bijto B &\defiff \text{$f:A\to B$ bijectiva}.
\endalign
$$
As palavras ``injectiva'', ``sobrejectiva'', e ``bijectiva''
são adjectivos.  Os substantivos correspondentes são os:
\dterm{injecção}, \dterm{sobrejecção}, \dterm{bijecção}.
Dizemos por exemplo que <<$f$ é uma bijecção>>, que significa
que <<$f$ é uma função bijectiva>>.

%%}}}

%%{{{ remark: contrapositive of injective 
\remark.
%%%{{{ meta 
\indexes
    * preservar    seealso: respeitar
    * respeitar    seealso: preservar
    * preservar!as distincções
    * respeitar!as distincções
    ;;
%%%}}}

A seguinte afirmação equivalente de $f : A \injto B$ é muito útil:
$$
\text{para todo $x,y \in A$, se $x\neq y$ então $f(x) \neq f(y)$}.
$$
(É a sua contrapositiva.)
Vamos traduzir essa afirmação mais perto ``no nível coração'':
\standout
<<$f$ \dterm{preserva} as distincções do seu domínio.>>
\endstandout
Também digamos que $f$ \dterm{respeita} as distincções.
Assim podemos pensar que uma função injetora embute seu domínio
no seu codomínio, criando uma \emph{cópia fiel} dele,
só que com nomes diferentes para seus membros.

%%}}}

%%{{{ remark: Setist vs. Categorist 
\remark Conjuntista \vs Categorista.
%%%{{{ meta 
%%%}}}

Observe que o conjuntista pode realmente se perguntar se uma função é
injetora ou não, pois a definição de ser injetora não mexe com o codomínio
da função. Mas pra ele, ser sobrejetora ou não, não é uma propriedade
da função ``sozinha''; ele afirma que <<a função $f$ é \dterm{sobre} o $B$>>,
e é isso que ele quis dizer quando ele afirma
<<a função $f : A\to B$ é sobrejetora>>.
Pense na diferença que suas caixas pretas têm:
como decidir se uma caixa preta dum conjuntista é sobrejetora
ou não?  Mas tem como decidir se ela é injetora sim.
Então o ``ser injetora'' é um predicado de aridade $1$ para ambos,
mas o predicado ``ser sobrejetora'' já difere dependendo da fé:
para o categorista tem aridade $1$;
para o conjuntista tem aridade $2$,
o segundo argumento sendo o conjunto $B$ nesse caso.

%%}}}

%%{{{ x: double_or_reverse_string_inj_or_surj 
\exercise.
%%%{{{ meta 
\label double_or_reverse_string_inj_or_surj
%%%}}}

Seja~$S$ o conjunto de todos os strings \emph{não vazios}
dum alfabeto $\Sigma$, com $\card{\Sigma} \geq 2$.
Considere a função
$f : S \times \set{0,1} \to S$ definida pela:
$$
f(w,i) =
\knuthcases {
ww, &se $i = 0$\cr
w', &se $i = 1$
}
$$
onde $w'$ é o string reverso de $w$,
e onde denotamos a concatenação de strings por justaposição.
(1) A $f$ é injetora?
(2) A $f$ é sobrejetora?

\hint
Quais são o domínio e o codomínio da $f$?

\solution
\proofpart {(1)}
Não, $f$ não é injetora.
Tome uma letra do alfabeto $a\in\Sigma$ e observe que
$$
f(a, 0) = aa = f(aa,1).
$$
Como $(a,0) \neq (aa,1)$, a $f$ não é injetora.
\crproofpart {(2)}
Sim, $f$ é sobrejetora.
Tome um aleatório string $w\in S$,
e seja $w'$ o string reverso de $w$.
Temos
$$
f(w',1) = (w')' = w.
$$

%%}}}

%%{{{ x: touch_of_godel_encoding 
\exercise.
%%%{{{ meta 
\label touch_of_godel_encoding_pairs
%%%}}}

Considere as $f,g,h : \nats^2 \to \nats$
definidas pelas
\mathcols 3
f (x,y) &= 2^x 3^y &
g (x,y) &= 2^x 6^y &
h (x,y) &= 12^x 18^y.
\endmathcols
Para cada uma, decida se é injetora, e se é sobrejetora.

\hint
Nenhuma é sobrejetora.
As $f,g$ são injetoras; a $h$ não.
Demonstre tudo isso.

\hint
Para refutar que $h$ é injetora, observe que $12=2^2 \ntimes 3$ e $18=2 \ntimes 3^2$.

%%}}}

%%{{{ df: jection_sets 
\definition.
%%%{{{ meta 
\label jection_sets
\defines
    * (~A \bijto ~B)  -- o conjunto de todas as bijecções  de $A$ para $B$
    * (~A \injto ~B)  -- o conjunto de todas as injecções  de $A$ para $B$
    * (~A \surto ~B)  -- o conjunto de todas as surjecções de $A$ para $B$
    ;;
%%%}}}

Sejam $A,B$ conjuntos.  Definimos os conjuntos:
\mathcol
(A \injto B) &\defeq \setstt {f : A \to B} {$f$ injetora} \\
(A \surto B) &\defeq \setstt {f : A \to B} {$f$ sobrejetora} \\
(A \bijto B) &\defeq \setstt {f : A \to B} {$f$ bijetora}
\endmathcol

%%}}}

%%{{{ x: cardinalities_of_jection_sets 
\exercise.
%%%{{{ meta 
\label cardinalities_of_jection_sets
%%%}}}

Ache a cardinalidade dos conjuntos da~\ref[jection_sets]
em termos das cardinalidades dos $A$ e $B$, supondo que
ambas são finitas.

%%}}}

%%{{{ x: x_mapsto_singleton_x_properties 
\exercise.
%%%{{{ meta 
\label x_mapsto_singleton_x_properties
%%%}}}

Sejam $A$ um conjunto habitado e $f : A \to \pset A$ definida pela equação
$$
f(a) = \set a.
$$
Investigue:
(i) A $f$ é injetora?
(ii) A $f$ é sobrejetora?

\solution
\noi
(i) Sim.  Sejam $a,a'\in A$ tais que $f(a) = f(a')$, ou seja, $\set a = \set {a'}$.
Logo $a = a'$.
\eop
\noi
(ii) Não, pois nenhum membro do $A$ é mapeado para o $\emptyset$, que é um membro do $\pset A$.
Seja $a\in A$.  Logo $f(a) = \set a \neq \emptyset \in \pset A$.

%%}}}

%%{{{ x: x_mapsto_singleton_x_empty_dom 
\exercise.
%%%{{{ meta 
\label x_mapsto_singleton_x_empty_dom
%%%}}}

No \ref[x_mapsto_singleton_x_properties], a hipotese sobre o $A$ é necessária?

%%}}}

\endsection
%%}}}

%%{{{ How to define and how not to define functions 
\section Como definir e como não definir funções.
%%%{{{ meta 
%%%}}}

%%{{{ Q: what must we do to correctly define a function f : A -> B ? 
\question.
%%%{{{ meta 
%%%}}}

O que precisamos fazer para definir corretamente uma função?

%%}}}

%%{{{ A: We must make clear what its values are for all of its domain. 
\note Resposta.
%%%{{{ meta 
%%%}}}

Precisamos deixar claro qual é o seu domínio e o seu valor
para cada ponto no seu domínio (totalidade e determinabilidade).
Se consideramos que o codomínio da função faz parte dela também
(veja conversa na~\reftag[Function_contept]), precisamos deixar
claro seu codomínio também---aqui sempre faremos isso.

%%}}}

%%{{{ Definition by expression 
\note Definição por expressão.
%%%{{{ meta 
%%%}}}

Uma das maneiras mais comuns para definir funções, é escrever algo do tipo:
\emph{Seja $f:A\to B$ a função definida pela \thole}

%%}}}

%%{{{ remark: what we define is f(x) not f 
\remark.
%%%{{{ meta 
%%%}}}

Literalmente, o que estamos definindo assim é o ``$f(x)$'' para todo $x \in A$,
e não o próprio $f$.  Mas, a $f$ sendo função, realmente é determinada para
seu comportamento (seus valores) das todas as entradas possíveis do seu domínio,
então isso realmente defina a própria função $f$---graças a definição de igualdade
de funções.  (Veja também a~\ref[from_x_in_A_union_B_to_A_union_B_to_union].)

%%}}}

%%{{{ eg: a_polynomial_function_on_reals 
\example.
%%%{{{ meta 
\label a_polynomial_function_on_reals
%%%}}}

Seja $f : \reals \to \reals$ definida pela
$$
f(x) = x^2 + 2x + 1, \qquad \text{para todo $x\in \reals$}.
$$
Em geral, cada polinómio de $n$ variáveis,
pode ser visto como uma função de aridade $n$.

%%}}}

%%{{{ not_well_defined_function_danger_argument_name_dependence
\beware depender de nome de parametro.
%%%{{{ meta 
\label not_well_defined_function_danger_argument_name_dependence
%%%}}}

Quando definimos uma função vale a pena pensar como programador
que está tentando programar essa função, ou até assumir o papel
da própria função que vai receber seus argumentos e vai precisar
decidir qual seria o seu valor.
Imagine alguém programando uma função $\code{foo}$
de $\code{int}$ para $\code{int}$ numa linguagem de programação.
O programador e sua função não têm como saber o \emph{nome}
que o chamador da função vai usar quando chamando-la.
Em algum ponto ela pode ser chamada pelo $\code{foo(42)}$
passando assim diretamente o \emph{literal} $\code{42}$,
ou, depois de umas atribuições como $\code{int a = 42; int num = 42;}$,
chamá-la $\code{foo(a)}$ ou $\code{foo(num)}$.
Não tem como programar a função depender nesses nomes.
Por exemplo:
<<se for chamada com nome que começa com vogal, retorna o inteiro 0;
caso contrário, retorna o inteiro 1>>;
ou
<<retorna o tamanho do nome do teu argumento>>
(querendo retornar $\code{1}$ caso que for chamada pelo $\code{foo(a)}$,
e $\code{3}$ caso que for chamada pelo $\code{foo(num)}$).

%%}}}

%%{{{ noneg: not_well_defined_function_choice_dependence_noneg 
\nonexample.
%%%{{{ meta 
\label not_well_defined_function_choice_dependence_noneg
%%%}}}

Seja $f : \ints \to \ints$ definida pela
$$
f(x+y) = y.
$$

%%}}}

%%{{{ not_well_defined_function_danger_choice_dependence 
\beware depender de escolhas.
%%%{{{ meta 
\label not_well_defined_function_danger_choice_dependence
%%%}}}

Por que o~\ref[not_well_defined_function_choice_dependence_noneg]
é um nãœxemplo mesmo?
Imagine que definimos uma
``função'' $f$ pela
$$
f(x+y) = y.
$$
O que seria o $f(2+3)$?  $3$?  Por que não $0$?
No final das contas (literalmente)
$$
2 + 3 \spaceq
5 + 0 \spaceq
4 + 1 \spaceq
12 + (-7) \spaceq
\dots
$$
e $f$ não tem como saber o jeito que tu imaginou ``quebrar''
sua entrada em dois somantes!
A $f$ está olhando ao seu argumento (aqui o $5$) e está tentando
decidir qual seria o seu valor nesse ponto!  E não tem como saber
pois, consultando a sua ``definição'' o resultado vai depender
da escolha desses $x$ e $y$.

%%}}}

%%{{{ Definitive description 
\note Descripção definitiva.
%%%{{{ meta 
\defines
    * descripção definitiva
    ;;
%%%}}}

Podemos definir uma função $f : A \to B$ dando uma \dterm{descripção definitiva}
do seu valor num ponto $x$ do seu domínio:
$$
f(x) = \text{aquele $b \in B$ que {\xlthole}}.
$$
Cuidado pois nesse caso precisamos verificar que realmente para cada $x\in A$,
existe exatamente um $b\in B$ que satisfaz a afirmação no {\xlthole}.%

%%}}}

%%{{{ Definitive descriptor 
\remark Descritor definitivo.
%%%{{{ meta 
\defines
    * \descrsym  -- descritor definitivo
    * descritor definitivo
    ;;
%%%}}}

Existe uma notação especial para a frase <<aquele $b$ que {\xlthole}>>:
o \dterm{descritor definitivo} $\descrsym$:
$$
\textwq{aquele $b$ que {\xlthole}} \quad\leadsto\quad \descr b {{\xlthole}}.
$$
Essa notação parece bastante com a λ-notação que encontramos logo
na~\ref[A_touch_of_lambda], mas é diferente pois na {\thole} aqui precisamos
algo que denota uma afirmação; na notação lambda algo que denota um objeto.
Aqui não vamos usar o descritor definitivo~$\descrsym$,
mas a λ-notação é importantíssima e ficaremos a usando o tempo todo.
Paciência até~\reftag[A_touch_of_lambda] então.

%%}}}

%%{{{ eg: mother_and_son_function_and_wannabe_example 
\example.
%%%{{{ meta 
\label mother_and_son_function_and_wannabe_example
%%%}}}

\emph{Queremos} definir as funções $m,s : \pers \to \pers$ pelas equações
$$
\align
m(p) &= \text{a mãe de $p$}\\
s(p) &= \text{o filho de $p$}
\endalign
$$
(onde ``mãe'' significa ``mãe biológica'').
Mas\dots

%%}}}

%%{{{ x: mother_and_son_function_and_wannabe 
\exercise.
%%%{{{ meta 
\label mother_and_son_function_and_wannabe
%%%}}}

Ache o problema no~\ref[mother_and_son_function_and_wannabe_example] acima.

\hint
Lembe-se as condições no~\reftag[functionhood_conditions].

\solution
A função $m$ é bem definida, ou seja, é uma função mesmo:
\emph{cada pessoa} tem (totalidade) exatamente uma (determinabilidade)
mãe e logo ambas as condições de funcionalidade (\reftag[functionhood_conditions])
são satisfeitas.
Por outro lado, a $s$ não satisfaz nenhuma das condições:
tem pessoas sem filhos, e logo a totalidade já era; e também
tem pessoas com mais que um filho, e logo nem determinabilidade
temos.

%%}}}

%%{{{ x: mother_and_son_function_and_wannabe_even_restricting 
\exercise.
%%%{{{ meta 
%%%}}}

Considere o problema do~\ref[mother_and_son_function_and_wannabe_example]
que achaste no~\ref[mother_and_son_function_and_wannabe].
Vamos tentar resolvê-lo restringindo o $\pers$:
em vez do conjunto de todas as pessoas,
$\pers'$ denota o conjunto de todas as pessoas
que possuem exatamente um filho.
Assim garantimos que $s(p)$ é bem definido, pois $s(p)$
é a única pessoa $y$ tal que $y$ é filho de $p$:
e sabemos que tal $y$ existe, e que é único,
pela definição de $\pers'$.
Então para esse conjunto as $m,s$
do~\reftag[mother_and_son_function_and_wannabe]
realmente definam funções.

\hint
Não.
Em vez de melhorar, a situação piorou:
agora nem $m$ nem $s$ são funções!

\solution
Não.
O $s(p)$ é a única pessoa $y$ tal que $y$ é filho de $p$
e sim, sabemos que tal $y$ existe e que é único mas\dots
talvez essa pessoa $y$ não possui exatamente um filho,
ou seja, talvez $y \nin \pers'$.
De fato, a situação piorou, pois agora nem a $m$ é função,
pelo mesmo motivo: uma pessoa $p$ mesmo tendo exatamente
um filho, a mesma coisa não é garantida para a mãe de $p$,
e logo o $m(p)$ talvez não pertence ao $\pers'$.

%%}}}

%%{{{ x: does it depend on religion? 
\exercise.
%%%{{{ meta 
%%%}}}

Tua resposta dependeu da tua religião?

\hint
Lembre o que $f : A \to B$ significa para cada religião.

\solution
Não: tanto para Conjuntistas quanto para Categoristas
a saida $f(x)$ duma função $f : A \to B$ deve
pertence ao $B$.

%%}}}

%%{{{ definition by cases (branching) 
\note Definição por casos (branching).
%%%{{{ meta 
%%%}}}

Às vezes os valores $f(x)$ duma função $f$ não seguem o mesmo ``padrão'',
a mesma ``regra'' para todos os $x\in\dom f$.

%%}}}

%%{{{ eg: branching_example_1 
\example.
%%%{{{ meta 
\label branching_example_1
%%%}}}

Seja $f : \reals \to \reals$ definida pela
$$
f(x)
=
\knuthcases {
x^2,     & se $x\in\rats$;\cr
0,       & se $x = \sqrt p$ para algum primo $p$;\cr
2x + 1,  & caso contrário.
}
$$

%%}}}

%%{{{ beware: function_definition_by_cases_mistakes 
\beware.
%%%{{{ meta 
\label function_definition_by_cases_mistakes
%%%}}}

Cada vez que definimos uma função por casos, precisamos verificar que:
\elist 1:
\li: contamos para todos os casos possíveis da entrada;
\li: não existe sobreposição inconsistente em nossos casos.
\endelist
Seguem uns exemplos que demonstram esses erros.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Definimos a função $f : \nats \to \nats$, pela
$$
f(n) = \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
k, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$.\cr
}
$$
Aqui o problema é que $f$ não foi definida para todo o seu domínio, pois
existem números (por exemplo o $2$) que não satisfazem nenhum dos casos da
definição da $f$.

%%}}}

%%{{{ remark: use of otherwise 
\remark.
%%%{{{ meta 
%%%}}}

Para ter certeza que tomamos cuidado de todos os casos possíveis,
podemos descrever o último caso com um ``otherwise''
(ou ``caso contrário'').
Observe que as funções $f_1, f_2 : \nats \to \nats$ definidas pelas
$$
\align
f_1(n) &= \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & se $n$ pode ser escrito como $3k+1$ para algum $k\in\nats$;\cr
2, & otherwise.\cr
}\\
f_2(n) &= \knuthcases {
0, & se $n$ pode ser escrito como $3k$ para algum $k\in\nats$;\cr
n, & otherwise.\cr
}\\
\endalign
$$
são realmente duas funções bem-definidas e diferentes.

%%}}}

%%{{{ x: prove that they are different 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que são diferentes!

\solution
Temos
$$
f_1(5) = 2 \neq 5 = f_2(5),
$$
logo $f_1 \neq f_2$.

%%}}}

%%{{{ eg: overlapping_inconsistent_cases 
\example.
%%%{{{ meta 
\label overlapping_inconsistent_cases
%%%}}}

Definimos a função $g : \nats \to \nats$, pela
$$
g(n) = \knuthcases {
0,  & se $n$ é primo;\cr
1,  & se $n$ é par;\cr
12, & caso contrário.
}
$$
Aqui o problema é que não determinamos um único valor para cada membro do domínio da $g$.
Por exemplo o $2$, satisfaz os dois primeiros casos da definição acima.
Então $g(2) = 0$, pois $2$ é primo, e também $g(2) = 1$, pois $2$ é par!
Por isso essa $g$ é mal-definida, e não uma função.

%%}}}

%%{{{ x: is g a well-defined function? 
\exercise.
%%%{{{ meta 
%%%}}}

A $h : \nats \to \nats$, definida pela
$$
h(n) = \knuthcases {
n+2, & se $n$ é primo;\cr
n^2, & se $n$ é par;\cr
12,  & caso contrário.
}
$$
é uma função bem-definida?

\hint
Qual é a sobreposição dos casos que aparecem na definição da $h$ e quais os
valores da $h$ seguindo cada um deles?

\solution
A $h$ realmente é bem-definida, mas isso não é imediatamente óbvio,
pois os dois primeiros casos na sua definição não são distintos,
e os valores que cada um escolhe para a $h$ são aparentemente diferentes.
Para demonstrar que a $h$ é uma função bem-definida 
precisamos ver quais são os membros do seu codomínio que satisfazem
mais que um caso (aqui os dois primeiros casos, pois o terceiro é o ``caso contrário'')
e verificar que o valor da $h$ para esses membros são os mesmos, independente
do caso escolhido.
O único número natural que é primo e par e o $2$.
Seguindo o primeiro caso temos
$$
h(2) = 2 + 2 = 4,
$$
e seguindo o segundo caso temos
$$
h(2) = 2^2 = 4.
$$
Logo, a $h$ realmente é uma função bem-definida.

%%}}}

%%{{{ remark: compatible cases (cases agree) 
\remark.
%%%{{{ meta 
%%%}}}

Quando dois casos diferentes duma definição de função atribuem os mesmos
valores para as mesmas entradas da sua sobreposição comum, dizemos que
são \emph{compatíveis}, ou que \emph{concordam}.

%%}}}

%%{{{ Else-if 
\note Else-if.
%%%{{{ meta 
%%%}}}

Programadores são bastante acostumados com o uso do
``else-if'', e isso é algo que podemos usar definindo funções por casos.
Alterando a definição da função do~\ref[overlapping_inconsistent_cases]
podemos realmente (bem) definir uma função $g : \nats \to \nats$ pela
$$
g(n) = \knuthcases {
0,  & se $n$ é primo;\cr
1,  & se não; e se $n$ é par;\cr
12, & caso contrário.
}
$$
Assim, cada caso é necessariamente separado de todos os casos anteriores.
Em programação o múltiplo uso de ``else-if'', é chamado uma
\dterm{if-else-if ladder}.

%%}}}

%%{{{ defining_function_by_formula 
\note Por fórmula.
%%%{{{ meta 
\label defining_function_by_formula
%%%}}}

Outro jeito para definir uma função $f : A \to B$, é
determinar completamente quando é que $f(x) = v$,
para todo $x\in A$ e $v \in B$:
$$
f(x) = v \defiff \tubrace {\phi(x,v)} {function-like}.
$$
Onde a fórmula (ou a afirmação) $\phi(x,v)$ deve ser \dterm{function-like}
no $A$, ou seja, $\phi$ é tal que para todo $x\in A$, exatamente um $v \in B$
satisfaz a $\phi(x,v)$.\foot
Pode olhar também na definição formal disso,~\reftag[functionlike].
\toof

%%}}}

%%{{{ x: welldefined_functionlike 
\exercise.
%%%{{{ meta 
\label welldefined_functionlike
%%%}}}

As ``funções'' abaixo são bem-definidas?
$$
\xalignat2
f &: \reals_{\geq0} \to \reals &
f(x) = y &\defiff y^2 = x \\
g &: \nats \to \nats &
g(x) = y &\defiff y^2 = x \\
h &: \reals \to \reals &
h(x) = y &\defiff \text{$y$ é o maior inteiro que satisfaz $y \leq x$} \\
u &: \ints^2 \to \ints &
u(x,y) = z &\defiff \text{$z$ é primo} \mland z \divides x+y; \\
v &: \ints^2 \to \ints &
v(x,y) = z &\defiff \text{$z$ é o menor primo tal que $z \divides x+y$}.
\endxalignat
$$
Justifique tuas refutações.

\solution
A $f$ não é bem-definida: perdemos a unicidade; pois, por exemplo, como $1^2 = 1 = (-1)^2$, o $f(1)$ fica sem valor unicamente determinado.
\eop
A $g$ não é bem-definida: perdemos a totalidade; pois para o $2\in\nats$
por exemplo, não existe nenhum $y\in\nats$ com $y^2 = 2$.
\eop
A $h$ realmente é bem-definida, conhecida como ``floor''.
\eop
A $u$ não é bem-definida: perdemos a unicidade; por exemplo o
$u(1,5)$ fica sem valor determinado, pois $2$ é primo e $2 \divides 6$ mas $3$ também é primo e $3\divides 6$.
\eop
A $v$ também não é bem-definida: perdemos a totalidade; por exemplo o
$v(0,1)$ fica sem valor nenhum, pois nenhum primo divide o $0+1=1$.

%%}}}

%%{{{ defining_function_by_graph 
\note Por gráfico.
%%%{{{ meta 
\label defining_function_by_graph
%%%}}}

Podemos definir uma função $f : A \to B$ se definir qual é o seu
gráfico $\graph f$.  Observe que do gráfico já podemos recuperar
o domínio mas o codomínio não (veja~\reftag[dom_and_cod_recoverable_or_not]).
Então basta so deixar isso claro e pronto.
Claro que precisamos tomar cuidado: o gráfico tem que satisfazer
as condições de ser função: totalidade e
determinabilidade~(\ref[functionhood_conditions]).
Olhando apenas para o gráfico, só a determinabilidade pode ser
quebrada.  Mas se o domínio foi especificado separadamente,
precisamos verificar a totalidade também.
(Aqui vamos sempre deixar claro o domínio e o codomínio.)
Seguem uns exemplos.

%%}}}

%%{{{ eg: defining_function_by_graph_eg 
\example.
%%%{{{ meta 
\label defining_function_by_graph_eg
%%%}}}

Sejam $A = \set{0,1,2,3}$ e $f : A \to \nats$ a função com gráfico
$$
\graph f = \set{ \tup{0,0}, \tup{1,1}, \tup{2,4}, \tup{3,2} }.
$$
Temos, por exemplo, $f(0) = 0$ e $f(2) = 4$.

%%}}}

%%{{{ x: which_of_the_graphs_define_functions 
\exercise.
%%%{{{ meta 
%%%}}}

Quais dos gráficos abaixo podem ser usados
para definir funções com codomínio o $\nats$?
Quais os seus domínios recuperados por seus gráficos?
$$
\align
\graph(f) &= \set{ \tup{0,1}, \tup{2,4}, \tup{3,8}, \tup{1,2} } \\
\graph(g) &= \set{ \tup{0,12^{12}} } \\
\graph(h) &= \set{ \tup{0,1}, \tup{1,1}, \tup{0,1}, \tup{8,1}, \tup{3,2} } \\
\graph(k) &= \set{ \tup{\nats,0}, \tup{\ints,0}, \tup{\rats,0}, \tup{\reals,1} } \\
\graph(r) &= \emptyset \\
\graph(s) &= \set{ \tup{0,0}, \tup{1,1}, \tup{2,2^3}, \tup{3,3^{-1}} } \\
\graph(t) &= \set{ \tup{3,0}, \tup{2,0}, \tup{2,1}, \tup{2,7} } \\
\graph(w) &= \set{ \tup{0,0}, \tup{\tup{1,2},2}, \tup{\tup{12,12},2}, \tup{\tup{0,1,0,0},1} }
\endalign
$$

\solution
Temos:
$$
\xalignat2
f &: \set{ 0,1,2,3 } \to \nats &
r &: \emptyset \to \nats \\
g &: \set{ 0 } \to \nats &
s &: \text{não é (range não contido no codomínio)} \\
h &: \set{ 0,1,3,8 } \to \nats &
t &: \text{não é (quebrou determinabilidade)} \\
k &: \set{ \nats,\ints,\rats,\reals } \to \nats &
w &: \set{ 0, \tup{1,2}, \tup{12,12}, \tup{0,1,0,0} } \to \nats
\endxalignat
$$

%%}}}

%%{{{ defining_function_by_drawing 
\note Por desenho.
%%%{{{ meta 
\label defining_function_by_drawing
%%%}}}

Conhecemos no~\ref[Internal_and_external_diagrams] dois tipos
de diagramas relacionados a funções: internos e externos.
Lá observamos que desenhando o diagrama \emph{interno} já temos
determinado tudo que precisamos determinar para definir uma função
(\ref[names_of_elements]).
O que deve te deixar surpreso é que usando certos diagramas \emph{externos}
podemos \emph{definir} sim funções muito interessantes e importantes em
muitos casos!
(Faremos isso bastante no~\ref[Category_theory].)
Isso \emph{deve} mesmo ser algo dificilmente aceitável neste momento:
se tu estiveres com dúvidas estás no caminho certo:
\wq{Como assim determinou uma função pelo diagrama externo?
Lá só tem domínio e codomínio!  Qual o comportamento da tua função?}
Calma:
é porque não conhecemos ainda o poder---nem a beleza,
nem a elegância---dos diagramas comutativos,
que encontraremos logo na \ref[Commutative_diagrams].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ainda não encontramos a notação mais interessante para definir funções.
Vamos estudá-la logo; ela merece uma secção própria (\ref[A_touch_of_lambda]).
Antes disso, vamos ver mais uma maneira de definir funções: com buracos!

%%}}}

\endsection
%%}}}

%%{{{ Empty (co)domains 
\section (Co)domínios vazios.
%%%{{{ meta 
%%%}}}

%%{{{ x: f_from_A_to_emptyset 
\exercise.
%%%{{{ meta 
\label f_from_A_to_emptyset
%%%}}}

Seja $f : A \to \emptyset$.
O que podemos concluir sobre o $A$?
Quantas funções têm esse tipo?

\hint
O que significa ser função?

\solution
$A=\emptyset$, pois, caso contrário, pegando um $a\in A$,
chegamos na contradição $f(a) \in \emptyset$.
Quantas funções $f$ têm esse tipo?
Vamos resolver isso logo: veja~\ref[emptyfun] e~\ref[a_or_the_emptyfun].

%%}}}

%%{{{ x: f_from_emptyset_to_A 
\exercise.
%%%{{{ meta 
\label f_from_emptyset_to_A
%%%}}}

Seja $f : \emptyset \to A$.
O que podemos concluir sobre o $A$?
Quantas funções têm esse tipo?

%%}}}

%%{{{ df: emptyfun 
\definition Função vazia.
%%%{{{ meta 
\label emptyfun
\indexes
    * vazia!função    see: função
    ;;
\defines
    * função!vazia
    ;;
%%%}}}

Uma função $f$ com $\dom f = \emptyset$ é chamada \dterm{função vazia}.

%%}}}

%%{{{ x: a_or_the_emptyfun 
\exercise.
%%%{{{ meta 
\label a_or_the_emptyfun
%%%}}}

<<Uma>> ou <<a>>?

\solution
\proofpart {Para o conjuntista:} <<a>> mesmo!
Pois, tome $f,g$ funções vazias.
Logo $f : \emptyset \to A$ e $g : \emptyset \to B$
para alguns conjuntos $A,B$.
Vacuamente temos que para todo $x\in \emptyset$, $f(x) = g(x)$.
\crproofpart {Para o categorista:} para cada conjunto $A$,
temos exatamente uma função vazia com codomínio $A$.

%%}}}

%%{{{ remark: emptyfun_is_not_strange 
\remark.
%%%{{{ meta 
\label emptyfun_is_not_strange
%%%}}}

Com tudo que o leitor tem visto até agora a \ref[emptyfun] não deve aparecer nada estranha.
Caso contrário---talvez tu pulou diretamente pra cá?---pense na maneira seguinte:
Já determinamos o domínio da função: é o $\emptyset$.
O que falta fazer para ter o direito de falar que definimos uma função?
Sendo conjuntista, basta determinar para cada um dos membros do domínio seu valor.
Se o domínio tivesse três membros, por exemplo se fosse o $\set{1,2,3}$, bastaria
definir as
$$
\align
f(1) &= \askdots \\
f(2) &= \askdots \\
f(3) &= \askdots
\endalign
$$
Mas agora o domínio tem zero membros, então temos zero valores para determinar,
e vamos fazer isso com uma equação para cada um deles mesmo.
Aqui, então, minhas zero equações:
$$
~
$$
Pronto, defini minha função.
(Lembrou da 0-tupla (\reftag[zero_tuple]), né?)
E se eu fosse categorista, teria mais um trabalho
para fazer: determinar o seu codomínio (\reftag[a_or_the_emptyfun]).

%%}}}

\endsection
%%}}}

%%{{{ Holed_expressions 
\section Expressões com buracos.
%%%{{{ meta 
\label Holed_expressions
%%%}}}

%%{{{ What is a holed expression? 
\note O que é uma expressão com buraco?.
%%%{{{ meta 
\indexes
    * buraco    seealso: função
    ;;
\defines
    * buraco
    ;;
%%%}}}

Podemos criar uma função através duma expressão,
escolhendo um dos objetos que aparecem nela e o substituindo por um \dterm{buraco}.
Criamos assim \emph{aquela função} que, recebendo um argumento,
retorna o valor criado botando sua entrada no buraco da expressão.
Usamos $\bhole$, $\dhole$, e $\uhole$, para denotar esses buracos.

%%}}}

%%{{{ eg: holed_expression 
\example.
%%%{{{ meta 
\label holed_expression
%%%}}}

Considere a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Qual o tipo dela?
Ela denota um número real, ou seja,}
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals.
\intertext{Escolhemos um objeto nela e botamos um buraco no seu lugar:}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5)&.
\intertext{Assim criamos uma função.
Qual o tipo dela?
Para decidir o domínio dela, olhamos para o tipo do objeto
substituido por esse buraco.  Nesse caso, consideramos $1 : \reals$, então
temos}
\cos(\bhole + 5\cbrt2)^{2a} + \sin(5) &: \reals \to \reals
\intertext{
Uma outra opção seria escolher o $2$ no $5\cbrt2$, ou até o próprio $5\cbrt2$,
criando assim a função}
\cos(1 + \bhole)^{2a} + \sin(5) &: \reals \to \reals
\endalign
$$
do mesmo tipo.

%%}}}

%%{{{ more than one hole 
\blah.
%%%{{{ meta 
%%%}}}

Podemos botar mais que um buraco na mesma expressão,
assim criando funções de aridades maiores.
Seguimos a convenção que os seus argumentos são botados
nos buracos que aparecem na ordem de esquerda para direita,
e de cima pra baixo.

%%}}}

%%{{{ eg: holed_expression_many 
\example.
%%%{{{ meta 
\label holed_expression_many
%%%}}}

Considere de novo a expressão
$$
\align
\cos(1 + 5\cbrt2)^{2a} + \sin(5) &: \reals,
\intertext{mas agora bote os buracos}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&.
\intertext{Qual o tipo dessa função?
Cada um dos buracos está esperando receber um real,
ou seja:}
\cos(\bhole + 5\cbrt2)^{2\bhole} + \sin(\bhole)&:\reals^3\to\reals
\intertext{Uma outra opção seria criar a função}
\cos(1 + \bhole\cbrt\bhole)^{\bhole a} + \sin(\bhole) &: \reals^4 \to \reals,
\endalign
$$
etc.

%%}}}

%%{{{ x: calculate_holes 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule:
\elist a:
\li: $(2 + \bhole)(40)$;
\li: $(\bhole + 2\bhole)(2,4)$;
\li: $(\dhole \ntimes 2^{\dhole})(3,0)$;
\li: $(\set{1,2,3} \union \dhole)(\set{2,8})$.
\endelist

\solution
Calculamos:
$$
\align
(2 + \bhole)(40) &= 2 + 40 = 42 \\
(\bhole + 2\bhole)(2,4) &= 2 + 2^4 = 18 \\
(\dhole \ntimes 2^{\dhole})(3,0) &= 3 \ntimes 2^0 = 3 \\
(\set{1,2,3} \union \dhole)(\set{2,8}) &= \set{1,2,3} \union \set{2,8} = \set{1,2,3,8}
\endalign
$$

%%}}}

%%{{{ remark: fractions and the symbol of division 
\remark.
%%%{{{ meta 
%%%}}}

Da expressão
$$
\frac 1 2 : \rats
$$
podemos criar as funções
$$
\xalignat3
\frac {\bhole} 2 & : \ints \to \rats &
\frac 1 {\bhole} & : \ints_{\neq0} \to \rats &
\frac {\bhole} {\bhole} & : \ints\times\ints_{\neq0} \to \rats
\endxalignat
$$
Agora o símbolo $\div$ da operação binária de divisão que aparece nos calculadores
talvez faz mas sentido, né?

%%}}}

%%{{{ Limitations 
\note Limitações.
%%%{{{ meta 
%%%}}}

Para um uso simples e rápido as expressões com buracos oferecem uma
ferramenta muito útil.  Mas, temos umas limitações importantes:
\elist a:
\li:
Não podemos ``ligar'' dois ou mais buracos para representar
a idéia que o mesmo argumento vai ser copiado em todos eles.
\li:
Não podemos escolher a ordem que os argumentos da função
criada vão preencher os buracos.
\endelist
Finalmente vamos estudar a notação lambda e com ela vamos
superar essas limitações facilmente!

%%}}}

\endsection
%%}}}

%%{{{ A_touch_of_lambda 
\section Um toque de lambda.
%%%{{{ meta 
\label A_touch_of_lambda
%%%}}}

%%{{{ Useless namings 
\note Nomeamentos inúteis.
%%%{{{ meta 
\label useless_namings
%%%}}}

Imagine que precisamos identificar uma certa função dum conjunto
$A$ prum conjunto $B$, e depois de muitos cálculos e usando várias
outras funções e objetos dados pelo nosso problema,
concluimos com a frase:
\emph{<<\dots a função desejada é aquela função que recebendo
como entrada um número $x$, ela retorna o $2x+5$.>>}.
Vamos isolar esta subfrase:
$$
\text{aquela função que recebendo como entrada um $x$, retorna o \thole$x$\thole}.
$$
O que ela denota?
Claramente uma função.
Mas qual é o \emph{nome} dessa função?
Pois é, ela não tem.
É uma função \emph{anônima}.
Isso talvez parece estranho, mas acontece o tempo todo com outros tipos
de objetos matemáticos, por exemplo com números.
Suponha que temos um triângulo com base $b$ e altura $h$.
Falamos
$$
\textwq{a área do triângulo é $bh/2$}
$$
sem nenhuma obrigação de nomear essa área com um nome para usá-la;
e ninguém reclama.
Se tivessimos essa obrigação deveriamos falar:
$$
\textwq{\dots seja $a = bh/2$.  A área do triângulo é $a$.}
$$
Claramente isso é inútil.
Introduzimos um novo nome apenas para usá-lo logo após e nunca mais.
Em nossa última frase ``a área do triângulo é $a$'', a informação
nem é mais visível.  O leitor vai ter que lembrar qual foi a definição desse $a$,
ou ir procurar achá-la.
Obviamente a abordagem anterior é melhor.
Com ela podemos enunciar nossa proposição numa maneira melhor:
$$
\textwq{a área dum triângulo com base $b$ e altura $h$ é $bh/2$}
$$
em vez de falar algo do tipo
$$
\textwq{a área dum triângulo com base $b$ e altura $h$ é $a$, onde $a = bh/2$.}
$$
\eop
Para usar um exemplo de ``nomeamento inútil'' em programação,
considere as funções seguintes em \indexed[Python]Python
cada uma programada por um programador diferente:
\sourcecode uselessnaming.py;
Como funções são iguais, mas o programador que programou $\code{g}$,
fez algo estranho.
Decidiu nomear a expressão $\code{2 * x + 1}$ com o nome $\code{r}$,
e a única coisa que ele fez com esse $\code{r}$, foi returnar seu
valor.  Pra quê isso, programador?

%%}}}

%%{{{ from_words_to_lambda 
\note De palavras para lambda.
%%%{{{ meta 
\label from_words_to_lambda
\defines
    * função!epônima
    * função!anônima
    ;;
%%%}}}

Voltamos na frase
$$
\text{``aquela função que recebendo como entrada um $x$,
retorna o \thole$x$\thole''}
$$
onde \sq{\thole$x$\thole} é uma expressão que determina um único objeto e que,
possivelmente depende (refere) no $x$, como aconteceu por exemplo com o $2x+5$ acima.
Se essa frase realmente determina uma função, então podemos também
definir uma função \dterm{epônima} (``com nome'') quando desejamos,
escrevendo:
\math
\text{<<Seja $f : A \to B$ tal que} \\
\text{$f \defeq \text{aquela função que recebendo\dots}$>>}.
\endmath
Mas escrever tudo isso toda vez que queremos construir uma função anônima
é muito chato.  Bem vindo $\lamsym$ (lambda) da notação de
λ-calculus!
Escrevemos apenas
$$
\lam x {2x+5}
$$
para a frase:
$$
\mobraceb {\procrustext {aquela função que recebendo como entrada um}} {\lamsym} ~~
\mobraceb {\procrustext {$x$}}       {x} ~~
\mobraceb {\procrustext {retorna o}} {\binderdot} ~~
\mobraceb {\procrustext {$2x + 5$}}  {2x + 5}.
$$

%%}}}

%%{{{ df: lambda_abstraction 
\definition lambda abstracção.
%%%{{{ meta 
\label lambda_abstraction
\defines
    * \lam {~x} {~{\thole}}  -- λ-abstracção
    * λ-abstracção
    * λ-abstracção!corpo
    ;;
%%%}}}

A expressão
$$
\lam x {\text{\thole$x$\thole}}
$$
é chamada \dterm{$\lamsym$-abstracção} e \emph{denota uma função}:
$$
\text{``aquela função que recebendo $x$ como entrada,
retorna o \thole$x$\thole''}
$$
Supomos aqui que o domínio e codomínio são claros pelo contexto.
Chamamos a parte ``\thole$x$\thole'' o \dterm{corpo} da abstracção.

%%}}}

%%{{{ df: barred arrow 
\definition.
%%%{{{ meta 
\label mapsto
\defines
    * (~x \mapsto ~\thole)  -- função anônima
    * setinha barrada
    ;;
%%%}}}

Uma notação diferente usada em matemática para criar funções anônimas
utiliza a \dterm{setinha barrada} \symq{$\mapsto$}:
$$
\text{escrevemos}\qquad
(x \mapsto \thole)
\qqtext{como sinônimo de}
\lam x {\thole}.
$$

%%}}}

%%{{{ remark: we won't use mapsto, we'll use lambdas instead 
\remark.
%%%{{{ meta 
%%%}}}

Não vamos usar muito a notação $(x \mapsto \thole)$.
Pois a notação $\lam x {\thole}$ serve bem melhor para a maioria dos nossos usos.

%%}}}

%%{{{ remark: variables_and_binding_in_lambda 
\remark.
%%%{{{ meta 
\label variables_and_binding_in_lambda
\indexes
    * ligador!de variável
    ;;
\defines
    * ligador!lambda
    ;;
%%%}}}

O $\lamsym$ é um \emph{ligador de variável}.
Todos os $x$ que aparecem livres no {\thole$x$\thole}
viram ligados com o $\alert x$ do $\lamhead x$.
Naturalmente consideramos funções que são diferentes apenas nos
nomes das variáveis ligadas como iguais.
Por exemplo:
$$
\lam x x = \lam y y.
$$
Compare com programação onde uma troca \emph{com cuidado} de variáveis
resulta em programas e procedimentos equivalêntes.
Precisamos tomar os mesmos cuidados aqui, e deixamos os
detalhes formais para o~\ref[Lambdas_and_combinators].

%%}}}

%%{{{ remark: comparison with set builder 
\remark Comparação com set builder.
%%%{{{ meta 
%%%}}}

Num certo sentido o papel de $\lam x {\thole}$ é parecido com o papel
do $\setst x {\thole}$.  O set builder constrói conjuntos (anônimos),
e o $\lamsym$ parece então um \dq{function builder} que constrói funções
(anônimas).

%%}}}

%%{{{ Is it functions that we are really constructing? 
\warning Construimos funções mesmo?.
%%%{{{ meta 
%%%}}}

É ``forte demais'' afirmar que a expressão $\lam x {x^2}$ determina
uma função.  Qual é o seu domínio?  E o categorista vai perguntar também
sobre seu codomínio.
Sem essa informação faz mais sentido considerar que um termo como o $\lam x {x^2}$
corresponde numa \emph{alma}, ou seja, \emph{um comportamento} que em geral
pode ``animar o corpo'' de várias funções.\foot
Aqui tô usando a palavra \wq{corpo} numa maneira mais antropomórfica,
e nesse caso corresponde num \emph{tipo} de função, que tá esperando
uma \emph{alma para habitá-lo}.
Quando pegamos emprestada a terminologia de programação a mesma palavra
\wq{corpo} acaba significando algo diferente:
aí, o corpo duma ``função'' seria o código que
determina o seu comportamento.
\toof
Se as informações de domínio (e codomínio dependendo da fé) não estão
claras pelo contexto escrevemos o tipo logo após da λ-expressão
para realmente determinar uma função.
Podemos ``tipar'' o termo $\lam x {x^2}$ então
$$
\xalignat3
\lam x {x^2} & \eqtype \reals\to\reals &
\lam x {x^2} & \eqtype \nats\to\nats &
\lam x {x^2} & \eqtype \set{0}\to\nats
\endxalignat
$$
etc., e agora sim cada uma dessas determina mesmo uma função.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então:
o $\lamsym$ nos permite criar funções anônimas numa maneira simples e útil.
E o que podemos fazer com uma expressão dessas?
\emph{Tudo} que podemos fazer com uma função!

%%}}}

%%{{{ eg: applying an anonymous function to an argument 
\example.
%%%{{{ meta 
%%%}}}

Calculamos:
$$
\align
\plam x {2x+5} (4) &= 2\ntimes 4 + 5 = 13 \\
\plam x x (2)      &= 2.
\endalign
$$
Em geral omitimos as parenteses no argumento, escrevendo:
$$
\plam x {2x+5} \lapp 4, \qquad
\plam x x \lapp 2, \qquad
\text{etc.},
$$
algo que acontece com funções epônimas também
(veja~\ref[function_notation]).

%%}}}

%%{{{ dot-till-end convention 
\note Convenção.
%%%{{{ meta 
%%%}}}

Para evitar uso excessivo de parenteses, acordamos que o corpo duma
λ-abstracção estende o maior possível, por exemplo:
$$
\plam x {x + y + z}
\qqtext{significa}
\plam x {\paren{x + y + z}}.
$$

%%}}}

%%{{{ The soul of λ-computation 
\note A alma da λ-computação.
%%%{{{ meta 
%%%}}}

Assim que aparecer uma coisa $\heart$ no lado duma
λ-abstracção $\plam x {\dotswithsome x}$
temos uma expressão \dterm{reductível} (chamada \dterm{β-redex})
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \lapp \heart
$$
ou seja, podemos fazer um passo computacional:
\emph{substituir o redex inteiro por uma nova expressão
criada substituindo todas as ocorrências livres de $x$ no $\tau(x)$
por $\heart$, chegando assim no $\tau(\heart)$}.
Denotando esse passo com um \symq{$\bstep$}, temos então
$$
\plam x {\mubrace {\dotswithsome x} {\tau(x)}} \la \heart
\bstep
\mubrace {\dotswithsome \heart} {\tau(\heart)}.
$$

%%}}}

%%{{{ eg: calculate lambda reduction 
\example.
%%%{{{ meta 
%%%}}}

Calcule a expressão:
$$
\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50.
$$

\solution.
Procuramos achar \emph{redexes} e achamos dois:
$$
\xalignat2
&\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50} &
&\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50.
\endxalignat
$$
Então temos dois caminhos diferentes para seguir.
Vamos tentar ambos:
$$
\align
\redex {\plam x {2 + \plam y {x - y} \lapp 8} \lapp 50}
&\lstep 2 + \redex {\plam y {50 - y} \lapp 8} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\intertext{%
Escolhendo o outro caminho, talvez chegamos em algum valor
diferente.
Vamos ver:
}
\plam x {2 + \redex {\plam y {x - y} \lapp 8}} \lapp 50
&\lstep \redex {\plam x {2 + \paren{x - 8}} \lapp 50} \\
&\lstep 2 + \paren{50 - 8} \\
&\isteq 44.
\endalign
$$
Interessante.
Chegamos no mesmo valor.
Mas talvez foi coincidência.

%%}}}

%%{{{ Church--Rosser: No it wasn't 
\note Church--Rosser: <<Foi não>>.
%%%{{{ meta 
%%%}}}

{\Church[teorema Church--Rosser]}%
{\Rosser[teorema Church--Rosser]}%
Graças ao teorema Church--Rosser que vamos estudar no~\ref[Lambdas_and_combinators]
sabemos que se existem dois caminhos que chegam em dois valores ``finais'',
não podem ser valores diferentes.
Isso não quis dizer que as escolhas não importam,
pois pode ser que um caminho nem termine!
Mas se dois caminhos realmente chegarem em valores finais mesmo,
então chegaram no mesmo valor!\foot
Essa é uma grande hipersimplificação do teorema de Church--Rosser;
para a versão ``raiz'', paciência até o~\ref[Lambdas_and_combinators].
\toof

%%}}}

%%{{{ x: calculate_lambda_expressions 
\exercise.
%%%{{{ meta 
\label calculate_lambda_expressions
%%%}}}

Calcule os seguintes:
% TODO: fix reflabs
\elist a:
\li: $\plam x x \la 5$;
\li: $\plam y {42} \la 5$;
\li: $\plam z x \la 5$;
\li: $\plam x {x+1} \la 41$;
\li: $\plam x {2 + \plam y {3y} \la 5} \la 3$;
\li: $\plam x {2 + \plam y {3y} \lap {x^2} } \la 3$;
\li: $\plam x {2 + \plam y {xy} \la 4 } \la 3$;
\li: $\lam x {\plam x {x + 1} \la 1 \ntimes \plam y {xy} \la 4}$. % <- cited as "last"
\endelist
Em cada passo, sublinhe o redex que tu escolheu para reduzir.
Não se preocupe se uns deles parecem errados ou bizarros,
nem se tu errar calculando uns deles; mas verifique tuas respostas.

\solution
Calculamos:
$$
\align
\redex {\plam x x \la 5}      &\lstep 5 \\
\redex {\plam y {42} \la 5}   &\lstep 42 \\
\redex {\plam z x \la 5}      &\lstep x \\
\redex {\plam x {x+1} \la 41} &\lstep 41 + 1 \\
&\isteq 42 \\
\redex {\plam x {2 + \plam y {3y} \la 5} \la 3}
&\lstep 2 + \redex{\plam y {3y} \la 5} \\
&\lstep 2 + 3\ntimes 5 \\
&\isteq 17 \\
\redex {\plam x {2 + \plam y {3y} (x^2)} \la 3}
&\lstep 2 + \redex {\plam y {3y} \lap {3^2}} \\
&\lstep 2 + 3 \ntimes 3^2 \\
&\isteq 29 \\
\plam x {2 + \redex {\plam y {xy} \la 4}} \la 3
&\lstep \redex {\plam x {2 + x\ntimes 4} \la 3} \\
&\lstep 2 + 3 \ntimes 4 \\
&\isteq 14 \\
\lam x {\plam x {x + 1} \la 1 \ntimes \redex {\plam y {xy} \la 4}}
&\lstep \lam x {\redex {\plam x {x + 1} \la 1} \ntimes x\ntimes 4} \\
&\lstep \lam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \lam x {8x}.
\endalign
$$
Se o último cálculo parece insatisfatório, é apenas
por causa de um preconceito teu que favorece os objetos
de tipo ``número'' contra os objetos de tipo ``função''.
Mais sobre isso no~\ref[first_class_citizens].

%%}}}

%%{{{ x: find_expressions_with_given_types_abstract 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_abstract
%%%}}}

Quando puder, escreva λ-expressões que podem ser
tipadas com os tipos seguintes:
$$
\xalignat2
&\aligned
&: A \to A \\
&: A\cross B \to A \\
&: A\cross B \to B \\
&: A\cross A \to A \\
&: A \to A \cross A \\
&: A \to A \cross B
\endaligned
&
&\aligned
&: A \cross B \to B \cross A \\
&: A \union B \to A \\
&: A \to A \union B \\
&: A \cross B \to A \union B \\
&: A \union B \to A \cross B \\
&: \paren{\pfprod A B \union \pfprod C D} \to \pfprod {(A \union C)} {(B \union D)}.
\endaligned
\endxalignat
$$
Observe que sobre os $A,B$ tu não tens nenhuma informação.
Pode achar mais que uma resolução para algum desses desafios?

%%}}}

%%{{{ x: find_expressions_with_given_types 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types
%%%}}}

Escreva λ-expressões que podem ser tipadas com os tipos seguintes:
$$
\align
&: \nats \to \nats \\
&: \nats^2 \to \nats \\
&: \nats \to \nats^2 \\
&: \pset\nats\setminus\set{\emptyset} \to \nats \\
&: \pset\nats \to \nats \\
&: \psetfin\nats \to \nats.
\endalign
$$
Tente usar o argumento no corpo dos teus λ-termos se puder.

%%}}}

%%{{{ x: eta_conversion_first_encounter 
\exercise.
%%%{{{ meta 
\label eta_conversion_first_encounter
%%%}}}

Seja $f : A \to B$.
Qual nome tu daria para a função $\lam x {f \app x}$?
Lembre-se que graças as convenções notacionais essa expressão é a mesma com a
$\lamp x {f(x)}$.

\hint
Como a função $\lam x {f \app x}$ comporta?

\solution
$f$.

%%}}}

%%{{{ β-reduction 
\note β-reducção.
%%%{{{ meta 
%%%}}}

O nome real desse passo computacional de λ-cálculo que encontramos
aqui é \dterm{β-reducção}, e o redex é formalmente chamado um
\dterm{β-redex}.
Para enfatizar quando for necessário escrevemos \symq{$\betastep$} para denotar
um passo de β-reducção.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tem mais duas regras de λ-computação:
α-renomeamento e η-conversão.

%%}}}

%%{{{ α-renaming 
\note α-renomeamento.
%%%{{{ meta 
%%%}}}

O princípio que nos permite identificar como equivalentes as λ-expressões
que diferem apenas nas escolhas das suas variáveis ligadas é chamado
\dterm{α-renomeamento} ou \dterm{α-conversão} ou
\dterm{α-equivalência}.
Podemos considerar cada λ-abstracção um \dterm{α-redex};
denotamos por \symq{$\alphastep$} um passo onde aconteceu um α-renomeamento.

%%}}}

%%{{{ eg: alpharename_code 
\example em programação.
%%%{{{ meta 
\label alpharename_code
%%%}}}

Considere o código seguinte:
\sourcecode alpharename1.py;
Aqui parece que o $\code{z}$ é uma variável já declarada e definida
no escopo exterior.
Deve ser óbvio que podemos trocar a variável $\code{x}$ por
qualquer variável que não aparece livre no corpo da $\code{f}$.
Escolhendo trocá-la por $\code{y}$, por exemplo, chegamos na função
equivalente:
\sourcecode alpharename2.py;
onde semanticamente nada mudou no nosso programa.
Mas seria errado ter escolhido a $\code{z}$, pois ela capturaria
a antes-livre $\code{z}$ do corpo da $\code{f}$:
\sourcecode alpharename3.py;
Isso não é mais o mesmo programa.
Antes a função $\code{f}$ poderia ser descrita como
\standout
<<a função que retorna o produto da sua entrada com $z$>>;
\endstandout
uma descripção que serve para qualquer um dos dois primeiros programas.
Observe que não usei nem \symq{$x$} nem \symq{$y$} nessa frase,
mas não teria como descrevé-la sem usar a \symq{$z$}.
Já a terceira função seria
\standout
<<a função que retorna o quadrado da sua entrada>>;
\endstandout
algo claramente diferente.

%%}}}

%%{{{ eg: alpharename_sets 
\example em conjuntos.
%%%{{{ meta 
\label alpharename_sets
\indexes
    * variável!capturada
    ;;
%%%}}}

Considere o conjunto seguinte:
$$
\setst x {x < z^2}.
$$
Obviamente podemos trocar o \symq{$x$} por qualquer variável que não aparece
livre no filtro \symq{$x < z^2$}, por exemplo por \symq{$y$}:
$$
\setst x {x < z^2}
\inteq
\setst y {y < z^2};
$$
mas não poderiamos ter escolhido substituir o \symq{$x$} por \symq{$z$},
pois assim aconteceria \emph{captura de variável}
(já discutimos isso no~\ref[variable_capturing_in_set_builder]).

%%}}}

%%{{{ η-conversion 
\note η-conversão.
%%%{{{ meta 
%%%}}}

Essa é a idéia de \emph{extensionalidade} para o sistema:
se duas expressões comportam na mesma maneira, as consideramos equivalentes.
Qualquer expressão da forma $\lam x {f \app x}$ é um \dterm{η-redex},
e denotamos por \symq{$\etastep$} o passo onde o substituimos por $f$.

%%}}}

%%{{{ pic: η-wrapping 
\note η-wrapping desenhado.
%%%{{{ meta 
%%%}}}

Começa com uma função $g$; agora pega um embrulho preto e embrulhe;
e pronto, tu criou uma ``nova'' função.
Só que não é tão nova né?
Talvez tu vai rotulá-la como $f$ ou talvez vai escolher um rótulo
mais honesto, como $\lam x {g \app x}$.
$$
\xalignat3
&\tikzpicture
\tikzi blackboxfuneta0;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta1;
\endtikzpicture
&
&\tikzpicture
\tikzi blackboxfuneta2;
\endtikzpicture
\endxalignat
$$
A η-conversão nos permite identificar as duas caixas acima.

%%}}}

%%{{{ eg: etawrap_code 
\example em programação.
%%%{{{ meta 
\label etawrap_code
%%%}}}

Considere o código seguinte, que corresponde no desenho acima:
\sourcecode etawrap.py;
Deve ser óbvio que essa $\code{f}$, como função,
comporta na mesma maneira que a $\code{g}$.

%%}}}

%%{{{ x: etawrap_sets 
\exercise em conjuntos.
%%%{{{ meta 
\label etawrap_sets
%%%}}}

Qual seria o equivalente de η-conversão para os conjuntos?

\solution
$A = \setst x {x \in A}$.

%%}}}

%%{{{ eg: alpha beta eta steps 
\example.
%%%{{{ meta 
%%%}}}

Computamos a mesma expressão usando dois caminhos diferentes:
$$
\xalignat2
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\estep \redex {\plam y {y^2}} \lapp 3 \\
&\astep \redex {\plam x {x^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
&
&\aligned
\redex {\plam x {\plam y {y^2} \lapp x}} \lapp 3
&\astep \redex {\plam y {\plam y {y^2} \lapp y}} \lapp 3 \\
&\estep \redex {\plam y {y^2} \lapp 3} \\
&\bstep 3^2.
\endaligned
\endxalignat
$$
Observe que provavelmente nenhum humano sano escolheria esse
α-renomeamento no segundo caminho, pois a expressão
piorou para nossos olhos humanos; aqui escolhi proceder assim
para enfatizar que não tem nada (literalmente) errado nisso.

%%}}}

\endsection
%%}}}

%%{{{ Partial_application 
\section Aplicação parcial.
%%%{{{ meta 
\label Partial_application
%%%}}}

%%{{{ Partial application with black boxes 
\note Aplicação parcial com black boxes.
%%%{{{ meta 
%%%}}}

Suponha que temos uma função de aridade~$2$:
$$
f : (A\times B) \to C.
$$
Ou seja, nossa função, ``para funcionar'', precisa receber
exatamente dois argumentos: algum $a\in A$ e algum $b\in B$
para ``produzir'' o valor $f(a,b) \in C$: $$
\tikzpicture
\tikzi blackboxfunpartapp1;
\endtikzpicture
$$
Queremos utilizar essa função de aridade~$2$,
para criar duas outras, cada uma de aridade~$1$.
A idéia é a seguinte: vamos ``fixar'' uma das suas entradas
com um valor, e deixar a outra como entrada mesmo.
Imagine que fixamos um certo $b_0\in B$ no segundo ``cabo'' de entrada,
puxamos o outro cabo, e criamos uma nova caixa assim:
$$
\tikzpicture
\tikzi blackboxfunpartapp2;
\endtikzpicture
$$
E agora pintamos preta nossa caixa, escrevemos seus rótulos (seu tipo),
e pronto, construimos uma nova função de aridade $1$:
$$
\tikzpicture
\tikzi blackboxfunpartapp3;
\endtikzpicture
$$
Observe que temos $f(\dhole,b_0):A \to C$.
Vamos agora ver a mesma idéia usando buracos, sem black boxes.

%%}}}

%%{{{ Partial application using holes 
\note Aplicação parcial usando buracos.
%%%{{{ meta 
%%%}}}

Considere uma função $f$ de aridade 3:
$$
A \times B \times C \longtoby f D.
$$
Lembre-se que
$$
f(\dhole, \dhole, \dhole) :
A \times B \times C \to D
$$
e ainda mais $f(\dhole, \dhole, \dhole)$ é a própria $f$!
Queremos preencher uns desses buracos, mas não todos.
E nada especial sobre esse $3$.
Em geral, dada uma função $f$ de aridade $n$,
podemos \emph{fixar} $k$ dos seus argumentos
com certos valores, botar buracos nos ouros,
e criar assim uma função de aridade $n-k$.
Uns exemplos vão esclarecer esse processo.

%%}}}

%%{{{ eg: partial_application_holes_eg 
\example.
%%%{{{ meta 
%%%}}}

Considere a função $f : \reals^3 \to \reals$, definida pela
$$
f(x,y,z) = x + y^2 + z^3.
$$
Temos então
$$
\align
f(\dhole,\dhole,\dhole) &: \reals^3 \to \reals.
\intertext{Com aplicação parcial, fixando uns dos seus argumentos,
criamos então as funções seguintes:}
f(2,\dhole,\dhole)      &: \reals^2 \to \reals \\
f(2,\dhole,\sin(2))     &: \reals   \to \reals \\
f(\dhole,\sqrt2,\cbrt2) &: \reals   \to \reals \\
f(\dhole,0,0)           &: \reals   \to \reals.
\endalign
$$
A última, por exemplo, é a $\idof \reals$; a penúltima é a $\lam x {x+4}$.

%%}}}

%%{{{ eg: partial_application_holes_infix_eg 
\example.
%%%{{{ meta 
%%%}}}

Aplicando a função de adição $+ : \nats^2 \to \nats$
parcialmente fixando seu segundo argumento no número $1$,
criamos a função
$$
\align
(\bhole + 1) &: \nats \to \nats
\intertext{que é a função $\namedfun{succ}$ de sucessor;
e fixando seu primeiro argumento no $0$ criamos a}
(0 + \bhole) &: \nats \to \nats
\endalign
$$
que é a $\idof \nats$.

%%}}}

%%{{{ teaser: partial application and currying 
\teaser.
%%%{{{ meta 
%%%}}}

Já que entendeu a relação entre expressões que envovlem buracos
e abstracções lambda com variáveis, espero que nem preciso
explicar que podemos denotar a aplicação parcial $f(2,\dhole)$
por $\lam x {f(2,x)}$.
Mas trabalhando com lambdas é mais comum tratar funções
de aridades maiores que $1$ numa outra maneira, chamada
currificação (\reftag[Currying]).  E a aplicação parcial
brilha ainda mais nesse caso: não precisa nem buracos,
nem variáveis (\ref[partial_application_and_currying])!

%%}}}

\endsection
%%}}}

%%{{{ Higher_order_functions 
\section Funções de ordem superior.
%%%{{{ meta 
\label Higher_order_functions
%%%}}}

%%{{{ Holes again 
\note Buracos de novo.
%%%{{{ meta 
%%%}}}

Já encontramos a idéia de \emph{abstrair} certas partes de uma expressão,
botando \emph{buracos}, criando assim funções de várias aridades.
Além de buracos, trabalhamos com \emph{λ-abstracção} que nos
permitiu dar nomes para esses buracos, ligar (identificar) certos buracos, etc.
Considere novamente uma expressão como a
$$
\cos(1 + 5\cbrt2)^{2a} + \sin(5)
$$
onde $\cos : \reals\to\reals$, $\sin : \reals\to\reals$, e $a\in \reals$.
Botando uns buracos ou abstraindo com lambdas, criamos, por exemplo, as funções:
$$
\alignat2
f_1 &= \cos(1 + 5\cbrt2)^{\bhole a} + \sin(5)            &&\eqtype \reals   \to \reals\\
f_2 &= \cos(\bhole + 5\cbrt{\bhole})^{2a} + \sin(\bhole) &&\eqtype \reals^3 \to \reals\\
f_3 &= \cos(\bhole + \bhole\cbrt2)^{2\bhole} + \sin(5)   &&\eqtype \reals^3 \to \reals\\
f_4 &= \cos(\bhole + \bhole)^{\bhole} + \sin(5)          &&\eqtype \reals^3 \to \reals\\
f_5 &= \bhole + \sin(\bhole)                             &&\eqtype \reals^2 \to \reals\\
f_6 &= \lam x {\cos(1 + 5\cbrt2)^{2x} + \sin(5)}         &&\eqtype \reals   \to \reals\\
f_7 &= \lam {x,y} {\cos(1 + y\cbrt x)^{2a} + \sin(y)}    &&\eqtype \reals^2 \to \reals.
\endalignat
$$

%%}}}

%%{{{ x: verify_abstractions_of_expression 
\exercise.
%%%{{{ meta 
\label verify_abstractions_of_expression
%%%}}}

Para quais entradas cada uma dessas funções retorna o valor da expressão inicial?

\hint
Respeite as aridades!

\solution
Temos
$$
\align
f_1&(2)\\
f_2&(1,2,5)\\
f_3&(1,5,a)\\
f_4&(1,5,2a)\\
f_5&(\cos(1 + 5\cbrt2)^{2a}, 5)\\
f_6&(a)\\
f_7&(2, 5).
\endalign
$$

%%}}}

%%{{{ Higher-order holes 
\note Buracos de ordem superior.
%%%{{{ meta 
%%%}}}

Em todos os exemplos acima, botamos os buracos para substituir
apenas termos cujos valores seriam números (reais).
Expressões tanto como as $2$, $1$, $5$, e $a$,
quanto como as $5\cbrt2$, $2a$, e $\cos(1 + 5\cbrt2)^{2a}$,
denotam, no final das contas, números reais.
Que tal botar um buraco assim:
$$
\cos(1 + 5\cbrt2)^{2a} + \bhole(5)
$$
O que substituimos aqui?  O próprio $\sin$!  Por que não?
E o que tipo de objetos podemos botar nesse buraco?
Um real, não serve: a expressão
$$
\cos(1 + 5\cbrt2)^{2a} + 7(5)
$$
não faz sentido: \emph{ela é mal-tipada}.
O $7$ não pode receber um argumento como se fosse uma função, pois não é.
Que tipo de coisas então cabem nesse buraco?
Funções!
E não funções quaisquer, mas precisam ter um tipo compatível,
com a aridade certa, etc.
Esses buracos são \emph{de ordem superior}.
E com buracos de ordem superior, vêm funções de ordem superior.

%%}}}

%%{{{ pseudodf: higher_order_function 
\pseudodefinition.
%%%{{{ meta 
\label higher_order_function
\defines
    * função!de ordem superior
    ;;
%%%}}}

Dizemos que uma função $f : A \to B$ é de \dterm{ordem superior}
se ela recebe ou retorna funções.

%%}}}

%%{{{ x: type_higher_order_holed_expressions 
\exercise.
%%%{{{ meta 
\label type_higher_order_holed_expressions
%%%}}}

Escreva os tipos das funções seguintes:
$$
\align
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}
\endalign
$$

\solution
Temos
\compute
F_1 &= \cos(1 + 5\cbrt2)^{2a} + \bhole(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_2 &= \bhole(1 + 5\cbrt2)^{2a} + \sin(5)                       &&\eqtype (\reals\to\reals) \to \reals\\
F_3 &= \bhole(1 + 5\cbrt2)^{2a} + \bhole(5)                     &&\eqtype \paren{(\reals\to\reals)\times(\reals\to\reals)} \to \reals\\
F_4 &= \cos(\bhole(1,5\cbrt2)^{2a} + \sin(5)                    &&\eqtype (\reals^2\to\reals)\to\reals\\
F_5 &= \cos(\bhole(1,5\cbrt2)^{2a} + \bhole(\bhole)             &&\eqtype \paren{(\reals^2\to\reals)\times(\reals\to\reals)\times\reals}\to\reals\\
F_6 &= \lam {r,t,u} {\cos(1 + r(u,\cbrt2))^{r(t,a)} + \sin(u)}  &&\eqtype \paren{(\reals^2\to\reals)\times\reals\times\reals}\to\reals
\endcompute

%%}}}

%%{{{ Returning functions 
\note Retornando funções.
%%%{{{ meta 
%%%}}}

Até agora encontramos exemplos onde funções recebem como
argumentos outras funções, mas ainda não conhecemos alguma
função que \emph{retorna função}.
Ou será que conhecemos?
Se tu resolveu o~\ref[calculate_lambda_expressions],
tu já encontrou esse caso, na sua última expressão.
Seguem uns exemplos de operadores de ordem superior que
você talvez já encontrou e até usou na tua vida.

%%}}}

%%{{{ eg: Defining a higher-order functions 
\example Definindo uma função de ordem superior.
%%%{{{ meta 
\indexes
    * função!anônima
    ;;
%%%}}}

Considere a função $F : \nats \to (\nats \to \nats)$ definida pela
$$
\align
F(w) &= \text{aquela função $g : \nats \to \nats$ que recebendo um $x$, retorna $w + x$}.
\intertext{%
Ou, equivalentemente:
}
F(w) &= \text{aquela função $g : \nats \to \nats$ definida pela $g(x) = w + x$}.
\intertext{%
Que tipo de objetos a função $F$ retorna?
Funções!  Nesse caso determinamos exatamente para qualquer entrada
dela, qual seria a função que vai ser retornada.
Observe que na definição de $F(w)$, apareceu a frase
\wq{aquela função $g$\dots}.
Assim baptizamos temporariamente essa função com um nome (``$g$'') à toa:
apenas para referir a ela e retorná-la.
Usando a λ-notação, essa definição fica mais direta, mais elegante,
e (logo) mais legível:
}
F(w) &= \lam x {w + x} \eqtype \nats \to \nats.
\endalign
$$
Observe que no lado direito aparece uma função anônima.

%%}}}

%%{{{ eg: in Python 
\example em Python.
%%%{{{ meta 
\indexes
    * Python
    ;;
%%%}}}

Em Python podemos (ainda bem\dots)~por exemplo escrever:
\sourcecode higher.py;
que corresponde na primeira maneira de definir a $F$, criando e nomeando
a função para ser retornada.
Podemos com $\lamsym$ também:
\sourcecode higherlam.py;
Não ficou melhor?

%%}}}

%%{{{ Q: what type of thing is F(25)? 
\question.
%%%{{{ meta 
%%%}}}

Que tipo de coisa é o $F(25)$?

%%}}}

\spoiler

%%{{{ Answer 
\note.
%%%{{{ meta 
%%%}}}

Antes de responder nessa pergunta, vamos responder numa outra,
ainda mais específica: quem \emph{é} o $F(25)$?
Ou seja:
$$
F(25) = \dots?\dots
$$
Não precisamos pensar nada profundo!
Vamos apenas \emph{copiar fielmente} sua definição (no lado depois do \symq{$=$}), substituindo cada ocorrência de $w$, por $25$:
$$
F(25) = \text{aquela função $g : \nats \to \nats$ que recebendo um $x\in\nats$, retorna o número $25 + x$}.
$$
Ou seja,
$$
F(25) : \nats\to\nats.
$$
Sendo função, podemos chamá-la com um argumento do certo tipo, por exemplo como o $3\in\nats$, e evaluá-la:
$$
\paren{F(25)}(3) = 28.
$$

%%}}}

%%{{{ x: where_did_28_come_from 
\exercise.
%%%{{{ meta 
\label where_did_28_come_from
%%%}}}

De onde chegou esse $28$?

\solution
Seguindo a definição da $F(25)$ ela é a função que recebendo um valor
(agora tá recebendo o $3$), retorna a soma de $25$ e esse valor:
$25 + 3 = 28$.

%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_higher_order
%%%}}}

Escreva λ-expressões que podem ser consideradas como funções com os
tipos seguintes:
$$
\align
F_1&\eqtype \reals \to \reals \\
F_2&\eqtype \reals \to (\reals \to \reals) \\
F_3&\eqtype (\reals \to \reals) \to \reals \\
F_4&\eqtype (\reals \to \reals) \to (\reals \to \reals) \\
F_5&\eqtype (\reals^2 \to \reals) \to \reals \\
F_6&\eqtype (\reals^2 \to \reals) \to (\reals \to (\reals \to \reals)).
\endalign
$$

%%}}}

%%{{{ x: find_expressions_with_given_types_higher_order_abstract 
\exercise.
%%%{{{ meta 
\label find_expressions_with_given_types_higher_order_abstract
%%%}}}

Escreva λ-expressões que podem ser consideradas como funções com os
tipos seguintes, onde $A,B,C$ são conjuntos sobre quais tu não podes supor
absolutamente nada mais!
Para cada um dos tipos, tente escrever as mais λ-expressões realmente
diferentes que tu consegues.
Cuidado: para uns deles não é possível achar nenhuma!
$$
\align
&: A \to B \\
&: A \to (B \to A) \\
&: A \to (B \to B) \\
&: (A \to A) \to A \\
&: A \to (A \to A) \\
&: A \to \bigparen{B \to \paren{(A\to B) \times (A\union C) \times \nats}} \\
&: (A \to (B \to C) \to ((A\times B)\to C)) \\
&: ((A\times B)\to C) \to (A \to (B \to C))
\endalign
$$

%%}}}

%%{{{ first_class_citizens 
\note First-class citizens.
%%%{{{ meta 
\label first_class_citizens
\indexes
    * cidadão da primeira classe
    * first-class citizen    see: cidadão
    * C
    * C++
    * Java
    * Haskell
    * PureScript
    * Idris
    * Agda
    * Racket
    * Clojure
    * Scala
    * Python
    ;;
%%%}}}

O slogan aqui é que funções são \emph{first-class citizens}.
Trabalhando no~\ref[calculate_lambda_expressions], o último cálculo
chega no valor seguinte:
$$
\align
\plam x {\plam x {x + 1} \lapp 1 \ntimes \redex {\plam y {xy} \lapp 4}}
&\lstep \plam x {\redex {\plam x {x + 1} \lapp 1} \ntimes x\ntimes 4} \\
&\lstep \plam x {(1 + 1) \ntimes x \ntimes 4)} \\
&\isteq \plam x {8x}.
\endalign
$$
Como falei na resolução, se esse ``resultado'' (valor final)
não parece satisfatório, é por causa de um preconceito teu que
favorece os objetos de tipo ``número'' contra os objetos de tipo
``função''.
Os números têm o direito de ser valores finais; e as funções
também têm!  Esse ``preconceito'' é bastante alimentado por causa
de varias linguagens de programação que realmente não tratam
as funções em termos iguais com os outros tipos.
Em C, C++, ou Java, por exemplo, não é possível passar como
argumentos funções, nem retorná-las; mas claramente números
podem ser argumentos e também podem ser retornados como saída
de funções.
Por outro lado, linguagens como Haskell, Agda, Idris,
PureScript, Racket, Clojure, Scala, Python, etc.,
adoptam o slogan
\standout
\emph{<<functions are first-class citizens>>}
\endstandout
ou seja, lá temos funções de ordem superior---e logo, felicidade.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Funções de ordem superior não é algo tão desconhecido como
talvez parece.
O leitor já está acostumado com os operadores nos exemplos seguintes:

%%}}}

%%{{{ eg: higher_order_example_composition 
\example Composição.
%%%{{{ meta 
\label higher_order_example_composition
%%%}}}

Sejam conjuntos $A,B,C$.
O operador da composição $\of$
(cuja notação decoramos aqui para especificar
o domínio e codomínio dele e dos seus argumentos)
é o seguinte:
$$
\dhole\oflab ABC\dhole : \bigparen{(B\to C) \times (A\to B)} \to (A\to C).
$$
Observe que ele é um operador de ordem superior, pois seus (dois) argumentos
são funcões, e também pois sua saída também é uma função.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Definimos agora a função $\eval$\/ que faz algo bem simples:
aplica seu primeiro argumento (que deve ser uma função) no seu
segundo (que deve ser um ponto do domínio do primeiro argumento).

%%}}}

%%{{{ df: eval_operation 
\definition eval.
%%%{{{ meta 
\label eval_operation
\defines
    * \evaldc {~A} {~B}  -- a operação que aplica funções de tipo $A\to B$ em objetos de tipo $A$
    * função!eval
    ;;
%%%}}}

Dados conjuntos $A,B$ definimos a função
$$
\align
\eval         &\eqtype \bigparen{(A \to B) \times A} \to B \\
\eval (f, a)  &= f(a).
\endalign
$$
Chamamos essa função de \dterm{evaluação} ou \dterm{avaliação}.
Como fizemos na composição, decoramos essa operação escrevendo
$\evaldc A B$ para esclarecer os conjuntos envolvidos, mas escrevemos
simplesmente $\eval$ quando os $A,B$ são implícitos pelo contexto.

%%}}}

%%{{{ eg: eval is indeed a higher order function 
\example.
%%%{{{ meta 
%%%}}}

Dados conjuntos $A,B$, a $\evaldc A B$ é claramente uma
operação de ordem superior.

%%}}}

%%{{{ x: type_of_restriction_op_with_hole 
\exercise.
%%%{{{ meta 
\label type_of_restriction_op_with_hole
%%%}}}

Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo dos:
$$
\align
f\resto \dhole  &\eqtype ?\\
(\dhole\resto X)\resto(A \to B)
                &\eqtype ?
\endalign
$$

\solution
Temos
$$
\align
f\resto \dhole  &\eqtype \pset A \to \Unionl_{X\in\pset A}(X\to B)\\
(\dhole\resto X)\resto (A \to B)
                &\eqtype \paren{(A \to B) \to (X \to B)}
\endalign
$$

%%}}}

%%{{{ eg: higher_order_example_derivation 
\example Derivação.
%%%{{{ meta 
\label higher_order_example_derivation
%%%}}}

Considere o operador da derivação $\deriv$.
Por exemplo, se $f(x) = x^3 + 5x$, temos
$$
\align
\deriv(f) &= g, \quad \text{onde $g(x) = 3x^2 + 5$}.
\intertext{%
Cuidado, não escrevemos aqui $\deriv(f) = 3x^2 + 5$,
mas podemos escrever
}
\deriv(f) &= \lam x {3x^2 + 5}
\endalign
$$
sim.
Qual o tipo da própria $\deriv$?
Ela recebe e retorna funções de reais para reais, mas não podemos tipá-la
$$
\align
\deriv(\dhole) &: \funs\reals\reals \to \funs\reals\reals
\intertext{%
pois estariamos perdendo a totalidade da $\deriv$:
tem funções no $\funs\reals\reals$ que não são deriváveis.
Ainda mais, seria legal poder iterar o $\deriv$ (\ref[function_iterations])
à vontade.
Logo tipamos assim:
}
\deriv(\dhole) &: \smooths \to \smooths
\endalign
$$
onde $\smooths$ é o conjunto de todas as funções infinitamente
deriváveis: são deriváveis, e suas derivadas também são, e suas
derivadas também, etc.

%%}}}

%%{{{ teaser: partial_functions_teaser 
\teaser funções parciais.
%%%{{{ meta 
%%%}}}

Mas talvez queremos mesmo considerar a $\deriv$ como uma operação
que opera no conjunto $\funs \reals \reals$
\emph{sacrificando} a totalidade.
Chegamos assim no conceito de \emph{função parcial}, que
voltamos a investigar na~\ref[Partial_functions].

%%}}}

%%{{{ eg: higher_order_example_integration 
\example Integração.
%%%{{{ meta 
\label higher_order_example_integration
\credits
    * Riemann : integral
    ;;
%%%}}}

Sejam $a,b\in\reals$ com $a<b$ e seja
$$
\riemannables a b \defeq \setstt {f : [a,b] \to \reals} {$f$ é Riemann-integrável}.
$$
Observe que $\riemannables a b$ é um conjunto de funções.
Definimos o operador
$$
\lam f {\lam x {\int_a^{x} f}} : \riemannables a b \to {\funs {[a,b]} \reals}
$$
cujo argumento é uma função---e ainda mais,
sua saída também é uma função---e logo ele é um operador de ordem superior
também.
Para a integração ``indefinita'' (antiderivadas), seja
$$
R \defeq \setstt {f : \reals\to\reals} {$f$ é Riemann-integrável}
$$
e defina o operador
$$
\int\dhole : R \to \pset{(\reals\to\reals)}
$$
onde $\int f$ é o conjunto das antiderivadas da $F$:
$$
\int f = \setst {F : \reals\to\reals} {\deriv(F) = f}.
$$
Observe que a notação comum em análise é diferente: usamos por exemplo
$\intbv a x {f(t)} t$, e o $\int f$ é visto como uma antiderivada
(que depende duma constante) e não como o conjunto de todas
essas antiderivadas como definimos aqui.

%%}}}

\endsection
%%}}}

%%{{{ Currying 
\section Currificação.
%%%{{{ meta 
\label Currying
%%%}}}

%%{{{ Ha-ha!  My language is better than yours 
\note Ha-ha!  Minha linguagem é melhor que a tua.
%%%{{{ meta 
%%%}}}

Imagine que um amigo definiu uma função $f : \ints^2\to\ints$
trabalhando numa linguagem de programação que não permite
definições de funções de ordem superior.
Queremos escrever um programa equivalente ao programa do nosso amigo
numa outra linguagem que permite sim definir funções de ordem superior
mas não funções de aridade maior que $1$.
Mesmo assim nossas funções podem \emph{chamar} a função $f$ do nosso amigo nos seus corpos.

%%}}}

%%{{{ Q: How can we do this? 
\question.
%%%{{{ meta 
%%%}}}

Como fazer isso?

%%}}}

\spoiler

%%{{{ Answer in Python 
\note Resposta em Python.
%%%{{{ meta 
\label currying_in_python
\indexes
    * Python
    ;;
%%%}}}

Aqui uma resposta, escrita em Python.
\sourcecode currying.py;
Para computar a $\code{f(x,y)}$ usando a $\code{F}$,
usamos a $\code{F(x)(y)}$, ou seja, $\code{(F(x))(y)}$.

%%}}}

\TODO Explicar o que acontece.

%%{{{ x: uncurry first exercise
\exercise.
%%%{{{ meta 
%%%}}}

Resolva o problema converso:
começando com a função de ordem superior $F$,
defina sua versão $f$ (de aridade 2).

\solution
Dados a $F : \ints\to(\ints\to\ints)$,
é só definir a $f : \ints^2\to\ints$ pela $f(x,y) = F(x)(y)$.
Note que a expressão ``$F(x)(y)$'' quis dizer ``$\bigparen{F(x)}(y)$'' mesmo.

%%}}}

%%{{{ Currying 
\note Currificação.
%%%{{{ meta 
\defines
    * currificação
    ;;
%%%}}}

A maneira que conseguimos utilizar funções de ordem
superior mas de aridade $1$, para ``emular'' funções
de aridades maiores é chamada \dterm{currificação},
em homenagem ao Haskell~Curry{\Curry[currificação]}.\foot
O próprio {\Curry}Curry atribuiu o conceito
ao Schönfinkel{\Schonfinkel[currificação]},
mas Frege{\Frege[currificação]} já tinha usado isso antes.
\toof
No exemplo acima dizemos que \emph{$F$ é a currificação da
da $f$}, ou \emph{sua versão currificada}.

%%}}}

%%{{{ Q: How can we define the generic curry and uncurry functions? 
\question.
%%%{{{ meta 
%%%}}}

Usando a λ-notação como podemos definir funções
$\curry, \uncurry$ para a situação mais genérica onde
a função de dois argumentos é do tipo $(A \times B) \to C$?

%%}}}

\spoiler

%%{{{ how_to_construct_curry_inhabitant 
\note Resposta.
%%%{{{ meta 
\label how_to_construct_curry_inhabitant
%%%}}}

Primeiramente vamos nos preocupar com os tipos dessas funções.
São assim:
$$
\cdopt{sep=2cm}
\paren{(A\times B)\to C}  \ar[r, shift left, "\curry"] \| \paren{A \to (B\to C)} \ar[l, shift left, "\uncurry"]
\endcd
$$
Temos então
$$
\curry : \paren{(A\times B)\to C} \longto \paren{A \to (B\to C)}
$$
definida pela
\lmath
\curry(\alert{\dots?}
\endlmath
Como denotar o arbitrário membro do seu domínio $\paren{(A\times B)\to C}$?
Sendo uma função, vou escolher denotá-lo por $f$.  Ajuda.
Voltamos então:
\lmath
\curry(f) = \alert{\dots?}
\endlmath
Que tipo de coisa estamos tentando \emph{construir} no lado direito?
Pelo tipo da $\curry$, deve ser uma função de $A$ para $(B\to C)$.
E o que tenho na minha disposição?  Neste ponto apenas a $f$.
Facilita escrever claramente todas as coisas disponíveis e seus tipos.
Então por enquanto tenho apenas
$$
f : (A\times B) \to C.
$$
E eu quero construir uma função de tipo $A\to (B \to C)$.
Para defini-la preciso deixar claro o seu comportamento então:
\lmath
\curry(f) = \lamhead {\alert{\dots?}}
\endlmath
Como denotar a arbitrária entrada dessa função?
Bem, sendo uma função com domínio $A$, vou escolher denotar
seu argumento por $a$:
\lmath
\curry(f) = \lam a {\alert{\dots?}}
\endlmath
A mesma pergunta: o que eu ganhei e o que tipo de coisa preciso construir agora?
Ganhei um $a : A$, e preciso construir
algo do tipo $B\to C$, ou seja, uma função (então vou começar com um $\lamsym$\dots)
que recebe $B$'s (então $\lam b {\dots}$) e retorna $C$'s:
\lmath
\curry(f) = \lam a {\lam b {\alert{\dots?}}}
\endlmath
Aqui preciso construir um $C$'zinho e eu tenho:
$$
\align
f &: (A\times B) \to C \\
a &: A \\
b &: B
\intertext{%
Fácil!  Pois eu tenho um fornecedor de $C$'s, e ele só
precisa de um par de um $A$'zinho e um $B$'zinho para
funcionar---pun intended---e felizmente eu tenho ambos, e logo
}
f(a,b) &: C
\endalign
$$
Com isso consigo finalmente terminar:
$$
\curry(f) = \lam a {\lam b {f(a,b)}}.
$$
Deixo a definição da $\uncurry$ pra ti:

%%}}}

%%{{{ x: uncurry_using_lambdas 
\exercise.
%%%{{{ meta 
\label uncurry_using_lambdas
%%%}}}

Defina a $\uncurry$.

\hint
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
então sabemos já como começar: basta definir o
$$
\uncurry(\alert{\dots?}\phantom)
$$
Peraí: qual seria uma opção boa para denotar esse argumento?

\hint
Que tipo de coisa é esse argumento?
Uma função $A \to (B\to C)$, ou seja, uma função de ordem
superior; vou escolher $F$ aqui, para me lembrar desse fato.
Voltando então:
$$
\uncurry(F) = \alert{\dots?}
$$
O que eu ganhei e o que eu preciso construir?
Ganhei
$$
F : A \to (B\to C)
$$
e preciso algo do tipo $(A\times B) \to C$.
Então já sei como começar.
Como?

\hint
Sendo uma função, vou já escrever:
$$
\uncurry(F) = \lam {\alert{\dots?}} {\dots}
$$
e preciso escolher como denotar a sua entrada.
E aqui tenho duas abordagens razoáveis:
ou escolher alguma variável como $w,t,\vec w, \vec t$, etc.,
onde ela terá o tipo $A\times B$;
ou usar a λ-notação de aridades maiores escrevendo
$\tup{a,b}$ para a arbitrária entrada dessa função.
Vamos escolher segunda opção (se quiser, pode escolher a primeira).
Continue!

\hint
Estamos aqui então:
$$
\uncurry(F) =
\lam {\tup{a,b}} {\alert{\dots?}}
$$
e o que precisamos construir aqui?
Sendo a ``saída'' duma função com tipo $(A\times B)\to C$,
eu preciso construir uma coisa do tipo $C$.
Mas o que mais eu tenho agora?
Meus dados tem aumentado:
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B)
\intertext{e logo}
a &: A \\
b &: B \\
\alert{??} &: C\\
\endalign
$$
Como posso usá-los para construir algo do tipo $C$?
Eu não tenho um ``fornecedor'' de $C$'s imediato,
mas percebo que tenho um\dots\ fornecedor de fornecedores
de $C$'s!  (Minha $F$.)
E para ela funcionar
preciso oferecer $A$'zinho, e pronto, ela vai fornecer
um fornecedor de $C$'s.
Felizmente temos um $a : A$.
Então temos:
$$
F(a) : ??
$$

\hint
Temos
$$
\align
F &: A\to (B \to C) \\
\tup{a,b} &: (A\times B) \\
a &: A \\
b &: B \\
F(a)    &: B \to C
\intertext{e logo}
F(a)(b) &: ??
\endalign
$$
Termine!

\solution
Queremos definir a
$$
\uncurry : \paren{A \to (B\to C)} \to \paren{(A\times B) \to C}
$$
e \emph{seguindo as dicas} chegamos em:
$$
\uncurry(F) = \lam {\tup{a,b}} {\bigparen{F(a)}(b)}.
$$

%%}}}

%%{{{ type_inference_tree_for_curry 
\note Árvore de inferência de tipo.
%%%{{{ meta 
%%%}}}

A última parte da argumentação acima corresponde na árvore de inferência
seguinte:
$$
\PROOFm {
\A {f \is A \cross B \to C}      \A {x \is A}  \A {y \is B}
                               \I2------------------------- {}
                                   {(x,y) \is A \cross B}
\I2------------------------------------------------------- {}
                        {f(x,y) \is C}
}
$$
Verifique cada passo, e acostume-se com essa forma!

%%}}}

%%{{{ x: type_inference_tree_for_uncurry 
\exercise Acostume-se mesmo.
%%%{{{ meta 
\label type_inference_tree_for_uncurry
%%%}}}

Construa a árvore que corresponde na última parte da
tua resolução do~\ref[uncurry_using_lambdas] caso que
tu não fez isso já enquanto o resolvendo.

\solution
$$
\PROOFm {
\A {f \is A \to (B \to C)}     \A {t \is A \cross B}
                               \I1------------------ {}
                                   {\outl t \is A}
\I2------------------------------------------------- {}
               {f (\outl t) \is B\to C}
                                               \A {t \is A \cross B}
                                               \I1------------------ {}
                                                   {\outr t \is B}
\I2---------------------------------------------------------------- {}
                     {f (\outl t) (\outr t) \is C}
}
$$

%%}}}

%%{{{ syntactic_associativity 
\note Associatividade sintáctica.
%%%{{{ meta 
\label syntactic_associativity
%%%}}}

Considere que temos uma operação binária $\heartop$.
A frase
$$
\text{<<$\heartop$ é associativa>>}
$$
é uma \emph{afirmação matemática:}
$$
\text{para todo $x,y,z$},
\quad
(x \heartop y) \heartop z
=
x \heartop (y \heartop z).
$$
Isso é algo que pode ser demonstrado, suposto, refutado, etc.
Por outro lado, considere as frases seguintes:
$$
\xalignat2
&\aligned
&\textwq{$\heartop$ é associativa na esquerda} \\
&\textwq{$\heartop$ associa na esquerda} \\
&\textwq{$\heartop$ é L-associativa}
\endaligned
&
&\aligned
&\textwq{$\heartop$ é associativa na direita} \\
&\textwq{$\heartop$ associa na direita} \\
&\textwq{$\heartop$ é R-associativa}
\endaligned
\intertext{%
Nenhuma dessas frases é algo que podemos demonstrar, refutar, ou supor!
O que significam então?
Apenas uma convenção sintáctica, que dá significado
às expressões como a \symq{$x \heartop y \heartop z$}
que sem uma associatividade sintáctica não denotam
absolutamente nada (pois têm um erro de aridade).
As frases acima então correspondem respectivamente nas:
}
&x \heartop y \heartop z \syndefeq (x \heartop y) \heartop z &
&x \heartop y \heartop z \syndefeq x \heartop (y \heartop z).
\endxalignat
$$

%%}}}

%%{{{ notational_abuse_curried 
\warning.
%%%{{{ meta 
\label notational_abuse_curried
%%%}}}

Às vezes abusarei essa idéia e escrever o nome duma função
currificada mas usá-la como se ela não fosse; e vice-versa.
Por exemplo, defini (\reftag[eval_operation]) a $\evaldc A B$
como uma função
$$
\evaldc A B : \pfprod {(A \to B)} A \to B.
$$
Ou seja, para chamá-la escrevemos
$$
\evaldc A B (f,a).
$$
Mas (abusando a notação!)~posso considerar o mesmo símbolo
$\evaldc A B$ para denotar sua currificação
$$
\evaldc A B : {(A \to B)} \to A \to B
$$
que \emph{é uma função diferente sim}, nesse caso escrevendo
$$
\evaldc A B \fa f \fa a.
$$
Tudo isso apenas no caso que pelo contexto tá claríssimo qual
das duas funções tá sendo denotada.

%%}}}

\TODO notação de ``aridades maiores'' currificada.

%%{{{ human_eyes_and_ho_types 
\note Olhos humanos e os tipos higher-order.
%%%{{{ meta 
\label human_eyes_and_ho_types
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ partial_application_and_currying 
\note Aplicação parcial e currificação.
%%%{{{ meta 
\label partial_application_and_currying
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ eg: powTwo 
\example powTwo.
%%%{{{ meta 
\label powTwo
%%%}}}

Definimos a função $\namedfun{powTwo} : \nats\to\reals$ pela
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2.
$$
Assim $powTwo\fa 0 = 1$, $\namedfun{powTwo} \fa 10 = 1024$, etc.

%%}}}

%%{{{ remark: looks_like_cancellation 
\remark Parece cancelamento.
%%%{{{ meta 
\label looks_like_cancellation
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Implementations_seq_fam 
\section Novas implementações: seqüências e famílias.
%%%{{{ meta 
\label Implementations_seq_fam
%%%}}}

%%{{{ Q: Can you implement sequences and indexed families? 
\question.
%%%{{{ meta 
%%%}}}

Suponha que alguém robou de ti os tipos (primitivos) de seqüências
e de famílias indexadas.  Dá para se virar sem esses?
Ou seja, tem como defini-los em termos dos outros tipos
que tu (ainda) tens?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Agora que temos funções, podemos apreciar
que qualquer seqüência $\seqn a n$
\emph{pode ser representada por uma função} com domínio $\nats$
e codomínio o conjunto de todos os membros da $\seqn a n$.
Similarmente, uma família $\famst {a_i} {i \in \cal I}$
indexada por um conjunto $\cal I$ \emph{pode ser representada por uma função}
com domínio $\cal I$ e codomínio o conjunto de todos os membros
da $\family {a_i} i$.

%%}}}

%%{{{ imp: sequences_as_functions 
\implementation Seqüências como funções.
%%%{{{ meta 
\label sequences_as_functions
%%%}}}

Chamamos qualquer função $a : \nats \to A$
de \dterm{seqüência de $A$}.
Introduzimos como açúcar sintáctico o
$$
a_n \sugeq a(n).
$$
Com essa definição, quando duas seqüências de $A$ são iguais?
Elas precisam concordar em cada $n \in \dom a$;
e essa implementação atende a especificação pois concorda com
a definição de igualdade do tipo que estamos implementando
(\ref[sequences_equality]).

%%}}}

%%{{{ imp: indexed_families_as_functions 
\implementation Famílias indexadas como funções.
%%%{{{ meta 
\label indexed_families_as_functions
%%%}}}

Chamamos qualquer função $a : \cal I \to A$.
de \dterm{família de $A$ indexada por $\cal I$}.
Introduzimos como açúcar sintáctico o
$$
a_i \sugeq a(i).
$$
Com essa definição, quando duas tais famílias são iguais?
Os conjuntos de índices precisam ser iguais, e as famílias precisam
concordar em cada índice.
Essa implementação atende a especificação pois concorda com
a definição de igualdade do tipo que estamos implementando
(\ref[indexed_families_equality]).

%%}}}

%%{{{ x: implement_tuples 
\exercise.
%%%{{{ meta 
%%%}}}

Implemente as tuplas;
tome cuidado para deixar claro como usá-las;
lembre-se o que elaboramos nas secções~\reftag[Tuples],
\reftag[Cartesian_product], \reftag[Type_implementation_triples],
e~\reftag[More_tuples].

%%}}}

%%{{{ x: implement_multisets 
\exercise.
%%%{{{ meta 
\label implement_multisets
%%%}}}

Implemente os multiset (\reftag[Multisets]);
tome cuidado para deixar claro como usá-las;
lembre-se o~\reftag[multiset_equality].

%%}}}

%%{{{ df: indexed_sets_adult_version 
\definition Conjuntos indexados: versão adulta.
%%%{{{ meta 
\label indexed_sets_adult_version
\defines
    * conjunto!indexado por conjunto
    ;;
%%%}}}

Já conhecemos o quesignifica que um conjunto $A$ é indexado
por um conjunto $B$~(\ref[indexed_set]).
Isso praticamente quis dizer que o $A$ pode ser escrito na forma
$$
A = \setst {\dots b \dots} {b \in B},
$$
ou, mais ``adultamente'' e plenamente:
$$
\text{$A$ é indexado por $B$}
\defiff
\text{existe função sobrejetora $f : B \surto A$}.
$$

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: initial_and_terminal_objects_teaser 
\problem iniciais e terminais teaser.
%%%{{{ meta 
\label initial_and_terminal_objects_teaser
%%%}}}

(1) Quais conjuntos $S$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única função $f:S \to A$.}
$$
(2) Quais conjuntos $T$ (se algum) têm a propriedade seguinte?:
$$
\text{para todo conjunto $A$, existe única função $f:A \to T$.}
$$

\solution
(1) Apenas o conjunto vazio:
a única função que existe de $\emptyset$ para $A$,
é a função vazia.
Se $S \neq \emptyset$ tome $s\in S$ e considere
o conjunto $A = \set{0,1}$.
Já temos duas funções diferentes $f,g : S \to A$:
basta apenas diferenciar elas no $s$.
Tome por exemplo $f = \lam x 0$ e $g = \lam x 1$.
Como $f(s) = 0 \neq 1 = g(s)$, temos $f\neq g$.
(2) Todos os singletons.
Se $T = \emptyset$, tome $A\neq\emptyset$ e observe
que não existe nenhuma função $f : A \to T$.
E se $\card T > 1$, tome $u,v\in T$ com $u\neq v$
e considere o $A = \set 0$.
Já temos duas funções $f,g : A \set T$:
a $f = \lam x u$ e a $g = \lam x v$.
Elas são realmente distintas,
pois $f(0) = u \neq v = g(0)$, e logo $f\neq g$.

%%}}}

\endproblems
%%}}}

% ENTER COMPOSITIONS, IDENTITY, INVERSION, SHIFTS

%%{{{ Composition 
\section Composição.
%%%{{{ meta 
\label Composition
%%%}}}

%%{{{ Composition with black boxes 
\note Composição com black boxes.
%%%{{{ meta 
%%%}}}

Suponha que temos uma configuração de conjuntos e funções assim:
$$
A \toby f B \toby g C.
$$
Note então que a saída da $f$ pode ser usada como entrada para
a $g$:
$$
\tikzpicture
\tikzi blackboxfuncomp1;
\endtikzpicture
$$
Podemos criar um novo black box, conectando os ``cabos'' assim:
$$
\tikzpicture
\tikzi blackboxfuncomp2;
\endtikzpicture
$$
Pintamos preta essa construção, botando os rótulos certos
de domínio e codomínio, e pronto:
$$
\tikzpicture
\tikzi blackboxfuncomp3;
\endtikzpicture
$$
Criamos assim a composição $g\of f$ das funções $f$ e $g$.
Formalmente, chegamos na definição seguinte.

%%}}}

%%{{{ df: fcompose 
\definition.
%%%{{{ meta 
\label fcompose
\indexes
    * composição!de funções    see: função
    ;;
\defines
    * função!composição
    ;;
%%%}}}

Sejam
$A \toby f B \toby g C$.
Definimos a função $g\of f : A\to C$ pela
$$
\paren{g\of f}(x) \defeq g\paren{f(x)}.
$$
Assim temos
$$
\xalignat2
\dom (g\of f) &= \dom f &
\cod (g\of f) &= \cod g.
\endxalignat
$$
Chamamos a $g\of f$ a \dterm{composição} da $g$ com $f$.
Pronunciamos a $g\of f$ também como:
\utter{$g$ seguindo $f$},
\utter{$g$ after $f$},
ou até \wq{$g$ de $f$}.

%%}}}

%%{{{ beware: diagrammatic_notation 
\beware.
%%%{{{ meta 
\label diagrammatic_notation
\indexes
    * diagramática            see: composição
    * notação!diagramática    see: composição
    ;;
\defines
    * ~f \dcom ~g  -- composição escrita na ordem diagramática
    * composição!diagramática
    ;;
%%%}}}

Escrevemos $g\of f$ e não $f\of g$ para a composição na~\ref[fcompose]!
Então quando temos $A\toby f B\toby g C$, a composição é
$A \toby {g\of f} C$, que parece o oposto da ordem das setinhas.
Definimos a notação alternativa
$$
f \dcom g \sugeq g\of f,
$$
chamada \dterm{notação diagramática}
pois concorda com a posição das setinhas do diagrama:
$$
A \toby {f \dcom g} C.
$$
Mas vamos principalmente usar a notação $g\of f$ mesmo.

%%}}}

%%{{{ x: when_is_fog_defined 
\exercise.
%%%{{{ meta 
\label when_is_fog_defined
%%%}}}

Sejam $A \toby f B \toby g C$.
Qual função é a $f \of g$?

\solution
Nem é definida a $f \of g$ no caso geral!
Para ser definida, é necessário e suficiente ter
$A = C$.

%%}}}

%%{{{ why_not_compose_more 
\note Por que não compor mais?.
%%%{{{ meta 
\label why_not_compose_more
%%%}}}

Sejam $f : A \to B$ e $g : B' \to C$, e suponha que $B \psubset B'$.
É tentador definir uma função de composição $g\of f : A \to C$ pela
$$
(g\of f)(x) = g\big(f(x)\big) \quad \text{para todo $x\in A$}.
$$
No final das contas, para qualquer $x\in A$ temos $f(x)\in B$
e como $B\psubset B'$, também temos $f(x) \in B'$.
Então $g(f(x))$ é definido!
Então por que não relaxar pouco a restricção que temos na
definição da composição
$$
\text{de}
\quad
\cod f = \dom g
\quad
\text{para}
\quad
\cod f \subset \dom g
\ \ \text{?}
$$
Usando black boxes, temos as funções
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)   at (4.5,0)    {$x$};
\node (fx) at (0,0)       {$f(x)$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\endtikzpicture
$$
e queremos ``conectar os cabos'' para criar um novo black box
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0.25mm, fill=gray!50]
      (-0.3,0.04)--(-0.3,-0.04)--(0.3,-0.04)--(0.3,0.04)--cycle;
\endtikzpicture
$$
pintar ele preto e considerar como a $g\of f$ de $A$ para $C$ mesmo:
$$
\tikzpicture
\tikzi blackboxfuncompthree;
\node (x)   at (4.5,0)    {$x$};
\node (gfx) at (-4.8,0)   {$g(f(x))$};
\node (gof) at (0,0)      {$g\of f$};
\node (A)   at (2.7,0.7)  {$A$};
\node (C)   at (-2.7,0.7) {$C$};
\endtikzpicture
$$
Qual o problema com isso?
\wq{Nenhum}, disse o Conjuntista orgulhoso.
E realmente muitos matemáticos responderiam a mesma coisa---até
uns irreligiosos---e ficariam usando esse tipo de composição
``mais geral''.
Mas para a gente aqui, vamos supor que para motivos que não
importam---talvez religiosos, ou um TOC mesmo---\emph{não podemos}
conectar esse cabo no meio quando os conjuntos são diferentes:
\standout
\emph{\wq{Não comporás funções $g$ e $f$ se $\cod f \neq \dom g$!}}
\endstandout
Essa suposta restricção, na verdade não nos restringe---pelo contrário:
nos ajuda criar composições ``limpas'' sem gambiarras como essa
``fita durex'' no cabo conectando o $B$ com o $B'$!
Trabalhe agora no exercício seguinte para demonstrar exatamente isso!

%%}}}

%%{{{ x: inclusions_for_compositions 
\exercise.
%%%{{{ meta 
\label inclusions_for_compositions
%%%}}}

Mostre como construir a função criada no~\ref[why_not_compose_more]
como composição de black boxes que contenha as $f$ e $g$ mas
sem nenhuma conexão ``proibida''.

\hint
Tu vai precisar definir uma terceira função $i$, e usar
seu black box na tua construção.

\hint
O que falta é decidir o que botar nos ``?'' abaixo,
e definir formalmente a função que corresponde nesta caixa:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\node (x)    at (4.5,0)     {$x$};
\node (gfx)  at (-4.8,0)    {$g(f(x))$};
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$?$};
\node (iS) at (0.3,0.3)  {$?$};
\node (iT) at (-0.3,0.3) {$?$};
\endtikzpicture
$$

\solution
Definimos a função $i : B \to B'$ pela regra
$$
i(x) = x,   \quad\text{para todo $x\in B$}.
$$
Seu black box então, parece assim:
$$
\tikzpicture
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\endtikzpicture
$$
e é exatamente o ``missing link'' para construir nosso black box:
$$
\tikzpicture
\tikzi blackboxfuncompsubset0;
\draw [rounded corners=0mm]
      (-3,1)--(-3,-1)--(3,-1)--(3,1)--cycle;
\draw[-Latex]  (1.5,0)  -- (0.5,0);
\draw[-Latex]  (-0.5,0) -- (-1.5,0);
\draw [rounded corners=0mm, fill=gray!10]
      (-0.5,0.5)--(-0.5,-0.5)--(0.5,-0.5)--(0.5,0.5)--cycle;
\node (i)  at (0,0)      {$i$};
\node (iS) at (0.3,0.3)  {$B$};
\node (iT) at (-0.3,0.3) {$B'$};
\endtikzpicture
$$
Construimos e usamos então a $g\of i\of f : A \to C$
em vez da ``gambiarrada'' e proibida $g\of f$.
Essa função $i$ é chamada a \dterm{inclusão do $A$ no $B$}
que definimos na~\ref[inclusion_function].

%%}}}

%%{{{ clearer_functional_notation 
\note Preguiça ({clareza!}) na notação funcional.
%%%{{{ meta 
\label clearer_functional_notation
\indexes
    * justaposição
    * notação!funcional
    ;;
%%%}}}

Como tu já se acostumou---eu espero---às vezes denotamos a aplicação duma
função no seu argumento silenciosamente, ou seja, por \dterm{justaposição:}
escrevemos $f x$ em vez do (mais comum em matemática clássica) $f(x)$.
Agora que temos \emph{uma operação padrão} entre funções queremos
pegar emprestada a mesma preguiça e denotar por justaposição a
composição também:
$$
\msymq{fg}
\qqtext{quis dizer}
\msymq{f \of g}.
$$
Com essa convenção, o que seria o
\symq{$f g x$}?
Acontece que ambas as interpretações
$$
\msymq{(f g) x}
\qqtext{ou}
\msymq{f (g x)}
$$
são iguais nesse caso (deu sorte \emph{extensional}\/),
mas \emph{intensionalmente} falando elas correspondem
nas notações tradicionais
$$
\msymq{(f \of g) (x)}
\qqtext{e}
\msymq{f (g(x))}
$$
respectivamente.
E até pior---nossa preguiça não tem fim---entre números também
temos uma operação padrão que denotamos por justaposição:
$$
xy
\qqtext{é o produto}
x\ntimes y.
$$
E supondo que $f,g:\reals\to\reals$ e $x,y\in\reals$,
a expressão
$
\msymq{g f x y}
$
denota o quê?
Sem parenteses, nada, por isso vamos escrever
$$
\msymq{g \fa f \fa (xy)}
\qqtext{ou}
\msymq{(gf)(xy)}
$$
que (ambas!)~denotam o
$$
(g \of f)(x\ntimes y)
$$
que é igual ao $g (f (x\ntimes y))$ pela definição da $\of$.
Eu vou ficar misturando a notação mais tradicional e a notação mais
``funcional'' dependendo do contexto e assim vamos se acostumar com ambas.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora ver uns exemplos para resumir:

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Sejam $f,g,h:\reals\to\reals$ e $x,y\in\reals$.
Usando \symq{$\syneq$} para igualdade sintáctica e \symq{$=$} para igualdade
semántica (veja~\ref[Arithmetic_expressions_syntax_vs_semantics]) temos:
$$
\align
fx         &\syneq f(x) \\
(fg)x      &\syneq (f\of g)(x) = f(g(x))\\
f(gx)      &\syneq f(g(x)) \\
fgh        &\syneq (f\of g\of h) \\
f(ghx)     &\syneq f ((g\of h)(x)) = f(g(h(x))) \\
(fg)h(xy)  &\syneq ((f\of g) \of h)(x\ntimes y)
                   = (f\of g)(h(x\ntimes y)) = f(g(h(x\ntimes y))).
\endalign
$$
Espero que ficou claro.

%%}}}

%%{{{ x: fcom_respects_jections 
\exercise Composição respeita ``-jectividade''.
%%%{{{ meta 
\label fcom_respects_jections
%%%}}}

Sejam $f : A\to B$ e $g : B \to C$.
Demonstre:
\item{(1)} Se $f$ e $g$ são injetoras, então $g \of f$ também é;
\item{(2)} Se $f$ e $g$ são sobrejetoras, então $g \of f$ também é;
\item{(3)} Se $f$ e $g$ são bijetoras, então $g \of f$ também é.

%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
%%%{{{ meta 
%%%}}}

Se $g\compose f$ é bijetora, o que podemos concluir sobre as $f,g$?  Justifique.

%%}}}

%%{{{ x: converse_to_gof_bij_conclusions 
\exercise.
%%%{{{ meta 
%%%}}}

Se $f$ é injetora e $g$ sobrejetora, a $g\compose f$ é necessariamente bijetora?

\solution
Não.
Aqui um contraexemplo:
$$
\tikzpicture
\draw (0,0) ellipse (-.75cm and 1.25cm);
\draw (3,0) ellipse (-.75cm and 1.25cm);
\draw (6,0) ellipse (-.75cm and 1.25cm);
\draw (0,-.5) node {$\bullet$};
\draw (3,.5)  node {$\bullet$};
\draw (3,-.5) node {$\bullet$};
\draw (6,.5)  node {$\bullet$};
\draw (6,-.5) node {$\bullet$};
\draw[|->] (0.2,-.5) -- (2.8,-.5);
\draw[|->] (3.2,-.5) -- (5.8,-.5);
\draw[|->] (3.2,.5) -- (5.8,.5);
\draw[->]  (0.5,1.5) -- (2.5,1.5);
\draw[->]  (3.5,1.5) -- (5.5,1.5);
\draw (0,1.5) node {$A$};
\draw (3,1.5) node {$B$};
\draw (6,1.5) node {$C$};
\draw (1.5,1.20) node {$f$};
\draw (4.5,1.20) node {$g$};
\endtikzpicture
$$

%%}}}

\endsection
%%}}}

%%{{{ Functions_for_free 
\section Funções de graça.
%%%{{{ meta 
\label Functions_for_free
%%%}}}

%%{{{ intro 
\secintro
Investigamos aqui umas funções garantidas de
existir assim que tivermos alguns outros objetos:
conjuntos, funções, etc.
%%}}}

% Identity

%%{{{ df: identity_function 
\definition Identidade.
%%%{{{ meta 
\label identity_function
\indexes
    * identidade    see: função
    ;;
\defines
    * \idof  {~A}  -- a identidade do conjunto $A$
    * \oneof {~A}  -- a identidade do conjunto $A$
    * função!identidade
    ;;
%%%}}}

Seja $A$ conjunto.
A função $\lam x x : A \to A$ é chamada
\dterm{identidade do $A$}.
Denotamos a identidade do conjunto $A$ por $\idof A : A \to A$ ou $\oneof A : A \to A$.

%%}}}

%%{{{ beware: a_or_the_idof 
\beware <<uma>> ou <<a>>.
%%%{{{ meta 
\label a_or_the_idof
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Podemos falar \emph{da} função identidade?
Não, pois para usar o artigo definido precisamos \emph{unicidade}
e não existe uma única <<função identidade>>.
Pelo contrário: para cada conjunto $A$, temos uma função identidade:
a identidade \emph{do $A$}.

%%}}}

% Inclusion

%%{{{ df: inclusion_function 
\definition Inclusão.
%%%{{{ meta 
\label inclusion_function
\defines
    * \incofin {~A} {~B}  -- a inclusão do $A$ no $B$
    * ~i : ~A \incto ~B  -- $i$ é a inclusão do $A$ no $B$ (ou uma injecção)
    * ~i : ~A \subset ~B  -- $A \subsetto B$ (notação alternativa)
    * ~i : ~A \subsetto ~B  -- $i$ é a inclusão do $A$ no $B$
    * função!inclusão
    ;;
%%%}}}

Sejam $A,B$ conjuntos com $A\subset B$.
A função $\lam x x : A \to B$ é chamada \dterm{inclusão do $A$ no $B$}.
Usamos o $\inc$ para denotar uma inclusão e escrevemos
$$
\inc : A \incto B
\qqtext{ou}
\inc : A \subsetto B
\qqtext{ou até}
\inc : A \subset B
$$
para enfatizar que é uma inclusão mesmo.
Decoramos a notação escrevendo $\incofin A B$ quando essa informação
não é implícita pelo contexto.
Todos os $i,\imath,\iota$ são símbolos freqüentemente usados para
denotar inclusões.

%%}}}

%%{{{ remark: inclusion_is_not_id 
\remark.
%%%{{{ meta 
\label inclusion_is_not_id
%%%}}}

Note que seguindo o ponto de vista categorial (\reftag[f_eq_g_catist]),
se $A \psubset B$ então $\incofin A B \neq \idof A$,
mas seguindo o ponto de vista conjuntista (\reftag[f_eq_g_setist]),
temos $\incofin A B = \idof A$.

%%}}}

%%{{{ x: idof_is_not_unique_for_any_religion 
\exercise.
%%%{{{ meta 
\label idof_is_not_unique_for_any_religion
%%%}}}

O~\ref[a_or_the_idof] afirmou que para conjuntos distintos
temos identidades distintas.
Isso é válido para o Conjuntista também?
Ou é como o que descobrimos resolvendo o~\ref[a_or_the_emptyfun]
sobre as funções vazias?:
que para o Categorista tem muitas funções vazias
(uma para cada conjunto) mas para o Conjuntista tem apenas uma
única.
Compare!

\hint
\ref[dom_and_cod_recoverable_or_not].

\solution
Sim: até para o Conjuntista cada conjunto tem sua própria identidade.
Para conjuntos distintos $A \neq B$ temos
$$
\dom(\idof A) = A \neq B = \dom(\idof B)
$$
e logo as identidades são distintas também: $\idof A \neq \idof B$.
Lembre que o domínio é observável pelo Conjuntista:
\ref[dom_and_cod_recoverable_or_not].
O mesmo argumento não passaria sobre as funções vazias,
pois para diferenciá-las precisamos olhar para os seus
codomínios, e isso é algo inobservável pelo Conjuntista.

%%}}}

%%{{{ x: composition_of_inclusions 
\exercise.
%%%{{{ meta 
\label composition_of_inclusions
%%%}}}

Verifique que composição de inclusões é inclusão.

\hint
$A \subset B \mland B \subset C \implies A \subset C$.

%%}}}

%%{{{ beware: incto might be some other injection 
\beware.
%%%{{{ meta 
%%%}}}

A notação $A \incto B$ não sempre denota a própria inclusão; pode ser usada
para denotar uma \emph{injecção} diferente dependendo do
contexto.  A idéia é que mesmo sem ter $A \subset B$ pensamos que uma
injecção determina uma cópia fiel do $A$ dentro do $B$.
Isso vai fazer muito mais sentido na \reftag[Jections], pois per enquanto
nem sabemos o que significa \wq{injecção}!

%%}}}

% Constant and steady

%%{{{ df: constant_function_steady_function
\definition constante; invariável.
%%%{{{ meta 
\label constant_function_steady_function
\indexes
    * função!steady    see: invariável
    ;;
\defines
    * função!constante
    * função!invariável
    ;;
%%%}}}

Dados conjuntos $A,B$, e $b\in B$, definimos a função
$\kon b : A \to B$ pela
$$
\kon b (x) = b.
$$
A $\kon b$ é chamada
\dterm{função constante (do $A$ para $B$) com valor $b$}.
Aqui tanto seu domínio quanto se codomínio estavam
claros pelo contexto então não precisamos sobrecarregar
nossa notação com muitas decorações.
Quando não são e quando importam escrevemos
$\kondom A b$ ou até $\kondomcod A B b$.
Dizemos que uma função $f : A \to B$ é \dterm{constante}
sse ela é constante com valor $b$ para algum $b \in B$:
$$
\align
\text{$f : A \to B$ constante}
&\defiff
\lexists {b \in B} {f = \kon b}.
\intertext{%
Chamamos uma função de \dterm{invariável} (ou \dterm{steady})
sse ela mapeia todos os membros do seu domínio para o mesmo objeto.
Formulamente,
}
\text{$f : A \to B$ invariável}
&\defiff
\lforall {x, y \in A} {f(x) = f(y)}.
\endalign
$$

%%}}}

%%{{{ beware: constant_may_mean_something_different 
\beware O termo ``constante''.
%%%{{{ meta 
\label constant_may_mean_something_different
%%%}}}

Muitos textos usam o termo ``constante'' para descrever o que
chamamos de ``invariável'' (ou ``steady'').
Na maioria dos casos não existe confusão, pois as duas definições
concordam.  Mas precisamos tomar cuidado, como tu vai descobrir
agora fazendo o~\ref[constant_notiff_steady].

%%}}}

%%{{{ x: constant_notiff_steady 
\exercise.
%%%{{{ meta 
\label constant_notiff_steady
%%%}}}

Às vezes aparece como definição de constante a seguinte:
\emph{\wq{A função $f : A \to B$ é constante sse mapeia todos
os membros do seu domínio para o mesmo objeto.}}
Essa definição é equivalente com a~\ref[constant_function_steady_function]?
Ou seja, com nossa terminologia aqui:
$$
\text{$f$ invariável}
\askiff
\text{$f$ constante}.
$$
(Verifique ambas as direcções.)

\hint
$\emptyset$.

\solution
Não.
Por exemplo a função vazia $f : \emptyset\to\emptyset$ é invariável
mas não constante.
Mas realmente temos que
$$
\text{$f$ invariável}
\impliedby
\text{$f$ constante}:
$$
Suponha $f : A \to B$ constante, e logo
seja $b\in B$ tal que $f = \kon b$.
Sejam $x,y \in A$ e calculamos:
$$
f(x) = \kon b (x) = b = \kon b (y) = f(y)
$$
e logo $f$ é invariável.

%}}}

%%{{{ x: constant_with_more_than_one_value 
\exercise.
%%%{{{ meta 
%%%}}}

Uma função $f : A \to B$ pode ser constante com valor $b$
e com valor $b'$ também, com $b \neq b'$?

\hint
$\emptyset$.

\solution
Pode sim.
Isso aconrece exatamente quando $A = \emptyset$
e $B$ possui pelo menos dois membros distintos $b\neq b'$.
Nesse caso temos
$$
\kondom A b = \kondom A {b'}.
$$

%%}}}

%%{{{ x: constant_function_definitions_almost_agree 
\exercise.
%%%{{{ meta 
\label constant_function_definitions_almost_agree
%%%}}}

Sejam $A \toby f B$ com $A \neq \emptyset$.
Demonstre que:
$$
\text{$f$ constante}
\iff
\pexists {b\in B}
\lforall {x\in A}
{f(x) = b}.
$$

\solution
\proofpart {\lrdir:}
Seja $a\in A$ ($A\neq\emptyset$).
Vamos mostrar que tomando $b\asseq f(a)$ a proposição na direita é satisfeita.
Observe que o $f(a)\in B$ e satisfaz
$$
\lforall {x\in A} {f(x) = f(a)}
$$
pela definição de constante.
\crproofpart {\rldir:}
Seja $b_0\in B$ tal que para todo $x\in A$, $f(x) = b_0$.
Agora para todo $x,y \in A$ temos $f(x) = b_0 = f(y)$ pela hipótese,
ou seja, $f$ é constante.

%%}}}

%%{{{ x: constant_function_which_definition_is_stronger 
\exercise.
%%%{{{ meta 
\label constant_function_which_definition_is_stronger
%%%}}}

No caso geral, alguma das direções
da~\ref[constant_function_definitions_almost_agree] é válida ainda?

\solution
Sim, a {\rldir}.
Observe \emph{bem} que na demonstração dessa direção não precisamos $A\neq\emptyset$.
E pelo~\ref[constant_notiff_steady] já sabemos que a {\lrdir} não é
válida em geral.

%%}}}

%%{{{ x: gof_constant_does_not_imply 
\exercise.
%%%{{{ meta 
\label gof_constant_does_not_imply
%%%}}}

Demonstre ou refute a afirmação seguinte:
\emph{se $(g \of f)$ é constante, então pelo menos uma das $f,g$ também é}.

\hint
Tente achar contraexemplo desenhando diagramas internos.

\solution
Falso.
Um contraexemplo é o seguinte:
$$
\tikzpicture
\tikzi gofconstantdoesnotimply;
\endtikzpicture
$$

%%}}}

%%{{{ x: wrong_order_of_quantifiers 
\exercise.
%%%{{{ meta 
\label wrong_order_of_quantifiers
%%%}}}

O que é errado na definição seguinte de função constante?
$$
\text{$f:A\to B$ constante}
\defiff
\pforall {a \in A}
\lexists {b \in B} {f(a) = b}.
$$
Será que substituindo o $\exists$ por $\unique$ o problema tá resolvido?
Sugira uma outra resolução simples.

\hint
Siga essa definição e tente achar alguam função que não vai ser chamada
constante.

\solution
A definição tem o problema que vai aceitar toda função como constante,
pois o que ela exige é satisfeito por toda função.
\emph{Substituindo} o $\exists$ por $\unique$ nada muda nesse sentido,
pois toda função satisfaz essa afirmação mais forte
(determinabilidade de função, \reftag[functionhood_conditions]).
\eop
O problema é que os quantificadores estão na ordem errada!
Simplesmente \emph{trocando a ordem deles}, chegamos numa
definição equivalente à do~\ref[constant_notiff_steady]:
$$
\text{$f:A\to B$ constante}
\defiff
\pexists {b \in B}
\lforall {a \in A}
{f(a) = b}.
$$

%%}}}

% Define as compositions

%%{{{ defining_functions_as_compositions 
\note Definindo funções como composições.
%%%{{{ meta 
\label defining_functions_as_compositions
%%%}}}

Como $(\of)$ é uma operação de funções, ganhamos então mais uma maneira
de definir funções.
Dadas componíveis funções $A \toby f B \toby g C$ podemos
definir uma função $h : A \to C$ apenas escrevendo:
$$
\textwq{Seja $h = g\of f$.}
$$
Claramente (e seguindo a discussão no~\reftag[useless_namings])
não precisamos dar um nome para essa função.
Podemos apenas falar sobre a $g \of f$, exatamente no mesmo
jeito que falamos do número $2 \ntimes 8$ sem precisar
dar um nome pra ele!

%%}}}

% Iterations and idempotent

%%{{{ df: function_iterations 
\definition iterações.
%%%{{{ meta 
\label function_iterations
\defines
    * ~f^~n  -- a $n$-ésima iteração da $f$
    * função!iteração
    ;;
%%%}}}

Seja $f : A \to A$.
Definimos as \dterm{iterações} de $f$ pela recursão
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f\of f^n.
\endalign
$$

%%}}}

%%{{{ eg: calculate_iterate_3_fx 
\example.
%%%{{{ meta 
%%%}}}

Seja $f : A \to A$.  Calculamos:
\compute
f^3(x)
&= (f \of f^2)(x)                      \by {def.~$f^3$} \\
&= (f \of (f \of f^1))(x)              \by {def.~$f^2$} \\
&= (f \of (f \of (f \of f^0)))(x)      \by {def.~$f^1$} \\
&= (f \of (f \of (f \of \idof A)))(x)  \by {def.~$f^0$} \\
&\dotseq (f \of f \of f)(x)            \by {ass.~$\of$; lei da~$\idof A$} \\
&\dotseq f (f (f (x)))                 \by {def.~$\of$} \\
\endcompute
Em geral omitimos parenteses quando a expressão envolve apenas uma operação
associativa;
botamos aqui para enfatizar cada aplicação de definição nesse cálculo.

%%}}}

%%{{{ x: succ3_is_plus_3 
\exercise.
%%%{{{ meta 
\label succ3_is_plus_3
%%%}}}

Como definarias numa maneira simples a função $\succ^3$ para alguém
que não sabe (e sequer quer saber) o que são as iterações duma função?

\solution
Temos $\succ^3 = \lam x {x+3} \eqtype \nats\to\nats$.

%%}}}

%%{{{ beware: notation of functions with exponents 
\beware.
%%%{{{ meta 
%%%}}}

Em certos textos de matemática, aparece a notação $f^n(x)$ como
sinónimo de $(f(x))^n$.
Por exemplo:
$$
\text{quem escreveu\dots}
\quad
\sin^2 x + \cos^2 x
\quad
\aligned
&\text{\dots quis dizer\dots}\\
&\text{\dots mas aqui seria\dots}
\endaligned
\quad
\aligned
&(\sin x)^2   + (\cos x)^2    \\
&\sin(\sin x) + \cos(\cos x).
\endaligned
$$

%%}}}

%%{{{ remark: function_iterations_altdef 
\remark.
%%%{{{ meta 
\label function_iterations_altdef
%%%}}}

Poderiamos ter escolhido definir as potências de $f$ pelas:
$$
\align
f^0     &= \idof A \\
f^{n+1} &= f^n \of f
\endalign
$$
em vez da recursão que usamos na~\ref[function_iterations].
As duas definições são equivalentes, ou seja, as duas operações
de exponenciação definidas são iguais.
Por enquanto pode aceitar isso como um fato que vamos demonstrar
depois (\ref[associative_with_identity_exp_defs_equiv]),
ou esquecer completamente essa definição alternativa.

%%}}}

%%{{{ thm: properties_of_function_iterations 
\theorem.
%%%{{{ meta 
\label properties_of_function_iterations
%%%}}}

A operação de iteração que definimos
no~\ref[function_iterations]
nos endomapas dum conjunto $A$ satisfaz as leis:
% TODO: fix reflabs
\tlist:
\li (1): $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m+n}        = a^m \of a^n}$;
\li (2): $\pforall {n,m\in\nats} \lforall {f : A \to A} {a^{m\ntimes n} = (a^m)^n}$;
\li (3): $\lforall {n\in\nats} {\id^n = \id}$.
\endtlist

\proof Já demonstrado.
Demonstramos por indução as três leis nos exercícios~\reftag[law_of_natexp_1],
\reftag[law_of_natexp_2], e~\reftag[law_of_natexp_3]---se tu não resolveu,
volte a resolver!
Verifique que nossas demonstrações precisaram apenas a \emph{associatividade}
e a \emph{identidade} da multiplicação e \emph{nada da sua definição},
então podemos substituir a multiplicação por nossa $\of$.
Sobre a outra operação envolvida nas demonstrações, a adição, não precisamos
verificar nada, pois nos dois casos é a mesma operação:
a adição nos naturais.

%%}}}

%%{{{ df: idempotent_function 
\definition Idempotente.
%%%{{{ meta 
\label idempotent_function
\indexes
    * idempotente!função    see: função idempotente
    ;;
\defines
    * função!idempotente
    ;;
%%%}}}

Seja $f : A \to A$ um endomapa.
Chamamos a $f$ \dterm{idempotente} sse
$$
f \of f = f.
$$

%%}}}

%%{{{ x: how_many_idempotents_on_AtoA_for_A_triset 
\exercise.
%%%{{{ meta 
\label how_many_idempotents_on_AtoA_for_A_triset
%%%}}}

Seja $A$ conjunto com $\card A = 3$.
Quantas funções idempotentes podemos definir no $A$?

\hint
Use um diagrama interno para endomapas!

\hint
Observe que em geral, aparecem certos ``redemoinhos''
num diagrama interno de endomapa quando ela é idempotente.

\hint
Separe as funções idempotentes dependendo na quantidade
de ``redemoinhos'' que aparecem nos seus diagramas.

\solution
Vamos tentar definir uma $f$ idempotente e contar as escolhas que temos.
Observe que assim que mandamos um $x \mapsto y$, o $f(y)$ ``não tem mais
escolha'': precisa ser $f(y) = y$, pois $f$ deve ser idempotente.
Ou seja, $y$ vai ser um \dterm{ponto fixo} (ou \dterm{fixpoint}) da $f$
(mais sobre isso na~\reftag[Fixpoints]).
A $f$ então deve ter pelo menos $1$ fixpoint, e no máximo $\card A = 3$.
Separamos então por casos, contamos as maneiras em cada caso e usamos
o Princípio da adição~(\reftag[principle_of_addition]) para contar
quantidade total das maneiras.
Defina então
$$
F_i \defeq \setstt {f : A \to A} {$f$ tem exatamente $i$ fixpoints}.
$$
Queremos achar o $\card{F_1} + \card{F_2} + \card{F_3}$.
Calculamos separadamente.:
\eop
\proofpart {Quantas funções no $F_1$?}
Temos $3$ funções, uma para cada escolha de fixpoint, pois
assim que determinamos o único fixpoint, todos os outros membros
devem ser mapeados nele.
\eop
\proofpart {Quantas funções no $F_2$?}
Temos $\comb 3 2 = 3$ maneiras de escolher $2$ dos membros de $A$ para ser
os fixpoints da $f$.  Para cada uma dessas escolhas, temos $2$ opções para
o não-fixpoint (escolher em qual dos dois fixpoints vamos mandá-lo).
Pelo Princípio da multiplicação~(\reftag[principle_of_multiplication]) então
temos $3\ntimes 2 = 6$ funções no $F_2$.
\eop
\proofpart {Quantas funções no $F_3$?}
Apenas uma: a identidade.
\eop
Finalmente podemos responder: existem $3 + 6 + 1 = 10$ funções idempotentes
num conjunto de cardinalidade $3$.

%%}}}

%%{{{ x: constant_implies_idempotent 
\exercise.
%%%{{{ meta 
\label constant_implies_idempotent
%%%}}}

Seja $f : A \to A$.
Demonstre ou refute a implicação:
$$
\text{$f$ constante}
\implies
\text{$f$ idempotente}.
$$

\hint
A implicação é válida.
Demonstre!

\solution
Vamos demonstrar a implicação.
Suponha que $f : A\to A$ é constante.
Caso $A=\emptyset$ a $f$ é a função vazia e a $f\of f$ também.
Caso $A\neq\emptyset$, usamos a definição alternativa
da~\ref[constant_function_definitions_almost_agree].
Seja $c\in A$ tal que para todo $x\in A$, $f(x) = c$\fact1.
Queremos mostrar que $f\of f = f$, ou seja, que para todo $a\in A$,
$$(f\of f)(a) = f(a)$$
(definição de igualdade de funções~\reftag[f_eq_g]).
Calculamos no lado esquerdo:
\compute
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$(\of)$} \\
&= f(c)            \by {pelo \byfact1, com $x \asseq a$} \\
&= c               \by {pelo \byfact1, com $x \asseq c$} \\
\intertext{e no lado direito:}
f(a)
&= c.              \by {pelo \byfact1, com $x \asseq a$} \\
\intertext{Logo, $f \of f = f$ como desejamos.
\eop
Alternativamente, podemos nos livrar dum passo no calculo do lado esquerdo assim:
}
(f\of f)(a)
&= f\paren{f(a)}   \by {def.~$(\of)$} \\
&= c.              \by {pelo \byfact1, com $x \asseq f(a)$} \\
\endcompute

%%}}}

% Characteristic

%%{{{ df: characteristic_function 
\definition Característica.
%%%{{{ meta 
\label characteristic_function
\indexes
    * característica    see: função
    ;;
\defines
    * \chr {~C}  -- a função característica do $C$ (com domínio implícito)
    * \chrdom {~A} {~C}  -- a função característica do $C$ no $A$
    * função!característica
    ;;
%%%}}}

Sejam $A$ conjunto e $C \subset A$.
A \dterm{função característica do $C$ no $A$} é a função
$\chrdom A C : A \to \set{0,1}$ definida pela
$$
\chrdom A C (x) =
\knuthcases {
1, &se $x\in C$;\cr
0, &se $x\nin C$.
}
$$
Escrevemos apenas $\chr C$ quando o domínio $A$ é implícito pelo
contexto---e na práctica esse é quase sempre o caso!

%%}}}

%%{{{ warning: characteristic_function_inverted_values 
\warning.
%%%{{{ meta 
\label characteristic_function_inverted_values
%%%}}}

O uso de $1$ para representar ``true'' e o $0$ para o ``false'' é aleatório.
De fato, dependendo de caso, às vezes definimos a função característica
com esses valores invertidos!  Isso é muito comum em teoria de recursão
(veja~\cite[kleeneIM] por exemplo), mas não só:
nos shells de Unix\indexed[Unix!shell],
também o valor $0$ representa o ``true'' (ou ``deu certo'')
e cada valor positivo o ``false'' (ou ``deu errado'').\indexed[main]\foot
Nesse caso essa escolha é obviamente melhor, pois sabendo que ``deu certo'',
em geral não perguntamos <<por que deu certo?>>; mas se der errado, queremos
saber mais sobre o motivo que deu errado: talvez um arquivo não
existe, talvez uma conexão não pode ser feita, talvez faltou uma permissão,
etc., e cada um desses casos pode retornar um valor positivo diferente.
\eop
Esse ``retornar'' que eu tô me referindo aqui é o proprio $\code{return}$
que muitas vezes estudando programação o aluno acaba memorizando como
``regrinha'' que sua $\code{main}$ precisa terminar com um
``$\code{return 0}$''.  Por quê?  E pra quem que ta retornando isso?
Para o próprio sistema operacional.  No final das contas, foi ele que
chamou essa $\code{main}$.
\toof
\eop
\emph{A moral da estória:}
sempre verifique a definição da função característica
usada---e se quiseres usar num texto teu, sempre bota sua definição junto!
Nesse texto, quando aparece a notação $\chr C$ sem definição,
denota a função que definimos acima na~\ref[characteristic_function].

%%}}}

%%{{{ x: explain_unix_shell_connectives 
\exercise Para os Unixeiros.
%%%{{{ meta 
\label explain_unix_shell_connectives
\indexes
    * Unix!shell
    ;;
%%%}}}

Num shell de Unix (cujo ``prompt'' denoto aqui por \symq{$\code{\#}$})
escrevemos:
\shell
\# cmd1 \&\& cmd2 \CR
\# cmd1 || cmd2
\endshell
onde $\code{cmd1}$ e $\code{cmd2}$ são dois comandos.
Explique o comportamento sabendo que $\code{\&\&}$ e $\code{||}$
denotam os operadores lógicos da conjunção e disjunção (respectivamente).
Conclua que o shell de Unix é ``apenas'' um calculador de valores de verdade
nesse sentido.  Todas as coisas que vão acontecer executando isso
``no mundo real'' são nada mais que \dterm{side-effects} enquanto calculando
os seus comandos, para achar seus valores de verdade.
Como posso dar para o shell a ordem
\wq{executa o $\code{cmd1}$ e depois o $\code{cmd2}$}?

%%}}}

%%{{{ remark: replacing_cases_by_characteristic_functions 
\remark.
%%%{{{ meta 
\label replacing_cases_by_characteristic_functions
%%%}}}

Um dos usos comuns de funções características é definir funções num jeito mais
curto, aproveitando os fato que $0x = 0$ e $1x = x$ para todo $x\in\reals$.
Esse uso lembra das expressões $\namedfun{if-then-else}$ que usamos
em linguagens de programação.

%%}}}

%%{{{ eg: replacing_cases_by_characteristic_functions_example 
\example.
%%%{{{ meta 
\label replacing_cases_by_characteristic_functions_example
%%%}}}

Considere a $f : \reals \to \reals$ definida pela
$$
f(x) = \knuthcases {
2\cbrt{x + \log_2 |x+1|} + x^2, & se $x \in \rats$ \cr
2\cbrt{x + \log_2 |x+1|} + e^x, & caso contrário.
}
$$
Usando as funções características de $\rats$ e $\reals\sminus\rats$
podemos definir a $f$ com uma equação só, e ``sem repetição'':
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + x^2 \chr\rats (x) + e^x \chr{\reals\sminus\rats} (x).
$$
Isso lembra um
$$
f(x) = 2\cbrt{x + \log_2 |x+1|} + \PIF x \in \rats \THEN x^2 \ELSE e^x \FIP.
$$
usado em linguagens de programação que suportam \dterm{if-then-else expressions}.

%%}}}

%%{{{ beware: expressions_vs_statemets 
\beware expressions \vs statements.
%%%{{{ meta 
\label expressions_vs_statemets
\indexes
    * C
    * Haskell
    ;;
\defines
    * expressão!\vs statement
    * statement!\vs expressão
    ;;
%%%}}}

Uma \dterm{if-then-else expression} não é a mesma coisa com um
\dterm{if-branching statement} encontrado em muitas linguagens de
programação imperativas.  A idéia é que uma expressão denota um
valor; um statement é apenas uma ordem para ser executada.
A linguagem C por exemplo tem ambas mas o que escrevemos em C
com ``\code{if}\dots''~corresponde no branching \emph{statement}.
Nunca faria sentido em C, por exemplo, multiplicar um
\emph{if statement} por um número.
A \emph{expressão} if-then-else de C corresponde no seu único
operador ternário, com a sintaxe (bizarra)
$$
\text{\code(\thole\code?\thole\code:\thole\code)}.
$$
Em Haskell, por outro lado, escrevemos mesmo
$$
\text{\code{if}\thole\code{then}\thole\code{else}\thole}.
$$

%%}}}

%%{{{ x: char_compose_char 
\exercise.
%%%{{{ meta 
%%%}}}

Sejam $A,X$ conjuntos com $A\subset X$.
Suponha que $\chrdom X A \of \chrdom X A$ é definida.
O que podes concluir sobre o $X$?
Podemos concluir que a $\chr A \of \chr A$ é constante ou a identidade?

\hint
O fato que uma composição é definida dá informação sobre um domínio
e um codomínio envolvido.

\solution
Temos $\chr A : X \to \set{0,1}$.
Como a composição $\chr A \of \chr A$ é definida,
concluimos que $\cod(\chr A) = \dom(\chr A)$.
Ou seja, $X = \set{0,1}$.
\eop
O $A$ sendo um subconjunto de $\set{0,1}$ so tem 4 possibilidades:
$$
\xalignat4
A &= \emptyset; &
A &= \set{0};   &
A &= \set{1};   &
A &= \set{0,1} = X.
\endxalignat
$$
Calculamos em todos os casos:
$$
\align
A = \emptyset &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 0
\endaligned
} \\
A = \set{0} &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(1) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(0) = 1
\endaligned
} \\
A = \set{1} &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = \chr A(0) = 0 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = \chr A(1) = 1
\endaligned
} \\
A = X &\implies
\leftbrace {
\aligned
(\chr A \of \chr A)(0) &= \chr A(\chr A(0)) = 1 \\
(\chr A \of \chr A)(1) &= \chr A(\chr A(1)) = 1\,.
\endaligned
}
\endalign
$$
Sobre a $\chr A\of\chr A$ então concluimos que
se $A$ é um dos singletons $\set{0}$ ou $\set{1}$ então ela é a identidade.
Caso contrário, ela é uma constante:
se $A = \emptyset$, a constante $0$; se $A = X$, a constante $1$.

%%}}}

% restriction

%%{{{ df: fresto 
\definition Restricção.
%%%{{{ meta 
\label fresto
\defines
    * ~f \resto    ~X    -- a restricção de $f$ no $X$
    * ~f \restosub {~X}  -- $f \resto X$ (notação alternativa)
    * função!restricção
    ;;
%%%}}}

Sejam $f : A \to B$ e $X \subset A$.
A \dterm{restricção da $f$ no $X$}, denotada por
$\resfun f X$ é a função de $X$ para $B$ definida pela
$$
(\resfun f X) \fa x = \fA f x.
$$
Também é usada a notação $\resfunsub f X$.

%%}}}

%%{{{ x: type_of_f_resto_X 
\exercise.
%%%{{{ meta 
\label type_of_f_resto_X
%%%}}}

Sejam $f : A\to B$ e $X\subset A$.
Ache o tipo de
$
f\resto X
$.

\solution
$f\resto X \is X \to B$.

%%}}}

%%{{{ x: fresto_pointfree 
\exercise restrição sem pontos.
%%%{{{ meta 
\label fresto_pointfree
%%%}}}

Sejam $A,B$ conjuntos e $X\subset A$.
Defina a função $f \resto X$ sem usar nenhuma referência aos membros desses conjuntos.
Na~\ref[fresto], por exemplo, usamos esse $x$ para representar um mebro de $A$.
(Esqueça o ``sem pontos'' no rótulo desse exercício;
vai fazer sentido depois:~\reftag[Pointfree_style].)

\hint
Defina como composição de funções conhecidas.

\hint
Inclusão.

\solution
$f\resto X = \incofin X A \of f$.

%%}}}

\endsection
%%}}}

%%{{{ Inverse_functions 
\section Funções inversas.
%%%{{{ meta 
\label Inverse_functions
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Informalmente, para construir a inversa duma função
pegamos o seu diagrama interno, e viramos todas
as setinhas barradas para a direção oposta.
Vamos estudar essa idéia formalmente agora.

%%}}}

%%{{{ df: finverse 
\definition função inversa.
%%%{{{ meta 
\label finverse
\defines
    * \finv {~f}  -- a função inversa da $f$
    * função!inversa
    ;;
%%%}}}

Seja função bijetora $f : A \bijto B$.
Definimos a função $\finv f : B \to A$ pela
$$
\finv f (y) \defeq \text{aquele $x\in A$ que $x \mapstoby f y$}.
$$
Ou, \emph{equivalentemente}, pela
$$
\finv f (y) = x \defiff f(x) = y.
$$
Com outra notação:
$$
y \mapstoby {\finv f} x \defiff x \mapstoby f y.
$$
Chamamos a $\finv f$ a \dterm{função inversa} da $f$.

%%}}}

%%{{{ remark: human_eyes_are_not_symmetric 
\remark Os olhos humanos não são simétricos.
%%%{{{ meta 
\label human_eyes_are_not_symmetric
%%%}}}

Às vezes a direção em que a gente olha para uma igualdade faz diferença:
$$
\alpha = \beta \iff \beta = \alpha
$$
sim, ou seja, \symq{$=$} é simétrica,
mas nossos olhos humanos conseguem enxergar certas informações melhor na
forma $\alpha = \beta$, e outras na forma $\beta = \alpha$!
(Talvez nossos olhos não são tão simétricos.)
A mesma coisa é sobre relações ``direcionadas'' como por exemplo:
$$
\alpha \leq \beta \iff \beta \geq \alpha
$$
que também são afirmações equivalentes,
mas muitas vezes a gente enxerga uma numa maneira diferente da outra!
\eop
Na~\ref[finverse] acima, por exemplo, reescrevendo a igualdade
na outra direção temos:
$$
\finv f (y) = x \defiff y = f(x)
$$
que possivelmente nos permite enxergar a situação numa maneira diferente.
Similarmente, usando a notação das setinhas barradas podemos enxergar
a equivalência assim:
$$
x \mapsfromby {\finv f} y \defiff x \mapstoby f y.
$$

%%}}}

%%{{{ x: finv_is_well_defined 
\exercise A inversa é bem-definida.
%%%{{{ meta 
\label finv_is_well_defined
%%%}}}

Demonstre que a função $\finv f$ foi bem-definida.
O que precisas demonstrar?

\solution
Pelo menos um tal $x\in A$ existe, pois a $f$ é sobrejetora.
E como $f$ é injetora, existe no máximo um.
Demonstramos assim a unicidade, algo que nos permite
\emph{definir a função} no jeito que definimos
na~\ref[finverse].

%%}}}

%%{{{ x: finv_is_bij 
\exercise A inversa é bijetora.
%%%{{{ meta 
\label finv_is_bij
%%%}}}

Demonstre que quando a função inversa $\finv f$ é definida, ela é bijetora.

\hint
O que exatamente garanta a injectividade da $\finv f$, e o que a sua sobrejectividade?

\hint
Considere:
$$
\align
\text{totalidade da $f$}        &\implies \text{$\finv f$ sobrejetora} \\
\text{determinabilidade da $f$} &\implies \text{$\finv f$ injetora}.
\endalign
$$

%%}}}

%%{{{ x: finv_of_finv 
\exercise Inversa da inversa.
%%%{{{ meta 
\label finv_of_finv
%%%}}}

Demonstre que se a função inversa $\finv f$ é definida,
então a sua inversa $\finvp{\finv f}$ também é
e temos $\finvp{\finv f} = f$.

\hint
Quando a função inversa é definida?

\hint
Aplique duas vezes a~\ref[finverse] de função inversa para demonstrar
que as duas funções são iguais.

\solution
Pelo~\ref[finv_is_bij] temos que $\finv f$ é bijetora,
então sua inversa $\finvp{\finv f}$ é definida sim
(e pelo~\ref[finv_is_bij] de novo ela é bijetora também).
As $f$ e $\finvp{\finv f}$ têm domínios e codomínios iguais.
Basta verificar que concordam em todo o seu domínio.
Seja $x \in \dom f$ então.
Calculamos
\compute
\finvp{\finv f}(x)    = f(x)
&\iff {\finv f}(f(x)) = x   \by {def.~$\finvp{\finv f}$} \\
&\iff f(x) = f(x)           \by {def.~$\finv f$} \\
\endcompute
e a última igualdade é trivialmente válida,
e logo $\finvp{\finv f} = f$.

%%}}}

%%{{{ x: finv_laws_pointful 
\exercise Leis da inversa (com pontos).
%%%{{{ meta 
\label finv_laws_pointful
%%%}}}

Seja $f: A \bijto B$.
Para todo $a\in A$ e todo $b\in B$, temos:
\mathxcols 4
\textrm{(L)} && \finv f (f a) &= a & f (\finv f b) &= b. && \textrm{(R)}
\endmathxcols

\solution
Seja $a\in A$ e $b\in B$.
Calculamos:
\compute
\finv f (f(a))
&= \text{aquele $x\in A$ que $f(x) = f(a)$} \\
&= a.          \by {$f$ inj.} \\
\endcompute
Agora tomando $y\in B$ calculamos a outra numa maneira diferente:
\compute
f(\finv f(b)) = y
&\iff \finv f (b) = \finv f (y) \\
&\iff b = y    \by {$\finv f$ inj.~(\reftag[finv_is_bij])} \\
&\iff \idof B (b) = y.
\endcompute

%%}}}

%%{{{ x: finv_of_id 
\exercise Inversa da identidade.
%%%{{{ meta 
%%%}}}

Para todo conjunto $A$, $\finv {\idof A} = \idof A$.

\solution
Temos $\idof A, \finv{\idof A} : A \bijto A$ então basta
verificar que comportam igualmente.
\crproofalt{Jeito 1.}
Seja $a \in A$ então e calculamos:
\compute
\finv{\idof A} a
&= \text{aquele $v\in A$ que $\idof A v = a$}  \by {def.~$\finv{\idof A}$} \\
&= a                                           \by {def.~$\idof A$} \\
&= \idof A a.                                  \by {def.~$\idof A$} \\
\endcompute
\proofalt{Jeito 2.}
Sejam $a,a'\in A$.
Calculamos:
\compute
\finv{\idof A} a = v
&\iff a = \idof A v     \by {def.~$\finv{\idof A}$} \\
&\iff a = v             \by {def.~$\idof A$} \\
&\iff \idof A a = v.    \by {def.~$\idof A$} \\
\endcompute

%%}}}

%%{{{ Q: finv_of_fcompose_question 
\question.
%%%{{{ meta 
\label finv_of_fcompose_question
%%%}}}

Queremos descrever a inversa duma composição de bijecções
em termos das inversas dessas bijecções.
Ou seja, temos a configuração seguinte:
$$
\cd
A \ar[r, tail, two heads, "f"] \ar[rr, tail, two heads, bend left=36, "g\of f"] \| B \ar[r, tail, two heads, "g"] \| C
\endcd
$$
Agora, já que $g\of f$ é bijetora, sabemos que possui inversa.
O desafio é descrevê-la em termos das $\finv f$ e $\finv g$.
Como o farias?

%%}}}

\spoiler

%%{{{ beware: finv_of_fcompose_error 
\beware.
%%%{{{ meta 
\label finv_of_fcompose_error
%%%}}}

Um erro comum é afirmar que $\finvp{g\of f} = \finv g \of \finv f$.
Por que isso não faz sentido?
Pense em funções como ``processos'' e na $g\of f$ como o processo
<<faça $f$ e depois faça $g$>>.
Como exemplo, considere $f$ o <<botar cueca>> e $g$ o
<<botar shorts>>.
Logo $g\of f$ é o processo <<botar a cueca e depois botar os shorts>>.
Assim, qual processo seria o $\finv g \of \finv f$?
<<Tirar a cueca e depois tirar os shorts.>>
O erro é óbvio: esquecemos de invertar a ordem das acções
(Mais um exemplo para enfatizar: tu tá usando teu editor de texto,
tu fez várias alterações, uma depois de outra, e agora quer desfazer
tudo que tu fez.  Começando fazer ``undo'' qual a primeira
alteração que vai ser ``undoada''?
Voltando: se eu quero desfazer o $g\of f$ mesmo, o que preciso fazer?
Praticamente já te dei a resposta para o exercício seguinte
(\reftag[finv_of_fcompose])---sorry.
Ainda bem que tem uma parte mais interessante: demonstrar.

%%}}}

%%{{{ x: finv_of_fcompose 
\exercise Inversa da composição.
%%%{{{ meta 
\label finv_of_fcompose
%%%}}}

Sejam
$
\cd
A \ar[r, tail, two heads, "f"] \| B \ar[r, tail, two heads, "g"] \| C
\endcd
$\!.
Descreva a $\finvp{g\of f}$ em termos das $\finv f$ e $\finv g$
e demonstre tua afirmação.

\hint
$\finvp{g\of f} = \finv f \of \finv g$.

\hint
Para demonstrar a $\finvp{g\of f} = \finv f \of \finv g$,
tome $x\in C$ e $z\in A$ e mostre a equivalência
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$

\hint
Calcule cada lado separadamente:
\compute
\finvp{g\of f}(x) = z
&\iff (g\of f)(z) = x  \by {def.~$\finvp{g\of f}$} \\
&\dotsiff \dots \\
\paren{\finv f \of \finv g}(x) = z
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f \of \finv g$} \\
&\dotsiff \dots
\endcompute

\solution
Vamos demonstrar que
$$
\finvp{g\of f} = \finv f \of \finv g.
$$
Tome $x \in C$ e $z \in A$.  Basta demonstrar que
$$
\finvp{g\of f}(x) = z
\iff
\paren{\finv f \of \finv g}(x) = z.
$$
pois isso quis dizer que as duas funções concordam em todo o seu domínio.
Calculamos:
\compute
\finvp{g\of f}(x) = z
&\iff x = (g\of f)(z)                     \by {def.~$\finvp{g\of f}$} \\
&\iff x = g(f(z))                         \by {def.~$g\of f$} \\
&\iff \finv g (x) = f(z)                  \by {def.~$\finv g$} \\
&\iff \finv f \funparen{\finv g (x)} = z  \by {def.~$\finv f$} \\
&\iff \paren{\finv f \of \finv g}(x) = z. \by {def.~$\finv f \of \finv g$} \\
\endcompute

%%}}}

%%{{{ x: finv_atleastonelaw_if_f_bij 
\exercise Basta uma lei.
%%%{{{ meta 
\label finv_atleastonelaw_if_f_bij
%%%}}}

Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis
do~\ref[finv_laws_pointful], então $f'$ é a própria $\finv f$.

\solution
Sejam $b\in B$, $a\in A$.
Caso que $f'$ satisfaz a (L)
calculamos:
\compute
\finv f b = a
&\iff b = f a               \by {def.~$\finv f$} \\
&\iff f' b = f' (f a)       \by {$f'$ inj.} \\
&\iff f' b = (f' f) \fa a   \by {def.~$(f'f)$} \\
&\iff f' b = a.             \by {(L) da $f'$ (com $w \asseq a$)} \\
\intertext{E caso que $f'$ satisfaz a (R):}
f' b = a
&\iff f (f' b) = f a        \by {$f$ inj.} \\
&\iff (f f') \fa b = f a    \by {def.~$(f f')$} \\
&\iff b = f a               \by {(R) da $f'$ (com $w \asseq b$)} \\
&\iff \finv f b = a.        \by {def.~$\finv f$} \\
\endcompute

%%}}}

%%{{{ Boring, innit? 
\blah É chato, né?.
%%%{{{ meta 
%%%}}}

Mergulhar nos domínios e codomínios das funções, mexendo com os
bichinhos que tem lá, tanto para enunciar teoremas quanto para
demonstrá-los espero que foi uma experiência não exatamente divertida.
Logo vamos ver uma outra maneira para enunciar e demonstrar
essas propriedades, ``de longe'', sem olhar os detalhes internos.

%%}}}

\endsection
%%}}}

%%{{{ Images_preimages 
\section Imagens, preimagens.
%%%{{{ meta 
\label Images_preimages
%%%}}}

%%{{{ Two important subsets 
\note Dois subconjuntos importantes.
%%%{{{ meta 
%%%}}}

Sejam $X,Y$ conjuntos e $f:X \to Y$.
$$
\tikzpicture[scale=0.75,node distance=0mm]
\tikzi imgpreimgbase;
\endtikzpicture
$$
Vamos associar, com qualquer subconjunto $A$ de $X$, um certo subconjunto de $Y$, que vamos chamá-lo a \emph{imagem} de $X$ através da $f$.
Similarmente, com qualquer subconjunto $B$ de $Y$, vamos associar um certo subconjunto de $X$, que vamos chamá-lo a \emph{preimagem} de $B$ através da $f$.
Parece que estamos \dq{elevando} a função $f$ do nível \emph{membros} para para o nível \emph{subconjuntos}.
Vamos ver como.

%%}}}

%%{{{ eg: sketches of image and preimage 
\example.
%%%{{{ meta 
%%%}}}

Nas figuras seguintes mostramos com azul o subconjunto com que começamos,
e com vermelho o subconjunto que associamos com ele.
Considere o $A\subset X$ como aparece no desenho abaixo,
e veja qual é o subconjunto $\img f A$ de $Y$ que vamos associar com o $A$:
$$
\mathed {
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5) ellipse (0.9cm and 1.6cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-A) at (-0.7,-2.1) {$A$};
\endtikzpicture
}
\quad\leadsto\quad
\mathed {
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (0,-.5)     ellipse (0.9cm and 1.6cm);
\draw [fill=red!25]  (4.9,-0.45) ellipse (0.7cm and 2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-A)  at (-0.7,-2.1) {$A$};
\node [color=red]  (subset-fA) at (5.9,-2.05) {$\img f A$};
\endtikzpicture
}
$$
Na direção oposta, comece por exemplo com esse $B\subset Y$
e observe qual é o subconjunto $\pre f B$ de $X$ que queremos associar com o $B$:
$$
\mathed {
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-B) at (5.95,0.4) {$B$};
\endtikzpicture
}
\quad\leadsto\quad
\mathed {
\tikzpicture[scale=0.75,node distance=0mm]
\draw [fill=blue!25] (4.9,1.45) ellipse (1.1cm and 1.2cm);
\draw [fill=red!25]  (0,1.0)    ellipse (0.8cm and 2.0cm);
\tikzi imgpreimgbase;
\node [color=blue] (subset-B)     at (5.95,0.4)  {$B$};
\node [color=red]  (subset-fpreB) at (-0.9,-1.1) {$\pre f B$};
\endtikzpicture
}
$$

%%}}}

%%{{{ remark: just a function from A to B is enough 
\remark.
%%%{{{ meta 
%%%}}}

Observe que na discussão acima não supusemos \emph{nada mais} além da
existência de uma função $f$ dum conjunto $X$ para um conjunto $Y$.

%%}}}

%%{{{ Q 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir formalmente os conjuntos indicados nos desenhos acima?

%%}}}

\spoiler

%%{{{ df: img_and_pre 
\definition.
%%%{{{ meta 
\label img_and_pre
\defines
    * \img {~f} {~X}  -- a imagem de $X$ através da $f$
    * \pre {~f} {~Y}  -- a preimagem de $Y$ através da $f$
    * função!imagem
    * função!preimagem
    ;;
%%%}}}

Seja $f : X \to Y$, e sejam subconjuntos $A \subset X$ e $B \subset Y$.
Definimos:
\mathcol
\img f A &\defeq \setst {f(a)} {a \in A} \\
\pre f B &\defeq \setst {x \in X} {f(x) \in B}.
\endmathcol
Lembrando a notação set builder~(\ref[set_builder]), temos as definições:
\mathcol
y \in \img f A &\defiff \lexists{a \in A} {f(a) = y} \\
x \in \pre f B &\defiff f(x) \in B.
\endmathcol
Chamamos o conjunto $\img f A$ \dterm{imagem} do $A$ através da $f$ ou,
mais curtamente, a $f$-\dterm{imagem} do $A$.  O conjunto $\pre f B$
é a \dterm{preimagem} do $B$ através da $f$; ou a $f$-\dterm{preimagem}
do $B$.
\mistake

%%}}}

%%{{{ warning: notations 
\warning.
%%%{{{ meta 
%%%}}}

Todas as notações seguintes são freqüentemente usadas para a denotar $f$-imagem de $A$:
$$
\funimg    f A, \quad
\astimg    f A, \quad
\pimg      f A, \quad
\pimgsub   f A, \quad
\rwimg     f A, \quad
\existsfun f A;
$$
e todas essas para a $f$-preimagem de $B$:
$$
\funpre  f B, \quad
\astpre  f B, \quad
\ppre    f B, \quad
\ppresub f B.
$$

%%}}}

%%{{{ x: type_of_img_f_hole_and_pre_f_hole  
\exercise.
%%%{{{ meta 
\label type_of_img_f_hole_and_pre_f_hole
%%%}}}

Quais os tipos das $\img f {\dhole}$ e $\pre f {\dhole}$?

\solution
\mathcol
\img f {\dhole} &\eqtype \pset A \to \pset B \\
\pre f {\dhole} &\eqtype \pset B \to \pset A.
\endmathcol

%%}}}

%%{{{ x: img_and_pre_of_emptyset 
\exercise.
%%%{{{ meta 
\label img_and_pre_of_emptyset
%%%}}}

Seja $f : X \to Y$.
Verifique:
$$
\img f \emptyset = \emptyset  \qqqtext{e}
\pre f \emptyset = \emptyset.
$$

\solution
As duas afirmações seguem diretamente pelas definições:
\mathcol
\img f \emptyset &= \setst {f(a)}   {a    \in \emptyset} = \emptyset \\
\pre f \emptyset &= \setst {x\in X} {f(x) \in \emptyset} = \emptyset.
\endmathcol

%%}}}

%%{{{ remark: range and surjection with f[-] notation 
\remark.
%%%{{{ meta 
%%%}}}

Se $f : X \to Y$ então, temos que:
\elist i: \spaciouslist
\li: $\range f = \img f X$;
\li: $\img f X = Y \iff \text{$f$ é sobrejetora}$.
\endelist
As duas afirmações são conseqüências imediatas das definições envolvidas.

%%}}}

%%{{{ x: our_img_notation_is_better 
\exercise Nossa notação é melhor.
%%%{{{ meta 
\label our_img_notation_is_better
%%%}}}

Em matemática, às vezes aparece a notação $f(X)$ para denotar a imagem do
$X\subset \dom f$ através da função $f$.
Aqui usamos a notação $\img f X$.
\emph{Sem usar o conjunto vazio em lugar nenhum na tua resposta},
dê um exemplo (completo) que mostra que a notação $f(X)$ pode ser problemática
(e logo nossa notação $\img f X$ é melhor).
Explique curtamente.

\hint
Pode acontecer que $X \in A$ e também $X \subset A$?

\hint
Vamos adoptar temporariamente a notação $f(X)$.
Daí, te pergunto: se $f : \nats\to\nats$ é o sucessor,
tem como calcular os seguinte?:
$$
f(5);\qquad
f(8);\qquad
f(\set{1,7});\qquad
f(2\nats);
$$
onde $2\nats \subset \nats$ é o conjunto dos pares naturais.
``Fácil'' tu pensou (certo?), e explicou:
$$
\align
f(5) &\ \text{\dots é o valor da $f$ no $5$, definido pois $5\in\dom f$} \\
\intertext{e similarmente sobre o $f(8)$, mas}
f(\set{1,7}) &\ \text{\dots não pode ser o valor da $f$ no $\set{1,7}$, pois $\set{1,7}\nin\dom f$.}
\endalign
$$
Então $f(\set{1,7})$ só pode ser a $f$-imagem do $\set{1,7}$ que realmente é um subconjunto do $\dom f$;
e similarmente sobre o $f(2\nats)$.
E assim tu calculou as respostas:
$$
\xalignat4
f(5) &= 6; & f(8) &= 9; & f(\set{1,7}) &= \set{2,8}; & f(2\nats) &= \set{1,3,5,\dots}.
\endxalignat
$$
Beleza, mas acontece que o $\nats$ é um conjunto homogêneo
(\reftag[homogeneous_and_heterogeneous_sets]).
Imagine que o domínio da $f$ tem todos os objetos seguintes como membros:
$$
1,\quad
7,\quad
\set{1,7}.
$$
Agora, se eu perguntar qual é o $f(\set{1,7})$ tu tens um dilemma:
$$
f(\set{1,7}) \askeq
\pathed{
\text{a $f$-imagem do $\set{1,7}$}   & (que realmente é um subconjunto do seu domínio) \cr
\pathween {\dots\orword\dots}
\text{o valor da $f$ no $\set{1,7}$} & (que realmente é um membro do seu domínio)?
}
$$

\solution
Sejam $A = \set{ 1, 7, \set{1,7} }$, e $X = \set{1,7}$.
Observe que $X\in A$ e $X \subset A$.
Seja $f : A \to \set{3}$ a função constante definida pela $f(x) = 3$.
Assim a notação $f(X)$ fica ambígua: a $f$-imagem de $X\subset A$ é o $\set 3$,
mas o valor da $f$ no $X$ é o $3$.
E $3 \neq \set{3}$!

%%}}}

%%{{{ remark: our_img_notation_is_better_not 
\note Só que não.
%%%{{{ meta 
\label our_img_notation_is_better_not
%%%}}}

Então no \ref[our_img_notation_is_better] descobrimos que \dq{nossa} notação é melhor.
Né?  Para o mundo não cuidosamente tipado, sim, ela é melhor.
Mas num mundo onde tipamos com carinho nossos objetos, tendo assim tipos distintos
$$
\Set(\Int), \qquad \Set(\Set(\Int)), \qquad \Set(\Set(\Set(\Int))), \qquad\dots
$$
será que podemos realmente nos livrar da complicação de ter notações distintas para
essa infinidade de ``elevações'' de $f$?
Considere:
\mathcol
5                             &\is \Int \\
\set{3,8,12}                  &\is \Set(\Int) \\
\set{\set{1,4},\set{3},\ints} &\is \Set(\Set(\Int)) \\
\endmathcol
Vamos usar a $f = \lam x {x+2} \is \Int \to \Int$.
Se eu escrever \symq{$f \app 5$}
só pode ser a $f$ \dq{original}, pois $5 \is \Int$.
E se eu escrever \symq{$f \app \set{3,8,12}$}
só pode ser a $\pimg f$ sendo aplicada mesmo, e escrevendo
\symq{$f \set{\set{1,4},\set{3},\ints}$}
só pode ser a $\pimg\pimg f$.
Calculamos:
\mathcol
f \app 5
&= 7 \\
f \app \set{3,8,12}
&= \set{f \app 3, f \app 8, f \app 12} \\
&= \set{5,10,14} \\
f \set{\set{1,4},\set{3},\ints}
&= \set{f \app \set{1,4}, f \app \set{3}, f \app \ints} \\
&= \set{\set{f \app 1, f \app 4},\set{f \app 3}, \setst {x + 2} {x \in \ints}} \\
&= \set{\set{3,6},\set{5},\ints}. \\
\endmathcol

%%}}}

%%{{{ remark: img_paren_notation_safe_even_when_homogenous_mistake 
\remark.
%%%{{{ meta 
\label img_paren_notation_safe_even_when_homogenous_mistake
%%%}}}

O perigo descrito no~\ref[our_img_notation_is_better] não existe quando
trabalhamos com conjuntos \emph{homogêneos} (\reftag[homogeneous_and_heterogeneous_sets]).
Em tal mundo podemos usar a notação $f(X)$ para o $\img f X$ sem problema:
um conjunto como o $\set{1, 7, \set{1,7}}$ seria considerado:
inconstrutível, mal-tipado, não definido, sem significado, blasfêmico, etc.
\mistake

%%}}}

%%{{{ x: erroneous_definition_of_pre 
\exercise.
%%%{{{ meta 
\label erroneous_definition_of_pre
%%%}}}

Podemos definir a $f$-preimagem de $Y$ assim?:
$$
\pre f Y \defeq \setst {\finv f (y)} {y \in Y}
$$

\solution
Não!
O símbolo $\finv f (y)$ nem é definido no caso geral:
o definimos \emph{apenas para funções bijetoras}.

%%}}}

%%{{{ x: when_erroneous_definition_of_pre_is_valid 
\exercise.
%%%{{{ meta 
\label when_erroneous_definition_of_pre_is_valid
%%%}}}

Sejam $f: A \bijto B$, e $Y \subset B$.
Mostre que
$$
\pre f Y = \setst {\finv f (y)} {y \in Y}.
$$

\hint
É um igualdade de conjuntos, então mostre cada uma das~{\lrdirset}
e~{\rldirset} separadamente.

\solution
Caso $\pre f Y = \emptyset$, necessariamente $Y=\emptyset$ também
(pois $f$ é sobrejetora) e logo
$$
\setst {\finv f (y)} {y \in Y}=\emptyset
$$
também.
Caso contrário, mostramos as duas direções separadamente:
\crtabproofpart {\lrdirset:}
Seja $x\in \pre f Y$ e logo
seja $y_x\in Y$ tal que $f(x) = y_x$ (pela def.~$\pre f Y$).
Logo $x = \finv f (y_x)$ pela definição da função inversa (\reftag[finverse]),
ou seja $x \in \setst {\finv f (y)} {y \in Y}$.
\crtabproofpart {\rldirset:}
É só seguir os passos da {\lrdirset} em reverso.

%%}}}

%%{{{ x: pre_notation_problem 
\exercise.
%%%{{{ meta 
\label pre_notation_problem
%%%}}}

Qual o problema com a~\ref[img_and_pre]?

\hint
Quando $f$ \emph{não} é bijetora, nenhum.

\hint
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes.
Quais?  E isso é um problema mesmo por quê?

\solution
Se $f$ é bijetora, o símbolo $\pre f Y$ pode ter duas interpretações diferentes:
$$
\pre f Y \askeq
\pathed{
\pre {\alert{(f)}} {\aB Y}
& a preimagem de $\aB Y$ através da função $\alert f$ \cr
\pathween {\dots\orword\dots}
\img {\alert{(\finv f)}} {\aB Y}
& a imagem de $\aB Y$ através da função $\alert{\finv f}$
}
$$
onde usamos cores e parenteses para enfatizar o ``parsing'' diferente
de cada interpretação.
Observe que a segunda alternativa não é possível quando $f$ não é bijetora,
pois a função $\finv f$ nem é definida nesse caso!

%%}}}

%%{{{ x: correctness_of_pre_notation 
\exercise.
%%%{{{ meta 
\label correctness_of_pre_notation
%%%}}}

Depois de resolver o~\ref[pre_notation_problem], justifique a corretude
da~\ref[img_and_pre]:
explique o que precisas demonstrar, e demonstre!

\hint
Precisamos demonstrar que no caso que $f:A\bijto B$ as duas
interpretações do símbolo $\pre f Y$ \emph{denotam o mesmo objeto}.

\hint
Temporariamente mude tua notação para ajudar teus olhos distinguir
entre as duas interpretações melhor.
Use, por exemplo, $f_{-1}\bracket{\dhole}$ para denotar
a preimagem através da $f$.
Assim teu alvo fica enxergável:
$$
\lforall {Y \subset B} {\img {\finv f} Y = f_{-1}\bracket Y}.
$$

\solution
Seja $f : A \bijto B$.
Introduzimos temporariamente a notação
$$
f_{-1}\bracket Y \defeq \text{a $f$-preimagem de $Y$}.
$$
Com essa notação precisamos demonstrar que
$$
\text{para todo $Y\subset B$,}\quad
\img {\finv f} Y = f_{-1}\bracket Y
$$
Seja $Y \subset B$.
\crtabproofpart {\lrdirset}.
Seja $x \in \img {\finv f} Y$\fact1.
Para mostrar que $x \in f_{-1}\bracket Y$ basta verificar que $f(x) \in Y$\fact1.
Seja $y_x \in Y$ tal que $\finv f y_x = x$ (pela~\byfact1).
Logo $y_x = f(x)$ pela definição de $\finv f$ e logo pertence ao $Y$
pela~\byfact2.
\crtabproofpart {\rldirset}.
Seja $x \in f_{-1}\bracket Y$\fact1.
Como $f x \in Y$ (pelo~\byfact1) e $f x \mapstoby {\finv f} x$
(pela definição da $\finv f$), logo $x \in \img {\finv f} Y$.

%%}}}

%%{{{ x: img_f_singleton_x_eq_singleton_f_x 
\exercise.
%%%{{{ meta 
\label img_f_singleton_x_eq_singleton_f_x
%%%}}}

Verdadeiro ou falso?:
para toda função $f$ e todo $x$ no seu domínio temos
$$
\img f {\set{x}} = \set{f(x)}.
$$

\solution
Verdade:
$$
\img f {\set{x}}
= \setst {f(z)} {z \in \set{x}}
= \set{f(x)}.
$$

%%}}}

%%{{{ x: is any of img f, pre f, guaranteed to be inj or surj? 
\exercise.
%%%{{{ meta 
%%%}}}

É alguma das $\img f {\dhole}$, $\pre f {\dhole}$ garantidamente
injetora ou sobrejetora?

%%}}}

%%{{{ x: bij_iff_all_pre_are_singletons 
\exercise.
%%%{{{ meta 
\label bij_iff_all_pre_are_singletons
%%%}}}

Seja $f : A \to B$.
Demonstre que
$$
\text{$f$ bijetora} \iff \text{para todo $b \in B$, $\pre f {\set b}$ é um conjunto unitário}.
$$

\hint
Pense\dots
Como podes matar um alvo que um conjunto $S$ é unitário?
Como podes usar um fato que um conjunto $S$ é unitário?

\hint
Como matar o alvo que um conjunto $S$ é unitário?
Basta mostrar duas coisas:
(1) $S$ tem pelo menos um membro (ou seja: $S\neq\emptyset$);
(2) $S$ tem no máximo um membro (ou seja: para todo $s,s' \in S$,
temos $s=s'$).
E como usar o fato que um conjunto $S$ é unitário?
Para todos os $s, s' \in S$, ganhamos que $s=s'$.

\solution
\proofpart {\lrdir}:
Suponha que $f$ bijetora, e seja $b\in B$.
Vou demonstrar que $\pre f {\set b}$ é unitário.
Vamos chamá-lo de $A_b$.
Como $f$ é sobrejetora, logo seja $a_b \in A$ tal que $f(a_b) = b$.
Logo $a_b \in A_b$ pela definição da preimagem,
e logo $A_b \neq\emptyset$ (pois tem pelo menos um membro).
Basta mostrar que tem no máximo um membro.
Sejam $a, a' \in A_b$ então e vamos mostrar que $a=a'$.
Pela escolha dos $a,a'$, temos $f(a) = f(a') = b$;
e agora pela injectividade da $f$ temos o desejado $a=a'$.
\crtabproofpart {\rldir}.
Suponha que para todo $b \in B$, o $\pre f {\set b}$ é unitário.
Preciso mostrar que $f$ é injetora e sobrejetora.
\crproofpart {$f$ injetora:}
Suponha que temos $x,y\in A$ tais que $f(x) = f(y)$
e chame esse valor comum de $b$.
Basta demonstrar que $x=y$.
Pela hipótese, o $\pre f {\set b}$ é unitário,
e pela escolha dos $x,y$ sabemos que $x,y$ pertencem a ele.
Logo $x=y$.
\crproofpart {$f$ sobrejetora:}
Seja $b\in B$.
Procuramos $a\in A$ tal que $f(a) = b$.
Pela hipótese, o conjunto $\pre f {\set b}$ é unitário (e logo não vazio).
Tome $a$ o (único) membro desse conjunto e observe que pela definição
de preimagem temos que $f(a) = b$.

%%}}}

%%{{{ x: composition_with_inverse_subsets 
\exercise.
%%%{{{ meta 
\label composition_with_inverse_subsets
%%%}}}

Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Demonstre as afirmações:
$$
\align
A &\subset \pre f {\img f A}\\
B &\supset \img f {\pre f B}.
\endalign
$$

\solution
Vamos demonstrar as duas afirmações.
\eop\indent
\proofpart {{\proofname} de $A \subset \pre f {\img f A}$.}
Suponha $a\in A$.
Logo $f(a) \in \img f A$ pela definição da função-imagem,
e logo $a \in \pre f {\img f A}$ pela definição da função-preimagem.
\eop\indent
\proofpart {{\proofname} de $B \supset \img f {\pre f B}$.}
Suponha $y_0 \in \img f {\pre f B}$.
Logo tome $x_0 \in \pre f B$ tal que $y_0 = f(x_0)$\fact1.
Pela definição da função-preimagem $f(x_0) \in B$,
e agora pela~\byfact1~temos $y_0 \in B$.

%%}}}

%%{{{ x: composition_with_inverse 
\exercise.
%%%{{{ meta 
\label composition_with_inverse
%%%}}}

Sejam conjuntos $X$ e $Y$, $f : X\to Y$, e $A\subset X$ e $B\subset Y$.
Considere as afirmações:
$$
\align
A &\askeq \pre f {\img f A}\\
B &\askeq \img f {\pre f B}.
\endalign
$$
Para cada uma delas: se podemos concluí-la, demonstre;
e caso contrário, mostre um contraexemplo.

\hint
Nenhuma é válida em geral.
Procure contraexemplos.

\hint
O enunciado do~\ref[jection_iff_composition_with_inverse]
pode te ajudar pensar em contraexemplos.

\solution
Mostramos dois contraexemplos, um para cada afirmação.
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,0.666) ellipse (5mm and 5mm);
\draw (-0.6,0.1) node {$A$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
\qqqquad
\tikzpicture
\draw (0,0) ellipse (1cm and 12mm);
\draw (3,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (8mm and 10mm);
\draw (2.4,0.1) node {$B$};
\draw (3,0.666)  node {$\bullet\,2$};
\draw (3,-0.666) node {$\bullet\,3$};
\draw (0,0)  node {$1\,\bullet$};
\draw[|->] (0.35,0.05) -- (2.7,0.6);
\draw (0,2.0) node {$X$};
\draw (3,2.0) node {$Y$};
\draw (1.5,1.70) node {$f$};
\draw[->]  (0.5,2.0) -- (2.5,2.0);
\endtikzpicture
$$
No primeiro contraexemplo temos:
$A = \set{1}$;
$\img f A = \set {3}$; e
$\pre f {\set 3} = \set {1,2}$.
Logo
$$
A = \set{ 1 } \neq \set {1, 2} = \pre f {\img f A}.
$$
No segundo contraexemplo temos:
$B = \set{2,3}$;
$\pre f B = \set {1}$; e
$\img f {\set 1} = \set {2}$.
Logo
$$
B = \set{ 2,3 } \neq \set {2} = \img f {\pre f B}.
$$

%%}}}

%%{{{ Q: what changes if f is inj or surj? 
\question.
%%%{{{ meta 
%%%}}}

O que muda no~\ref[composition_with_inverse] se $f$ é injetora?  Se é sobrejetora?

%%}}}

\spoiler

%%{{{ jection_iff_composition_with_inverse 
\theorem.
%%%{{{ meta 
\label jection_iff_composition_with_inverse
%%%}}}

Seja $f : X \to Y$.
Temos:
$$
\align
\text{$f$ injetora}    &\iff \text{para todo $A \subset X$, $A = \pre f {\img f A}$}  \tag{1}\\
\text{$f$ sobrejetora} &\iff \text{para todo $B \subset Y$, $B = \img f {\pre f B}$}. \tag{2}
\endalign
$$

\proof.
As duas idas tu demonstrarás
(agora!)~no~\reftag[jection_implies_composition_with_inverse];
as voltas no~\ref[jection_iff_composition_with_inverse_proof] (pode ser depois).

%%}}}

%%{{{ x: jection_implies_composition_with_inverse 
\exercise.
%%%{{{ meta 
\label jection_implies_composition_with_inverse
%%%}}}

Demonstre as idas do~\ref[jection_iff_composition_with_inverse].

\solution
Temos duas implicações para demonstrar.
\crtabproofpart {Ida da (i).}
Suponha que $f$ é injetora, e seja $A\subset X$.
Já temos a
$$
A \subset \pre f {\img f A}
$$
pelo~\ref[composition_with_inverse_subsets], então basta mostrar
$$
\pre f {\img f A} \subset A.
$$
Tome então $x_0 \in \pre f {\img f A}$.
Logo $f(x_0) \in \img f A$.
Logo $f(a) = f(x_0)$ para algum $a \in A$ (pela definição da função-imagem).
Mas $f$ é injetora, então $a = x_0$ e logo $x_0\in A$.
\crtabproofpart {Ida da (ii).}
Suponha que $f$ é sobrejetora, e seja $Y\subset B$.
Já temos a
$$
\img f {\pre f B} \subset B
$$
pelo~\ref[composition_with_inverse_subsets], então basta mostrar
$$
B \subset \img f {\pre f B}
$$
Tome então $b \in B$.
Agora seja $x_b \in X$ tal que $f(x_b) = b$ (pois $f$ é sobrejetora).
Então $x_b \in \pre f B$.
Logo $f(x_b) \in \img f {\pre f B}$.
Logo $b \in \img f {\pre f B}$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver agora como essas operações comportam
em combinação com as operações de conjuntos.

%%}}}

%%{{{ x: operations_respected_by_img 
\exercise.
%%%{{{ meta 
\label operations_respected_by_img
%%%}}}

Sejam $f : X \to Y$, $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\union  B} &=       \img f A \union  \img f B\\
\img f {A\inter  B} &\askeq  \img f A \inter  \img f B\\
\img f {A\sminus B} &\askeq  \img f A \sminus \img f B
\endalign
$$
onde nas $\askeq$ demonstre que a igualdade em geral não é válida,
mas uma das~\lrdirset~e~\rldirset, é.

\hint
Ataque cada direção ({\lrdirset} e {\rldirset}) da primeira separadamente.
Das duas $\askeq$, são válidas as inclusões:
$$
\align
\img f {A\inter  B} &\subset \img f A \inter  \img f B\\
\img f {A\sminus B} &\supset \img f A \sminus \img f B
\endalign
$$
Demonstre; e mostre contraexemplos que demonstram que as reversas
inclusões não são válidas em geral.

\solution
Vamos primeiramente demonstrar a
$\img f {A\union B} = \img f A \union \img f B$.
\proofpart {\lrdirset}:
Tome $y \in \img f {A\union B}$.
Logo seja $x \in A\union B$ tal que $f(x) = y$.
\proofcase {Caso $x \in A$,} temos $f(x)\in \img f A$
e logo $f(x)$ pertence na união $\img f A \union \img f B$.
\proofcase {Caso $x \in B$,} concluímos similarmente
que $f(x) \in \img f B \subset \img f A \union \img f B$.
\eop
\proofpart {\rldirset}:
Tome $y \in \img f A \union \img f B$.
\proofcase {Caso $y \in \img f A$,} seja $a\in A$ tal que $f(a)=y$.
Mas $a \in A\union B$, logo $y\in \img f {A\union B}$.
\proofcase {O caso $y \in \img f B$} é similar.
\eop
Vamos demonstrar a
$\img f {A\inter B} \subset \img f A \inter \img f B$ agora.
Tome $y \in \img f {A\inter B}$ e
seja $d \in A\inter B$ tal que $f(d) = y$.
Mas $d \in A$ e $d \in B$, ou seja $y \in \img f A$ e $y \in \img f B$,
e logo $y \in \img f A \inter \img f B$.
\eop
Vamos demonstrar a
$\img f {A\sminus B} \supset \img f A \sminus \img f B$ agora.
Tome $y \in \img f A \sminus \img f B$ então, ou seja
$y \in \img f A$ e $y \nin \img f B$.
Traduzindo:
$$
\lexists {a\in A} {f(a) = y}
\qquad\mland\qquad
\lforall {b\in B} {f(b) \neq y}.
$$
Usando a primeira afirmação abaixo tome $a\in A$ tal que $f(a) = y$,
e observe que graças à segunda, $a \nin B$.
Logo $a \in A\sminus B$, e chegamos no desejado
$y \in \img f {A\sminus B}$.
\eop
Finalmente, usamos apenas um contraexemplo para refutar simultaneamente
as duas inclusões que são inválidas no caso geral:
$$
\tikzpicture
\draw (0,0) ellipse (1cm and 15mm);
\draw (3,0) ellipse (1cm and 12mm);
\draw (0,.666) ellipse (5mm and 5mm);
\draw (0,-.666) ellipse (5mm and 5mm);
\draw (-0.6,0.25)  node {$A$};
\draw (-0.6,-0.25) node {$B$};
\draw (0,0.666)  node {$1\,\bullet$};
\draw (0,-0.666) node {$2\,\bullet$};
\draw (3,0)  node {$\bullet\,3$};
\draw[|->] (0.3,0.6) -- (2.7,0.1);
\draw[|->] (0.3,-0.6) -- (2.7,-0.1);
\node (X) at (0,2.0) {$X$};
\node (Y) at (3,2.0) {$Y$};
\draw[->]  (0.5,2.0) -- (2.5,2.0) node[midway, below] {$f$};
\endtikzpicture
$$
Calculamos para verificar:
$$
\aligned
\img f {A \inter B}
&= \img f \emptyset
= \emptyset \\
\img f A \inter \img f B
&= \set{3} \inter \set{3}
= \set{3}
\endaligned
\qquad
\aligned
\img f {A \sminus B}
&= \img f A
= \set {3}\\
\img f A \sminus \img f B
&= \set {3} \sminus \set {3}
= \emptyset.
\endaligned
$$
Um contraexemplo mais pictorial seria considerar uma função $f$
que mapeia pontos do plano $\reals^2$
para pontos da reta $\reals$, mandando cada
entrada $\tup{x,y}$ para sua ``sombra'' $x$.
Já conhecemos essa função: é a primeira projecção: $f = \pi_0$.
Observe que a $\img {\pi_0} {\dhole}$ manda cada subconjunto de $\reals^2$
para sua ``sombra'':
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A$};
\draw[-]  (-1,0) -- (6,0);
\draw[|->] (2,2.6) -- (2,0.5);
\endtikzpicture
$$
Para achar o contraexemplo agora, basta só escolher dois subconjuntos de
$\reals^2$ como esses:
$$
\tikzpicture
\draw [rounded corners=8mm, fill=gray!10] (1,3)--(1,5)--(4,5)--(4,3)--cycle;
\node at (2.5,4) {$A$};
\draw [rounded corners=3mm, fill=gray!10] (1,1)--(1,2)--(4,2)--(4,1)--cycle;
\node at (2.5,1.5) {$B$};
\draw [rounded corners=0mm, fill=black]   (1,-0.1)--(1,0.1)--(4,0.1)--(4,-0.1)--cycle;
\node at (2.5,-0.4) {$\img {\pi_0} A = \img {\pi_0} B$};
\draw[-]  (-1,0) -- (6,0);
\endtikzpicture
$$
Verifique que isso é um contraexemplo que refuta as duas igualdades
que queremos refutar.

%%}}}

%%{{{ x: operations_respected_by_img_of_inj 
\exercise.
%%%{{{ meta 
\label operations_respected_by_img_of_inj
%%%}}}

Sejam $f : X \injto Y$ injetora, e $A,B\subset X$.
Mostre que:
$$
\align
\img f {A\inter  B} &= \img f A \inter  \img f B\\
\img f {A\sminus B} &= \img f A \sminus \img f B.
\endalign
$$

\hint
Já demonstrou metade de cada igualdade no~\ref[operations_respected_by_img]
até sem a hipótese que $f$ é injetora.
Basta então demonstrar as duas inclusões:
$$
\align
\img f {A\inter  B} &\supset \img f A \inter  \img f B\\
\img f {A\sminus B} &\subset \img f A \sminus \img f B.
\endalign
$$

\solution
Já demonstramos metade de cada igualdade no~\ref[operations_respected_by_img]
para qualquer função, então para nossa injetora $f$ também.
Basta então demonstrar as duas inclusões:
$$
\align
\img f {A\inter  B} &\supset \img f A \inter  \img f B\\
\img f {A\sminus B} &\subset \img f A \sminus \img f B.
\endalign
$$
\proofpart {{\proofname} de $\img f {A\inter B} \supset \img f A \inter \img f B$}:
Suponha $y \in \img f A \inter \img f B$.
Logo $y \in \img f A$ e $y \in \img f B$.
Tome então $a\in A$ tal que $f(a) = y$ e $b \in B$ tal que $f(b) = y$.
Juntando as duas igualdades temos $f(a) = f(b)$.
Mas $f$ é injetora, e logo $a = b$.
Ou seja, $a \in A\inter B$, e chegamos no desejado
$y \in \img f {A \inter B}$.
\eop\noi
\proofpart {{\proofname} de $\img f {A\sminus B} \subset \img f A \sminus \img f B$}:
Suponha $y \in \img f {A\sminus B}$.
Tome então $a_0 \in A\sminus B$ tal que $f(a_0) = y$.
Logo $a_0 \in A$ e $a_0 \nin B$.
Já sabemos então que $y \in \img f A$.
Agora usamos a injectividade da $f$ para demonstrar que $y \nin \img f B$.
Se $y$ fosse um membro de $\img f B$, existiria $b\in B$ com $f(b) = y$.
Mas já temos o único ($f$ injetora) membro do domínio $X$ que $f$ mapeia no $y$,
o $a_0$, e sabemos que $a_0 \nin B$!
Logo $y \nin \img f B$ e chegamos no $y\in \img f A \sminus \img f B$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A preimagem comporta bem melhor que a imagem: ela respeita
todas essas operações mesmo quando $f$ não é injetora,
algo que tu demonstrarás agora.

%%}}}

%%{{{ x: operations_respected_by_pre 
\exercise.
%%%{{{ meta 
\label operations_respected_by_pre
%%%}}}

Sejam $f : X \to Y$, $A,B\subset Y$.
Mostre que:
$$
\align
\pre f {A\union  B} &= \pre f A \union  \pre f B\\
\pre f {A\inter  B} &= \pre f A \inter  \pre f B\\
\pre f {A\sminus B} &= \pre f A \sminus \pre f B
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas propriedades generalizam naturalmente para uniões e intersecções
de seqüências e famílias de conjuntos;
veja por exemplo o~\ref[big_operations_respected_by_img_and_pre].

%%}}}

\endsection
%%}}}

%%{{{ Pointfree_style 
\section Definições estilo point-free (tácito).
%%%{{{ meta 
\label Pointfree_style
%%%}}}

%%{{{ Pointful_vs_pointfree 
\note Pointful \vs pointfree.
%%%{{{ meta 
\label Pointful_vs_pointfree
%%%}}}

Olhe para a definicão seguinte duma função $f : \nats \to \nats$:
$$
f \fa n = 2 \ntimes (n^2 + 1).
$$
Literalmente estamos definindo o que significa $f \fa n$, e não o que significa $f$.
Mas, já que temos igualdade extensional entre funções, e já que $n$ é um natural
arbitrário natural aqui, definindo $f \fa n$ é suficiente para determinar a $f$.
A situação deve te lembrar algo (\ref[defining_sets]) por justa causa.
\eop
Agora olhe novamente na definição acima.
Para entender \emph{quem é $f$} precisamos \emph{entrar na floresta do seu domínio},
pegar uma árvore $n$, \emph{entrar na floresta do seu codomínio} e procurar passo
por passo o que aconteceu com ela.
Lendo o início da definição, <<$2 \ntimes {\ldots}$>> sabemos que alguém foi multiplicado
por $2$, talvez não tem algo a ver como nossa árvore, precisamos andar ainda mais,
e depois de muitas trilhas descubrir o que aconteceu.
\eop
Compare com a definição seguinte que define a mesma função $f$ sem sequer mencionar
\dq{árvores}:
$$
f = \double \of \succ \of \square
\qqqtext{ou}
f = \square \dcom \succ \dcom \double.
$$
Ela é claríssima e sucinta, define \emph{diretamente} a própria $f$
(sem enrolar fazendo trilhas nas florestas), e dá pra ler e entender
tanto da esquerda para a direita, quanto da direita para a esquerda.

%%}}}

%%{{{ factorize_a_function_example 
\example.
%%%{{{ meta 
\label factorize_a_function_example
%%%}}}

Seja $f : \ints\to\ints$ a função definida pela
$$
f(x) = -(x^2 + 3).
$$
Mostre como definir a $f$ como composição
de três funções $g,h,k : \ints\to\ints$
sem nenhuma das $g,h,k$ ser a $\lam x x$.
Sim, use lambdas (só pra praticá-los mais).

\solution.
Idéia: vamos tentar descrever o processo do que
acontece na entrada $x$ passo por passo até
chegar na saida $-(x^2 + 3)$.
Primeiramente acontece um quadramento,
depois um incremento por $3$,
e depois uma negação.
Vamo lá então:
sejam as $g,h,k : \ints\to\ints$
definidas pelas
$$
\xalignat3
g &= \lam x {x^2} &
h &= \lam x {x + 3} &
k &= \lam x {{-x}}.
\endxalignat
$$
Assim definimos a $f$ como
$$
f = k \of h \of g.
$$
Sem ambigüidade podemos omitir os \sq{$\of$}
pois já estamos em modo ``de longe'' (sem mexer
com pontinhos):
$$
f = khg.
$$
Simplíssimo!

%%}}}

%%{{{ advice: to_name_or_not_to_name 
\advice to name or not to name.
%%%{{{ meta 
\label to_name_or_not_to_name
%%%}}}

Observe que nem precisamos nomes para as funções
``intermediárias'' do~\ref[factorize_a_function_example].
Poderiamos simplesmente definir a função
$f : \ints\to\ints$ assim:
$$
f =
\plam x {{-x}} \of
\plam x {x + 3} \of
\plam x {x^2}.
$$
(Nesse caso não vamos omitir os \sq{$\of$} pois aparecem os
pontinhos (os \sq{$x$}) e poderia confundir entre composição
e aplicação.)
Então: usamos funções anônimas ou epônimas?
Depende!
E a escolha não é nada de boba.
Pelo contrário, é muito importante elaborar uma intuição
boa sobre:
% TODO: use bullets if not ref'ed
\tlist:
\li (i):  \emph{se} vamos nomear algo (lembra do~\reftag[useless_namings]);
\li (ii): \emph{qual} vai ser o seu nome, caso que decidirmos dar um.
\endtlist
Isso tanto em programação quanto em matemática!
Vamos voltar no nosso \ref[factorize_a_function_example] onde
temos três ``componentes intermediários'' e precisamos
decidir para cada um deles se vamos nomeá-lo e como.
Uns fatores importantes para considerar:
\tlist:
\li: esse componente é algo já bem conhecido?  já possui um nome?
\li: esse componente vai ser reutilizado?
\endtlist
Com essa guia, faria sentido definir a $f$ assim:
$$
f = \negate \of \plam x {x+3} \of \square
$$
onde
\mathcols 2
\negate    &\eqtype \ints\to\ints &
\square    &\eqtype \ints\to\ints \\
\negate(x) &= -x   &
\square(x) &= x^2. \\
\endmathcols
Aqui não me pareceu tão útil ter um nome para a operação
$\lam x {x+3}$ e logo escolhi deixá-la anônima.
Se fosse $\lam x {x+1}$ teria escolhido usar o $\succ$.
Não existe maneira correta ou errada aqui: nomeá-las por $g,h,k$
também não foi bizarro não, nem deixá-las todas anônimas!
Depende da situação, do contexto, da intenção, do uso, das estrelas, etc.

%%}}}

%%{{{ x: factorize_a_function_exercise 
\exercise.
%%%{{{ meta 
\label factorize_a_function_exercise
%%%}}}

Fatore as funções seguintes na maneira mais legal que tu consegues:
\mathcols 2
f      &\eqtype \rats \to \rats &
f(x)   &= \frac 1 {\sqrt{(x+1)^2 + 1}} \\
g      &\eqtype \nats\cross\nats \to \nats &
g(x,y) &= y^2 + 1 \\
h      &\eqtype \nats\cross\nats \to \nats &
h(x,y) &= 2(x+y) + 1 \\
k      &\eqtype \nats\cross\nats \to \nats &
k(x,y) &= 2(x+2y) + 1.
\endmathcols

\hint
Aqui uma maneira de definir a $f$ como composição
de $4$ fatores:
$$
f = \inverse \of \namedfun{squareRoot} \of \succ \of square \of succ.
$$
A definição de cada um deve ser óbvia pelo próprio nome.

\hint
Não se preocupe se não conseguir a $k$ neste momento.
Daqui a pouco (\reftag[Pointfree_style]) vai parecer fácil.

\solution
Temos:
\mathcol
f &= \inverse \of \namedfun{squareRoot} \of \succ \of \square \of succ \\
g &= \succ \of \square \of \outl \\
h &= \succ \of \double \of \plus \\
k &= \succ \of \double \of \plus \of \namedfun{doubleHeight}.
\endmathcol
A definição de cada função-fator que aparece na direita
deve ser óbvia pelo próprio nome, exceto talvez da
$\namedfun{doubleHeight}$.
(Tá vendo como é bom escolher nomes bons?)
Definimos a $\namedfun{doubleHeight} : \nats^2\to\nats$
pela $\namedfun{doubleHeight}(x,y) = \tupp{x,2y}$.
Observe também que a $\succ$ da primeira linha é diferente
da $\succ$ das outras, por causa do seu tipo.
Mesma coisa sobre a $\square$.
Teria sido melhor usar $\succ_\rats$ para diferenciá-la
mas escolhi deixar pra lá essa decoração e todo o resto
da informação de tipos dos componentes intermediários
contando que tu consegues inferir cada domínio e cada
codomínio envolvido.
Espero que tu achou a resolução de $k$ meio ``meh'',
por causa dessa bizarra (muito \emph{ad hoc}) função
$\namedfun{doubleHeight}$ que talvez até ``forcei a
barra'' para nomeá-la.
Se preocupe não: como avisei na dica, daqui a pouco
(\reftag[Pointfree_style]) vamos ver como resolver isso
numa maneira bem legal mesmo.
Por enquanto, podemos melhorar a resolução assim:
\mathcol
k &= h \of \namedfun{doubleHeight}
\intertext{%
que com certeza é mais elegante, já que
}
k &= {\mubrace {(\succ \of \double \of \plus)} h}
     \of {\namedfun{doubleHeight}}.
\endmathcol

%%}}}

%%{{{ eg: two_x_plus_one 
\example.
%%%{{{ meta 
\label two_x_plus_one
%%%}}}

Defina a função $f = \lam x {2x+1} : \nats\to\nats$ diretamente como
composição de funções sem usar λ-notação.
Desenhe o diagrama externo da configuração e confirme tua resolução.

\solution.
Temos as funções
$$
\cdopt{sep=1.666cm}
\nats
\ar[r, "\dsize\diag"]   \| \nats\cross\nats
\ar[r, "\dsize\nplus"]  \| \nats
\ar[r, "\dsize\succ"]   \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{\succ} \of \mathord{\nplus} \of {\diagdom\nats}} : \nats \to \nats
$$
e tomando um $x\in\nats$ calculo:
\compute
f(x)
&= \paren{\succ \of \mathord{\nplus} \of \diag} (x) \by {def.~$f$} \\
&= \succ(\mathord{\nplus}(\diag(x)))                \by {def.~$\of$} \\
&= \succ(\mathord{\nplus}(x,x))                     \by {def.~$\diag$} \\
&= \succ(2x)                                        \\
&= 2x+1                                             \by {def.~$\succ$} \\
\endcompute
confirmando assim que minha definição foi correta.

%%}}}

%%{{{ x: two_x_squared_pointfree 
\exercise.
%%%{{{ meta 
\label two_x_squared_pointfree
%%%}}}

Faça a mesma coisa para a função $f = \lam x {2x^2} : \nats\to\nats$.

\solution
Temos as funções
$$
\cd
\nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "\ntimes"] \| \nats
\ar[r, "\diag"]   \| \nats\cross\nats
\ar[r, "+"]       \| \nats.
\endcd
$$
Assim defino
$$
f = \paren{{+} \of \diagdom\nats \of {\ntimes} \of \diagdom\nats} : \nats \to \nats
$$
e tomando um $x\in\nats$ confirmo:
\compute
f(x)
&= \paren{\mathord{+} \of \diag \of \mathord{\ntimes} \of \diag} (x) \by {def.~$f$} \\
&= \mathord{+}(\diag(\mathord{\ntimes}(\diag(x))))                   \by {def.~$\of$} \\
&= \mathord{+}(\diag(\mathord{\ntimes}(x,x)))                        \by {def.~$\diag$} \\
&= \mathord{+}(\diag(x^2))                                           \\
&= \mathord{+}(x^2,x^2)                                              \by {def.~$\diag$} \\
&= x^2 + x^2                                                         \\
&= 2x^2.
\endcompute

%%}}}

%%{{{ x: finv_laws_pointfree 
\exercise Leis da inversa (sem pontos).
%%%{{{ meta 
\label finv_laws_pointfree
%%%}}}

Como podemos expressar as leis da inversa (F-Inv)
sem pontos?

\solution
A configuração na esquerda implica as equações na direita:
\mathcol
A \bijtoby f B
& \;\;\implies\;\;
\lsystemed {
\finv f \of f &= \idof A \\
f \of \finv f &= \idof B
}
\tag{F-Inv}
\endmathcol

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: succiter_for_dummies 
\problem.
%%%{{{ meta 
\label succiter_for_dummies
%%%}}}

Supondo que teu leitor não sabe o que são as iterações duma função
(\ref[function_iterations]) e que \emph{sequer quer saber},
defina a função $\succ^n$ numa maneira simples.
Demonstre tua afirmação, que a $\succ^n$ (oficial) realmente é igual
à função que tu escreveste para teu leitor.

\hint
Fez o~\ref[succ3_is_plus_3] né?

\hint
Basta demonstrar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
e como $\succ^n$ (oficial) foi definida recursivamente,
como tu vai demonstrar isso?

\hint
Indução!

\solution
Seja $n\in\nats$.
A $\succ^n : \nats\to\nats$ é a função definida pela
$$
\succ^n(x) = x + n.
$$
Basta demonstrar que para todo $n\in\nats$
$$
\lforall {x\in\nats} {\succ^n(x) = x + n}
$$
algo que vou demonstrar por indução no $n$.
\crproofpart {Base.}
Seja $x\in\nats$.
Calculamos:
\compute
\succ^0 (x)
&= \idof\nats (x)   \by {pela def.~da $\succ^0$} \\
&= x                \by {pela def.~da $1_A$} \\
&= x + 0.           \by {pelo ensino fundamental} \\
\endcompute
\crproofpart {Passo indutivo.}
Suponha $k\in\nats$ tal que
$$
\lforall {x\in\nats} {\succ^k(x) = x + k}. \tag{H.I.}
$$
Basta demonstrar que
$$
\lforall {y\in\nats} {\succ^{k+1}(y) = y + (k+1)}.
$$
Seja $y\in\nats$ então.
Calculamos:
\compute
\succ^{k+1}(y)
&= \paren{\succ\of\succ^{k}}(y) \by {pela def.~de $\succ^{k+1}$} \\
&= \succ\big( \succ^k(y) \big)  \by {pela def.~de $\succ\of \succ^k$} \\
&= \succ(y + k)                 \by {pela HI com $x := y$} \\
&= (y + k) + 1                  \by {pela def.~de $\succ$} \\
&= y + (k + 1).                 \by {pelo ensino fundamental} \\
\endcompute

%%}}}

%%{{{ prob: constant_function_why_did_we_omit_unique 
\problem.
%%%{{{ meta 
\label constant_function_why_did_we_omit_unique
%%%}}}

Na definição do~\ref[constant_notiff_steady]
não escrevemos ``existe único'', mas apenas ``existe''.
O que mudaria com esse ``único''?
Demonstre tua afirmação.

\hint
Lembra se que a definição é apenas aplicável numa \emph{função}.
Mas cuidado com os casos especiais que envolvem o $\emptyset$.

\solution
\emph{Quase} nada!
Parece ser redundante, pois a definição é aplicável numa \emph{função}
e graças à determinabilidade sabemos que se existe, tem que ser
único---mas!
Vamos tentar demonstrar para achar algo interessante.
\eop
Suponha que temos $b,b'\in B$ que satisfazem a condição, ou seja,
temos:
$$
\align
\text{para todo $x \in A$,}& f(x) = b \\
\text{para todo $x \in A$,}& f(x) = b'
\endalign
$$
Logo tomando um $x\in A$, temos
$$
b = f(x) = b',
$$
ou seja, unicidade mesmo desse $b$,
dado qualquer $x\in A$.
Mas isso é, supondo que $A\neq\emptyset$.
O que acontece se $A=\emptyset$ e $B\neq\emptyset$?
Botando esse ``único'' na definição, uma função
$$
\emptyset\toby f B
$$
vai ser constante com valor $b$ sse $B$ é um singleton
e $b$ é seu único membro.
Sem o ``único'', ela vai ser constante sse $B\neq\emptyset$.
Veja também o exercício 

%}}}

% JECTIONS AND INVERSES

%%{{{ prob: touch_of_godel_encoding_strings 
\problem.
%%%{{{ meta 
\label touch_of_godel_encoding_srings
%%%}}}

Seja $\kstar \nats = \Union_n \nats^n$ o conjunto de todos
os strings finitos feitos por naturais.
Considere a $f : \kstar \nats \to \nats_{>0}$ definida pela
$$
f (x_0,\dotsc,x_{n-1}) = \Prod_{i=0}^{n-1} p_i^{x_i}
$$
onde $\seqn p n$ é a seqüência dos números primos
($p_0 = 2$, $p_1 = 3$, $p_2 = 5$, \dots).
(1) Explique por que $f$ não é injetora.
(2) Demonstre que $f$ é sobrejetora.
(3) O que acontece se substituir os exponentes $x_i$ por $x_i + 1$?

\solution
\proofpart {(1) $f$ não é injetora}
pois
$$
f(1) = 2 = f(1,0).
$$
\proofpart {(2) $f$ é sobrejetora.}
Seja $y \in \nats_{>0}$.
Pelo teorema fundamental de aritmética~\reftag[fundamental_theorem_of_arithmetic]
$y$ pode ser escrito como produtório de primos
$$
y = q_0^{y_i}
$$
\proofpart {(3) Acontece}
que ganha injectividade
(veja o~\ref[encoding_of_finite_sequences] e sua resolução)
e perde sobrejectividade:
nenhuma entrada é mapeada para o $3$, pois o único ímpar
que realmente está no $\range f$ é o $1$ ($f() = 1$ pela definição
do produtório vazio); todos os outros pontos do domínio da $f$
são múltiplos de $2$ pela sua definição.
Observe que tem números pares que faltam também, por exemplo o
$$
10 = 2^1 \ntimes 3^0 \ntimes 5^1.
$$

%%}}}

%%{{{ prob: epimono_factorization_teaser 
\problem.
%%%{{{ meta 
\label epimono_factorization_teaser
%%%}}}

Sejam $A \toby f B$.
Então existem: injecção $m$, surjecção $e$, e conjunto $C$
tais que o diagrama seguinte comuta:
$$
\cdopt{sep=1cm}
A \ar[rr, "f"]\ar[dr, twoheadrightarrow, "e"'] \| \| B \\
                                                  \| C \ar[ur, rightarrowtail, "m"']
\endcd
$$
Em outras palavras, mostre que qualquer função $f : A \to B$
pode ser \dq{decomposta} em
$$
f = m \of e
$$
onde $e$ é uma função sobrejetora e $m$ uma função injetora.

\hint
Para garantir que $e$ é sobrejetora escolher como $C$ 
o próprio $\range(f)$.

\solution
Sejam
$$
\align
C &= \range(f) \\
e &= \lam x {f x} : A \to C \\
m &= \inc : C \incto B
\endalign
$$
Basta demonstrar que $f = m \of e$.
Seja $x \in A$.
Calculamos:
\compute
(m \of e) x
&= m (e x)  \by {def.~$m \of e$} \\
&= m (f x)  \by {def.~$e$} \\
&= f x.     \by {def.~$m$} \\
\endcompute

%%}}}

%%{{{ prob: injto_surfrom_powerset 
\problem.
%%%{{{ meta 
\label injto_surfrom_powerset
%%%}}}

Seja $A$ um conjunto habitado.
Defina funções $f,g$ com os tipos seguintes:
\mathcol
f &: A \injto \pset A \\
g &: \pset A \surto A.
\endmathcol
Demonstre que:
(i) a $f$ é injetora;
(ii) a $f$ não é sobrejetora;
(iii) a $g$ é sobrejetora;
(iv) a $g$ não é sobrejetora.
Como eu posso pedir pra tu demonstrar tudo isso (as (ii) e (iv))
sem sequer saber quais são as $f,g$ que tu escolheu definir?
(Essa pergunta não é retórica.)

\hint
Cuidado: sobre o $A$ não podes supor nada mais que $A\neq\emptyset$.

\hint
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref[x_mapsto_singleton_x_properties].
Falta a parte sobre a $g : \pset \surto A$.

\hint
É para a parte do problema sobre a $g : \pset A \surto A$
que precisas o $A\neq\emptyset$.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
\dots?\dots, & $\dots?\dots$ \cr
\dots?\dots, & caso contrário.
}
$$
Novamente: cuidado para não supor nada mais que $A\neq\emptyset$
sobre o $A$.  Por exemplo: não sabemos se $A$ tem \emph{mais}
que um elemento (sabemos apenas que tem \emph{pelo menos} um);
não sabemos se os membros dele são ordenados; etc.
Se a gente soubesse que os membros de $A$ são \emph{bem ordenados}
a gente poderia definir o primeiro caso acima pela
$$
g(X) = \knuthcases {
\min X, & se $X \neq \emptyset$ \cr
\dots?\dots, & caso contrário.
}
$$
mas sem a informação que o $A$ é bem ordenado a $g$ não seria
bem-definida.
Por enquanto: um conjunto é chamado \dterm{bem ordenado} sse todo
$\emptyset\psubset X \subset A$ possui elemento mínimo.
No~\ref[Wosets] estudamos conjuntos bem ordenados e suas propriedades.

\hint
Seja $a_0 \in A$.  Defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
x,   & se $X$ é o singleton $\set{x}$ \cr
a_0, & caso contrário.
}
$$
Falta demonstrar que ela é sobrejetora e que não é injetora.

\solution
A parte do problema sobre a $f : A \injto \pset A$ foi resolvida
no~\ref[x_mapsto_singleton_x_properties], onde definimos a
$f : A \to \pset A$ pela $f(x) = \set{x}$ e demonstramos as (i)--(ii).
\eop
Fixe $a_0 \in A$ ($A\neq\emptyset$) e defina a $g : \pset A \to A$ pela
$$
g(X) = \knuthcases {
x,   & se $X$ é o singleton $\set{x}$\cr
a_0, & caso contrário.
}
$$
\eop
(iii) \proofpart {A $g$ é sobrejetora.}
Seja $y \in A$.  Observe que $g(\set{y}) = y$.
Como $\set{y}\in\pset A$, temos que $g$ é sobrejetora.
\eop
(iv) \proofpart {A $g$ não é injetora.}
Observe que $\emptyset, \set{a_0} \in \pset A$ e que $\emptyset \neq \set{a_0}$,
mas mesmo assim $g(\emptyset) = a_0 = g(\set{a_0})$.
Logo, $g$ não é injetora.
\crproofpart {Para responder na pergunta não retórica}
precisamos \emph{demonstrar} que não existe nenhuma função
$A \bijto \pset A$ e nenhuma função $\pset A \bijto A$.
Na verdade basta apenas demonstrar apenas uma das duas afirmações,
pois quando temos uma função bijetora de $A$ para $\pset A$
também temos ``de graça'' uma bijetora de $\pset A$ para $A$:
sua inversa.
Mas como conseguimos então \emph{demonstrar} que não existe bijecção
entre o $A$ e o $\pset A$?
Isso eu vou te deixar pensar.
Mas te aviso: é algo \emph{muito difícil de pensar}.
(Seria fácil se tivermos que $A$ é finito, mas pode ser que não é.)
Mas dê uma chance nele!
E não se preocupe: no~\ref[Cantors_paradise] estudamos umas
idéias de {\Cantor[teorema]}Cantor; foi ele que se perguntou
sobre isso, e foi ele que deu a resposta mesmo
(teorema de Cantor~\reftag[cantor_theorem],
\reftag[Cantors_theorem_and_its_consequences]).
As conseqüências do seu teorema são{\dots}
Brutais!
Paciência.

%%}}}

%%{{{ prob: projection_inj_or_surj 
\problem.
%%%{{{ meta 
\label projection_inj_or_surj
%%%}}}

Sejam $A\neq\emptyset$ conjunto, $n\in\nats_{>0}$,
e $I = \setst {i\in\nats} {i < n}$.
Considere a função $\pi : I \times A^n \to A$ definida por
$$
\pi(i, \alpha)
= \pi_i(\alpha)
\qquad\Bigparen{
= \text{o $i$-ésimo membro da tupla $\alpha$}
}
$$
onde consideramos o primeiro membro duma tupla seu
``$0$-ésimo'' membro, etc.
Investigue a injectividade e a sobrejectividade da $\pi$.

\hint
Calcule uns valores primeiro.  Por exemplo,
$$
\xalignat3
\pi (2, \tup{2,3,5,7}) &= 5 &
\pi (0, \tup{2})       &= 2 &
\pi (3, \tup{2,0,0,1}) &= 1
\endxalignat
$$

\solution
\proofpart {Injectividade.}
A injectividade da $\pi$ depende no $n$:
\crproofcase {Caso $n>1$}, não é:
pois tomando $a\in A$,
$$
\pi(0,\tup{a,\dotsc,a}) = a = \pi(1,\tup{a,\dotsc,a}).
$$
\proofcase {Caso $n=1$}, é:
tomando $w, w' \in I\times A^n$ com $w\neq w'$, temos
que $w = \tup{ 0, \tup{a} }$ e $w' = \tup{ 0, \tup{a'} }$
para alguns $a,a'\in A$.
Agora como $w\neq w'$ concluimos que $a\neq a'$ e logo
$\pi(0,w) \neq \pi(0,w')$, ou seja, $\pi$ é injetora
nesse caso.
\crproofpart {Sobrejectividade.}
A $\pi$ é sobrejetora sim:
pois para qualquer $a\in A$, $\pi(0,\tup{a,\dotsc,a}) = a$.

%%}}}

% SHIFTS

% img/pre

%%{{{ prob: jection_iff_composition_with_inverse_proof 
\problem.
%%%{{{ meta 
\label jection_iff_composition_with_inverse_proof
%%%}}}

Demonstre o~\ref[jection_iff_composition_with_inverse].

\solution
Já demonstrou as idas no~\reftag[jection_implies_composition_with_inverse].
Vamos demonstrar as voltas.
\eop
\proofpart {Volta da (1).}
Suponha a hipótese:
$$
\text{para todo $A \subset X$, $A = \pre f {\img f A}$}.
$$
Para mostrar que $f$ é injetora, suponha que $x,x'\in X$ tais que $f(x) = f(x')$.
Basta verificar que $x = x'$.
Considere o conjunto $A = \set{x}$.
Observe que $A \subset X$, e logo pela hipótese temos
$$
A = \pre f {\img f A}.\tag{A}
$$
Temos $f(x) \in \img f A$ pela definição da função-imagem.
Como $f(x') = f(x)$ temos também $f(x') \in \img f A$.
Logo
$$
x, x' \in \pre f {\img f A} \eqlabel A A = \set{x}.
$$
Como $x, x' \in \set{x}$, logo $x = x'$.
\eop
\proofpart {Volta da (2).}
Suponha a hipótese:
$$
\text{para todo $B \subset Y$, $B = \img f {\pre f B}$}.
$$
Tome $y_0\in Y$.
Para mostrar que $f$ é sobrejetora
basta mostrar que $\pre f {\set{y_0}} \neq \emptyset$.
Considere o
$$
B = \set{y_0} \subset Y
$$
e logo pela hipótese temos
$$
B = \img f {\pre f B}.\tag{B}
$$
Ou seja, $\pre f B \neq \emptyset$
(caso contrário teriamos
$$
B
\eqlabel B \img f {\pre f B}
= \img f {\emptyset}
= \emptyset
$$
que é absurdo pois $B = \set{y_0}$).
Isso mostra que $f$ é sobrejetora.

%%}}}

%%{{{ prob: big_operations_respected_by_img_and_pre 
\problem.
%%%{{{ meta 
\label big_operations_respected_by_img_and_pre
\pdefs
    \pdef I {{\cal I}}
    \pdef J {{\cal J}}
    ;;
%%%}}}

Sejam $f : A \to B$, e duas famílias indexadas de conjuntos:
$\famil A i \I$ feita por subconjuntos de $A$, e
$\famil B j \J$ feita por subconjuntos de $B$.
Ou seja, par todo $i\in \I$, e todo $j \in \J$,
temos $A_i \subset A$ e $B_j \subset B$.
Mostre que:
$$
\align
\img f {\Unionl_{i \in \I} A_i} &=      \Unionl_{i \in \I} \img f {A_i} \tag1\\
\img f {\Interl_{i \in \I} A_i} &\askeq \Interl_{i \in \I} \img f {A_i} \tag2\\
\pre f {\Unionl_{j \in \J} B_j} &=      \Unionl_{j \in \J} \pre f {B_j} \tag3\\
\pre f {\Interl_{j \in \J} B_j} &=      \Interl_{j \in \J} \pre f {B_j} \tag4
\endalign
$$
onde na $\askeq$ demonstre que a igualdade em geral não é válida,
mas uma das~{\lrdirset}~e~{\rldirset} é.
A demonstre, e, supondo que $f$ é injetora, demonstre a outra também.

\solution
\proofpart {(1)}:
Demonstramos cada direção separadamente.
{\lrdirset}:
Seja $b \in \img f {\Union_{i\in\I} A_i}$.
Seja $a\in\Union_{i\in\I} A_i$ tal que $f(a) = b$\fact1 (pela definição de função-imagem).
Agora tome $i\in\I$ tal que $a\in A_i$\fact2.
Agora pelas~\byfact1,\byfact2~temos que $b\in\img f {A_i}$.
Ou seja, $b \in \Union_{i\in\I} \img f {A_i}$.
{\rldirset}:
Seja $b \in \Union_{i\in\I} \img f {A_i}$.
Seja $i\in\I$ tal que $b\in \img f {A_i}$.
Tome $a\in A_i$ tal que $f(a) = b$\fact1.
Como $a\in A_i$, logo $a\in\Union_{i\in\I} A_i$ e agora pela~\byfact1
ganhamos $b \in \img f {\Union_{i\in\I} A_i}$.
\eop
\proofpart {(2)}:
Demonstramos primeiramente a {\lrdirset} que é válida para toda $f$,
e mostramos que se $f$ é injetora, a {\rldirset} também é válida.
{\lrdirset}:
Seja $b \in \img f {\Inter_{i\in\I} A_i}$.
Logo tome $a \in \Inter_{i\in\I} A_i$\fact1 tal que $f(a) = b$\fact2.
Agora, como $a$ pertence a todos os $A_i$'s e $f(a) = b$,
então para cada $i\in\I$, $b\in\img f {A_i}$.
Ou seja, $b$ pertence a todos os $\img f {A_i}$'s.
Chegamos então no desejado $b\in\Inter_{i\in\I} \img f {A_i}$.
\eop
{\rldirset}:
Para essa direção vamos supor que $f$ é injetora.
Tome $b\in\Inter_{i\in\I} \img f {A_i}$, ou seja $b$
pertence a todos os $\img f {A_i}$'s.
Ou seja, para cada um dos $A_i$'s, existe $a_i\in A_i$
tal que $f(a_i) = b$.
Mas a $f$ é injetora, então todos esses $a_i$'s são iguais;
seja $a$ então esse membro comum dos $A_i$'s.
Temos então que:
$a \in \Inter_{i\in\I} {A_i}$ e $f(a) = b$.
Ou seja, $b \in \img f {\Inter_{i\in\I} A_i}$.
\eop
\proofpart {(3)}:
Calculamos:
\compute
a \in \pre f {\Unionl_{j\in\J} B_j}
&\iff f(a) \in \Unionl_{j\in\J} B_j           \by {def.~$\pre f {\Unionl_{j\in\J} B_j}$} \\
&\iff \lexists {j\in\J} {f(a) \in B_j}        \by {def.~$\Unionl_{j\in\J} B_j$} \\
&\iff \lexists {j\in\J} {a \in \pre f {B_j}}  \by {def.~$\pre f {B_j}$} \\
&\iff a \in \Unionl_{j\in\J} {\pre f {B_j}}.  \by {def.~$\Unionl_{j\in\J} {\pre f {B_j}}$} \\
\endcompute
Ou seja, $\pre f {\Unionl_{j \in \J} B_j} = \Unionl_{j \in \J} \pre f {B_j}$.
\eop
\proofpart {(4)}:
{\lrdirset}:
Seja $a \in \pre f {\Inter_{i\in\J}^\infty B_j}$.
Logo $f(a) \in {\Inter_{i\in\J}^\infty B_j}$,
ou seja, para todo $i\in\J$, $f(a) \in B_j$.
Logo $a \in \pre f {B_j}$ para todo $i\in\J$, ou seja,
$a \in {\Inter_{i\in\J}^\infty \pre f {B_j}}$.
{\rldirset}.
Similar: é só seguir os passos da {\lrdirset} em reverso.

%%}}}

%%{{{ prob: big_intersection_respected_by_img_wrong_proof 
\problem.
%%%{{{ meta 
\label big_intersection_respected_by_img_wrong_proof
%%%}}}

Um aluno \dq{demonstrou} que se $f : A \to B$ e $\seqn A n$ é uma
seqüência de subconjuntos de $A$, então
$$
\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}.
$$
Sua \dq{demonstração} foi a seguinte:
\quote
<<Calculamos:
\compute
b \in \img f {\Interl_{n=0}^\infty A_n}
&\ifflabel1 \lexists {a \in \Interl_{n=0}^\infty A_n} {f(a) = b}            \by {def.~$\img f {\dhole}$} \\
&\ifflabel2 \exists a \paren{a \in \Interl_{n=0}^\infty A_n \land f(a) = b} \by {lógica} \\
&\ifflabel3 \exists a \paren{\forall n \paren{a \in A_n} \land f(a) = b}    \by {def.~$\Interl_{n=0}^\infty$} \\
&\ifflabel4 \exists a \paren{\forall n \paren{a \in A_n \land f(a) = b}}    \by {lógica} \\
&\ifflabel5 \exists a \forall n \paren{a \in A_n \land f(a) = b}            \by {lógica} \\
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b}            \by {lógica} \\
&\ifflabel7 \forall n \lexists {a \in A_n} {f(a) = b}                       \by {lógica} \\
&\ifflabel8 \forall n \paren{b \in \img f {A_n}}                            \by {def.~$\img f {\dhole}$} \\
&\ifflabel9 b \in \Interl_{n=0}^\infty {\img f {A_n}}                       \by {def.~$\Interl_{n=0}^\infty$} \\
\endcompute
Logo temos
$\img f {\Interl_{n=0}^\infty A_n} = \Interl_{n=0}^\infty \img f {A_n}$
pela definição de igualdade de conjuntos.>>
\endquote
Ache os seus erros.

\hint
Justificar um passo de demonstração com a palavrinha
``lógica'' não vai aumentar a confiança de ninguém sobre
a validez de tal passo.
De fato, nessa demonstração pelo menos um desses passos é errado.

\hint
O problema está na $\ifflabel6$.
Uma da suas direções não é válida.

\solution
Um primeiro problema é esse ``lógica'' que aparece várias vezes
como suposta justificativa de passos.
Já que todos os passos que fazemos numa demonstração supostamente
são logicamente válidos, não faz sentido pensar que decorando
um tal passo com a palavrinha ``lógica'' pode convencer alguém
sobre algo.
\eop
O problema aqui é com a direção {\rldir} da $\ifflabel6$:
\compute
\cdots\iff  \exists a \forall n \paren{a \in A_n \land f(a) = b}
&\ifflabel6 \forall n \exists a \paren{a \in A_n \land f(a) = b} \by {lógica} \\
\endcompute
Saber que
\emph{existe $a$ tal que para todo $n$ algo $P(a,n)$ acontece}
é uma afirmação bem mais forte do que saber que
\emph{para todo $n$ existe algum $a$ tal que $P(a,n)$ acontece}.
Na primeira temos pelo menos um $a$ que serve para todo $n$,
mas na segunda pode ser que para cada $n$, o $a$ ``que serve''
é diferente.  Para enfatizar essa dependência podemos escrever:
\emph{para todo $n$ existe algum $a_n$ tal que $P(a_n, n)$}.
É por isso que a ida é válida mas a vólta, em geral, não é.
Compare com o~\ref[wrong_order_of_quantifiers].

%%}}}

%%{{{ prob: f_surj_iff_pre_f_inj 
\problem.
%%%{{{ meta 
\label f_surj_iff_pre_f_inj
%%%}}}

Seja $f : A \to B$.
Considere a afirmação seguinte:
$$
\text{$f(\dhole)$ sobrejetora}
\askiff
\text{$\pre f {\dhole}$ injetora}.
$$
Para cada uma das direções responda\dots
(1) ``sim'', e demonstre;
(2) ``não'', e refute; ou
(3) ``depende'', e mostre dois exemplos:
um onde a implicação é válida, e outro onde não é.

\hint
Ambas as implicações são válidas.
(Observe que $f(\dhole)$ é a própria $f$.)

\solution
Ambas as direcções são válidas.
\crtabproofpart {\lrdir}:
Suponha $f$ sobrejetora e sejam $Y,Y'$ no $\dom(\pre f {\dhole})$
tais que $Y\neq Y'$.
(Temos então $Y,Y'\subset B$.)
Basta demonstrar que $\pre f {Y} \neq \pre f {Y'}$.
Como $Y\neq Y'$, sem perda de generalidade, seja $d \in Y \setminus Y'$.
Como $f$ é sobrejetora, seja $a_d \in A$ tal que $f(a_d) = d$.
Observe que $f(a_d) \in Y$ e que $f(a_d) \nin Y'$.
Logo $a_d \in \pre f Y$ e $a_d \nin \pre f {Y'}$,
pela definição da $\pre f {\dhole}$.
Logo $\pre f Y \neq \pre f Y'$.
\crtabproofpart {\rldir}:
Vou demonstrar a contrapositiva da afirmação.
Suponha então que $f$ não é sobrejetora.
Vou demonstrar que $\pre f {\dhole}$ não é injetora.
Basta então achar dois membros distintos no seu domínio
mapeados no mesmo objeto.
Como $f$ não é sobrejetora, seja $t\in B$ tal que
$t \nin \range(f)$, ou seja, tal que
para todo $a \in A$, $f(a) \neq t$.
Agora considere os: $\emptyset$ e $\set{t}$.
Ambos são subconjuntos de $B$, e eles são distintos,
mas mesmo assim
$$
\pre f {\emptyset} = \emptyset = \pre f {\set{t}}.
$$
Ou seja, a $\pre f {\dhole}$ não é injetora.

%}}}

%%{{{ prob: Halmos_advice_f_surj_iff_pre_f_inj 
\problem Don't just read it; fight it.
%%%{{{ meta 
\label Halmos_advice_f_surj_iff_pre_f_inj
%%%}}}

Ache a coisa mais óbvia para se perguntar depois
do~\ref[f_surj_iff_pre_f_inj];
pergunte-se; responda (demonstra ou refuta).

\hint
$$
f(\dhole)
\brace{%
\mathed{
\text{injetora} \\
\text{sobrejetora}
}}
\askiff
\brace{\mathcoled{
\img f \dhole \\
\pre f \dhole
}}
\brace{\mathed{
\text{injetora} \\
\text{sobrejetora}
}}
$$

%%}}}

% iter, img/pre

%%{{{ prob: succiter_for_dummies_returns 
\problem.
%%%{{{ meta 
\label succiter_for_dummies_returns
%%%}}}

(Continuação do~\ref[succiter_for_dummies].)
Qual é (a extensão d)o conjunto
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}\,?
$$
Demonstre tua afirmação.

\hint
$\Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$.

\hint
Suponha que tem $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats} = \emptyset$
e chegue numa contradicção.

\solution
Eu vou demonstrar que
$$
\Inter_{n=0}^\infty \img {\succ^n} {\nats}=\emptyset.
$$
Para chegar num absurdo,
suponha que $w \in \Inter_{n=0}^\infty \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, $w \in \img {\succ^n} {\nats}$.
Logo, para todo $n\in\nats$, existe $m\in\nats$ tal que $\succ^n(m) = w$.
Mas $\succ^n(m) = n + m$ (\ref[succiter_for_dummies]).
Ou seja:
$$
\text{para todo $n\in\nats$, existe $m\in\nats$ tal que $n + m = w$}.
$$
Ou seja, lembrando da \ref[natleq],
$$
\text{para todo $n\in\nats$, $n \leq w$}. \tag{*}
$$
Ou seja, $w$ é o máximo do $\nats$; absurdo pois $\nats$ não tem máximo!
\crproofalt{Alternativamente,}
bote $n := w+1$ na (*) para chegar no absurdo $w + 1 \leq w$.

%%}}}

% img/pre

%%{{{ prob: img_paren_notation_not_safe_even_when_homogenous 
\problem.
%%%{{{ meta 
\label img_paren_notation_not_safe_even_when_homogenous
%%%}}}

A~\ref[img_paren_notation_safe_even_when_homogenous_mistake] tem um probleminha.
Mesmo trabalhando apenas com uma funções homogêneas podemos cair em
ambigüidade!
Bem depois, no~\ref[Type_theory], vamos entender a situação melhor;
e tenho um teaser na resolução.
Mas por enquanto só resolva esse problema, ou seja,
ache um exemplo problemático para essa notação,
usando apenas conjuntos homogêneos.

\hint
Dá pra achar um tal exemplo usando uma função $f: \pset\nats \to \pset\nats$.

\hint
$\emptyset \in \pset\nats$, mas também $\emptyset \in \pset\pset\nats$
(pois $\emptyset \subset \pset\nats$).

\solution
Considere uma função $f : \pset\nats\to\pset\nats$.
Sobre a $f$-imagem do $\emptyset$, não tenho opção:
sei que vai ser o $\emptyset$ (\ref[img_and_pre_of_emptyset]).
Mas sobre o $f$-\emph{valor} do $\emptyset$ eu tenho
opção sim---minha função, minhas regras!
Defino a $f$ para ser a constante que sempre retorna o $\set{1,2}$
então.
Logo temos:
$$
f(\emptyset) = \set{1,2} \neq \emptyset = \img f \emptyset.
$$
Ou seja, a notação que usa as parenteses, tá buggada mesmo
que os conjuntos que trabalhamos são homogêneos.
\eop
\proofpartstylize{Teaser.}
Talvez o problema seria resolvido se cada objeto chegasse
junto com um rótulo, dizendo \emph{que tipo de coisa} ele é.
Assim talvez teriamos como diferenciar entre os
dois(!?)~$\emptyset$'s
(algo que no nosso contexto não faz sentido nenhum pois
violaria a unicidade do conjunto
vazio~\reftag[naive_uniqueness_of_emptyset]).
Um $\emptyset$ diria:
\quote
\wq{Eu sou um conjunto de naturais com nenhum membro.}
\endquote
E o outro $\emptyset$ diria:
\quote
\wq{Eu sou um conjunto de conjuntos de naturais com nenhum membro.}
\endquote
Vamos voltar nisso bem, bem, bem depois,
no~\ref[Type_theory]: teoria dos tipos.
Por enquanto, esqueça.

%%}}}

% currying (flip)

%%{{{ prob: flip_definition 
\problem flip.
%%%{{{ meta 
\label flip_definition
%%%}}}

No \ref[powTwo] da~\reftag[Currying] definimos a função $\namedfun{powTwo}$
diretamente como aplicação parcial da função $\namedfun{exp}$
$$
\namedfun{powTwo} = \namedfun{exp} \fa 2
$$
evitando o uso de pontos ou lambdas:
\mathcols 2
\namedfun{powTwo} \fa n &= \namedfun{exp} \fa 2 \fa n; &
\namedfun{powTwo}       &= \lam n {\namedfun{exp} \fa 2 \fa n}.
\endmathcols
Similarmente podemos definir a função que corresponde seqüência das potências
de qualquer outro número real.
Mas parece que não podemos criar com a mesma laconicidade (apenas como
aplicação parcial) uma função $\namedfun{square}$ ou $\namedfun{cube}$,
pois os argumentos da $\namedfun{exp}$ estão ``na ordem errada''.
O objectivo desse problema é fazer exatamente isso.
\eop
Defina uma função de ordem superior $\namedfun{flip}$, que recebe qualquer
função binária currificada, e retorna a função binária currificada que
comporta no mesmo jeito mas recebendo seus argumentos na ordem oposta.
Por exemplo:
\mathcols 2
\namedfun{exp} \fa 2 \fa 3 &= 8; &
\paren{\namedfun{flip} \fa \namedfun{exp}} \fa 2 \fa 3 &= 9
\endmathcols
Começa escrevendo o tipo da $\namedfun{flip}$ e o lendo com as duas
maneiras diferentes que discutimos na~\ref[human_eyes_and_ho_types].

%%}}}

\endproblems
%%}}}

% COMPOSITION LAWS, COMMUTATIVE DIAGRAMS, PRODUCTS

%%{{{ Composition_laws 
\section Leis de composição.
%%%{{{ meta 
\label Composition_laws
%%%}}}

%%{{{ Composition as an operation 
\note Composição como operação.
%%%{{{ meta 
\label composition_as_an_operation
%%%}}}

No mesmo jeito que o produto $3\ntimes 2$ denota um número,
a composição $g \of f$ de certas funções $f$ e $g$ denota uma função.
A $\of$ então realmente é uma operação (binária) nas funções,
e agora vamos investigar as leis que ela satisfaz, fazendo uma
comparação com a multiplicação nos números, procurando similaridades
e diferêncas.  Note que já começamos com uma ambigüidade com esse
``nos números'', pois as leis satisfeitas pela~$(\ntimes)$~dependem de
\emph{qual multiplicação} estamos considerando:
a multiplicação nos reais, por exemplo, satisfaz a uma lei de inversos
(viz.~\wq{cada número diferente de zero tem um inverso multiplicativo})
mas nos inteiros não.  Mais sobre isso depois.

%%}}}

%%{{{ factorization_of_function 
\note Fatoração de função.
%%%{{{ meta 
\defines
    * fatoração!de função
    ;;
%%%}}}

Num certo sentido muito interessante, e fortalecendo
nossa metáfora entre composição e multiplicação,
o que fizemos no~\ref[factorize_a_function_example]
pode ser visto como uma \dterm{fatoração de função}:
escrevemos a $f$ como ``produto'' dos ``fatores''
$g,h,k$.
Sabendo como fatorar funções é importaníssimo
em programação, algo que apreciamos extensivamente no
no~\ref[Recursion_induction].

%%}}}

%%{{{ Totality 
\note Totalidade.
%%%{{{ meta 
%%%}}}

Primeiramente observe uma grande diferença entre composição e multiplicação:
a multiplicação é uma operação \dterm{total}, ou seja, para todo número
$x, y$, seu produto $x\ntimes y$ é definido.
Mas como vimos na~\ref[fcompose], para formar a composição $g\of f$
de duas funções $f$ e $g$ elas precisam satisfazer a condição
$\cod f = \dom g$.  Caso contrário, o $g\of f$ nem tem significado!
Continuamos investigando mais propriedades.

%%}}}

%%{{{ Intuition with tasks 
\note Intuição com tarefas.
%%%{{{ meta 
%%%}}}

Vamos agora imaginar funções como tarefas para ser feitas em algo,
e a composição como a idéia de ``seqüenciar as tarefas''.
Ou seja $g\of f$ seria a tarefa de \emph{fazer a tarefa $f$ e depois a $g$}.
Com essa intuição, parecem óbvias estas duas afirmações:
\elist i:
\li: a composição é associativa;
\li: a composição não é comutativa.
\endelist
Mas intuição nunca demonstrou nada sozinha,
então bora demonstrar essas afirmações!

%%}}}

%%{{{ Associativity 
\note Associatividade.
%%%{{{ meta 
%%%}}}

Suponha que temos funções
$$
A \toby f B \toby g C \toby h D.
$$
Podemos então formar as composições $g\of f$ e $h\of g$.
Temos então:
$$
A \toby {g\of f} C \toby h D
\qqquad
A \toby f B \toby {h\of g} D.
$$
Compondo as funções do primeiro diagrama criamos a função $h\of(g\of f)$,
e compondo aquelas do segundo criamos a $(h\of g)\of f$:
$$
A \longtoby {h\of (g\of f)} D
\qqquad
A \longtoby {(h\of g)\of f} D.
$$
Queremos saber se as duas funções são iguais.
Vamos pensar sobre isso usando black boxes.
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc1;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc2;
\endtikzpicture
\endgathered
$$
Primeiramente observe que os tipos delas são iguais.
Então basta verificar que concordam para todo ponto $x\in A$.
Pela definição de composição sabemos que ``internalmente''
elas funcionam assim:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc3;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc4;
\endtikzpicture
\endgathered
$$
Agora pelas definições das $g\of f$ e $h\of g$,
o que precisamos comparar na verdade são as:
$$
\gathered
\tikzpicture
\tikzi blackboxfuncompassoc5;
\endtikzpicture
\\
\tikzpicture
\tikzi blackboxfuncompassoc6;
\endtikzpicture
\endgathered
$$
Agora que tá tudo transparente parece óbvio que as duas funções são iguais,
e comportam como a seguinte:
$$
\tikzpicture
\tikzi blackboxfuncompassoc0;
\endtikzpicture
$$
Mas para demonstrar que as duas construções resultam na mesma função,
vamos precisar calcular os <<$?$>> do desenho acima, e seguir
fielmente as definições.

%%}}}

%%{{{ thm: fcom_associativity_law 
\theorem Lei de associatividade.
%%%{{{ meta 
\label fcom_associativity_law
%%%}}}

Sejam
$$
A \toby f B \toby g C \toby h D.
$$
Então
$$
h \of (g \of f) = (h \of g) \of f.
$$

\sketch.
Mostramos que as duas funções são iguais seguindo a definição
de igualdade~\reftag[f_eq_g]:
mostrando que elas têm o mesmo domínio $A$,
e que comportam igualmente para o arbitrário $a \in A$.
Observe que seus codomínios também são iguais, satisfazendo
assim a definição de igualdade~\reftag[f_eq_g_catist] também.
Pegando cada lado da igualdade e aplicando a definição de $\of$
chegamos no mesmo valor.

\proof.
Primeiramente vamos verificar que as duas funções tem o mesmo domínio:
\compute
\dom\paren{ h \of (g \of f) }
&= \dom (g \of f)               \by {def.~$h\of(g\of f)$} \\
&= \dom f                       \by {def.~$g\of f$} \\
\intertext{e do lado direito}
\dom\paren{ (h \of g) \of f }
&= \dom f.                      \by {def.~$(h\of g)\of f$} \\
\endcompute
Similarmente elas têm os mesmos codomínios
(caso que seguimos a definição~\reftag[f_eq_g_catist])
\compute
\cod\paren{ h \of (g \of f) }
&= \cod h                       \by {def.~$h\of(g\of f)$} \\
\intertext{e do lado direito}
\cod\paren{ (h \of g) \of f }
&= \cod (h \of g)               \by {def.~$(h\of g)\of f$} \\
&= \cod h.                      \by {def.~$h\of g$} \\
\endcompute
Agora precisamos mostrar que as duas funções comportam no mesmo jeito
para todos os elementos no $A$.
Suponha $a\in A$ então, e calcule:
\compute
\paren{h \of (g \of f)}(a)
&= h\paren{\paren{g \of f}(a)}  \by {def.~$h\of(g\of f)$} \\
&= h\paren{g \paren{f(a)}}      \by {def.~$g\of f$} \\
\intertext{e o lado direito:}
\paren{(h \of g) \of f}(a)
&= \paren{h \of g}\paren{f(a)}  \by {def.~$(h\of g)\of f$} \\
&= h\paren{g \paren{f(a)}}      \by {def.~$h\of g$} \\
\endcompute

%%}}}

%%{{{ Commutativity 
\note Comutatividade.
%%%{{{ meta 
%%%}}}

É fácil demonstrar que a composição de funções \emph{não é comutativa}.
Faça isso agora no exercício seguinte!

%%}}}

%%{{{ x: non_commutativity_of_fcom 
\exercise.
%%%{{{ meta 
\label non_commutativity_of_fcom
%%%}}}

Existem funções $f,g$ entre conjuntos $A,B$
tais que $f\of g$ e $g\of f$ são ambas definidas,
mas mesmo assim
$$
f\of g \neq g\of f.
$$
Mostre pelo menos dois exemplos diferentes:
um com $A\neq B$; outro com $A = B$.

\solution
\DefFun flip
\DefFun zero
\DefFun one
Para o primeiro exemplo, escolhe $A = \set{0}$ e $B=\set{0,1}$.
Agora sejam $f : A \to B$ e $g : B \to A$ definidas pelas
$$
\xalignat2
f(0) &= 0  &  g(x) = 0
\endxalignat
$$
Ambas as $g\of f$ e $f\of g$ são definidas mas são diferentes
pois nem domínios iguais elas têm:
$$
\dom (g\of f) = \dom g = B \neq A = \dom f = \dom (f\of g).
$$
\eop
Para o segundo exemplo, tome $A=B=\set{0,1}$
e defina as funções $\flip,\zero,\one:A \to A$ pelas:
$$
\xalignat3
\flip(0) &= 1  &  \zero(0) &= 0  &  \one(0) &= 1\\
\flip(1) &= 0  &  \zero(1) &= 0  &  \one(1) &= 1.
\endxalignat
$$
Calculando temos $\flip\of\zero = \one$ mas $\zero\of\flip = \zero$.
De fato, quaisquer duas dessas três funções servem como um exemplo nesse caso!

%%}}}

%%{{{ Identity 
\note Identidades.
%%%{{{ meta 
%%%}}}

Investigamos agora se a operação de composição possui \emph{identidade}
mas primeiramente vamos lembrar o que isso significa.
Por enquanto não demonstramos nada a respeito disso, então trate
as funções que chamamos de identidades na~\reftag[identity_function]
como uma coincidência.

%%}}}

%%{{{ Q: what_is_the_identity_of_composition 
\question.
%%%{{{ meta 
\label what_is_the_identity_of_composition
%%%}}}

Chamamos o $1$ a \dterm{identidade} da operação $(\ntimes)$ nos reais, pois:
$$
1\ntimes x = x = x\ntimes 1, \qquad \text{para todo $x\in \reals$}.
$$
Tentando achar uma similaridade entre funções e números num lado, e composição e multiplicação no outro,
qual seria nosso $1$ aqui?
Ou seja,
procuramos objeto \holed?\ tal que
$$
\holed? \of f = f = f \of \holed?
$$
para toda função $f$.

%%}}}

\spoiler

%%{{{ x: id_compose_practice 
\exercise.
%%%{{{ meta 
\label id_compose_practice
%%%}}}

Sejam $A,B$ conjuntos diferentes, e $f : A \to B$.
Para cada uma das igualdades abaixo,
decida se ela é válida ou não, justificando tua resposta.
$$
\xalignat4
(1)\quad f &= {f \compose \idof A}; &
(2)\quad f &= {f \compose \idof B}; &
(3)\quad f &= {\idof A \compose f}; &
(4)\quad f &= {\idof B \compose f}.
\endxalignat
$$

\solution
\noi (1)
Válida: a composição é definida, e se $a\in A$ então:
\compute
(f \of \idof A)(a)
&= f(\idof A (a))  \by {def.~$f\of\idof A$} \\
&= f(a).           \by {def.~$\idof A$} \\
\endcompute
\eop
\noi (2) e (3): as composições não são definidas
\eop
\noi (4) Similar com (1): a composição é definida e se $a \in A$ então:
\compute
(\idof B \of f)(a)
&= \idof B (f(a))  \by {def.~$\idof B\of f$} \\
&= f(a).           \by {def.~$\idof B$} \\
\endcompute

%%}}}

%%{{{ thm: fcom_identity_laws  
\theorem Leis de identidade.
%%%{{{ meta 
\label fcom_identity_laws
%%%}}}

Para todo conjunto $A$,
existe unica função $\idof A : A \to A$ tal que:
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \idof A = f; \\
\text{para toda $f : B \to A$},&\quad \idof A \of f = f.
\endalign
$$

\sketch.
Primeiramente verificamos que a identidade do $A$ (\ref[identity_function])
que ``coincidentemente'' denotamos por $\idof A$ realmente satisfaz tudo isso.
Depois mostramos que qualquer outra possível função $\idof A'$
com essas propriedades deve ser (igual) {\paraccenta à} própria $\idof A$.

\proof.
Observe que dado conjunto $A$, a $\idof A$ tem o domínio e codomínio certo.
Basta então verificar que ela tem as propriedades (i)--(ii) e que ela é única.
\crproofpart {$\idof A$ tem a primeira propriedade.}
Seja $f : A \to B$.
Preciso mostrar que $f \of \idof A = f$.
Primeiramente verifico que têm o mesmo domínio e---para satisfazer
até os categoristas---o mesmo codomínio:
$$
\align
\dom (f\of\idof A) &= \dom(\idof A) = A = \dom f; \\
\cod (f\of\idof A) &= \cod f.
\endalign
$$
Basta ver se tem o mesmo comportamento.
Seja $x\in A$ então, e calcule:
\compute
(f \of \idof A) x
&= f(\idof A x) \by {def.~$f \of \idof A$} \\
&= f(x).        \by {def.~$\idof A$} \\
\endcompute
\proofpart {$\idof A$ tem a segunda propriedade.}
Similar.
\crproofpart {$\idof A$ é única.}
Seja $\idof A' : A \to A$ função tal que
$$
\align
\text{para toda $f : A \to B$},&\quad f \of \idof A' = f; \\
\text{para toda $f : B \to A$},&\quad \idof A' \of f = f.
\endalign
$$
Preciso mostrar que $\idof A = \idof A'$.
Calculamos:
\compute
\idof A
&= \idof A \of \idof A'  \by {primeira propriedade da $\idof A'$ com $f \asseq \idof A$} \\
&= \idof A'.             \by {segunda propriedade da $\idof A$ com $f \asseq \idof A'$} \\
\endcompute

%%}}}

%%{{{ function_laws 
\note Leis de funções.
%%%{{{ meta 
\label function_laws
%%%}}}

As configurações na esquerda implicam as equações na direita:
\mathcol
A \toby f B \toby g C \toby h D
& \;\;\implies\;\;
(h \of g) \of f = h \of (g \of f)
\tag{F-Ass}\\
A \toby f B
& \;\;\implies\;\;
\lsystemed {
f \of \idof A &= f \\
\idof B \of f &= f
}
\endmathcol

%%}}}

\endsection
%%}}}

%%{{{ Commutative_diagrams 
\section Diagramas comutativos.
%%%{{{ meta 
\label Commutative_diagrams
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Começamos com uma definição complicada; leia agora, mas veja logo os exemplos
seguintes.

%%}}}

%%{{{ pseudodf: commutative_diagram 
\pseudodefinition diagrama comutativo.
%%%{{{ meta 
\label commutative_diagram
\defines
    * diagrama!comutativo
    ;;
%%%}}}

Digamos que um diagrama externo de funções \dterm{comuta} ou que é um
\dterm{diagrama comutativo} sse: para todo par de ``caminhos'' feitos
por seguindo setas, \emph{se pelo menos um dos dois caminhos tem tamanho
maior que $1$}, então os dois caminhos são iguais.

%%}}}

%%{{{ eg: triangle 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[dr, "h"'] \| B \ar[d, "g"] \\
                             \| C
\endcd
$$
Significa que $h = g\of f$.

%%}}}

%%{{{ eg: square 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "h"'] \| B \ar[d, "g"] \\
D   \ar[r, "k"]             \| C
\endcd
$$
Significa que $g\of f  = k\of h$

%%}}}

%%{{{ eg: cd_example_line 
\example.
%%%{{{ meta 
\label cd_example_line
%%%}}}

O que significa que o diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
Significa que $f\of g  = f\of h$.

%%}}}

%%{{{ beware: at least one path must have length greater than 1 
\beware.
%%%{{{ meta 
%%%}}}

Graças à parte enfatizada na~\ref[commutative_diagram], \emph{não podemos}
concluir no~\ref[cd_example_line] que $g = h$, pois mesmo que
existem esses dois caminhos de $A$ para $B$ (um seguindo a seta $g$, outro
seguindo a seta $h$), nenhum deles tem tamanho maior que 1.

%%}}}

%%{{{ eg: part of diagram commutes 
\example.
%%%{{{ meta 
%%%}}}

O que significa que o rectângulo no diagrama seguinte comuta?
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[d, "k"'] \| B \ar[d, "g"]  \ar[dr, "i"] \\
D                           \| C \ar[l, "h"'] \ar[r, "j"] \| D 
\endcd
$$
Apenas que $h \of g \of f = k$.
Observe que isso não nos permite concluir nada especial sobre as
setas~$i$ e~$j$ do triângulo.  Se soubéssemos que o diagrama
comuta (e não apénas seu rectângulo), poderiamos concluir
que $i = j\of g$ também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Afirmando a comutatividade de certos diagramas vira uma maneira curta de
afirmar proposições, como por exemplo essas duas leis que já encontramos
na~\reftag[Composition_laws].

%%}}}

%%{{{ eg: cd_associativity_law 
\example.
%%%{{{ meta 
\label cd_associativity_law
%%%}}}

Afirme a lei da associatividade da~\reftag[Composition_laws]
usando a comutatividade dum diagrama.

\solution.
Sejam $A\toby f B \toby g C \toby h D$.
Basta desenhar um diagrama cuja comutatividade quis dizer
$h \of (g \of f) = (h \of g) \of f$.
É o seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rr, bend left=30,  "g\of f"] \|
B   \ar[r, "g"]\ar[rr, bend right=30, "h\of g"'] \|
C   \ar[r, "h"] \|
D
\endcd
$$
Outra maneira para desenhar o mesmo diagrama seria a seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"]\ar[rd, "g\of f"'] \| B \ar[d, "g"]  \ar[dr, "h\of g"] \\
                                  \| C \ar[r, "h"']      \| D
\endcd
$$
Questão de gosto.

%%}}}

%%{{{ x: cd_id_laws 
\exercise.
%%%{{{ meta 
\label cd_id_laws
%%%}}}

Como podemos expressar as leis da identidade (\ref[Composition_laws])
usando apenas a comutatividade dum diagrama?

\hint
Use uma $f : A \to B$, e as identidades $\idof A,\idof B$.

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "f"']\ar[r, "\idof A"] \| A \ar[d, "f"]  \ar[dr, "f"]   \\
                                   \| B \ar[r, "\idof B"'] \| B
\endcd
$$

%%}}}

%%{{{ x: cd_finv_laws 
\exercise Leis da inversa (com diagrama comutativo).
%%%{{{ meta 
\label cd_finv_laws
%%%}}}

Como podemos expressar as leis da inversa (F-Inv)
usando apenas a comutatividade dum diagrama?

\hint
A forma do diagrama parece com o diagrama das
leis de identidade (\ref[cd_id_laws]).

\solution
Assim:
$$
\cdopt{sep=2cm}
A   \ar[dr, "\id"']\ar[r, "f"] \| B \ar[d, "\finv f"]  \ar[dr, "\id"]   \\
                               \| A \ar[r, "f"'] \| B
\endcd
$$

%%}}}

%%{{{ x: cd_copy_paste 
\exercise.
%%%{{{ meta 
\label cd_copy_paste
%%%}}}

Suponha que os quadrados no diagrama seguinte comutam:
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
Demonstre que o rectângulo grande também comuta.

\solution
Temos que os quadrados do
$$
\cdopt{sep=2cm}
A   \ar[r, "f"] \ar[d, "i"] \| B \ar[r, "g"] \ar[d, "j"] \| C \ar[d, "k"] \\
P   \ar[r, "s"]             \| Q \ar[r, "t"]             \| R
\endcd
$$
comutam.
Precisamos demonstrar que o rectângulo também comuta, ou seja, que
\compute
k \of g \of f &= t \of s \of i.
\intertext{Calculamos:}
k \of g \of f
&= (k \of g) \of f   \by {assoc.~da~$\of$} \\
&= (t \of j) \of f   \by {comut.~do quad.~direito} \\
&= t \of (j \of f)   \by {assoc.~da~$\of$} \\
&= t \of (s \of i)   \by {comut.~do quad.~esquerdo} \\
&= t \of s \of i.    \by {assoc.~da~$\of$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Products_and_more_constructions 
\section Produtos e demais construções.
%%%{{{ meta 
\label Products_and_more_constructions
%%%}}}

%%{{{ df: fprod 
\definition cross.
%%%{{{ meta 
\label fprod
\defines
    * ~f \times ~g  -- a função-produto das $f,g$
    * função!cross
    * função!produto
    ;;
%%%}}}

Sejam
\math
A \longtoby f C\\
B \longtoby g D
\endmath
Chamamos \dterm{função-produto das $f,g$},
que denotamos por $f \cross g$,
a função
$$
A \times B \longtoby {f\cross g} C \times D
$$
definida pela
$$
(f \cross g)(x,y) = \tup{f(x), g(y)}.
$$
Pronunciamos \utter{$f$ cross $g$}.

%%}}}

%%{{{ x: fprod_commutative_diagram 
\exercise.
%%%{{{ meta 
\label fprod_commutative_diagram
%%%}}}

Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']   \|  A\times B \ar[l, dash, ""]\ar[r, dash, ""]\ar[d, dotted, ""]   \| B \ar[d, "g"]  \\
C                \|  C\times D \ar[l, dash, ""]\ar[r, dash, ""]                     \| D
\endcd
$$

\solution
Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']   \|  A\times B \ar[l, "\outl"]\ar[r, "\outr"]\ar[d, dotted, ""]   \| B \ar[d, "g"]  \\
C                \|  C\times D \ar[l, ""]\ar[r, dash, ""]                         \| D
\endcd
$$


%%}}}

%%{{{ remark: commutative_diagrams_as_puzzles 
\remark Um puzzle.
%%%{{{ meta 
\label commutative_diagrams_as_puzzles
%%%}}}

Vamos fazer um ``rewind'' no momento exatamente antes de
definir nossa função de $A \cross B$ para $C \cross D$.
O diagrama parece como no~\ref[fprod_commutative_diagram],
exceto sem a setinha pontilhada no meio.
E esse é o ``missing piece'' do nosso puzzle.
Procuramos então achar uma \emph{seta} que é \dterm{legal}.
O que significa ``legal'' aqui?
\emph{Uma seta que faz o diagrama comutar!}

%%}}}

%%{{{ x: fprod_practise 
\exercise.
%%%{{{ meta 
\label fprod_pratise
%%%}}}

Para cada uma das expressões seguintes, calcule seu valor quando tiver.
\mathcols 2
(\sin \cross \cos) (\pi)        &= &
(\outl \cross \succ) (5, 6)     &= \\
(\sin \cross \cos) (\pi/2, \pi) &= &
(\idof\nats \cross \succ) (0,1) &= 
\endmathcols
Pode ser que umas delas tem type errors, e logo nenhum valor.

%%}}}

%%{{{ x: fprod_is_total 
\exercise.
%%%{{{ meta 
\label fprod_is_total
%%%}}}

O operador binário $(\dhole\cross\dhole)$ nas funções
que definimos no~\ref[fprod], é um operador total?

\solution
Sim.
A gente não necessitou nenhuma propriedade especial
sobre nossas funções $f,g$ na definição.

%%}}}

%%{{{ df: fpair 
\definition pairing.
%%%{{{ meta 
\label fpair
\defines
    * \fpair {~f} {~g}  -- a função-par $f$ ``pair'' $g$
    * função!par
    ;;
%%%}}}

Sejam
$$
A \longfromby f D \longtoby g B
$$
Chamamos \dterm{função-pareamento da $f$ ``pairing'' $g$},
que denotamos por $\fpair f g$,
a função
$$
D \longtoby {\fpair f g} A\times B
$$
definida pela
$$
\fpair f g (x) = \tup{f(x), g(x)}.
$$

%%}}}

%%{{{ x: fpair_commutative_diagram 
\exercise.
%%%{{{ meta 
\label fpair_commutative_diagram
%%%}}}

Bote nomes e direcções onde faltam e demonstre que o diagrama comuta:
$$
\cdopt{sep=2cm}
A \| A\times B \ar[l, dash, ""]\ar[r, dash, ""] \| B \\
  \| D\ar[u, dotted, ""]\ar[ul, "f"]\ar[ur, "g"']
\endcd
$$

%%}}}

%%{{{ Q: Can you define the pointwise operation function? 
\question.
%%%{{{ meta 
%%%}}}

Dadas $f,g : A \to B$, e sabendo que no $B$ é definida uma operação
binária $\ast : B^2 \to B$, qual função interessante tu podes definir
de $A$ para $B$?  Qual notação tu gostaria de usar pra ela?

%%}}}

\spoiler

%%{{{ df: pointwise_operation 
\definition pointwise.
%%%{{{ meta 
\label pointwise_operation
\indexes
    * função!pointwise operação    see: pointwise
    ;;
\defines
    * pointwise!operação
    ;;
%%%}}}

Sejam $A,B$ conjuntos e $\ast$ uma operação binária no $B$.
Dadas funções $f,g : A \to B$, definimos a função
$f \ast g : A \to B$
pela
$$
(f \ast g)(x) = f(x) \ast g(x) , \qquad \text{para todo $x\in A$}.
$$
Chamamos a $(\dhole \ast \dhole)$ a \dterm{operação pointwise}
da $\ast$ no conjunto $\funs A B$.

%%}}}

%%{{{ pointwise_operation_outside_the_forest 
\note Uma outra maneira de se inspirar.
%%%{{{ meta 
\label pointwise_operation_outside_the_forest
%%%}}}

Se tu realmente tentou responder na pergunta acima, provavelmente
tu chegou nessa mesma definição.  Uma maneira de chegar nela é
realmente ``entrar na floresta'', e começar brincar com as árvores,
ate achar o que tu ta procurando.
Uma outra abordagem seria observar a floresta de longe, por fora.
Desenhar as setas que tu tens, e ver o que tu podes fazer
interessante com elas; pra onde elas te guiam.
Nesse caso temos $f, g : A \to B$, e também a $\ast : B^2 \to B$.
Nosso desafio é definir uma função \emph{interessante}
do tipo $A \to B$.\foot
Claramente não é o desafio mais claro que tu já viu na vida,
mas isso faz parte do próprio desafio!
\toof
Desenhamos então:
$$
\phantom{A \longtoby ? {}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B.
$$
O que \emph{interessante} podemos definir agora?
Com certeza uma composição tem chances boas de ser interessante,
só que aqui a
$$
\ast \of \pfprod f g : A \cross A \longto B
$$
não tem o tipo desejado $A\to B$.
Agora podemos desistir dessa abordagem e entrar na floresta mesmo
para brincar com as árvores; \emph{ou podemos perceber que talvez
falta apenas uma setinha para nos ajudar}.
Se a gente tivesse uma setinha interessante assim:
$$
A \alert{{}\longtoby ?{}} A \cross A \longtoby {f \cross g} B \cross B \longtoby {\ast} B,
$$
a gente teria um candidato ótimo para algo interessante, pois
assim a composição de todas essas setinhas tem o tipo desejado.
Basta definir uma função interessante então de $A$ para $A\cross A$
e assim ganhar a
$$
A \xlongtoby {\ast \of \pfprod f g \of \alert ?} B.
$$

%%}}}

%%{{{ x: discover_diagonalizer 
\exercise.
%%%{{{ meta 
\label discover_diagonalizer
%%%}}}

Dado conjunto $A$, define uma função interessante de $A$ para $A \cross A$.
Começa descrevendo sua alma com um $\lamsym$; consegue defini-la sem
descrever explicitamente o seu comportamento?

\solution
Usando $\lamsym$, a função que procuramos é a seguinte:
$$
A \longtoby {\lam x {\tup{x,x}}} A \cross A.
$$
Essa função é a $\fpair {\idof A} {\idof A}$.

%%}}}

%%{{{ x: pointwise_operation_two_paths_to_solution_same_or_not 
\exercise.
%%%{{{ meta 
\label pointwise_operation_two_paths_to_solution_same_or_not
%%%}}}

Verifique se as duas funções definidas na~\ref[pointwise_operation]
e no fim do~\ref[pointwise_operation_outside_the_forest]
(com o~\ref[discover_diagonalizer]) são as mesmas.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A função que tu definiu no~\ref[discover_diagonalizer] é muito útil
e freqüentemente usada e sim, tem seu próprio nome e sua própria notação:

%%}}}

%%{{{ df: diagonal_function 
\definition Função diagonal.
%%%{{{ meta 
\label diagonal_function
\defines
    * \diagdom {~A}  -- a função diagonal do $A$
    * \diag  -- a função diagonal do conjunto implicito pelo contexto
    * função!diagonal
    ;;
%%%}}}

Seja $A$ conjunto.
Definimos sua \dterm{função diagonal} $\diagdom A : A \to A \times A$
pela
$$
\diagdom A (x) = \tup{x,x}.
$$
Equivalentemente:
$$
\diagdom A \defeq \fpair {\idof A} {\idof A}.
$$
Quando o conjunto $A$ é implícito pelo contexto escrevemos apenas $\diag$.

%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Com o que já temos na nossa disposição podemos definir umas funções
interessantes apenas usando composições, e \emph{diretamente} definindo
a função (sem utilizar um ponto do seu domínio nem a λ-notação).
Vamos investigar isso agora no~\ref[Pointfree_style].

%%}}}

\endsection
%%}}}

%%{{{ prob: funion 
\problem união de funções.
%%%{{{ meta 
\label funion
%%%}}}

Sejam $f : A \to C$ e $g : B \to D$.
Queremos definir a $f\union g : A\union B \to C\union D$,
consultando as $f$ e $g$, numa maneira parecida com aquela da
definição de $f\cross g$ (\reftag[fprod]).
Uma definição razoável deve fazer o diagrama seguinte comutar:
$$
\cdopt{sep=2cm}
A \ar[d, "f"']\ar[r, hook] \| A\union B \ar[d, dashed, ""] \| B \ar[l,hook']\ar[d, "g"] \\
C \ar[r,hook]              \| C\union D                    \| D \ar[l,hook']
\endcd
$$
Explique quais são as condições necessárias para definir
a $f\union g$, e defina-a.

\solution
Chame as $f$ e $g$ \dterm{compatíveis} sse:
$$
\text{para todo $x\in\dom f \inter \dom g$, $f(x) = g(x)$}.
$$
Agora dadas compatíveis $f : A \to C$ e $g : B \to D$,
definimos a $f \union g : A\union B \to C\union D$ pela
$$
(f \union g)(x) =
\knuthcases {
f(x), & se $x \in A$ \cr
g(x), & se $x \in B$.
}
$$
Equivalentemente, podemos definir a $f\union g$ definindo seu gráfico:
$$
\graph (f\union g) \defeq \graph f \union \graph g.
$$
Observe que nas duas maneiras precisamos a condição de
compatibilidade para a $f\union g$ ser bem-definida.
\crproofalt{Resolução alternativa:}
Usamos a mesma definição mas exigimos que os $A,C$ são disjuntos.
A primeira resolução consegue definir a $f \union g$ em mais casos
que essa mas, por outro lado, essa seria aceitável também e é mais
simples e \dq{arrumada}.

%%}}}

%%{{{ Coproduct; disjoint union 
\section Coproduto; união disjunta.
%%%{{{ meta 
\label Coproduct
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos voltar no~\ref[funion].
(Se tu não resolveu ainda, volte a resolver agora, antes de continuar.)
Definimos o $f \union g$ a partir de duas funções $f$ e $g$ mas a
situação não foi tão agradável como esperamos (cf.~$f \cross g$):
necessitamos restrições adicionais.

%%}}}

%%{{{ Q: Whose fault is it? 
\question.
%%%{{{ meta 
%%%}}}

Quem é o culpado?

%%}}}

\spoiler

%%{{{ A: The union! 
\note Resposta.
%%%{{{ meta 
%%%}}}

A união!
O conjunto que $\union$ construiu, ο $A\union B$, não é útil aqui.
Nem se compara com o $A \cross B$, em questão de
utilidade e elegância.
Além disso---caso que os conjuntos são finitos por enquanto---%
com o produto tivemos a lei bacana
$$
\align
\card{A \cross B} &= \card A \ntimes \card B.
\intertext{%
A união não é tão legal, pois não consegue garantir igualdade
mas apenas
}
\card{A \union B} &\leq \card A + \card B.
\endalign
$$
Decepção de novo!
Será que podemos descobrir um outro operador binário
que comportaria numa maneira tão legal como o~$\cross$?

%%}}}

%%{{{ constructing the coproduct 
\note Contruindo o coproduto.
%%%{{{ meta 
%%%}}}

$$
\tikzpicture
\tikzi disjunion0;
\endtikzpicture
$$
unindo:
$$
\tikzpicture
\tikzi disjunion1;
\endtikzpicture
$$
Em vez disso, vamos criar cópias $A',B'$ dos $A,B$ numa maneira
que garanta que os $A',B'$ são disjuntos.
Por exemplo, pintamos todos os membros de $A$ azuis e de $B$ vermelhos:\foot
Leitores sem acesso nessas cores neste texto vão ficar confusos aqui;
mas paciência pois uma definição formal tá chegando já já; uma que
não necessita telas e impressoras (e olhos?)~chiques.
\toof
$$
\tikzpicture
\tikzi disjunion2;
\endtikzpicture
$$
Os conjuntos agora são disjuntos
(observe que $\aB 4 \neq \aR 4$ e $\aB5 \neq \aR 5$)
então vamos simplesmente uni-los:
$$
\tikzpicture
\tikzi disjunion3;
\endtikzpicture
$$
e nesse caso vamos tomar $A \disjunion B \asseq A' \union B'$.
Observe que esse processo descrito aqui garanta mesmo que
\compute
\card{A \disjunion B}
&= \card{A' \union B'}      \by {def.~$A\disjunion B$} \\
&= \card {A'} + \card {B'}  \by {$A',B'$ disjuntos} \\
&= \card A + \card B.       \by {$\card A = \card A'$ e $\card B = \card B'$} \\
\endcompute
Parece então que conseguimos definir o operador de união disjunta.

%%}}}

%%{{{ the or one? 
\note ``O'' ou ``um''?.
%%%{{{ meta 
%%%}}}

A descripção acima envolve um passo bem ambiguo:
a \emph{contruição das cópias} $A', B'$.
Com certeza existem muitas maneiras diferentes de conseguir essas
cópias e a gente so descreveu uma---inclusive nem formalmente, mas
dá pra fazer (\ref[formal_equivalent_of_painting]).
Precisamos escolher uma pra realmente definir nosso operador.

%%}}}

%%{{{ x: formal_equivalent_of_painting 
\exercise.
%%%{{{ meta 
\label formal_equivalent_of_painting
%%%}}}

Ache algo matematicamente formal que podes usar em vez do informal
<<pintar os membros do $A$ de azul e do $B$ de vermelho>>.

\solution
Em vez de cores, tagamos cada membro de $A$ com um $0$ e cada
membro de $B$ com um $1$:
$$
\alignat2
A' &\asseq \set{0} \cross A = \setst {(0,a)} {a \in A} &
B' &\asseq \set{1} \cross B = \setst {(1,b)} {b \in B}.
\endalignat
$$

%%}}}

%%{{{ df: disjunion_aka_coproduct 
\definition união disjunta ou coproduto.
%%%{{{ meta 
\label disjunion_aka_coproduct
\defines
    * ~A \coprod ~B     -- o coproduto de $A$ e $B$
    * ~A \disjunion ~B  -- a união disjunta de $A$ e $B$
    * coproduto
    * união disjunta
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Definimos o \dterm{coproduto}
$$
A \coprod B \defeq \paren{\set{0} \cross A} \union \paren{\set{1} \cross B}.
$$
Generalizmos para qualquer família indexada $\famil A i {\cal I}$:
$$
\tsize\Coprod_i A_i \defeq \Union_i \paren{\set{i} \cross A_i}.
$$
Também usamos o termo \dterm{união disjunta};
e a notações correspondente $A \dunion B$ para o caso binário;
e a $\Dunion_i A_i$ para famílias.

%%}}}

%%{{{ remark: sum type notation teaser 
\remark.
%%%{{{ meta 
%%%}}}

No contexto de teoria dos tipos (\ref[Type_theory]) o tipo correspondente
é chamado \dterm{sum type} e usamos as notações $A \plus B$ e $\Sum_i A_i$.

%%}}}

%%{{{ choosers_coproduct 
\note Nível coração: escolhedores.
%%%{{{ meta 
\defines
    * escolhedor!coproduto
    ;;
%%%}}}

Seja $\famil A i {\cal I}$ família de conjuntos.
Lembre-se que enxergamos (\reftag[choosers_product]) cada membro
do produto $\Prod_i A_i$ como um escolhedor:
ele escolhe exatamente um membro \emph{de cada $A_i$}.
Podemos enxergar um membro do coproduto como um escolhedor
também.
Mas antes disso, vamos ver se podemos enxergar o arbitrário
membro do $\Union_i A_i$ como escolhedor.
Sim: o $a\in\Union_i A_i$ representa o escolhedor que escolha
o $a$, entre todos os membros que pertencem a qualquer um dos $A_i$'s.
No coproduto a situação é mais informativa e interessante:
o arbitrário membro do $\Coprod_i A_i$ parece assim:
$(j, a)$, onde $j\in\cal I$ e $a \in A_j$.
Ou seja, parece uma escolha rotulada, que selecionou um membro do
conjunto com seu rótulo e nada mais.
Vamos comparar três escolhedores $P,C,U$ então:
$$
\xalignat3
\vphantom{\Coprod_i}
P &\tsize\in \Prod_i A_i &
C &\tsize\in \Coprod_i A_i &
U &\tsize\in \Union_i A_i.
\endxalignat
$$
Podemos perguntar ao $P$:
\dialogue
\say Qual foi tua escolha para o $i\in\cal I$?
\say Do $A_i$ escolhi o $u \in A_i$.
\say E para o $j\in\cal I$?
\say Do $A_j$ escolhi o $v \in A_j$.
\say E para o $k\in\cal I$?
\say Do $A_k$ escolhi o $w \in A_k$.
\enddialogue
etc., e vamos ter uma resposta para cada um dos $i$'s.
Ao $C$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$ por dentro do $w$-esimo: $x \in A_w$.
\enddialogue
E ao $U$ perguntamos:
\dialogue
\say Quem tu escolheu?
\say Escolhi o $x$.
\say Donde?
\say Como assim?
\say Onde tu achou esse $x$, em qual dos $A_i$'s?
\say Sei-lá!  Foi num deles.  Não lembro.  Não quero dizer.
\enddialogue

%%}}}

%%{{{ x: fpair_for_union_and_coprod 
\exercise.
%%%{{{ meta 
\label fpair_for_union_and_coprod
%%%}}}

Imite a idéia da construcção do $\fpair f g$ (\ref[fpair]) que baseamos no
$\cross$ para definir duas novas construcções parecidas:
uma baseada no $\union$,
e outra no $\coprod$.
Qual das duas parece comportar melhor?
(Nossa referência de comportamento aqui é a construcção baseada no $\cross$.)

%%}}}

%%{{{ x: product_vs_coproduct_diagrams 
\exercise.
%%%{{{ meta 
\label product_vs_coproduct_diagrams
%%%}}}

O que tu percebes sobre os diagramas comutativos
do $\cross$ (\ref[fpair]) e do $\coprod$ (que tu desenhou
no~\ref[fpair_for_union_and_coprod])?

\hint
Olha nas setinhas.

\solution
Podemos obter um diagrama a partir do outro simplesmente
trocando a direcção de cada uma das suas setas.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: how_many_idempotents_on_AtoA_for_A_finite 
\problem.
%%%{{{ meta 
\label how_many_idempotents_on_AtoA_for_A_finite
%%%}}}

Generalize o~\ref[how_many_idempotents_on_AtoA_for_A_triset] para
um arbitrário conjunto finito $A$.

\hint
Seja $n = \card A$.

%%}}}

\endproblems
%%}}}

% PARTIAL FUNCTIONS, FIXPOINTS, RECURSIVE DEFS

%%{{{ Partial_functions 
\section Funções parciais.
%%%{{{ meta 
\label Partial_functions
%%%}}}

%%{{{ intro 
\secintro
A restricção que uma função $f : A \to B$ precisa ser \emph{totalmente}
definida no $A$, não nos permite considerer naturalmente situações onde
um certo programa, por exemplo, retorna valores para certas entradas
aceitáveis, e para as outras não:
talvez ele fica num \emph{loop infinito}; ou ele faz a máquina explodir;
ou simplesmente não termina com uma saída---não importa o porquê.
Definimos então o conceito de \emph{função parcial}, que é exatamente
isso: funções que para certas entradas aceitáveis delas, possivelmente
\dterm{divergem}.
%%}}}

%%{{{ df: partial_function 
\definition.
%%%{{{ meta 
\label partial_function
\defines
    * função!parcial
    * função!convergir
    * função!divergir
    * \pars {~A} {~B}      -- o conjunto das funções parciais de $A$ para $B$
    * ~f : ~A \parto ~B    -- $f$ é uma função parcial de $A$ para $B$
    * \diverges {~f(~x)}   -- $f$ diverge no $x$
    * \converges {~f(~x)}  -- $f$ converge no $x$
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos a $f$ uma \dterm{função parcial} de $A$ para $B$ sse:
$$
\text{para todo $x\in A$, se $f(x)$ é definido, então $f(x) \in B$.}
$$
Nesse caso, chamamos \dterm{domínio de convergência} o conjunto
$$
\domain f \defeq \setstt {x \in A} {$f(x)$ é definido}
$$
e \dterm{codomínio} o $B$ mesmo.
Preferimos usar os sinônimos \dterm{source} e \dterm{target} para
o $A$ e $B$ para não ter o conflito entre domínio e domínio de convergência,
escrevendo $\src f$ e $\tgt f$ respectivamente.
\eop
Naturalmente não podemos usar o símbolo $f x$ em expressões matemáticas
quando o $x \notin \domain f$, já que $f x$ é indefinido nesse caso.
Mesmo assim, abrimos uma exceção, introduzindo a notação
$$
\diverges{f\app x} \defiff x \in A \mland x \notin \domain f
$$
que lemos assim: $f$ \dterm{diverge} no $x$.
Dizemos que $f$ \dterm {converge} no $x$, e escrevemos $\converges{f \app x}$
quando $x \in \domain f$.
\eop
Escrevemos $f : A \parto B$ para \wq{$f$ é uma função parcial de $A$ para $B$}.
Naturalmente denotamos o conjunto de todas as funções parciais de $A$ para $B$ por
$$
(A \parto B) \defeq \setst f {f : A \parto B}.
$$

%%}}}

%%{{{ x: size_of_pars 
\exercise.
%%%{{{ meta 
\label size_of_pars
%%%}}}

Se $A,B$ são finitos,
qual a cardinalidade do $\pars A B$?

\hint
Já calculou como achar a cardinalidade de $\funs X Y$ para
quaisquer finitos $X,Y$.
Então \emph{hackeia!}

\hint
Considere um objeto $\bottom$ fora do $B$.

%%}}}

%%{{{ remark: total vs partial: default 
\remark.
%%%{{{ meta 
%%%}}}

Com essas definições cada função total é uma função parcial.
Escrevemos esse \wq{total} quando queremos enfatizar, mas normalmente
\wq{função} sem o adjectivo \wq{parcial} significa \wq{função total}.
Claramente, quando trabalhamos principalmente com funções parciais,
seguimos a convenção oposta.

%%}}}

%%{{{ x: composition_of_partial_functions 
\exercise.
%%%{{{ meta 
\label composition_of_partial_functions
\defines
    * composição!de função parcial   see: função
    * função!parcial!composição
    ;;
%%%}}}

Sejam $A \partoby f B \partoby g C$.
Como definarias a composição $g \of f$?

%%}}}

%%{{{ remark: partial function conditions 
\remark Condições.
%%%{{{ meta 
%%%}}}

Encontramos então aqui o que acontece se apagar a primeira das
condições~\reftag[functionhood_conditions]:
\tlist: \notags
\li: \strikeout{(1)~totalidade};
\li: (2)~determinabilidade.
\endtlist
e ficar só com a (2).
No~\ref[implement_nondeterministic_functions] implementarás funções
\dterm{não-deterministicas}, onde apagamos a (2), ficando apenas com a totalidade.
E se apagar as duas?
Esse conceito podemos facilmente implementar assim que
conhecer melhor relações (\ref[Relations]).

%%}}}

\endsection
%%}}}

%%{{{ Fixpoints 
\section Fixpoints.
%%%{{{ meta 
\label Fixpoints
%%%}}}

%%{{{ df: fixpoint 
\definition Fixpoint.
%%%{{{ meta 
\label fixpoint
\indexes
    * função!fixpoint    see: fixpoint
    ;;
\defines
    * fixpoint
    ;;
%%%}}}

Seja $f : A \to A$ um endomapa num conjunto $A$.
Chamamos \dterm{fixpoint} da $f$ qualquer $x\in A$ tal que
$f(x) = x$.
Com palavras de rua,
$$
\text{$x$ é um fixpoint de $f$}
\heartiff
\text{$f$ deixa $x$ em paz}.
$$

%%}}}

%%{{{ eg: fixpoints_of_identities 
\example.
%%%{{{ meta 
\label fixpoints_of_identities
%%%}}}

Para qualquer conjunto $A$, todos os seus membros são
pontos fixos da $\idof A$.

%%}}}

%%{{{ noneg: succ and mother 
\nonexample.
%%%{{{ meta 
%%%}}}

No outro extremo, nem a $\succ : \nats\to\nats$ possui fixpoints,
nem a $\mother : \Person \to \Person$---o que seria
um fixpoint da $\mother$?

%%}}}

%%{{{ eg: fixpoints_of_sin 
\example trigonometria.
%%%{{{ meta 
\label fixpoints_of_sin
%%%}}}

$0$ é um fixpoint da $\sin$---tem outros?  E a $\cos$?

%%}}}

%%{{{ eg: fixpoints_of_square 
\example.
%%%{{{ meta 
\label fixpoints_of_square
%%%}}}

A $\square = \lam x {x^2} : \ints\to\ints$
possui dois fixpoints: o $0$ e o $1$.

%%}}}

%%{{{ remark: how fixpoints look like internally 
\remark.
%%%{{{ meta 
%%%}}}

Olhando para o diagrama interno dum endomapa (\reftag[diagram_of_endomap])
os fixpoints são os ``redemoinhos''
$
\tikzpicture[>=stealth, scale=0.5]
\node (dot-h) at (0 , 0.2 ) {};
\node (dot) at (0 , 0   ) {$\bullet$};
\draw[->] (dot-h) arc (10:290:0.25);
\endtikzpicture
$.

%%}}}

%%{{{ x: exact_number_of_fixpoints_challenge 
\exercise.
%%%{{{ meta 
\label exact_number_of_fixpoints_challenge
%%%}}}

Seja $d\in\nats$.
Defina uma função $f : \nats\to\nats$ com exatamente
$d$ fixpoints.

\hint
Isso é mais um exercício pra ver se tu consegue definir
funções do que em fixpoints.

\solution
Seja $f : \nats \to \nats$
definida pela
$$
f(n) =
\knuthcases {
n,   &se $n\in D$;\cr
n+1, &caso contrário.
}
$$
onde $D \asseq \set{0,\dots,d}$.

%%}}}

%%{{{ teaser: fixpoints_teaser 
\teaser.
%%%{{{ meta 
\label fixpoints_teaser
%%%}}}

OK, eu sei: parece estranho dedicar uma secção só pra isso.
Mas os fixpoints vão fazer um papel importantíssimo depois,
e queria destacá-los desde já.
(Mentira: não um.  Muitos!)

%%}}}

\TODO Adicionar refs para secções específicas.

\endsection
%%}}}

%%{{{ Recursive_definitions_as_systems 
\section Definições recursivas.
%%%{{{ meta 
\label Recursive_definitions_as_systems
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já encontramos várias definições recursivas.
Agora vamos analisar com que precisamos tomar cuidado para garantir
que nossas ``funções'' realmente são funções bem-definidas.
Vamos começar lembrando como exemplo duas funções recursivas famosas demais.

%%}}}

%%{{{ eg: fact_and_fib_recursive_eg 
\example.
%%%{{{ meta 
\label fact_and_fib_recursive_eg
%%%}}}

Sejam $a:\nats\to\nats$ definida pelas
$$
\align
a(0) &= 1\\
a(n) &= n \ntimes a(n-1), \quad\text{para todo $n>0$};
\intertext{e $b:\nats\to\nats$ definida pelas}
b(0) &= 1\\
b(1) &= 1\\
b(n) &= b(n-1) + b(n-2), \quad\text{para todo $n>1$}.
\endalign
$$
Muitas vezes deixamos as frases ``para todo $n>0$'' como
implícitas pelo contexto---mas entenda que elas precisam estar lá,
e \emph{estão} lá mesmo quando escolhemos omiti-las.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora, assuma que tu aceita ambas as $a,b : \nats\to\nats$ do
exemplo assima como funções \emph{bem-definidas}, e continue lendo.

%%}}}

%%{{{ mutual_recursion 
\note Recursão mutual.
%%%{{{ meta 
\label mutual_recursion
%%%}}}

Podemos definir duas ou mais funções, cada uma chamando recursivamente
outras, tomando certos cuidados como sempre para garantir que realmente
todas as funções vão ser definidas mesmo para todas as entradas
aceitas pelos domínios delas.

%%}}}

%%{{{ eg: mutual_recursion_even_odd 
\example.
%%%{{{ meta 
\label mutual_recursion_even_odd
%%%}}}

Vamos definir as funções $\even,\odd:\nats\to\set{0,1}$ pelas
$$
\xalignat2
\even(0)   &= 1       & \odd(0)   &= 0 \\
\even(n+1) &= \odd(n) & \odd(n+1) &= \even(n)
\endxalignat
$$
Calculamos, por exemplo:
$$
\align
\even(3) &
= \odd(2)
= \even(1)
= \odd(0)
= 0 \\
odd(3) &
= \even(2)
= \odd(1)
= \even(0)
= 1
\endalign
$$

%%}}}

%%{{{ Safe recursion 
\note Recursão segura.
%%%{{{ meta 
%%%}}}

Na maioria das vezes que definimos funções recursivamente
existe ``algo''---muitas vezes esse ``algo'' é o próprio
argumento da função (como no~\ref[fact_and_fib_recursive_eg])
mas não sempre---que com cada ``chamada recursiva''
da função fica menor e menor, até cair num valor que garanta
uma ``saída da recursão''.
(Essa descripção é bem vaga sim.)

%%}}}

%%{{{ eg: recursion_with_powers_of_two 
\example.
%%%{{{ meta 
\label recursion_with_powers_of_two
%%%}}}

Seja $p : \nats\to\nats$ a função definida pela:
$$
p(x) =
\knuthcases {
\log_2(x), & se $x$ é uma potência de $2$;\cr
p(x+1), & se não.
}
$$
Aqui nas chamadas recursivas não é o próprio argumento que é
``cada vez menor''---pelo contrário: as chamadas recursivas
estão sendo cada vez com argumento maior!
Mesmo assim, a recursão ``sempre termina'', e a $f$ realmente
é bem-definida.
Calculamos como exemplo uns valores:
$$
\align
p(0) &= p(1) = \log_2(1) = 0 \\
p(4) &= \log_2(4) = 2 \\
p(5) &= p(6) = p(7) = p(8) = \log_2(8) = 3 \\
p(1020) &= p(1021) = p(1022) = p(1023) = p(1024) = \log_2(1024) = 10.
\endalign
$$

%%}}}

%%{{{ x: find invariant 
\exercise.
%%%{{{ meta 
%%%}}}

Ache um ``algo'' que fica cada vez menor com cada chamada recursiva
da $p$ do~\ref[recursion_with_powers_of_two].

\hint
Uma ``distância'' está sendo cada vez menor.  Qual?

\solution
Com cada chamada com entrada $x$, o número $b - x$ é cada vez menor,
onde
$$
b = \min \setst {2^n} {x \leq 2^n, \ n\in\nats}.
$$

%%}}}

%%{{{ Dangerous recursion 
\note Recursão perigosa.
%%%{{{ meta 
%%%}}}

Não é cada equação recursiva que realmente defina uma função!
Vamos ver agora uns exemplos que mostram exatamente isso.

%%}}}

%%{{{ eg: dangerous_recursion_f 
\example.
%%%{{{ meta 
\label dangerous_recursion_f
%%%}}}

Seja $f : \nats\to\nats$ a função definida pela
$$
f(n) = f(n),
\quad\text{para todo $n\in\nats$}.
$$
É óbvio que isso não \emph{determina} uma função.
Mas por quê?

%%}}}

%%{{{ eg: dangerous_recursion_g 
\example.
%%%{{{ meta 
\label dangerous_recursion_g
%%%}}}

Seja $g : \nats\to\nats$ a função definida pela
$$
\align
g(0) &= 1 \\
g(n) &= g(n)+1, \quad\text{para todo $n>0$}.
\endalign
$$
Isso também não \emph{determina} uma função.
Por quê?

%%}}}

%%{{{ eg: dangerous_recursion_h 
\example.
%%%{{{ meta 
\label dangerous_recursion_h
%%%}}}

Seja $h : \nats\to\nats$ a função definida pela
$$
h(n) = h(n+1), \quad\text{para todo $n\in\nats$}.
$$
Isso também não \emph{determina} uma função---mas por quê?

%%}}}

%%{{{ x: what_is_the_problem_with_those_recursive_definitions 
\exercise.
%%%{{{ meta 
\label what_is_the_problem_with_those_recursive_definitions
%%%}}}

As perguntas sobre as $f,g,h$ acima não foram rhetóricas!

%%}}}

%%{{{ eg: pre_collatz_safe 
\example.
%%%{{{ meta 
\label pre_collatz_safe
%%%}}}

Considere a função $k : \nats \to \nats$ definida pela recursão
$$
\align
k(0) &= 1\\
k(1) &= 1\\
k(n) &=
\knuthcases {
k(n/2), & se $n$ é potência de $2$\cr
k(n+1), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma função $k : \nats\to\nats$?

%%}}}

%%{{{ eg: pre_collatz_unsafe 
\example.
%%%{{{ meta 
\label pre_collatz_unsafe
%%%}}}

Considere a função $d : \nats \to \nats$ definida pela recursão
$$
\align
d(0) &= 1\\
d(1) &= 1\\
d(n) &=
\knuthcases {
d(n/2), & se $n$ é potência de $2$\cr
d(n+3), & caso contrário
}\quad\text{(para todo $n > 1$)}.
\endalign
$$
Aceitaria isso como uma definição duma função $d : \nats\to\nats$?

%%}}}

%%{{{ x: reply 
\exercise.
%%%{{{ meta 
%%%}}}

Responda nas perguntas dos exemplos acima~(\reftag[pre_collatz_safe]
e~\reftag[pre_collatz_unsafe]).

%%}}}

%%{{{ x: calculate_pre_collatz 
\exercise.
%%%{{{ meta 
\label calculate_pre_collatz
%%%}}}

Usando as $k,d : \nats\to\nats$ dos exemplos \reftag[pre_collatz_safe]
e~\reftag[pre_collatz_safe] acima calcule os:
$$
k(6); \quad
k(9); \quad
d(5); \quad
d(11);\quad
d(6).
$$
(Confira teus resultados com minha dica e minha resolução!)

\hint
Se tu achou valores para todas as expressões,
tu errou (pelo menos uma vez).
Todos eles são definidos exceto um!

\solution
Calculamos:
$$
\align
k(6)  &= k(7) = k(8) = k(4) = k(2) = k(1) = 1 \\
k(9)  &= k(10) = k(11) = k(12) = \dotsb = k(16) = k(8) \dotseq 1 \\
d(5)  &= d(8) = d(4) = d(2) = d(1) = 1 \\
d(11) &= d(14) = d(17) = d(20) = d(23) = d(26) = d(29) = d(32) = d(16) \dotseq 1 \\
d(6)  &= d(9) = d(12) = d(15) = d(18) = d(21) = d(24) = d(27) = d(30) = d(33) = d(36) = \dotsb
\endalign
$$
onde parece que o último cálculo \emph{nunca terminará}.
Deixo você se preocupar com a veracidade dessa afirmação
no~\ref[why_pre_collatz_unsafe_diverges_on_6].

%%}}}

%%{{{ x: k_is_the_constant_one 
\exercise.
%%%{{{ meta 
%%%}}}

Qual é a função $k$ do~\ref[pre_collatz_safe]?
(Tu deves saber um nome dela bem simples.)

\solution
Ela é a função constante do $\nats$ com valor $1$.

%%}}}

%%{{{ eg: collatz_recursive 
\example.
%%%{{{ meta 
\label collatz_recursive
%%%}}}

Considere a função $c : \Nat \to \Nat$ definida pela recursão
\mathcol
c(0) &= 1 \\
c(1) &= 1 \\
c(n) &=
\knuthcases {
c(n/2),  & se $n$ é par\cr
c(3n+1), & caso contrário
}\quad\text{(para $n > 1$)}.
\endmathcol
E a mesma pergunta: aceita?

%%}}}

%%{{{ x: calculate three values 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule os valores $c(8), c(3), c(7)$ da função $c$ acima.

%%}}}

%%{{{ What's going on? 
\note O que tá acontecendo?.
%%%{{{ meta 
\label what_is_going_on_with_recursive_definitions
%%%}}}

Já deve ser claro que apenas escrevendo umas equações que envolvem
a função que queremos definir não é uma maneira segura que garanta
que realmente nossas equações \emph{determinam} (definam) uma função.
Umas vezes deu certo, outras não.
Mas em todos os casos, a ``definição'' da função foi apenas uma
\emph{lista de equações}.\foot
Foi mesmo?
Não exatamente: mas deixe isso para
depois~(\ref[not_exactly_a_list_of_equations]).
\toof
Estamos procurando entender melhor essa situação:
um cara chega com um um bocado de equações como uma suposta definição
recursiva duma função, e a gente da uma olhada nelas, e aceita isso como
definição mesmo;
outro cara chega com \emph{o mesmo tipo de coisa} (um bocado de equações)
e no caso dele a gente falou ``desculpa mas isso não serve como
definição de função''.
O que tá acontecendo?

%%}}}

%%{{{ Do you remember school "math"? 
\note Lembra da ``matemática'' na escola?.
%%%{{{ meta 
%%%}}}

Lembra os \emph{sistemas de equações} em um ou mais
\emph{incógnitos} que tu precisava \emph{resolver}
estudando matemática básica?\foot
Presumo aqui que o leitor já teve contato com esse
tipo de exercícios desde criança; mas caso contrário, espero
que a conversa vai continuar fazendo sentido.
\toof
Por exemplo, um exercício pode pedir para o aluno:
\emph{resolva o sistema} seguinte nos reais ($x\in\reals$):
\system
x^2     &= 64 \\
10 + 2x &= 2 + x
\endsystem
O aluno vai responder que
$$
\text{<<o sistema tem uma resolução única: $x = -8$>>}
$$
e vai ganhar um biscoito.
Esses sistemas são mais comuns em espaços de dimenções superiores
($\reals^2$, $\reals^n$, $\complex^n$, etc.).
Mas no final das contas, qual é o objectivo?
O que significa resolver um sistema deles?
Bem, significa dar uma das seguintes respostas:
\elist i:
\li: O sistema é impossível;
\li: O sistema é possível e indeterminado;
\li: O sistema é possível e determinado;
\endelist
e nos dois últimos casos, queremos descrever todas as resoluções
se for indeterminado, ou achar sua única resolução caso que é determinado.
Uns sistemas no $\reals^2$ por exemplo são os:
$$
\xxalignat4
\text{(A)}&
\lsystemed {
x^2 + y^2 &= 1 \\
y         &= 2x
}&
\text{(B)}&
\lsystemed {
y &= x^2 + 8 \\
x &= y + 1
}&
\text{(C)}&
\lsystemed {
x       &= 2y + 1 \\
3x - 6y &= 3
}&
\text{(D)}&
\lsystemed {
x &= y^2 \\
y &= \sin(x).
}&
\endxxalignat
$$
Aqui o aluno deu umas respostas interessantes.
(A) O sistema é possível mas indeterminado: tem duas resoluções:
$\tupp{x,y} = \tupp{\sqrt3/2, 1/2}$
e
$\tupp{x,y} = \tupp{1/2,\sqrt3/2}$.
(B) O sistema é impossível: nenhum par $\tupp{x,y}\in\reals^2$
satisfaz ambas as equações.
(C) O sistema é possível mas indeterminado: todos os membros do
conjunto
$
\setst {\tupp{t, 2t+1} \in\reals^2} {t\in \reals}
$
satisfazem o sistema (e tem pelo menos dois membros nesse conjunto---na
verdade tem uma infinidade deles).
(D) O sistema é possível e determinado: tem resolução única, o
$\tupp{x,y} = \tupp{0,0}$.

%%}}}

%%{{{ remark: infinite_does_not_mean_all_eg_systems 
\remark.
%%%{{{ meta 
\label infinite_does_not_mean_all_eg_systems
%%%}}}

O fato que um sistema tem uma infinidade de resoluções, não
significa que \emph{todos} os possíveis candidatos são resoluções.
Por exemplo o sistema~(3) acima tem uma infinidade de resoluções,
mas não são todos os membros do $\reals^2$ que servem:
considere o $\tupp{x,y} \asseq \tupp{1,1}$ por exemplo.

%%}}}

%%{{{ Recursive definitions as systems to solve 
\note Definições recursivas como sistemas para resolver.
%%%{{{ meta 
%%%}}}

O que isso tem a ver com as definições recursivas?
No primeiro sistema acima estamos procurando \emph{números reais},
ou seja, estamos procurando determinar o \alert{incógnito}
$\alert x\in\reals$ que consegue satisfazer todas as suas equações.
$$
\align
\systemed {
\alert x^2     &= 64 \\
10 + 2\alert x &= 2 + \alert x
}&
\intertext{%
Podemos pensar então que todos os reais são candidatos consideráveis
aqui, e nosso trabalho é achar quem serve para o sistema (se é possível)
e quem não.
Testando então para o $\alert x\asseq 8$ temos:
}
\systemed {
\alert x^2            &= 64 \\
10 + 2\ntimes\alert x &= 2 + \alert x
}&\quad\leadsto\quad
\systemed {
\alert 8^2            &= 64 \\
10 + 2\ntimes\alert 8 &= 2 + \alert 8
}
\endalign
$$
e assim percebemos que o $8$ \emph{não} serve pois tem pelo menos uma
equação que ele não satisfaz.
E a situação é similar resolvendo sistemas com incógnitos membros
de $\reals^2$ ou $\complex^n$, etc., onde procuramos um par de números
reais no primeiro caso, ou $n$ números complexos no segundo, etc.
Testamos então o $(\sqrt 2, 0)$ nos sistemas
$$
\xxalignat4
\text{(A)}&
\lsystemed {
\alert x^2 + \alert y^2 &= 1 \\
\alert y         &= 2\alert x
}&
\text{(B)}&
\lsystemed {
\alert y &= \alert x^2 + 8 \\
\alert x &= \alert y + 1
}&
\text{(C)}&
\lsystemed {
\alert x       &= 2\alert y + 1 \\
3\alert x - 6\alert y &= 3
}&
\text{(D)}&
\lsystemed {
\alert x &= \alert y^2 \\
\alert y &= \sin(\alert x).
}&
\endxxalignat
$$
etc., etc.
\eop
Agora te convido olhar para todas as definições recursivas que a gente
encontrou aqui com uma maneira similar:
\emph{como sistemas}, onde agora \emph{o incógnito não é um número real
mas uma função no $(\nats\to\nats)$}.

%%}}}

%%{{{ eg: fibs again 
\example.
%%%{{{ meta 
%%%}}}

Considere o sistema que usamos para definir a função $b$
do~\ref[fact_and_fib_recursive_eg].
\system
\alert b(0) &= 0 \\
\alert b(1) &= 1 \\
\alert b(n) &= \alert b(n-1) + \alert b(n-2), \quad\text{para todo $n>1$}.
\endsystem
Agora o incógnito é uma função $b : \nats\to\nats$.
Vamos testar uns candidatos consideráveis:
tome $b \asseq \idof \nats$:
$$
\align
\rsystemed {
\alert{\idof \nats}(0) &= 0\\
\alert{\idof \nats}(1) &= 1\\
\alert{\idof \nats}(n) &= \alert{\idof \nats}(n-1) + \alert{\idof \nats}(n-2)
}
&\iff
\lsystemed {
0 &= 0\\
1 &= 1\\
n &= (n-1) + (n-2),\quad\text{para todo $n>1$}.
}
\intertext{%
Legal!  As duas primeiras linhas do sistema são satisfeitas.
Para a terceira, testando com o $n\asseq 3$ dá certo, pois realmente
$3 = 2 + 1$
mas é muito fácil perceber que essa igualdade não é satisfeita em geral.
Tome $n\asseq 4$ e já temos problema, pois
$4 \neq 3 + 2$.
O candidato $\idof \nats$ então não satisfaz o sistema.
Próximo!
Vamos tentar com $b \asseq \succ$, essa vez divulgando a notação
mais econômica, sem parenteses:
}
\rsystemed {
\alert{\succ}\fa 0 &= 0\\
\alert{\succ}\fa 1 &= 1\\
\alert{\succ}\fa n &= \alert{\succ} \fap {n-1} + \alert{\succ} \fap {n-2}
}
&\iff
\lsystemed {
1   &= 0\\
2   &= 1\\
n+1 &= n + (n-1),\quad\text{para todo $n>1$}.
}
\endalign
$$
Fuen-fuen-fuen!
Bem, então nem a $\idof \nats$ nem a $\succ$ satisfazem esse sistema.

%%}}}

%%{{{ remark: not_exactly_a_list_of_equations 
\remark.
%%%{{{ meta 
\label not_exactly_a_list_of_equations
%%%}}}

No~\ref[what_is_going_on_with_recursive_definitions]
afirmei que cada suposta definição de função foi ``apenas
uma lista de equações''.
São realmente listas de \emph{equações?}
Umas dessas afirmações não são equações não;
pois em vez de ter a forma ``\,${\lthole} = {\lthole}$\,''
elas têm a forma ``\,$\forall n {\lthole}$\,''.
Ou seja, correspondem em proposições universais
(quantificadas universalmente) e não em proposições
(atômicas) de equações.
Mas não seria errado considerar que essas são listas de
equações sim, com o acordo que\dots são listas infinitas!
Pois sim, podemos ver cada uma dessas como um \emph{esquema}
de equações que fornece uma equação para cada escolha de $n\in\nats$.

%%}}}

%%{{{ When a system serves as a definition.
\note Quando um sistema serve para definir.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Quando um sistema cujos incógnitos são números tem resolução
única isso quis dizer que o sistema \emph{determina}
um certo número.  Ou seja, \emph{podemos usar o próprio sistema
para definir um número real} como a resolução dele.
Por exemplo, escrevemos
<<seja $r\in\reals$ \emph{a} resolução do sistema tal>>, etc.
Observe o artigo definido!
Por outro lado, se o sistema tem várias resoluções,
\emph{não pode servir como definição;} mas pelo menos
sabendo que o conjunto das suas resoluções não é vazio
podemos escrever, por exemplo,
<<seja $t\in\reals$ \emph{uma} resolução do sistema tal>>.
E nada muda com sistemas cujos incognitos são funções!
E por que mudaria?  No final das contas é a existência
e unicidade de algo que nos permite defini-lo!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Voltamos agora para o sistema que usamos para definir
as funções $a,b$ do~\ref[fact_and_fib_recursive_eg].

%%}}}

%%{{{ Q: Do you know of a solution to a or b's systems ?
\question.
%%%{{{ meta 
%%%}}}

Tu conhece alguma função que satisfaz o sistema da $a$?
Alguma que satisfaz o sistema da $b$?

%%}}}

\spoiler

%%{{{ A: Common answer 
\blah Resposta comum.
%%%{{{ meta 
%%%}}}

\emph{Possivelmente} o leitor respondeu
\quote
<<Sim:
o factorial para o primeiro, e a função fibonacci para o segundo.>>
\endquote
ou algo similar.
Só que: eu esqueci quais são essas funções.
Pode lembrar pra mim, por exemplo, qual é essa função ``fibonacci''
que tu tá afirmando que é uma resolução do sistema da $b$?
\quote
\wq{Claro.  Vou escrever esse poeminho mágico para dar a sua definição:}
\endquote

%%}}}

%%{{{ df: fibonacci_dangerous_def 
\definition.
%%%{{{ meta 
\label fibonacci_dangerous_def
%%%}}}

Seja $\fib:\nats\to\nats$ definida pelas
$$
\text{(FIB)}\ \lsystemed {
\fib \fa 0 &= 0\\
\fib \fa 1 &= 1\\
\fib \fa n &= \fib\fap {n-1} + \fib\fap {n-2}, \quad\text{para todo $n>1$}.
}
$$
\mistake

%%}}}

%%{{{ Q: Is there a problem? 
\question.
%%%{{{ meta 
%%%}}}

Tem problema?

%%}}}

\spoiler

%%{{{ A: We used fib to justify its own definition!
\blah Resposta.
%%%{{{ meta 
%%%}}}

Usamos a própria coisa que queremos definir (a função fibonacci)
para justificar sua própria definição (ou seja, para argumentar
que o sistema (FIB) tem resolução única)!
(E sobre o factorial seria a mesma coisa.)
Como a $\fib$ foi definida pelas equações recursivas do (FIB),
sua definição \emph{depende da existência e unicidade da
resolução do sistema}, então não podemos usá-la antes
de demonstrar isso!

%%}}}

%%{{{ We can't prove existence yet; assume it and prove uniqueness 
\note.
%%%{{{ meta 
\credits
    * Fibonacci : função
    ;;
\indexes
    * teorema!de recursão
    ;;
%%%}}}

Infelizmente, caro \sayFibonacci, não estamos prontos neste momento
para demonstrar que esse sistema tem \emph{pelo menos} uma resolução!\foot
Mas calma, daqui uns capítulos estaremos!
\toof
Atrás desse fato fica o poderoso
Teorema de Recursão~\reftag[recursion_theorem].
Mas pelo menos deve ser fácil demonstrar que tem \emph{no máximo}
uma resolução:

%%}}}

%%{{{ x: fib_system_has_at_most_one_solution 
\exercise.
%%%{{{ meta 
\label fib_system_has_at_most_one_solution
%%%}}}

Demonstre que se o sistema (FIB) da~\ref[fibonacci_dangerous_def]
tem resolução, então ela é única.

\hint
Por ``fight club'':
suponha que $f,f'$ são resoluções do sistema (FIB);
demonstre que $f=f'$.

\hint
Ou seja, basta demonstrar que para todo $n\in\nats$, $f n = f'n$.

\hint
Indução!

\hint
Vai precisar de duas bases.

\solution
Sejam $f,f'$ resoluções do sistema (FIB).
Vou demonstrar por indução que:
$$
\lforall {n\in \nats} {f n = f'n}.
$$
Vou demonstrar duas bases, ganhando assim 2 hipoteses indutivas.
\crproofpart {Base 0:}
Calculamos:
\compute
f(0)  &= 1 \by {$f$ resolução de (FIB)} \\
f'(0) &= 1 \by {$f'$ resolução de (FIB)} \\
\endcompute
\crproofpart {Base 1:}
Mesma coisa: $f(1) = 1 = f'(1)$.
\crproofpart {Passo indutivo.}
Seja $k\in \nats$ tal que $f,f'$ concordam nos pontos $k-1$ e $k-2$:
$$
\xxalignat4
\text{(H.I.1)} & & f(k-1) &= f'(k-1) & f(k-2) &= f'(k-2). & & \text{(H.I.2)}
\endxxalignat
$$
Preciso demonstrar que elas concordam no ponto $k$ também:
\compute
f(k)
&= f(k-1) + f(k-2)   \by {$f$ resolução de (FIB)} \\
&= f'(k-1) + f'(k-2) \by {(H.I.1) e (H.I.2)} \\
&= f'(k).            \by {$f'$ resolução de (FIB)} \\
\endcompute
Pronto.

%%}}}

%%{{{ x: why_each_of_the_non_definitions_fails 
\exercise.
%%%{{{ meta 
\label why_each_of_the_non_definitions_fails
%%%}}}

Com esse novo ponto de vista, para cada uma
das supostas definições das funções $f,g,h:\nats\to\nats$
(dos exemplos~\reftag[dangerous_recursion_f],
\reftag[dangerous_recursion_g], e~\reftag[dangerous_recursion_h])
responda na pergunta: por que não deu certo?
$$
\xalignat3
(1)~&\lsystemed {
f(n) &= f(n)
}&
(2)~&\lsystemed {
g(0) &= 1 \\
g(n) &= g(n)+1
}&
(3)~&\lsystemed {
h(n) &= h(n+1)
}
\endxalignat
$$
Foi porque o sistema não tem resoluções?
Ou porque tem várias?  Tem infinítas?  Tem todas?

\solution
Sobre a $f$:
toda função $f : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\eop
Sobre a $g$:
nenhuma função $g : \nats\to\nats$ satisfaz essa equação,
então não podemos usá-la como definição!
\eop
Sobre a $h$:
mais que uma função $h : \nats \to \nats$ satisfaz essa equação,
então não podemos usá-la como definição!

%%}}}

%%{{{ x: which_functions_satisfy_the_equations_of_h 
\exercise.
%%%{{{ meta 
\label which_functions_satisfy_the_equations_of_h
%%%}}}

Quais são exatamente as funções que satisfazem a ``definição''
da $h$ acima?

\hint
Suponha que uma $h : \nats\to\nats$ satisfaz essa
definição, e suponha que seu valor $h(5) = v$
para algum $v\in\nats$.  O que podes concluir
sobre os valores da $h$ para suas outra entradas?

\solution
Todas as funções constantes.

%%}}}

%%{{{ x: why_recursive_collatz_does_not_define_a_function 
\exercise.
%%%{{{ meta 
\label why_recursive_collatz_does_not_define_a_function
%%%}}}

Qual o problema com a definição da função $c$ do~\ref[collatz_recursive]?

\hint
Por que termina a recursão para toda entrada?

\solution
Não sabemos se ela satisfaz a totalidade de função, ou seja,
se ela é realmente definida em todo o seu domínio.
Ate agora, ninguém sabe dizer!
Essa é exatamente a conjectura de
Collatz{\Collatz[conjectura]}~(\ref[collatz_conjecture]).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixamos esse assunto por enquanto (até o~\ref[Recursion_induction]),
supondo que temos já um entendimento de como definições recursivas
funcionam.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: implement_partial_functions 
\problem Implementação: funções parciais.
%%%{{{ meta 
\label implement_partial_functions
\defines
    * função!partial
    ;;
%%%}}}

Pense numa maneira de \emph{implementar} o tipo das
\dterm{funções parciais} (\ref[Partial_functions])
usando conceitos (tipos) que encontramos até agora:
conjuntos, tuplas, seqüências, famílias indexadas, funções, etc.
\eop
Para implementar um conceito não basta apenas definir o que são os
objetos desse tipo em termos de já conhecidos.
Precisamos implementar também a interface desejada, em termos de
operações e relações que já temos em nossa disposição.

\hint
Cada função parcial $f : A \parto B$ pode ser representada
como uma função total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Uma idéia seria adicionar no $B$ um objeto ``fresco'' para representar
a falta de valor; outra idéia seria tomar como $B'$ um subconjunto do $\pset B$.
Qual?

\hint
A primeira idéia não precisa de mais dicas.
Sobre a segunda:
$$
B' \asseq \setst {X \subset B} {\card X \leq 1}.
$$

%%}}}

%%{{{ prob: implement_nondeterministic_functions 
\problem Implementação: funções não-determinísticas.
%%%{{{ meta 
\label implement_nondeterministic_functions
\defines
    * função!não-determinística
    ;;
%%%}}}

Na~\ref[Partial_functions] definimos um conceito mais geral de
``função'':
as \emph{funções parciais}, onde apagamos a primeira das
condições~\reftag[functionhood_conditions]:
\tlist: \notags
\li: \strikeout{(1)~totalidade};
\li: (2)~determinabilidade.
\endtlist
Neste problema, encontramos \dterm{funções não-determinísticas}, ou seja,
``funções'' que não respeitam necessariamente a determinabilidade;
apenas a totalidade.  Ou seja, agora apagamos a outra condição:
\tlist: \notags
\li: (1)~totalidade;
\li: \strikeout{(2)~determinabilidade}.
\endtlist
O objectivo desse problema é \emph{implementar o tipo de função não-determinística}.
\eop
Como definarias a composição $g \cdot f$ de duas funções não-determinísticas?
Use a notação $f : A \ndeto B$ para <<$f$ é uma função não-determinística
de $A$ para $B$>>.
Que mais tu poderias fazer para tua implementação ser uma implementação boa?

\solution
Podemos representar a $f : A \ndeto B$ pela função
$\bar f : A \to \pset B\setminus\set{\emptyset}$ definida pela
$$
\bar f(x) = \setst {y\in B} {x\mapstoby f y}.
$$
Sejam~$f : A \ndeto B$ e~$g : B \ndeto C$ funções não-determinísticas.
Logo temos $\bar f : A \to \pset B\setminus\set{\emptyset}$
e          $\bar g : B \to \pset C\setminus\set{\emptyset}$.
Definimos sua composição
$g\cdot f : A \ndeto C$ pela
$$
(\overline{g\cdot f})(x) = \Union \img {\bar g} {\bar f (x)}.
$$
O que mais seria legal definir e mostrar para nossa implementação?
Bem, seria bom definir pelo menos a identidade não-determinística
$id_A : A \ndeto A$, e investigar se as leis que demonstramos sobre
o caso de funções que conectam composição e identidades estão válidas
para nossas funções não-determinísticas também.

%%}}}

%%{{{ prob: fixpoints_of_different_square 
\problem.
%%%{{{ meta 
\label fixpoints_of_different_square
%%%}}}

Tem como mudar o $\ints$ do~\ref[fixpoints_of_square] para outro
conjunto $X$ de números, tal que tua $\square : X \to X$ terá mais
que dois fixpoints?

\hint
Tem sim.

\hint
Esqueceu o~\ref[The_integers]?

\hint
Use um dos $\intsmod n$'s.

\solution
A $\square : \intsmod 6 \to \intsmod 6$, por exemplo, tem quatro fixpoints: $0,1,3,4$.

%%}}}

%%{{{ prob: fixpoint_iff_iterations 
\problem.
%%%{{{ meta 
\label fixpoint_iff_iterations
%%%}}}

Seja $f : A\to A$.
Demonstre a afirmação:
$$
\text{$x$ é um fixpoint da $f$}
\iff
\text{para todo $n\in\nats$, $x$ é um fixpoint da $f^n$}.
$$

\hint
A {\rldir} é muito fácil; para a {\lrdir} use indução.

\solution
\proofpart {\lrdir}:
Suponha $x$ é um fixpoint da $f$.
Vamos demonstrar o que precisamos por indução no $n$.
\proofpart {Base:}
Calculamos:
\compute
f^0 (x)
&= 1_A (x)  \by {pela def.~da $f^0$} \\
&= x        \by {pela def.~da $1_A$} \\
\endcompute
e logo $x$ é um fixpoint da $f^0$.
\proofpart {Passo indutivo:}
Suponha $k\in\nats$ tal que $x$ é um fixpoint da $f^k$ (H.I.).
Calculamos:
\compute
f^{k+1}(x)
&= (f \of f^k)(x)   \by {pela def.~de $f^{k+1}$} \\
&= f\paren{f^k(x)}  \by {pela def.~de $f\of f^k$} \\
&= f( x )           \by {pois $x$ é um fixpoint da $f^k$ (H.I.)} \\
&= x                \by {pois $x$ é um fixpoint da $f$} \\
\endcompute
e logo $x$ é um fixpoint da $f^{k+1}$.
\crproofpart {\rldir}:
Usando nossa hipótese com $n \asseq 1$, temos que $x$ é um fixpoint da $f^1$.
Mas $f^1$ é a própria $f$ (pois $f^1 = f \of f^0 = f \of 1_A = f$)
e logo $x$ é um fixpoint da $f$.

%%}}}

%%{{{ prob: fixpoint_iff_iterations_generalization 
\problem.
%%%{{{ meta 
\label fixpoint_iff_iterations_generalization
%%%}}}

Seja $F \subset \funs A A$ e seja $a \in A$.
Demonstre ou refute a afirmação:
$$
\text{$a$ é um fixpoint de toda $f\in F$}
\iff
\brace {\mathed {
\text{para todo $d\in\nats$ e toda $\vec f \in F^d$} \\
\text{$a$ é um fixpoint da $f_1 \of f_2 \of \dotsb \of f_d$}.
}}
$$
Como isso se compara com o~\ref[fixpoint_iff_iterations]?

%%}}}

%%{{{ prob: fix_f_properties 
\problem.
%%%{{{ meta 
\label fix_f_properties
%%%}}}

Seja $f : A \to A$,
e seja $F$ o conjunto de todos os fixpoints da $f$.
$$
F = \setstt {x \in A} {$x$ é um fixpoint da $f$}
$$
Quais das igualdades seguintes podemos concluir?:
$$
\xalignat2
\img f F &= F &
\pre f F &= F
\endxalignat
$$
Demonstre aquelas que sim; mostre um contraexemplo daquelas que não,
mas verifique se alguma das duas inclusões
{\lrdirset} ou {\rldirset} é válida.
O que muda se $f$ é injetora?

\solution
Sempre temos $\img f F = F$ e $\pre f F \supset F$.
Se $f$ é injetora, ganhamos a $\pre f F \subset F$ também.
\eop
\proofpart {{\proofname} de $\img f F \subset F$.}
Seja $y\in\img f F$.
Logo tome $p\in F$ tal que $f(p) = y$\fact1 (pela definição da função-imagem).
Logo $p$ é um fixpoint da $f$, ou seja, $f(p) = p$\fact2.
Juntando as {\byfact1} e~{\byfact2}, ganhamos $p = y$, ou seja $y$ é um fixpoint da $f$, e logo $y\in F$.
\eop
\proofpart {{\proofname} de $\img f F \supset F$.}
Seja $p \in F$.
Logo $f(p) \in \img f F$ (pela definição da função-imagem).
Mas $p$ é um fixpoint da $f$ (pois $p\in F$), ou seja $f(p) = p$.
Logo $p \in \img f F$.
\eop
\proofpart {{\proofname} de $\pre f F \supset F$.}
Seja $p \in F$, ou seja $p$ é um fixpoint da $f$.
Logo $f(p) = p \in F$, e logo $p \in \pre f F$.
\eop
\proofpart {Contraexemplo para $\pre f F \subset F$.}
Tome $A = \set{0,1}$ e defina $f$ pela $f(x) = 0$.
Nesse caso temos $F = \set{0}$, mas $\pre f F = \set{0,1}$.
\eop
\proofpart {{\proofname} da $\pre f F \subset F$ quando $f$ injetora.}
Seja $a\in \pre f F$.
Logo $f(a)$ é um fixpoint da $f$.
Ou seja, $f(f(a)) = f(a)$
Agora, como $f$ é injetora, temos $f(a) = a$, ou seja,
$a$ é um fixpoint também e logo $a\in F$.

%%}}}

\endproblems
%%}}}

% EPICNESS

%%{{{ An_epic_trip 
\section Uma viagem épica.
%%%{{{ meta 
\label An_epic_trip
%%%}}}

%%{{{ mathematical_OCD: Something irritating 
\note Algo irritante?.
%%%{{{ meta 
\label mathematical_OCD
\indexes
    * TOC!matemático
    ;;
%%%}}}

Seria bom desenvolver um certo ``TOC'' matemático:
ganhar certas frescuras matemáticas úteis, e sentir
\emph{matematicamente irritados} quando sentir algo bizarro.
E algo bizarro já aconteceu recentemente:
tá bem ali na~\ref[jections] de injetora e sobrejetora:
$$
\matrix
\format
\l & \;\c\; & \l\, & \l\, & \l \\
\text{$f$ injetora}    & \defiff & \pforall {x \in A} & \cforall {y \in A} {f \fa x = f \fa y \implies x = y}; \\
\text{$f$ sobrejetora} & \defiff & \pforall {b \in B} & \cexists {a \in A} {f \fa a = b}.
\endmatrix
$$
Consegues ver algo irritante?
\spoiler
Injectividade e sobrejectividade têm cara de conceitos que
deveriam ser intimamente relacionados.
Simétricos, duais, espelhados, sei lá o que,
algo que com certeza não parece olhando para suas definições!
A primeira começa com dois quantificadores do mesmo tipo,
universais, ambos no domínio, e acaba com uma implicação;
a segunda começa com dois quantificadores de tipos diferentes:
um existencial, agora no codomínio, o outro universal no domínio,
e acaba com uma igualdade!
\emph{Nada a ver}, pelo jeito!\foot
Existe uma justificativa muito boa sobre isso:
na própria idéia do que é uma função, não tratamos
seu domínio e seu codomínio numa maneira parecida:
a função foi ``total no seu domínio'' mas não no seu
codomínio, e foi ``univoca'', ou seja, do mesmo ponto
do seu domínio não podem sair duas setinhas (barradas),
mas estamos de boas se nuns pontos do seu codomínio
chegam mais que uma setinhas.
Esqueça esse ponto de vista para viajar comigo aqui;
prometo que no~\ref[Relations] tu pode voltar
a repensar nesse assunto.
\toof
Isso deveria te dar pelo menos uns arrepeios;
e no pior---melhor?---dos casos te deixar acordado até encontrar
definições desses dois conceitos que realmente são intimamente
relacionadas.
Agora calma---podes dormir tranqüilamente---pois vamos chegar
nessa satisfacção logo.

%%}}}

%%{{{ let_us_trip_1 
\note Bora viajar.
%%%{{{ meta 
\label let_us_trip_1
%%%}}}

Começamos na~\ref[Composition_laws] procurar conexões entre
a composição e a multiplicação e realmente achamos muitas
similaridades e essa influência já se tornou muito útil.
Vamos começar dando uma olhada novamente numa propriedade
de funções, a injectividade.
Pela sua definição, $f$ é injetora exatamente quando
$$
\text{para todo $x,y$,} \quad f\fa x = f\fa y \implies x=y.
$$
Isso até parece pouco com cancelamento:
$$
\cancelspc f x = \cancelspc f y \implies x = y.
$$
Queremos investigar se e quando podemos cancelar uma
função quando operada com composições:
\mathcol
f \of g = f \of h &\askimplies g = h
\intertext{e como nossa operação já sabemos que não
é comutativa precisamos tratar essa questões similares separadamente:}
g \of f = h \of f &\askimplies g = h\\
g \of f = f \of h &\askimplies g = h.
\endmathcol
Vamos voltar no
$$
\cancelspc f x = \cancelspc f y \implies x = y
$$
mas agora vamos fingir que os $f,x,y$ são números reais!
E logo as expressões $f x$ e $f y$ denotam apenas os produtos
$f\ntimes x$ e $f\ntimes y$.
Bem.
O que podemos concluir sabendo que
$$
f \fa x = f \fa y ?
$$
Caso $f\neq0$, podemos cancelá-lo:
$$
\cancelspc f x = \cancelspc f y
$$
chegando assim na
$$
x = y.
$$
Caso $f=0$, a $f$ não é cancelável.\foot
Por que não?
Se tu aprendeu numa maneira religiosa algum poeminha
do tipo ``não cancelarás $0$ nas multiplicações'', esqueça;
ninguém se importa com que teu padre falou.
A gente vai voltar nessa questão mais tarde
(\ref[Algebraic_structures] (\reftag[Rings]);
\ref[The_reals]).
\toof
\eop
Parece ótimo: exatamente o tipo da coisa que estamos procurando!
Será que podemos já trazer essa sabedoria da $(\ntimes)$
nos números para a $\of$ nas funções?
O que seria nosso ``zero'' nas funções?
Uma resposta boba seria <<a função constante 0>>.
Com certeza para funções numéricas
a função constante $\kon 0 = \lam x 0$ não é nada de cancelável.
(Veja~\ref[kon_is_not_cancellable_in_general].)
Por que boba então?
Pois dizendo isso já perdemos a generalidade:
\emph{queremos algo descrevível para qualquer
função e não algo que serve apenas para funções cujos codomínios
tem o $0$ como membro.}
Mas peraí.
Talvez não é o ``ser zero'' que é importante nesse ponto de
cancelamento!
Realmente: por que esse \wq{se $f \neq 0$} acima?
\emph{\wq{É que se $f=0$ então $f$ não é cancelável.}}
Mas essa resposta não é exatamente iluminante.
O que nos permite cancelar números na multiplicação?
Vamos tentar algo mais cuidadoso e formal:\foot
Mesmo sendo cedo neste momento para essa abordagem
creio que o leitor vai conseguir acompanhar a idéia.
Estudando algebra abstrata nos capítulos~\reftag[Group_theory]
e~\reftag[Algebraic_structures] tudo isso vai aparecer
bem tranqüilo e natural.  Prometo.
\toof
\compute
f x = f y
&\implies f^{-1} (f x) = f^{-1} (f y)   \by {multiplicando por $f^{-1}$} \\
&\implies (f^{-1} f) x = (f^{-1} f) y   \by {pela associatividade da $(\ntimes)$} \\
&\implies 1 x = 1 y                     \by {pela def.~da $f^{-1}$} \\
&\implies x = y.                        \by {pela def.~de $1$} \\
\endcompute
O único passo duvidoso seria o primeiro:
como sabemos que existe esse inverso?
\emph{Não sabemos.}
Então talvez é isso que estamos procurando!
Talvez
$$
\text{$f$ tem inversa} \askiff \text{$f$ é cancelável}!
$$
Para demonstrar essa afirmação precisamos saber
o que ``cancelável'' significa formalmente aqui.
Qual das três implicações que consideramos acima vamos escolher?:
$$
\text{$f$ é cancelável}
\askiff
\leftbrace {
\aligned
f \of g = f \of h &\implies g = h \\
g \of f = h \of f &\implies g = h \\
g \of f = f \of h &\implies g = h.
\endaligned
}
$$
A $(\ntimes)$ nos números, sendo uma operação \emph{comutativa},
não consegue diferenciar entre essas afirmações.
Ou seja, por causa da riquesa das leis que temos
na multiplicação nos números, certas distinções desaparecem,
``se desabam''---algo que podemos pensar como pobresa também!
E vice versa: com menos leis ganhamos mais distinções---riquesa!
No mundo dos reais, um certo $x$ ou tem inverso
ou não.  De qual lado inverso?  Não faz sentido perguntar
isso nos números pois o lado não importa.
Quando importa, não vamos falar apenas sobre ``inverso'' mas sim sobre
\dterm{inverso esquerdo} e \dterm{inverso direito}.
Similarmente, nos números só tem uma $1$ para considerar;
nas funções, cada conjunto $A$ chega com sua própria $1_A$!
\emph{O mundo das funções é suficientemente rico para enxergar
essas noções inenxergáveis no mundo dos números!}

%%}}}

%%{{{ x: kon_is_not_cancellable_in_general 
\exercise.
%%%{{{ meta 
\label kon_is_not_cancellable_in_general
%%%}}}

Demonstre que a função constante $\kon 0 : \reals \to \reals$
em geral não é cancelável nem pela direita nem pela esquerda.

\solution
\proofpart {Incancelável pela esquerda.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\cos"']
\| \reals \ar[r, "\kon 0"]
\| \reals
\endcd
$$
que obviamente comuta; ou seja $\kon 0 \sin = \kon 0 \cos (= \kon 0)$)
mas mesmo assim $\sin \neq \cos$.
\crproofpart {Incancelável pela direita.}
Tome por exemplo as
$$
\cdopt{sep=2cm}
\reals \ar[r, "\kon 0"]
\|\reals \ar[r, shift left, "\sin"]\ar[r, shift right, "\id"']
\|\reals
\endcd
$$
que obviamente comuta; ou seja $\sin \kon 0 = \id \kon 0 (= \kon 0)$)
mas mesmo assim $\sin \neq \id$.

%%}}}

%%{{{ let_us_trip_2 
\note.
%%%{{{ meta 
\label let_us_trip_2
%%%}}}

Olhe de novo na implicação que tem na definição da injetora:
$$
f \fa x = f \fa y \implies x = y. \tag{L-canc}
$$
Ela lembra muito do que acabamos de demonstrar, mas nosso objectivo
foi investigar a composição $\of$ usando a multiplicação $(\ntimes)$.
Quando escrevi a (L-canc) em números, a justaposição denotou
a $(\ntimes)$ mesmo; mas na definição da injetora que temos,
a justaposição não denota a $\of$, mas a $\eval$\/!
Então vamos ver o que acontece se mudar para a $\of$, obviamente
tomando cuidado para usar objetos dos certos tipos:
$$
f \of g = f \of h \askimplies g = h
$$
que escrevemos por justaposição sem confusão:
$$
f g = f h \askimplies g = h.
$$
Vamos tentar imitar a demonstração anterior:
\compute
f g = f h
&\implies {\finv f} (f g) = {\finv f} (f h) \by {??} \\
&\implies ({\finv f} f) g = ({\finv f} f) h \by {(F-Ass)} \\
&\implies \idoneof A g = \idoneof A h       \by {(F-Inv)} \\
&\implies g = h                             \by {(F-Id)} \\
\endcompute
O que precisamos no \symq{??} acima?

%%}}}

\spoiler

%%{{{ let_us_trip_3 
\note.
%%%{{{ meta 
\label let_us_trip_3
%%%}}}

Uma resposta ``de preguiça'' seria \dq{preciso $f$ bijetora}.
Claro que isso é \emph{suficiente}, mas é \emph{necessário}
também?  Começamos pensando que \dq{$f$ injetora} é algo que
corresponde nesse cancelamento aí, então será que basta só
isso?
Mas parece que precisei a existência de $\finv f$,
ou seja, precisamos que $f$ seja invertível.  Ou não?
Lembre que o inverso $\finv f$ de $f$ é um objeto que
satisfaz \emph{ambas} as
\mathxcols 4
\text{(LInv)} && \finv f f &= \idoneof A; & f \finv f &= \idoneof B && \text{(RInv)}
\endmathxcols
mas, olhando de novo para nosso caminho, a gente precisou
apenas a (LInv).
Então não necessitamos mesmo que $f$ tem um inverso $\finv f$;
basta ter um inverso-esquerdo $\labL f$ e a demonstração rola:
\compute
f g = f h
&\implies {\labL f} (f g) = {\labL f} (f h) \by {$f$ é L-invertível} \\
&\implies ({\labL f} f) g = ({\labL f} f) h \by {(F-Ass)} \\
&\implies \idoneof A g = \idoneof A h       \by {(F-LInv)} \\
&\implies g = h.                            \by {(F-Id)} \\
\endcompute
Já temos descoberto umas idéias interessantes:
L-cancelável e L-invertível, e obviamente temos as noções
laterais de R-cancelável e R-invertível.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Influenciados por toda essa viagem, podemos chegar nuns resultados
muito importantes e interessantes sobre as ``jectividades''
(`in-' e `sobre-'); as invertibilidades laterais;
e as cancelabilidades laterais das funções.

%%}}}

%%{{{ Q: guess the theory that's about to come 
\question.
%%%{{{ meta 
%%%}}}

Quais resultados tu acha que vamos demonstrar?
Consegues demonstrá-los?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Um chute bom é o seguinte:
$$
\matrix
\format
\l & \c & \l & \c & \l & \c & \l \\
\text{$f$ mono} & \defiff & \text{$f$ L-cancelável} & \askiff & \text{$f$ L-invertível} & \askiff & \text{$f$ injetora} \\
\text{$f$ epí}  & \defiff & \text{$f$ R-cancelável} & \askiff & \text{$f$ R-invertível} & \askiff & \text{$f$ sobrejetora}.
\endmatrix
$$
E sim, tem esses nomes chique mesmo.

%%}}}

%%{{{ df: mono_epi_functions
\definition mono, epi.
%%%{{{ meta 
\label mono_epi_functions
\indexes
    * mônica   see: função, mono
    * épica    see: função, epí
    ;;
\defines
    * função!epi
    * função!mono
    ;;
%%%}}}

Seja $f : A \to B$.
Dizemos que $f$ é uma função \dterm{mônica}
(ou simplesmente que $f$ é uma \dterm{mono}) sse $f$ é $\of$-cancelável pela esquerda.
Dizemos que $f$ é uma função \dterm{épica}
(ou simplesmente que $f$ é uma \dterm{epí}\/) sse $f$ é $\of$-cancelável pela direita.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora investigar então!

%%}}}

%%{{{ thm: injection_iff_mono 
\theorem.
%%%{{{ meta 
\label injection_iff_mono
%%%}}}

Sejam $B \toby f C$.
A $f$ é injetora sse ela é \dterm{$\of$-cancelável pela esquerda:}
$$
f\of g = f \of h \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.

\sketch.
A direção {\lrdir} é o~\ref[injection_iff_mono_lrproof].
Para a direção {\rldir}, tome $b,b'\in B$ tais que $f(b)=f(b')$.
Basta demonstrar que $b=b'$.
Tome $A\asseq\set{0}$ e defina $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
em tal maneira que o diagrama comuta (tem que definir mesmo as $g,h$).
Usamos agora a hipótese para concluir que $b=b'$.

\proof.
\proofpart {\lrdir:} \ref[injection_iff_mono_lrproof]:
\crproofpart {\rldir:}
Suponha $b,b' \in B$ tais que $f(b) = f(b')$.
Basta mostrar que $b = b'$.
Temos então o diagrama interno seguinte:
$$
\tikzpicture
\tikzi mono_implies_inj0;
\endtikzpicture
$$
Seja $A = \set{0}$ e defina as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
\set{0}   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
como as funções constantes definidas pelas 
$$
g(0) = b
\qqtext{e}
h(0) = b'.
$$
Então agora estamos com o diagrama interno assim:
$$
\tikzpicture
\tikzi mono_implies_inj1;
\endtikzpicture
$$
Observe que como
$$
\align
(f\of g)(0) &= f(g(0)) = f(b) \\
(f\of h)(0) &= f(h(0)) = f(b')
\endalign
$$
e $f(b) = f(b')$, temos
$f\of g = f\of h$ e agora usamos a hipótese para ganhar $g = h$.
Logo as $g,h$ concordam no $0$, ou seja, $b = b'$.

%%}}}

%%{{{ x: injection_iff_mono_lrproof 
\exercise.
%%%{{{ meta 
\label injection_iff_mono_lrproof
%%%}}}

Demonstre a direção {\lrdir} do~\ref[injection_iff_mono].

\solution
Suponha então que $f\of g = f\of h$.
Vamos mostrar que $g = h$.
Seja $x \in A$.
Pela hipótese,
$$
(f\of g)(x) = (f\of h)(x)
$$
logo $f(g(x)) = f(h(x))$
e como $f$ injetora, chegamos no desejado $g(x) = h(x)$.

%%}}}

%%{{{ thm: surjection_iff_epic 
\theorem.
%%%{{{ meta 
\label surjection_iff_epic
%%%}}}

Sejam $B \toby f C$.
A $f$ é sobrejetora sse ela é \dterm{$\of$-cancelável pela direita:}
$$
g\of f = h\of f \implies g = h
$$
para todas as $g,h$ tais que as composições acima são definidas.
Digamos então que $f$ é \dterm{$\of$-cancelável pela direita}.

\sketch.
A direção {\lrdir} é o~\ref[surjection_iff_epic_lrproof].
Para a direção {\rldir}, tomamos $c \in C$ e procuramos achar
$b\in B$ tal que $f(b) = c$.
Defina o $D$ (cuidado: aqui não ajuda tomar $D=\set{0}$)
e as $g,h$ no diagrama
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
em tal maneira que $g\neq h$,
mas mesmo assim \emph{concordam em todo o $C$ exceto no ponto $c$}.
Usando a contrapositiva da hipótese ganhamos
$g\of f \neq h\of f$, mas isso só pode acontecer se a $f$ mandou pelo
menos um ponto do domínio dela para o $c$.

\proof.
\lrdir:
\ref[surjection_iff_epic_lrproof].
\eop
\rldir:
Suponha $c\in C$.
Procuramos $b\in B$ tal que $f(b) = c$.
Começamos então com o diagrama interno seguinte:
$$
\tikzpicture
\tikzi epic_implies_surj0;
\endtikzpicture
$$
Seja $D=\set{0,1}$ e defina as funções $g,h:C\to D$ pelas
$$
g(y) = 0
\qqtext{e}
h(y) = \knuthcases {
1, &se $y = c$; \cr
0, &se $y \neq c$.
}
$$
Logo $g(c) \neq h(c)$, mas $g(y)=h(y)$ para todo $y\neq c$.
Agora estamos assim:
$$
\tikzpicture
\tikzi epic_implies_surj1;
\endtikzpicture
$$
Como $g\neq h$ então, pela hipótese concluimos que $g\of f \neq h\of f$, ou seja,
as $g\of f$ e $h\of f$ discordam em pelo menos um membro de $B$,
e seja $b$ um tal membro:
$$
(g\of f)(b) \neq (h\of f)(b).
$$
Logo
$$
g(f(b)) \neq h(f(b)),
$$
ou seja, $g$ e $h$ discordam no $f(b)$.
Mas $g$ e $h$ discordam apenas no $c$; ou seja,
$f(b) = c$ como desejamos.

%%}}}

%%{{{ x: surjection_iff_epic_lrproof 
\exercise.
%%%{{{ meta 
\label surjection_iff_epic_lrproof
%%%}}}

Demonstre a direção {\lrdir} do~\ref[surjection_iff_epic].

\solution
Suponha que $g\of f = h\of f$.  Vamos mostrar que $g = h$.
Seja $c\in C$.
Logo existe $b\in B$ tal que $f(b) = c$.
Como
$$
(g\of f)(b) = (h\of f)(b)
$$
temos $g(f(b)) = h(f(b))$; e, pela escolha de $b$, $g(c) = h(c)$.
Logo $g = h$.

%%}}}

%%{{{ x: mono_epi_commutative_diagrams 
\exercise Mono e epí com diagramas comutativos.
%%%{{{ meta 
\label mono_epi_commutative_diagrams
%%%}}}

Descreva as propriedades das definições de mono e
epi~(\reftag[mono_epi_functions]) usando diagramas comutativos.

\solution
\proofpart {A função $f$ é mônica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
A   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| B \ar[r, "f"]  \|  C
\endcd
$$
temos $g=h$.
\crproofpart {A função $f$ é épica sse} em todo diagrama comutativo da forma
$$
\cdopt{sep=2cm}
B  \ar[r, "f"] \|  C   \ar[r, shift left, "g"]\ar[r, shift right, "h"'] \| D
\endcd
$$
temos $g=h$.

%%}}}

%%{{{ df: isomorphic_sets 
\definition conjuntos isómorfos.
%%%{{{ meta 
\label isomorphic_sets
\defines
    * ~A \iso ~B  -- os conjuntos $A,B$ são isómorfos
    * ~f : ~A \iso ~B  -- $f : A \isoto B$ (notação alternativa)
    * ~f : ~A \isoto ~B  -- $f$ é um isomorfismo do $A$ para o $B$
    * isomorfismo!de conjuntos
    ;;
%%%}}}

Sejam $A,B$ conjuntos.
Chamamos os $A,B$ \dterm{conjuntos isómorfos} (ou \dterm{isomórficos})
sse existe bijecção $f : A \bijto B$.
Nesse caso chamamos a $f$ um \dterm{isomorfismo de conjuntos}.
Escrevemos $A \iso B$, e também
$f : A \iso B$ ou $f : A \isoto B$ para denotar que
$f$ é um isomorfismo do conjunto $A$ para o conjunto $B$.

%%}}}

%%{{{ remark: etymology_of_isomorphic 
\remark etimologia.
%%%{{{ meta 
\label etymology_of_isomorphic
%%%}}}

As palavras vêm do grego \emph{ίσο}
que significa ``igual'' e \emph{μορφή} que significa ``forma''.
Isómorfos então são aqueles que têm a mesma forma; ``a mesma cara''.
Mas o que significa forma, cara?
Depende do contexto!
Aqui nos conjuntos, podemos pensar que $A\iso B$ quis dizer
que os $A$ e $B$ só podem variar nos \emph{nomes} usados para
seus membros e em nada mais: um isomorfismo seria um renomeamento,
uma tradução \emph{fiel} de $A$ para $B$.  Podemos considerar
então o $B$ como uma \emph{cópia} do $A$ onde apenas re-rotulámos
seus membros.
Começando no~\ref[Group_theory] vamos estudar tipos de coisas
onde sua forma é bem mais rica que isso, e lá ``isómorfos'' vai
acabar sendo uma noção bem mais forte.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já tivemos definido os conceitos de inversa e de identidade
antes de fazer essa viagem que fizemos aqui.
Mas com essa experiência podemos voltar e repensar
em mais motivações e influências para chegar nesses
conceitos, e mais idéias para demonstrar nossos
teoremas.
Pode viajar à vontade!
Graças a tudo isso, já podemos dormir tranqüilamente
pois encontramos finalmente umas definições para satisfazer
nossas frescuras.

%%}}}

\endsection
%%}}}

%%{{{ Retractions_and_sections 
\section Retracções e secções.
%%%{{{ meta 
\label Retractions_and_sections
%%%}}}

%%{{{ df: retraction_section 
\definition Retracções, secções.
%%%{{{ meta 
\label retraction_section
\defines
    * função!inversa direita
    * função!inversa esquerda
    * função!retracção
    * função!secção
    ;;
%%%}}}

Seja $f : A \to B$.
Se $r : B \to A$ satisfaz a
$$
r \of f = \idof A
$$
dizemos que $r$ é uma \dterm{retracção} ou uma
\dterm{$\of$-inversa esquerda} da $f$.
Se $s : B \to A$ satisfaz a
$$
f \of s = \idof B
$$
dizemos que $s$ é uma \dterm{secção} ou uma
\dterm{$\of$-inversa direita} da $f$.
Observe que no primeiro caso, $f$ é uma secção da $r$;
e no segundo caso $f$ é uma retracção da $s$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ganhamos imediatamente dois corolários fáceis dos teoremas
\reftag[injection_iff_mono]--\reftag[surjection_iff_epic]:

%%}}}

%%{{{ cor: retraction_implies_injection 
\corollary.
%%%{{{ meta 
\label retraction_implies_injection
%%%}}}

Se $f : A \to B$ tem retracção, então $f$ é injetora.

\proof.
Seja $r$ uma retracção da $f$.
Temos
$$
f \of g = f \of h
\implies r \of f \of g = r \of f \of h
\implies \idof A \of g = \idof A \of h
\implies g = h
$$
e logo $f$ é injetora pelo~\ref[injection_iff_mono].

%%}}}

%%{{{ cor: section_implies_surjection 
\corollary.
%%%{{{ meta 
\label section_implies_surjection
%%%}}}

Se $f : A \to B$ tem secção, então $f$ é sobrejetora.

\proof.
Seja $s$ uma secção da $f$.
Temos
$$
g \of f = h \of f
\implies g \of f \of s = h \of f \of s
\implies g \of \idof B = h \of \idof B
\implies g = h
$$
e logo $f$ é sobrejetora pelo~\ref[surjection_iff_epic].

%%}}}

%%{{{ x: retraction_implies_injection_elementary_proof 
\exercise.
%%%{{{ meta 
\label retraction_implies_injection_elementary_proof
%%%}}}

Demonstre o~\ref[retraction_implies_injection] elementariamente
(sem o~\reftag[injection_iff_mono]).

\solution
Suponha que $f : A \to B$ e que $r : B \to A$ é uma retracção da $f$.
Tome $x, x' \in A$ tais que $f(x) = f(x')$.
Logo $r(f(x)) = r(f(x'))$.
Logo $(r\of f)(x) = (r\of f)(x')$.
Como $r$ é retracção, temos $\idof A(x) = \idof A(x')$,
ou seja, $x = x'$ e $f$ é injetora.

%%}}}

%%{{{ x: section_implies_surjection_elementary_proof 
\exercise.
%%%{{{ meta 
\label section_implies_surjection_elementary_proof
%%%}}}

Demonstre o~\ref[section_implies_surjection] elementariamente
(sem o~\reftag[surjection_iff_epic]).

\solution
Suponha que $f : A \to B$ e que $s : B \to A$ é uma secção da $f$.
Tome $b \in B$.
Logo $s(b) \in A$, e como $s$ secção, temos $f(s(b)) = b$, ou seja
a $f$ é sobrejetora pois mapeia $s(b) \mapstoby f b$.

%%}}}

\TODO Como chegar na definição alternativa.
% Exceto um detalhe que ainda falta verificar:

%%{{{ x: finv_altdef_missing_detail 
\exercise.
%%%{{{ meta 
\label finv_altdef_missing_detail
%%%}}}

O que mais falta demonstrar?
Apenas enuncie o que é, sem demonstrar.

\hint
A $\finv f$ foi definida apenas quando $f$ é bijetora.

%%}}}

%%{{{ thm: finv_atleastonelaw_if_f_bij_pointless 
\theorem Basta uma lei: agora sem pontos.
%%%{{{ meta 
\label finv_atleastonelaw_if_f_bij_pointless
%%%}}}

Seja $f : A \bijto B$.
Se uma $f' : B \to A$ satisfaz pelo menos uma das duas leis da
inversa~(\ref[function_laws]), então $f' = \finv f$.

\proof.
Caso que $f'$ satisfaz a (L):
\compute
f'
&= f' \of \idof B          \by {lei da $\idof B$} \\
&= f' \of (f \of \finv f)  \by {(R) da $\finv f$} \\
&= (f' \of f) \of \finv f  \by {assoc.} \\
&= \idof A \of \finv f     \by {(L) da $f'$} \\
&= \finv f.                \by {lei da $\idof A$} \\
\intertext{E caso que $f'$ satisfaz a (R):}
f'
&= \idof A \of f'          \by {lei da $\idof A$} \\
&= (\finv f \of f) \of f'  \by {(L) da $\finv f$} \\
&= \finv f \of (f \of f')  \by {assoc.} \\
&= \finv f \of \idof B     \by {(R) da $f'$} \\
&= \finv f.                \by {lei da $\idof B$} \\
\endcompute

%%}}}

%%{{{ x: retraction_and_section_implies_inverse 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $f : A \to B$ tal que $r,s : A \from B$ são retracção
e secção da $f$ respectivamente.
Podemos concluir a afirmação seguinte?:
$$
\text{$f$ é bijetora}
\quad\mland\quad
\text{$r = \finv f = s$}.
$$
Se sim, demonstre; se não, refute.

\hint
Primeiramente observe:
$$
\rightbrace {
\aligned
\text{$f$ tem retracção} &\implies   \text{$f$ é injetora} \\
\text{$f$ tem secção}    &\implies   \text{$f$ é sobrejetora}
\endaligned
}
\implies \text{$f$ bijetora}.
$$

\solution
Como $f$ tem retracção, ela é injetora;
e como ela tem secção, ela é sobrejetora;
logo $f$ é bijetora e a $\finv f$ é definida.
Aplicamos então o~\ref[finv_atleastonelaw_if_f_bij] com $f'\asseq r$
e com $f'\asseq s$ e ganhamos:
$$
r = \finv f = s.
$$

%%}}}

\endsection
%%}}}

%%{{{ From a solution to a problem to a theory 
\section Duma resolução para um problema para uma teoria.
%%%{{{ meta 
%%%}}}

%%{{{ from a solution to a problem 
\note Duma resolução para o problema.
%%%{{{ meta 
\label from_a_solution_to_a_problem_first_uniprop
%%%}}}

Aqui o produto cartesiano $A\cross B$ que chega junto com suas projecções
$\outl : A \cross B \to A$ e $\outr : A \cross B \to B$:
$$
\cdopt{sep=1cm}
                                                                          \| A \\
A\cross B \ar[ur, bend left=15, "\outl"] \ar[dr, bend right=15, "\outr"'] \|   \\
                                                                          \| B
\endcd
$$
Esse bicho junto com suas duas setinhas, $\tupp{\outl, A\cross B, \outr}$
tem uma propriedade \emph{muito interessante:}
para cada \dterm{impostor} $\tupp{f_1,F,f_2}$:
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                  \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| A\cross B
                                         \ar[ur, bend left=15,  "\outl"]
                                         \ar[dr, bend right=15, "\outr"'] \|   \\
                                   \| \|                                  \| B
\endcd
$$
A partir dessa \emph{resolução}, vamos descobrir um \emph{problema:}
determine os $\aR?$ no
$$
\cdopt{sep=1cm}
                                                                   \| A \\
\aR? \ar[ur, bend left=15, "\aR?"] \ar[dr, bend right=15, "\aR?"'] \|   \\
                                                                   \| B
\endcd
$$
tais que para todo $\tupp{f_1,F,f_2}$,
$$
\cdopt{sep=1cm}
                                                              \| A \\
F \ar[ur, bend left=15, "f_1"] \ar[dr, bend right=15, "f_2"'] \|   \\
                                                              \| B
\endcd
\quad\implies\quad
\cdopt{sep=1cm}
                                   \| \|                                     \| A \\
F
\ar[rr, dotted, "\aB\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']   \| \| \aR?
                                         \ar[ur, bend left=15, "\aR?"]
                                         \ar[dr, bend right=15, "\aR?"'] \|   \\
                                   \| \|                                     \| B
\endcd
$$
Observe que realmente o $\tupp{\aR\outl, \aR{A\cross B}, \aR\outr}$
é uma resolução desse problema.

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Categories_a_first_taste 
\section Pouco de cats---um primeiro toque de categorias.
%%%{{{ meta 
\label Categories_a_first_taste
%%%}}}

%%{{{ intro 
\secintro
Podemos \emph{finalmente} introduzir pouca da linguagem e das
idéias principais das \emph{categorias} para ter na nossa
disposição antes de chegar no~\ref[Category_theory] onde vamos
fazer mesmo nossos primeiros passos na sua teoria.
Mas o que é uma categoria?
%%}}}

%%{{{ df: category_first_def 
\definition categoria.
%%%{{{ meta 
\label category_first_def
%%%}}}

Uma \dterm{categoria} $\cat C$ é composta por duas colecções de coisas:
\tlist:
\li: $\Obj {\cat C}$: os \dterm{objetos} da $\cat C$, que denotamos por $A,B,C,\dots$;
\li: $\Arr {\cat C}$: as \dterm{setas} da $\cat C$, que denotamos por $f,g,h,\dots$;
\endtlist
tais que:
\elist i:
\li: Para toda seta $f$ do $\Arr {\cat C}$, são determinados dois objetos:
     o \dterm{source} da $f$ e o \dterm{target} da $f$, denotados por
     $\src f$ e $\tgt f$ respectivamente.
     Escrevemos $f : A \to B$ para afirmar que $f$ é uma seta,
     e que $\src f = A$ e $\tgt f = B$.
     Denotamos por $\Hom(A,B)$ a colecção de todas as setas de $A$ para $B$.
\li: Para cada objeto $A$ da $\cat C$ é determinada uma seta $\oneof A : A \to A$
     chamada \dterm{a identidade do $A$}.
\li: Dados objetos $A,B,C$ e setas $A \toby f B \toby g C$ é determinada uma seta
     $g \of f : A \to C$ chamada \dterm{a composição da $g$ com $f$}
     (ou \dterm{``$g$ de $f$''}\/; ou \dterm{``$g$ seguindo $f$''}\/)
     que freqüentemente denotamos por $gf$ ou $f \dcom g$.
     Ou seja, dados quaisquer objetos $A,B,C$ temos um operador de composição
     $$
     \oflab ABC : \Hom(B,C) \times \Hom(A,B) \to \Hom(A,C).
     $$
\endelist
Tudo isso é o que temos numa categoria.
Mas apenas \emph{ter} tudo isso não é suficiente.
Essas coisas todas devem satisfazer as \dterm{leis de categoria:}
\tlist:
\li (C-Ass):cat_ass_law
Para todas as setas $A \toby f B \toby g C \toby h D$ temos:
$$
(hg)f = h(gf).
$$
\li (C-Unit):cat_unit_law
Para toda seta $A \toby f B$ temos:
$$
f \oneof A = f = \oneof B f.
$$
\endtlist

%%}}}

%%{{{ remark: operations from the definition of a category 
\remark.
%%%{{{ meta 
%%%}}}

Observe que a~\ref[category_first_def] está nos dando operações:
$$
\cd
\Arr{\cat C}
\ar[r, shift left, "\src"]
\ar[r, shift right, "\tgt"'] \| \Obj{\cat C}.
\endcd
$$
E também
$$
\cd
\Obj{\cat C} \ar[r, "\id"] \| \Arr{\cat C} \\
A   \ar[r, maps to, "\id"] \| \oneof A
\endcd
\qquad
\cd
\Hom(B,C) \cross \Hom(A,B) \ar[r, "\of"]          \| \Hom(A,C) \\
\tup{g,f}                  \ar[r, maps to, "\of"] \| gf
\endcd
$$

%%}}}

%%{{{ eg: SET 
\example conjuntos.
%%%{{{ meta 
\label SET
\defines
    * \SET  -- a categoria dos conjuntos e suas funções
    ;;
%%%}}}

A $\SET$ com objetos os conjuntos e setas as funções entre conjuntos
é uma categoria.

%%}}}

%%{{{ x: SET_is_a_cat 
\exercise.
%%%{{{ meta 
\label SET_is_a_cat
%%%}}}

Verifique.

%%}}}

%%{{{ eg: INTLEQ 
\example inteiros com ordem.
%%%{{{ meta 
\label INTLEQ
%%%}}}

Denotamos por $\INTLEQ$ a categoria cujos objetos são os inteiros
e entre dois objetos $A,B$ existe seta $f$ sse $A \leq B$.
Observe que o que são mesmo as setas não importa, mas caso que
insista para defini-las podemos considerar a única seta de $A$
para $B$ pra ser o par $\tup{A,B}$.

%%}}}

%%{{{ x: INTLEQ_is_a_cat 
\exercise.
%%%{{{ meta 
\label INTLEQ_is_a_cat
%%%}}}

Demonstre que a suposta categoria do \ref[INTLEQ]
realmente é uma categoria mesmo.
Deixe claro o que precisas demonstrar mesmo; e demonstre.

%%}}}

%%{{{ eg: INTDIV 
\example inteiros com divide.
%%%{{{ meta 
\label INTDIV
%%%}}}

Similarmente definimos a $\INTDIV$:
aqui temos seta $f : A \to B$ sse $A \divides B$.

%%}}}

%%{{{ x: INTDIV_is_a_cat 
\exercise.
%%%{{{ meta 
\label INTDIV_is_a_cat
%%%}}}

Demonstre que a suposta categoria do \ref[INTDIV] realmente
é uma categoria.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Queremos trazer o conceito de isomorfismo pra cá, pra ser aplicável
em qualquer categoria.  Observe que não podemos usá-lo mesmo,
pois na $\SET$ definimos o isomorfismo pra ser sinônimo de bijecção.
E não temos como falar ``bijecção'' no contexto abstrato de categorias.

%%}}}

%%{{{ x: why_cannot_use_bijective_in_cat 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\solution
Pois a definição de função bijectiva (como injectiva e surjectiva) usou
a natureza dos objetos e das setas e não apenas suas propriedades
categóricas.  (Dependeu dos \emph{pontos} dos domínio e do codomínio.)

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mesmo assim, podemos definir o que significa que uma seta é \emph{iso},
numa maneira que acaba sendo equivalente a ser bijectiva quando aplicada
na $\SET$:

%%}}}

%%{{{ df: iso 
\definition iso.
%%%{{{ meta 
\defines
    * iso
    ;;
%%%}}}

Seja $\cat C$ uma categoria e $f : A \to B$ uma das suas setas.
Chamamos a $f$ de \dterm{iso} sse $f$ é invertível:
$$
\text{$f$ iso}
\defiff
\lexists {f' : B \to A} {f'f = \oneof A \mland ff' = \oneof B}.
$$
Nesse caso chamamos os objetos $A,B$ \dterm{isómorfos}
ou \dterm{isomórficos}, algo que denotamos por $A \iso B$.
Como encontramos na~\ref[isomorphic_sets], às vezes
escrevemos $f : A \isoto B$ ou até $f : A \iso B$
para enfatizar que $f$ é um isomorfismo de $A$ para $B$.

%%}}}

%%{{{ df: initial_terminal_null_objects 
\definition iniciais, terminais.
%%%{{{ meta 
\label initial_terminal_null_objects
%%%}}}

Numa categoria $\cat C$, um objeto $S$ é \dterm{inicial} sse
para todo objeto $X$, existe única seta $S \uto X$.
Similarmente, um objeto $T$ é \dterm{terminal} sse
para todo objeto $X$, existe única seta $X \uto T$.
Sinônimos de terminal: \dterm{universal}, \dterm{final}, \dterm{terminador};
sinônimos de inicial: \dterm{couniversal}, \dterm{coterminal}, \dterm{coterminador}.
Um objeto inicial e terminal é chamado \dterm{nulo}.

%%}}}

%%{{{ x: null_unique_up_to_iso 
\exercise.
%%%{{{ meta 
\label null_unique_up_to_iso
%%%}}}

Todos os objetos nulos duma categoria $\cat C$
são isómorfos.
Em outras palavras, se $\cat C$ tem objeto nulo,
ele é \emph{único a menos de isomorfismos}.

%%}}}

%%{{{ x: zero_arrow 
\exercise seta zero.
%%%{{{ meta 
\label zero_arrow
%%%}}}

Seja $Z$ um objeto nulo duma categoria $\cat C$.
Dados quaisquer objetos $A,B$ existe uma única seta
que \dterm{passa pelo} $Z$:
$$
A \uto Z \uto B
$$
(a composição das setas acima)
onde entendemos que os $!$ nas setas indicam que
essa seta é \emph{a única seta} desse objeto para
aquele objeto.

%%}}}

%%{{{ beware: some use terminal for either term 
\beware.
%%%{{{ meta 
%%%}}}

Na literatura às vezes aparece o termo ``terminal'' para
significar tanto ``inicial'' quanto ``final''.
Se o contexto deixa claro qual dos dois é, procure
a definição.

%%}}}

%%{{{ eg: initial_and_terminal_of_SET 
\example.
%%%{{{ meta 
\label initial_and_terminal_of_SET
%%%}}}

A categoria $\SET$ possui iniciais?  Terminais?  Quais?

\solution.
Sim e sim.
Demonstraste isso no~\ref[initial_and_terminal_objects_teaser]:
$\emptyset$ é seu único objeto inicial; e cada singleton é um terminal.

%%}}}

%%{{{ x: initial_terminal_of_INTLEQ 
\exercise.
%%%{{{ meta 
\label initial_terminal_of_INTLEQ
%%%}}}

A categoria $\INTLEQ$ tem iniciais?  Terminais?  Se sim, quais são?

%%}}}

%%{{{ x: initial_terminal_of_INTDIV 
\exercise.
%%%{{{ meta 
\label initial_terminal_of_INTDIV
%%%}}}

A $\INTDIV$?

%%}}}

%%{{{ df: product_in_category 
\definition produto.
%%%{{{ meta 
\label product_in_category
%%%}}}

Sejam $A,B$ objetos numa categoria $\cat C$.
Uma tripla $\tupp{p_1,P,p_2}$ é um \dterm{produto} dos $A,B$, sse:
\tlist:
\li: $A \fromby {p_1} P \toby {p_2} B$;
\li: para toda tripla $\tupp{f_1,F,f_2}$ com $A \fromby {f_1} F \toby {f_2} B$,
existe única seta $!$ que faz o diagrama
$$
\cdopt{sep=1cm}
                                  \| \|                                \| A \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"']  \| \| P
                                        \ar[ur, bend left=15,  "p_1"]
                                        \ar[dr, bend right=15, "p_2"'] \| \\
                                  \| \|                                \| B
\endcd
$$
comutar.
\endtlist
Quando as setas são óbvias usamos apenas o objeto $P$ para representar
a tripla $\tupp{p_1,P,p_2}$.

%%}}}

%%{{{ x: product_is_a_product 
\exercise o produto é um produto.
%%%{{{ meta 
\label product_is_a_product
%%%}}}

Dados conjuntos $A,B$ na $\SET$, demonstre que $A\cross B$
é um produto.
Entenda que literalmente o produto não é o $A \cross B$,
mas a tripla $\tupp{\outl, A \cross B, \outr}$.

%%}}}

%%{{{ x: products_are_not_unique 
\exercise produtos não são únicos.
%%%{{{ meta 
\label products_are_not_unique
%%%}}}

Dados conjuntos $A,B$ na $\SET$, ache um outro conjunto,
além do $A \cross B$ que também é produto dos $A,B$.
Pode achar mais?

%%}}}

%%{{{ x: products_are_unique_up_to_unique_isomorphism 
\exercise são únicos a menos de isomorfismo.
%%%{{{ meta 
\label products_are_unique_up_to_unique_isomorphism
%%%}}}

Demonstre que em qualquer categoria, dois produtos dos mesmos objetos
são necessariamente isómorfos.

%%}}}

%%{{{ remark: another way to design the diagram 
\remark.
%%%{{{ meta 
%%%}}}

Outras maneira para desenhar o diagrama acima são as seguintes:
$$
\cdopt{sep=1cm}
A \| P
     \ar[l, "p_1"']
     \ar[r, "p_2"]             \| B \\
  \| F
     \ar[ul, "f_1"]
     \ar[ur, "f_2"']
     \ar[u, dotted, "\unique"] \|
\endcd
\qqquad
\cdopt{sep=1cm}
  \| P
     \ar[dl, "p_1"']
     \ar[dr, "p_2"]            \|   \\
A \| F
     \ar[l, "f_1"]
     \ar[r, "f_2"']
     \ar[u, dotted, "\unique"] \| B
\endcd
$$
Obviamente é a mesma coisa.  Use qualquer delas, ou qualquer outra
equivalente.

%%}}}

%%{{{ x: does_INTLEQ_have_products 
\exercise.
%%%{{{ meta 
\label does_INTLEQ_have_products
%%%}}}

A categoria $\INTLEQ$ do~\ref[INTLEQ]
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

%%}}}

%%{{{ x: does_INTDIV_have_products 
\exercise.
%%%{{{ meta 
\label does_INTDIV_have_products
%%%}}}

A categoria $\INTDIV$ do~\ref[INTDIV]
tem produtos?  Se sim, dados dois objetos nela $A,B$, qual
seria o seu produto $A\cross B$?

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: cancellable_stereo 
\problem.
%%%{{{ meta 
\label cancellable_stereo
%%%}}}

Sabemos que bijecções tem inversa e logo são canceláveis
pela esquerda, e também canceláveis pela direita.
Mas no~\reftag[let_us_trip_1] da viagem da~\reftag[An_epic_trip]
encontramos mais uma versão de cancelável: ``cancelável stereo'',
que---para motivos óbvios---desconsideramos na discussão.
Então: existe bijecção $f$ e funções $g,h$ tais que
$$
f \of g = h \of f \nimplies g = h\, ?
$$
Se sim mostre um exemplo;
se não, refute mesmo a afirmação.

%%}}}

%%{{{ prob: fcom_respects_jections_pointfree 
\problem.
%%%{{{ meta 
\label fcom_respects_jections_pointfree
%%%}}}

Demonstre que a composição respeita injectividade e sobrejectividade
num estilo point-free (\ref[fcom_respects_jections]).
Ou seja, tu vai ter que usar as ``versões point-free'' dessas noções.

%%}}}

%%{{{ prob: define_constant_function_pointfree 
\problem.
%%%{{{ meta 
\label define_constant_function_pointfree
%%%}}}

Descreva a afirmação <<$f$ é constante>> numa maneira point-free.

\hint
Vai precisar de usar um singleton, $\set{\ast}$, não importa
qual é o seu único membro.

%%}}}

%%{{{ prob: coproduct_in_category 
\problem Definição: coproduto em categoria.
%%%{{{ meta 
\label coproduct_in_category
%%%}}}

Defina formalmente o que significa \dterm{coproduto} numa categoria.

%%}}}

%%{{{ prob: disjunion_is_a_coproduct 
\problem o coproduto é um coproduto ué.
%%%{{{ meta 
\label disjunion_is_a_coproduct
%%%}}}

Demonstre que a \emph{união disjunta} $A \disjunion B$ que encontramos
na~\ref[disjunion_aka_coproduct], conhecida por seus amigos
algebristas e categoristas como \emph{coproduto} e denotado por
$A \coprod B$ e $A \plus B$, merece seu apelido:
``ele'' realmente é um coproduto dos $A,B$ na $\SET$.
Por que o ``ele'' está em aspas?

%%}}}

%%{{{ prob: coproducts_in_INTLEQ_and_INTDIV 
\problem mais coprodutos.
%%%{{{ meta 
\label coproducts_in_INTLEQ_and_INTDIV
%%%}}}

As $\INTLEQ$ e $\INTDIV$ têm coprodutos?
Quais são?

%%}}}

%%{{{ prob: why_pre_collatz_unsafe_diverges_on_6 
\problem.
%%%{{{ meta 
\label why_pre_collatz_unsafe_diverges_on_6
%%%}}}

Calculando para resolver o~\ref[calculate_pre_collatz]
pareceu que o cálculo do $d(6)$ não ia terminar.
Demonstre que realmente não termina.

\hint
Botei esse problema para desenferrujar tuas armas
de teoria dos números (\ref[The_integers]).

\hint
Observe que a seqüência desses valores começa com 6, assim:
$$
6
\leadsto 9
\leadsto 12
\leadsto 15
\leadsto 18
\leadsto 21
\leadsto \dotsb
$$
Mas, somando $+3$ num número par, sabemos já que o próximo
número será ímpar e logo não pode ser potência de $2$,
e logo já sabemos que o próximo passo será somar $+3$ novamente.
Então podemos pular os ímpares acima, e reduzir nosso trabalho
focando nessa seqüência:
$$
6
\leadsto 12
\leadsto 18
\leadsto 24
\leadsto 30
\leadsto 36
\leadsto \dotsb
$$
De $6$ para $12$ ela ``pulou'' a potência (de $2$) $8$.
E de $12$ para $18$ também pulou o $16$.
A próxima potência é o $32$, que nossa seqüência tambem
conseguiu pular ($30\leadsto 36$).
Teu objectivo é \emph{demonstrar} que ela consegue ``pular''
\emph{todas} as potências de $2$.

\hint
Módulo $6$.

\hint
Como parecem \emph{todas} as potências de $2$ ``dentro do módulo~$6$''?

\hint
A seqüência de todas as potências de $2$ é:
$$
1, 2, 4, 8, 16, 32, 64, \dotsc
$$
que, módulo $6$ fica:
$$
1, 2, 4, 2, 4, 2, 4, 2, \dotsc \pmod 6.
$$
Isso é fácil de demonstrar: então demonstre.

\hint
Observe que somando $+6$ num número não o muda ``módulo $6$''.
(Lembre que $6 \cong 0 \pmod 6$.)

\hint
Ou seja: começando com qualquer número $m$ que módulo $6$
é um dos $0,3,5$ sabemos que $d(m)$ \emph{diverge}, ou seja,
o $d(m)$ não é definido.
E se $m$ é $1$ módulo $6$?
A única potência de $2$ que é $1$ módulo $6$ é o próprio $1$,
e logo qualquer outro inteiro que é $1$ módulo $6$ não
pode ser uma potência de $2$.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[velleman: Cap.~5] defina e trata funções
como casos especiais de relações (veja~\ref[Relations]),
algo que não fazemos nesse texto.
Muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.

Um livro excelente para auto-estudo é o~\cite[babylawvere].
\emph{Não pule seus exercícios e problemas!}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Relations 
\chapter Relações.
%%%{{{ meta 
\label Relations
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo estudamos então mais um \emph{tipo} importante para matemática:
a \emph{relação}.
Se pensamos em funções como construtores (ou ``apontadores'') de objetos,
então as relações são \emph{construtores de afirmações}.
Podemos pensar que uma relação é como um \emph{verbo}, ou um \emph{predicado}
duma afirmação.
Como no~\ref[Functions], nosso objectivo é entender \emph{o que são}
as coisas desse tipo (relações) e não como defini-las formalmente como
objetos matemáticos---sobre isso, paciência até o~\ref[Set_theory].
%%}}}

%%{{{ Concept, notation, equality 
\section Conceito, notação, igualdade.
%%%{{{ meta 
%%%}}}

%%{{{ eg: leq_geq_lt_gt_example 
\example.
%%%{{{ meta 
\label leq_geq_lt_gt_example
%%%}}}

Nos números, estamos bem acostumados com as relações de ordem:
$(\leq)$, $(\geq)$, $(<)$, $(>)$.
Nos inteiros já estudamos bastante a relação binária de \wq{divide}
($\dhole \divides \dhole$) e a relação ternária de \wq{congruência modular}
($\dhole \cong \dhole \pmod \dhole$).

%%}}}

%%{{{ eg: mother_parents_love_example 
\example.
%%%{{{ meta 
\label mother_parents_love_example
%%%}}}

No nossa vida, conhecemos várias relações também:
$$
\align
\Mother (x,y)     &\defiff \text{$x$ é a mãe de $y$}\\
\Parents (x,y,z)  &\defiff \text{$x$ e $y$ são os pais de $z$}\\
\Love (x,y)       &\defiff \text{$x$ ama $y$}.
\endalign
$$

%%}}}

%%{{{ Black boxes 
\note Black boxes.
%%%{{{ meta 
\label blackbox_rel
\indexes
    * relação!como black box    see: black box
    ;;
\defines
    * black box!de relação
    ;;
%%%}}}

Visualizamos uma relação $R$ de aridade $n$ como um black box com $n$ entradas
e uma lâmpada que pisca sim ou não (como o black box dum conjunto), dependendo
de se os objetos-entradas $x_1,\dotsc,x_n$ são relacionados pela $R$.
Nesse caso dizemos que os $x_1,\dotsc,x_n$ \dterm{satisfazem} a $R$
e escrevemos
$$
R(x_1,\dotsc,x_n)
$$
para denotar isso e, quando $R$ é binária, em vez de escrever
$R(x,y)$ preferimos usar o $R$ com notação \emph{infixa}:
$$
x \rel R y \syndefiff R(x,y).
$$
Podemos então visualizar uma relação binária assim:
$$
\tikzpicture
\tikzi blackboxrel;
\endtikzpicture
$$
Como nas funções, se suas entradas são rotuladas ou não é questão de
religião: para o Conjuntista o black box parece como esse acima,
e para o Categorista como este abaixo:
$$
\tikzpicture
\tikzi blackboxrelcat;
\endtikzpicture
$$
Ele escreveria $R : \reltype{A,B}$ para deixar claro o tipo dessa relação.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Relações podem relacionar tipos diferentes:

%%}}}

%%{{{ eg: born_author_read_example 
\example.
%%%{{{ meta 
\label born_author_read_example
%%%}}}

Considere as relações seguintes, cujos argumentos não têm o mesmo tipo.
$$
\align
\Born (x,w)       &\defiff \text{$x$ nasceu no ano $w$} \\
\Author (x,k)     &\defiff \text{$x$ escreveu o livro $k$} \\
\Read (x,k)       &\defiff \text{$x$ leu o livro $k$}
\endalign
$$
O primeiro argumento da primeira relação é uma pessoa
mas o segundo é um ano; e as relações $\namedrel{Author}$
e $\namedrel{Read}$ são ambas entre pessoas e livros.

%%}}}

%%{{{ eg: equalities 
\example Igualdades.
%%%{{{ meta 
\indexes
    * aplicação!parcial
    ;;
%%%}}}

Para cada tipo, sua igualdade é uma relação, de aridade $2$.
Nos números naturais por exemplo, se $n,m\in\nats$, $n = m$ é uma afirmação:
\mathcol
n = m &\pseudodefiff \text{os $n$ e $m$ denotam o mesmo número natural}.
\intertext{Similarmente nos conjuntos: se $A,B$ são conjuntos, $A = B$ é a afimação seguinte:}
A = B &\pseudodefiff \text{os $A$ e $B$ denotam o mesmo conjunto}.
\endmathcol
Etc., etc.
Observe que podemos fazer uma \emph{aplicação parcial},
nas relações como fazemos nas funções.
Fixando um objeto de nosso tipo, por exemplo o natural $0\in\nats$
em qualquer um dos dois lados da igualdade (vamos fixar na direita nesse exemplo),
chegamos numa relação de aridade $1$:
\mathcol
\dhole &= 0
\intertext{%
onde \symq{$\dhole$} é um buraco e aplicando a relação para
qualquer $x\in\nats$ chegamos na afirmação
}
x &= 0.
\endmathcol

%%}}}

%%{{{ The type of a relation 
\definition O tipo duma relação.
%%%{{{ meta 
\defines
    * ~R : \reltype{~{A_1,\dotsc,A_n}}  -- $R$ é uma relação entre os conjuntos $A_1,\dotsc,A_n$
    * tipo!duma relação
    ;;
%%%}}}

Com cada relação associamos o seu \dterm{tipo} (pedimos emprestada aqui
a terminologia usada em funções) que é apenas a informação de qual é o tipo
de cada uma das suas entradas.
Escrevemos
$$
R : \reltype{A_1,\dotsc,A_n}
$$
para afirmar que $R$ é uma relação $n$-ária
entre os conjuntos $A_1,\dotsc,A_n$.
As relações dos exemplos~\reftag[mother_parents_love_example]
e~\reftag[born_author_read_example] têm os tipos seguintes:
$$
\xalignat2
\namedrel{Mother}  &: \reltype{\pers, \pers}        & \namedrel{Born}   &: \reltype{\pers, \cal Y} \\
\namedrel{Parents} &: \reltype{\pers, \pers, \pers} & \namedrel{Author} &: \reltype{\pers, \cal B} \\
\namedrel{Love}    &: \reltype{\pers, \pers}        & \namedrel{Read}   &: \reltype{\pers, \cal B}
\endxalignat
$$
onde $\pers, \cal Y, \cal B$ são os conjuntos de pessoas, anos, livros
(respectivamente).

%%}}}

%%{{{ funlike_notation_for_relations 
\notation funcionista.
%%%{{{ meta 
\label funlike_notation_for_relations
%%%}}}

Relações de aridade $2$ são as mais comuns, e usamos certa notação
e terminologia especialmente só para elas.
Nesse caso, podemos ver o conceito de relação como uma generalização de função,
onde nos livramos das duas condições do~\reftag[functionhood_conditions].
Por isso, quando temos uma relação no $\relspace{A,B}$
usamos a frase \wq{relação \emph{de} $A$ \emph{para} $B$}.
Vamos criar uma notação parecida com aquala das funções para dizer que $R$
é uma relação do conjunto $A$ para o conjunto $B$.
Escrevemos, equivalentemente:
$$
R : A \relto B
\qqqquad
R : B \relfrom A
\qqqquad
A \reltoby R B
\qqqquad
B \relfromby R A.
$$
Tudo isso quis dizer apenas que $R$ é uma relação binária entre $A$ e $B$.
Ou seja, tudo isso é sinónimo com o $R : \reltype{A,B}$.

%%}}}

%%{{{ beware: this notation is not standard 
\beware.
%%%{{{ meta 
%%%}}}

A notação ``$\relto$'' definida no~\reftag[funlike_notation_for_relations]
\emph{não} é padrão.

%%}}}

%%{{{ setlike_notation_for_relations 
\notation conjuntista.
%%%{{{ meta 
\label setlike_notation_for_relations
%%%}}}

Vestindo nosso chapéu de conjuntista, abusamos a notação e escrevemos
também $\tupp{x,y} \in R$ para dizer que $R(x,y)$.
E para afirmar que $R : \reltype{A,B}$, escrevemos
até $R \subset A \cross B$.
É importante entender bem neste momento que essas são apenas
\emph{notações}.  Uma relação $R$ \emph{não é} um conjunto,
então nada pertence a ela, e conseqüentemente ela não é
subconjunto de ninguém!
Mesmo assim escrevemos coisas como
$$
\xalignat2
\namedrel{Author}  &\subset \pers \cross \cal B &
\namedrel{Parents} &\subset \pers^3
\intertext{%
\emph{entendendo} como:
}
\namedrel{Author}  &\eqtype \reltype{\pers, \cal B} &
\namedrel{Parents} &\eqtype \reltype{\pers, \pers, \pers}.
\endxalignat
$$
É muito conveniente tratar relações \emph{como se fossem} conjuntos
---mas mais uma vez: relações \emph{não são} conjuntos.

%%}}}

%%{{{ x: repeat_after_me_relations_are_not_sets 
\exercise.
%%%{{{ meta 
\label repeat_after_me_relations_are_not_sets
%%%}}}

Repita!

\hint
Relações \emph{não são}\dots

\solution
Relações \emph{não são} conjuntos!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Cada vez que introduzimos um tipo novo, precisamos definir quando dois
objetos desse tipo são iguais.  Vamos fazer isso agora.
Novamente, vamos optar para identificar relações cujos comportamentos
são indistinguíveis usando apenas as suas interfaces.

%%}}}

%%{{{ df: R_eq_S_bin_on_single_set_case 
\definition igualdade.
%%%{{{ meta 
\label R_eq_S_bin_on_single_set_case
%%%}}}

Sejam $R,S$ relações binárias num conjunto $A$.
Definimos
$$
R=S
\defiff
\lforall {x,y \in A} {x \rel R y \iff x \rel S y}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Principalmente vamos trabalhar com relações binárias definidas
num conjunto só, então a definição de
igualdade~\reftag[R_eq_S_bin_on_single_set_case] que
acabamos de ver nos serve bem.
No~\ref[R_eq_S_bin_on_different_sets_case]
e no~\ref[R_eq_S] tu vai estender essa definição para
os casos mais gerais.

%%}}}

%%{{{ x: R_eq_S_bin_on_different_sets_case 
\exercise igualdade.
%%%{{{ meta 
\label R_eq_S_bin_on_different_sets_case
%%%}}}

Como tu estenderia a~\ref[R_eq_S_bin_on_single_set_case]
para o caso que as $R,S$ não são relações num conjunto só?
Ou seja, tendo relações binárias~$R,S$, a~$R$ de~$A$ para~$B$,
e a~$S$ de~$C$ para~$D$, como tu definirias a igualdade~$R=S$ nesse caso?

\solution
Digamos que $R=S$ sse para todo $x\in A\union C$,
e todo $y \in B\union D$, temos $x \rel R y \iff x \rel S y$.

%%}}}

%%{{{ x: R_eq_S 
\exercise igualdade (agnóstica).
%%%{{{ meta 
\label R_eq_S
%%%}}}

Defina a igualdade para o caso mais geral de relações,
numa maneira ``agnóstica'' como fizemos nas funções (\ref[f_eq_g]).

%%}}}

%%{{{ Intension vs. Extension 
\note Intensão \vs extensão.
%%%{{{ meta 
%%%}}}

Com nossa experiência com \emph{intensão} e \emph{extensão} de
conjuntos~(\reftag[Intension_vs_extension_in_sets]) e de
funções~(\reftag[intension_vs_extension_in_functions]
e~\reftag[programs_vs_functions]), não precisamos esclarecer
muita coisa sobre relações, pois a idéia continua a mesma.

%%}}}

%%{{{ eg: R(n) vs T(n) intensionally and extensionally 
\example.
%%%{{{ meta 
%%%}}}

Considere as relações no $\nats$:
$$
\align
R(n) &\defiff \Prime(n) \mland \Even(n) \\
T(n) &\defiff n = 2.
\endalign
$$
As \emph{intensões} das relações $R$ e $T$ são diferentes,
mas a \emph{extensão} é comum:
$$
\lforall {n\in\nats} {R(n) \iff T(n)}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para capturar a extensão duma relação, definimos o seu gráfico,
na mesma forma que definimos no caso de funções~(\ref[function_graph]).

%%}}}

%%{{{ df: relation_graph 
\definition gráfico.
%%%{{{ meta 
\label relation_graph
\indexes
    * gráfico    see: função
    * gráfico    see: relação
    ;;
\defines
    * \graph{~R}  -- o gráfico da relação $R$
    * relação!gráfico
    * truth set
    ;;
%%%}}}

Dado relação $R : \reltype{A_1,\dotsc,A_n}$,
o \dterm{gráfico da $R$} é o conjunto
$$
\graph R \defeq \setst {\vec a \in A_1\cross\dotsb\cross A_n} {R(\vec a)},
$$
também conhecido como \dterm{truth set} da $R$.

%%}}}

%%{{{ remark: graph R = graph T and setlike notation 
\remark.
%%%{{{ meta 
%%%}}}

Agora temos uma maneira formal para afirmar que $R$ e $T$ tem
a mesma extensão: $\graph R = \graph T$.
E agora a notação conjuntista do~\reftag[setlike_notation_for_relations]
vira literalmente até correta se substituir as relações por seus gráficos.

%%}}}

\endsection
%%}}}

%%{{{ Defining relations 
\section Definindo relações.
%%%{{{ meta 
%%%}}}

%%{{{ with holes 
\note Com buracos.
%%%{{{ meta 
%%%}}}

Começando com uma expressão que denota um \emph{objeto}
e botando $n$ buracos em certas subexpressões dela, criamos
uma \emph{função} de aridade $n$.
Se fizer a mesma coisa numa expressão que denota uma \emph{afirmação},
então criamos uma \emph{relação} de aridade $n$.

%%}}}

%%{{{ eg: john_loves_mary_holes 
\example.
%%%{{{ meta 
%%%}}}

Considere a frase \trel{João ama Maria}.
Criamos assim as relações:
$$
\align
L &\defeq \mtrel{{\thole} ama {\thole}} \\
J &\defeq \mtrel{João ama {\thole}} \\
M &\defeq \mtrel{{\thole} ama Maria}.
\endalign
$$
A primeira é uma relação binária no $\pers$ e as outras duas unárias.
Usando variáveis em vez de buracos, escrevemos:
$$
\align
L(x,y) &\defiff \mtrel{$x$ ama $y$} \\
J(x)   &\defiff \mtrel{João ama $x$} \\
M(x)   &\defiff \mtrel{$x$ ama Maria}.
\endalign
$$

%%}}}

%%{{{ other ways of defining relations 
\note Outras maneiras de definir relações.
%%%{{{ meta 
%%%}}}

Em vez de explicar todas as maneiras seguintes em detalhe,
eu acho que um exemplo é suficiente para cada caso, pois
todas essas maneiras são já bem conhecidas graças à nossa
experiência com funções no~\ref[Functions].

%%}}}

%%{{{ eg: with formulas 
\example formulamente.
%%%{{{ meta 
%%%}}}

Considere os conjuntos $\pers$ de todas as pessoas
e $\cal B$ de todos os livros.
Sejam as relações
$$
\xalignat4
P &: \reltype {\ints}, &
R &: \reltype {\ints, \ints}, &
Q &: \reltype {\pers \times \cal B}, &
M &: \reltype {\ints,\ints,\ints},
\endxalignat
$$
definidas pelas fórmulas:
$$
\align
P(n)     &\defiff \lforall {x,y\in\ints} {xy = n \limplies \paren{|x| = 1 \lor |y| = 1}} \\
R(n,m)   &\defiff \lnot\lexists {k \in \ints} {\Prime(k) \land 2^n < k < 3^m}; \\
Q(p,b)   &\defiff \lexists {b' \in \cal B} {b \neq b' \land \namedrel{Read}(p,b') \land \lexists {a \in \pers} {\namedrel{Author}(a,b) \land \namedrel{Author}(a,b')}} \\
C(a,b,m) &\defiff \lexists {k \in \ints} {mk = a-b}
\endalign
$$
Tente expressar cada uma delas em lingua natural.

%%}}}

%%{{{ eg: relations_with_text_example 
\example Com texto.
%%%{{{ meta 
\label relations_with_text_example
%%%}}}

Sejam as relações $\namedrel{Coauthors}$ (binária, entre pessoas)
e $\namedrel{SameCard}$ (unária, nos conjuntos), definidas pelas:
$$
\align
\namedrel{Coauthors}(x,y) &\defiff \text{$x$ e $y$ já escreveram algum livro juntos}; \\
\namedrel{SameCard}(x)    &\defiff \text{todos os membros de $x$ são conjuntos com a mesma cardinalidade}.
\endalign
$$
Por exempo: $\namedrel{Coauthors}(\textrm{Birkhoff}, \textrm{Mac Lane})$
e $\namedrel{SameCard}(\set{ \set{0,1}, \set{\nats,\set{42}}, \set{\emptyset, \set{\emptyset}}})$.

%%}}}

%%{{{ beware: definitive text 
\beware.
%%%{{{ meta 
%%%}}}

Como sempre, tomamos cuidado quando definimos coisas com texto:
tem que ser uma afirmação definitiva, sem ambigüidades, etc.

%%}}}

%%{{{ x: do_nats_ints_rats_reals_have_the_same_cardinality 
\exercise.
%%%{{{ meta 
\label do_nats_ints_rats_reals_have_the_same_cardinality
%%%}}}

Com a definição de $\namedrel{SameCard}$ do~\ref[relations_with_text_example],
$\namedrel{SameCard}(\set{\nats,\ints,\rats,\reals})$?
Responda com ``sim'' ou ``não'', com uma curtíssima explicação (sem demonstração).

\hint
Lembre a~\ref[naive_cardinality].

\solution
Infelizmente não podemos ainda responder nessa pergunta:
sua resposta é um dos assuntos principais do~\ref[Cantors_paradise].
Paciência!
Se tu respondeste ``sim, pois todos são conjuntos infinitos'',
fizeste bem, pois é uma resposta aceitável \emph{neste momento}.
Só que\dots~não é uma resposta correta!
Aliás, seguindo a~\ref[naive_cardinality] é uma resposta correta sim,
porém vamos ter que redefinir o conceito de cardinalidade logo.

%%}}}

%%{{{ eg: partial_application_in_relations_example 
\example Aplicação parcial.
%%%{{{ meta 
\label partial_application_in_relations_example
\DefRel EqParity
\DefRel Neg
%%%}}}

Sejam as relações $\EqParity$ (binária entre inteiros),
$B$ (unária em pessoas), e $\Neg$ (unária em inteiros), definidas pelas:
$$
\align
\EqParity(a,b) &\defiff a \cong b \pmod 2 \\
B(y)           &\defiff \Coauthors(\mathrm{Birkhoff}, y) \\
\Neg(x)        &\defiff x < 0.
\endalign
$$
Assim temos por exemplo:
$\EqParity(103,11)$ mas não $\EqParity(21,42)$;
$B(\mathrm{Mac~Lane})$ mas não $B(\mathrm{Thanos})$;
$\Neg(-23)$ mas não $\Neg(0)$.

%%}}}

\endsection
%%}}}

%%{{{ Internal diagrams 
\section Diagramas internos.
%%%{{{ meta 
%%%}}}

%%{{{ Relation as a generalization of function 
\note Relação como uma generalização de função.
%%%{{{ meta 
%%%}}}

Um jeito de olhar para uma relação é como uma ``função'' sem as restricções
de totalidade e de determinabilidade que encontramos no~\reftag[functionhood_conditions].
Então: lembra dos conjuntos $A,B$ que encontramos na~\ref[Images_preimages]?
Aqui são duas relações $R,Q$ de $A$ para $B$, determinadas por seus
diagramas internos:
$$
\xxalignat2
&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-R) at (2.5,4) {$R$};
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-b) -- (elem-2);
\draw[->] (elem-c) -- (elem-2);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-6);
\draw[->] (elem-e) -- (elem-5);
\draw[->] (elem-e) -- (elem-2);
\endtikzpicture
&&
\tikzpicture[>=stealth,node distance=0mm,scale=0.8]
\tikzi imgpreimgpointsetsbase;
\draw[-{Latex[length=6pt,open]}]  (0.5,4.5) -- (4.5,4.5);
\node (arrow-Q) at (2.5,4) {$Q$};
\draw[->] (elem-a) -- (elem-1);
\draw[->] (elem-b) -- (elem-1);
\draw[->] (elem-c) -- (elem-1);
\draw[->] (elem-d) -- (elem-3);
\draw[->] (elem-d) -- (elem-4);
\draw[->] (elem-d) -- (elem-5);
\draw[->] (elem-d) -- (elem-6);
\draw[->] (elem-f) -- (elem-6);
\endtikzpicture
\endxxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A situação sobre relações binárias definidas num conjunto $A$
é mais divertida.

%%}}}

%%{{{ Relation as a directed graph 
\note Relação como grafo direcionado.
%%%{{{ meta 
%%%}}}

Seja $A$ um conjunto e $R$ uma relação binária nele.
Podemos representar a $R$ como um \emph{grafo direcionado},
onde, para todos $x,y\in A$, desenhamos uma setinha
$x\longrightarrow y$ sse $x \rel R y$.

%%}}}

%%{{{ eg: first_internal_diagrams_for_rel 
\example.
%%%{{{ meta 
\label first_internal_diagrams_for_rel
%%%}}}

Seja $A = \set{1, 2, 3, 4, 5, 6, 7, 8}$.
Desenhamos os diagramas de três relações binárias no $A$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-5) to                 (elem-7);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] ([shift={(0,.2)}]elem-4) arc (10:290:0.25);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$R$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to                 (elem-2);
\draw[->] (elem-8) to                 (elem-6);
\draw[->] (elem-7) to                 (elem-5);
\draw[->] (elem-5) to                 (elem-8);
\draw[->] (elem-6) to                 (elem-5);
\draw (rellabel) node {$S$};
\endtikzpicture
\quad
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw[->] (elem-1) to [bend left=20]  (elem-2);
\draw[->] (elem-2) to [bend left=20]  (elem-1);
\draw[->] (elem-5) to [bend left=20]  (elem-8);
\draw[->] (elem-8) to [bend left=20]  (elem-5);
\draw[->] (elem-3) to [bend left=20]  (elem-4);
\draw[->] (elem-4) to [bend left=20]  (elem-3);
\draw[->] (elem-7) to [bend left=10]  (elem-6);
\draw[->] (elem-6) to [bend left=10]  (elem-7);
\draw[->] ([shift={(0,.2)}]elem-5) arc (10:290:0.25);
\draw (rellabel) node {$Q$};
\endtikzpicture
$$
Os gráficos delas então são os
$$
\align
\graph R &= \set{ (1,2), (2,1), (4,4), (5,5), (5,7), (5,8), (8,6) } \\
\graph S &= \set{ (1,2), (5,8), (6,5), (7,5), (8,6) } \\
\graph Q &= \set{ (1,2), (2,1), (3,4), (4,3), (5,5), (5,8), (6,7), (7,6), (8,5) }.
\endalign
$$
Mais uma vez, aviso que é comum identificar uma relação $R$ com seu gráfico
$\graph R$, escrevendo por exemplo $R = \set { (1,2), (2,1), \dotsc }$.
Já fez o~\ref[repeat_after_me_relations_are_not_sets], né?

%%}}}

%%{{{ x: empty_and_true_relation 
\exercise.
%%%{{{ meta 
\label empty_and_true_relation
%%%}}}

No mesmo conjunto $A = \set{1,2,3,4,5,6,7,8}$, como parecem os diagramas
das relações $F,T$ com gráficos $\graph F = \emptyset$ e $\graph T = A^2$?

\solution
O diagrama da $F$ parece assim:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi internaldiagramrel0;
\draw (0,-3.0) node {$F$};
\endtikzpicture
$$
E o diagrama da $T$ parece uma bagunça.

%%}}}

%%{{{ x: we_cannot_draw_two_parallel_arrows_on_a_rel_diagram 
\exercise.
%%%{{{ meta 
\label we_cannot_draw_two_parallel_arrows_on_a_rel_diagram
%%%}}}

Para quais relações podemos ter \emph{duas} setinhas do objeto $x$
para o objeto $y$?

\solution
Para nenhuma!
Exatamente como um conjunto não tem noção de \emph{quantas vezes}
um certo objeto pertence nele, uma relação também não tem noção
de \emph{quantas vezes} um certo objeto relaciona com um certo outro.

%%}}}

\endsection
%%}}}

%%{{{ Constructions and operations on relations 
\section Construções e operações em relações.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Todas as relações que consideramos nessa secção serão binárias.

%%}}}

%%{{{ df: ropposite 
\definition.
%%%{{{ meta 
\label ropposite
\defines
    * \rop {~R}  -- a relação oposta da $R$
    * relação!dual
    * relação!oposta
    ;;
\indexes
    * relação!inversa  see: oposta
    ;;
%%%}}}

Seja $R$ uma relação de $A$ para $B$.
Definimos a sua \dterm{relação oposta} (ou \dterm{relação dual})
$\rop R$ de $B$ para $A$ pela:
$$
x \rop R y \defiff y \rel R x.
$$
Também é conhecida como a \emph{relação inversa da $R$},
e a galera que a chama assim usa notação $\rinv R$,
\emph{mas não vamos usá-la nesse texto}---explicarei o porquê
no~\ref[rinv_is_not_inverse].

%%}}}

%%{{{ x: rop_is_an_involution 
\exercise.
%%%{{{ meta 
\label rop_is_an_involution
\defines
    * involução
    ;;
%%%}}}

A operação $\rop{\dhole}$ é uma \dterm{involução}:
$$
\text{para toda relação binária $R$, $\ropp {\rop R} = R$}.
$$

\solution
$
x \ropp{\rop R} y
\iff y \rop R x
\iff x \rel R y
$.

%%}}}

%%{{{ eg: opposite_relations_of_common_orders 
\example.
%%%{{{ meta 
%%%}}}

Nos $\reals$, a relação oposta $(\rop<)$ da $(<)$ é a $(>)$,
e a $(\rop\leq)$ é a $(\geq)$.

%%}}}

%%{{{ Composition 
\note Composição.
%%%{{{ meta 
%%%}}}

Dadas relações compatíveis, podemos formar sua composição
$R\rcom S$ numa forma natural.  Vamos ver uns exemplos
antes de chegar na definição formal.

%%}}}

%%{{{ eg: persons_books_words 
\example.
%%%{{{ meta 
\label persons_books_words
%%%}}}

Sejam os conjuntos $\pers$ de pessoas, $\cal B$ de livros, e $\cal W$ de palavras.
Considere as relações:
$$
\align
\Author(x,y)    &\defiff \text{$x$ é um escritor do livro $y$}\\
\Read(x,y)      &\defiff \text{$x$ leu o livro $y$}\\
\Contains(x,y)  &\defiff \text{a palavra $y$ aparece no livro $x$}
\endalign
$$
Observe que $\Author$ e $\Read$ são relações de $\pers$ para $\cal B$,
e $\Contains$ de $\cal B$ para $\cal W$.
O que seria a relação $\Author\rcom\Read$, o que a $\Author\rcom\Contains$,
e o que a $\Read\rcom\Contains$?
Antes de defini-las, vamos primeiramente pensar se faz sentido compor essas
relações.
Realmente $\Read$ é componível com $\Contains$
(gráças ao $\cal B$ ``no meio'') e
similarmente sobre a $\Author$ com $\Contains$.
Por outro lado, não podemos compor as $\Author$ e $\Read$ em nenhuma
ordem!
Bem, então $\Author\rcom\Contains$ e $\Read\rcom\Contains$ são ambas
relações de $\pers$ para $\cal W$.
Mas quais?
Lembre que para definir uma relação, precisamos determinar
completamente quando dois arbitrários $x,y$ são relacionados pela
relação.
Precisamos então completar as:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{\dots?\dots}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{\dots?\dots}
\endalign
$$
mas como?
\spoiler
Bem, botamos:
$$
\align
x \relp{\Author\rcom\Contains} y &\iff \text{a pessoa $x$ escreveu algum livro que contem a palavra $y$}\\
x \relp{\Read\rcom\Contains}   y &\iff \text{a pessoa $x$ leu algum livro que contem a palavra $y$}
\endalign
$$

%%}}}

%%{{{ x: comparison_of_statements_about_reading_books 
\exercise.
%%%{{{ meta 
\label comparison_of_statements_about_reading_books
%%%}}}

A relação $R$ de $\pers$ para $\cal W$ definida pela
$$
R(p,w) \defiff \text{a pessoa $p$ leu a palavra $w$ num livro}
$$
é a mesma relação com a $\Read\rcom\Contains$?
Em outras palavras:
$$
R \askeq \Read\rcom\Contains
$$

\hint
As afirmações:
$$
\gather
\text{a pessoa $p$ leu a palavra $w$ num livro}\\
\text{a pessoa $p$ leu um livro onde a palavra $w$ aparece}
\endgather
$$
estão afirmando a mesma coisa?

\solution
Não.
Pode ser que a pessoa leu uma palavra $w$ num livro $b$ mas nunca chegou
a ler um livro inteiro que contem a $w$.
Nesse caso temos apenas
$$
p \relp{\Read\rcom\Contains} w \implies p \rel R y
$$
pois se $p$ leu um livro que tem a palavra $w$ com certeza $p$ leu $w$ num livro.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já observamos que não podemos compor as $\Author$ e $\Read$ em nenhuma ordem,
mas podemos aplicar o operador $\rop\dhole$ e compor depois:

%%}}}

%%{{{ x: using_rop_to_compose 
\exercise.
%%%{{{ meta 
\label using_rop_to_compose
%%%}}}

Como definarias as relações $\Author\rcom{\rop\Read}$ e
$\Read\rcom{\rop\Author}$?
São iguais?

\solution
Temos:
$$
\align
x \relp{\Author\rcom{\rop\Read}} y &\iff \text{$x$ escreveu um livro que $y$ leu}\\
x \relp{\Read\rcom{\rop\Author}} y &\iff \text{$x$ leu um livro que $y$ escreveu}.
\endalign
$$
Não são iguais: uma é a oposta da outra.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Segue mais um exemplo, essa vez usando apenas um conjunto---e
logo todas as relações são gratuitamente compatíveis para composição.

%%}}}

%%{{{ x: grandparents_grandchildren_siblings_and_couples_with_children 
\exercise.
%%%{{{ meta 
\label grandparents_grandchildren_siblings_and_couples_with_children
%%%}}}

Considere as relações
$$
\align
\Parent(x,y) &\defiff \text{$x$ é a mãe ou o pai de $y$}\\
\Child(x,y)  &\defiff \text{$x$ é filho ou filha de $y$}.
\endalign
$$
Como tu definirias diretamente as relações seguintes?:
$$
\Parent\rcom\Parent
\qqquad
\Child\rcom\Child
\qqquad
\Parent\rcom\Child
\qqquad
\Child\rcom\Parent
$$

\solution
Temos:
$$
\align
x \relp{\Parent\rcom\Parent} y &\defiff \text{$x$ é um avô ou uma avó de $y$}\\
x \relp{\Child\rcom\Child}   y &\defiff \text{$x$ é um neto ou uma neta de $y$}\\
x \relp{\Parent\rcom\Child}  y &\defiff \text{$x$ e $y$ tem um filho ou uma filha juntos}\\
x \relp{\Child\rcom\Parent}  y &\defiff \text{$x$ e $y$ são irmã(o)s ou a mesma pessoa}
\endalign
$$

%%}}}

%%{{{ Q: How can we define composition of relations? 
\question.
%%%{{{ meta 
%%%}}}

Como tu imaginas o interior desse black box?
$$
\tikzpicture
\tikzi blackboxrelcompb;
\endtikzpicture
$$
E, como tu definarias a composição de relações?

%%}}}

\spoiler

%%{{{ Composition with black boxes 
\note Composição com black boxes.
%%%{{{ meta 
%%%}}}

Talvez as imagens seguintes com black boxes ajudam a pensar numa definição formal.
$$
\tikzpicture
\tikzi blackboxrelcompt;
\endtikzpicture
$$

%%}}}

%%{{{ df: rcompose 
\definition.
%%%{{{ meta 
\label rcompose
\indexes
    * composição!de relações    see: relação
    ;;
\defines
    * relação!composição
    ;;
%%%}}}

Sejam conjuntos $A,B,C$ e as relações~$R$ de~$A$ para~$B$
e~$S$ de~$B$ para~$C$.
Definimos a relação~$R\rcom S$ de~$A$ para~$C$ pela
$$
a\rel{(R \rcom S)}c
\defiff
\text{existe $b \in B$ tal que $a \rel R b$ \& $b \rel S c$}.
$$
Chamamos a $R \rcom S$ a \dterm{composição} da $R$ \emph{com} a $S$.
Quando não existe possibilidade de confusão escrevemos a composição
com várias outras notações.
Todas as expressões seguintes podem ser usadas:
$$
\xalignat5
& R \rcom S &
& R \com  S &
& R \dcom S &
& R \cdot S &
& RS
\endxalignat
$$

%%}}}

%%{{{ beware: RoS_not_SoR 
\beware.
%%%{{{ meta 
\label RoS_not_SoR
%%%}}}

Não existe um consensus para a ordem de escrever os $R,S$
usando o símbolo $\compose$.
Tome cuidado então enquanto lendo a notação $R \com S$,
pois o que um autor escreve como $R \com S$, outro pode escrever
como $S \com R$.
Quando a composição é denotada por $\dcom$ a ordem concorda com nossa:
$$
a\rel{(R \dcom S)}c
\defiff
\text{existe $y \in B$ tal que $a \rel R y$ \& $y \rel S c$}.
$$
Veja também o~\ref[diagrammatic_notation].

%%}}}

%%{{{ prop: associativity_of_rcom 
\property.
%%%{{{ meta 
\label associativity_of_rcom
%%%}}}

Sejam conjuntos $A,B,C,D$ e relações binárias
$R : \reltype{A,B}$,
$S : \reltype{B,C}$, e
$T : \reltype{C,D}$.
Então
$$
(R\rcom S)\rcom T = R \rcom (S\rcom T),
$$
e logo podemos escrever apenas $R\rcom S\rcom T$.

\sketch.
Supomos $a \in A$ e $d\in D$, e mostramos a equivalência
$$
a \relp{(R\rcom S)\rcom T} d
\iff
a \relp{R\rcom (S\rcom T)} d.
$$

\proof.
Demonstrarei em detalhe a
$$
a \relp{(R\rcom S)\rcom T} d
\implies
a \relp{R\rcom (S\rcom T)} d.
$$
A {\rldir} é similar:
\proofsteps
\steptnb {Suponha $a\in A$ e $d\in D$ tais que $a \rel{(RS)T} d$.}
\steptnb {Logo seja $c \in C$ tal que $a \rel {RS} c\fact1 \mland c \rel T d\fact2$.}
\steptby {Logo Seja $b \in B$ tal que $a \rel R b\fact3 \mland b \rel S c\fact4$.} {pelo~\byfact1}
\steptby {Logo $b \rel {ST} d$\fact5.} {pelos~\byfact4 e~\byfact2}
\steptby {Logo $a \rel {R(ST)} d$.}    {pelos~\byfact3 e~\byfact5}
\endproofsteps

%%}}}

%%{{{ x: associativity_of_rcom_nat_lang 
\exercise.
%%%{{{ meta 
\label associativity_of_rcom_nat_lang
%%%}}}

Escreva uma demonstração em linguagem natural da~\ref[associativity_of_rcom].

\solution
\lrdir:
Suponha $a \in A$ e $d \in D$ tais que
$a \rel{((R\rcom S)\rcom T)} d$.
Logo, para algum $c\in C$, temos $a \rel{(R\rcom S)} c$\fact1\ e
$c \rel{T} d$\fact2,
e usando a \byfact1\ ganhamos um $b\in B$ tal que $a \rel{R} b$\fact3
e $b \rel{S} c$\fact4.
Juntando as \byfact4~e~\byfact2 temos $b \rel{(S \rcom T)} d$, e agora
junto com a \byfact3~chegamos em
$a \rel{((R\rcom S)\rcom T)} d$.
\eop
A direção \rldir\ é similar.

%%}}}

%%{{{ x: only_if_incest 
\exercise.
%%%{{{ meta 
\label only_if_incest
%%%}}}

Demonstre ou refute:
$$
\Child\rcom\Parent
\askeq
\Parent\rcom\Child.
$$

\hint
$\Child\rcom\Parent\neq\Parent\rcom\Child$.
Agora refute!

\solution
Temos $\Child\rcom\Parent\neq\Parent\rcom\Child$:
\eop
Tome $x,y\in \pers$ dois irmãos que não têm filhos (juntos).
Logo
$$
x \relp{\Parent\rcom\Child} y
\qqtext{mas não}
x \relp{\Child\rcom\Parent} y.
$$
Demonstramos assim que as duas relações são diferentes.

%%}}}

%%{{{ x: id_of_rcom 
\exercise.
%%%{{{ meta 
\label id_of_rcom
%%%}}}

Considere a $\rcom$ como uma operação binária nas relações binárias num conjunto $A$.
Ela tem \dterm{identidade}?  Ou seja, existe alguma relação binária $I$ no $A$,
tal que
$$
\text{para toda relação $R$ no $A$,}\quad
I \rcom R = R = R \rcom I\,?
$$
Se sim, defina essa relação $I$ e demonstre que realmente é.
Se não, demonstre que não existe.

\hint
Sem pensar, dois candidatos prováveis para considerar seriam a igualdade no $A$
e a relação trivial $\True$ satisfeita por todos os pares de elementos de $A$:
$$
\text{ou}
\knuthcases {
x \rel I y \defiff \True\cr
x \rel I y \defiff x = y
}
$$

\solution
Existe sim: a $I$ é a igualdade $\eqof A$ no $A$.
Vamos mostrar que para todos $a,b \in A$
$$
a \rel R b \iff a \relp{I \rcom R} b.
$$
Tratamos cada direção separadamente.
\eop
\lrdir.
Suponha que $a \rel R b$.
Precisamos mostrar que
existe $w\in A$ tal que $a \rel I w$ e $w \rel R b$.
Tome $w \asseq a$.  Realmente temos $a \rel I a$ (pois $I$ é a igualdade),
e $a \rel R b$ que é nossa hipótese.
\eop
\rldir.
Suponha que $a \relp{I \rcom R} b$.
Logo, existe $w\in A$ tal que $a \rel I w$\fact1 e $w \rel R b$\fact2.
Mas, como $I$ é a igualdade, o único $w$ que satisfaz a~\reffact1 é o próprio~$a$.
Ou seja, $w = a$.
Substituindo na~\byfact2, ganhamos o desejado $a \rel R b$.
\eop
A outra equivalência,
$$
a \rel R b \iff a \relp{R \rcom I} b,
$$
é similar.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo uma operação binária (composição) e sua identidade (\ref[id_of_rcom])
podemos já definir as suas potências.

%%}}}

%%{{{ x: R_exp_n 
\exercise Potências.
%%%{{{ meta 
\label R_exp_n
%%%}}}

Defina formalmente as ``potências'' $R^n$ duma dada relação binária $R$
num conjunto $A$, informalmente definida por:
$$
x \relp{R^n} y \pseudodefiff
x \rel{\Big(\tubrace{R \rcom\dotsb\rcom R}{$n$ vezes}\Big)} y,
$$
válida \emph{para todo $n\in\nats$}.

\hint
Questão: o que precisa achar para tua definição servir para o caso $n=0$ também?

\hint
Resposta: precisa achar o elemento neutro da operação $\rcompose$.
Já fez o~\ref[id_of_rcom], né?

\solution
Definimos:
$$
\align
x \relp{R^0} y     &\defiff x=y \\
x \relp{R^{n+1}} y &\defiff x \relp{R \rcom {R^n}} y
\endalign
$$
ou, diretamente, em estilo ``point-free'':
$$
\align
R^0     &\defeq \Eq \\
R^{n+1} &\defeq R^n \rcom R,
\endalign
$$
onde escrevemos $\Eq$ para a relação $\eqof A$ de igualdade no $A$.

%%}}}

%%{{{ x: operation_with_opposite_does_not_yield_identity 
\exercise.
%%%{{{ meta 
\label operation_with_opposite_does_not_yield_identity
%%%}}}

Demonstre ou refute:
\emph{para toda relação binária $R$ num conjunto $A$,
$R \rcom {\rop R} = \Eq = {\rop R} \rcom R$}.

\hint
\ref[grandparents_grandchildren_siblings_and_couples_with_children].

\hint
\ref[only_if_incest]

\hint
Temos $\Parent = \rop \Child$ (e logo $\Child = \rop \Parent$ também).

\solution
Não, como o contraexemplo do~\ref[only_if_incest] mostra, pois
$$
{\Parent} = {\rop \Child} \qquad\mland\qquad {\Child} = {\rop \Parent}.
$$

%%}}}

%%{{{ x: describe_coauthors_in_terms_of_author 
\exercise.
%%%{{{ meta 
\label describe_coauthors_in_terms_of_author
%%%}}}

Descreva a $\namedrel{Coauthors}$ do \ref[relations_with_text_example]
em termos da $\namedrel{Author}$.

\solution
Considerando que um escritor é coescritor com ele mesmo,
$$
\namedrel{Coauthors} = \namedrel{Author}\rcom\rop{\namedrel{Author}}.
$$

%%}}}

%%{{{ beware: rinv_is_not_inverse 
\beware A inversa não é inversa.
%%%{{{ meta 
\label rinv_is_not_inverse
%%%}}}

Depois dos exercícios~\reftag[operation_with_opposite_does_not_yield_identity]
e~\reftag[describe_coauthors_in_terms_of_author], deve ser claro porque eu
preferi chamar a $\rop R$ a relação \emph{oposta} da $R$, e usar essa notação
em vez de $\rinv R$ e o nome \emph{inversa}.
(Que também usamos pois são os mais comuns!)
Se usar a notação $\rinv R$, cuidado para não confundir que
$R \rcom {\rinv R} = \Eq = {\rinv R} \rcom R$,
pois em geral isso não é verdade.
Ou seja: a relação ``inversa'' $\rinv R$,
\emph{não é a $\rcom$-inversa} da $R$!

%%}}}

%%{{{ x: rop_of_rcompose 
\exercise Some stuff.
%%%{{{ meta 
\label rop_of_rcompose
%%%}}}

Sejam $R,S$ relações binárias tais que a $R\rcom S$ é definida.
Descreva a $\ropp{R\rcom S}$ em termos das $\rop R$ e $\rop S$
e demonstre tua afirmação.

\hint
${\ropp{R \rcom S}} = {\rop S \rcom \rop R}$.
Demonstre!

\solution
Vou demonstrar que $\ropp{R \rcom S} = \rop S \rcom \rop R$.
Calculo:
\compute
x \ropp{RS} y
&\iff y \rel{RS} x                                              \by {def.~$\ropp{RS}$} \\
&\iff \text{existe $w$ tal que $y \rel R w \mland w \rel S x$}  \by {def.~$RS$} \\
&\iff \text{existe $w$ tal que $w \rop R y \mland x \rop S w$}  \by {def.~$\rop R$ e~$\rop S$} \\
&\iff \text{existe $w$ tal que $x \rop S w \mland w \rop R y$}  \\
&\iff x \rel{{\rop S}{\rop R}} y.                               \by {def.~${\rop S}{\rop R}$} \\
\endcompute

%%}}}

%%{{{ df: union_and_inter_of_rels 
\definition união; intersecção.
%%%{{{ meta 
\label union_and_inter_of_rels
%%%}}}

Sejam $R,S\subset A\times B$ relações binárias.
Definimos as relações $R\union S$ e $R\inter S$ no $\relspace{A,B}$
pelas
$$
\align
x \relp{R \union S} y &\defiff x \rel R y \mlor  x \rel S y \\
x \relp{R \inter S} y &\defiff x \rel R y \mland x \rel S y.
\endalign
$$
Observe que, identificando as relações com seus gráficos,
as $R \union S$ e $R \inter S$ acabam sendo a união
e intersecção deles mesmo:
$$
\align
\graphP {R \union S} &= \graph R \union \graph S \\
\graphP {R \inter S} &= \graph R \inter \graph S.
\endalign
$$
Claramente generalizamos para famílias de relações $\scr R$,
e assim temos as relações
$$
\xalignat2
\tsize \Union \scr R &: \reltype{A,B} &
\tsize x \relp{\Union \scr R} y & \defiff \lexists {R \in \scr R} {x \rel R y} \\
\tsize \Inter \scr R &: \reltype{A,B} &
\tsize x \relp{\Inter \scr R} y & \defiff \lforall {R \in \scr R} {x \rel R y}.
\endxalignat
$$

%%}}}

%%{{{ eg: union_and_inter_of_orders 
\example.
%%%{{{ meta 
%%%}}}

Nos reais, a $(<) \union (=)$ é a relação $(\leq)$,
e a $(\leq) \inter (\geq)$ é a relação $(=)$.
Substituindo o \wq{é a relação} com o símbolo \symq{$=$} que usamos
normalmente a gente acabaria escrevendo essas coisas horrorosas:
$$
\xalignat2
\mathord{\mathop{<}\union\mathop{=}} &= \mathord{\leq} &
\mathord{\mathop{\leq}\inter\mathop{\geq}} &= \mathord{=}.
\intertext{%
Isso fica \emph{muito} esquisito no olho para parsear;
botando parenteses ajuda:
}
\paren{\mathord{\paren{\mathop{<}}\union\paren{\mathop{=}}}} &= \paren{\mathord{\leq}} &
\paren{\mathord{\paren{\mathop{\leq}}\inter\paren{\mathop{\geq}}}} &= \paren{\mathord{=}}.
\endxalignat
$$
Tente sempre escrever na maneira mais legível e entendível.

%%}}}

\endsection
%%}}}

%%{{{ Properties of relations 
\section Propriedades de relações.
%%%{{{ meta 
%%%}}}

%%{{{ intro 
\secintro
Aqui aumentamos nossa terminologia, identificando certas propriedades
interessantes que uma relação binária $R$ no $X$ pode ter.
%%}}}

%%{{{ Reflection 
\note Reflexão.
%%%{{{ meta 
\label reflexion_terminology
\defines
    * relação!irreflexiva
    * relação!reflexiva
    ;;
%%%}}}

Olhamos como cada elemento do $X$ relaciona com ele mesmo.
Dois casos notáveis aparecem:
(i) pode ser que para todo $x$ temos $x\rel R x$;
(ii) pode ser que para nenhum $x$ temos $x\rel R x$.
No primeiro caso, chamamos $R$ \dterm{reflexiva}; no segundo, \dterm{irreflexiva}.
Observe que ``irreflexiva'' não significa ``não reflexiva'', etc:
$$
\alignat 2
\text{$R$ é reflexiva}      &\iff \phantom\lnot\forall x R(x,x)        &&\iff \lnot\exists x \lnot R(x,x)\\
\text{$R$ não é reflexiva}  &\iff \lnot\forall x R(x,x)                &&\iff \phantom\lnot\exists x \lnot R(x,x)\\
\text{$R$ é irreflexiva}    &\iff \phantom\lnot\forall x \lnot R(x,x)  &&\iff \lnot\exists x R(x,x)\\
\text{$R$ não é irreflexiva}&\iff \lnot\forall x \lnot R(x,x)          &&\iff \phantom\lnot\exists x R(x,x)
\endalignat
$$
onde os quantificadores quantificam sobre o $X$.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

As relações $(=)$, $(\leq)$, $(\geq)$, nos números e $(=)$, $(\subset)$, $(\supset)$ nos conjuntos são todas reflexivas.
Também reflexivas são as relações
\trel{\thole\ nasceu no mesmo pais que \thole},
\trel{\thole\ tem o mesmo primeiro nome com \thole}, etc.,
definidas entre pessoas.
Típicos exemplos de irreflexivas são as $(\neq)$, $(<)$, $(>)$, $(\psubset)$, $(\supsetneq)$,
\trel{\thole\ é mais baixo que \thole},
\trel{\thole\ e \thole\ nunca estiveram em distância de 2 metros entre si},
etc.

%%}}}

%%{{{ Symmetry 
\note Simetria.
%%%{{{ meta 
\label symmetry_terminology
\defines
    * relação!antissimétrica
    * relação!assimétrica
    * relação!simétrica
    ;;
%%%}}}

Agora examinamos a relação $R$ com respeito à ordem dos seus argumentos.
Novamente, certos casos notáveis aparecem:
(i) $R$ pode comportar sempre no mesmo jeito independente da ordem dos seus argumentos; nesse caso a chamamos \dterm{simétrica}.
(ii) O $R$-relacionamento dum objeto $x$ com outro $y$ pode garantir que o $y$ não esta $R$-relacionado com o $x$; a chamamos \dterm{assimétrica}.
(iii) O único caso onde a $R$ relaciona os mesmos argumentos com as duas possíveis órdens, é quando os dois argumentos são iguais; chamamos a $R$ \dterm{antissimétrica}.

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Simétricas:
$(=)$, $(\neq)$,
\trel{\thole\ e \thole\ são irmãos},
\trel{\thole\ e \thole\ são cidades do mesmo país},
etc.
\eop\noi
Asimétricas:
$(<)$, $(\psubset)$, $(>)$, $(\supsetneq)$,
\trel{\thole\ deve dinheiro para \thole},
\trel{\thole\ está andando na mesma direção e no lado esquerdo de \thole},
\trel{\thole\ é a mãe de \thole},
etc.
\eop\noi
Antissimétricas:
$(\leq)$, $(\subset)$, $(\geq)$, $(\supset)$, $(=)$,
\trel{a palavra \thole\ aparece, mas não depois da palavra \thole\ no dicionário},
etc.

%%}}}

%%{{{ x: not_symmetric_notequiv_asymmetric 
\exercise.
%%%{{{ meta 
\label not_symmetric_notequiv_asymmetric
%%%}}}

Verifique que ``não simétrica'' não significa nem ``assimétrica''
nem ``antissimétrica'', escrevendo todas as fórmulas envolvidas e suas negações,
como no~\reftag[reflexion_terminology].

%%}}}

%%{{{ x: check_reflexion_and_symmetry 
\exercise.
%%%{{{ meta 
\label check_reflexion_and_symmetry
%%%}}}

Decida a ``reflexão'' e a ``simetria'' das relações seguintes:
$$
\align
R(A, B) &\letiff \text{os conjuntos $A$ e $B$ são disjuntos}\\
S(A, B) &\letiff |A\setminus B| > 1\\
T(A, B) &\letiff A\symdiff B \neq \emptyset.
\endalign
$$
Isso quis dizer: para cada uma dessas relações, decida se ela é:
reflexiva, irreflexiva, simétrica, assimétrica, antissimétrica.

%%}}}

%%{{{ x: asymmetric_implies_irreflexive 
\exercise.
%%%{{{ meta 
\label asymmetric_implies_irreflexive
%%%}}}

Mostre que:
$$
\text{$R$ assimétrica} \implies \text{$R$ irreflexiva}.
$$

\hint
Contrapositivo.

\solution
Mostramos o contrapositivo.
Suponha que $R$ não é irreflexiva.
Então existe $s$ com $R(s,s)$,
e logo é impossível que a $R$ seja assimétrica,
pois achamos $x$ e $y$ ($x,y\asseq s$) que satisfazem ambas
$R(x,y)$ e $R(y,x)$.

%%}}}

%%{{{ x: asymetric_implies_antisymmetric 
\exercise.
%%%{{{ meta 
\label asymetric_implies_antisymmetric
%%%}}}

Uma das duas direções abaixo é válida:
$$
\text{$R$ assimétrica} \askiff \text{$R$ antissimétrica}.
$$
Demonstre-a, e mostre que a oposta não é.

\hint
Como uma relação assimétrica poderia não ser antissimétrica?
(O que significa ``não ser antissimétrica''?)

\hint
Procure contraexemplo nos exemplos típicos de relação antissimétrica.

\solution
Para demonstrar a \lrdir, observe que $R$ não é antissimétrica
sse existem $x$ e $y$ tais que:
$$
\underbrace{R(x,y)
\land
R(y,x)}_{\text{impossível por assimetria}}
{}\land\ \ 
{x\neq y}.
$$
Para refutar a \rldir, considere o contraexemplo da antissimétrica $(\leq)$
no $\nats$, que não é assimétrica, pois é reflexiva.

%%}}}

%%{{{ x: rop_of_symmetric 
\exercise.
%%%{{{ meta 
\label rop_of_symmetric
%%%}}}

Seja $R : \reltype{X,X}$.
Logo
$$
\text{$R$ simétrica}
\iff
R = \rop R.
$$

\solution
\proofpart {\lrdir.}
Suponha $R$ simétrica.
\compute
x \rel R y
&\implies y \rel R x  \by {hipótese} \\
&\implies x \rop R y. \by {def.~$\rop R$} \\
\endcompute
\proofpart {\rldir.}
Suponha $R = \rop R$.
\compute
x \rel R y
&\implies y \rop R x  \by {def.~$\rop R$} \\
&\implies y \rel R x. \by {hipótese} \\
\endcompute

%%}}}

%%{{{ Transitions 
\note Transições.
%%%{{{ meta 
\defines
    * relação!circular
    * relação!left-euclidean
    * relação!right-euclidean
    * relação!transitiva
    ;;
%%%}}}

Às vezes queremos garantir a existência de alguma seta dadas duas ou mais setas.
Suponha que $x\rel R y$ e $y \rel R z$.
Se isso garanta que $x\rel R z$ chamamos a $R$ \dterm{transitiva};
e se isso garanta que $z \rel R x$, \dterm{circular}.
Suponha agora que temos dois objetos cada um relacionado com um terceiro.
Se isso já é suficiente para garantir que eles também são relacionados,
chamamos a relação \dterm{left-euclidean}.
Similarmente, se a relação de um objeto com dois outros garanta que os outros
também relacionam entre si, chamamos a relação \dterm{right-euclidean}.

%%}}}

%%{{{ Why the names -euclidean? 
\note Por que ``euclidean''?.
%%%{{{ meta 
\credits
    * Euclid
    ;;
%%%}}}

O primeiro axioma de Euclides nos seus \emph{Elementos} (\cite[elements]) é:
\emph{coisas iguais com outra coisa, são iguais entre si também}.
Podemos visualizar isso tanto como
<<$a=c$ e $b=c$ implica $a=b$>>
(left-euclidean pois a conclusão aconteceu no lado esquerdo); 
quanto como
<<$a=b$ e $a=c$ implica $b=c$>>
(right-euclidean pois a conclusão aconteceu no lado direito).

%%}}}

%%{{{ Totalities 
\note Totalidades.
%%%{{{ meta 
\defines
    * relação!total
    * relação!tricotômica
    ;;
%%%}}}

Tem duas noções onde uma relação pode ``dominar'' um conjunto, no sentido
de ``opiniar'' sobre quaisquer $x,y$ nele.
A primeira só usa a relação em questão $R$ mesmo:
dizemos que $R$ é \dterm{total} sse quaisquer $x,y$ são relacionados em pelo
menos uma ordem: $x \rel R y$ ou $y \rel R x$.
A segunda usa a ajuda da igualdade:
dizemos que $R$ é \dterm{tricotômica} sse para quaisquer $x,y$ exatamente
uma das três possibilidades é válida: $x \rel R y$; $y \rel R x$; $x = y$.

%%}}}

%%{{{ Glossary: relations_glossary 
\note Glossário.
%%%{{{ meta 
\label relations_glossary
%%%}}}

Resumimos aqui as propriedades que encontramos.
Seja $X$ conjunto e $R$ uma relação binária nele.
Definimos as seguintes propriedades:
\mathcall
& x \rel R x                                           \called {reflexiva} \\
& x \not\rel R x                                       \called {irreflexiva} \\
& x \rel R y  \implies  y \rel R x                     \called {simétrica} \\
& x \rel R y  \implies  y \not\rel R x                 \called {assimétrica} \\
& x \rel R y  \mland y \rel R x \implies x = y         \called {antissimétrica} \\
& x \rel R y  \mland  y \rel R z \implies x \rel R z   \called {transitiva} \\
& x \rel R y  \mland  y \rel R z \implies z \rel R x   \called {circular} \\
& x \rel R y  \mland  x \rel R z \implies y \rel R z   \called {right-euclidean} \\
& x \rel R z  \mland  y \rel R z \implies x \rel R y   \called {left-euclidean} \\
& x \rel R y  \mlor   y \rel R x                       \called {total} \\
& \text{exatamente uma das:
        $x \rel R y$; $y \rel R x$; $x = y$}           \called {tricotômica} \\
\endmathcall
Para o caso mais geral onde $R$ é uma relação binária de $X$ para $Y$, temos:
\mathcall
&  \pforall {x \in X} \lexists {y \in Y} {x \rel R y}  \called {left-total} \\
&  \pforall {y \in Y} \lexists {x \in X} {x \rel R y}  \called {right-total ou surjectiva} \\
&  y \rel R x  \mland  z \rel R x \implies y = z       \called {left-unique ou injectiva} \\
&  x \rel R y  \mland  x \rel R z \implies y = z       \called {right-unique ou funcional} \\
\endmathcall

%%}}}

%%{{{ x: investigate_rel_properties_of_three_diags 
\exercise.
%%%{{{ meta 
\label investigate_rel_properties_of_three_diags
%%%}}}

Para cada uma das relações $R,S,Q,F,T$ do~\reftag[first_internal_diagrams_for_rel]
e do~\ref[empty_and_true_relation] decida se ela têm ou não, cada uma das
propriedades do glossário no~\reftag[relations_glossary].

\hint
Cuidado: nas propriedades que acabam ser implicações, as variáveis que aparecem
nas suas premissas não denotam obrigatoriamente objetos distintos!

%%}}}

%%{{{ prop: wrong_property_of_sym_and_trans_implies_refl 
\proposition.
%%%{{{ meta 
\label wrong_property_of_sym_and_trans_implies_refl
%%%}}}

Seja $X\neq\emptyset$ e $\sim$ uma relação no $X$.
Se $\sim$ é simétrica e transitiva, então ela é reflexiva.

\wrongproof.
Como ela é simétrica, de $x\sim y$ concluimos que $y\sim x$ também.
E agora usando a transitividade, de $x\sim y$ e $y\sim x$, concluimos a $x\sim x$,
que mostra que $\sim$ é reflexiva também.

%%}}}

%%{{{ x: find the error and prove that the proposition is false 
\exercise.
%%%{{{ meta 
%%%}}}

Ache o erro na demonstração acima e \emph{demonstre} que a proposição é falsa!

%%}}}

%%{{{ remark: conventions_for_internal_diagrams_of_rel 
\remark Convenções para diagramas internos.
%%%{{{ meta 
\label conventions_for_internal_diagrams_of_rel
\indexes
    * Hasse!diagrama
    ;;
\credits
    * Hasse
    ;;
%%%}}}

Quando queremos desenhar o diagrama duma relação que
sabemos que tem uma certa propriedade, podemos preguiçar
e não desenhar todas as suas setas.
\crtabproofcase {Reflexiva:}
não precisamos botar nenhuma das setinhas-redemoinhos,
pois graças à reflexividade são todas implicitas.
\crtabproofcase {Simétrica:}
não precisamos botar cabeças nas setas, pois para
cada seta já é garantida a sua seta-oposta, então
botamos apenas uma linha entre dois objetos e já
entendemos que existem as setas das duas direções
entre si.
\crtabproofcase {Transitiva:}
não precisamos desenhar setas entre objetos se já
existe um caminho entre eles usando outras setas
já desenhadas.
\crtabproofcase {Relação de equivalência:}
não precisamos desenhar nem linhas entre os objetos
que relacionam; apenas desenhar regiões por volta
de todos os relacionados, algo que vai virar óbvio
na~\ref[Quotient_set].
\crtabproofcase {Relação de ordem:}
desenhamos diagramas de~Hasse, que vamos
encontrar depois (pouco
na~\ref[hasse_diagrams_first_encounter] e muito
no~\ref[Posets_Lattices]).

%%}}}

\endsection
%%}}}

%%{{{ Closures 
\section Fechos.
%%%{{{ meta 
\label Closures
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Antes de definir formalmente o conceito importante de fechos,
começamos com uns exemplos ilustrativos para os três fechos mais comuns:
reflexivo, simétrico, transitivo.
A idéia é sempre a mesma, e vamos descrevê-la como um algoritmo.

%%}}}

%%{{{ The idea 
\note A idéia.
%%%{{{ meta 
\label Closure_informal_bottom_up
%%%}}}

Começamos com uma relação $R$, e fixamos uma propriedade
desejada (por exemplo, a transitividade).
Vamos construir uma nova relação $\bar R$, que chamamos o \dterm{fecho}
da $R$ pela propriedade escolhida.
Pense na $R$ como o seu diagrama interno, com suas setinhas.
Primeiramente nós nos perguntamos:
<<a relação já tem essa propriedade?>>
Caso que sim, não precisamos fazer nada, a relação que temos é
o fecho $\bar R$ que queríamos construir.
Caso que não, quis dizer que tem setinhas que
\emph{deveriam estar} no diagrama, mas não estão.
(Essas setinhas são as testemunhas que refutam a nossa propriedade.)
Vamos adicioná-las na nossa relação.
E agora voltamos a perguntar a mesma pergunta,
e continuar no mesmo jeito, até finalmente chegar numa
relação $\bar R$ que realmente satisfaz a propriedade escolhida.
Essa relação $\bar R$ é o fecho da $R$ a respeito dessa propriedade.

%%}}}

%%{{{ eg: reflexive_closure_example 
\example Fecho reflexivo.
%%%{{{ meta 
\label reflexive_closure_example
%%%}}}

Seja $R$ a relação no $A$ com o diagrama seguinte:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Qual é o fecho reflexivo dela?
Bem, primeiramente nós nos perguntamos:
será que a relação já é reflexiva?
Ela não é.
Identificamos então as setinhas-testemunhas desse fato:
são as $(1,1)$, $(3,3)$, $(7,7)$, e $(8,8)$.
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\node[color=blue] (elem-1b) at (elem-1) {$1$};
\node[color=blue] (elem-3b) at (elem-3) {$3$};
\node[color=blue] (elem-7b) at (elem-7) {$7$};
\node[color=blue] (elem-8b) at (elem-8) {$8$};
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->, color=red, ultra thick, dotted] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
As adicionamos na relação e chegamos em:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->] ([shift={(0,0.2)}]elem-3) arc (10:290:0.25);
\draw[->] ([shift={(0,0.2)}]elem-7) arc (10:290:0.25);
\draw[->] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\draw[->] ([shift={(-.2,0)}]elem-8) arc (80:350:0.25);
\endtikzpicture
$$
\dots e perguntamos a mesma pergunta:
será que ela é reflexiva?
Agora é sim!
Essa relação então é o \emph{fecho reflexivo} da $R$.

%%}}}

%%{{{ eg: symmetric_closure_example 
\example Fecho simétrico.
%%%{{{ meta 
\label symmetric_closure_example
%%%}}}

Vamos calcular agora o fecho simétrico da mesma relação $R$
do~\ref[reflexive_closure_example]:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Será que ela já é simétrica?
Ela não é por causa das três setinhas seguintes,
onde para cada uma mostro em azul a setinha-razão que obriga
a setinha-faltante (em vermelho) ser adicionada:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to                 (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-6) to [bend left=30]  (elem-8);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-6) to                 (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-7) to [bend left=15]  (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to                 (elem-8);
\draw[->, color=red , ultra thick, dotted] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
\endxxalignat
$$
Então adicionamos todas essas setinhas necessárias:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->            ] (elem-8) to                 (elem-6);
\draw[->            ] (elem-6) to                 (elem-7);
\draw[->            ] (elem-5) to                 (elem-8);
\draw[->            ] (elem-6) to [bend left=30]  (elem-8);
\draw[->            ] (elem-7) to [bend left=15]  (elem-6);
\draw[->            ] (elem-8) to [bend right=30] (elem-5);
\endtikzpicture
$$
Agora perguntamos novamente: a relação é simétrica?
Ela é sim, então paramos aqui.
A relação criada é o \emph{fecho simétrico} da $R$.

%%}}}

%%{{{ eg: transitive_closure_example 
\example Fecho transitivo.
%%%{{{ meta 
\label transitive_closure_example
%%%}}}

Para ser original, seja $R$ a mesma relação dos
exemplos~\reftag[reflexive_closure_example]--\reftag[symmetric_closure_example]:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\endtikzpicture
$$
Essa vez vamos calcular o fecho transitivo dela, então começamos com a pergunta:
será que a relação já é transitiva?
Não é!
Então precisamos achar todas as setinhas que deveriam estar nela e não estão
e adicioná-las:
$$
\xxalignat3
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-6);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-8) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosures0;
\draw[->, color=blue, ultra thick        ] (elem-1) to [bend left=20] (elem-2);
\draw[->, color=blue, ultra thick        ] (elem-2) to [bend left=20] (elem-1);
\draw[->, color=red , ultra thick, dotted] ([shift={(0,-.2)}]elem-1) arc (-170:120:0.25);
\endtikzpicture
\endxxalignat
$$
Adicionando todas essas setas necessárias, chegamos na relação:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\endtikzpicture
$$
E perguntamos: ela é transitiva?
\emph{Ainda não!}
Pois, as novas setinhas que adicionamos criaram novos caminhos que
obrigam mais uma setinha estar na relação (dois caminhos diferentes
explicam a adição dessa mesma setinha nesse caso):
$$
\xalignat2
&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-6);
\draw[->, color=blue, ultra thick        ] (elem-6) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
&&
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->, color=blue, ultra thick        ] (elem-5) to (elem-8);
\draw[->, color=blue, ultra thick        ] (elem-8) to (elem-7);
\draw[->, color=red , ultra thick, dotted] (elem-5) to (elem-7);
\endtikzpicture
\endxalignat
$$
Adicionamos então a setinha $(5,7)$:
$$
\tikzpicture[>=stealth, scale=0.84]
\tikzi reldiagclosurest1;
\draw[->] (elem-5) to (elem-7);
\endtikzpicture
$$
Ela é transitiva agora?  Sim, finalmente!
Então esse é o \emph{fecho transitivo} da $R$.

%%}}}

%%{{{ pseudodf: fecho_pseudodefinition 
\pseudodefinition.
%%%{{{ meta 
\label closure_pseudodefinition
\defines
    * fecho!de relação
    ;;
%%%}}}

Seja $R$ uma relação binária num conjunto $A$,
e fixe uma propriedade \emph{razoável}
daquelas que aparecem no~glossário~\reftag[relations_glossary].
Definimos o fecho da $R$ pela propriedade para ser a relação que criamos se
\emph{adicionar} numa maneira \emph{justa} todas as setinhas \emph{necessárias}
no diagrama da $R$ até ela virar uma relação com a propriedade
desejada.

%%}}}

%%{{{ remark: we may add but never remove 
\remark Podemos botar mas não retirar.
%%%{{{ meta 
%%%}}}

Note então que o fecho $\bar R$ duma relação $R$ tem todas
as setinhas que $R$ tem, e possivelmente mais ainda.
Ou seja, temos
$$
\graph R \subset \graph \bar R
$$
para qualquer fecho escolhido.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na~\ref[closure_pseudodefinition] enfatizei as palavras \wq{razoável},
\wq{justa} e \wq{necessárias}.
Vamos ver o que cada uma delas quis dizer mesmo.

%%}}}

%%{{{ Necessary arrows 
\note Setinhas necessárias.
%%%{{{ meta 
%%%}}}

\wq{Adicionar apenas as setinhas \emph{necessárias}} quis dizer que
a falta de cada uma dessas setinhas é uma razão que nossa relação não
satisfaz a propriedade escolhida.
Caso contrário não vamos adiciona-la, \emph{mesmo se sua adição não afeta nada}.

%%}}}

%%{{{ Fair way 
\note Maneira justa.
%%%{{{ meta 
%%%}}}

\wq{Adicionar setinhas numa maneira \emph{justa}} quis dizer que em
nenhum ponto vamos ter que escolher entre duas ou mais setinhas-testemunhas
\emph{tais que a adição de apenas uma} seria suficiente para satisfazer
a propriedade.
Imagine que nesse caso, nossa escolha não seria justa para a setinha
não-escolhida (ou para a setinha escolhida, dependendo o ponto de vista).
Formar o fecho duma relação deve ser uma operação, e sendo isso deve
ser determinística.
Imagina então que temos uma propriedade estranha, dizendo que:
$$
x \rel R x \mland y \rel R y \implies x \rel R y \mlor y \rel R x.
$$
(Nem adianta tentar achar um nome razoável para essa propriedade.)
Agora, a relação $R$ no $\nats$ com $\graph R = \set{ (0,0), (1,1) }$
claramente não satisfaz essa propriedade.
Tentando formar o fecho através dessa propriedade, já na primeira etapa,
temos duas ``setinhas-testemunhas'' que podemos escolher para adicionar:
a $(0,1)$ e a $(1,0)$.  Graças à restricção de ``necessárias'', não podemos
adicionar ambas, pois assim que adicionar uma, a propriedade já é satisfeita.
Por outro lado, não podemos escolher uma das duas numa maneira justa:
as duas servem igualmente bem.
\emph{Para esse tipo de propriedade então não podemos definir um fecho.}
Espero que isso explica também o que eu quis dizer com a palavra \wq{razoável}.
O~\ref[unreasonable_properties_for_closures_of_relations] esclarecerá
isso ainda mais.

%%}}}

%%{{{ x: unreasonable_properties_for_closures_of_relations 
\exercise.
%%%{{{ meta 
\label unreasonable_properties_for_closures_of_relations
%%%}}}

Por que não falamos de fecho total, irreflexivo, e assimétrico?

\hint
Seja justo.

\solution
Fechando através da totalidade a gente deveria tomar umas decisões
injustas.
Fechando através da irreflexividade a gente deveria retirar setinhas
quando fechando podemos apenas adicionar.
Fechando através da assimetria, a gente deveria retirar setinhas
também e inclusive isso seria numa maneira injusta:
dadas setinhas $(0,1)$ e $(1,0)$ qual das duas tu vai escolher para retirar?

%%}}}

%%{{{ x: order_of_closures_matters 
\exercise.
%%%{{{ meta 
\label order_of_closures_matters
%%%}}}

Seja $R$ relação num conjunto $A$.
Podemos concluir alguma das afirmações seguintes?:
% TODO: fix reflabs
\tlist:
\li (i):   $t(r(R)) \askeq r(t(R))$
\li (ii):  $t(s(R)) \askeq s(t(R))$
\li (iii): $r(s(R)) \askeq s(r(R))$
\endtlist
Aqui $r, s, t$ são os fechos reflexivo, simétrico, transitivo respectivamente.

\hint
Use diagramas internos.

\hint
Tente achar um contraexemplo para o (ii).
Qual a dificuldade de achar contraexemplo para o (i) e qual para o (iii)?

%%}}}

%%{{{ Q: How would you define the reflexive and symmetric closures of R? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias formalmente o fecho reflexivo e o fecho simétrico duma relação $R$?

%%}}}

\spoiler

%%{{{ df: rclosure 
\definition Fecho reflexivo.
%%%{{{ meta 
\label rclosure
\defines
    * \rclo {~R}  -- o fecho reflexivo da $R$
    * \rclosure {~R}  -- o fecho reflexivo da $R$
    * fecho!reflexivo
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos a relação $\rclosure R$ pela
$$
x \rclosure R y \defiff x \rel R y \mlor x = y
$$
Chamamos a $\rclosure R$ o \dterm{fecho reflexivo} da $R$.
Também usamos a notação $\rel {R^=}$.

%%}}}

%%{{{ x: wrong_sclosure_definition 
\exercise.
%%%{{{ meta 
%%%}}}

Alguém definiu o fecho simétrico assim:
\quotepar
<<Seja $R$ relação binária num conjunto $A$.
Seu fecho simétrico é a relação $\sclosure R$ definida pela
$$
x \sclosure R y \pseudodefiff x \rel R y \mland y \rel R x\;\text{.>>}
$$
\endquote
Ache o erro na definição e mostre que a definição realmente é errada.

\hint
Aplique fielmente essa definição na relação do~\ref[symmetric_closure_example].

\hint
Essa definição pode acabar apagando setas!

\solution
Tome a relação $R$ nos $\nats$ com gráfico $\set{(0,1)}$.
Aplicando essa suposta definição da $\sclosure R$ então temos:
$$
x \sclosure R y \iff x \rel R y \mland y \rel R x \iff \False
$$
ou seja, a $x \sclosure R y$ acaba sendo a relação vazia.
Assim acabamos apagando setinhas, algo contra do nosso conceito de fecho!

%%}}}

%%{{{ df: sclosure 
\definition Fecho simétrico.
%%%{{{ meta 
\label sclosure
\defines
    * \sclo {~R}  -- o fecho simétrico da $R$
    * \sclosure {~R}  -- o fecho simétrico da $R$
    * fecho!simétrico
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos a relação $\sclosure R$ pela
$$
x \sclosure R y \defiff x \rel R y \mlor y \rel R x.
$$
Chamamos a $\sclosure R$ o \dterm{fecho simétrico} da $R$.
Também usamos a notação $\rel {R^\leftrightarrow}$.

%%}}}

%%{{{ x: wrong_tclosure_definition 
\exercise.
%%%{{{ meta 
%%%}}}

Alguém definiu o fecho transitivo assim.
\emph{Seja $R$ relação binária num conjunto $A$.
Seu fecho transitivo é a relação $\tclosure R$ definida pela}
$$
x \tclosure R y \pseudodefiff \text{existe $w\in A$ tal que $x \rel R w \mland w \rel R y$}.
$$
Mas isso não é o fecho transitivo da $R$.  O que é mesmo?

\solution
A relação definida é a $R^2$, ou seja, a $R \rcom R$.

%%}}}

%%{{{ Q: How would you define the transitive closures of R? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias formalmente o fecho transitivo duma relação $R$?

%%}}}

\spoiler

%%{{{ df: tclosure 
\definition Fecho transitivo.
%%%{{{ meta 
\label tclosure
\defines
    * \rtclo {~R}      -- o fecho reflexivo-transitivo da $R$
    * \rtclosure {~R}  -- o fecho reflexivo-transitivo da $R$
    * \tclo {~R}       -- o fecho transitivo da $R$
    * \tclosure {~R}   -- o fecho transitivo da $R$
    * fecho!reflexivo-transitivo
    * fecho!transitivo
    ;;
%%%}}}

Seja $R$ relação num conjunto $A$.
Definimos as relações $\tclosure R$ e $\rtclosure R$ pelas
$$
\xalignat2
x \tclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats_{>0}$}.
&&\text{(\dterm{fecho transitivo} da $R$)}\\
x \rtclosure R y &\defiff x \rel {R^n} y \ \ \text{para algum $n\in\nats$}
&&\text{(\dterm{fecho reflexivo-transitivo} da $R$)}\\
\endxalignat
$$
Chamamos a $\tclosure R$ o \dterm{fecho transitivo} da $R$,
e a $\rtclosure R$ o \dterm{fecho reflexivo-transitivo} da $R$.
Também usamos as notações $\tclo R$ para o $\tclosure R$
e $\rtclo R$ para o $\rtclosure R$.

%%}}}

%%{{{ x: find_reflexive_transitive_closure_of_pgoesto 
\exercise.
%%%{{{ meta 
\label find_reflexive_transitive_closure_of_pgoesto
%%%}}}

Definimos no $\nats$ a relação binária $\leadsto$ pela:
$$
a\leadsto b \defiff \text{para algum primo $p$, $ap = b$}.
$$
Qual é o seu fecho reflexivo-transitivo?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Deixamos as definições de outros fechos para os problemas.

%%}}}

%%{{{ x: isPred 
\exercise.
%%%{{{ meta 
\label isPred
%%%}}}

Considere a relação $\to$ no $\nats$, definida pela:
$$
x\to y \defiff x + 1 = y.
$$
Descreva as relações seguintes:
\item{$\transcl{\to}$}: seu fecho transitivo;
\item{$\rtranscl{\to}$}: seu fecho reflexivo-transitivo;
\item{$\rtranscl{\leftrightarrow}$}: seu fecho reflexivo-transitivo-simétrico.
\eop\noi

%%}}}

%%{{{ x: isPred_in_reals 
\exercise.
%%%{{{ meta 
\label isPred_in_reals
%%%}}}

Considere a relação $\to$ definida pela mesma equação como
no~\ref[isPred], mas essa vez no conjunto $\reals$.
Descreva os mesmos fechos.

%%}}}

%%{{{ remark: and_if_we_never_reach_closure 
\remark E se nunca chegar?.
%%%{{{ meta 
\label and_if_we_never_reach_closure
%%%}}}

Esse processo descrito no~\ref[Closure_informal_bottom_up] pode ser
que nunca termina, ou seja esse \wq{até finalmente chegar} que escrevi
lá pode ser que nunca chega mesmo numa relação com a propriedade
desejada.  Por exemplo, considere a $\to$ do~\ref[isPred].
Se pensar que começamos com ela no dia $1$ e que cada dia que passa
adicionamos todas as cetinhas atualmente sendo testemunhas de
falta de transitividade, em qual dia vamos chegar numa relação
transitiva?
\emph{Nunca!}
\emph{E isso seria verdade para um imortal também!}
Mas a idéia descrita no~\reftag[Closure_informal_bottom_up] funciona
mesmo assim; é só esquecer essa frase de \wq{finalmente chegar}
e entender que pode ser que nunca chegamos numa relação completa,
mas mesmo assim, o processo determina uma relação sim:
para saber se uma setinha $(x,y)$ está no fecho ou não, é só
perguntar se ela vai ``entrar'' um belo dia ou não.

%%}}}

\endsection
%%}}}

%%{{{ Bottom_up_top_down_closures 
\section Bottom-up \vs top-down.
%%%{{{ meta 
\label Bottom_up_top_down_closures
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos fingir para essa discussão que relações são mesmo
os conjuntos das suas setinhas (ou seja, seus gráficos)
pois vai facilitar a fala informal e uma notação conjuntista
que vou usar.  Espero que tu já fez
o~\ref[repeat_after_me_relations_are_not_sets], e logo
tu entenderás bem a discussão seguinte tanto no nível informal
quanto nos detalhes ``verdadeiros'' por trás.  Vamo lá!

%%}}}

\TODO Adicionar desenhos.

%%{{{ top_down_closure 
\note Top-down.
%%%{{{ meta 
\label top_down_closure
%%%}}}

Imagine que para algum motivo gostamos muito duma propriedade de
relações da forma
\standout
\wq{se \emph{algo}, então tem que ter essas certas setinhas}.
\endstandout
(Pense em transitividade como exemplo ``padrão'' aqui.)
Vamos chamar as relações que tem nossa propriedade de \dterm{legais}.
Começamos com um conjunto $A$ uma relação nele $R$ bugada,
possivelmente ilegal.
(Isso quis dizer que não tem a propriedade escolhida.)
Procuramos \emph{a} relação $\overline R$ para chamar
de fecho ``legal'' da $R$; esse fecho deve satisfazer:
\tlist:
\li (L1): $\overline R \supset R$;
\li (L2): $\overline R$ é legal;
\endtlist
e deve ser \dq{a melhor} entre todas as relações $L$ que
satisfazem ambas essas condições.
Mas o que significa \emph{melhor}, e o que nos faz acreditar
que existe \emph{a} melhor?
Aqui melhor quis dizer que a $\overline R$ deve ser \emph{fiel}
na $R$, no sentido de não conter setas desnecessárias, setas
não fornecidas/necessidadas por causa da relação original $R$.
Como vamos descobrir, tal $\overline R$ existe mesmo, e vamos
definí-la numa maneira extremamente elegante e legal!
\eop
A primeira coisa importante para perceber é que
\emph{já sabemos que pelo menos uma relação satisfaz ambas as
condições (L1)--(L2) acima:} a relação cheia, trivial $\True$
do $A$.  Vamos chamá-la de $G$---pense ``Grande''.
Com certeza $G \supset R$, pois como poderia não ser?
$G$ é a relação cheia, ela tem todas as setinhas, então
com certeza as setinhas da $R$ também.
Pelo mesmo motivo e pela natureza da própria propriedade
temos certeza que $G$ também goza da (L2): ela é legal.
\eop
Bem, temos uma candidata; mas estamos procurando a melhor,
pois essa pode ter \dterm{lixo}.  Procuramos uma maneira
de jogar fora todo o lixo da $G$.
\eop
Uma idéia ruim para conseguir isso seria seguinte:
pega uma setinha $\alpha$ do $G\setminus R$ e veja se removendo
essa $\alpha$, tu quebras a ``legaldade''.
Qual o problema com essa abordagem?
Bem: vai que tu pegou uma setinha e que observou
que ela não pode ser jogada fora, pois duas outras setinhas
estão a obrigando ficar mesmo.
Mas, por que confiar nessas outras setinhas?
Talvez elas mesmas também fazem parte do lixo, e deveriam ser jogadas
foras também.  Mas então, como escolher onde começar a investigação?
Hah!  Nem vamos escolher nenhum canto para começar, pois nem vamos
começar investigar nada disso!  Vamos usar uma maneira bem simples
e jogar todo o lixo fora num instante só!
\eop
Vamos definir a colecção de todos os candidatos:
$$
\scr L_R \defeq
\setst {L : \reltype{A,A}} {L \supset R \mland \text{$L$ é legal}}.
$$
Primeiramente observe que sabemos que essa colecção não é vazia,
pois se fosse a gente teria um problema grande---tu vai entender logo qual.
Realmente, a $G$ é uma das candidatas, então $G \in \scr L_R$ e logo
$\scr L_R \neq \emptyset$.
Agora observe que cada candidato $L \in \scr L_R$ satisfaz
$$
G \supset L \supset R.
$$
Ambas são imediates pela definição do $\scr L_R$.
Tem então dois casos extremos (onde $L$ é uma das $G,R$) mas no caso
geral $L$ fica estritamente entre as relações $G$ e $R$.
Estamos finalmente prontos para a definição linda que prometi,
que vai acabar com todo o lixo:
\eop
$$
\overline R \defeq \Inter \scr L_R.
$$
Afirmo que:
% TODO: fix reflabs
\tlist:
\li (1): $\overline R \supset R$;
\li (2): $\overline R$ é legal;
\li (3): $\overline R$ é a melhor: não tem lixo nenhum.
\endtlist
Antes de demonstrar esses pontos, primeiramente quero te preocupar
com uma outra perguta:

%%}}}

%%{{{ Q: How do you know that the arrow you deleted is not needed? 
\question.
%%%{{{ meta 
%%%}}}

Alguém poderia reclamar que certas das setinhas que foram jogadas
fora nesse processo, por exemplo essa aqui abaixo, foram injustamente
tiradas, e talvez eram essenciais, ou seja, necessárias mesmo para
a legaldade da relação.  O que responderias?  Como podemos convencer
essa pessoa que a setinha não foi realmente necessária?

%%}}}

\spoiler

%%{{{ A 
\note Resposta.
%%%{{{ meta 
%%%}}}

Observe que essa setinha pertence a uma das candidatas do $\scr L_R$,
mas tem outras candidatas que não têm essa setinha nelas e mesmo assim
conseguem ser legais!  Ou seja, com certeza essa setinha não pode ser
necessária mesmo para a legaldade da relação que estamos procurando!

%%}}}

%%{{{ What's missing? 
\note O que falta?.
%%%{{{ meta 
%%%}}}

Basta demonstrar as (1)--(3) agora.
A primeira \emph{deve ser óbvia} para o leitor que já passou pelo~\ref[Collections]
(até se ele pulou---foi sem querer né?---o~\ref[Inter_of_supsets_supset],
que é exatamente isso).
As outras duas, tu demonstrarás agora:

%%}}}

%%{{{ x: top_down_closure_prove_2 
\exercise.
%%%{{{ meta 
\label top_down_closure_prove_2
%%%}}}

Demonstre a (2) do~\ref[top_down_closure]

%%}}}

%%{{{ x: top_down_closure_prove_3 
\exercise.
%%%{{{ meta 
\label top_down_closure_prove_3
%%%}}}

Demonstre a (3) do~\ref[top_down_closure]

%%}}}

%%{{{ bottom_up_closure 
\note Bottom-up.
%%%{{{ meta 
%%%}}}

\TODO Descrever como imortal construtor por dia.

%%}}}

%%{{{ Always coincide? 
\note Sempre concordam?.
%%%{{{ meta 
%%%}}}

Tem situações onde a definição bottom-up e definição top-down discordam!
Isso pode acontecer, por exemplo, quando o ``imortal'' construindo na
maneira bottom-up necessitaria uma infinidade
\emph{mais longa que a largura dos naturais}---e se essa frase
não fez nenhum sentido agora, tranqüilo, não era pra fazer:
volte a relê-la depois de ter estudado \emph{aritmética ordinal}
no~\ref[The_ordinals].

%%}}}

\endsection
%%}}}

%%{{{ Order relations 
\section Relações de ordem.
%%%{{{ meta 
\label Order_relations
%%%}}}

%%{{{ df: order_relation 
\definition Ordem.
%%%{{{ meta 
\label order_relation
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem parcial} sse ela é reflexiva, transitiva, e antissimétrica.
Se ela também é total, a chamamos de \dterm{ordem total}.

%%}}}

%%{{{ beware: total-partial default, relations vs functions 
\beware.
%%%{{{ meta 
%%%}}}

Quando usamos apenas o termo \emph{ordem}, entendemos como \emph{ordem parcial}.
Observe que esta convenção é a oposta que seguimos nas funções, onde um pleno
\emph{função} quis dizer \emph{função total}.

%%}}}

%%{{{ eg: subset and supset are orders 
\example.
%%%{{{ meta 
%%%}}}

Dado qualquer conjunto $X$, seus subconjuntos
são parcialmente ordenados tanto por $(\subset)$
quanto por $(\supset)$.

%%}}}

%%{{{ eg: common orders are orders 
\example.
%%%{{{ meta 
%%%}}}

As $(\leq)$ e $(\geq)$ comuns são ordens totais nos $\nats,\ints,\rats,\reals$.

%%}}}

%%{{{ divides_is_not_an_order_on_ints 
\exercise.
%%%{{{ meta 
\label divides_is_not_an_order_on_ints
%%%}}}

A relação $(\divides)$ nos inteiros é uma relação de ordem?

\hint
O que podemos concluir se $a \divides b$ e $b \divides a$?

%%}}}

%%{{{ divides_is_a_partial_order_on_nats 
\example.
%%%{{{ meta 
%%%}}}

A relação $(\divides)$ no $\nats$ é uma ordem parcial.
(Demonstraste isso no~\ref[divides_is_almost_a_partial_order].)

%%}}}

%%{{{ df: strict_order 
\definition Ordem estrita.
%%%{{{ meta 
\label strict_order
\defines
    * ordem!estrita
    ;;
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
Chamamos a $R$ \dterm{ordem estrita} sse ela é irreflexiva, transitiva, e assimétrica.
Se ela também é tricotômica, chamamos-la \dterm{ordem estrita total}.

%%}}}

%%{{{ remark: default adjective 
\remark Adjectivo implícito.
%%%{{{ meta 
\defines
    * ordem!fraca
    ;;
%%%}}}

Quando queremos enfatizar que uma relação é uma ordem e não uma ordem estrita,
usamos o termo \dterm{fraca}.  Similarmente com as funções (totais \vs parciais),
Dependendo do contexto o \emph{adjectivo implícito} pode mudar.
Quando focamos em ordens estritas, ``ordem'' vira sinônimo de ``ordem estrita''
e precisamos o adjectivo ``fraca'' para referir a uma ordem (fraca).

%%}}}

%%{{{ x: weak_fromto_strong_orders 
\exercise De fraca para estrita; ida e volta.
%%%{{{ meta 
\label weak_fromto_strong_orders
%%%}}}

(1)
Seja $(\leq)$ ordem num conjunto $A$.
Defina a relação $(<)$ no $A$ pela:
$$
x < y \defiff x \leq y \mland x \neq y.
$$
Demonstre que $(<)$ é uma ordem estrita.
\eop\noi
(2)
Seja $(<)$ ordem estrita num conjunto $A$, e
defina a relação $(\leq)$ no $A$ pela:
$$
x \leq y \defiff x < y \mlor x = y.
$$
Demonstre que $(\leq)$ é uma ordem.

%%}}}

%%{{{ df: preorder_relation 
\definition Preordem.
%%%{{{ meta 
\label preorder_relation
\indexes
    * quasiordem    see: preordem
    ;;
\defines
    * preordem
    ;;
%%%}}}

Uma relação binária $R$ num conjunto $A$ é chamada \dterm{preordem} (ou \dterm{quasiordem}) sse ela é reflexiva e transitiva.

%%}}}

%%{{{ eg: divides_is_a_preorder_on_ints 
\example.
%%%{{{ meta 
\label divides_is_a_preorder_on_ints
%%%}}}

Como demonstramos no~\ref[divides_is_almost_a_partial_order],
a relação $(\divides)$ nos inteiros é uma preordem.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No~\ref[why_called_preorder] tu vai justificar o nome ``preordem'',
mostrando que cada preordem $R$ fornece uma ordem $R'$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Paramos \emph{por enquanto} o estudo de relações de ordem;
voltaremos ao estudo profundo delas no \ref[Posets_Lattices].

%%}}}

\endsection
%%}}}

%%{{{ Equivalence relations 
\section Relações de equivalência.
%%%{{{ meta 
\label Equivalence_relations
%%%}}}

%%{{{ idea_of_equivalence 
\note Equivalência.
%%%{{{ meta 
\label idea_of_equivalence
%%%}}}

Considere um conjunto $A$, onde queremos ``identificar'' certos elementos deles,
talvez porque ligamos apenas sobre uma propriedade, e queremos ignorar os
detalhes irrelevantes que nos obrigariam distinguir uns deles.
Por exemplo, se $A$ é um conjunto de pessoas, podemos focar apenas na
``nacionalidade''.  Esquecendo todos os outros detalhes então, vamos
considerar todos os compatriotas como se fossem ``iguais'':
o termo certo é \dterm{equivalentes}.
Outra propriedade poderia ter sido o ano que cada pessoa nasceu,
ou o primeiro nome, ou até quem é a mãe de cada pessoa.
Queremos identificar as propriedades que uma relação desse tipo tem que ter:
\item{(i)} Reflexividade: não importa qual foi o critério que escolhemos
para ``equivaler'' os objetos, cada objeto com certeza vai ``concordar''
com ele mesmo nesse critério.
\item{(ii)} Transitividade:
se $a$ e $b$ concordam no assunto escolhido, e $b$ e $c$ também,
com certeza $a$ e $c$ devem concordar também.
\item{(iii)} Simetría: pela natureza da nossa intuição é claro que
para decidir se dois elementos serão equivalentes ou não, não precisamos
considerá-los numa ordem específica.
\eop
\noi Chegamos assim na definição seguinte:

%%}}}

%%{{{ df: equivalence_relation 
\definition.
%%%{{{ meta 
\label equivalence_relation
\defines
    * relação!de equivalência
    ;;
%%%}}}

Seja $A$ conjunto e $\sim$ uma relação binária no $A$.
Chamamos $\sim$ uma \dterm{relação de equivalência} sse ela é
reflexiva, simétrica, e transitiva.
Definimos também o
$$
\eqrelspace A \defeq \setstt {R \in \relspace{A,A}} {$R$ é uma relação de equivalência}.
$$

%%}}}

%%{{{ eg: eqrel_eg_eq 
\example.
%%%{{{ meta 
\label eqrel_eg_eq
%%%}}}

A $(=)$ é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_parity 
\example.
%%%{{{ meta 
\label eqrel_eg_parity
%%%}}}

A relação $\sim_2$ que relaciona exatamente os inteiros com a mesma paridade
$$
x \sim_2 y \defiff \text{ambos os $x,y$ são pares ou ambos os $x,y$ são ímpares}.
$$
Essa relação de equivalência é um caso especial da próxima.

%%}}}

%%{{{ x: congruence_mod_m_is_an_eqrel_again 
\exercise.
%%%{{{ meta 
\label congruence_mod_m_is_an_eqrel_again
%%%}}}

Seja $m\in\nats$.
Demonstre que a relação binária nos inteiros definida pela
$$
a \congmod m b \defiff a \cong b \pmod m
$$
é uma relação de equivalência.

\solution
Esqueceu o~\ref[congruence_mod_m_is_an_eqrel]?

%%}}}

%%{{{ eg: eqrel_eg_countries 
\example.
%%%{{{ meta 
\label eqrel_eg_countries
%%%}}}

Em qualquer conjunto $P$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_children 
\example.
%%%{{{ meta 
\label eqrel_eg_children
%%%}}}

No conjunto $\pers$ de pessoas, a relação
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
é uma relação de equivalência.

%%}}}

%%{{{ eg: eqrel_eg_teams 
\example.
%%%{{{ meta 
\label eqrel_eg_teams
%%%}}}

No conjunto $\cal B$ de jogadores profissionais de basquete,
a relação
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
é uma relação de equivalência.

%%}}}

%%{{{ noneg: eqrel_noneg_food
\nonexample.
%%%{{{ meta 
\label eqrel_noneg_food
%%%}}}

Num conjunto $\pers$ de pessoas, a relação
$$
x \sim y \defiff \text{existe comida que $x$ e $y$ ambos comeram hoje}
$$
não é sempre uma relação de equivalência.

%%}}}

%%{{{ x: why not? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\hint
Não é necessariamente nem reflexiva nem transitiva.
Invente um contraexemplo para cada propriedade.

%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_plane 
\example.
%%%{{{ meta 
\label equivalent_relations_on_euclidean_plane
%%%}}}

No $\reals^2$ considere as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Facilmente todas são relações de equivalência.

%%}}}

%%{{{ eg: equivalent_relations_on_euclidean_space 
\example.
%%%{{{ meta 
\label equivalent_relations_on_euclidean_space
%%%}}}

No $\reals^3$ considere as relações:
$$
\align
\tup{x,y,z} \sim_3 \tup{x',y',z'}
&\iff z = z'\\
\tup{x,y,z} \sim_{1,2} \tup{x',y',z'}
&\iff x = x' \mland y = y' \\
\tup{x,y,z} \sim_{\textrm N} \tup{x',y',z'}
&\iff \norm{ \tup{x,y,z} } = \norm{ \tup{x',y',z'} }
\endalign
$$
Facilmente todas são relações de equivalência.

%%}}}

%%{{{ x: cannot replace and with or 
\exercise.
%%%{{{ meta 
%%%}}}

Mudamos o ``e'' para ``ou'' na segunda relação
do~\ref[equivalent_relations_on_euclidean_space]:
$$
\tup{x,y,z} \sim \tup{x',y',z'} \iff x = x' \mlor y = y'
$$
A $\sim$ é uma relação de equivalência?

\hint
Ache um contraexemplo que refuta sua transitividade.

\solution
Não, pois não é transitiva.
Tome os
$\tup{0,0,0}$,
$\tup{0,1,0}$, e
$\tup{2,1,0}$.
Observe que
$$
\tup{0,0,0}
\sim
\tup{0,1,0}
\mland
\tup{0,1,0}
\sim
\tup{2,1,0}
$$
mas $\tup{0,0,0} \not\sim \tup{2,1,0}$.

%%}}}

%%{{{ x: guaranteed_eqrels 
\exercise.
%%%{{{ meta 
\label guaranteed_eqrels
%%%}}}

Seja $A$ um conjunto qualquer.
Quais relações de equivalência podes já definir nele,
sem saber absolutamente nada sobre seus elementos?

\solution
A identidade $\eqof A$, a trivial $\True$, e a vazia $\False$.

%%}}}

%%{{{ x: how_many_equivalence_relations_on_3 
\exercise.
%%%{{{ meta 
\label how_many_equivalence_relations_on_3
%%%}}}

Seja $A$ conjunto com $\card A = 3$.
Quantas relações de equivalência podemos definir no $A$?

\hint
Deixe para responder junto com o~\ref[how_many_partitions_on_3].

\solution
Encontramos a resposta dessa pergunta no~\ref[how_many_partitions_on_3].

%%}}}

%%{{{ x: equivalent_properties_to_eqrel 
\exercise.
%%%{{{ meta 
\label equivalent_properties_to_eqrel
%%%}}}

Seja $R$ uma relação binária num conjunto $A$.
O.s.s.e.:
\item{(i)}   $R$ é uma relação de equivalência;
\item{(ii)}  $R$ é reflexiva e circular;
\item{(iii)} $R$ é reflexiva e left-euclideana;
\item{(iv)}  $R$ é reflexiva e right-euclideana.

%%}}}

%%{{{ x: distance_like_not_transitive 
\exercise.
%%%{{{ meta 
\label distance_like_not_transitive
%%%}}}

Seja real $\epsilon\in(0,1)$, e defina a relação $\approx_\epsilon$:
$$
x \approx_\epsilon y \defiff (x-y)^2 < \epsilon.
$$
A $\approx_\epsilon$ é uma relação de equivalência?

\hint
Primeiramente lembre o mesmo problema mas para a relação:
$$
x \sim_\epsilon y \defiff |x-y| < \epsilon
$$
onde $\epsilon > 0$;
foi resolvido---eu espero---no \ref[epsilon_close_is_not_an_equivalence_relation].

\hint
Reflexividade e simetria das $(\sim_\epsilon)$ e $(\approx_\epsilon)$ são imediatas.
Sobre a transitividade, um desenho na linha real ajudaria.

\hint
Como contraexemplo, tome os reais $0$, $\epsilon/2$, e $\epsilon$ e
observe que $0 \sim_\epsilon \epsilon/2$ e $\epsilon/2 \sim_\epsilon \epsilon$
mas mesmo assim não temos $0\sim_\epsilon \epsilon$.

\hint
Como podes usar a não-transitividade da $(\sim_\epsilon)$
para deduzir a não-transi\-tivi\-dade da $(\approx_\epsilon)$?

\hint
Para todo $\alpha\in\reals_{\geq 0}$ temos:
$$
\cdots
\iff
\sqrt{\alpha}\in(0,1)
\iff
\alpha\in(0,1)
\iff
\alpha^2\in(0,1)
\iff
\cdots
$$

\solution
Não é.  Uma resolução já foi rescunhada nas dicas.
Para um contraexemplo direto, pode tomar os reais
$0$, $\sqrt \epsilon / 2$, e $\sqrt \epsilon$.
Observe que $0 \approx_\epsilon \sqrt \epsilon / 2$
e $\sqrt \epsilon / 2 \approx_\epsilon \sqrt \epsilon$
mas não temos $0 \approx_\epsilon \sqrt \epsilon$.

%%}}}

%%{{{ df: equivalent_class 
\definition.
%%%{{{ meta 
\label equivalent_class
\defines
    * \eqclass {~a} {~R}  -- a classe de equivalência do $a$ através da $R$
    * \eqclassimp {~a}  -- a classe de equivalência do $a$ (relação implícita pelo contexto)
    * classe de equivalência
    ;;
%%%}}}

Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Para cada $a\in A$, definimos a \dterm{classe de equivalência do} $a$
como o conjunto de todos os membros de $A$ que $\sim$-relacionam com o $a$.
Formalmente definimos
$$
\eqclass a {\sim} \defeq \setst {x\in A} {x\sim a}.
$$
Às vezes aparece também a notação $\eqclassalt a \sim$.
Quando a relação de equivalência é implicita pelo contexto
denotamos a $\eqclass a \sim$ apenas por $\eqclassimp a$.

%%}}}

%%{{{ x: type_of_eqclass_hole 
\exercise.
%%%{{{ meta 
\label type_of_eqclass_hole
%%%}}}

Sejam $A$ conjunto, $a\in A$, e $\sim$ relação de equivalência no $A$.
Considere as funções seguintes definidas com buracos:
$$
\xalignat3
\eqclass {\dhole} {\sim}   &: \ \askdots &
\eqclass {a} {\dhole}      &: \ \askdots &
\eqclass {\dhole} {\dhole} &: \ \askdots
\endxalignat
$$
Escreva tipos válidos para essas funções.

\solution
Escrevemos os tipos:
$$
\align
\eqclass {\dhole} {\sim}   &: A \to \pset A \\
\eqclass {a} {\dhole}      &: E \to \pset A \\
\eqclass {\dhole} {\dhole} &: \paren{A \cross \eqreltype A} \to \pset A.
\endalign
$$

%%}}}

%%{{{ x: equivalent_statements_to_x_equiv_y 
\exercise.
%%%{{{ meta 
\label equivalent_statements_to_x_equiv_y
%%%}}}

Sejam $\sim$ uma relação de equivalência num conjunto $X$, e $a,b\in X$.
Mostre que as afirmações seguintes são equivalentes:
\item{(i)} $a\sim b$;
\item{(ii)} $\eqclassimp a = \eqclassimp b$;
\item{(iii)} $\eqclassimp a \inter \eqclassimp b \neq \emptyset$.

\solution
\proofpart {Vamos demonstrar primeiro a {\rm ((i)\tiff(iii))}.}
\crtabproofpart {\lrdir.}
Suponha que $a \sim b$.
Precisamos achar um elemento que pertence nos dois conjuntos
$\eqclassimp a$ e $\eqclassimp b$.
Tome o próprio $a$.
Temos $a\in \eqclassimp a$ pois $a \sim a$ (pela reflexividade da $\sim$).
Também temos $a \in \eqclassimp b$, pois $a \sim b$ (hipótese).
Logo $a \in \eqclassimp a \inter \eqclassimp b\neq\emptyset$.
\crtabproofpart {\rldir.}
Suponha que $\eqclassimp a\inter\eqclassimp b \neq \emptyset$
e tome $w \in \eqclassimp a\inter\eqclassimp b$.
Logo $w \in \eqclassimp a$ e $w \in \eqclassimp b$,
ou seja $w \sim a$ e $w \sim b$ pela definição de classe de equivalência.
Pela simetría da $\sim$ temos $a \sim w$.
Agora como $a\sim w$ e $w \sim b$, pela transitividade da $\sim$ ganhamos
o desejado $a \sim b$.
\crproofpart {Agora vamos demonstrar a {\rm ((i)\tiff(ii))}.}
\crtabproofpart {\lrdir.}
Suponha que $a \sim b$.
Tome $x\in \eqclassimp a$.
Logo $x \sim a$.
Mas $a \sim b$ e logo pela transitividade da $\sim$ temos $x \sim b$,
e logo $x \in \eqclassimp b$.
\crtabproofpart {\rldir.}
Suponha que $\eqclassimp a = \eqclassimp b$.
Pela reflexividade da $\sim$, sabemos que $a\in\eqclassimp a$.
Logo $a\in\eqclassimp b$, e logo $a\sim b$ pela definição de $\eqclassimp b$.

%%}}}

%%{{{ idea_of_partition 
\note Partição.
%%%{{{ meta 
\label idea_of_partition
%%%}}}

Voltamos de novo para nosso conjunto $A$ do~\reftag[idea_of_equivalence],
mas esta vez sem uma predeterminada propriedade para focar.
Esta vez vamos dividir os elementos do $A$ em \dterm{classes},
tais que cada membro do $A$ pertencerá a \emph{exatamente uma delas},
e cada uma delas terá pelo menos um membro do $A$.
E nem vamos justificar essa separação, explicando o como ou o porquê.
Esse tipo de colecção de classes já encontramos na \ref[Coverings_and_partitions]:
é o que chamamos de \dterm{partição}; aqui uma reformulação da \ref[partition_sets]:

%%}}}

%%{{{ df: partition 
\definition.
%%%{{{ meta 
\label partition
\defines
    * partição
    ;;
%%%}}}

Seja $A$ conjunto e $\scr A \subset \pset A$ uma família de subconjuntos de $A$.
$\scr A$ é uma \dterm{partição} de $A$, sse:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \scr A = A$;
\li (P2): os membros de $\scr A$ são disjuntos dois-a-dois;
\li (P3): $\emptyset \nin \scr A$.
\endtlist
Chamamos de \dterm{classes} os membros da $\scr A$.

%%}}}

%%{{{ x: partition_equivalent_defs 
\exercise.
%%%{{{ meta 
\label partition_equivalent_defs
%%%}}}

Verifique que as definições \reftag[partition_sets] e \reftag[partition]
são, de fato, equivalentes.

%%}}}

%%{{{ x: union_scr_A_subset_already_known 
\exercise.
%%%{{{ meta 
\label union_scr_A_subset_already_known
%%%}}}

Podemos trocar o~(P1) da~\ref[partition] por
$$
\text{(P1$'$)}\quad\Union \scr A \supset A \ ?
$$

\hint
Será que já sabemos a outra \dq{direção} da igualdade?

\solution
Sim!
Pois como $\scr A$ é uma família de subconjuntos de $A$,
já sabemos que $\Union \scr A \subset A$.
Logo, afirmar $\Union \scr A = A$ ou afirmar $\Union \scr A \supset A$
nesse caso é a mesma coisa.
Escolhemos o (P1) pois fica mais natural (e porque se retirar a hipótese
que $\scr A \subset \pset A$, o (P1) vira necessário).

%%}}}

%%{{{ x: pairwise_necessary_for_partition 
\exercise.
%%%{{{ meta 
\label pairwise_necessary_for_partition
%%%}}}

Podemos trocar o~(P2) da~\ref[partition] por
$$
\text{(P2$'$)}\quad\Inter \scr A = \emptyset\  ?
$$

\hint
Não: nossa definição vai permitir mais colecções ser chamadas ``partição'' do que deveriam.

\hint
Uma das colecções não-partições do~\ref[partitions_of_seven] vai
acabar sendo partição.

\solution
A $\scr A_5\subset\powerset A$ do~\ref[partitions_of_seven] satisfaz as
$$
\Union \scr A_5 = A,
\qqqquad
\Inter \scr A_5 = \emptyset,
$$
mas não é uma partição: o $2\in A$ por exemplo, pertenceria em duas classes
diferentes, algo contra da nossa idéia de ``partição''.

%%}}}

\TODO Check blending.

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: preorders_are_idempotent 
\problem.
%%%{{{ meta 
\label preorders_are_idempotent
%%%}}}

Seja $R$ uma preordem num conjunto $A$.
Demonstre que $R$ é \dterm{idempotente}, ou seja, $R = R \rcom R$.

\solution
\def\R{\rel R}%
\def\RR{\rel {(R \rcom R)}}%
Vamos demonstrar as duas direções separadamente.
\crproofpart {$x \R y \implies x \RR y$:}
Suponha $x \R y$.
Como $\R$ é reflexiva, logo $x \R x$.
Pelas $x \R x$ e $x \R y$ concluimos que $x \RR y$.
\crproofpart {$x \RR y \implies x \R y$:}
Suponha $x \RR y$.
Logo $x \R w$ e $w \R y$ para algum $w \in A$ (pela def.~de $\rcom$),
e logo pela transitividade da $\R$ temos $x \R y$.

%%}}}

%%{{{ prob: when_is_rop_irreflexive 
\problem.
%%%{{{ meta 
\label when_is_rop_irreflexive
%%%}}}

Seja $S$ uma relação binária num conjunto $A$ tal que
$$
\text{$\relp{S \rcom {\rop S}}$ é irreflexiva}.
$$
Qual é o gráfico da $S$?
Demonstre tua resposta.

\hint
Supondo que $x \rel S y$, o que tu consegues concluir?

\solution
$\graph(S) = \emptyset$.
\eop
Pois, supondo que tem membros, tome $(x,y) \in \graph(S)$, e agora:
$x \rel S y$ e logo $y \rop S x$ (pela def.~de $\rop S$).
Logo $x \relp{S \rcom {\rop S}} x$, que contradiza
a irreflexividade da $S \rcom {\rop S}$.

%%}}}

%%{{{ prob: rcom_does_not_respect_transitivity 
\problem.
%%%{{{ meta 
\label rcom_does_not_respect_transitivity
%%%}}}

Sejam $R,S$ relações binárias e transitivas no $A$.
Podemos concluir que $R \rcom S$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.  Para achar um contraexemplo desenha as
setinhas das relações envolvidas para construir
os desejados $x,y,z$.

%%}}}

%%{{{ prob: rop_iter_R_eq_iter_rop_R 
\problem.
%%%{{{ meta 
\label rop_iter_R_eq_iter_rop_R
%%%}}}

Seja $R:\reltype{X,X}$.
Demonstre que para todo $n\in\nats$,
$$
\ropp{R^n} = \paren{\rop R}^n.
$$

\hint
Indução.

\solution
Por indução.
\crproofpart {Base.}
Calculamos:
\compute
\ropp{R^0}
&= \ropp{\eqof X}     \by {def.~$R^0$} \\
&= (\eqof X)          \by {pelo~\ref[rop_of_symmetric]} \\
&= \paren{\rop R}^0.  \by {def.~$\paren{\rop R}^0$} \\
\endcompute
\crproofpart {Passo indutivo.}
Seja $k\in\nats$ tal que $\ropp{R^k} = \paren{\rop R}^k$\fact{HI}.
Calculamos:
\compute
\ropp{R^{k+1}}
&=\ropp{R R^k}              \by {def.~$R^{k+1}$} \\
&=\ropp{R^k R}              \by {Lemma} \\
&=\rop R \ropp{R^k}         \by {\ref[rop_of_rcompose]} \\
&=\rop R \paren{\rop R}^k   \by {HI} \\
&=\paren{\rop R}^{k+1}      \by {def.~$R^{k+1}$} \\
\endcompute
Onde devemos demonstrar o Lemma:
{\proclaimstyle
para todo $t\in\nats$, $R^t R = R R^t$.}
\crproofpart {Demonstração do Lemma.}
Por indução.
\crproofpart {Base: $R^0 R \askeq R R^0$.}
Imediato pois $R^0 = (\eqof X)$ e $\eqof X$ é uma $\rcom$-identidade (\ref[id_of_rcom]).
\crproofpart {Passo indutivo.}
Seja $w \in \nats$ tal que $R^w R = R R^w$\fact{HI}.
Calculamos:
\compute
R^{w+1} R
&= (R^w R) R  \by {def.~$R^{w+1}$} \\
&= (R R^w) R  \by {HI} \\
&= R (R^w R)  \by {assoc.~$\rcom$ (\reftag[associativity_of_rcom])} \\
&= R (R R^w)  \by {HI} \\
&= R R^{w+1}. \by {def.~$R^{w+1}$} \\
\endcompute

%%}}}

%%{{{ prob: condorcet_paradox 
\problem O paradoxo de Condorcet.
%%%{{{ meta 
\label condorcet_paradox
\credits
    * Condorcet : paradoxo
    ;;
\indexes
    * paradoxo!de Condorcet
    ;;
%%%}}}

Seja $P\neq\emptyset$ um conjunto de pessoas e
$C\neq\emptyset$ um conjunto de candidatos.
Seja $\gtrdot$ a relação binária no $C$ definida pela
$$
x \gtrdot y \defiff \text{a maioria da população do $P$ prefere $x$ do que $y$}.
$$
Podemos concluir que $\gtrdot$ é transitiva?
Responde ``sim'' e demonstre; ou ``não'' e mostre um contraexemplo.

\hint
Já jogou ``pedra--papel--tesoura''?

\solution
Não.  Sejam $P = \set{p,q,r}$ e $C = \set{a,b,c}$.
Considere que as pessoas do $P$ em ordem de preferência de melhor para pior têm:
$$
\align
    p:\ & a, b, c \\
    q:\ & c, a, b \\
    r:\ & b, c, a.
\endalign
$$
Assim temos:
$$
\alignat2
a &\gtrdot b, \by {pois os $p,q$ preferem $a$ que $b$} \\
b &\gtrdot c, \by {pois os $p,r$ preferem $b$ que $c$} \\
\endalignat
$$
mas $a \smartnot\gtrdot c$ pois apenas o $p$ prefere $a$ que $c$.
De fato, $c \gtrdot a$, pois os $q,r$ preferem $c$ que $a$.

%%}}}

%%{{{ prob: dom_trans_cod_not_trans 
\problem.
%%%{{{ meta 
\label dom_trans_cod_not_trans
%%%}}}

Sejam $A \toby f B$ e $\leadsto$ uma relação transitiva no $A$.
Definimos a relação $R$ no $B$ pela
$$
b \rel R b'
\defiff
\text{existem $a, a' \in A$ tais que $f(a) = b$, $f(a') = b'$, e $a \leadsto a'$}.
$$
Podemos concluir que $R$ também é transitiva?
Se sim, demonstre; se não, mostre um contraexemplo.

\hint
Não.

\hint
A $f$ não é necessariamente injetora.

\solution
Não, e vamos ver um contraexemplo.
Considere:
$$
\align
A &= \set{1,2,3,4} \\
B &= \set{5,6,7}
\endalign
$$
e a $\leadsto$ relacionando apenas os:
$$
\align
1 &\leadsto 2 \\
3 &\leadsto 4.
\endalign
$$
Defina a $f:A\to B$ pelas
$$
\align
1 &\mapstoby f 5 \\
2 &\mapstoby f 6 \\
3 &\mapstoby f 6 \\
4 &\mapstoby f 7.
\endalign
$$
Primeiramente observe que realmente $\leadsto$ é transitiva.
Vamos verificar que: $5 \rel R 6$ e $6 \rel R 7$ mas mesmo assim
$5 \not\rel R 7$.
Os testemunhos de $5 \rel R 6$ são os $1$ e $2$; e
os testemunhos de $6 \rel R 7$ são os $3$ e $4$.
Mas os únicos candidados para testemunhos de $5 \rel R 7$
são os $1$ e $4$, e $1 \not\leadsto 4$; e logo $5 \not\rel R 7$.

%%}}}

%%{{{ prob: dom_trans_cod_trans_if_inj 
\problem.
%%%{{{ meta 
\label dom_trans_cod_trans_if_inj
%%%}}}

O que muda no~\ref[dom_trans_cod_not_trans] se
adicionar a hipótese que $f$ é injetora?
Demonstre tua afirmação.

%%}}}

%%{{{ prob: explain_succ_rel 
\problem.
%%%{{{ meta 
\label explain_succ_rel
%%%}}}

Seja a relação $\to$ no $\nats$ definida pela
$$
a \to b \defiff a + 1 = b.
$$
Dê uma definição simples da relação $\to^n$ para quem não sabe
nem de iterações nem de composições de relações (e sequer quer aprender essas noções).
Demonstre tua afirmação, que a relação $\to^n$ é igual à relação que tu definiu.

\hint
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Agora demonstre que isso é válido para todo $a,b,n\in\nats$.

\solution
Seja $n\in\nats$.  Temos:
$$
a \rel{\to^n} b \iff a + n = b.
$$
Sejam $a,b\in\nats$.
Vou demonstrar por indução que para todo $n\in\nats$,
$$
a \ton n b  \iff  a + n = b.
$$
\proofpart {Base.}
Temos
\compute
a \ton 0 b
&\iff a = b \by {pela def.~$\ton 0$} \\
&\iff a + 0 = b.
\intertext{
\proofpart {Passo Indutivo.}
Seja $k\in\nats$ tal que
}
a \ton k b &\ifflabel {HI} a + k = b.
\intertext{Calculamos:}
a \ton {k+1} b
&\iff a \rel{(\ton k\rcom\to)} b              \by {def.~$\ton{k+1}$} \\
&\iff \lexists w {a \ton k w \mland w \to b}  \by {def.~$\rcom$} \\
&\iff \lexists w {a + k = w \mland w + 1 = b} \by {HI; def.~de~$\to$} \\
&\iff {(a + k) + 1 = b} \\
&\iff {a + (k + 1) = b}.
\endcompute

%%}}}

%%{{{ prob: agree_on_at_least_half_relation 
\problem.
%%%{{{ meta 
%%%}}}

Sejam conjunto $A$ com $\card A>2$, e $n$ inteiro par positivo.
No $A^n$ defina:
$$
a \sim b
\defiff
\card{ \setst {i\in\finord n} {a_i = b_i} } \geq n/2,
$$
onde
$a \eqass \tup{ a_0, \dotsc, a_{n-1}}$
e
$b \eqass \tup{ b_0, \dotsc, b_{n-1}}$.
A $\sim$ é uma relação de equivalência?

\solution
Não é.
Sejam $s,t,u\in A$ distintos dois-a-dois.
Tome
$$
\align
a &\leteq \tup{ s,s,\dots,s,t,t,\dotsc,t }\\
b &\leteq \tup{ s,s,\dots,s,u,u,\dotsc,u }\\
c &\leteq \tup{ t,t,\dots,t,u,u,\dotsc,u }
\endalign
$$
como contraexemplo, pois temos
$a \sim b$ e $b \sim c$ mas $a\not\sim c$.

%%}}}

%%{{{ prob: simh_simv_apph_appv 
\problem.
%%%{{{ meta 
\label simh_simv_apph_appv
\pdefs
    \pdef apph {\mathrel{\approx}}
    \pdef appv {\mathrel{\wr\mkern-1mu\wr}}
    \pdef simh {\mathrel{\sim}}
    \pdef simv {\mathrel{\wr}}
    ;;
%%%}}}

Considere as relações seguintes no $(\ints\to\ints)$:
\mathcol
f \simh g &\defiff \pexists {u\in\phints} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \apph g &\defiff \pexists {u\in\nnints} \lforall {x \in\ints} {f(x) = g(x+u) } \\
f \simv g &\defiff \pexists {u\in\phints} \lforall {x \in\ints} {f(x) = g(x)+u } \\
f \appv g &\defiff \pexists {u\in\nnints} \lforall {x \in\ints} {f(x) = g(x)+u }.
\endmathcol
Para cada uma dessas relações, decida se é:
(ir)reflexiva; transitiva; (a(nti)s)simétrica.

\hint
Primeiramente tente entender (visualizar) essas relações.

\solution
Primeiramente tentamos entender essas relações bem informalmente.
As $\simh$ e $\apph$ envolvem um movimento horizontal,
e as $\simv$ e $\appv$ um movimento vertical.
Especificamente $f \simh g$ [$f \simv g$]
sse $f$ e $g$ são a mesma função depois de um ``shift'' horizontal
[vertical] para qualquer direção.
As $\apph$ e $\appv$ são parecidas so que $f \apph g$
[$f \appv g$] sse a $f$ ``coincide'' com a $g$ depois de um
``shift'' da $f$ para a direita [para baixo] $0$ ou mais ``posições''.
\eop\medskip
\crtabproofpart {Reflexividade.}
Todas são reflexivas, algo que mostramos tomando $u \asseq 0$.
Vamos ver em detalhe apenas para a $\simh$.
\crproofpart {Reflexividade da $\apph$.}
\eop\noi
    Seja $f : \ints\to\ints$.
    Temos para todo $x\in \ints$, $f(x) = f(x + 0)$, e como $0\in\nnints$,
    logo $f\apph f$.
\eop\medskip
\crtabproofpart {Transitividade.}
Todas são transitivas, e parecida em todas:
usando nossas hipoteses ganhamos dois números $i,j$ e o número que procuramos
acaba sendo o $i + j$.
Vamos ver em detalhe apenas para a $\appv$:
\crproofpart {Transitividade da $\appv$.}
\eop\noi
    Sejam $f,g,h: \ints\to\ints$ tais que $f\simh g$ e $g\simh h$.
    Sejam então $i,j\in\ints$ tais que:
    \mathcol
    \text{para todo $x\in \ints$, } & f(x) = g(x+i) \tag{1} \\
    \text{para todo $x\in \ints$, } & g(x) = h(x+j).\tag{2}
    \endmathcol
    Seja $z\in\ints$ e calcule:
    \compute
    f(z)
    &= g(z+i)       \by {pela (1) com $x \asseq z$} \\
    &= h((z+i)+j)   \by {pela (2) com $x \asseq z+i$} \\
    &= h(z+(i+j)).
    \endcompute
    Ou seja, o inteiro $i+j$ mostra que $f\simh h$.
Já demonstramos então que todas essas relações são preordens!
Vamos pesquisar sobre as outras propriedades agora.
\eop\medskip
\crtabproofpart {(A(nti)s)simetria.}
As $\simh$ e $\simv$ são simétricas, algo que mostramos para as
duas no mesmo jeito: nossa hipótese fornece um $i\in\ints$
que satisfaz algo, e o inteiro que procuramos acaba sendo o $-i$.
As $\appv$ é antissimétrica, mas a $\apph$ não satisfaz nenhuma
dessas propriedades.
Vamos demonstrar a simetria da $\simh$, a antissimetria da $\appv$,
e refutar a simetria e a antissimetria da $\apph$.
\crproofpart {Simetria da $\simh$.}
    \eop\noi
    Sejam $f,g : \ints\to\ints$ tais que $f\simh g$.
    Então seja $i\in\ints$ tal que
    para todo $x\in \ints$, $f(x) = g(x+i)$\fact1.
    Observe que para todo $x\in\ints$, temos:
    \compute
    g(x)
    &= g(x+(i-i)) \\
    &= g((x-i)+i) \\
    &= f(x-i).    \by {pela~\byfact1~com $x\asseq x-i$} \\
    \endcompute
    Ou seja, o $-i\in\ints$ mostra que $g\simh f$.
\crproofpart {Antissimetria da $\appv$.}
    \eop\noi
    Sejam $f,g : \ints\to\ints$ tais que $f\appv g$ e $g\appv f$.
    Sejam então $i,j\in\nnints$ tais que para todo $x\in \ints$
    $f(x) = g(x)+i$ e $g(x) = f(x)+j$.
    Seja $x\in\ints$ e calcule:
    $$
    f(x) = g(x)+i = f(x) + j + i.
    $$
    Logo $i+j = 0$, e sendo ambos naturais, temos $i=j=0$.
    Ou seja, para todo $x\in\ints$, $f(x) = g(x)$, e logo $f=g$.
\crtabproofpart {A $\appv$ não é nem relação de equivalência nem de ordem.}
\crproofpart {Refutação da simetria da $\apph$.}
    \eop\noi
    Como contraexemplo tome as funções $f,g : \ints\to\ints$
    definidas pelas:
    \mathcols 2
    f(0) &= 1                   & g(1) &= 1 \\
    f(x) &= 0 \quad (x \neq 0)  & g(x) &= 0 \quad (x \neq 1)
    \endmathcols
    Observe que realmente $f \apph g$ pois temos
    que para todo $x \in \ints$, $f(x) = g(x+1)$.
    Mas $g\not\apph f$.  Suponha que tem $u\in\nnints$
    tal que para todo $x\in\ints$, $g(x) = f(x + u)$.
    Basta ou achar um absurdo.
    Pela nossa hipótese, $g(1) = f(1 + u)$.
    Mas $g(1) = 1$, ou seja $f(1+u) = 1$.
    Pela definição da $f$ então $u+1 = 0$,
    Absurdo, pois o $0$ não é sucessor de nenhum natural.
\crproofpart {Refutação da antissimetria da $\apph$.}
    \eop\noi
    Como contraexemplo tome as funções $f,g : \ints\to\ints$
    definidas pelas:
    \mathcols 2
    f(x) &=
    \knuthcases {
        0, & se $x$ é par; \cr
        1, & se $x$ é ímpar;
    } &
    g(x) &=
    \knuthcases {
        1, & se $x$ é par; \cr
        0, & se $x$ é ímpar;
    }
    \endmathcols
    Observe que realmente $f \apph g$ (tome $u \asseq 1$)
    e $g \apph f$ (tome $u \asseq 1$ de novo).
    Mesmo assim, $f\neq g$.
    Logo $\apph$ não é uma relação antissimétrica.
\eop\medskip
Concluimos então que:
as $\simh$ e $\simv$ são relações de equivalência,
a $\appv$ é uma relação de ordem,
e a $\apph$ apenas uma preordem.

%%}}}

%%{{{ prob: simz_sime_simo_simi 
\problem.
%%%{{{ meta 
\label simz_sime_simo_simi
\pdefs
    \pdef sime {\rel{\stackrel{{}_{\mathrmsmall e}}=}}
    \pdef simi {\rel{\stackrel{\infty}=}}
    \pdef simo {\rel{\stackrel{{}_{\mathrmsmall o}}=}}
    \pdef simz {\rel{\stackrel{{}_{\mathrmsmall z}}=}}
    ;;
%%%}}}

Defina as relações seguintes no $(\nats\to\nats)$ assim:
$$
\align
f\simz g&\defiff f(0)    = g(0) \\
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$} \\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$} \\
f\simi g&\defiff f(n)    = g(n)   \ \text{para uma infinidade de $n\in\nats$.}
\endalign
$$
% TODO: fix reflabs
\tlist:
\li (i):
Para cada uma da $\simz,\sime,\simo,\simi$, decida se é uma relação de
equivalência ou não.
\li (ii):
Demonstre ou refute a afirmação seguinte:
\emph{a relação $(\sime\rcom\simo)$ é a relação trivial $\mathsf{True}$.}
\endtlist

\hint
Ache um contraexemplo para a $\simi$.  As outras, são.

\solution
\proofpart {(i)}
A $\simi$ não é.  Considere o seguinte contraexemplo.
Sejam as $\alpha, \beta, \gamma : \nats\to\nats$ (como seqüências):
$$
\align
\alpha &= \tup{0,1,0,1,0,1,\dotsc} \\
\beta  &= \tup{0,2,0,2,0,2,\dotsc} \\
\gamma &= \tup{1,2,1,2,1,2,\dotsc}.
\endalign
$$
Trivialmente, $\alpha\simi\beta$ e $\beta\simi\gamma$ mas $\alpha\not\simi\gamma$.
\crproofpart {(ii)}
Correto.
Sejam $f, g \in (\nats\to\nats)$.
Vamos mostrar que $f \relp{\sime\rcom\simo} g$.
Pela definição da $\rcom$ temos:
$$
f \relp{\sime\rcom\simo} g
\iff \text{existe $h \in (\nats\to\nats)$ tal que $f \sime h$ e $h\simo g$}.
$$
A função $h : \nats\to\nats$ definida pela
$$
h(n) = \knuthcases {
f(n), &se $n$ par \cr
g(n), &se $n$ ímpar
}
$$
satisfaz as $f \sime h\simo g$ pela sua construção.
Logo, $f \relp{\sime\rcom\simo} g$.

%%}}}

%%{{{ prob: cofinite_cameo_appearance 
\problem.
%%%{{{ meta 
\label cofinite_cameo_appearance
%%%}}}

No conjunto $(\reals\to\reals)$ definimos:
$$
\align
f \approx g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) = g(x)}$ é infinito};\\
f \sim    g &\defiff \text{o conjunto $\setst {x \in \reals} {f(x) \neq g(x)}$ é finito}.
\endalign
$$
Demonstre que:
\item{(i)} uma delas é relação de equivalência;
\item{(ii)} a outra não é.

\hint
Se um subconjunto $X\subset\reals$ é infinito, isso não quis dizer
que $\reals\setminus X$ é finito!

\hint
A $\sim$ é a relação de equivalência.
Demonstre.

\hint
A $\approx$ não é transitiva.
Refute!

\solution
A $\sim$ é uma relação de equivalência:
\crproofpart {Reflexiva.}
Seja $f : \reals\to\reals$.
Calculamos:
$$
\setst {x \in \reals} {f(x) \neq f(x)} = \emptyset,
$$
que, sendo finito, mostra que $f\sim f$.
\crproofpart {Simétrica.}
Trivial, pois para quaisquer $f,g : \reals\to\reals$ temos
$$
\setst {x \in \reals} {f(x) \neq g(x)}
=
\setst {x \in \reals} {g(x) \neq f(x)}
$$
e logo um é finito sse o outro é finito.
\crproofpart {Transitiva.}
Sejam $f,g,h:\reals\to\reals$ tais que $f\sim g$ e $g\sim h$.
Logo:
$$
\align
A &\defeq \text{$\setst {x \in \reals} {f(x) \neq g(x)}$ finíto} \tag{1} \\
B &\defeq \text{$\setst {x \in \reals} {g(x) \neq h(x)}$ finíto} \tag{2}.
\endalign
$$
Seja $w \in \reals$.
Vamos demonstrar que
$$
w \nin A \union B \implies f(w) = h(w).
$$
Calculamos:
\compute
f(w) &= g(w)    \by {pois $w \nin A$} \\
     &= h(w).   \by {pois $w \nin B$} \\
\endcompute
Contrapositivamente,
$$
f(w) \neq h(w) \implies w \in A \union B.
$$
Mas $A\union B$ é finito,
(sendo uma união finita de conjuntos finitos)
e mostramos que
$$
\setst {x \in \reals} {f(x) \neq h(x)} \subset A\union B
$$
e logo também finito, ou seja, $f\sim h$.
\crproofpart {A $\approx$ não é uma relação de equivalência.}
Vamos refutar a sua transitividade.
Como contraexemplo, tome as $f,g,h : \reals\to\reals$ definidas pelas:
$$
\xalignat3
    f(x) &= 1 &
    g(x) &= \cos(x) &
    h(x) &= -1.
\endxalignat
$$
Observe que $f \approx g$ pois concordam nos pontos $2k\pi$ para todo $k\in\ints$.
Também $g \approx h$ pois concordam nos pontos $(2k+1)\pi$ para todo $k\in\ints$.
Mesmo assim, $f \not\approx h$ pois não concordam em ponto nenhum.

%%}}}

%%{{{ prob: efle_vs_fele_and_eflt_vs_felt 
\problem.
%%%{{{ meta 
\label efle_vs_fele_and_eflt_vs_felt
\pdefs
    \pdef efle {\rel{\buildrel{{}_{\exists\forall}} \over \leq}}
    \pdef eflt {\rel{\buildrel{{}_{\exists\forall}} \over <}}
    \pdef fele {\rel{\buildrel{{}_{\forall\exists}} \over \leq}}
    \pdef felt {\rel{\buildrel{{}_{\forall\exists}} \over <}}
    ;;
%%%}}}

Defina no $(\reals\to\reals)$ as relações seguintes:
$$
\align
f \efle g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) \leq g(x) } \\
f \fele g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) \leq g(x) } \\
f \eflt g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) < g(x) } \\
f \felt g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) < g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela tem ou não cada uma
das propriedades de uma ordem total, e de uma ordem estrita.

%%}}}

%%{{{ prob: implementing_functions_as_relations_and_vice_versa 
\problem implementando funções como relações e vice versa.
%%%{{{ meta 
\label implementing_functions_as_relations_and_vice_versa
%%%}}}

Já encontramos a idéia de \emph{implementação} de algum
conceito matemático no~\ref[Functions]
(\reftag[Implementations_seq_fam], \reftag[implement_partial_functions],
\reftag[implement_nondeterministic_functions]).
Como tu definiria funções como relações, e como relações como funções?
Dê apenas um esboço da tua idéia, sem entrar em muitos detalhes.

\solution
Seguem umas idéias.
\crproofpart {Função como relação.}
Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$
tal que $f$ é \emph{left-total} e \emph{right-unique}
(veja o glossário~\reftag[relations_glossary])
é chamada uma \dterm{função de $A$ para $B$}.
Escrevemos $f(x) = y$ em vez de $f(x,y)$ ou de $x \rel f y$
e para todo $a\in A$ denotamos com $f(a)$ o único $b\in B$
tal que $a \rel f b$.
\crproofpart {Relação binária como função.}
Sejam $A,B$ conjuntos.
Uma função $R : A \to \pset B$ é chamada uma \dterm{relação de $A$ para $B$}.
Escrevemos $a \rel R b$ quando $b \in R(a)$,
e $a \not\rel R b$ quando $b \nin R(a)$.
\crproofpart {Relação geral como função.}
Seja $W$ conjunto.
Uma função $R : W \to \bools$ é chamada uma \dterm{relação no $W$}.
Escrevemos $R(w)$ como afirmação, quando $R(w) = \True$, e $\lnot R(w)$
ou ``não $R(w)$'' quando $R(w) = \False$.

%%}}}

\endproblems
%%}}}

%%{{{ Partitions 
\section Partições.
%%%{{{ meta 
\label Partitions
%%%}}}

\endsection
%%}}}

%%{{{ Quotient set 
\section Conjunto quociente.
%%%{{{ meta 
\label Quotient_set
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os dois conceitos de ``relação de equivalência'' e ``partição'',
parecem diferentes mas realmente são apenas duas formas diferentes de
expressar a mesma idéia.
Cada relação de equivalência determina uma partição;
e vice-versa: cada partição determina uma relação de equivalência.
Bora demonstrar isso!

%%}}}

%%{{{ x: wrong_partition_of_eqrel_def 
\exercise Cuidado!.
%%%{{{ meta 
\label wrong_partition_of_eqrel_def
%%%}}}

Tentando investigar isso, começando com uma relação de equivalência $R$,
um aluno tentou definir a partição correspondente $\scr A_R$ assim:
$$
\align
C \in \scr A_R
\defiff
&C \subset A \\
&\mland  C \neq \emptyset \\
&\mland  \lforall {c,d \in C} {c \rel R d}.
\endalign
$$
Qual o erro na definição do aluno?
O que faltou escreverer para virar uma definição correta?

\hint
Considere o conjunto $A$ com a relação de equivalência $R$ como no diagrama
interno seguinte:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\draw (elem-1) -- (elem-2) -- (elem-3) -- (elem-4);
\draw (elem-5) -- (elem-6);
\endtikzpicture
$$
Lembra-se que como já declaramos a~$R$ de ser uma relação de
equivalência, não precisamos botar todas as setinhas, apenas as necessárias
para ``gerar'' a~$R$
(veja~\ref[conventions_for_internal_diagrams_of_rel]).
Agora, seguindo fielmente sua definição, qual é o conjunto $\scr A_{R}$?

\hint
\emph{Não} é o conjunto dos seguintes subconjuntos de $A$:
$$
\tikzpicture
\tikzi eqrel2partitionbase;
\tikzi eqrel2partitiondesired;
\endtikzpicture
$$
Ache um $C\subset A$ tal que $C \in \scr A_{R}$ mas \emph{não deveria}.

\hint
A definição do aluno garanta que todos os elementos numa classe realmente
relacionam entre si através da $R$;
mas não garanta que cada classe $C$ é feita por \emph{todos} os elementos
de~$A$ que relacionam com os membros da $C$ mesmo.
Por exemplo, ela \emph{corretamente exclue} conjuntos como $\set{2,5}$;
mas ela \emph{incorretamente inclue} conjuntos como o $\set{2,3}$.
$$
\tikzpicture
\draw [rounded corners=3mm, fill=blue!20] (-1.6,0.4)--(-1.6,1.4)--(-0.3,1.4)--(-0.3,0.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
\qqqquad
\tikzpicture
\draw [rounded corners=2mm, fill=red!20] (-1.5,1.4)--(-1.5,-1.0)--(-0.9,-1.0)--(-0.9,1.4)--cycle;
\tikzi eqrel2partitiondesired;
\tikzi eqrel2partitionbase;
\endtikzpicture
$$

\solution
Seguindo as dicas, faltou escrever a ultima linha:
$$
\align
C \in \scr A_{R}
\defiff
&C \subset A\\
&\mland  C \neq \emptyset\\
&\mland  \lforall {c,d \in C} {c \rel R d}\\
&\mland  \pforall {a \in A} \lforall {c \in C} {a \rel R c \implies a \in C}.
\endalign
$$

%%}}}

%%{{{ x: from_eqrel_to_partition 
\exercise De equivalência para partição.
%%%{{{ meta 
\label from_eqrel_to_partition
%%%}}}

Seja $\sim$ relação de equivalência num conjunto $A$.
Escreva formalmente como definir uma partição
$\scr A_{\sim}$ do $A$ em que suas classes são feitas
por todos os $\sim$-relacionados.
Demonstre que realmente é uma partição.

\hint
Mande os membros de $A$ se separar:
<<se juntem todos os relacionados entre si!>>.

\solution
\proofpart {Definir uma família de subconjuntos de $A$.}
Definimos $\scr A_{\sim}$ para ser a família de todas as
classes de equivalência através da $\sim$.  Formalmente:
$$
\scr A_{\sim}
\defeq
\setst {\eqclassimp a} {a \in A}.
$$
\proofpart {Demonstrar que a família $\scr A_{\sim}$ é uma partição.}
Primeiramente observe que cada membro de $\scr A_{\sim}$
é um subconjunto de $A$.
Agora basta verificar as (P1)--(P3) da~\ref[partition].
\crproofpart {(P1) Mostrar que $A \subset \Union \paren{\scr A_{\sim}}$.}
Tome $a\in A$.
Como $a \sim a$ (reflexividade), então $a \in \eqclassimp a$.
Agora como $\eqclassimp a \in \scr A_{\sim}$,
temos que $a \in \Union \paren{\scr A_{\sim}}$.
\crproofpart {(P2) Os membros de $\scr A_{\sim}$ são disjuntos dois-a-dois.}
Sejam $C,D \in \scr A_{\sim}$.
Logo sejam $c,d \in A$ tais que $C = \eqclassimp c$ e $D = \eqclassimp d$.
Precisamos demonstrar \emph{qualquer uma} das duas implicações (são contrapositivas):
$$
\align
C\neq D                 &\implies C\inter D = \emptyset; \\
C\inter D\neq\emptyset  &\implies C = D.
\endalign
$$
Vamos demonstrar a segunda.
Suponha $C\inter D \neq \emptyset$ e seja logo $w\in C\inter D$.
Ou seja, $w\in C$ e $w \in D$, e logo $w \sim c$ e $w \sim d$.
Queremos demonstrar que $C = D$.
{\lrdirset.}
Tome $x \in C = \eqclassimp c$.
Temos:
$$
x \sim c \sim w \sim d
$$
(simetria e transitividade da $\sim$)
e logo $x \in \eqclassimp d = D$ e $C\subset D$.
A {\rldirset} é similar.
\crproofpart {(P3) $\emptyset \nin \scr A_{\sim}$.}
Basta demonstrar que para cada $a\in A$, $\eqclassimp a \neq \emptyset$.
Isso é uma conseqüência da reflexividade da $\sim$, pois
para todo $a\in A$, $a \in \eqclassimp a$.
\eop
Se escolher a primeira implicação na parte de (P2), a gente continua assim:
Suponha $C\neq D$ e logo sem perda de generalidade, tome $c_0 \in C\setminus D$.
Logo $c_0 \sim c$ e $c_0 \not\sim d$.
Isso já mostra que não pode ter nenhum elemento $w \in C\inter D$, pois
nesse caso usando a simetria e transitividade da $\sim$ teriamos
$c_0 \sim c \sim w \sim d$ que obrigaria $c_0 \sim d$;
impossível.

%%}}}

%%{{{ x: why_all_of_eqrel_properties_are_needed 
\exercise.
%%%{{{ meta 
\label why_all_of_eqrel_properties_are_needed
%%%}}}

Explique onde precisou cada uma das propriedades da~\ref[equivalence_relation]
(reflexividade, transitividade, simetria)
na tua resolução do~\ref[from_eqrel_to_partition].

\solution
Veja a resolução do~\ref[from_eqrel_to_partition].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A partição definida no~\ref[from_eqrel_to_partition] é muito importante
e merece seu próprio nome e sua própria notação.  Definimos agora.

%%}}}

%%{{{ df: quoset 
\definition.
%%%{{{ meta 
\label quoset
\indexes
    * quociente!conjunto    see: conjunto quociente
    ;;
\defines
    * \quoset {~A} {~R}  -- o conjunto quociente do $A$ por $R$
    * conjunto!quociente
    ;;
%%%}}}

Seja $A$ um conjunto e $\sim$ uma relação de equivalência no $A$.
Definimos o \dterm{conjunto quociente} de $A$ por $\sim$ para ser a colecção
de todas as classes de equivalência através da $\sim$.
Formalmente:
$$
\quoset A {\sim} \defeq \setst {\eqclass a {\sim}} {a \in A}.
$$

%%}}}

%%{{{ x: type_of_holed_quoset 
\exercise.
%%%{{{ meta 
\label type_of_holed_quoset
%%%}}}

Sejam $A$ conjunto e $\sim$ relação de equivalência no $A$.
Considere a função seguinte definida com buraco:
$$
\quoset A \dhole : \ \askdots
$$
Escreva um tipo válido para essa função.

\solution
$\quoset A \dhole : \eqreltype A \to \pset\pset A$.

%%}}}

%%{{{ seeing_the_quotient_set 
\note Enxergando o conjunto quociente.
%%%{{{ meta 
\label seeing_the_quotient_set
%%%}}}

Tendo um conjunto $A$ e uma relação de equivalência $(\sim)$,
no conjunto quociente $\quoset A \sim$ a relação de equivalência
$(\sim)$ se vira igualdade $(=)$ mesmo.
Numa maneira, $\quoset A \sim$ é o mundo que chegamos se nossa $(\sim)$
virar para ser a nossa $(=)$.  O mundo onde não conseguimos enxergar
diferenças entre objetos $(\sim)$-relacionados.
Para dar um exemplo, considere o conjunto dos inteiros $\ints$,
e a relação de equivalência $(\sim)$ definida pela
$$
x \sim y \defiff x \cong y \pmod 2,
$$
ou seja, $(\sim)$ relaciona os inteiros com a mesma \dterm{paridade}
(\ref[eqrel_eg_parity]).
Vamos olhar para nosso conjunto:
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
Quantos elementos ele tem?
Uma infinidade, correto?
Sim, pois todos os
$$
\dots, -3, -2, -1, 0, 1, 2, 3, \dots
$$
são distintos dois-a-dois.
Vamos lembrar uma propriedade fundamental de conjuntos:
quantos elementos tem o
$$
\set {7, 7, 7, 5, 0, 8, 8}?
$$
Temos escrito $7$ termos para ser exatamente os membros
desse conjunto, mas quantos elementos ele tem mesmo?
$4$, pois num conjunto não existe a noção de
\emph{quantas vezes} um membro pertence a ele;
só a noção de pertencer.
E isso é uma conseqüência imediata da definição de igualdade
de conjuntos.  Lembre se:
$$
A = B \defiff \lforall x {x\in A \iff x \in B}
$$
e logo
$$
\set {7, 7, 7, 5, 0, 8, 8} = \set {0, 8, 7, 5}
$$
pois realmente para todo $x$,
$$
x \in \set {7, 7, 7, 5, 0, 8, 8}
\iff
x \in \set {0, 8, 7, 5}
$$
e, sendo iguais não pode ser que eles têm cardinalidades diferentes!
Voltando para o conjunto de inteiros
$$
\set {\dots, -3, -2, -1, 0, 1, 2, 3, \dots}
$$
agora imagina que perguntamos sobre sua cardinalidade uma pessoa
$\sim$-cega.  O que quis dizer $\sim$-cega?  Ela não consegue
enxergar como distintos objetos relacionados pela $\sim$.
O que ela vai responder em nossa pergunta?
<<2>>.
Pois, para essa pessoa os
$$
\dots, -4, -2, 0, 2, 4, \dots
$$
são todos indistingüíveis, e a mesma coisa sobre os
$$
\dots, -5, -3, -1, 1, 3, 5, \dots
$$
O conjunto quociente $\quoset \ints \sim$ então,
é o conjunto que ela enxerga.
Só tem um probleminha agora:
\emph{quais} são esses dois membros do conjunto que ela enxerga?
A resposta correta aqui pode aparecer chocante mas é a seguinte:
\standout
\emph{Não importa!}
\endstandout
Uma escolha natural seria escolher como membros do $\quoset \ints \sim$
os dois conjuntos:
$$
\set{\dots, -4, -2, 0, 2, 4, \dots}
\qqtext{e}
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
$$
chegando assim no
$$
\quoset\ints\sim
= \set {
\set{\dots, -4, -2, 0, 2, 4, \dots},
\set{\dots, -5, -3, -1, 1, 3, 5, \dots}
}.
$$
De fato, pela \ref[quoset] do conjunto quociente, $\quoset\ints\sim$
realmente \emph{é} esse conjunto.  E isso faz sentido,
pois uma definição de $\quoset A R$ precisa determinar completamente
um objeto.
Mas uma outra escolha poderia ser, por exemplo, o conjunto
$$
\set{0, 1}
$$
ou qualquer conjunto feito escolhendo outros ``rótulos'' para cada
classe de equivalência:
$$
\set{{\mathbf 0}, {\mathbf 1}}, \quad
\set{\mathrm{even}, \mathrm{odd}}, \quad
\set{\mathrm{E}, \mathrm{O}}, \quad
\set{\emptyset, \set{\emptyset}}, \quad\dotsc
$$
Basta só ter exatamente dois membros.
Toda esta conversa chega no teorema e na definição seguintes:

%%}}}

%%{{{ thm: only_theorem_about_relations 
\theorem.
%%%{{{ meta 
\label only_theorem_about_relations
%%%}}}

Seja $A$ conjunto e $\sim$ uma relação binária nele.
A $\sim$ é uma relação de equivalência se e somente se
existe conjunto $Q$ e surjecção
$$
\pi : A \surto Q
\mtag[quoset_determining_surjection_1=QS1]
$$
tal que $(\sim) = (\frel \pi)$ (\ref[kernel_coimage]), ou seja, tal que
$$
x \sim y \iff \pi(x) = \pi(y).
\mtag[quoset_determining_surjection_2=QS2]
$$

\sketch.
\proofpart {\lrdir.}
O conjunto $Q$ é o $\quoset A \sim$ e a surjecção $\pi$
é a ``projecção canônica'' $\eqclass \dhole \sim$.
\crproofpart {\rldir.}
Demonstrado no~\ref[frel_is_an_eqrel].

%%}}}

%%{{{ df: general_quotient_and_determining_surjection 
\definition.
%%%{{{ meta 
\label general_quotient_and_determining_surjection
%%%}}}

No contexto do~\ref[only_theorem_about_relations],
quando temos $\pi$ e $Q$ que satisfazem
as~\mref[quoset_determining_surjection_1]
 e~\mref[quoset_determining_surjection_2],
dizemos que $Q$ é um \dterm{quociente} de $A$ por $\sim$,
e que $\pi$ é uma \dterm{surjecção determinante} da $\sim$.

%%}}}

%%{{{ remark: choose_your_quotient_wisely 
\remark.
%%%{{{ meta 
\label choose_your_quotient_wisely
%%%}}}

A demonstração do~\ref[only_theorem_about_relations] fornece
o quociente $\quoset A \sim$ e a surjecção determinante
$\lam x {\eqclass x \sim}$
(ou, com buracos, $\eqclass {\dhole} {\sim}$)
que mapeia cada membro de $A$ a sua classe de equivalência.
Vamos dizer que esse será o ``conjunto quociente oficial'',
e a ``surjecção determinante oficial''.
Mas dependendo do uso, pode ser que para uns
casos é melhor utilizar outro quociente
e outra surjecção determinante.
E até pior---ou, na verdade, melhor---pessoas
diferentes podem escolher quocientes diferentes
como \emph{mais iluminantes}.
Vamos ver uns exemplos.
Em cada um, vamos ver o oficial, e comparar com uma
alternativa melhor.
Vamos usar a notação
$$
\quoset A \sim \pseudoeq Q
$$
para afirmar que $Q$ é \emph{um} quociente que possivelmente
parece mais iluminante do que o oficial.

%%}}}

%%{{{ eg: quoset_eg_countries 
\example.
%%%{{{ meta 
\label quoset_eg_countries
%%%}}}

Considere um conjunto de pessoas $P$.
Na relação do~\ref[eqrel_eg_countries]
$$
x \sim y \defiff \text{$x$ e $y$ nasceram no mesmo país}
$$
o conjunto quociente oficial é feito por conjuntos
de pessoas compatriotas.  Uma escolha melhor seria
usar os próprios países como quociente, e a
$$
\pi(x) = \text{o país em que $x$ nasceu}.
$$
Para ser sobrejetora mesmo, no quociente não vamos
incluir paises em quais nenhuma pessoa (de $P$) nasceu.
Seja $C$ esse conjunto de paises $c$ onde pelo menos
uma pessoa $p\in P$ nasceu.
Então temos
$$
\quoset {P} {\sim} \pseudoeq C.
$$
Num certo sentido, \emph{dividindo esse conjunto de pessoas
$P$ pela relação $\sim$}, chegamos no conjunto de
paises $C$.

%%}}}

%%{{{ x: quoset_children 
\exercise.
%%%{{{ meta 
\label quoset_children
%%%}}}

Na relação do~\ref[eqrel_eg_children]
$$
x \sim y \defiff \text{$x$ e $y$ têm a mesma quantidade de filhos}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

%%}}}

%%{{{ x: quoset_teams 
\exercise.
%%%{{{ meta 
\label quoset_teams
%%%}}}

Na relação do~\ref[eqrel_eg_teams]
$$
x \sim y \defiff \text{$x$ e $y$ jogam no mesmo clube}
$$
qual é o conjunto quociente (oficial)?
Qual tu escolharia como melhor?

%%}}}

%%{{{ eg: some_eqclasses_geometrically_and_algebrically 
\example.
%%%{{{ meta 
\label some_eqclasses_geometrically_and_algebrically
%%%}}}

Vamos descrever geometricamente as classes de equivalência das
relações do~\ref[equivalent_relations_on_euclidean_plane] no $\reals^2$,
ou seja, determinar os conjuntos quocientes correspondentes.
Lembramos as relações:
$$
\align
\tup{x,y} \sim_1 \tup{x',y'}
&\iff x = x'\\
\tup{x,y} \sim_2 \tup{x',y'}
&\iff y = y'\\
\tup{x,y} \sim_{\textrm N} \tup{x',y'}
&\iff \norm{ \tup{x,y} } = \norm{ \tup{x',y'} }
\endalign
$$
Em cada classe de equivalência da $\sim_1$ então, estão todos os
pares que concordam na sua primeira coordenada.  Ou seja,
cada classe é uma retas vertical, e o conjunto quociente é
colecção de todas essas linhas.  Olhando ainda mais de longe,
podemos ``identificar'' cada reta com seu representante canônico
que fica no eixo-$x$, ou seja, podemos dizer que
$$
\quoset {\reals^2} {\sim_1} \pseudoeq \reals.
$$
A situação é similar para a $\sim_2$, so que essa vez são todas
as retas horizontais, mas olhando novamente de longe,
identificamos cada reta com seu representante canônico
que agora fica no eixo-$y$, ou seja, novamente temos
$$
\quoset {\reals^2} {\sim_2} \pseudoeq \reals.
$$
Sobe a $\sim_{\textrm N}$, a classes do seu
conjunto quociente são todos os cíclos com centro a origem $(0,0)$,
incluindo o ``ciclo-trivial'' com raio $0$, que acaba sendo apenas
o ponto $(0,0)$ mesmo.
Essa vez, identificando cada cíclo com seu raio, chegamos na
$$
\quoset {\reals^2} {\sim_{\textrm N}} \pseudoeq \reals_{\geq 0}.
$$
Por enquanto, entendemos todas essas $\pseudoeq$ apenas como
um ``modo de falar''.
Cuidado pois nenhuma delas é uma verdadeira $(=)$!
Os dois lados dessas ``igualdades'' são conjuntos cujos membros
nem são objetos do mesmo tipo!
No lado esquerdo pertencem \emph{conjuntos de pares de números reais},
no lado direito pertencem \emph{números reais}.

%%}}}

%%{{{ x: more_eqclasses_geometrically_and_algebrically 
\exercise.
%%%{{{ meta 
\label more_eqclasses_geometrically_and_algebrically
%%%}}}

Descreva geometricamente e algebricamente os conjuntos quocientes
das relações de equivalência
do~\ref[equivalent_relations_on_euclidean_space].

\hint
Entendeu o~\ref[some_eqclasses_geometrically_and_algebrically]?

\solution
O $\quoset {\reals^3} {\sim_3}$ parece lasanha:
é composto por todos os planos horizontais.
O $\quoset {\reals^3} {\sim_{1,2}}$ é composto pelas todas as retas
verticais (perpendiculares no $xy$-plano).
O $\quoset {\reals^3} {\sim_{\textrm N}}$ é composto pelas todas as
sferas com centro na origem.
Informalmente temos as ``equações'' seguintes:
$$
\xalignat3
\quoset {\reals^3} {\sim_3}             & \pseudoeq \reals &
\quoset {\reals^3} {\sim_{1,2}}         & \pseudoeq {\reals^2} &
\quoset {\reals^3} {\sim_{\textrm N}}   & \pseudoeq \reals_{\geq 0}.
\endxalignat
$$
Na primeira identificamos cada plano com sua altura;
na segunda cada reta com sua sombra no $xy$-plano;
na terceira casa sfera com seu raio.

%%}}}

%%{{{ x: quoset_of_congruence_mod_m 
\exercise.
%%%{{{ meta 
\label quoset_of_congruence_mod_m
%%%}}}

Seja $m\in\nats_{>1}$.
Já demonstrou no~\ref[congruence_mod_m_is_an_eqrel_again] que a relação de
congruência módulo $m$ é uma relação de equivalência.
Vamos denotá-la \symq{$\congmod m$}.
Então: qual é o seu conjunto quociente?
Também: seguindo a idéia do~\ref[some_eqclasses_geometrically_and_algebrically],
com que tu ``identificaria'' o $\quoset \ints {\congmod m}$?

%%}}}

%%{{{ x: cong_0_and_cong_1 
\exercise.
%%%{{{ meta 
%%%}}}

Continuando: quais são as relações $\congmod 0$ e $\congmod 1$?

\hint
Uma é a igualdade e outra é a trivial $\True$.
Qual é qual?  Demonstre.

\solution
Temos:
$$
\align
a \congmod 0 b &\iff 0 \divides a - b \iff a - b = 0 \iff a = b \\
a \congmod 1 b &\iff 1 \divides a - b \iff \True.
\endalign
$$
Ou seja:  $(\congmod 0) = (\eqof \ints)$ e $(\congmod 1) = (\True)$.

%%}}}

%%{{{ x: isPred_quoset 
\exercise.
%%%{{{ meta 
\label isPred_quoset
%%%}}}

Descreva o conjunto quociente
$\quoset{\nats}{\rtranscl{\leftrightarrow}}$ do~\ref[isPred].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já vimos que cada relação de equivalência determina uma partição:
seu conjunto quociente.
Mas parece que a partição é um conceito mais geral, pois nos permite
``separar em classes'' um conjunto numa forma que não é obrigada seguir
nenhuma lógica ou regra: sem nenhuma relação de equivalência
``por trás''.
Ou seja: \emph{talvez tem partições que não são conjuntos quocientes de
nenhuma relação de equivalência.}
Mas essa intuição razoável é enganosa!
Vamos investigar agora o caminho de volta: mostrar que cada
partição $\scr A$ também determina uma relação de equivalência
$\sim_{\scr A}$, e sim, a partição $\scr A$ é um conjunto quociente:
o $\quoset A {\sim_{\scr A}}$!

%%}}}

%%{{{ x: from_partition_to_eqrel 
\exercise de partição para equivalência.
%%%{{{ meta 
\label from_partition_to_eqrel
%%%}}}

Seja $A$ conjunto e $\scr A$ partição dele.
Escreva claramente como definir uma relação de equivalência $\sim_{\scr A}$
no $A$ tal que $\quoset A {\sim_{\scr A}} = \scr A$.

\hint
Defina a relação tal que dois objetos são relacionados sse eles pertencem
no mesmo membro da família $\scr A$.

\hint
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
Demonstre que $\sim_{\scr A}$ é uma relação de equivalência.

\solution
Definimos a $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y
\defiff
\lexists {C \in \scr A} {x,y \in C}.
$$
\crtabproofpart {A relação $\sim_{\scr A}$ é uma relação de equivalência.}
\crproofpart {Reflexiva.}
Tome $a \in A$.
Precisamos mostrar que existe $C \in \scr A$ tal que $a \in C$.
Mas, como $\scr A$ é uma partição \byfact{P1}, temos que $\Union \scr A = A$.
Seja então $C$ tal que $a \in C \in \scr A$.  Logo $a \sim_{\scr A} a$.
\crproofpart {Simétrica.}
Trivial pois $x,y \in C \iff y,x \in C$.
\crproofpart {Transitiva.}
Suponha $x \sim_{\scr A} y$ e $y \sim_{\scr A} z$.
Logo sejam $C,D \in \scr A$ tais que $x,y \in C$ e $y,z \in D$.
Agora, como $y \in C\inter D$ e $\scr A$ é uma partição \byfact{P2},
temos $C = D$.  Ou seja, $x,z \in C \in \scr A$ e logo $x \sim_{\scr A} z$.
\crtabproofpart {O conjunto quociente $\quoset A {\sim_{\scr A}}$ é a partição $\scr A$.}
\crproofpart {\lrdirset.}
Tome $C \in \quoset A {\sim_{\scr A}}$.
Seja $c \in A$ tal que $C = \eqclassimp c$.
Como $c \in \Union \scr A$ ($\scr A$ partição \byfact{P1}),
seja $C'$ o único ($\scr A$ partição \byfact{P2}) membro da $\scr A$ tal que $c \in C'$.
Basta mostrar que $C = C'$.
Tome $x \in C = \eqclassimp c$.
logo $x \sim_{\scr A} c$, e logo existe $D' \in \scr A$ tal que $x,c \in D'$.
Mas pela escolha do $C'$, temos $D' = C'$, e logo $x \in C'$ e $C \subset C'$.
Conversamente, tome $x' \in C'$.
Logo $x',c \in C'$, logo $x'\sim_{\scr A} c$, e logo $x' \in \eqclassimp c = C$.
Ou seja, $C' \subset C$.
\crproofpart {\rldirset.}
Tome $C' \in \scr A$.
Como $C' \neq \emptyset$ (pois $\scr A$ é partição~\byfact{P3}),
seja $c' \in C'$.
Basta demonstrar que $\eqclassimp {c'} = C'$.
Tome $x \in \eqclassimp {c'}$.
Logo $x \sim_{\scr A} c'$, e logo seja $D' \in \scr A$ tal que $x,c' \in D'$.
Mas, como $c' \in C'\inter D'$, concluimos que $C'=D'$ (pela~\byfact{P2}).
Ou seja, $x \in C'$.
Conversamente, tome $x' \in C'$.
Como $c'\in C'$, logo $x' \sim_{\scr A} c'$ pela definição da $\sim_{\scr A}$,
ou seja $x'\in\eqclassimp {c'}$.

%%}}}

%%{{{ x: why_all_of_partition_properties_are_needed 
\exercise.
%%%{{{ meta 
\label why_all_of_partition_properties_are_needed
%%%}}}

Explique onde precisou cada uma das condições (P1)--(P3) da~\ref[partition]
na tua resolução do~\ref[from_partition_to_eqrel].

\solution
Veja a resolução do~\ref[from_partition_to_eqrel].

%%}}}

%%{{{ df: induced_equivalence_relation_and_partition 
\definition.
%%%{{{ meta 
\label induced_equivalence_relation_and_partition
\defines
    * partição!induzida
    * relação!induzida
    ;;
%%%}}}

Chamamos a $\sim_{\scr A}$ a \dterm{relação de equivalência induzida pela $\scr A$}.
Similarmente chamamos o conjunto quociente $\quoset A {\sim}$
a \dterm{partição induzida pela $\sim$}.

%%}}}

%%{{{ x: how_many_partitions_on_3 
\exercise.
%%%{{{ meta 
\label how_many_partitions_on_3
%%%}}}

Seja $A$ conjunto finito com $\card A = 3$.
Quantas partições de $A$ existem?
Por que isso resolve o~\ref[how_many_equivalence_relations_on_3]?

%%}}}

%%{{{ Summary 
\note Resumo.
%%%{{{ meta 
\label eqrel_quoset_partition_summary
\DefFun eqrelize
\DefFun quotient
\DefOp EqRel
\DefOp Part
%%%}}}

O coração dessa secção fica nos exercícios~\reftag[from_eqrel_to_partition]
e~\reftag[from_partition_to_eqrel].  Vamos resumir o que tá acontecendo.
Para qualquer conjunto $A$ definimos os conjuntos $\EqRel(A)$
de todas as suas relações de equivalência e $\Part(A)$ de
todas as suas partições:
\mathcol
\EqRel(A) &\defeq \setstt {{\sim}} {$\sim$ é uma relação de equivalência no $A$} \\
\Part(A)  &\defeq \setstt {{\scr A}} {$\scr A$ é uma partição do $A$}.
\endmathcol
Dado conjunto $A$ encontramos como definir \emph{funções}
$$
\cdopt{sep=2cm}
\EqRel(A) \ar[r, shift left, "\quotient"] \|
\Part(A)  \ar[l, shift left, "\eqrelize"]
\endcd
$$
que ``traduzem'' qualquer relação de equivalência para sua partição induzida
e qualquer partição para sua relação de equivalência induzida.
São definidas pelas:
\mathcols 2
\quotient(\sim) &\defeq \quoset A {\sim} &
x \relp{\eqrelize(\scr A)} y &\defiff \lexists {C\in \scr A} {x,y \in C}.
\endmathcols
Essas traduções são fieis, no sentido de:
\mathcols 2
\quotient \of \eqrelize &= \idof {\Part(A)} &
\eqrelize \of \quotient &= \idof {\EqRel(A)}.
\endmathcols
De fato, ambas são bijecções, e cada uma é a inversa da outra.
Com as primeiras notações que usamos e também com palavras, temos:
\mathcall
{\sim_{\scr A_{\sim}}}   &= {\sim}    \called{<<a relação induzida pela partição induzida pela $\sim$ é a própria $\sim$>>}; \\
{\scr A_{\sim_{\scr A}}} &= {\scr A}  \called{<<a partição induzida pela relação induzida pela $\scr A$ é a própria $\scr A$>>}.
\endmathcall
Não se preocupe se o conceito do \emph{conjunto quociente} ainda parece meio
distante ou abstrato demais.  Ataque os problemas e os exercícios, e confie
que estudando teoria dos grupos (\ref[Group_theory]) isso vai mudar!

%%}}}

%%{{{ two_sides_of_the_same_coin_eqrel_partition 
\note Dois lados da mesma moeda.
%%%{{{ meta 
\label two_sides_of_the_same_coin_eqrel_partition
%%%}}}

Vimos aqui que ``partição'' e ``classe de equivalência'' são
\emph{dois lados da mesma moeda}.  Considere um conjunto $A$.
\elist:
\li:
Quando precisamos \emph{definir uma relação de equivalência} no $A$,
podemos \emph{definir uma partição} $\scr A$ de $A$ e usar a $\sim_{\scr A}$.
\li:
Conversamente, quando precisamos \emph{definir uma partição} no $A$,
podemos \emph{definir uma relação de equivalência} $\sim$ no $A$
e usar a $\quoset A {\sim}$.
\li:
Além disso, quando temos uma relação $\sim$ no $A$ e precisamos
\emph{demonstrar que ela é uma relação de equivalência},
podemos definir uma família $\scr A$ de subconjuntos de $A$,
\emph{demonstrar que ela é uma partição}, e mostrar que:
$$
x \sim y \iff \lexists {C\in\scr A} {x,y \in C}.
$$
\li:
Finalmente, quando temos uma família $\scr A$ de subconjuntos de $A$
e precisamos \emph{demonstrar que ela é uma partição}, podemos definir
a relação $\sim_{\scr A}$ pela
$$
x \sim_{\scr A} y \iff \lexists {C\in\scr A} {x,y \in C}
$$
e \emph{demonstrar que ela é uma relação de equivalência}.
\endelist
Não esqueça essas dicas!

%%}}}

%%{{{ df: kernel_coimage 
\definition.
%%%{{{ meta 
\label kernel_coimage
\defines
    * \coim {~f}  -- a coimagem da $f$
    * \ker {~f}  -- o kernel da $f$
    * coimagem
    * kernel
    ;;
%%%}}}

Seja $f : X \to Y$ e defina a relação binária $\frel f$ no $X$ pela
$$
x_1 \frel f x_2 \defiff f(x_1)=f(x_2).
$$
Chamamos a $\frel f$ o \dterm{kernel} da $f$, e seu conjunto quociente
a \dterm{coimagem} da $f$.
Usamos também os símbolos $\ker f$ e $\coim f$ respectivamente.

%%}}}

%%{{{ x: frel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label frel_is_an_eqrel
%%%}}}

Com os dados da~\ref[kernel_coimage] mostre que $\frel f$
é uma relação de equivalência e descreva os elementos da coimagem.
O que podemos dizer se $f$ é injetora?
Se ela é sobrejetora?

\solution
\proofpart {$\frel f$ é uma relação de equivalência.}
Cada uma das três propriedades é uma conseqüência direta da
propriedade correspondende da igualdade.  Em detalhe:
\crproofpart {Reflexiva.}
Seja $x\in X$.
Temos $x \frel f x$ pois $f(x) = f(x)$ (reflexividade da $(=)$).
\crproofpart {Transitiva.}
Sejam $a,b,c \in X$ tais que $a \frel f b$ e $b \frel f c$.
Logo $f(a) = f(b)$ e $f(b) = f(c)$.
Logo $f(a) = f(c)$ (transitividade da $(=)$), ou seja, $a \frel f c$.
\crproofpart {Simétrica.}
Sejam $a, b \in X$ tais que $a \frel f b$, e logo $f(a) = f(b)$
e logo $f(b) = f(a)$ (simetria da $(=)$), ou seja, $b \frel f a$.
\crtabproofpart {Descripção do conjunto quociente.}
O conjunto quociente ``é'' a imagem $\ima f$.
Caso que $f$ é injetora a relação acaba sendo a igualdade e logo
o conjunto quociente acaba sendo o próprio $\dom f$.
Caso que $f$ é sobrejetora nada demais muda,
só que agora $\ima f = \cod f$.

%%}}}

%%{{{ x: gen_frel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label gen_frel_is_an_eqrel
%%%}}}

Seja $f : A \to B$ e seja $\sim_B$ uma relação de equivalência no $B$.
Defina a $\frel {f,\sim_B}$ no $A$ pela
$$
x_1 \frel {f,\sim_B} x_2 \defiff f(x_1) \sim_B f(x_2).
$$
A $\frel {f,\sim_B}$ é uma relação de equivalência?

\solution
A $\frel {f,\sim_B}$ é uma relação de equivalência sim.
Isso já foi demonstrado, pois a resolução do~\ref[frel_is_an_eqrel]
usou apenas o fato que a igualdade é uma relação de equivalência.

%%}}}

%%{{{ x: immediate applications 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre que todas as relações dos
exemplos~\reftag[equivalent_relations_on_euclidean_plane]
e~\reftag[equivalent_relations_on_euclidean_space]
são casos especiais do~\ref[frel_is_an_eqrel]
(e logo são relações de equivalência ``gratuitamente'').

\hint
Para cada uma delas, precisa definir completamente a
$f : A \to B$ (esclarecendo também quais são os $A,B$).

%%}}}

\endsection
%%}}}

%%{{{ Recursive definitions 
\section Relações recursivas.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Aqui são exemplos familiares para definir recursivamente relações.

%%}}}

%%{{{ eg: even_and_odd_rels_recursion 
\example.
%%%{{{ meta 
%%%}}}

No $\nats$ definimos:
$$
\xalignat2
\Even(0).      &                       &\lnot\Odd(0).&\\
\Even(n+1)     &\defiff \lnot \Even(n) &\Odd(n+1)&\defiff \lnot \Odd(n)
\intertext{Ou, alternativamente, usando duas bases:}
\Even(0).      &                       &\lnot\Odd(0).&\\
\lnot\Even(1). &                       &\phantom\lnot\Odd(1).&\\
\Even(n+2)     &\defiff \Even(n)       &\Odd(n+2)&\defiff \Odd(n)
\endxalignat
$$

%%}}}

%%{{{ eg: even_and_odd_rels_mutual_recursion 
\example Recursão mutual.
%%%{{{ meta 
%%%}}}

$$
\xalignat2
\Even(0).  &                  &\lnot\Odd(0).&\\
\Even(n+1) &\defiff \Odd(n)   &\Odd(n+1)&\defiff \Even(n)
\endxalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Num paradigma de programação declarativa, na \emph{programação lógica},
programamos definindo relações nesse jeito.

%%}}}

\endsection
%%}}}

%%{{{ Logic_programming 
\section Programação lógica.
%%%{{{ meta 
\label Logic_programming
%%%}}}

\TODO Escrever e combinar com a seção anterior.

\endsection
%%}}}

%%{{{ Higher-order relations 
\section Relações de ordem superior.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Talvez você já se perguntou o que acontece se numa frase como a
$$
\mtrel{João ama Maria}
$$
em vez de substrituir os objetos ``João'' e ``Maria'' com buracos,
substituir o próprio verbo ``amar'':
$$
\mtrel{João {\thole} Maria}.
$$
Chegamos assim no conceito de relações de ordem superior.
Não vale a pena investigar (ainda) esse conceito pois necessita
mais umas ferramentas (e pouco mais maturidade).
Voltamos depois de estudar programação lógica (\ref[Logic_programming])
e lógicas de ordem superior (\ref[Mathematical_logic]).

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_relations 
\section Pouco de cats---categorias e relações.
%%%{{{ meta 
\label Categories_and_relations
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: rats_via_eqrel_no_ints 
\problem.
%%%{{{ meta 
\label from_ints_to_rats_via_eqrel
%%%}}}

Defina no $\ints\times\ints_{\neq0}$ a relação
$$
\tup{a,b} \approx \tup{c,d}
\defiff
ad = bc
$$
Mostre que $\approx$ é uma relação de equivalência
e descreva suas classes de equivalência:
$\quoset {\ints\times\ints_{\neq0}} {\approx} \pseudoeq ?$

%%}}}

%%{{{ prob: like_vitali_rel 
\problem.
%%%{{{ meta 
\label like_vitali_rel
%%%}}}

Defina no $\rats$ a relação
$$
r \sim s \defiff r-s\in\ints.
$$
Demonstre que $\sim$ é uma relação de equivalência e descreva as
classes do $\quoset {\rats} {\sim}$.

%%}}}

%%{{{ prob: vitali_rel 
\problem.
%%%{{{ meta 
\label vitali_rel
%%%}}}

Defina no $\reals$ a relação
$$
x \sim y \defiff x-y\in\rats.
$$
Demonstre que $\sim$ é uma relação de equivalência e descreva as classes
do $\quoset {\reals} {\sim}$.

%%}}}

%%{{{ prob: epimono_factorization_teaser_now_easy 
\problem Agora é fácil.
%%%{{{ meta 
\label epimono_factorization_teaser_now_easy
%%%}}}

Resolvemos o~\ref[epimono_factorization_teaser].
Seja $f : A\to B$ uma função qualquer, e considere a $(\frel f)$
da~\ref[kernel_coimage].
Então $f$ pode ser ``decomposta'' assim:
$$
\cdopt{sep=1.5cm}
A   \ar[r,two heads, ""]\ar[rrr, bend left, "f"] \|
\quoset A {\frel f} \ar[r,two heads,tail, "\tilde f"'] \|
\ima f              \ar[r,hook, ""] \|
B
\endcd
$$
onde a primeira função é a \dq{projecção} $\eqclassimp {\dhole}$,
a terceira é a inclusão $\ima f \subset B$, e a bijecção no meio
é a função definida pela
$$
\tilde f(\eqclassimp a) = f(a),
$$
que garanta a comutatividade do diagrama acima.
Mesmo assim, falta demonstrar umas coisas.
Ache o que, e prove.

\hint
Precisas mostrar que:
(1) a $\tilde f$ é bem-definida;
(2) a $\tilde f$ é uma bijecção.

\hint
(1)
Para mostrar que $\tilde f$ é bem-definida, precisa mostrar que
a escolha do representante da classe não afeta o valor da função.
Ou seja, tome $a, a'\in A$ e mostre que:
$$
\eqclass a = \eqclass {a'} \implies f(a) = f(a').
$$
(2)
A bijectividade da $\tilde f$ não precisa de dicas!

%%}}}

%%{{{ word_on_the_street_for_order_of_limit_depending_quantifiers 
\note Com palavras da rua.
%%%{{{ meta 
\label word_on_the_street_for_order_of_limit_depending_quantifiers
%%%}}}

Já encontramos várias vezes situações onde a troca dos $\forall\exists$
para $\exists\forall$ mudou completamente o significado
(o~\ref[mother_of_all] é o mais ilustrativo).
Vamos focar agora no caso onde o universo é o $\nats$, o primeiro
quantificador quantifica o $n$ sobre todo o $\nats$, mas o segundo
quantifica todos os naturais \emph{começando com esse $n$}.
Tu já fez o~\ref[set_liminf_limsup_problem_heart_level], certo?
Seria bom achar aqui mais uma maneira de entender essa situação,
explicando os dois significados \emph{com palavras de rua}.
A situação aqui é parecida:
$$
\gather
\pexists {n\in\nats} \lforallt {x \geq n} { algo }\phantom.\\
\pforall {n\in\nats} \lexistst {x \geq n} { algo }.
\endgather
$$
Supondo que esse ``algo'' tá dizendo que \wq{$x$ é legal},
as afirmações acima com palavras de rua ficam assim:
$$
\align
\pexists {n\in\nats} \lforallt {x \geq n} { $x$ é legal }
&\quad\textwq{A partir dum ponto, todos são legais.} \\
\pforall {n\in\nats} \lexistst {x \geq n} { $x$ é legal }
&\quad\textwq{Sempre vai ter legais.}
\endalign
$$
Assim, ambas nos permitem concluir que tem uma infinidade de legais.
Mas quantos \emph{ilegais} tem?  A primeira nos permite concluir
que tem apenas uma quantidade finita de ilegais, pois, escolhendo
tal $n_0\in\nats$ cuja existência é afirmada sabemos que todas
as possíveis excessões (os ``possivelmente ilegais'') estão
entre eles: $0,1,\dotsc,n_0-1$.
Note que isso não quis dizer que todos eles são ilegais.
Por outro lado, a segunda, não nos permite concluir isso.
O fato que ``sempre vai ter legais'', não exclue a possibilidade
de ``sempre vai ter ilegais'' também!
Por exemplo, sempre vai ter números pares, mas sempre vai ter números
ímpares também, né?
Os problemas seguintes brincam com essas idéias.

%%}}}

%%{{{ prob: efeq_vs_feeq 
\problem.
%%%{{{ meta 
\label efeq_vs_feeq
\pdefs
    \pdef efeq {\rel{\buildrel{{}_{\exists\forall}} \over =}}
    \pdef feeq {\rel{\buildrel{{}_{\forall\exists}} \over =}}
    ;;
%%%}}}

Defina no $(\nats\to\nats)$ as relações seguintes:
$$
\align
f \efeq g &\defiff \pexists {n\in\nats} \lforall {x \geq n} { f(x) = g(x) }\\
f \feeq g &\defiff \pforall {n\in\nats} \lexists {x \geq n} { f(x) = g(x) }
\endalign
$$
Para cada uma das relações acima, decida se ela é relação de equivalência (demonstre ou refute).
Se é, descreva seu conjunto quociente.

%%}}}

%%{{{ why_called_preorder 
\problem Por que preordem?.
%%%{{{ meta 
\label why_called_preorder
%%%}}}

Justifique o nome ``preordem'': mostre como começando com uma preordem
$R$ num conjunto $A$, podemos construir uma relação $R'$ consultando a $R$.
Pode demonstrar essa afirmação em vários jeitos, mas o objectivo é achar
a ordem $R'$ mais natural e a mais \emph{justa}, seguindo a preordem $R$.

\hint
A ordem $R'$ não vai ser uma ordem no $A$, pois não podemos
decidir como ``resolver conflitos'' do tipo $R(a,b)$ e $R(b,a)$.
Não podemos arbitrariamente escolher um dos $a,b$ como ``menor'',
botando assim por exemplo $R'(a,b)$ e $\lnot R'(b,a)$.
Isso não seria justo!
Então, em qual conjunto $A'$ faz sentido definir nossa ordem $R'$?

%%}}}

%%{{{ prob: how_many_partitions 
\problem Números Bell.
%%%{{{ meta 
\label how_many_partitions
\indexes
    * Bell!números see: Bell
    ;;
\credits
    * Bell!números
    ;;
%%%}}}

Seja $A$ conjunto finito.
Quantas partições de $A$ existem?

\hint
Conte ``manualmente'' os casos com $\card A = 0, 1, 2, 3$.

\hint
(Os números que tu achou na dica anterior devem ser: $1$, $1$, $2$, e $5$, respectivamente.)
Chame $B_n$ o número de partições dum conjunto finito com $n$ elementos.
Use recursão para definir o $B_n$.

\hint
Já temos umas bases desde a dica anterior:
$$
\align
B_0 &= 1\\
B_1 &= 1\\
B_2 &= 2\\
B_3 &= 5
\intertext{Para a equação recursiva,}
B_{n+1} &= \dots
\endalign
$$
lembra-se que podes considerar conhecidos \emph{todos} os números
$B_k$ para $k \leq n$.

\hint
Sejam $a_0,\dots,a_n$ os $n+1$ elementos de $A$
e considere uma partição arbitrária $\scr A$ dele.
Sendo partição, existe exatamente um conjunto-classe $A_0$ no $\scr A$
tal que $a_0\in A_0$.
Influenciados pela notação de classes de equivalência, denotamos
o $A_0$ por $\eqclassimp {a_0}$.
Tirando esse conjunto da partição $\scr A$ chegamos no
$$
\scr A \setminus \set {\eqclassimp {a_0}}
$$
que é (certo?)\ uma partição do conjunto
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
Seja $k$ o número de elementos desse conjunto.
Quais são os possíveis valores desse $k$?

\hint
Vamos melhorar nossa notação para nos ajudar raciocinar.
O conjunto 
$$
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
da dica anterior, depende de quê?
Como a gente fixou uma enumeração dos elementos do $A$,
ele depende apenas na partição $\scr A$.
Introduzimos então a notação
$$
R_{\scr A} \asseq
\Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}.
$$
E denotamos o $k$ da dica anterior com
$k_{\scr A} \asseq \card {R_{\scr A}}$.
O $k_{\scr A}$ da dica anterior pode ter qualquer um dos valores
$k_{\scr A}=0,\dotsc,n$.
E agora?

\hint
Agora separe todas as partições $\scr A$ de $A$ em grupos dependendo
no valor de $k_{\scr A}$, ache o tamanho de cada grupo separadamente,
e use o princípio da adição para achar a resposta final.

\hint
Todas as partições do $A$ são separadas assim em:
\tlist:
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = 0$;
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = 1$;
\li $\eqvdots$:
\li: as partições $\scr A$ de $A$ tais que $k_{\scr A} = n$.
\endtlist
Seja
$N_i$
o número das partições $\scr A$ de $A$ tais que $k_{\scr A} = i$.
Graças ao princípio da adição, procura-se o somatório $\Sum_{i=0}^n N_i$.
Ache o valor do arbitrário $N_i$.

\hint
De quantas maneiras pode acontecer que o
$$
R_{\scr A} = \Union\paren{\scr A \setminus \set {\eqclassimp {a_0}}}
$$
tem $i$ elementos?

\hint
Sabemos que o $a_0$ não pode ser um deles,
então precisamos escolher $i$ elementos dos $n$ seguintes: $a_1, \dotsc, a_n$.
Ou seja, de $\comb n i$ maneiras.
Cada escolha $A_i$ corresponde numa colecção de partições:
$$
\Big\{
\eqclassimp {a_0}\ 
,
\underbrace{\quad\dots\quad}_{\hbox{partição do $A_i$}}
\Big\}
$$

\hint
Sabemos a quantidade de partições de qualquer conjunto de tamanho $i$
com $i\leq n$: são $B_i$.

\solution
Seguindo todas as dicas, basta definir:
$$
\align
B_0 &= 1\\
B_{n+1}
&= \Sum_{i=0}^n N_i
= \Sum_{i=0}^n \comb n i B_i
\endalign
$$
Essa seqüência de números é conhecida como
\credited[Bell : números]\dterm{números~Bell}.

%%}}}

%%{{{ prob: same_limits_eqrel 
\problem.
%%%{{{ meta 
\label same_limits_eqrel
%%%}}}

No $(\nats\to\reals)$ defina a relação
$$
a\sim b
\defiff
\lim\nolimits_n a_n = \lim\nolimits_n b_n
\mlor
\text{nenhum dos dois limites é definido.}
$$
descreva o $\quoset {(\nats\to\reals)} {\sim}$.

%%}}}

%%{{{ prob: smiles_and_frowns 
\problem.
%%%{{{ meta 
\label smiles_and_frowns
%%%}}}

No conjunto $\reals$ defina as relações:
$$
\align
x \smile y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x \leq n \leq y} \\
x \frown y
    &\defiff x \leq y
             \mland
             \lnot \lexists {n \in \ints} {x < n < y}
\endalign
$$
Sejam $\Smile$ o fecho reflexivo-simétrico da $\smile$,
e $\Frown$ o fecho simétrico da $\frown$.
\eop
(i) Demonstre que $\Smile$ é uma relação de equivalência;
(ii) Demonstre ou refute a afirmação: \emph{$\Frown$ é uma relação de equivalência}.

\hint
Sobre a (i): veja o~\ref[two_sides_of_the_same_coin_eqrel_partition].
Sobre a (ii): a afirmação é falsa; refute!

\hint
Sobre a (i):
Defina a partição de $\reals$
$$
\scr C \defeq
\mubraceb {\setst {(n,n+1)} {n\in\ints}} {\cal I}
\union
\mubraceb {\setst {\set{n}} {n\in\ints}} {\cal S}.
$$
Basta demonstrar que $\scr C = \quoset \reals {\Smile}$.
\eop\noi
Sobre a (ii):
mostre com um contraexemplo que $\Frown$ não é transitiva.

\solution
(i)
Defina a partição de $\reals$
$$
\scr C \defeq
\mubraceb {\setst {(n,n+1)} {n\in\ints}} {\cal I}
\union
\mubraceb {\setst {\set{n}} {n\in\ints}} {\cal S}.
$$
Basta demonstrar que
$
\scr C = \quoset \reals {\Smile}
$,
ou seja:
$$
x\Smile y \iff \lexists {C\in \scr C} {x\in C \mland y\in C}.
$$
{\rldir}.
Trivial nos dois casos $C\in\cal I$ e $C\in\cal S$.
\eop\noi
{\lrdir}.
Pela hipótese, $x=y$ ou $x\smile y$ ou $y\smile x$.
Separamos então em casos:
\eop\noi
\proofcase {Caso $x=y$:}
Caso $x\in\ints$ tome $C=\set x\in\cal S$.
Caso $x\nin\ints$ tome $C=(\floor x, \floor x + 1)\in\cal I$.
\eop\noi
\proofcase {Caso $x\smile y$:}
Nesse caso $[x,y] \inter \ints = \emptyset$.
Facilmente, $\floor x < x \leq y < \floor x + 1$.
Tome novamente $C=(\floor x, \floor x + 1)\in\cal I$.
\eop\noi
\proofcase {Caso $y\smile x$:}
Similar.
\eop
(ii) Não é, pois não é transitiva.
Observe que $0 \Frown 1$, pois não existe inteiro no $(0,1)$,
e similarmente $1 \Frown 2$.
Mas $0 \not\Frown 2$, pois $1$ é inteiro e $1\in(0,2)$.

%%}}}

%%{{{ prob: cyclic_and_euclidean_closures 
\problem Fecho cíclico, fechos euclideanos.
%%%{{{ meta 
\label cyclic_and_euclidean_closures
\defines
    * \cclo {~R}  -- o fecho cíclico da $R$
    * \leclo {~R}  -- o fecho left-euclideano da $R$
    * \reclo {~R}  -- o fecho right-euclideano da $R$
    * fecho!cíclico
    * fecho!left-euclideano
    * fecho!right-euclideano
    ;;
%%%}}}

Seja $R$ uma relação num conjunto $A$.
Defina seus fechos: cíclico~($\cclo R$), left-euclideano~($\leclo R$), right-euclideano~($\reclo R$).

%%}}}

%%{{{ prob: tclosure_recursive_def 
\problem.
%%%{{{ meta 
%%%}}}

Seja $R$ relação binária num conjunto $A$.
Dê uma definição recursiva do fecho transitivo $\tclosure R$.

\solution
Definimos:
$$
x \tclosure R y
\defiff
x \rel R y \mlor \lexists {w \in A} {x \rel R w \mland w \tclosure R y}.
$$
Pense para visualizar como isso ``funciona''.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

O \cite[velleman: Cap.~4] defina e trata relações
diretamente como conjuntos, algo que não fazemos nesse texto.
De novo: muitos livros seguem essa abordagem, então o leitor é conselhado
tomar o cuidado necessário enquanto estudando esses assuntos.
Nos vamos \emph{implementar} e tratar relações como conjuntos apenas
no~\ref[Set_theory].

Sobre programação lógica:
\cite[lpbook],
\cite[artofprolog],
\cite[holpbook].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Group_theory 
\chapter Teoria dos grupos.
%%%{{{ meta 
\label Group_theory
\pdefs
    \pdef G {{\ssetfont G}}
    \pdef H {{\ssetfont H}}
    ;;
%%%}}}

%%{{{ intro 
\chapintro
Neste capítulo vamos ver os ``baby steps'' da teoria dos grupos.
Os grupos têm uma quantidade de leis perfeita que fornecem
uma estrutura ideal para começar nosso estudo de \dterm{algebra abstrata}.
Depois estudamos mais teorias de outras estruturas algébricas,
e até descubrimos como podemos abstrair tais teorias algébricas
e elaborar um estudo universal delas.
%%}}}

%%{{{ History 
\history.
%%%{{{ meta 
\credits
    * Abel
    * Cauchy
    * Galois
    * Lagrange
    * Lambert
    * Ruffini
    * Wantzel
    * vonLindemann
    ;;
%%%}}}

A teoria dos grupos é principalmente atribuída no trabalho do gigante
Galois.  Ele morreu muito jovem (20 anos) baleado num duel.
Sua biografia sendo bastante romântica e aventurosa,
naturalmente atrai muita atenção, muitas lendas, umas exageradas, outras não.
Mas seu trabalho matemático não precisa nenhum toque de exagero.
Ele introduziu o conceito de grupo e começou estudar sua teoria.
Ele conseguiu perceber, construir, e abstrair numa maneira tão profunda e
original que o resto da humanidade demorou para entender e apreciar.
O que chamamos hoje de \dterm{teoria dos grupos} e de \dterm{teoria de Galois}
nasceram na cabeça desse menino francês, e os \dterm{corpos finitos} também!
A teoria de Galois conecta as duas teorias, de grupos e de corpos.

Abel, um matemático norueguês que morou na mesma época
(e também morreu jovem: 26 anos) estudou uns assuntos parecidos,
e hoje em dia chamamos uma classe de grupos de
\dterm{abelianos} como homenagem a ele.
Uma das coisas que Abel conseguiu demonstrar foi que não existe uma única fórmula
para \dq{matar} todas as equações de quinto grau.  Esse teorema é conhecido como
Abel--Ruffini: Ruffini atacou o problema com uma demonstração complicada
que, mesmo que Cauchy a aceitou como convincente, ela realmente tava
incompleta; foi Abel que matou o problema no \yearof{1826} numa maneira completa e concisa.
Mas o teorema de Abel deixa a possibilidade de existir, por exemplo,
uma família de fórmulas, ou até uma fórmula diferente para resolver cada
polinómio de quinto grau separadamente.

É a teoria de Galois que ilumina mesmo a situação: graças à ela sabemos
que tem polinómios que não são resolutíveis por nenhuma fórmula.
E bem mais que isso.

Três problemas abertos na epoca desde os gregos antigos eram as
construções de régua e compaço seguintes:
(1) trissecção do ângulo;
(2) quadratura do cíclo;
(3) duplicação do cubo.
No (1) são dadas duas linhas que interesetam num ponto único,
formando assim um ângulo.
O problema pede construir duas linhas que dividem esse ângulo
em $3$ ângulos iguais.
No (2) é dado um cíclo e seu ráio e o objectivo é construir
um quadrado com a mesma área.
No (3) é dado um cubo e queremos construir um cubo com
volume duplo.\foot
Na verdade, é dada a \emph{aresta} dum cubo com volume $V$,
é o problema é construir a aresta dum cubo com volume $2V$.
Ou seja, chamando o tamanho da aresta dada $1$,
construir segmento com tamanho $\cbrt 2$.
\toof

Wantzel no \yearof{1837} demonstrou a \emph{impossibilidade}
desses três problemas.  Para os (1) e (2), sua demonstração dependeu
do fato que $\pi$ é \dterm{transcendental}.
Na época a transcendentalidade do $\pi$ era apenas uma conjectura,
proposta por Lambert no \yearof{1768} (no mesmo artigo onde
\emph{demonstrou} a sua irracionalidade).
A conjectura vira teorema bem depois, no ano \yearof{1882},
por von~Lindemann.
Mesmo que esse trabalho de Wantzel é depois da morte de
Galois, ele não aproveitou a teoria de Galois pois
ela demorou bastante para ser publicada (\yearof{1846}), e ainda mais
para ser entendida e aproveitada!

Novamente, é a teoria de Galois que ilumina a situação:
ela oferece as ferramentas para demonstrar com elegância e clareza
todos esses teoremas difíceis!

\endhistory
%%}}}

%%{{{ Permutations 
\section Permutações.
%%%{{{ meta 
%%%}}}

%%{{{ Introduce \sym 3 
\note.
%%%{{{ meta 
\indexes
    * permutação
    ;;
%%%}}}

Vamos começar considerando o conjunto $\sym n$ de todas as permutações
dum conjunto com $n$ elementos, i.e., todas as endofunções bijetivas.
Escolhemos o $\set{1,2,\dotsc,n}$ como nosso conjunto mas esta escolha
é inessencial.
Logo temos
\mathcols 2
\sym n &\defeq (\set{1,\dotsc,n}\bijto\set{1,\dotsc,n})
\intertext {e, em particular,}
\sym 3 &= (\set{1,2,3}\bijto\set{1,2,3}).
\endmathcols
Quantos elementos tem o $\sym 3$?
Lembramos\foot
Se não lembramos, veja a~\ref[total_permutations]
e a~\reftag[Permutations_and_combinations] em geral.
Depois disso, lembramos!
\toof
que são
$$
\card{\sym 3} = \totperm 3 = 3! = 3\ntimes 2\ntimes 1 = 6.
$$
Nosso primeiro objectivo é achar todos esses $6$ membros de $\sym 3$.
\eop
Primeiramente, a identidade $\idof {\set{1,2,3}} \in \sym 3$ pois é bijetiva.
Para continuar, introduzimos aqui uma notação bem práctica para
trabalhar com permutações:

%%}}}

%%{{{ notation: notation_with_cycles 
\notation.
%%%{{{ meta 
\label notation_with_cycles
%%%}}}

Denotamos a bijecção $f \in \sym n$ assim:
$$
f \inteq \permf{
1    & 2    & \dotsb & n\\
f(1) & f(2) & \dotsb & f(n)
}
$$
Por exemplo, a identidade de $\sym 3$,
e a permutação $\phi$ que troca apenas o primeiro com o segundo elemento
são denotadas assim:
\mathcols 2
\id
&= \permf {
1 & 2 & 3 \\
1 & 2 & 3
} &
\phi
&\asseq \permf {
1 & 2 & 3 \\
2 & 1 & 3
}
\endmathcols
Considere agora uma permutação do $\sym 8$ e uma do $\sym {12}$:
\mathcols 2
&\permf {
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
2 & 3 & 1 & 4 & 6 & 5 & 7 & 8
}; &
&\permf {
1 & 2 & 3 & 4 & 5 & 6  & 7 & 8  & 9 & 10 & 11 & 12\\
2 & 3 & 1 & 4 & 5 & 10 & 6 & 11 & 9 & 12 & 8  & 7
}.
\intertext{Podemos quebrá-las em \dterm{ciclos} escrevendo}
&
\permc{1 & 2 & 3}
\permc{5 & 6} &
&
\permc{1 & 2 & 3}
\permc{6 & 10 & 12 & 7}
\permc{8 & 11}
\endmathcols
respectivamente.
Entendemos o ciclo $\permc{1 & 2 & 3}$ como
$1 \mapsto 2 \mapsto 3 \mapsto 1$:
$$
(
\cdopt{sep=.333cm}
1 \ar[r,maps to] \| 2 \ar[r,maps to] \| 3 \ar[ll,maps to,bend left=36]
\endcd
)
$$
Observe que não há uma única maneira de denotar um cíclo com essa notação; por exemplo:
$$
\permc{1 & 3 & 2} = \permc{3 & 2 & 1} = \permc{2 & 1 & 3}
=
\mathed {
\tikzpicture
\node (a) at ( 0,.866) {$1$};
\node (b) at (-.5,0)   {$2$};
\node (c) at ( .5,0)   {$3$};
\draw[|->] (a) to [bend left=30] (c);
\draw[|->] (c) to [bend left=30] (b);
\draw[|->] (b) to [bend left=30] (a);
\endtikzpicture
}
$$
mas mesmo assim preferimos botar o menor número na primeira posição na escrita;
optamos para o $\permc{1 & 3 & 2}$ neste caso.

%%}}}

%%{{{ x: verify cycle notation 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que as duas permutações que escrevemos usando ciclos
realmente correspondem nas permutações anteriores.

%%}}}

%%{{{ beware: beware_notation_with_cycles 
\beware.
%%%{{{ meta 
\label beware_notation_with_cycles
%%%}}}

Para usar a notação com ciclos para denotar os membros de algum
$\sym n$, precisamos esclarecer o $n$---algo que não é necessário
com a notação completa, onde esta informação é dedutível pela
sua forma.  Por exemplo as duas permutações
$$
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5\\
2 & 1 & 3 & 5 & 4
}}_{\permc{1 & 2}\permc{4 & 5}}
\qtext{e}
\underbrace{
\permf{
1 & 2 & 3 & 4 & 5 & 6 & 7\\
2 & 1 & 3 & 5 & 4 & 6 & 7
}}_{\permc{1 & 2}\permc{4 & 5}}
$$
compartilham a mesma forma usando a notação com ciclos!
Olhando para as formas acima, sabemos que a primeira
é um membro do $\sym 5$, e a segunda do $\sym 7$.
\eop
Mais um defeito dessa notação é que não temos como denotar
a identidade numa forma consistente: podemos concordar
denotá-la pelo $\permc {1}$ ou $\permc {}$, mas na práctica
optamos para o $\id$ mesmo.

%%}}}

%%{{{ The members of \sym 3 
\note Os membros de $\sym 3$.
%%%{{{ meta 
%%%}}}

Já achamos $2$ dos $6$ elementos de $\sym 3$:
\mathcols 2
\id
&= \permf {
1 & 2 & 3 \\
1 & 2 & 3
}
&
\phi
&\leteq \permf {
1 & 2 & 3 \\
2 & 1 & 3
}
= \permc {1 & 2}
\endmathcols
Sabendo
que a composição de bijecções é bijecção (\ref[fcom_respects_jections]),
tentamos a
$$
\phi^2 = \phi\com\phi
=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
1 & 2 & 3
}
=\id
$$
e voltamos para a própria $\id$!
Uma outra permutação no $\sym 3$ é a
$$
\psi\leteq\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permc{1 & 2 & 3}.
$$
Vamos agora ver quais diferentes permutações ganhamos combinando essas:
$$
\align
\psi^2
= \psi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
3 & 1 & 2
}
=\permc{1 & 3 & 2}
\\
\phi\com\psi
&=\permf{
1 & 2 & 3\\
2 & 1 & 3
}\com\permf{
1 & 2 & 3\\
2 & 3 & 1
}
=\permf{
1 & 2 & 3\\
1 & 3 & 2
}
=\permc{2 & 3}\\
\psi\com\phi
&=\permf{
1 & 2 & 3\\
2 & 3 & 1
}\com\permf{
1 & 2 & 3\\
2 & 1 & 3
}
=\permf{
1 & 2 & 3\\
3 & 2 & 1
}
=\permc{1 & 3}
\endalign
$$
E achamos $6$ membros distintos do $\sym 3$.\foot
Por que são distintos?
Veja~\ref[why_phipsi_neq_psiphi] por exemplo.
\toof
Mas $\card{\sym 3} = 6$, e logo achamos \emph{todos} os membros de
$\sym 3 = \set{\id, \phi, \psi, \psi^2, \phi\psi,\psi\phi}$:
\mathcols 3
\id  &= \permc {}      &\psi   &= \permc {1 & 2 & 3}  & \phi\com\psi &= \permc {2 & 3} \\
\phi &= \permc {1 & 2} &\psi^2 &= \permc {1 & 3 & 2}  & \psi\com\phi &= \permc {1 & 3}.
\endmathcols

%%}}}

%%{{{ remark: is_it_needed_to_compute_last_value_of_perm 
\remark.
%%%{{{ meta 
\label is_it_needed_to_compute_last_value_of_perm
%%%}}}

Preciso mesmo calcular os últimos números das permutações?
Vamos voltar no momento que estamos calculando o $\phi\of\psi$;
acabamos de calcular as imagens de $1$ e $2$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| \\
 \aB1                 \| \aB3         \| \aR?
\endcd
$$
Estamos então aqui:
$$
\phi \of \psi
= \permf {
1 & 2 & 3 \\
\aB1 & \aB3 & \aR?
}
$$
Agora podemos continuar do mesmo jeito, para calcular a imagem de $3$:
$$
\cdopt{column sep=4mm}
 1 \ar[d,maps to,"\psi"'] \| 2 \ar[d,maps to] \| 3 \ar[d,maps to] \\
 2 \ar[d,maps to,"\phi"'] \| 3 \ar[d,maps to] \| 1 \ar[d,maps to] \\
 1                        \| 3                \| 2
\endcd
$$
e assim chegar no
$$
\phi\of\psi
= \permf {
1 & 2 & 3 \\
1 & 3 & 2
}
$$
Mas, $\phi\of\psi$ é uma bijecção (pois $\phi,\psi$ são,
e~\ref[fcom_respects_jections]), e logo podemos concluir desde o penúltimo
passo que $(\phi\of\psi) \fa 3 = 2$.
Mesmo assim, sendo humanos, faz sentido achar esse último valor
\emph{com as duas maneiras}.
Assim, caso que elas chegam em resultados diferentes, teriamos um aviso sobre
(pelo menos) um erro nos nossos cálculos anteriores!

%%}}}

%%{{{ x: inj_or_surj_needed_to_compute_last_value_of_perm 
\exercise.
%%%{{{ meta 
\label inj_or_surj_needed_to_compute_last_value_of_perm
%%%}}}

Qual das duas propriedades de bijecção estamos usando
na~\ref[is_it_needed_to_compute_last_value_of_perm] para
concluir que $(\phi\of\psi) \fa 3 = 2$ sem calculá-lo
explicitamente?

\solution
Qualquer uma das duas seria suficiente nesse caso!
A injetividade obrigaria a imagem de $3$ evitar
tanto o $1$ quanto o $3$ (pois o primeiro é imagem
do $1$ e o segundo do $2$), e logo só sobra uma
opção para ser a imagem do $3$: o $2$.
A sobrejetividade obrigaria a imagem de $3$ ser
o $2$ também, pois por enquanto ninguém foi mapeado
a ele.


%%}}}

%%{{{ x: calculate psi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule a $\psi\of\psi^2$ e justifique que ela é igual à $\psi^2\of\psi$.

\solution
Calculamos:
\mathcol
1 &\mapstoby {\psi^2} 3 \mapstoby \psi 1 \\
2 &\mapstoby {\psi^2} 1 \mapstoby \psi 2 \\
3 &\mapstoby {\psi^2} 2 \mapstoby \psi 3
\endmathcol
ou seja, $\psi\of\psi^2 = \id$.
A igualdade é imediata pela associatividade da $(\of)$.
(E ambas são iguais à $\psi^3$.)

%%}}}

%%{{{ x: calculate phi psi^2 and psi^2 phi 
\exercise.
%%%{{{ meta 
%%%}}}

Calcule as $\phi\of\psi^2$ e $\psi^2\of\phi$.

%%}}}

%%{{{ abstracting_the_notion_of_group_the_bad_way 
\note Abstraindo (maneira ruim).
%%%{{{ meta 
\label abstracting_the_notion_of_group_the_bad_way
%%%}}}

Temos um conjunto (ou um tipo) cujos membros podemos
\dq{combinar}.
Destacamos as seguintes propriedades que são satisfeitas:
\tlist:
\li (G0):
O conjunto é fechado sobre a operação.\foot
Aplicando a operação em quaisquer membros do nosso conjunto,
o resultado pertence ao conjunto.
\toof
\li (G1):
A operação é associatíva.
\li (G2):
A operação tem identidade no conjunto.
\li (G3):
Cada elemento do conjunto possui inverso no conjunto.
\endtlist
Conjuntos onde é definida uma operação que satisfaz essas propriedades
aparecem com freqüência, e vamos ver que são suficientes para construir
uma teoria rica baseada neles.

%%}}}

%%{{{ abstracting_the_notion_of_group
\note Abstraindo (maneira boa).
%%%{{{ meta 
\label abstracting_the_notion_of_group
%%%}}}

Temos um mundo $G$ (pense num tipo ou num conjunto) em qual podemos fazer
três operações-perguntas:
\tlist:
\li (op):
dando um habitante $x$ e um habitante $y$ podemos solicitar a combinação deles $xy$;
\li (id):
podemos solicitar um destacado membro do mundo a qual vamos referir como \dterm{a identidade do mundo};
\li (inv):
dando um habitante $x$ podemos solicitar um correspondente membro do mundoujo nome é \dterm{o inverso do $x$}.
\endtlist
Resumindo, temos:
\mathcols 3
\fun{op}  &\is G \times G \to G &
\fun{id}  &\is G &
\fun{inv} &\is G \to G.
\endmathcols
Essas operações satisfazem:
\tlist:
\li (Ass):
$(xy)z = x(yz)$.
\li (Id):
$ex = x = xe$
\li (Inv):
$x'x = e = xx'$
\endtlist
Esse padrão (conjunto com tais operações respeitando tais leis) aparecem
com freqüência, e vamos ver que são suficientes para construir
uma teoria rica baseada neles.

%%}}}

\endsection
%%}}}

%%{{{ What is a group? 
\section O que é um grupo?.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Seguindo a abstracção do~\reftag[abstracting_the_notion_of_group],
chegamos numa primeira definição:

%%}}}

%%{{{ df: group_def_wordy 
\definition Grupo.
%%%{{{ meta 
\label group_def_wordy
\defines
    * grupo
    ;;
%%%}}}

Um conjunto $G$ com uma operação binária $\ast$ é um \dterm{grupo}
sse:
o $G$ é $\ast$-\emph{fechado};
a $\ast$ é \emph{associativa};
a $\ast$ tem \emph{identidade} no $G$;
cada elemento de $G$ possui $\ast$-\emph{inverso}.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Anticipando o dicionário relevante (\ref[dictionary_of_operation_properties])
vamos esclarecer pouco essa definição:

%%}}}

%%{{{ pseudodf: group_def_2_classic 
\pseudodefinition Grupo.
%%%{{{ meta 
\label group_def_2_classic
\defines
    * grupo
    ;;
%%%}}}

Um conjunto $G$ com uma operação binária $\ast$ no $G$ é um \dterm{grupo}
sse as leis seguintes
$$
\gather
a,b \in G \implies a\ast b \in G                                             \tag{G0} \\
a\ast(b\ast c) = (a\ast b)\ast c                                             \tag{G1} \\
\text{existe $e\in G$ tal que para todo $a\in G$, $e\ast a = a = a\ast e$}   \tag{G2} \\
\text{para todo $a\in G$, existe $y\in G$, tal que $y\ast a = e = a \ast y$} \tag{G3}
\endgather
$$
são satisfeitas.
\mistake

%%}}}

%%{{{ Laws vs. axioms 
\note Leis \vs axiomas.
%%%{{{ meta 
\label laws_vs_axioms
\indexes
    * axioma!\vs lei
    ;;
\defines
    * leis de grupo
    * lei
    ;;
%%%}}}

As (G0)--(G3) são conhecidas como \dterm{as leis de grupos},
ou \dterm{os axiomas de grupos}.
Tentarei evitar---mas não sempre!---usar a palavra \emph{axioma}
com esse sentido, optando para a palavra \emph{lei} mesmo,
pois chamamos de ``axioma'' algo que aceitamos como verdade em
nosso univérso (mais sobre isso no~\ref[Set_theory]),
mas nesse caso não estamos afirmando a veracidade das (G0)--(G3).
Faz apenas parte do que significa ``ser grupo''.
Se um conjunto estruturado satisfaz todas as leis,
bem, ele ganha o direito de ser chamado um ``grupo''.
Se não, beleza, ele não é um grupo.

%%}}}

%%{{{ warning: notational_abuse_groups 
\warning abuso notacional.
%%%{{{ meta 
\label notational_abuse_groups
%%%}}}

Lembra-se o abuso notacional que introduzímos
no~\reftag[notational_abuse_structured_sets]:
usamos $a,b\in\ssetfont G$, $G=\sset G {\bullet}$, etc.

%%}}}

%%{{{ Multiplicative and additive groups 
\note Grupos multiplicativos e aditivos.
%%%{{{ meta 
\defines
    * grupo!aditivo
    * grupo!multiplicativo
    ;;
%%%}}}

Dependendo da situação, podemos adoptar um ``jeito multiplicativo''
para a notação dum grupo, ou um ``jeito additivo''---ou ficar
realmente com um jeito neutro.
Num \dterm{grupo multiplicativo} usamos $\cdot$ para denotar a operação do grupo,
aproveitamos a convenção de omitir o símbolo totalmente, usando apenas
justaposição: $a(bc)$ significa $a\cdot(b\cdot c)$ por exemplo.
A identidade parecerá com $e$ ou $1$, e $a^{-1}$ será o inverso de~$a$.
Num \dterm{grupo aditivo} usamos $(+)$ para denotar a operação do grupo,
a identidade parecerá com $e$ ou $0$; e $-a$ será o inverso de~$a$.
Naturalmente usamos $\ast$, $\bullet$, etc.~para denotar operação
de grupo, $e$ para sua identidade, e $a^{-1}$ para denotar o inverso de~$a$.
É importante entender que os termos ``grupo multiplicativo'' e ``grupo aditivo''
usados assim não carregam nenhum significado matemático mesmo: apenas mostram
uma preferência notacional.
Mas quando um conjunto já tem adição e/ou multiplicação definida
(como por exemplo os reais), então usamos frases como
``o grupo aditivo dos reais'' para referir ao $\sset \reals +$,
e até ``o grupo multiplicativo dos reais'' para referir ao
$\sset {\reals_{\neq0}} \ntimes$, considerando óbvio o ``sem o zero'',
pois \emph{com} o zero nem é grupo (\ref[numeric_noneg_of_groups_are_really_noneg]).

%%}}}

%%{{{
\blah.
%%%{{{ meta 
%%%}}}

Para entender melhor as quatro leis de grupo, as escrevemos novamente,
essa vez sem deixar nenhum quantificador como implícito,
e começando com um \emph{conjunto estruturado} com uma operação binária:

%%}}}

%%{{{ pseudodf: group_def_2 
\pseudodefinition Grupo (2).
%%%{{{ meta 
\label group_def_2
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast}$ é um \dterm{grupo} sse
\mathcol
\cforall {a,b\in G}                  {a\ast b \in G}                     \tag{G0} \\
\cforall {a,b,c\in G}                {a\ast(b\ast c) = (a\ast b)\ast c}  \tag{G1} \\
\pexists {e\in G} \cforall {a \in G} {e\ast a = a = a\ast e}             \tag{G2} \\
\pforall {a\in G} \cexists {y \in G} {y\ast a = e = a \ast y}.           \tag{G3} \\
\endmathcol
Chamamos o elemento garantido pela~(G2) a \dterm{identidade} do grupo,
chamamos o~$y$ da~(G3) o \dterm{inverso} de~$a$.
\mistake

%%}}}

%%{{{ x: check_group_def_classic_and_group_def_2 
\exercise.
%%%{{{ meta 
\label check_group_def_classic_and_group_def_2
%%%}}}

Tá tudo certo com as definições~\reftag[group_def_2_classic]
e~\reftag[group_def_2]?

\hint
Quem é esse $e$ que aparece no (G3)?

\hint
Como assim \emph{o} inverso?

%%}}}

%%{{{ Galois, Abel, Cayley.
\note Galois, Abel, Cayley.
%%%{{{ meta 
\credits
    * Galois
    * Abel
    * Cayley
    ;;
%%%}}}

Como vimos, na mesma época o Galois e o Abel chegaram na
idéia abstrata de grupo.  Galois mesmo escolheu a palavra \wq{group} para
esse conceito.
A definição \dq{moderna} de grupo como conjunto munido com operação que
satisfaz as leis~(G0)--(G3) é de Cayley.
Como Abel focou em grupos cuja operação é comutativa, chamamos esses
grupos de abelianos:

%%}}}

%%{{{ df: abelian group 
\definition Grupo abeliano.
%%%{{{ meta 
\label abelian_group
\defines
    * grupo!abeliano
    ;;
%%%}}}

Um grupo é \dterm{comutativo}
(também: \dterm{abeliano})
sse sua operação é comutativa:
\mathcol
\cforall {a,b \in G} {a \ast b = b \ast a}.  \tag{GA}
\endmathcol

%%}}}

%%{{{ groups_and_abelian_groups_schematically 
\note.
%%%{{{ meta 
\label groups_and_abelian_groups_schematically
%%%}}}

Esquematicamente:
$$
% body
\gathered
\text{(fechado)}\\
\text{(associatividade)}\\
\text{(identidade)}\\
\text{(inversos)}\\
\text{(comutatividade)}
\endgathered
% right braces
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3
\endgathered
}
\text{grupo}\\
\vphantom4\\
\endgathered
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3\\
\vphantom4
\endgathered
}
\text{grupo abeliano}
\endgathered
$$

%%}}}

%%{{{ eg: S3_is_a_non_abelian_group 
\example.
%%%{{{ meta 
\label S3_is_a_non_abelian_group
%%%}}}

Verifique que $\sym 3$ é um grupo.
Ele é abeliano?

\solution.
Precisamos verificar as leis de grupo.
\eop\noi
{(G0).}
Para demonstrar que $\sym 3$ é $(\fcom)$-fechado, precisamos verificar
que para todo $a,b\in \sym 3$, $a \fcom b \in \sym 3$.
Pela definição do $\sym 3$, isso segue pelo~\ref[fcom_respects_jections]~(3).
\eop\noi
{(G1).}
Já demonstramos a associatividade da $\fcom$ na~\ref[fcom_associativity_law].
\eop\noi
{(G2).}
Facilmente verificamos que a $\idof {\set{1,2,3}}$ é a identidade do
$\sset {\sym 3} {\fcom}$, pela sua definição.
\eop\noi
{(G3).}
Cada bijecção tem uma função-inversa, que satisfaz as equações dessa lei
pela definição de função-inversa.
(Veja~\ref[finverse] e~\ref[finv_is_bij].)
\eop\noi
{(GA).}
Basta mostrar pelo menos um contraexemplo, ou seja, duas permutações
$a,b$ do $\sym 3$ tais que $a\fcom b \neq b\fcom a$.
Agora preciso saber o que significa igualdade entre \emph{funções}
(\ref[f_eq_g]).
Escolho os $\phi,\psi$.
Já calculamos as $\phi\fcom\psi$ e $\psi\fcom\phi$ e são diferentes.
\eop
Logo, $\sym 3$ é um grupo não abeliano.

%%}}}

%%{{{ x: why_phipsi_neq_psiphi 
\exercise.
%%%{{{ meta 
\label why_phipsi_neq_psiphi
%%%}}}

E por que $\phi\fcom\psi \neq \psi\fcom\phi$?

\solution
Pois elas discordam em pelo menos um valor: tome o $1$.
Agora
$$
(\phi\fcom\psi)(1)
= \phi(\psi(1))
= \phi(2)
= 1
\neq
3
= \psi(2)
= \psi(\phi(1))
= (\psi\fcom\phi)(1).
$$
Logo $\phi\fcom\psi \neq \psi\fcom\phi$.

%%}}}

%%{{{ And why 1 ≠ 3? 
\note E por que 1 ≠ 3?.
%%%{{{ meta 
%%%}}}

Na resolução do~\ref[why_phipsi_neq_psiphi] nosso argumento reduziu
o que queríamos demonstrar à afirmação $1 \neq 3$.
\emph{E por que $1 \neq 3$?}
Bem, precisamos saber o que significa igualdade no $\nats$!
Mas podemos já considerar o $1 \neq 3$ como um fato conhecido sobre os números
naturais.  Depois, no~\ref[Set_theory], vamos \emph{fundamentar}
o~$\nats$ na teoria de conjuntos, e logo vamos ter como realmente demonstrar essa
afirmação para nosso $\nats$, por exemplo.

%%}}}

%%{{{ x: find_all_inverses_on_S3 
\exercise.
%%%{{{ meta 
\label find_all_inverses_on_S3
%%%}}}

Ache o inverso de cada elemento de $\sym 3$.\foot
Se tu já fez isso para resolver o~\ref[S3_is_a_non_abelian_group],
não foi necessário.  Por quê?
Veja a resolução do~\reftag[S3_is_a_non_abelian_group] mesmo.
\toof

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora vamos dar mais uma definição de grupo, essa vez usando um conjunto
estruturado de tipo diferente: além de ter uma operação binária,
tem uma constante também:

%%}}}

%%{{{ df: group_def_20 
\definition Grupo (2,0).
%%%{{{ meta 
\label group_def_20
\defines
    * grupo
    ;;
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast, e}$ é um grupo sse
\mathcol
\cforall {a,b\in G}                 {a\ast b \in G}                    \tag{G0} \\
\cforall {a,b,c\in G}               {a\ast(b\ast c) = (a\ast b)\ast c} \tag{G1} \\
\cforall {a \in G}                  {e\ast a = a = a\ast e}            \tag{G2} \\
\pforall {a\in G} \cexists {y\in G} {y\ast a = e = a \ast y}.          \tag{G3} \\
\endmathcol

%%}}}

%%{{{ x: check_group_def_20 
\exercise.
%%%{{{ meta 
\label check_group_def_20
%%%}}}

Tá tudo certo com a~\ref[group_def_20]?

\solution
Sim!
Veja também a~\ref[a_vs_the_identity_of_a_group].

%%}}}

%%{{{ remark: a_vs_the_identity_of_a_group 
\remark.
%%%{{{ meta 
\label a_vs_the_identity_of_a_group
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

O $e$ que aparece na~(G3) não é ``\emph{a} identidade do $\cal G$''.
É sim \emph{a} constante que aparece na estrutura do $\sset G {\ast,e}$,
que---graças à~(G2)---é \emph{uma} identidade do $\cal G$.
No~\ref[uniqueness_of_identity_in_group] vamos demonstrar que cada grupo tem identidade única,
e a partir dessa demonstração, vamos ganhar o direito de usar o artigo definido ``a''.

%%}}}

%%{{{ Q: can you define group (2,1,0)? 
\question.
%%%{{{ meta 
%%%}}}

Já encontramos definições de grupo como conjunto estruturado com assinaturas
de aridades $(2)$ e $(2,0)$.
Como definarias com assinatura de aridades $(2,1,0)$?

%%}}}

\spoiler

%%{{{ df: group_def_210 
\definition Grupo (2,1,0).
%%%{{{ meta 
\label group_def_210
%%%}}}

Um conjunto estruturado $\ssetfont G = \sset G {\ast, {}^{-1}, e}$
onde $\ast$ é uma operação binária, ${}^{-1}$ unária, e $e$ uma constante
é um \dterm{grupo} sse:
\tlist:
\li (G0): $G$ é $\ast$-fechado;
\li (G1): $\ast$ é associativa;
\li (G2): $e$ é uma $\ast$-identidade;
\li (G3): para todo $a \in G$, $\ginv a$ é um $\ast$-inverso do $a$.
\endtlist
Formulamente:
\mathcol
\cforall {a,b \in G}   {a\ast b \in G}                     \tag{G0} \\
\cforall {a,b,c \in G} {a\ast(b\ast c) = (a\ast b)\ast c}  \tag{G1} \\
\cforall {a \in G}     {e\ast a = a = a\ast e}             \tag{G2} \\
\cforall {a \in G}     {a^{-1}\ast a = e = a \ast a^{-1}}. \tag{G3} \\
\endmathcol

%%}}}

%%{{{ df: order of group 
\definition Ordem de grupo.
%%%{{{ meta 
\label order_of_group
\defines
    * \gord {~G}  -- a ordem do grupo $G$
    * ordem!de grupo
    ;;
%%%}}}

O número de elementos de um grupo $G$ é sua \dterm{ordem}.
Denotamos a ordem de $G$ com:
$\gord G$, $\tord G$, ou até $\bord G$ quando não existe ambigüidade.
Se o carrier set do grupo é infinito, escrevemos
$\gord G = \infty$.

%%}}}

%%{{{ x: group_of_any_finite_order 
\exercise.
%%%{{{ meta 
\label group_of_any_finite_order
%%%}}}

Já conhecemos um grupo finito bem, o $\sym 3$,
com $\gord {\sym 3} = 6$.
No~\ref[Sn_is_a_group] demonstrarás que para todo $n\in\nats$,
o $\sym n$ é um grupo.
Seja $m\in\nats$.
Tem como achar um grupo com ordem $m$?
Observe que como sabemos que $\gord {\sym n} = n!$, podemos já achar
um grupo com ordem $m$ para qualquer $m$ que fosse um fatorial.
Por exemplo, se $m=120$ já temos o grupo $\sym 5$,
pois $\gord {\sym 5} = 5! = 120$.
Mas para um $m$ arbitrário, existe grupo de ordem $m$?

\hint
\ref[The_integers].

%%}}}

%%{{{ remark: G0_is_redundant 
\remark Uma lei que não é lei.
%%%{{{ meta 
%%%}}}

Talvez resolvendo os exercícios~\reftag[check_group_def_classic_and_group_def_2]
e~\reftag[check_group_def_20],
tu já percebeste algo redundante na~\ref[group_def_2]:
\emph{pra que essa (G0)?}
O $\sset G \ast$ é um conjunto estruturado cuja estrutura tem uma
\emph{operação binária}, ou seja uma \emph{função}
$$
\ast : G \cross G \to G.
$$
Logo, a (G0) não tem absolutamente nada pra oferecer:
\emph{necessariamente}
$$
\lforall {a,b \in G} {a \ast b \in G}
$$
pois $\ast : G \cross G \to G$.
Observe que se relaxar a definição de conjunto estruturado
para permitir operações \emph{parciais} (\ref[partial_function])
o (G0) vira lei necessária mesmo e afirma simplesmente
que $\ast$ é total.
Mas nosso padrão de operação foi operação total mesmo,
e, nesse sentido, \emph{as leis de grupo} são as (G1)--(G3).\foot
E por isso denotei a primeira com \symq{0}, não foi questão
de começar a conta com o primeiro Nat.
\toof
\emph{Mesmo assim}, é comum encontrar a (G0) como axioma
de grupo, e se tirá-la não ganhamos nada mesmo.
Suponha que tu trabalhas com a (G0) como lei que faz parte
da tua definição de grupo; e teu amigo trabalha apenas com
as (G1)--(G3).
Inicialmente parece que teu amigo vai ter menos trabalho
pra fazer quando precisar demonstrar que um $\sset G \ast$
é um grupo.
Mas não é assim: a definição começa com um
\emph{conjunto estruturado} cuja estrutura inclui a operação
binária $\ast$.
Ou seja, para demonstrar que $\sset G \ast$ é um grupo
ele vai precisar demonstrar que $\ast$ realmente é uma operação
$$
\ast : G \cross G \to G
$$
ou seja, (G0), ou seja, ele não vai ter menos trabalho;
se preocupe não!

%%}}}

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.
%%%{{{ meta 
%%%}}}

%%{{{ eg: with numbers 
\example Com números.
%%%{{{ meta 
%%%}}}

Todos os seguintes conjuntos estruturados são grupos:
\tlist:
\li: $\sset A {+,0}$, onde $A \asseq \ints, \rats, \reals, \complex$;
\li: $\sset B {\ntimes,1}$, onde $B \asseq \rats_{\neq0}, \reals_{\neq0}$;
\li: $\sset C {\ntimes,1}$, onde $C \asseq \set{1,-1}, \set{1,i,-1,-i} \subset\complex$.
\endtlist

%%}}}

%%{{{ noneg: with numbers 
\nonexample Com números.
%%%{{{ meta 
%%%}}}

E \emph{nenhum} dos seguintes é um grupo:
$\sset \nats {+}$;
$\sset \reals {\ntimes,1}$;
$\sset {\ints_{\neq 0}} {\ntimes,1}$;
$\sset \reals {+,1}$.

%%}}}

%%{{{ x: why? : numeric_noneg_of_groups_are_really_noneg 
\exercise.
%%%{{{ meta 
\label numeric_noneg_of_groups_are_really_noneg
%%%}}}

Por quê?

%%}}}

%%{{{ noneg: strings_with_concat_is_not_a_group 
\nonexample Strings.
%%%{{{ meta 
\label strings_with_concat_is_not_a_group
%%%}}}

Sejam $\Sigma\neq\emptyset$ um alfabeto finíto,
e $S$ o conjunto de todos os strings finitos formados por símbolos do $\Sigma$.
O $\sset S +$ onde $(+)$ é a \emph{concatenação} de strings \emph{não} é um grupo.

%%}}}

%%{{{ x: verify_all_group_laws_for_strings 
\exercise.
%%%{{{ meta 
\label verify_all_group_laws_for_strings
%%%}}}

Para cada uma das leis~(G0)--(GA), decida se é
satisfeita pelo $\sset S +$ do~\ref[strings_with_concat_is_not_a_group].
Se é, demonstre; se não é, refute!

%%}}}

%%{{{ x: shared_carrierset_group_notgroup 
\exercise.
%%%{{{ meta 
\label shared_carrierset_group_notgroup
%%%}}}

Sejam $B = \setst {2^m} {m \in \ints}$ e $B_0 = B \union \set{0}$.
Considere os conjuntos estruturados
$$
\xalignat4
&\sset B {+}
&&\sset B {\ntimes}
&&\sset {B_0} {+}
&&\sset {B_0} {\ntimes}.
\endxalignat
$$
Para cada um deles decida se satisfaz cada uma das leis (G0)--(GA).

%%}}}

%%{{{ x: more number-based groups 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre mais grupos formados de números dos
$\nats$, $\ints$, $\rats$, $\reals$, $\complex$,
e uma operação não-padrão da sua escolha.

%%}}}

%%{{{ eg: matrix_group_examples 
\example Matrizes.
%%%{{{ meta 
\label matrix_group_examples
%%%}}}

Considere os conjuntos seguintes:
$$
\xalignat2
A &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {a,b,c,d \in \reals } &
M &= \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }.
\endxalignat
$$
O $A$ com a adição de matrízes vira um grupo $\sset A +$,
mas com a multiplicação não: não todos os seus membros tem inverso.
Por outro lado, graças à condição no filtro na definição do conjunto $M$,
todos os seus membros são matrízes invertíveis,
e $\sset M {\cdot}$ realmente é um grupo.

%%}}}

%%{{{ x: (M;+) is not a group 
\exercise matrizes.
%%%{{{ meta 
%%%}}}

O $\sset M +$ é?

\hint
Não: tem como adicionar dois matrizes invertíveis e resultar
numa matriz que não é.

\solution
Não é, pois quebra a (G0):
$$
\mubrace {\matrixp{1 & 0\\0 & 1}} {\in \sset M +} +
\mubrace {\matrixp{0 & 1\\1 & 0}} {\in \sset M +} =
\mubrace {\matrixp{1 & 1\\1 & 1}} {\nin \sset M +}.
$$

%%}}}

%%{{{ eg: modular_addition_group_eg 
\example Adição modular.
%%%{{{ meta 
\label modular_addition_group_eg
%%%}}}

O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $+_n$
da adição módulo $n$.
Qual é o inverso de um elemento $a$ nesse caso?
É o $n-a$, pois $a +_n (n-a) = 0 = (n-a) +_n a$.

%%}}}

%%{{{ df: modular addition group 
\definition.
%%%{{{ meta 
\defines
    * \ints_{~n}  -- o grupo aditivo dos inteiros módulo
    ;;
%%%}}}

Denotamos o grupo do~\ref[modular_addition_group_eg] por $\ints_n$.

%%}}}

%%{{{ noneg: modular_multiplication_group_noneg
\nonexample Multiplicação modular.
%%%{{{ meta 
\label modular_arithmetic_group_eg
%%%}}}

O $\finord n \defeq \set{0,\dotsc,n-1}$ com a operação $\ntimes_n$
da multiplicação módulo $n$, não é um grupo, pois o $0$ não tem inverso.
E se jogar fora o problemático $0$?  Talvez vira um grupo.
Mas não: o $\sset {\set{1,\dotsc,5}} {\ntimes_6}$ também não é um grupo,
pois não é fechado: $2 \ntimes_6 3 = 0$.

%%}}}

%%{{{ df: symmetric_group 
\definition.
%%%{{{ meta 
\label symmetric_group
\defines
    * \sym {~n}  -- o grupo simétrico $\sym n$
    * grupo!simétrico
    ;;
%%%}}}

Usamos $\sym n$ para denotar o conjunto de todas as permutações
dum conjunto de tamanho $n\in\nats$.
Para definir mesmo o $\sym n$ escolhemos o conjunto canônico:
$$
\sym n \pseudodefeq (\set{1,\dotsc,n}\bijto\set{1,\dotsc,n}).
$$
Para qualquer $n\in\nats$, chamamos o $\sset {\sym n} {\fcom}$
o \dterm{grupo simétrico} de tamanho $n$.

%%}}}

%%{{{ x: Sn_is_a_group 
\exercise.
%%%{{{ meta 
\label Sn_is_a_group
%%%}}}

Justifique a~\ref[symmetric_group]: demonstre que o grupo simétrico $\sym n$
realmente é um grupo.
Ele é abeliano?

%%}}}

%%{{{ x: pset_with_setops_group 
\exercise Conjuntos.
%%%{{{ meta 
\label pset_with_setops_group
%%%}}}

Seja $A$ conjunto.
Com quais das operações $\union$, $\inter$, $\symdiff$, e $\setminus$,
o $\pset A$ é um grupo?

%%}}}

%%{{{ x: real_functions_pointwise_plus_group 
\exercise Funções reais: adição pointwise.
%%%{{{ meta 
\label real_functions_pointwise_plus_group
%%%}}}

O $(\reals \to \reals)$ com operação a pointwise $(+)$, é um grupo?\foot
Qual operação é a pointwise $(+)$?  Veja a~\ref[pointwise_operation].
\toof
Ele é abeliano?

%%}}}

%%{{{ x: real_functions_pointwise_times_nongroup 
\exercise Funções reais: multiplicação pointwise.
%%%{{{ meta 
\label real_functions_pointwise_times_nongroup
%%%}}}

O $(\reals \to \reals) \setminus \set{ \lam x 0 }$ com operação a
pointwise~$(\ntimes)$, é um grupo?
Ele é abeliano?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Lembre que já usamos $\times$ entre \emph{conjuntos} $A,B$ para formar seu
produto cartesiano $A \times B$; e também entre \emph{funções} $f : A \to B$,
$g : C \to D$ para formar seu produto
$f \times g : (A\times C) \to (B \times D)$.
Vamos agora sobrecarregar ainda mais esse $\times$:

%%}}}

%%{{{ df: direct_product_of_groups 
\definition Produtos diretos.
%%%{{{ meta 
\label direct_product_of_groups
%%%}}}

Sejam $\cal G_1 = \sset {G_1} {\ast_1}$ e $\cal G_2 = \sset {G_2} {\ast_2}$ grupos.
Definimos o grupo
$$
\cal G_1 \times \cal G_2 = \sset {G_1 \times G_2} {\ast},
$$
onde $\ast$ é a operação definida pela
$$
\tup{x_1, x_2} \ast \tup{y_1, y_2} = \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2}.
$$

%%}}}

%%{{{ x: direct_product_of_groups_is_a_group 
\exercise.
%%%{{{ meta 
\label direct_product_of_groups_is_a_group
%%%}}}

Demonstre que realmente é um grupo.

\solution
\def\xx{\tup{x_1,x_2}}%
\def\yy{\tup{y_1,y_2}}%
\def\zz{\tup{z_1,z_2}}%
Precisamos verificar as leis (G0)--(G3).
\crproofpart {(G0).}
Tome $\xx, \yy \in G_1\times G_2$.
Calculamos
\compute
\xx \ast \yy
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \by {def.~$\ast$} \\
&\in G_1 \times G_2.                    \by {$G_1$ e $G_2$ fechados sob suas operações} \\
\endcompute
e logo $G_1\times G_2$ é $\ast$-fechado.
\crproofpart {(G1).}
Tome $\xx, \yy, \zz \in G_1\times G_2$.
Calculamos:
$$
\align
\paren{\xx \ast \yy} \ast \zz
&= \tup{x_1 \ast_1 y_1, x_2 \ast_2 y_2} \ast \zz \\
&= \tup{\paren{x_1 \ast_1 y_1} \ast_1 z_1, \paren{x_2 \ast_2 y_2} \ast_2 z_2} \\
&= \tup{x_1 \ast_1 \paren{y_1 \ast_1 z_1}, x_2 \ast_2 \paren{y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\tup{y_1 \ast_1 z_1, y_2 \ast_2 z_2}} \\
&= \xx \ast \paren{\yy \ast \zz}.
\endalign
$$
\proofpart {(G2).}
Afirmação: o $\tup{e_1,e_2}\in G_1\times G_2$ é a $\ast$-identidade.
Prova da afirmação: tome $\xx \in G_1\times G_2$ e calcule:
$$
\tup{e_1, e_2} \ast \xx
= \tup{e_1 \ast_1 x_1, e_2 \ast_2 x_2}
= \xx
= \tup{x_1 \ast_1 e_1, x_2 \ast_2 e_2}
= \xx \ast \tup{e_1, e_2}.
$$
\proofpart {(G3).}
Seja $\xx \in G_1 \times G_2$.
Afirmação: o $\tup{\ginv{x_1}, \ginv{x_2}}$ é o $\ast$-inverso dele.
Realmente temos:
$$
\align
\xx \ast \tup{\ginv{x_1}, \ginv{x_2}}
&= \tup{x_1 \ast_1 \ginv{x_1}, x_2 \ast_2 \ginv{x_2}}
 = \tup{e_1, e_2} \\
\tup{\ginv{x_1}, \ginv{x_2}} \ast \xx
&= \tup{\ginv{x_1} \ast_1 x_1, \ginv{x_2} \ast_2 x_2}
 = \tup{e_1, e_2}
\endalign
$$
Assim concluimos nossa demonstração.

%%}}}

%%{{{ df: gop 
\definition grupo oposto.
%%%{{{ meta 
\label gop
%%%}}}

Seja $\G = \sset G {\ast, \ginv{}, \gid}$ grupo.
Definimos no $\carrier\G$ a operação binária $\ast'$ pela:
$$
x \ast' y = y \ast x.
$$
Chamamos o $\sset G {\ast'}$ de \dterm{grupo oposto do $\G$},
e o denotamos por $\gopp\G$.

%%}}}

%%{{{ x: gop_is_a_group 
\exercise.
%%%{{{ meta 
\label gop_is_a_group
%%%}}}

Justifique o nome escolhido na~\ref[gop]:
demonstre que o $\gopp\G$ é um grupo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Chegam os exemplos por enquanto.
Vamos começar ver a \emph{teoria} de grupos, investigando propriedades que
todos os grupos necessariamente têm.
Ou seja, procuramos as \emph{conseqüências das leis} (G0)--(G3).

%%}}}

\endsection
%%}}}

%%{{{ First consequences 
\section Primeiras conseqüências.
%%%{{{ meta 
\label First_consequences_of_group_laws
%%%}}}

%%{{{ lm: uniqueness_of_identity_in_group 
\lemma unicidade da identidade.
%%%{{{ meta 
\label uniqueness_of_identity_in_group
\indexes
    * unicidade!da identidade
    ;;
%%%}}}

Em todo grupo $G$ existe único elemento $e$ que satisfaz a (G2).

\sketch.
Seja $G$ grupo.
Sabemos que existe pelo menos uma identidade no $G$ pela (G2),
então precisamos mostrar que existe no máximo uma (unicidade).
Vamos supor que $e_1, e_2$ são identidades do $G$, e usando
as leis~(G0)--(G2) mostrar que $e_1 = e_2$.

\proof.
Seja $G$ grupo.
Sabemos que $G$ tem pelo menos uma identidade graças à (G2),
então o que precisamos mostrar é sua unicidade mesmo.
Suponha que $e_1,e_2\in G$ tais que $e_1,e_2$ são identidades do $G$;
em outras palavras:
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1   \tag{1}\\
\text{para todo $b\in G$},\quad & e_2\ast b \eqlabel L b \eqlabel R b\ast e_2.  \tag{2}
\endalign
$$
Agora exatamente a mesma demonstração pode ser escrita em dois caminhos
meio diferentes:
\crtabproofalt{Caminho 1:}
Temos
\compute
e_1
&= e_1 \ast e_2  \by {pela (2R), com $b\asseq e_1$} \\
&= e_2           \by {pela (1L), com $a\asseq e_2$} \\
\endcompute
e demonstramos o que queremos: $e_1 = e_2$, ou seja,
em cada grupo existe única identidade.
\crtabproofalt{Caminho 2.}
Temos
\compute
e_1 \ast e_2 &= e_1  \by {pois $e_2$ é uma R-identidade (2R)} \\
e_1 \ast e_2 &= e_2  \by {pois $e_1$ é uma L-identidade (1L)} \\
\endcompute
e concluimos o desejado $e_1 = e_2$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Uma demonstração errada desse lemma aparece
no~\ref[bust_proof_of_uniqueness_of_identity_in_group],
onde peço identificar seus erros.

%%}}}

%%{{{ Q: What have we just won? 
\question.
%%%{{{ meta 
%%%}}}

O que acabamos de ganhar?

%%}}}

%%{{{ A: The right to use the definite article 
\note Resposta.
%%%{{{ meta 
\indexes
    * artigo!(in)definido
    ;;
%%%}}}

Ganhamos o direito de usar o artigo definido:
para cada grupo~$\cal G$ falar \emph{da}~identidade do~$\cal G$,
em vez \emph{duma}~identidade do~$\cal G$.
Observe que dado algum $a\in \cal G$ ainda não podemos falar sobre
\emph{o}~inverso de~$a$, mas apenas sobre \emph{um}~inverso de~$a$,
pois por enquanto a~(G3) garanta que pelo menos um inverso existe.
Vamos resolver isso agora.

%%}}}

%%{{{ beware: bound_variables_in_proof_of_uniqueness_of_identity_in_group 
\beware.
%%%{{{ meta 
\label bound_variables_in_proof_of_uniqueness_of_identity_in_group
\indexes
    * variável!ligada
    ;;
%%%}}}

Os $a$ e $b$ que aparecem nas~(1)--(2) na demonstração do~\ref[uniqueness_of_identity_in_group]
são \emph{variáveis ligadas} aos correspondentes <<para todo ${\thole} \in G$>>
e logo, ``nascem'' com essa frase e ``morrem'' no fim da mesma linha!\foot
Veja~a~\ref[Variables] também.
\toof
Daí, não faz sentido afirmar logo após das~(1)--(2) algo do tipo $e = a \ast e$, pois o $a$ não foi declarado!
Podemos escrever as duas afirmações sem usar o nome $a$:
\emph{para cada elemento do $G$, operando com o~$e_1$ ao qualquer lado (direito ou esquerdo), o resultado é o próprio elemento}.
E para enfatizar ainda mais a independência do~$a$ que aparece na~(1) com o~$b$ que aparece na~(2) escolhemos variáveis diferentes.
Mas isso é \emph{desnecessário}, em geral vamos reusar variáveis ligadas quando não gera confusão---e aqui não geraria nenhuma.

%%}}}

%%{{{ x: rewrite_proof_with_same_bound_var 
\exercise.
%%%{{{ meta 
\label rewrite_proof_of_uniqueness_of_identity_in_group_with_same_bound_var
%%%}}}

O que muda na demonstração do~\ref[uniqueness_of_identity_in_group] se usar a mesma
variável ligada nas afirmações~(1) e~(2)?

\solution
É apenas escrever
$$
\align
\text{para todo $a\in G$},\quad & e_1\ast a \eqlabel L a \eqlabel R a\ast e_1 \tag{1}\\
\text{para todo $a\in G$},\quad & e_2\ast a \eqlabel L a \eqlabel R a\ast e_2 \tag{2}
\endalign
$$
e depois
\compute
e_1
&= e_1 \ast e_2     \by {pela (2R), com $a\asseq e_1$} \\
&= e_2.             \by {pela (1L), com $a\asseq e_2$} \\
\endcompute
Observe que os $a$ que aparecem nas instanciações $a \asseq \dots$ são completemante independentes.
Ou seja, nada muda mesmo!

%%}}}

%%{{{ lm: uniqueness_of_inverses_in_group 
\lemma unicidade dos inversos.
%%%{{{ meta 
\label uniqueness_of_inverses_in_group
\indexes
    * unicidade!dos inversos
    ;;
%%%}}}

Em todo grupo $G$, cada $a\in G$ tem
exatamente um inverso $\ginv a$ que satisfaz a (G3).

\sketch.
Supondo que existe um certo $a \in G$ que possui inversos
$a_1,a_2\in G$, mostramos que necessariamente $a_1 = a_2$.
Ganhamos isso como corolário do~\ref[cancellation_laws_in_group].
(Como?)

\proof.
Seja $\sset G {\ast, e}$ grupo, e suponha que existem $a,a_1,a_2\in G$
tais que $a_1,a_2$ são inversos de $a$, ou seja,
\compute
a_1 \ast a &\eqlabel L e \eqlabel R a \ast a_1  \by {$a_1$ é um inverso de $a$} \tag 1 \\
a_2 \ast a &\eqlabel L e \eqlabel R a \ast a_2. \by {$a_2$ é um inverso de $a$} \tag 2 \\
\endcompute
Vamos mostrar que $a_1 = a_2$.
Temos:
\compute
a_1 \ast a &= a_2 \ast a \by {pelas (1L), (2L)} \\
a_1        &= a_2        \by {pelo~\reftag[cancellation_laws_in_group]~(GCR)} \\
\endcompute
e \emph{ficamos devendo} demonstrar a (GCR) do~\ref[cancellation_laws_in_group].

%%}}}

%%{{{ beware: Proof dependencies 
\beware Dependências de demonstrações.
%%%{{{ meta 
%%%}}}

Até realmente demonstrar as leis
de can\-ce\-la\-men\-to~(\reftag[cancellation_laws_in_group]) não temos
a unicidade dos inversos~(\reftag[uniqueness_of_inverses_in_group]).
Dado um elemento $a$ dum grupo $G$ não podemos ainda falar \emph{do}
inverso do $a$, nem usar a notação $\ginv a$ (seria mal-definida), etc.\foot
Na verdade, se a gente usa como definição de grupo a \reftag[group_def_210],
temos como usar a notação $\ginv a$ sim, mas ainda não podemos afirmar que
$\ginv a$ é \emph{a} inversa do $a$.  \emph{Uma}, sim.
\toof
Crucialmente, não podemos usar nada disso em nossa demonstração
do~\reftag[cancellation_laws_in_group];
caso contrário criamos uma loope de dependências.
``Forward dependencies'' são perigosos exatamente por causa disso,
e nós as evitamos mesmo.\foot
Aqui escolhi essa abordagem para enfatizar a importância de ficar
alertos para identificar chances de afirmar e demonstrar lemmas separadamente,
os usando em nossa demonstração e para demonstrar outros teoremas depois à vontade.
Fazemos isso exatamente no mesmo jeito que um bom programador
percebe padrões nos seus programas e suas funções e separa certas partes para
outras funções, as chamando depois à vontade.
\toof

%%}}}

%%{{{ lm: cancellation_laws_in_group 
\lemma Leis de cancelamento.
%%%{{{ meta 
\label cancellation_laws_in_group
%%%}}}

Seja $\ssetfont G = \sset G {\ast, \gid}$ grupo.
Então as leis de cancelamento pela esquerda e pela direita
\mathcol
\cforall {a,x,y\in G}  {a\ast x = a\ast y \implies x=y}  \tag{GCL} \\
\cforall {a,x,y\in G}  {x\ast a = y\ast a \implies x=y}  \tag{GCR} \\
\endmathcol
são válidas em $G$.

\sketch.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Queremos demonstrar $x=y$.
Tome a~(1) então, e usando umas das leis de grupo---comece com a~(G3)---chegue no desejado $x=y$, demonstrando assim a~(GCL).
A~(GCR) é similar.

\proof.
Sejam $a,x,y\in G$ tais que
$$
a \ast x = a \ast y.   \tag{1}
$$
Pela (G3) o $a$ possui inverso no $G$;
daí, seja $a_0$ \emph{um} inverso de $a$, ou seja,
$$
a_0 \ast a \eqlabel L e  \eqlabel R a \ast a_0.  \tag{2}
$$
Agora temos:
\compute
a_0 \ast (a \ast x) &= a_0 \ast (a \ast y)  \by {pela (1)} \\
(a_0 \ast a) \ast x &= (a_0 \ast a) \ast y  \by {pela (G1): $\ast$ é associativa} \\
e \ast x            &= e \ast y             \by {pela escolha do $a_0$: (2L)} \\
x                   &= y                    \by {pela definição do $e$} \\
\endcompute
Demonstramos assim a~(GCL).
A~(GCR) é completamente simétrica (e vamos precisar a~(2R) em vez da~(2L)).

%%}}}

%%{{{ x: converses_of_cancellation_laws 
\exercise.
%%%{{{ meta 
\label converses_of_cancellation_laws
%%%}}}

Os conversos das leis de cancelamento~(GCL)~\&~(GCR) são válidos?

\hint
Sim; mas por quê?

\hint
Não precisamos nem saber que $G$ é um grupo nem nada sobre $\ast$, etc.

\solution
Se $x=y$ isso quis dizer que podemos substituir à vontade em cada
\emph{expressão} que envolve $x$ e $y$, uns $x$'s por $y$'s, e vice versa.
Nesse caso, começa com o
$$
a \ast x
$$
e troca a única ocorrência de $x$ nessa expressão por $y$, e já chegamos no
$$
a \ast y
$$
ou seja, $a \ast x = a \ast y$.

%%}}}

%%{{{ x: refute_the_diffside_cancellation_law 
\exercise.
%%%{{{ meta 
\label refute_the_diffside_cancellation_law
%%%}}}

Refuta: para todo grupo $\sset G {\ast, e}$ e $a,x,y\in G$
$$
a\ast x = y\ast a \implies x=y
$$

\hint
Não tem como achar um contraexemplo em grupos abelianos.

\hint
Tem contraexemplo no $\sym 3$.

\hint
Procuramos $a,x,y$ num grupo tais que
$$
ax = ya \nimplies x = y,
$$
ou seja, tais que $ax = ya$ e $x \neq y$.
Mas, o que podemos concluir se $ax = ya$?
$$
ax = ya \implies x = \ginv a y a.
$$
Então nossos $a,x,y$ tem que ser tais que
$x = \ginv a y a$ e mesmo assim $x \neq y$.
Pensando nesses membros como processos e na operação como
``seguindo'' (exatamente a intuição da composição de funções),
para conseguir um contraexemplo, precisamos achar $a$ e $y$
tais que:
fazendo o $a$, depois o $y$, e depois desfazendo o $a$, não
vai ter o mesmo efeito com o processo de fazer apenas o $y$.

\solution
No $\sym 3$, temos
$$
\phi (\psi\phi) = (\phi\psi) \phi
$$
e mesmo assim
$$
\psi\phi \neq \phi\psi.
$$

%%}}}

%%{{{ x: why_is_this_not_a_counterexample_of_the_diffside_cancellation_law
\exercise.
%%%{{{ meta 
\label why_is_this_not_a_counterexample_of_the_diffside_cancellation_law
%%%}}}

Um aluno achou o seguinte contraexemplo para refutar a lei
no~\reftag[refute_the_diffside_cancellation_law]:
$$
\text{nos reais com multiplicação, temos $0\ntimes 1 = 2\ntimes 0$ mas $1\neq 2$.}
$$
Por que sua resposta é errada?

\hint
O que exatamente é um contraexemplo nesse caso?

%%}}}

%%{{{ x: uniqueness_of_inverses_in_group_proof_without_cancellation 
\exercise.
%%%{{{ meta 
\label uniqueness_of_inverses_in_group_proof_without_cancellation
%%%}}}

Ache uma demonstração do~\ref[uniqueness_of_inverses_in_group]
que não precisa das leis de cancelamento.

%%}}}

%%{{{ remark: what is your group structure? 
\remark Qual a estrutura dos teus grupos?.
%%%{{{ meta 
%%%}}}

Suponha que na nossa estrutura não temos a operação unária de ${}^{-1}$.
Provando finalmente a unicidade dos inversos
(\reftag[uniqueness_of_inverses_in_group]) ganhamos então em cada
grupo $G$ uma \emph{função} (unária) de inverso
$$
\ginvt : G \to G.
$$
Sua \emph{totalidade} já era garantida pela~(G3), que nesse caso é a:
\mathcol
\pforall {a\in G} \cexists {y\in G} {y\ast a = e = a \ast y}   \tag{G3} \\
\intertext{%
e agora acabamos de ganhar sua \emph{determinabilidade} com
o~\ref[uniqueness_of_inverses_in_group].
Ou seja: \emph{função!}
Podemos finalmente definir uma notação para denotar o inverso
de qualquer $a\in G$.
Similarmente, se na nossa estrutura não temos a constante $e$,
então demonstrando a unicidade da identidade ganhamos o direito de
definir uma notação para \emph{a} identidade dum grupo $G$.
Cuidado, pois agora a (G2) tá apenas afirmando a existência
\emph{duma} identidade:
}
\pexists {e\in G} \cforall {a \in G} {e\ast a = a = a\ast e}   \tag{G2} \\
\endmathcol
mas graças ao \ref[uniqueness_of_identity_in_group] sabemos
que é única então podemos definir uma notação pra ela.
Vamos fazer essas duas coisas agora:

%%}}}

%%{{{ df: gid 
\definition identidade para estruturas incompletas.
%%%{{{ meta 
\label gid
\defines
    * \gidof {~G}  -- a identidade do grupo $G$
    * \gid  -- a identidade dum grupo implicito pelo contexto
    ;;
%%%}}}

Seja $\sset G \ast$ grupo.
Denotamos a única identidade de $G$ por
$\gidof G$, ou simplesmente $\gid$ se o grupo $G$ já é
implícito pelo contexto.

%%}}}

%%{{{ df: ginv ; gid 
\definition inversos para estruturas incompletas.
%%%{{{ meta 
\label ginv
\defines
    * \ginv {~a}  -- o inverso de $a$ num grupo
    ;;
%%%}}}

Seja $\sset G \ast$ ou $\sset G {\ast,e}$ grupo.
Para qualquer $a\in G$, definimos o
$$
\ginv a \defeq \text{o único inverso de $a$ no $G$}.
$$

%%}}}

%%{{{ beware: choice_of_group_structure_justifications 
\beware a escolha de estrutura: escrevendo justificativas.
%%%{{{ meta 
\label choice_of_group_structure_justifications
%%%}}}

Um matemático tá trabalhando com grupos $\sset G \ast$,
e ta querendo justificar que
$$
a \ast \gidof G = a.
$$
Qual seria a justificativa que ele vai escrever?
Ele não pode dizer <<pela (G2)>>, pois a (G2)
ta afirmando apenas a existência duma identidade;
ela não ta afirmando nada sobre esse $\gidof G$ ali.
A justificativa dele seria:
\standout
\wq{pela definição do $\gidof G$}.
\endstandout
Por outro lado, um matemático que trabalha com grupos
cuja estrutura já tem a constante $e$ nela, ou seja,
com grupos $\sset G {\ast, e}$ ou $\sset G {\ast, {}^{-1}, e}$,
justificaria o mesmo passo assim:
\standout
\wq{pela (G2R)}.
\endstandout
Similarmente sobre a justificativa de uma igualdade como a
$$
\ginv a \ast a = \gidof G.
$$
Um matemático que trabalha com $\sset G {\ast, {}^{-1}, e}$
justificaria com um simples
\standout
\wq{pela (G3L)}.
\endstandout
Mas para os matemáticos que não tem a operação de inverso
na sua estrutura, a justificativa seria
\standout
\wq{pela definição do $\ginv a$}.
\endstandout
Nesse texto vou usar ambas as abordagens.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo ganhado unicidade da identidade e dos inversos,
vamos responder agora em duas perguntas.

%%}}}

%%{{{ Q1: When is y the inv(a)? 
\question 1.
%%%{{{ meta 
%%%}}}

Num grupo $G$, dado $a\in G$,
o que precisamos mostrar para demonstrar que um certo $y\in G$ é o inverso de $a$?

%%}}}

%%{{{ wrong answer 
\note Resposta errada.
%%%{{{ meta 
%%%}}}

Basta mostrar que $a \ast y = e$
(ou, alternativamente, que $y \ast a = e$)
pois, \emph{graças à unicidade dos inversos},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $y = \ginv a$.

%%}}}

%%{{{ Q2: When is u the identity? 
\question 2.
%%%{{{ meta 
%%%}}}

Num grupo $G$, o que precisamos mostrar para demonstrar que um certo $u\in G$ é a identidade do grupo?

%%}}}

%%{{{ wrong answer 
\note Resposta errada.
%%%{{{ meta 
%%%}}}

Basta achar um $a\in G$ tal que $a \ast u = a$
(ou, alternativamente, tal que $u \ast a = a$),
pois, \emph{graças à unicidade da identidade},
apenas um membro do grupo pode satisfazer essa equação,
e logo necessariamente $u = e$.

%%}}}

%%{{{ Where's the mistake? 
\note Cadê o erro?.
%%%{{{ meta 
%%%}}}

O \emph{raciocínio} nas duas respostas é errado numa maneira parecida:
\eop
Na (1), pode ser que $y$ satisfaz a $a\ast y = e$ sem $y$ ser o inverso do $a$.
\emph{E isso não violaria a unicidade do inverso $\ginv a$},
pois pela definição de \emph{inverso do $a$}, ambas equações $a \ast y = e = y \ast a$
precisam ser satisfeitas, e talvez $y \ast a \neq e$.
\eop
Na (2), pode ser que $u$ satisfaz $a \ast u = a$ para algum membro $a \in G$ sem $u$ ser a identidade do grupo.
\emph{E isso não violaria a unicidade da identidade $e$},
pois pela definição de \emph{identidade do $G$}, o $u$ precisa satisfazer ambas as $a \ast u = e = u \ast e$ e mesmo se satisfaria ambas isso não seria sufiziente: ele tem que as satisfazer não apenas \emph{para algum} $a\in G$ que deu certo, mas \emph{para todo} $a\in G$!
Ou seja: o fato que achamos \emph{algum} $a \in G$ tal que $a \ast u = a (= u \ast a)$
não quis dizer que esse $u$ merece ser chamado \emph{a identidade do $G$} ainda,
pois talvez tem membros $c \in G$ tais que $c \ast u \neq c$ ou $u \ast c \neq c$.

%%}}}

%%{{{ warning: wrong_reasoning_nimplies_wrong_claim_group_eg 
\warning.
%%%{{{ meta 
\label wrong_reasoning_nimplies_wrong_claim_group_eg
%%%}}}

Os raciocínios acima sendo errados não quis dizer que as afirmações também são!
Na verdade, nos dois casos podemos realmente ganhar o que queremos:
identidades e inversos \emph{mais baratos}, sem pagar todo o preço das definições.
Ambos resultados seguem como corolários diretos do~\ref[group_latin_square]
que vamos demonstrar daqui a pouco.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Por enquanto, vamos continuar pesquisando o que mais podemos concluir assim
que tivermos um grupo~$G$, e voltaremos logo nessas duas questões.

%%}}}

%%{{{ Q: Can we conclude something about these? 
\question.
%%%{{{ meta 
%%%}}}

Se $a,b$ são membros de algum grupo $\sset G {\ast,e}$, podemos concluir algo sobre os\dots
\mathcols 3
\ginv {e}           &\askeq \dots? &
\ginvp{\ginv a}     &\askeq \dots? &
\ginvp{a \ast b}    &\askeq \dots?
\endmathcols

%%}}}

\spoiler

%%{{{ A: yes, but we need to prove them 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Sim:
\mathcols 3
\ginv  e            &\askeq e &
\ginvp{\ginv a}     &\askeq a &
\ginvp{a \ast b}    &\askeq \ginv b \ast \ginv a.
\endmathcols
Mas precisamos demonstrar cada uma delas.

%%}}}

%%{{{ different_interpretations_of_same_eq 
\note Interpretações diferentes.
%%%{{{ meta 
\label different_interpretations_of_same_eq
%%%}}}

Considere a primeira afirmação acima:
$$
\ginv e = e.
$$
De quantas maneiras podemos ler (entender) essa equação,
e o que seria uma demonstração de cada uma dessas maneiras?
\mathxcols 3
\text{\proofcase {Maneira 1:}} &&
    \tubrace {\ginv \gid}   {isso}
  & \tubrace {=}            {é}
    \tubrace {\gid}         {a identidade do grupo.}
    &&\\\\
\text{\proofcase {Maneira 2:}} &&
    \tubrace {\aR \gid}         {\aR {isso}}
  & \tubrace {=}                {é}
    \tubrace {\ginv {\aB \gid}} {o inverso de $\aB \gid$.}
    &&\\\\
\text{\proofcase {Maneira 3:}} &&
    \tubrace {\ginv \gid}   {isso}
  & \tubrace {=}            {é}
    \tubrace {\gid}         {isso.}
    &&\text{\phantom{\proofcase {Maneira 0:}}}
\endmathxcols
Com a primeira, o que precisamos mostrar é que o objeto $\ginv \gid$
satisfaz a definição de ser a identidade do grupo, ou seja:
$$
\text{para todo $a \in G$, $\ginv \gid \ast a = a = a \ast \ginv \gid$}.
$$
Com a segunda, precisamos mostrar que a \aR{coisa vermelha}
é o inverso da \aB{coisa azul}.
Mas o que significa ser inverso de algo?
Precisamos mostrar que:
\mathcol
\aR \gid \ast \aB \gid &= \gid \\
\aB \gid \ast \aR \gid &= \gid.
\endmathcol
Com a terceira, a única coisa que podemos fazer é começar calcular
até finalmente chegar nessa igualdade.

%%}}}

%%{{{ advice: read_the_same_equation_in_different_ways 
\advice.
%%%{{{ meta 
\label read_the_same_equation_in_different_ways
%%%}}}

Cada vez que tu queres demonstrar uma igualdade que envolve certas
noções, tente ``ler'' o que a igualdade realmente afirma em
várias maneiras diferentes.  Cada uma é uma chance para te dar
uma idéia de como demonstrá-la!

%%}}}

%%{{{ lemma: inverse_of_identity_in_group 
\lemma inverso da identidade.
%%%{{{ meta 
\label inverse_of_identity_in_group
%%%}}}

Em todo grupo $G$, $\ginv e = e$.

\proof.
Basta mostrar que $e$ é o inverso de $e$, ou seja,
que ele satisfaz $ee = e$, algo imediato pela definição da identidade $e$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Das três maneiras analisadas acima, escolhi a segunda.
Investigue as outras duas:

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

Ache uma demonstração alternativa do~\ref[inverse_of_identity_in_group],
baseada na primeira maneira do~\reftag[different_interpretations_of_same_eq].

\solution
Precisamos mosrar que
$$
\text{para todo $a \in G$, $\ginv e \ast a = e = a \ast \ginv e$}.
$$
Seja $a \in G$.
Vamos mostrar que o $\ginv e$ ``deixa o $a$ em paz'' pelos dois lados.
Calculamos:
\compute
\ginv e \ast a
&= \ginv e \ast (e \ast a)  \by {$a = e\ast a$} \\
&= (\ginv e \ast e) \ast a  \by {G1} \\
&= e \ast a                 \by {def.~de $\ginv e$} \\
&= a                        \by {def.~de $e$} \\
\endcompute
Ou outro lado é similar.

%%}}}

%%{{{ x 
\exercise.
%%%{{{ meta 
%%%}}}

E uma baseada na terceira.

\solution
Calculamos:
\compute
\ginv e
&= \ginv e \ast e   \by {def.~$e$} \\
&= e                \by {def.~$\ginv e$} \\
\endcompute

%%}}}

%%{{{ lm: inverse_of_inverse_in_group 
\lemma inverso de inverso.
%%%{{{ meta 
\label inverse_of_inverse_in_group
%%%}}}

Em todo grupo $G$, $\ginvp {\ginv a} = a$ para todo $a\in G$.

\sketch.
Uma maneira de ler a afirmação: {\proclaimstyle <<$a$ é o inverso de $\ginv a$>>}.
Usando o que significa ser inverso de alguém chegamos no resultado.
Alternativamente, usamos as definições dos inversos envolvidos para ganhar duas equações.
Com elas, chegamos na equação desejada.

\proof.
Vamos ver duas maneiras de demonstrar isso:
\crproofalt{Maneira 1:}
Basta demonstrar que $a$ satisfaz a propriedade de
ser inverso do $\ginv a$:
$$
a \ginv a \eqlabel L e \eqlabel R \ginv a a
$$
e ambas são imediatas: a (L) pela (G3R), e a (R) pela (G3L).
\crproofalt{Maneira 2:}
Pelas definições de $\ginvp{\ginv a}$ e $\ginv a$ ganhamos
as equações:
\compute
\ginvp{\ginv a} \ast \ginv a &= e   \by {def.~$\ginvp{\ginv a}$} \\
a               \ast \ginv a &= e.  \by {def.~$\ginv a$} \\
\intertext{Logo}
\ginvp{\ginv a} \ast \ginv a &= a \ast \ginv a
\endcompute
e cancelando agora pela direita (GCR), chegamos na desejada
$\ginvp{\ginv a} = a$.

%%}}}

%%{{{ x: cd 
\exercise.
%%%{{{ meta 
%%%}}}

Desenhe um diagrama cuja comutatividade é a lei que tu acabou de demonstrar.

\solution
$$
\cdopt{sep=2cm}
A   \ar[r, "\ginvt"]\ar[dr, "\id"'] \| A \ar[d, "\ginvt"] \\
                                    \| A
\endcd
$$

%%}}}

%%{{{ remark: where did the inversion come from 
\remark.
%%%{{{ meta 
%%%}}}

É comum adivinhar erroneamente que em geral
$\ginvp{a \ast b} = \ginv a \ast \ginv b$.
O erro é feito pois, acostumados com certos grupos \emph{bem especiais}
como o $\sset {\reals_{\neq0}} {\ntimes}$ (onde essa lei realmente é válida),
generalizamos para o caso geral de grupos, sem perceber algo estranho e
esquisito que acontece nessa equação.  Repensando em nosso exemplo-guia de
grupos, o~$\sym 3$, o que significa~$a \ast b$?
<<Faça a~$b$, depois a~$a$.>>
E o que signfica $\ginvp{a \ast b}$ então?
<<Desfaça a~$\paren{a \ast b}$.>>
E se aplicar uma transformação~$b$, e depois mais uma~$a$, qual seria o jeito
para desfazer tudo isso e voltar na configuração inicial?
<<Desfaça a~$a$, e depois desfaça a $b$.>>
Ou seja,~$\ginv b \ast \ginv a$.
Isso é bem natural sim: para desfazer uma seqüência de ações, começamos
desfazenso a última, depois a penúltima, etc., até finalmente desfazer
a primeira.
Sendo o inverso então, faz sentido que \emph{a ordem é a inversa também!}
E nos reais, por que não foi a inversa?
Foi sim!
É apenas que o~$\sset {\reals_{\neq0}} {\ntimes}$ é um grupo abeliano;
em outras palavras a ``ordem que acontecem os membros'' não importa.
Mas tudo isso é apenas uma \emph{intuição correta} para adivinhar essa lei.
Precisamos demonstrá-la.  Bora!

%%}}}

%%{{{ lm: inverse_of_product_in_group 
\lemma inverso de produto.
%%%{{{ meta 
\label inverse_of_product_in_group
%%%}}}

Em todo grupo $G$, $\ginvp{a\ast b} = \ginv b \ast \ginv a$
para todo $a,b\in G$.

\sketch.
Queremos mostrar que $\ginv b \ast \ginv a$ é o inverso do $a \ast b$.
Mas o que <<ser o inverso do $a \ast b$>> significa?
Precisamos verificar que o $\ginv b \ast \ginv a$ satisfaz a definição:
$$
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b} = e = \paren{a \ast b} \ast \paren{\ginv b \ast \ginv a}.
$$
Agora só basta fazer esse cálculo mesmo.

\proof.
Calculamos
\compute
\paren{\ginv b \ast \ginv a} \ast \paren{a \ast b}
&= \paren{\paren{\ginv b \ast \ginv a} \ast a} \ast b   \by {assoc.} \\
&= \paren{\ginv b \ast \paren{\ginv a \ast a}} \ast b   \by {assoc.} \\
&= \paren{\ginv b \ast e} \ast b                        \by {def.~$\ginv a$} \\
&= \paren{\ginv b} \ast b                               \by {def.~$e$} \\
&= e                                                    \by {def.~$\ginv b$} \\
\endcompute
A $\paren{a \ast b} \ast \paren{\ginv b \ast \ginv a} = e$ é similar.

%%}}}

%%{{{ x: cd 
\exercise.
%%%{{{ meta 
%%%}}}

Desenhe um diagrama cuja comutatividade é a lei que tu acabou de demonstrar.

\hint
A idéia é descrever cada lado da
$$
\ginvp{a\ast b} = \ginv b \ast \ginv a
$$
como um caminho.
Pense em duas listas de instruções para ser aplicadas no $\tup{a,b}$,
tais que:
seguindo uma das listas acabamos no $\ginv b \ast \ginv a$,
e seguindo a outra no $\ginvp{a\ast b}$.
Para o lado $\ginvp{a\ast b}$ existe apenas uma maneira razoável
de ``quebrá-lo'' em sub-passos.
Para o lado $\ginv b \ast \ginv a$ existem duas equivalentes.
Escolha uma, ou desenha as duas no mesmo diagrama.

\hint
Podes começar com os conjuntos seguintes:
$$
\cdopt{column sep=1cm, row sep=1cm}
            \| G\times G\ar[d]\ar[rrrr] \|           \| \| \| G\ar[dd] \\
            \| G\times G\ar[d]          \|           \| \| \|   \\
            \| G\times G\ar[rrrr]       \|           \| \| \| G
\endcd
$$
A coluna esquerda corresponde num caminho do $\tup{a,b}$
para o $\tup{\ginv b, \ginv a}$.

\hint
Substitui a coluna esquerda por dois caminhos formando o rombo
na esquerda (ele comuta):
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W]
\ar[from=N,to=E]
\ar[from=W,to=S]
\ar[from=E,to=S]
\ar[from=N,to=NE]
\ar[from=NE,to=SE]
\ar[from=S,to=SE]
\endcd
$$
Agora só basta botar nomes nas setas.

\solution
Um tal diagrama é o seguinte:
$$
\cdopt{column sep=6mm, row sep=2cm}
                        \| |[alias=N]| G\times G \|                      \| \| \| |[alias=NE]| G \\
|[alias=W]| G\times G   \|                       \||[alias=E]| G\times G \| \| \|                \\
                        \| |[alias=S]| G\times G \|                      \| \| \| |[alias=SE]| G
\ar[from=N,to=W,"\swap"']
\ar[from=N,to=E,"\ginvt\times\ginvt"]
\ar[from=W,to=S,"\ginvt\times\ginvt"']
\ar[from=E,to=S,"\swap"]
\ar[from=N,to=NE,"\ast"]
\ar[from=NE,to=SE,"\ginvt"]
\ar[from=S,to=SE,"\ast"]
\endcd
$$
onde $\swap(x,y) = \tup{y,x}$.

%%}}}

%%{{{ lemma: group_latin_square 
\lemma resolução de equações: Latin square.
%%%{{{ meta 
\label group_latin_square
%%%}}}

Seja $G$ grupo.
Para quaisquer $a,b,x,y\in G$,
cada uma das equações abaixo tem resolução única para $x$ e $y$:
$$
\xalignat2
a\ast x &= b
&
y\ast a &= b
\endxalignat
$$

\sketch.
Aplicando o inverso de $a$ em cada equação pelo lado certo,
achamos que as soluções necessariamente são
$x = \ginv a \ast b$ e $y = b \ast \ginv a$.

\proof.
Aplicando $(a^{-1}\ast)$ nos dois lados da primeira
e $(\ast a^{-1})$ nos dois lados da segunda temos:
$$
\xalignat2
  a\ast x = b &\impliesbecause{$\ginv a\ast$} \ginv a\ast \paren{a\ast x} = a^{-1} \ast b 
& y\ast a = b &\impliesbecause{$\ast\ginv a$} \paren{x\ast a}\ast \ginv a = b \ast \ginv a
\\
&\implies\paren{\ginv a\ast a}\ast x = \ginv a \ast b
&&\implies y\ast \paren{a\ast \ginv a} = b \ast \ginv a
\\
&\implies e \ast x = \ginv a \ast b
&&\implies y\ast e = b \ast \ginv a
\\
&\implies x = \ginv a \ast b
&&\implies y = b \ast \ginv a
\endxalignat
$$

%%}}}

%%{{{ remark: ab_eq_c_each_determined_by_other_two 
\remark.
%%%{{{ meta 
\label ab_eq_c_each_determined_by_other_two
%%%}}}

Isso quis dizer que dada uma equação $a \ast b = c$,
cada um dos $a,b,c$ é determinado pelos outros dois!
Assim, podemos \emph{definir} por exemplo o objeto $x$
como \emph{a única solução da} $a\ast x = b$, etc.

%%}}}

%%{{{ cor: cheaper_ginv 
\corollary inversos mais baratos.
%%%{{{ meta 
\label cheaper_ginv
%%%}}}

Seja $G$ grupo e $a,y \in G$
tais que $a\ast y = e$ ou $y \ast a = e$.
Logo $y = \ginv a$.

%%}}}

%%{{{ cor: cheaper_gid 
\corollary identidade mais barata.
%%%{{{ meta 
\label cheaper_gid
%%%}}}

Seja $G$ grupo $u\in G$.
Se para algum $a\in G$, $au = a$ ou $ua = a$, então $u$ é a identidade do grupo:
$u = e$.

%%}}}

%%{{{ x: cheaper_ginv_and_gid_by_cancellation 
\exercise.
%%%{{{ meta 
\label cheaper_ginv_and_gid_by_cancellation
%%%}}}

Ganhamos esses resultados (\ref[cheaper_ginv] e~\reftag[cheaper_gid])
como corolários do~\ref[group_latin_square].
Mostre como ganhá-los como corolários das leis de cancelamento.

%%}}}

%%{{{ x: abelian_iff_inv_of_prod_sameorder 
\exercise.
%%%{{{ meta 
\label abelian_iff_inv_of_prod_sameorder
%%%}}}

Seja $G$ grupo.
Demonstre a equivalência:
$$
\text{$G$ abeliano} \iff \text{para todo $a,b\in G$, $\ginvp{ab} = \ginv a \ginv b$}.
$$

\solution
\lrdir.
Calculamos:
\compute
\ginvp{ab}
&= \ginv b \ginv a      \by {pelo~\ref[inverse_of_product_in_group]} \\
&= \ginv a \ginv b.     \by {$G$ abeliano} \\
\endcompute
\rldir.
Calculamos:
\compute
ab
&= \ginvp{\ginvp{ab}}               \by {pelo~\ref[inverse_of_inverse_in_group]} \\
&= \ginvp{\ginv b \ginv a}          \by {pelo~\ref[inverse_of_product_in_group]} \\
&= \ginvp{\ginv b} \ginvp{\ginv a}  \by {pela hipótese} \\
&= b a.                             \by {pelo~\ref[inverse_of_inverse_in_group]~($\times2$)} \\
\endcompute

%%}}}

%%{{{ criterion: cancellation_based_group_def 
\criterion Definição de grupo com cancelamento.
%%%{{{ meta 
\label cancellation_based_group_def
%%%}}}

Seja $\ssetfont G = \sset G \ast$ um conjunto \emph{finito} estruturado
que satisfaz:
\mathcol
\cforall {a,b\in G}    {a\ast b \in G}                    \tag{G0}  \\
\cforall {a,b,c\in G}  {a\ast(b\ast c) = (a\ast b)\ast c} \tag{G1}  \\
\cforall {a,x,y\in G}  {a\ast x = a\ast y \implies x=y}   \tag{GCL} \\
\cforall {a,x,y\in G}  {x\ast a = y\ast a \implies x=y}.  \tag{GCR} \\
\endmathcol
Então $\ssetfont G$ é um grupo.

\proof.
\ref[cancellation_based_group_def_proof]

%%}}}

%%{{{ x: cancellation_based_group_def_only_valid_for_finite_G 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre que não podemos apagar o ``finito'' das nossas hipoteses.

\hint
Procure contraexemplo!

\solution
Veja~\ref[how_come_the_cancellation_laws_hold_in_nongroup_without_inverses].

%%}}}

%%{{{ criterion: onesided_group_def 
\criterion Definição unilateral ``one-sided'' de grupo.
%%%{{{ meta 
\label onesided_group_def
%%%}}}

Seja $\ssetfont G = \sset G {\ast,e}$ um conjunto estruturado que satisfaz:
\mathcol
\cforall {a,b\in G}      {a \ast b \in G}                        \tag{G0}  \\
\cforall {a,b,c\in G}    {a \ast (b \ast c) = (a \ast b) \ast c} \tag{G1}  \\
\cforall {a \in G}       {a \ast e = a}                          \tag{G2R} \\
\pforall {a\in G} \cexists {y\in G} {a \ast y = e}               \tag{G3R} \\
\intertext{%
Então $\ssetfont G$ é um grupo.
Similarmente se adicionar as
}
\cforall {a \in G}                  {e \ast a = a}   \tag{G2L} \\
\pforall {a\in G} \cexists {y\in G} {y \ast a = e}.  \tag{G3L} \\
\endmathcol

\proof.
\ref[onesided_group_def_proof].

%%}}}

%%{{{ x: onesided_group_def_catch 
\exercise.
%%%{{{ meta 
\label onesided_group_def_catch
%%%}}}

Verifique que mesmo se conseguir demonstrar as
\mathcol
\cforall {a \in G}                    {e \ast a = a}   \tag{G2L} \\
\pforall {a \in G} \cexists {y \in G} {y \ast a = e}   \tag{G3L} \\
\endmathcol
isso não nos permite deduzir trivialmente as (G2) e (G3)!
Explique o porquê.

%%}}}

%%{{{ x: splitsided_group_notdef 
\exercise.
%%%{{{ meta 
\label splitsided_group_notdef
%%%}}}

Podemos substituir a (G3R) do~\ref[onesided_group_def] por
\mathcol
\pforall {a \in G} \cexists {y \in G} {y \ast a = e}   \tag{G3L} \\
\endmathcol
e ainda concluir que $\ssetfont G$ é grupo?
Ou seja, se a operação possui R-identidade,
e se cada membro tem L-inverso, o $\ssetfont G$
é necessariamente um grupo?
(Obviamente a resposta na pergunta simétrica deve ser a mesma.)

\hint
Não!

\hint
Procure um contraexemplo.
(Claramente, a operação não pode ser comutativa.)

\hint
Dá pra construir contraxemplo com apenas $2$ membros.

\hint
Considere como operação binária a $\outl$.

\solution
Seja $A = \set{\idr,a}$ um conjunto com dois membros.
Definimos a operação $\ast$ pela:
$$
x \ast y = x.
$$
Confirmamos que $\sset A \ast$ satisfaz todas as
(G0),(G1),(G2R),(G3L), mas mesmo assim não é um
grupo: não tem identidade, pois a $\idr$ não serve
como L-identidade:
$$
\idr \ast a = \idr \neq a.
$$

%%}}}

\endsection
%%}}}

%%{{{ Cayley tables 
\section Tabelas Cayley.
%%%{{{ meta 
\label Cayley_tables
%%%}}}

%%{{{ Q: In how many ways can we define an operation to create a finite group? 
\question.
%%%{{{ meta 
%%%}}}

De quantas maneiras podemos definir uma operação binária $\ast$
num conjunto finito $G$, tal que $\sset G \ast$ é um grupo?

%%}}}

\spoiler

%%{{{ What determines an operation 
\note O que determina uma operação.
%%%{{{ meta 
%%%}}}

O que significa \emph{definir uma operação} (binária)?
Seguindo nossa definição de igualdade (extensional) entre funções,
precisamos deixar claro para qualquer $\tup{x,y}\in G\times G$,
seu único valor $x \ast y \in G$.
Vamos brincar com os casos mais simples.
Se $\card G = 0$, não tem como virar um grupo,
pois todo grupo tem pelo menos um membro: sua identidade.
Se $\card G = 1$, só tem uma operação possível, pois não existe
nenhuma opção para o valor $e \ast e$: necessariamente $e \ast e = e$.
E essa opção realmente vira-se o $\sset G \ast$ um grupo (trivial).

%%}}}

%%{{{ 234_groups 
\note Os casos 2,3,4.
%%%{{{ meta 
%%%}}}

Vamos dizer que temos um conjunto $G$ com $\card G = 4$.
Não sabemos nada sobre seus membros, podem ser números, letras, pessoas,
funções, conjuntos, sapos, sei-lá:
$$
G = \set{ \bullet, \bullet, \bullet, \bullet }.
$$
Então faz sentido começar nossa investigação dando uns nomes para
esses membros, por exemplo $a,b,c,d$, onde não vamos supor nada mais
sobre eles exceto que são distintos dois-a-dois.
$$
\text{<<Sejam $G\eqass\set{a,b,c,d}$.>>}
$$
Sera que podemos fazer algo melhor?
Querendo tornar o $G$ em grupo, sabemos que ele vai ter exatamente uma
identidade, então melhor denotá-la com $e$,
e escolher nomes para os outros três membros do $G$:
$$
G = \set {e, a, b, c}.
$$
Similarmente, caso que $\card G = 2$ ou $3$, teremos
$G = \set {e, a}$
ou
$G = \set {e, a, b}$
respectivamente.

%%}}}

%%{{{ Cayley tables 
\note Tabelas Cayley.
%%%{{{ meta 
\defines
    * tabela!Cayley
    ;;
%%%}}}

{\Cayley[tabela]}%
Temos então que ver o que podemos botar nos $\faded?$ para completar
as \dterm{tabelas Cayley} abaixo:
$$
\xalignat3
\matrix
\ast& e & a \\
e   & \faded? & \faded? \\
a   & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & \faded? & \faded? & \faded? & \faded? \\
a   & \faded? & \faded? & \faded? & \faded? \\
b   & \faded? & \faded? & \faded? & \faded? \\
c   & \faded? & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$
Mas, não todos os $\faded?$ realmente representam uma escolha,
pois certos deles são determinados; e cada vez que fazemos uma escolha
para um deles, possivelmente nossas opções próximas deminuiam.
Para começar, como $e\ast x = x = x \ast e$ para qualquer $x$ do grupo,
a primeira linha e a primeira coluna da tabela já são determinadas:\foot
De fato, foi por isso que Cayley realmente nem escreveu a coluna
e a linha ``exterior'', tomando a convenção que o elemento que aparece
primeiro é a sua identidade.
Para um grupo de três elementos então, ele começaria assim:
$$
\matrix
a & b       & c       \\
b & \faded? & \faded? \\
c & \faded? & \faded?
\endmatrix
\qquad
\text{que, seguindo nossa convenção com \symq{$e$}, escreveríamos}
\qquad
\matrix
e & a       & b       \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
$$
\toof
$$
\xalignat3
\matrix
\ast& e & a \\
e   & e & a \\
a   & a & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b \\
e   & e & a & b \\
a   & a & \faded? & \faded? \\
b   & b & \faded? & \faded?
\endmatrix
&&
\matrix
\ast& e & a & b & c \\
e   & e & a & b & c \\
a   & a & \faded? & \faded? & \faded? \\
b   & b & \faded? & \faded? & \faded? \\
c   & c & \faded? & \faded? & \faded?
\endmatrix
&
\intertext{Exatamente por causa dessa observação, em geral omitimos a
primeira coluna e a primeira linha dessas tabelas, escrevendo as três
tabelas acima nesse jeito:}
\matrix
e & a \\
a & \faded?
\endmatrix
&&
\matrix
e & a & b \\
a & \faded? & \faded? \\
b & \faded? & \faded?
\endmatrix
&&
\matrix
e & a & b & c \\
a & \faded? & \faded? & \faded? \\
b & \faded? & \faded? & \faded? \\
c & \faded? & \faded? & \faded?
\endmatrix
&
\endxalignat
$$

%%}}}

%%{{{ Q: how can we replace the blanks? 
\question.
%%%{{{ meta 
%%%}}}

O que tu podes botar nos\/ $\faded?$ para chegar num grupo?
O que muda se tu queres construir um grupo abeliano?

%%}}}

\spoiler

%%{{{ 2 members 
\note 2 membros.
%%%{{{ meta 
%%%}}}

Vamos começar no caso mais simples, onde temos apenas um $\faded?$ para preencher.
Em teoria temos duas opções: $e,a$.  Mas precisamos verificar se o conjunto
realmente torna-se um grupo ou não.  Escolha $a$:
$$
\matrix
e & a \\
a & \alert a
\endmatrix
$$
Qual seria o inverso do $a$?
Nenhum!
Assim o~(G3) será violado, ou seja, não podemos escolher o $a$.
Se escolher nossa única outra opção ($e$) temos:
$$
\matrix
e & a \\
a & \alert e
\endmatrix
$$
Que realmente é um grupo.

%%}}}

%%{{{ x: Verify! 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique!


%%}}}

%%{{{ x: find_all_groups_of_order_3 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_3
%%%}}}

Ache todas as operações possíveis que tornam um conjunto com $3$ membros um grupo.

\hint
Só tem uma maneira.  Qual?  Por quê?

\solution
Só tem uma maneira:
$$
\matrix
e & a & b\\
a & b & e\\
b & e & a
\endmatrix
$$
Realmente não temos nenhuma opção em nenhum dos $\faded?$.
O~\ref[find_the_rules_of_grupoku] investiga o porquê.

%%}}}

%%{{{ Playing ``grupoku'' 
\note Jogando ``Grupoku''.
%%%{{{ meta 
\defines
    * Grupoku
    ;;
%%%}}}

Investigar todas as possíveis escolhas para os~$\faded?$ parece como um jogo
de Sudoku, só que nossa restricção não é com a soma dos números de cada linha e
cada coluna como no Sudoku---nem poderia ser isso: nossos membros possivelmente
nem são números---mas as leis~(G0)--(G3) que tem que ser satisfeitas.
E caso que queremos criar um grupo abeliano, a~(GA) também.

%%}}}

%%{{{ x: find_the_rules_of_grupoku 
\exercise.
%%%{{{ meta 
\label find_the_rules_of_grupoku
%%%}}}

Que restricções pode afirmar que temos nesse jogo de ``Grupoku'',
graças todos os resultados que temos demonstrado até agora sobre grupos?
E se queremos um grupo abeliano, muda o quê?

%%}}}

%%{{{ x: find_all_groups_of_order_4 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_4
%%%}}}

Ache todas as operações possíveis que tornam um conjunto com $4$
membros um grupo.

\hint
\emph{Essencialmente} são apenas $2$.
Se achar mais, verifique que renomeando seus membros umas viram iguais,
e só tem dois que realmente não tem como identificá-las,
mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\reftag[Group_morphisms]).

\solution
\emph{Essencialmente} são apenas $2$:
$$
\xalignat2
\matrix
e & a & b & c \\
a & b & c & e \\
b & c & e & a \\
c & e & a & b
\endmatrix
&&
\matrix
e & a & b & c \\
a & e & c & b \\
b & c & e & a \\
c & b & a & e
\endmatrix
&
\endxalignat
$$
O primeiro é conhecido como o grupo cíclico de ordem $4$;
o segundo como {\Klein[four-group]}Klein four-group.
Se tu achaste mais, verifique que renomeando seus membros
umas viram iguais, e só tem dois que realmente não tem como
identificá-las, mesmo renomeanos seus membros.
Tudo isso vai fazer bem mais sentido daqui umas secções onde vamos
estudar o conceito de isomorfia~(\reftag[Group_morphisms]).

%%}}}

%%{{{ x: find_all_groups_of_order_0_and_1 
\exercise.
%%%{{{ meta 
\label find_all_groups_of_order_0_and_1
%%%}}}

Tem grupos de ordem 1?  De 0?

\solution
De ordem $1$ sim.  Cada um tem a mesma forma: seu único elemento é sua identidade.
De ordem $0$, não: a lei (G2) \emph{manda a existência} de um certo membro do grupo (a sua identidade).

%%}}}

\endsection
%%}}}

%%{{{ Powers_and_orders 
\section Potências e ordens.
%%%{{{ meta 
\label Powers_and_orders
%%%}}}

%%{{{ df: powers_in_group 
\definition.
%%%{{{ meta 
\label powers_in_group
\defines
    * ~a^{~m}  -- $a \ast \dotsb \ast a$ ($m$ vezes)
    ;;
%%%}}}

Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos suas potências $a^{\ast n}$ onde $n\in\nats$ recursivamente:
$$
\align
a^{\ast 0}     &\defeq e\\
a^{\ast {n+1}} &\defeq a \ast a^{\ast n}
\endalign
$$
Quando a operação $\ast$ é entendida pelo contexto
escrevemos apenas $a^n$ em vez de $a^{\ast n}$.

%%}}}

%%{{{ x: powers_in_group_altdef 
\exercise.
%%%{{{ meta 
\label powers_in_group_altdef
%%%}}}

Demonstre que a definição alternativa de exponenciação ao natural
$$
\align
a^{\ast 0}     &= e\\
a^{\ast {n+1}} &= a^{\ast n} \ast a
\endalign
$$
é equivalente.

\hint
Como o próprio ``operador'' de exponenciar fica escondido na notação
comum $a^b$, melhor escrever temporariamente as duas definições como:
$$
\xalignat2
a \uparrow_1 0 &= e &
a \uparrow_2 0 &= e \\
a \uparrow_1 (n+1) &= a \ast (a \uparrow_1 n) &
a \uparrow_2 (n+1) &= (a \uparrow_2 n) \ast a.
\endxalignat
$$
Agora tem uma notação melhor para demonstrar o que queremos: ${\uparrow_1} = {\uparrow_2}$.
O que significa que duas operações (funções) são iguais?

\hint
Precisamos mostrar que:
$$
\text{para todo $a\in G$ e todo $n\in\nats$,}\quad
a \uparrow_1 n = a \uparrow_2 n
$$
ou, simbolicamente:
$$
\align
\pforall {a \in G}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\intertext{\emph{Seja $a\in G$.}  Agora queremos demonstrar:}
&\lforall {n\in\nats} {a \uparrow_1 n = a \uparrow_2 n}.
\endalign
$$
Como demonstrar isso?

\hint
As definições envolvidas são recursivas.

\hint
Ou seja: indução.

\hint
\proofpart {Base:} demonstrar que $a \uparrow_1 0 = a \uparrow_2 0$:

\hint
Seja $k\in\nats$ tal que $a \uparrow_1 k = a \uparrow_2 k$ (hipótese indutiva).
Queremos mostrar que
$$
a \uparrow_1 (k+1) = a \uparrow_2 (k+1).
$$

\hint
Seguindo as dicas anteriores, provavelmente tu chegou aqui:
\compute
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$} \\
&= a \ast (a \uparrow_2 k)   \by {HI} \\
\intertext{\dots e agora?
\emph{Se} $\ast$ fosse comutativa (ou seja, se o grupo fosse abeliano),
a gente \emph{poderia} continuar assim:}
&= (a \uparrow_2 k) \ast a   \by {comutatividade~(GA)} \\
&= a \uparrow_2 (k+1).       \by {def.~$\uparrow_2$} \\
\intertext{\emph{Só que não!}
Sobre o $G$ sabemos apenas que é um grupo, então não podemos contar na
comutatividade da sua operação $\ast$.
(Inclusive, se a $\ast$ fosse comutativa o resultado seria
trivial e nem precisaria indução.)
Voltando no passo que tivemos colado}
a \uparrow_1 (k+1)
&= a \ast (a \uparrow_1 k)   \by {def.~$\uparrow_1$} \\
&= a \ast (a \uparrow_2 k)   \by {HI} \\
\endcompute
percebemos que precisamos ``abrir mais'' a expressão $(a \uparrow_2 k)$,
aplicando a definição de $\uparrow_2$, mas não podemos, pois não sabemos se $k=0$ ou não.
Neste momento então percebemos que saber a veracidade dessa equação apenas para o valor $n=k$ não é suficiente.
Tu vai precisar o $n=k-1$ também.
\eop
Ou seja, tu vai precisar \emph{duas} bases ($n=0,1$),
e supor que tem um $k \geq 2$ tal que ambos os $k-1$ e $k-2$ satisfazem a
$a \uparrow_1 n = a \uparrow_2 n$.
Ou seja, tu ganharás as \emph{duas} hipoteses indutivas:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2) \tag{HI2}
\endalign
$$
e só bastará demonstrar que $a \uparrow_1 k = a \uparrow_2 k$.

\solution
Seja $a \in G$.
Vamos demonstrar que para todo $n\in\nats$, $a \uparrow_1 n = a \uparrow_2 n$
por indução no $n$.
\crproofpart {Bases $n\asseq 0,1$:}
Temos
$$
\computed {
a \uparrow_1 0
&= e               \by {def.~$\uparrow_1$} \\
&= a \uparrow_2 0  \by {def.~$\uparrow_2$} \\
}
\qqqquad
\computed {
a \uparrow_1 1
&= a \ast (a \uparrow_1 0)  \by {def.~$\uparrow_1$} \\
&= a \ast e                 \by {def.~$\uparrow_1$} \\
&= a                        \by {def.~$e$} \\
&= e \ast a                 \by {def.~$e$} \\
&= (a \uparrow_2 0) \ast a  \by {def.~$\uparrow_2$} \\
&= a \uparrow_2 1           \by {def.~$\uparrow_2$} \\
}
$$
\proofpart {Passo indutivo:}
Seja $k\in\nats$, tal que $k\geq 2$ e:
$$
\align
a \uparrow_1 (k-1) &= a \uparrow_2 (k-1) \tag{HI1}\\
a \uparrow_1 (k-2) &= a \uparrow_2 (k-2).\tag{HI2}
\endalign
$$
Precisamos demonstrar que $a \uparrow_1 k = a \uparrow_2 k$.
Calculamos:
\compute
a \uparrow_1 k
&= a \ast \paren{a \uparrow_1 (k-1)}                \by {def.~$\uparrow_1$} \\
&= a \ast \paren{a \uparrow_2 (k-1)}                \by {HI1} \\
&= a \ast \paren{\paren{a \uparrow_2 (k-2)} \ast a} \by {def.~$\uparrow_2$} \\
&= a \ast \paren{\paren{a \uparrow_1 (k-2)} \ast a} \by {HI2} \\
&= \paren{a \ast \paren{a \uparrow_1 (k-2)}} \ast a \by {associatividade~(G1)} \\
&= \paren{a \uparrow_1 (k-1)} \ast a                \by {def.~$\uparrow_1$} \\
&= \paren{a \uparrow_2 (k-1)} \ast a                \by {HI1} \\
&= a \uparrow_2 k.                                  \by {def.~$\uparrow_2$} \\
\endcompute
Pelo principio da indução segue que para todo $n\in\nats$,
$a \uparrow_1 n = a \uparrow_2 n$.
Como $a$ foi arbitrário membro de $G$, isso termina nossa demonstração que
${\uparrow_1} = {\uparrow_2}$.

%%}}}

\TODO connect this with \ref[concat_iterations_equivalent].

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Acabaste de demonstrar um teorema bem mais geral do que parece
no enunciado do~\ref[powers_in_group_altdef]!
É o seguinte:

%%}}}

%%{{{ thm: associative_with_identity_exp_defs_equiv 
\theorem.
%%%{{{ meta 
\label associative_with_identity_exp_defs_equiv
%%%}}}

Seja $A$ um conjunto estruturado e~$\ast$~uma operação
binária e associativa no~$A$, com identidade $u$.
As duas definições de potências
$$
\xalignat2
a^{\ast0}     &= u &
a^{\ast0}     &= u \\
a^{\ast{n+1}} &= a \ast a^n &
a^{\ast{n+1}} &= a^n \ast a
\endxalignat
$$
são equivalentes, ou seja, as duas operações
definidas são iguais.

\proof Demonstrado.
No~\ref[powers_in_group_altdef], pois as únicas coisas que
precisamos na sua demonstração foram exatamente as hipoteses
desse teorema.

%%}}}

%%{{{ thm: properties_of_exp_in_general 
\theorem.
%%%{{{ meta 
\label properties_of_exp_in_general
%%%}}}

A operação de exponenciação definida
no~\ref[associative_with_identity_exp_defs_equiv]
satisfaz as leis:
% TODO: fix reflabs
\tlist:
\li (1): $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m+n}        = a^m \ast a^n}$;
\li (2): $\pforall {n,m\in\nats} \lforall {a \in A} {a^{m\ntimes n} = (a^m)^n}$;
\li (3): $\lforall {n\in\nats}   {\gid^n = \gid}$.
\endtlist

\proof Já demonstrado.
Como observamos no~\ref[properties_of_function_iterations] também,
quando demonstramos por indução as leis nos exercícios~\reftag[law_of_natexp_1],
\reftag[law_of_natexp_2], e~\reftag[law_of_natexp_3],
usamos apenas a \emph{associatividade} e a \emph{identidade} da
multiplicação e \emph{não usamos sua definição}.
Logo a mesma demonstração serve aqui, trocando a multiplicação por nossa $\ast$.

%%}}}

\TODO Teaser/remark about \ref[Algebraic_structures].

%%{{{ x: sq_of_prod_not_prod_of_sq 
\exercise.
%%%{{{ meta 
\label sq_of_prod_not_prod_of_sq
%%%}}}

Mostre que, \emph{em geral}, $(a \ast b)^2 \neq a^2 \ast b^2$.

%%}}}

\TODO check the following exercise for dups and position.

%%{{{ x: in_finite_groups_all_members_have_finite_orders 
\exercise.
%%%{{{ meta 
\label in_finite_groups_all_members_have_finite_orders
%%%}}}

Seja $G$ grupo finito.
Para todo $a \in G$, existe $n \in \nats_{>0}$
tal que $a^n = e$.
Demonstre:
(i) diretamente;
(ii) usando a contrapositiva;
(iii) usando reductio ad absurdum.

%%}}}

%%{{{ beware: for which values of w have we defined a^w? 
\beware.
%%%{{{ meta 
%%%}}}

Neste momento então, para qualquer grupo $G$ e qualquer $a\in G$,
o símbolo $a^w$ é definido \emph{apenas} para $w \asseq -1, 0, 1, 2, \dots$
e nada mais!
Vamos agora estender para os valores $w \asseq -2, -3, -4, \dots$
num jeito razoável.

%%}}}

%%{{{ Q: what do you think a^{-2} should mean? 
\question.
%%%{{{ meta 
%%%}}}

O que você acha que deveria ser denotado por $a^{-2}$?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Bem, tem duas interpretações, ambas razoáveis:
$$
a^{-2} \askeq \pathed {
\paren{\ginv a}^2 & (o quadrado do inverso do $a$) \cr
\pathween {\dots\orword\dots}
\ginvp{a^2}       & (o inverso do quadrado do $a$)
}
$$
As duas interpretações são equivalentes:

%%}}}

%%{{{ x: inv_of_square_eq_square_of_inv 
\exercise.
%%%{{{ meta 
\label inv_of_square_eq_square_of_inv
%%%}}}

Seja $G$ grupo.  Para todo $a\in G$,
$\paren{a^{-1}}^2 = \paren{a^2}^{-1}$.
Ou seja, o diagrama
$$
\cdopt{sep=2cm}
G \ar[r, "\ginv\bhole"] \ar[d, "\bhole^2"] \| G \ar[d, "\bhole^2"]\\
G \ar[r, "\ginv\bhole"]                    \| G
\endcd
$$
comuta.

\hint
\ref[different_interpretations_of_same_eq]
e~\ref[read_the_same_equation_in_different_ways].

\hint
Tem como demonstrar isso numa linha só!
Se não enxergar como, seja $a\in G$.
O que tu precisas mostrar, é que $\paren{\ginv a}^2$ é o inverso do $a^2$.
O que significa <<ser o inverso do $a^2$>>?

\hint
$
\paren{\ginv a}^2 \ast {a^2}
\askeq e
\askeq {a^2} \ast \paren{\ginv a}^2
$.

\solution
Graças ao~\ref[cheaper_ginv], basta demonstrar que para todo $a\in G$,
$\paren{\ginv a}^2 \ast a^2 = e$.
Seja $a\in G$ então.  Calculamos:
\compute
\paren{a^{-1}}^2 \ast {a^2}
&= (\ginv a \ast \ginv a) \ast {a^2}             \by {def.~$\paren{\ginv a}^2$} \\
&= (\ginv a \ast \ginv a) \ast \paren{a\ast a}   \by {def.~$a^2$} \\
&= \paren{(\ginv a \ast \ginv a) \ast a}\ast a   \by {ass.} \\
&= \paren{\ginv a \ast (\ginv a \ast a)}\ast a   \by {ass.} \\
&= \paren{\ginv a \ast e}\ast a                  \by {def.~$\ginv a$} \\
&= \ginv a \ast a                                \by {def.~$e$} \\
&= e                                             \by {def.~$\ginv a$} \\
\endcompute
Logo $\paren{\ginv a}^2$ é o inverso de $a^2$.
\eop
Mas, um segundo!
Nessa maneira fizemos bem mais trabalho do que precisamos.
Observe que praticamente repetimos aqui a demonstração
do~\ref[inverse_of_product_in_group]!
Seria melhor simplesmente usá-lo,
chegando assim nessa demonstração bem mais simples:
\compute
\ginvp{a^2}
&= \ginvp{aa}           \by {def.~$a^2$} \\
&= \ginv a \ginv a      \by {inv.~prod.~(\ref[inverse_of_product_in_group])} \\
&= \paren{\ginv a}^2.   \by {def.~$\paren{\ginv a}^2$} \\
\endcompute

%%}}}

%%{{{ x: inv_of_npow_eq_npow_of_inv 
\exercise.
%%%{{{ meta 
\label inv_of_npow_eq_npow_of_inv
%%%}}}

Generalize o~\ref[inv_of_square_eq_square_of_inv] para $n\in\nats$:
\emph{para todo grupo $G$ e todo $n\in\nats$, se $a\in G$ então
$\paren{\ginv a}^n = \ginvp{a^n}$}.

\hint
As potências de elementos de grupo foram definidas
\emph{recursivamente}.

\hint
Indução.

%%}}}

%%{{{ df: negpowers_in_group 
\definition.
%%%{{{ meta 
\label negpowers_in_group
%%%}}}

Seja $a$ elemento dum grupo $\sset G {\ast,e}$.
Definimos para todo $n\in\nats_{>0}$.
$$
a^{-n} \defeq \paren{\ginv a}^n
$$
Note que graças ao \ref[inv_of_npow_eq_npow_of_inv]
a definição alternativa de exponenciação ao inteiro negativo
$
a^{-n} \defeq \ginvp {a^n}
$
é equivalente.

%%}}}

%%{{{ property: properties_of_powers_in_groups 
\property Potências.
%%%{{{ meta 
\label properties_of_powers_in_groups
%%%}}}

Sejam $G$ grupo, $a \in G$, e $m,n\in\ints$.
Temos:
\item{\rm (1)} $a^m \ast a^n = a^{m+n}$;
\item{\rm (2)} $(a^m)^n = a^{m\ntimes n}$;
\item{\rm (3)} $\gid^n = \gid$;
\item{\rm (4)} $\ginvp {a^n} = \paren{\ginv a}^n$.

\sketch.
Demonstramos a (4) primeiro para $m,n\in\nats$ por
indução---as (1)--(3) já demonstramos~(\ref[properties_of_exp_in_general]).
Depois consideramos os casos de inteiros negativos para as quatro leis.

%%}}}

%%{{{ x: square_of_product_abelian_criterion
\exercise.
%%%{{{ meta 
\label square_of_product_abelian_criterion
%%%}}}

Seja $G$ grupo tal que para todo $a,b \in G$, $(ab)^2 = a^2 b^2$.
Logo, $G$ é abeliano.

\hint
Sejam $x,y\in G$.
Calcule o $(xy)^2$ em dois jeitos.

\solution
Sejam $x,y\in G$.
Pela hipótese temos:
$$
\align
(xy)^2 &= x^2y^2 = xxyy;
\intertext{e pela definição de $(xy)^2$ temos}
(xy)^2 &= xyxy.
\endalign
$$
Ou seja
$$
\align
xxyy &= xyxy
\intertext{e cancelando os $x$ pela esquerda
e os $y$ pela direita, chegamos no desejado:}
xy &= yx.
\endalign
$$

%%}}}

%%{{{ df: order_of_member_in_group 
\definition Ordem de membro em grupo.
%%%{{{ meta 
\label order_of_member_in_group
\defines
    * \gord {~a}  -- a ordem do elemento $a$ num grupo
    * ordem!de membro em grupo
    ;;
%%%}}}

Seja $\sset G {\ast,e}$ grupo e $a\in G$.
Chamamos \dterm{ordem} de $a$ o menor positivo $n\in\nats$ tal que
$a^n = e$, se tal $n$ existe; caso contrário, dizemos que o $a$ tem ordem infinita.
Usamos a mesma notação como no caso de ordem de grupos:
$\gord a$, $\tord a$, ou $\bord a$, com os mesmos cuidados.
Logo:
$$
\gord a =
\knuthcases {
\min \setst {n\in\nats_{>0}} {a^n = e}, & se $\setst {n\in\nats_{>0}} {a^n = e} \neq \emptyset$\cr
\infty,                                 & caso contrário.
}
$$

%%}}}

%%{{{ eg: orders_of_members_of_S3 
\example.
%%%{{{ meta 
\label orders_of_members_of_S3
%%%}}}

No $\sym 3$, temos
$$
\xalignat3
\gord {\id} &= 1 & \gord {\phi}         &= 2  &  \gord {\psi}   &= 3\\
            &    & \gord {\phi\com\psi} &= 2  &  \gord {\psi^2} &= 3.\\
            &    & \gord {\psi\com\phi} &= 2  &  
\endxalignat
$$

%%}}}

%%{{{ x: verify the numbers of orders_of_members_of_S3 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique os números do~\ref[orders_of_members_of_S3].

%%}}}

%%{{{ x: nonzero_power_is_gid_implies_finite_order 
\exercise.
%%%{{{ meta 
\label nonzero_power_is_gid_implies_finite_order
%%%}}}

Seja $G$ grupo e $a\in G$.
Se existe $m\in\ints_{\neq 0}$ tal que $a^m = e$, então $\gord a < \infty$.

\hint
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.

\hint
Se $m>0$, tome $n\leteq m$.  Se não?

\solution
Precisamos mostrar que existe $n\in\nats_{>0}$ com $a^n = e$.
Se $m>0$, o conjunto $N \leteq \setst {n\in\nats_{>0}} {a^n = e}$ não é vazio,
então pelo princípio da boa ordem~\indexed[princípio!da boa ordem](PBO)
possui elemento mínimo e logo
$\gord a = \min N < \infty$.
Se $m<0$, observe que $-m > 0$, e calcule:
$$
a^{-m} = \ginvp{a^m} = \ginv e = e,
$$
e novamente
$N\neq\emptyset$ e $\gord a < \infty$.

%%}}}

%%{{{ lm: a_has_exactly_gord_a_powers 
\lemma.
%%%{{{ meta 
\label a_has_exactly_gord_a_powers
%%%}}}

Sejam $G$ grupo e $a\in G$, e suponha $\gord a = n\in\nats$.
Existem exatamente $n$ distintas potências de $a$.

\sketch.
As potências de $a$ são as:
$$
\dotsc, a^{-2}, a^{-1}, a^0, a^1, a^2, \dotsc, a^{n-1}, a^n, a^{n+1}, a^{n+2}, \dotsc
$$
Queremos demonstrar que, no final das contas, nesta lista aparecem exatemente $n$
distintos membros de $G$.  Ou seja,
$$
\card{\setst {a^k} {k\in\ints}} = n.
$$
Consideramos os
$$
a^0, a^1, \dotsc, a^{n-1}
$$
e usando a definição de $\gord a$ demonstramos:
\crtabproofpart {Existência:} os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
\eop\noi
Ou seja: para todo $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$, temos $a^i \neq a^j$.
\crtabproofpart {Unicidade:} para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\eop\noi
Sabemos diretamente pela sua definição que $a^0 = e$, e que $a^n = e$, pois $\gord a = n$.
Com pouca imaginação chegamos na idéia que a cadeia de membros
$$
\alignat{12}
&\dotsc,\ && a^{-2},\ && a^{-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^n,\ && a^{n+1},\ && a^{n+2},\ && \dotsc\\
\intertext{é feita por uma copia de $a^0, \dotsc, a^{n-1}$ se repetindo infinitamente para as duas direções:}
&\dotsc,\ && a^{n-2},\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc,\ && a^{n-1},\ && a^0,\ && a^1,\ && a^2,\ && \dotsc
\endalignat
$$
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref[euclidean_division])
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$.

\proof.
\proofpart {Existência:}
existem $n$ potências de $a$.
\eop\noi
Demonstramos isso mostrando que os $a^0,\dotsc,a^{n-1}$ são distintos dois-a-dois.
Sejam $i,j\in \set{0,\dotsc,n-1}$ com $i\neq j$.
\emph{Sem perda de generalidade}, suponha que $i<j$, ou seja:
$$
0 \leq i < j < n.
$$
Para chegar num absurdo, suponha que $a^i = a^j$.
Assim temos:
$$
\align
\mubrace{aa\dotsb a} i &= \mubrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i<j$, quebramos o lado direito assim:}
\mubrace{aa\dotsb a} i &= \mubrace{\mobrace{aa\dotsb a} i \mobrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref[cheaper_gid].
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.  Como $0 < j-i < n$, isso contradiza a definição
de $n$ como a ordem de $a$:
$n = \gord a$.
Logo $a^i \neq a^j$, que foi o que queremos demonstrar.
\eop\noi
\proofpart {Unicidade:}
os $a^0,\dotsc,a^{n-1}$ são as \emph{únicas} potências de $a$.
Ou seja, para todo $M\in\ints$ o $a^M$ é um dos $a^0,\dotsc,a^{n-1}$.
\eop\noi
Tome $M\in \ints$.
Aplicando a divisão de \Euclid[divisão]Euclides~(\ref[euclidean_division])
no~$M$ por~$n$, ganhamos $q,r\in\ints$ tais que:
$$
M = q\ntimes n + r,\qquad 0 \leq r < n.
$$
Só basta calcular o $a^M$ para verificar que realmente é um dos $a^0, \dotsc, a^{n-1}$:
$$
a^M
= a^{q\ntimes n + r}
= a^{q\ntimes n} a^r
= \paren{a^n}^q a^r
= e^q a^r
= e a^r
= a^r
$$
e como $0\leq r < n$, demonstramos o que queríamos demonstrar.

%%}}}

%%{{{ x: a_has_exactly_gord_a_powers_without_reductio 
\exercise.
%%%{{{ meta 
\label a_has_exactly_gord_a_powers_without_reductio
%%%}}}

Leia a demonstração do~\ref[a_has_exactly_gord_a_powers]
e escreva uma que não usa \emph{reductio ad absurdum}.

\solution
Sejam $i,j \in \set{0,\dotsc,n-1}$ tais que $a^i = a^j$.
Preciso mostrar que $i=j$.
Sem perda de generalidade suponha que $i \leq j$, ou seja:
$$
0 \leq i \leq j < n.
$$
Agora temos
$$
\align
\mubrace{aa\dotsb a} i &= \mubrace{aa\dotsb aaa\dotsb a} j
\intertext{E como $i \leq j$, quebramos o lado direito assim:}
\mubrace{aa\dotsb a} i &= \mubrace{\mobrace{aa\dotsb a} i \mobrace{aa\dotsb a} {j-i}} j
\intertext{Ou seja,}
a^i &= a^i a^{j-i}
\intertext{e logo}
e &= a^{j-i}
\endalign
$$
pelo~\ref[cheaper_gid].
Achamos então uma potência de $a$ igual à identidade $e$:
$a^{j-i} = e$.
Logo $j-i \geq n$ ou $j-i = 0$, pela definição da $\gord a$.
A primeira alternativa é impossível pela escolha dos $i,j$,
e logo concluimos que $j-i=0$, ou seja, $i=j$.

%%}}}

%%{{{ Q: a^m = e => ? ; o(a) = infty => ? 
\question.
%%%{{{ meta 
%%%}}}

Se $a^m = e$ para algum $m\in\ints$, o que podemos concluir sobre o $m$ e a $\gord a$?
Se $\gord a = \infty$, o que podemos concluir sobre todas as potências de $a$?

%%}}}

\spoiler

%%{{{ lm: a_exp_m_is_e_iff_gord_a_divides_m 
\lemma.
%%%{{{ meta 
\label a_exp_m_is_e_iff_gord_a_divides_m
\indexes
    * Euclid : lemma da divisão
    ;;
%%%}}}

Sejam $\sset G \ast$ grupo, $a\in G$, e $m\in\ints$.
Logo
$$
a^m = e \iff \gord a \divides m.
$$

\proof.
\proofpart {\rldir:}
Como $\gord a \divides m$,
temos $m = k\gord a$ para algum $k\in\ints$.
Calculamos:
$$
a^m
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= \gid^k
= \gid.
$$
\proofpart {\lrdir:}
Para demonstrar que $\gord a \divides m$,
aplicamos o~\ref[euclidean_division] da divisão de Euclides,
dividindo o $m$ por $\gord a$, e ganhando assim inteiros $q$ e $r$ tais que
$$
m = \gord a q + r
\qquad
0\leq r < \gord a.
$$
Vamos demonstrar que o resto $r=0$.
Calculamos:
$$
e
= a^m
= a^{\gord a q + r}
= a^{\gord a q} \ast a^r
= \paren{a^{\gord a}}^q \ast a^r
= \gid^q \ast a^r
= \gid \ast a^r
= a^r.
$$
Ou seja, $a^r = \gid$ com $0\leq r < \gord a$,
então pela definição de $\gord a$
como o mínimo inteiro positivo $n$ que satisfaz a $a^n = \gid$,
o $r$ não pode ser positivo.
Logo $r=0$ e $\gord a \divides m$.

%%}}}

%%{{{ lm: infinite_order_of_a_guarantees_all_powers_distinct 
\lemma.
%%%{{{ meta 
\label infinite_order_of_a_guarantees_all_powers_distinct
%%%}}}

Sejam $G$ grupo e $a\in G$.  Se $\gord a = \infty$,
então as potências de $a$ são distintas dois-a-dois.

\sketch.
Precisamos demonstrar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
chegamos em $a^{r-s} = e$; e como a ordem de $a$ é infinita,
temos $r-s=0$ e logo $r=s$.

\proof.
Precisamos demonstrar que para todo $r,s\in\ints$,
$$
a^r = a^s \implies r = s.
$$
Sem perda de generalidade suponhamos $s\leq r$ e usando a hipótese
temos
$$
a^sa^{r-s} = a^s
$$
e logo $a^{r-s} = e$ (\ref[cheaper_gid]).
Agora, como $\gord a = \infty$, usando o contrapositivo
do~\ref[nonzero_power_is_gid_implies_finite_order] obtemos que não existe
nenhum inteiro $m\neq 0$ tal que $a^m=e$.  Logo $r-s = 0$, ou seja $r = s$.

%%}}}

\endsection
%%}}}

%%{{{ Choosing_the_laws 
\section Escolhendo as leis.
%%%{{{ meta 
\label Choosing_the_laws
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Como escolhemos as leis~(G0)--(G3)?
Por que essas?
Por que não botamos a~(GA)?
Por que botamos a~(G3)?
Vamos discutir pouco sobre essas perguntas.

%%}}}

%%{{{ More theorems or more models? 
\note Mais teoremas ou mais modelos?.
%%%{{{ meta 
%%%}}}

Óbvio que adicionando mais leis na definição de grupo,
a gente poderia demonstrar mais teoremas.
Mas o que ganhamos em teoremas, perdemos em generalidade
da nossa teoria: menos coisas vão acabar sendo \dterm{modelos}
dos nossos axiomas, e logo esse bocado de teoremas que
vamos conseguir demonstrar não poderá ser aproveitado
em muitos contextos diferentes.
Adicionando a~(GA) nos axiomas de grupo por exemplo,
os $\sym n$ iam parar de ser grupos, e não teriamos
nenhum teorema ``de graça'' pra eles.
Como eu afirmei na introdução desse capítulo,
a escolha~(G0)--(G3) tem um equilibrio muito bom entre
riquesa da teoria e diversidade de modelos.
Faz sentido tirar o~(G3)?
Claro que sim; chegamos numa estrutura com mais modelos
(e menos teoremas), que com certeza vale a pena estudar.
O nome dessa estrutura é \dterm{monóide}, que estudamos
no~\reftag[Algebraic_structures].

%%}}}

%%{{{ Avoid redundancies 
\note Evite redundâncias.
%%%{{{ meta 
%%%}}}

Vamos dizer que estamos escolhendo as leis para a definição de grupo.
Já escolhemos as~(G0)--(G3), mas queremos que em cada grupo seja
possível cancelar pela esquerda~(GCL) e pela direita~(GCR).
Mesmo assim, não faz sentido adiconar as~(GCL)--(GCR) como leis,
pois como a gente descobriu no~\ref[cancellation_laws_in_group],
ambas são \emph{teoremas} da teoria dos~(G0)--(G3).
Similarmente, escolhemos os axiomas~(G2) e~(G3) que garantam
a existência \emph{duma} identidade e para cada membro \emph{dum}
inverso, em vez de botar como leis as proposições mais fortes
que afirmam as \emph{unicidades} deles também.
Por quê?
A resposta é parecida: se for possível, preferimos limitar
nossos axiomas nas versões mais fracas possíveis para elaborar
nossa teoria.
Nesse caso, a gente também descobriu que mesmo com os~(G2)--(G3)
as unicidades são garantidas na nossa teoria, agora como
\emph{teoremas}~(\reftag[uniqueness_of_identity_in_group]
e~\reftag[uniqueness_of_inverses_in_group]).

%%}}}

%%{{{ Clarity and intuitiveness 
\note Clareza e intuitividade \vs mão-de-vaca.
%%%{{{ meta 
\label clarity_and_intuitiveness
\credits
    * Kunen
    ;;
%%%}}}

Por outro lado, optamos para botar as leis~(G2)--(G3),
em vez do par mais fraco~(G2L)--(G3L),
ou do~(G2R)--(G3R), que como tu sabes---ou como tu
vai descobrir quando finalmente resolver
o~\ref[onesided_group_def_proof]---qualquer
um par poderia substituir o par~(G2)--(G3), sem
afetar a teoria pois os~(G2)--(G3) viram teoremas
nesse caso~(\ref[onesided_group_def]).
Por que não escolher como axiomas dos grupos os
(G0),(G1),(G2L),(G3L) então?
Aqui é mais difícil justificar essa escolha.
Queremos achar um \emph{equilíbrio} entre a
economia, fraqueza, e quantidade dos axiomas num
lado; e a clareza e intuitividade no outro.
Não queremos exagerar nem no lado de clareza
(sendo redundantes), nem no lado de economia
(sendo mão-de-vaca).
Escolhendo as~(G2L)--(G3L) como axiomas, daria
um toque assimétrico na definição do que é um grupo.
Pelas leis apareceria (erroneamente) que a operação
dum grupo trata seus dois lados em maneiras diferentes,
prejudicando ou favorecendo um em comparação com o outro.
Botamos então como leis as~(G2)--(G3) e demonstramos
como \emph{critérion}~(\reftag[onesided_group_def]) que
assim que os~(G0),(G1),(G2L),(G3L) são satisfeitos,
temos um grupo (e similarmente para os~(G2R)--(G3R)).
Nossas leis escolhidas ((G0)--(G3)) estão falando
claramente para nosso coração.  Cada um é simples;
descreve uma propriedade simples e significante.
Imagine se alguém definir que o
$\sset G {\ast, \ginv{}, \gid}$ é um \dterm{grupo}
sse
satisfaz uma lei única e bizarra, como a
$$
\lforall
{a,b,c \in G}
{\paren{\ginvp{c \ast \ginvp{a \ast b}} \ast (c \ast \ginv b)} \ast \ginvp{\ginv b \ast b} = a}.
\tag{GKUN}
$$
Dá pra entender no teu coração qualquer coisa sobre
o $G$ e sua alma?
Dá pra entender, olhando para essa lei única,
se tem alguma operação associativa com identidade
e inversos por aí?
Por incrível que pareça, eu nem tô brincando sobre
a lei (GKUN).  Realmente, Kunen construiu o
(GKUN) e demonstrou que a teoria do (GKUN) sozinho
e a mesma da teoria dos (G1)+(G2)+(G3)
(veja~\cite[kunensinglegroup])!
Ou seja:
$$
\text{$\ssetfont G$ satisfaz a (GKUN)}
\wowiff
\text{$\ssetfont G$ é grupo}.
$$
Considerei aqui a (G0) como automaticamente garantida
(e logo redundante) pelo fato de ter uma operação (total)
na minha estrutura.
A volta é muito fácil, e tu demonstrarás agora
no~\ref[group_implies_kunen]; deixo o converso para
o~\ref[kunen_implies_group].

%%}}}

\TODO Clarificar single axioms; elaborar e mostrar mais.

%%{{{ x: group_implies_kunen 
\exercise.
%%%{{{ meta 
\label group_implies_kunen
%%%}}}

Demonstre a {\rldir}.

\hint
Sejam $a,b,c \in G$.
Calcule:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&\eqvdots \\
&= a
\endcompute

\solution
Sejam $a,b,c \in G$.
Calculamos:
\compute
\paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \ginvp{\ginv b b}
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b \ginvp{\ginv b}) \obvious \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} (\ginv b b) \\
&= \paren{\ginvp{c \ginvp{a b}} (c \ginv b)} \gid \\
&= \ginvp{c \ginvp{a b}} (c \ginv b) \\
&= \paren{\ginvp{\ginvp{a b}} \ginv c} (c \ginv b) \\
&= \paren{(a b) \ginv c} (c \ginv b) \\
&= (a b) (\ginv c c) \ginv b \\
&= (a b) e \ginv b \\
&= (a b) \ginv b \\
&= a (b \ginv b) \\
&= a e \\
&= a.
\endcompute

%%}}}

%%{{{ Modularity 
\note Modularidade.
%%%{{{ meta 
%%%}}}

Também é bom ter \emph{modularidade} entre nossos
axiomas, em tal forma que facilita tirar um, botar
outro, e chegar numa teoria diferente mas
interessante também.
Continuando no mesmo exemplo da definição unilateral
de grupos, suponha que tiramos o~(G3L), que é
nosso axioma de L-inversos.
Onde chegamos?
Numa estrutura verdadeiramente L-lateral---esquisito!

%%}}}

%%{{{ proving_the_unprovability 
\note Demonstrando a indemonstabilidade.
%%%{{{ meta 
\label proving_the_unprovability
%%%}}}

Alguém poderia pensar (ra\-zo\-avel\-mente) que a inclusão
do~(G3) nos axiomas de grupos foi desnecessária.
A gente deveria derivá-lo como conseqüência do resto dos axiomas,
na mesma maneira que demonstramos tantas outras proposições.
Aceitando o desafio começamos pensar para achar uma
demonstração do~(G3) a partir dos~(G0)--(G2).
E o tempo passa, passa, e passa\dots
\eop
E não conseguimos demonstrar.
\emph{Isso não quis dizer que o~(G3) é indemonstrável!}
Talvez amanha a gente terá uma idéia nova e conseguir demonstrá-lo;
ou talvez amanhã um rapaz mais esperto vai achar uma demonstração.
Mas, nesse caso, não vai não.
Pois podemos \emph{demonstrar} que o~(G3) é realmente
\emph{indemonstrável} pelos~(G0)--(G2).

%%}}}

%%{{{ proving_the_unprovability_method 
\exercise.
%%%{{{ meta 
\label proving_the_unprovability_method
%%%}}}

Como?
O que seria um argumento convencente sobre isso?
E em geral, como podemos demonstrar
a indemonstrabilidade duma proposição $\psi$
a partir dumas proposições $\phi_1,\dots,\phi_n$?
Depois de deixar claro tua estratégia demonstre
que realmente:
\tlist:
\li: a (GA) não é uma conseqüência das (G0)--(G3);
\li: a (G3) não é uma conseqüência das (G0)--(G2);
\li: a (G2) não é uma conseqüência das (G0)--(G1);
\li: a (G1) não é uma conseqüência da  (G0).
\endtlist

\hint
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
Qual modelo tu escolheria para cada uma delas?

\hint
Para a~(GA) basta achar um grupo que não
seja abeliano;
para a~(G3) basta achar um \dterm{monóide}
(ou seja, algo que satisfaz as~(G0)--(G2))
que não é um grupo;
para a~(G2) basta achar um \dterm{semigrupo}
(ou seja, algo que satisfaz as~(G0)--(G1))
que não é um monóide;
para a~(G1) basta achar um \dterm{magma}
(ou seja, algo que satisfaz a~(G0))
que não é um semigrupo.

\solution
Basta achar um \emph{modelo} (ou seja, algo que
satisfaz as leis) que não satisfaz a proposição
que queremos mostrar sua indemonstrabilidade.
\crproofpart {Para a~(GA)}
tome o $\sym 3$, que é grupo mas não abeliano
($\phi\psi\neq\psi\phi$).
\crproofpart {Para a~(G3)}
tome o $S$ do~\ref[strings_with_concat_is_not_a_group]
que ja verificámos que não satisfaz a~(G3), e que
tu já demonstrou~(\ref[verify_all_group_laws_for_strings])
que ele goza das outras:~(G0)--(G2).
\crproofpart {Para a~(G2)}
considere um conjunto $A = \set{a,b}$ com operação $\ast$
a $\outl$:
$$
x \ast y = x.
$$
Facilmente o $\sset A \ast$ satisfaz as (G0)--(G1) mas
não possui identidade.
\crproofpart {Para a~(G1)}
tome o $\nats$ com a exponenciação: o conjunto obviamente
é fechado, mas a operação não é associativa:
$$
2^(1^2) \neq (2^1)^2.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Não se preocupe demais com essas questões; com mais experiência
e maturidade tu vai reconhecer e apreciar os motivos dessas escolhas,
e tu elaborarás teu próprio gosto, instinto, e talento, para escolher
axiomas.
Mas chega!
Voltamos a estudar a teoria dos grupos agora.

%%}}}

\endsection
%%}}}

%%{{{ Group_conjugation 
\section Conjugação de grupo.
%%%{{{ meta 
\label Group_conjugation
%%%}}}

%%{{{ df: conjugates_of_group_element 
\definition Conjugados.
%%%{{{ meta 
\label conjugates_of_group_element
\defines
    * conjugado!de elemento de grupo
    ;;
%%%}}}

Seja $G$ grupo e $a\in G$.
Para qualquer $g\in G$, o $ga\ginv g$ é chamado
um \dterm{conjugado} de $a$.

%%}}}

%%{{{ df: conjugation_of_group 
\definition conjugação.
%%%{{{ meta 
\indexes
    * relação!conjugação    see: conjugação
    ;;
\defines
    * ~a \gconjrel ~b  -- conjugação de grupo
    * conjugação!de grupo
    ;;
%%%}}}

Seja $G$ um grupo.
A \dterm{conjugação do $G$}
é a relação ${\gconjrel} : \reltype{G,G}$ definida pela
$$
\align
a \gconjrel b
&\defiff \text{$a$ é um conjugado de $b$}\\
&\intiff \lexists {g\in G} {a = gb\ginv g}.
\endalign
$$

%%}}}

%%{{{ x: gconjrel_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label gconjrel_is_an_eqrel
%%%}}}

Seja $G$ grupo.  A conjugação $\gconjrel$ do $G$
é uma relação de equivalência.

\solution
\proofpart {Reflexividade:}
Seja $a \in G$.
Procuramos $g\in G$ tal que $a = ga\ginv g$.
Como $a = e a \ginv e$, temos que realmente $a \gconjrel a$.
\eop
\proofpart {Simetria:}
Sejam $a,b \in G$ tais que $a \gconjrel b$.
Daí, seja $x\in G$ tal que $a = xb\ginv x$.
Operando pela esquerda com $\ginv x$ e pela direita com $x$, temos:
$$
\ginv x a x = \ginv x x b \ginv x x = b.
$$
Mas $x = \ginvp {\ginv x}$, ou seja
$b = \ginv x a \ginvp{\ginv x}$
e logo $b \gconjrel a$.
\eop
\proofpart {Transitividade:}
Sejam $a,b,c \in G$ tais que $a \gconjrel b$ e $b \gconjrel c$.
Daí, sejam $x,y \in G$ tais que:
\compute
a &= x b \ginv x \\
b &= y c \ginv y.
\intertext{Substituindo a segunda na primeira, temos}
a &= x \paren{ y c \ginv y } \ginv x                \\
  &= \paren{ xy } c \paren{ \ginv y \ginv x} \by {ass.} \\
  &= \paren{ xy } c \ginvp{ xy }.            \by {inverso de produto (\reftag[inverse_of_product_in_group])} \\
\endcompute
Ou seja, $a \gconjrel c$.

%%}}}

%%{{{ df: conjugacy_class 
\definition Classe de conjugação.
%%%{{{ meta 
\label conjugacy_class
\defines
    * \gcl {~a}  -- a classe de conjugação de $a$
    * classe de conjugação
    ;;
%%%}}}

Seja $G$ grupo e $a\in G$.
A \dterm{classe de conjugação} de $a$ é o conjunto
$$
\gcl a \defeq \setst {ga\ginv g} {g \in G},
$$
ou seja, $\gcl a$ é a classe de equivalência do $a$
através da relação <<é um conjugado de>>.

%%}}}

%%{{{ x: conjugacy_class_of_e 
\exercise.
%%%{{{ meta 
\label conjugacy_class_of_e
%%%}}}

Seja $G$ grupo.
Calcule a $\gcl e$.

\hint
$\gcl e = \set{e}$.
Por quê?

%%}}}

%%{{{ x: conjugacy_classes_of_S3 
\exercise.
%%%{{{ meta 
\label conjugacy_classes_of_S3
%%%}}}

Ache todas as classes de conjugação de $\sym 3$.

\hint
Já achou uma no \ref[conjugacy_class_of_e].

%%}}}

%%{{{ df: conjugator 
\definition conjugadores.
%%%{{{ meta 
\label conjugator
\defines
    * \gconj {~g}  -- o $g$-conjugador
    * conjugador
    ;;
%%%}}}

Seja $G$ grupo e $g\in G$.
Definimos a função $\gconj g : G \to G$ pela
$$
\gconj g x = gx\ginv g.
$$
Chamamos a $\gconj g$ de \dterm{$g$-conjugador}.
Observe que o conjugador $\gconj g$ é um ator:
$\actorS g {\ginv g}$.

%%}}}

%%{{{ x: conjugators_respect_powers 
\exercise.
%%%{{{ meta 
\label conjugators_respect_powers
%%%}}}

Sejam $G$ grupo e $g,a\in G$.
Para todo $n\in\ints$,
$\paren{ga\ginv g}^n = g a^n \ginv g$.
Em outras palavras, a conjugação por membro respeita as potências:
$$
\gconj g (a^n) = \paren{\gconj g a}^n
$$
para todo $n\in\ints$.

\hint
Indução para os inteiros não-negativos.
E os negativos?

\solution
Demonstramos primeiramente por indução que para todo $n \in \nats$,
$\paren{ga\ginv g}^n = g a^n \ginv g$.
Observe que
$$
\align
(ga\ginv g)^0 &= e \\
g a^0 \ginv g &= g e \ginv g = g \ginv g = e.
\endalign
$$
Agora seja $k\in\nats$ tal que
$$
(ga\ginv g)^k = g a^k \ginv g. \tag{H.I.}
$$
Calculamos
\compute
(ga\ginv g)^{k+1}
&= (ga\ginv g)^k (ga\ginv g) \\
&= (ga^k\ginv g) (ga\ginv g) \by {pela H.I.} \\
&= ga^k(\ginv g g)a\ginv g \\
&= ga^ka\ginv g \\
&= ga^{k+1}\ginv g.
\endcompute
Para terminar a demonstração basta observar que para qualquer $n \in \nats$ temos:
\compute
\paren{ga\ginv g}^n = g a^n \ginv g
& \implies \ginvp{\paren{ga\ginv g}^n} = \ginvp{g a^n \ginv g} \\
& \implies \paren{ga\ginv g}^{-n} = \ginvp{\ginv g} \ginvp{a^n} \ginv g \\
& \implies \paren{ga\ginv g}^{-n} = g a^{-n} \ginv g.
\endcompute

%%}}}

%%{{{ x: exponentiation_respects_conjugation 
\exercise.
%%%{{{ meta 
\label exponentiation_respects_conjugation
%%%}}}

Se $x,y$ são conjugados, então para todo $n$ inteiro,
$x^n$ e $y^n$ também são.

\hint
Lembre o~\ref[conjugators_respect_powers].

\solution
Isso é um corolário imediato
do~\ref[conjugators_respect_powers]:
Como $x,y$ conjugados, temos $x = gy\ginv g$ para algum $g\in G$.
E agora calculamos:
\compute
x^n
&= \paren{gy\ginv g}^n \\
&= gy^n\ginv g.  \by {pelo \reftag[conjugators_respect_powers]} \\
\endcompute
e logo $x^n,y^n$ conjugados também.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

A idéia de conjugação deve aparecer meio aleatória
pra ti neste momento, mas não tanto como logo depois
da definição (agora pelo menos tu já demonstrou
muitas propriedades interessantes).
Logo vamos descobrir que os subgrupos que são
\emph{fechados pela conjugação} (ou \emph{fechados pelos conjugados}\/)
são muito interessantes.  Paciência.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: group_actors_are_bijective_proof 
\problem.
%%%{{{ meta 
\label group_actors_are_bijective_proof
%%%}}}

Sejam $G$ grupo e $a,b\in G$.
Definimos as funções $f,g,h : G \to G$ pelas
$$
\xalignat3
f(x) &= ax  &
g(x) &= xa  &
h(x) &= axb.
\endxalignat
$$
Demonstre que as $f,g,h$ são bijecções e ache suas inversas.

\solution
\proofpart {Injectividade:}
$$
f(x) = f(y)
\implies ax = ay
\implies x = y.
$$
\proofpart {Sobrejectividade:}
Seja $y \in G$.
Considere o $\ginv a y \in G$.
Observe que
$$
f(\ginv a y)
= a (\ginv a y)
= (a \ginv a) y
= y.
$$
A $\finv f$ é definida pela:
$$
\finv f (y) = \ginv a y
$$
pois, de fato, $f(\ginv a y) = a \ginv a y = y$.
Similar para a $g$.
Sobre a $h$, observe que $h = g\of f$ e logo ela é bijetora
como composição de bijetoras, e sua inversa é dada
pela~\ref[finv_of_fcompose].

%%}}}

%%{{{ prob: how_come_the_cancellation_laws_hold_in_nongroup_without_inverses 
\problem.
%%%{{{ meta 
\label how_come_the_cancellation_laws_hold_in_nongroup_without_inverses
%%%}}}

Na~\ref[First_consequences_of_group_laws] demonstramos que as leis de cancelamento
implicam a existência de únicos inversos.
Lembre-se que o $\sset {\nats} {+}$ não é um grupo pois não satisfaz a (G3).
Mesmo assim, no $\sset {\nats} {+}$ ambas as leis de cancelamento são válidas.
Então, isso implica a existência de inversos únicos!
Qual o erro aqui?

\hint
O que precisamos na demonstração do fato que as leis de cancelamento implicam
a existência de inversos únicos?

\solution
Na demonstração do fato que as leis de cancelamento implicam a existência
de inversos únicos, \emph{usamos} a (G3) que garanta a existência,
e demonstramos a unicidade.  No caso do $\sset {\nats} {+}$ não temos a
(G3) (existência de inversos).  Então nossa demonstração nesse caso mostra
que cada membro de $\sset {\nats} +$ tem \emph{no máximo} um inverso,
algo que realmente é verdade: o $0$ tem exatamente um, e nenhum dos
outros tem.

%%}}}

%%{{{ prob: bust_proof_of_uniqueness_of_identity_in_group 
\problem.
%%%{{{ meta 
\label bust_proof_of_uniqueness_of_identity_in_group
%%%}}}

Considere essa suposta demonstração da unicidade da identidade~(\ref[uniqueness_of_identity_in_group]):
\quote
\indent<<Seja $G$ grupo e suponha que temos identidades $e_1,e_2 \in G$.
Seja $a\in G$.
Como $e_1$ é identidade, temos $a \ast \ginv a = e_1$\fact1.
Como $e_2$ é identidade, também temos $a \ast \ginv a = e_2$\fact2.
Pelas \byfact1~e~\byfact2, como os lados esquerdos são iguais,
o lados direitos também são.
Ou seja, $e_1 = e_2$ que foi o que queremos demonstrar.>>
\endquote
Identifique todos os erros nessa tentativa de demonstração.

%}}}

%%{{{ prob: onesided_group_def_proof 
\problem leis unilaterais de grupo.
%%%{{{ meta 
\label onesided_group_def_proof
%%%}}}

Demonstre o~\ref[onesided_group_def].
Cuidado: lembre-se o~\ref[onesided_group_def_catch].

\hint
Para diminuir as chances de ``roubar'' sem querer,
use uma notação adaptada às novas leis:
chame $\idr$ a identidade-direita grantida pela (G2R)
e use $\invr a$ para o inverso-direito de $a$, garantido pela (G3R);
similarmente use $\idl$ e $\invl a$ para a identidade-esquerda
e os inversos-esquerdos, garantidos pelas (G2L) e (G3L).

\hint
Precisas mostrar as (G2)--(G3).
Ou seja, verificar que o $\idr$ é uma identidade-esquerda,
\mathcol
\cforall {a\in G} {\idr a = a}             \tag{G2'} \\
\intertext{e que para todo $a\in G$,
seu inverso direito $\invr a$ é um inverso esquerdo também:}
\cforall {a\in G} {\invr a \ast a = \idr}. \tag{G3'} \\
\endmathcol

\hint
Para demonstrar a (G2') tome um $a\in G$ e comece com:
\compute
\idr \go a
&= (\idr \go a) \go \idr \\
&= \idr \go (a \go \idr) \\
&= \idr \go (a \go (\; \alert? \go \invr{\alert?}\;)) \by {qual membro de $G$ serve aqui?} \\
&\eqvdots \\
&= a
\endcompute
Para a (G3'), o lemma seguinte pode ajudar:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
Use isso para demonstrar que um inverso direito é esquerdo também.

\hint
Para a (G2'), qual produto podes botar no lugar do $(\;?\;)$ da dica anterior?
Sabendo que (G2R) é válida, faz sentido substituí-lo com um termo
$\paren{x \invr x}$ para algum $x\in G$, mas qual seria esse $x$?
\emph{Não precisamos adivinhar ainda!}
Continue assim com um $x$ não-especificado por enquanto,
e logo tu vai chegar numa expressão que vai te ajudar escolher teu $x$ para
continuar, pois tu vai querer que esse $x$ ``anula'' a coisa que aparecerá
na sua esquerda.
\eop
Para a (G3'), teu objectivo é demonstrar que dado qualquer $a \in G$,
$\invr a a = \idr$; e o Lemma te oferece um critério para
decidir que algo é o $\idr$.  Use!

\solution
Vamos demonstrar em detalhe o critério unilateral direito.
A demonstração do esquerdo é simétricamente análoga.
\proofpart {Demonstração da (G2').}
Preciso demonstrar que a identidade direita $\idr$
é uma identidade esquerda.  Seja $a \in G$.
Basta verificar que $\idr a \askeq a$.
Calculamos:
\compute
\idr a
&= \idr a \idr                       \by {def.~$\idr$} \\
&= \idr a (\invr a \invr {\invr a})  \by {def.~$\invr {\invr a}$} \\
&= \idr (a \invr a) \invr {\invr a}  \\
&= \idr \idr \invr {\invr a}         \by {def.~$\invr a$} \\
&= (\idr \idr) \invr {\invr a}       \\
&= \idr \invr {\invr a}              \by {def.~$\idr$} \\
&= (a \invr a) \invr {\invr a}       \by {def.~$\invr a$} \\
&= a (\invr a \invr {\invr a})       \\
&= a \idr                            \by {def.~$\invr {\invr a}$} \\
&= a.                                \by {def.~$\idr$} \\
\endcompute
onde botei parenteses apenas para ajudar a leitura;
seu uso sendo opcional graças a (G1).
\eop
Para demonstrar o (G3'), eu vou usar o Lemma:
$$
\lforall {g \in G} {gg = g \implies g = \idr}.
$$
\proofpart {Demonstração do Lemma.}
Seja $g\in G$.  Temos
\compute
gg = g
&\implies (gg)\invr g = g \invr g  \by {$(\go g)$} \\
&\implies g(g\invr g) = \idr       \by {(G1); def.~$\invr g$} \\
&\implies g \idr = \idr            \by {def.~$\invr g$} \\
&\implies g = \idr                 \by {def.~$\idr$} \\
\endcompute
\proofpart {Demonstração da (G3').}
Vou demonstrar que para todo $a \in G$, o $\invr a$ é um inverso
esquerdo do $a$.  Seja $a \in G$ então; preciso mostrar que
$\invr a a \askeq \invr \gid$.
Verificamos que $(\invr a a)(\invr a a) = (\invr a a)$:
\compute
(\invr a a)(\invr a a)
&= \invr a (a\invr a) a  \by {(G1)} \\
&= \invr a (\idr) a      \by {def.~$\invr a$} \\
&= (\invr a \idr) a      \by {(G1)} \\
&= \invr a a.            \by {def.~$\idr$} \\
\endcompute
e logo pelo Lemma concluimos que $(\invr a a) = \idr$.

%%}}}

%%{{{ prob: cancellation_based_group_def_proof 
\problem.
%%%{{{ meta 
\label cancellation_based_group_def_proof
%%%}}}

Demonstre o~\ref[cancellation_based_group_def].

\hint
Como podemos usar o fato que um conjunto é finito?

\hint
O $G$ é finito, logo sejam $G \eqass \set{a_1, \dotsc, a_n}$.

\hint
Seja $g \in G = \set{a_1, \dotsc, a_n}$.
Considere o $Ga \defeq \setst {ga} {a \in G} = \set{ga_1, \dotsc, ga_n}$.
E agora?

%%}}}

%%{{{ prob: cancellation_based_group_def_both_cancellations 
\problem.
%%%{{{ meta 
\label cancellation_based_group_def_both_cancellations
%%%}}}

Podemos apagar um dos (GCL), (GCR) das hipoteses do~\ref[cancellation_based_group_def]?

\hint
Não.
Como podemos demonstrar isso?

\hint
Basta achar um contraexemplo: um conjunto estruturado $\sset G \ast$
tal que $G$ é finito e satisfaz as (G0),(G1),(GCL) mas mesmo assim
não é um grupo; isso mostraria que não podemos apagar o (GCR).
Similarmente para o (GCL).

%%}}}

%%{{{ prob: conjugates_have_the_same_order 
\problem.
%%%{{{ meta 
\label conjugates_have_the_same_order
%%%}}}

Membros da mesma classe de conjugação tem a mesma ordem.

\hint
Separe os casos em $\gord a = n \in\nats$ e $\gord a = \infty$.

\hint
Lembre o~\ref[exponentiation_respects_conjugation]
e o~\ref[conjugacy_class_of_e].

\solution
Sejam $a,b$ conjugados.
\crproofcase {Caso que $\gord a < \infty$.}
\crproofpart {Resolução 1.}
Preciso mostrar:
(i) $b^n = e$;
(ii) para todo $m$ com $0<m<n$, $b^m \neq e$.
\eop
(i) Pelo~\ref[exponentiation_respects_conjugation],
temos que $a^n$ e $b^n$ são conjugados,
mas $a^n = e$, e a classe de conjugação de $e$ é o singleton $\set{e}$
(\ref[conjugacy_class_of_e]).
Logo $b^n = e$.
\eop
(ii) Pela mesma observação cada suposto $b^m = e$
obrigaria $a^m = e$ também.
Logo $\gord b = n$.
\crproofpart {Resolução 2.}
Pelo~\ref[exponentiation_respects_conjugation]
temos $a^{\gord a}$ conjugado com $b^{\gord a}$.
Logo $b^{\gord a} = e$ e logo $\gord b \divides \gord a$.
Similarmente $\gord a \divides \gord b$ e logo $\gord a = \gord b$
pois ambos são naturais.
\crproofcase {Caso que $\gord a = \infty$.}
Tenho que para todo $n > 0$, $a^n \neq e$,
e preciso mostrar a mesma coisa sobe os $b^n$.
De novo, de qualquer suposto contraexemplo $m\in \nats$ com $b^m = e$
concluimos $a^m = e$ que é absurdo pois $\gord a = \infty$.
\eop
Para uma resolução mais poderosa e simples,
veja o~\ref[conjugates_look_alike].

%%}}}

%%{{{ prob: G abelian iff something with conjugates 
\problem.
%%%{{{ meta 
%%%}}}

Ache uma propriedade interessante que tem a ver com conjugados,
tal que para todo grupo $G$,
$$
\text{$G$ abeliano} \iff \text{essa propriedade}.
$$
Demonstre tua afirmação!

\hint
Num grupo abeliano, o que podes afirmar se $a \gconjrel b$?
(A próxima dica já tem a resposta, depois disso vai faltar
só demonstrá-la.)

\hint
$$
\text{$G$ abeliano} \iff (\gconjrel) = (\eqof G)
$$
Demonstre!

%%}}}

%%{{{ prob: Futurama 
\problem Futurama.
%%%{{{ meta 
\label Futurama
\indexes
    * Futurama
    ;;
\defines
    * teorema!Futurama
    ;;
\credits
    * Keeler
    ;;
%%%}}}

No episódio <<The prisoner of Benda>> do seriado \emph{Futurama},
a galera resolve seu problema usando teoria dos grupos!
um teorema ficou enunciado e demonstrado por Keeler,
o escritor desse episódio, e foi a primeira (e provavelmente única)
vez que um teorema matemático foi publicado num seriado!
o teorema ficou conhecido como o \emph{Futurama theorem}.
Assista o episódio, entenda o enunciado do teorema, e demonstre!

%%}}}

%%{{{ prob: kunen_implies_group 
\problem.
%%%{{{ meta 
\label kunen_implies_group
%%%}}}

\TODO Escrever.

%%}}}

\endproblems
%%}}}

%%{{{ Subgroups 
\section Subgrupos.
%%%{{{ meta 
%%%}}}

%%{{{ df: subgroup 
\definition Subgrupo.
%%%{{{ meta 
\label subgroup
\defines
    * ~H \subgroup ~G  -- $H$ é um subgrupo de $G$
    * subgrupo!trivial
    * subgrupo
    ;;
%%%}}}

Seja $\sset G {\ast,e}$ grupo.
Um subconjunto $H\subset G$ é um \dterm{subgrupo} de $G$ sse
$H$ é um grupo com a mesma operação $\ast$.
Escrevemos $H \subgroup G$.
Chamamos os $\set e$ e $G$ \dterm{subgrupos triviais} de $G$.

%%}}}

%%{{{ remark: is it really the same op really? 
\remark A mesma mesmo?.
%%%{{{ meta 
%%%}}}

Na~\ref[subgroup] falamos que $H$ é um grupo com \emph{a mesma operação} $\ast$.
Literalmente as duas operações são diferentes, pois seus domínios são diferentes.
O que entendemos com essa frase aqui é que o conjunto $H$ é um grupo com operação
\emph{a restricção da $\ast$ no $H\times H$}.
Com símbolos, $\sset H {\resfunsub \ast {H\times H}}$ é um grupo.
(Lembre-se a~\ref[fresto].)

%%}}}

%%{{{ x: singleton_e_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label singleton_e_is_a_subgroup
%%%}}}

Verifique que para todo grupo $\sset G {\ast,e}$, temos $\set e \subgroup G$.

%%}}}

%%{{{ eg: Numbers 
\example Números reais.
%%%{{{ meta 
%%%}}}

(1) Considere o grupo $\sset \reals {+}$.
Observe que $\rats$ e $\ints$ são subgrupos dele, mas $\nats$ não é.
\eop\noi
(2) Considere o grupo $\sset {\reals_{\neq0}} {\ntimes}$.
Observe que $\set{1, -1}$, $\rats_{\neq0}$, e para qualquer
$\alpha\in\reals_{\neq0}$ o conjunto $\setst {\alpha^k} {k\in\ints}$ são todos
subgrupos dele, mas $\ints$ e $\setst {\alpha^n} {n\in\nats}$ não são.

%%}}}

%%{{{ x: rationals 
\exercise.
%%%{{{ meta 
%%%}}}

Considere o grupo $\ssetfont Q \leteq \sset {\rats\setminus\set0} {\ntimes}$
e seus subconjuntos:
$$
\align
Q_1 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ e $q$ ímpares} }\\
Q_2 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ ímpar, $q$ par} }\\
Q_3 &\leteq \setst { p/q } { p, q \in \ints,\ \text{$p$ par, $q$ ímpar} }.
\endalign
$$
Para quais dos $i=1,2,3$ temos $Q_i \subgroup \ssetfont Q$?

%%}}}

%%{{{ property: empty_is_never_a_subgroup 
\property.
%%%{{{ meta 
\label empty_is_never_a_subgroup
%%%}}}

$H\subgroup G \implies H \neq\emptyset$.

\proof.
Como $H$ é um grupo, necessariamente $e\in H$.

%%}}}

%%{{{ x: some_subgroups_of_additive_ints 
\exercise.
%%%{{{ meta 
\label some_subgroups_of_additive_ints
\defines
    * ~m \ints  -- o conjunto de todos os múltiplos do $m$
    ;;
%%%}}}

Demonstre que para todo $m\in\ints$, $m\ints \subgroup \sset \ints +$,
onde $m\ints \defeq \setst {mk} {k \in \ints}$.

%%}}}

%%{{{ x: some_nontrivial_subgroups_of_multiplicative_reals 
\exercise.
%%%{{{ meta 
\label some_nontrivial_subgroups_of_multiplicative_reals
%%%}}}

Ache uns subgrupos não-triviais do
$\sset {\reals\setminus\set0} {\ntimes}$.

%%}}}

%%{{{ remark: ass_for_free_in_subgroup
\remark Associatividade de graça.
%%%{{{ meta 
\label ass_for_free_in_subgroup
%%%}}}

Seja $\sset G \ast$ grupo, e tome um $H\subset G$.
Para ver se $H \subgroup G$, seguindo a definição,
precisamos verificar as (G0)--(G3) no $\sset H \ast$.
Mas a lei~(G1) da associatividade não tem como ser violada no $\sset H \ast$.
O que significaria violar essa lei?
$$
\text{Teriamos $a,b,c \in H$, tais que $a\ast (b\ast c) \neq (a \ast b) \ast c$.}
$$
Mas como $H \subset G$, nos teriamos o mesmo contraexemplo para a (G1) de $G$,
impossível pois $G$ é um grupo mesmo (e a operação é a mesma).
Logo, jamais precisaramos verificar a~(G1) para um possível subgrupo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E isso não é o único ``desconto'' que temos quando queremos demonstrar
que~$H \subgroup G$.  Vamos ver mais dois critéria agora:

%%}}}

%%{{{ criterion: nonempty_subgroup_criterion 
\criterion Subgrupo.
%%%{{{ meta 
\label nonempty_subgroup_criterion
%%%}}}

Se $H$ é um subconjunto não vazio do grupo $\sset G {\ast,e}$, então:
$$
\rightbrace {
\alignedat3
\textrm{(0)} & \quad &                      & \emptyset \neq H \subset G          &\qquad &\textrm{($H$ é n\~ao vazio)}\\
\textrm{(1)} & \quad & \cforall {a,b \in G}  {a, b \in H \implies a\ast b \in H}  &\qquad &\textrm{($H$ é $\ast$-fechado)}\\
\textrm{(2)} & \quad & \cforall {a \in G}    {a \in H    \implies \ginv a \in H}  &\qquad &\textrm{($H$ é $^{-1}$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$

\sketch.
Observamos que a associatividade é garantida pelo fato que $G$ é grupo,
então basta demonstrar que $e\in H$.
Por isso, usamos a hipótese $H\neq\emptyset$ para tomar um $a\in H$
e usando nossas (poucas) hipoteses concluimos que $e\in H$ também.

\proof.
Precisamos verificar as leis (G0)--(G3) para o $\sset H {\ast}$.
Os (1) e (2) garantam as (G0) e (G3) respectivamente,
e o fato que $G$ é grupo garanta a (G1) também.
Basta verificar a (G2), ou seja, que $e\in H$:
\proofsteps
\steptby {Tome $a\in H$.}              {$H\neq\emptyset$\,}
\steptby {Logo $\ginv a \in H$.}       {pela (ii)}
\steptby {Logo $a\ast \ginv a \in H$.} {pela (i)}
\steptby {Logo $e \in H$.}             {def.~$\ginv a$}
\endproofsteps

%%}}}

%%{{{ The skeleton of the proof 
\note O esqueleto dessa demonstração.
%%%{{{ meta 
%%%}}}

Vamos lembrar o tema de árvores, escrevendo a demonstração
do~\ref[nonempty_subgroup_criterion] assim:
$$
\PROOFm {
\A    {h\in H}
\I1-------------- {\phantom{$H$ $\ginv{}$-fechado}}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {\phantom{$H$ $\ast$-fechado}}
           {\ginv h h \in H}
    \I1-------------------------- {\phantom{def.~$\ginv h$}}
               {e \in H}
}
$$
Quais são as justificações de cada linha de inferência?
$$
\PROOFm {
\A    {h\in H}
\I1-------------- {$H$ $\ginv{}$-fechado}
   {\ginv h\in H}
\A                        {h \in H}
\I2--------------------------------- {$H$ $\ast$-fechado}
           {\ginv h h \in H}
    \I1-------------------------- {def.~$\ginv h$}
               {e \in H}
}
$$

%%}}}

%%{{{ remark: shorter formulas 
\remark.
%%%{{{ meta 
%%%}}}

Observe que como $H\subset G$, a afirmação
$$
\lforall {a,b \in G} {a,b\in H \implies ab \in H}
$$
é equivalente à
$$
\lforall {a,b \in H} {ab \in H}.
$$
No próximo critério vamos escrever nessa forma mais curta.

%%}}}

%%{{{ criterion: finite_subgroup_criterion 
\criterion Subgrupo finito.
%%%{{{ meta 
\label finite_subgroup_criterion
%%%}}}

Se $\sset G {\ast,e}$ é um grupo e $H$ é um subconjunto finito e não vazio do $G$,
fechado sobre a operação $\ast$, então $H$ é um subgrupo de $G$.
Em símbolos:
$$
\rightbrace {
\alignedat2
\textrm{(0)} \quad & \emptyset \neq H \finsubset G        &\qquad &\textrm{($H$ é \emph{finito} e n\~ao vazio)}\\
\textrm{(1)} \quad & \lforall{a, b \in H}{a\ast b \in H}    &\qquad &\textrm{($H$ é $\ast$-fechado)}
\endalignedat
}
\implies
H \subgroup G
$$

\sketch.
Basta demonstar o (2) para aplicar o~\ref[nonempty_subgroup_criterion].
Tome um $a\in H$ e considere a seqüência das suas potências
$a, a^2, a^3, \dotsc \in H$.
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ com inteiros $r > s > 0$, e usamos isso
para achar qual dos $a, a^2, a^3, \dotsc$ deve ser o $\ginv a$,
demonstrando assim que $\ginv a\in H$.

\proof.
Graças ao~\ref[nonempty_subgroup_criterion], basta mostrar que todos os membros
de $H$ têm seu inverso dentro do $H$.
Tome um $a\in H$ e considere a seqüência das suas potências positivas:
\compute
a, a^2, a^3, \dotsc &\in H \by {graças à hipótese (1)} \\
\endcompute
Como o $H$ é finito vamos ter um elemento repetido,
$a^r = a^s$ para alguns distintos positivos $r,s \in \nats$.
Sem perda de generalidade, suponha $r > s$.
Temos
$$
\align
\tobrace{a\ast a \ast \dotsb \ast a}{$r$ vezes}
&=\tobrace{a\ast a \ast \dotsb \ast a}{$s$ vezes}
\intertext{e como $r>s$, reescrevemos assim:}
\tobrace{
\tubrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
\ast
\tubrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}
}{$r$ vezes}
&=\tobrace{\cancel{a\ast a \ast \dotsb \ast a}}{$s$ vezes}.
\intertext{Agora operando nos dois lados pela direita por $\ginvp{a^s}$:}
\tobrace{a\ast a \ast \dotsb \ast a}{$r-s$ vezes}
&=e
\intertext{Ou seja, $e = a^{r-s}$ e acabamos de demonstrar que $e\in H$.
Observe que $r-s>0$, então temos pelo menos um $a$ na esquerda:}
\tobrace{a\ast \tubrace{a \ast \dotsb \ast a}{$r-s-1$ vezes}}{$r-s$ vezes}
&=e
\endalign
$$
e agora \emph{precisamos} considerar dois casos:
\eop\noi
\proofcase {Caso $r-s = 1$:}
Nesse caso então temos $e = a^1 = a$,
e logo $\ginv a = \ginv e = e = a \in H$.
\eop\noi
\proofcase {Caso $r-s > 1$:}
Nesse caso, temos $e = aa^{r-s-1}$, ou seja,
achamos o inverso do $a$: é o $a^{r-s-1}$, e ele pertence no $H$,
pois é potência positiva de $a$ (e $H$ é fechado sob a operação).
\eop
Em ambos dos casos mostramos que $\ginv a \in H$ e podemos
aplicar o~\ref[nonempty_subgroup_criterion] para concluir o desejado
$H\subgroup G$.

%%}}}

%%{{{ criterion: subgroup_one_test 
\criterion subgrupo: ``one-test''.
%%%{{{ meta 
\label subgroup_one_test
%%%}}}

Se $G$ é um grupo e $\emptyset\neq H \subset G$ tal que
$$\text{para todo $a,b\in H$},\ a\ginv b\in H,$$
então $H\subgroup G$.  Em símbolos:
$$
\rightbrace {
\aligned
\textrm{(0)} \quad & \emptyset \neq H \subset G \\
\textrm{(1)} \quad & \lforall {a, b \in H} {a\ast \ginv b \in H}
\endaligned
}
\implies
H \subgroup G
$$

\proof.
\ref[subgroup_one_test_proof].

%%}}}

%%{{{ remark: the converses of all criteria above are obviously true 
\remark.
%%%{{{ meta 
%%%}}}

Em todos esses critérios, as direções {\rldir} também são válidas
(e suas demonstrações devem ser óbvias).

%%}}}

%%{{{ x: subgroup_one_test_proof 
\exercise.
%%%{{{ meta 
\label subgroup_one_test_proof
%%%}}}

Demonstre o~\ref[subgroup_one_test].

\hint
Demonstre primeiro que $H$ é fechado sob inversos, tomando um $h\in H$
e demonstrando que $\ginv h \in H$.
Depois basta demonstrar que $H$ é fechado sob a operação, tomando
$a,b\in H$ e demostrando que $ab \in H$.

\solution
Como $H\neq\emptyset$, tome $h\in H$.
Pela hipótese, $h\ginv h\in H$, ou seja $e\in H$.
Como $e,h\in H$, de novo pela hipótese temos $e\ginv h \in H$,
ou seja $\ginv h \in H$.
Temos então que o $H$ é fechado sob inversos.
Basta demonstrar que é fechado sob a operação de $G$ também:
tomando $a,b\in H$, ganhamos $a,\ginv b\in H$,
então pela hipótese $a\ginvp{\ginv b} \in H$, ou seja, $ab \in H$.

%%}}}

%%{{{ x: subgroup_is_an_order 
\exercise.
%%%{{{ meta 
\label subgroup_is_an_order
%%%}}}

Mostre que $\subgroup$ é uma relação de ordem:
$$
\gather
G \subgroup G\\
K \subgroup H \mland H \subgroup G \implies K\subgroup G\\
H \subgroup G \mland G \subgroup H \implies H = G.
\endgather
$$

%%}}}

%%{{{ x: Matrices 
\exercise Matrizes.
%%%{{{ meta 
%%%}}}

Verificamos que
$$
G \leteq \setst{ \matrixp{a & b\\c & d}\in\reals^{2\times2}} {ad - bc \neq 0 }
$$
com multiplicação é um grupo no~\ref[matrix_group_examples].
Considere seus subconjuntos:
$$
\xalignat2
G_{\rats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\rats^{2\times2}} {ad - bc \neq 0 }&\quad H &\leteq \setlst { \matrixp{a & b\\0 & d}      } { a,b,d \in\reals,\ ad \neq 0 }\\
G_{\ints} &\leteq \setst{ \matrixp{a & b\\c & d}\in\ints^{2\times2}} {ad - bc \neq 0 }&\quad K &\leteq \setlst { \matrixp{1 & b\\0 & 1}      } { b\in\reals }                 \\
G_{\nats} &\leteq \setst{ \matrixp{a & b\\c & d}\in\nats^{2\times2}} {ad - bc \neq 0 }&\quad L &\leteq \setlst { \matrixp{a & 0^{\phantom{-1}}\\0 & a^{-1}} } { a\in\reals,\ a\neq 0 }
\endxalignat
$$
Para cada relação de $(\subset)$ válida entre 2 dos 7 conjuntos acima,
decida se a correspondente relação~$\subgroup$ também é válida.

%%}}}

%%{{{ eg: Modular arithmetic 
\example Aritmética modular.
%%%{{{ meta 
%%%}}}

Considere o grupo $\sset {\finord 6} {+_6}$ onde $+_6$ é a adição modulo $6$.
Os $\set{0,2,4}$ e $\set{0,3}$ são seus únicos subgrupos não-triviais.

%%}}}

%%{{{ eg: Permutations 
\example Permutações.
%%%{{{ meta 
%%%}}}

O $\set{\id, \phi}$ é um subgrupo de $\sym 3$, onde $\phi = \permc{1 & 2}$.

%%}}}

%%{{{ x: find all subgroups of \sym 3 
\exercise.
%%%{{{ meta 
%%%}}}

Ache todos os subgrupos do $\sym 3$.

\hint
São 6.  Ache todos.

\solution
Os seguintes são todos os subgrupos do $\sym 3$:
$$
\xalignat6
&\set {\id} &
&\set {\id, \phi} &
&\set {\id, \phi\psi} &
&\set {\id, \psi\phi} &
&\set {\id, \psi, \psi^2} &
&\sym 3.
\endxalignat
$$

%%}}}

%%{{{ eg: Real functions 
\example Funções reais.
%%%{{{ meta 
%%%}}}

Seja $F = (\reals\to\reals_{\neq0})$ com operação a
multiplicação pointwise~(\ref[pointwise_operation]).
Os subconjuntos seguintes de $F$ são todos subgrupos dele:
$$
\xalignat2
&\setstt {f\in F} {$f$ contínua} &
&\setst  {f\in F} {f(0) = 1} \\
&\setstt {f\in F} {$f$ constante} &
&\setstt {f\in F} {$f(r) = 1$ para todo $r\in\rats$}
\endxalignat
$$

%%}}}

%%{{{ eg: Sets 
\example Conjuntos.
%%%{{{ meta 
%%%}}}

Sejam $A$ conjunto, e $X\subset A$.
Lembra que $\sset {\pset A} {\symdiff}$ é um
grupo~(\ref[pset_with_setops_group]).
Os $\set{\emptyset, X}$ e $\set{\emptyset, X, A\setminus X, A}$ são subgrupos dele,
mas os $\set{\emptyset, X, A}$ e $\set{\emptyset, X, A\setminus X}$ não são.

%%}}}

%%{{{ x: why not? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

\hint
(G0).

\solution
O $H = \set{\emptyset, X, A}$ em geral não é um subgrupo, pois pode violar a
lei~(G0) no caso que $A\setminus X \nin H$, pois~$A \symdiff X = A \setminus X$.

%%}}}

%%{{{ x: intersection_of_subgroups_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label intersection_of_subgroups_is_a_subgroup
%%%}}}

Seja $G$ grupo, e $H_1,H_2\subgroup G$.
Então $H_1\inter H_2 \subgroup G$.

\hint
Precisa mostrar que $H_1\inter H_2 \neq \emptyset$ e que é fechado sobre a
operação do grupo e sobre inversos.

\hint
Para mostrar que é fechado sobre a operação do grupo
tome $a,b\in H_1\inter H_2$ e mostre que
$ab\in H_1\inter H_2$.
Similarmente, para mostrar que é fechado sobre os inversos,
tome $a\in H_1\inter H_2$ e mostre que
$\ginv a \in H_1\inter H_2$.

\solution
Temos $H_1\inter H_2 \subset G$.
Observe primeiramente que $H_1\inter H_2\neq \emptyset$,
pois $e\in H_1$ e $e\in H_2$ (os dois sendo subgrupos de $G$).
Agora mostramos que o $H_1\inter H_2$ é fechado sob a operação:
\proofsteps
\steptnb {Sejam $a,b \in H_1\inter H_2$.}
\steptby {Logo $a,b \in H_1$ e $a,b\in H_2$.} {def.~$\inter$}
\steptby {Logo $ab  \in H_1$ e $ab\in H_2$.}  {$H_1$ e $H_2$ grupos}
\steptby {Logo $ab  \in H_1\inter H_2$.}      {def.~$\inter$}
\intertext{e sob inversos:}
\steptnb {Seja $a \in H_1\inter H_2$.}
\steptby {Logo $a      \in H_1$ e $a\in H_2$.}      {def.~$\inter$}
\steptby {Logo $a^{-1} \in H_1$ e $a^{-1}\in H_2$.} {$H_1$ e $H_2$ grupos}
\steptby {Logo $a^{-1} \in H_1\inter H_2$.}         {def.~$\inter$}
\endproofsteps
e o resultado segue graças ao~\ref[nonempty_subgroup_criterion].

%%}}}

%%{{{ x: union_of_subgroups_is_a_subgroup_wrong 
\exercise.
%%%{{{ meta 
\label union_of_subgroups_is_a_subgroup_wrong
%%%}}}

Trocamos o $\inter$ para $\union$
no~\ref[intersection_of_subgroups_is_a_subgroup].
\item{(i)} Ache o erro na demonstração seguinte:
\quote
<<Como $H \leteq H_1\inter H_2 \subset G$,
precisamos mostrar que $H$ é fechado sobre a operação:
\proofsteps
\steptnb {Sejam $a,b \in H_1\union H_2$.}
\steptby {Logo $a,b \in H_1$ ou $a,b\in H_2$.}   {def.~$\union$}
\steptby {Logo $ab \in H_1$ ou $ab\in H_2$.}     {$H_1$ e $H_2$ grupos}
\steptby {Logo $ab \in H_1\union H_2$.}          {def.~$\union$}
\intertext{e sobre os inversos:}
\steptnb {Seja $a \in H_1\union H_2$.}
\steptby {Logo $a \in H_1$ ou $a\in H_2$.}           {def.~$\union$}
\steptby {Logo $a^{-1} \in H_1$ ou $a^{-1}\in H_2$.} {$H_1$ e $H_2$ grupos}
\steptby {Logo $a^{-1} \in H_1\union H_2$.}          {def.~$\union$}
\endproofsteps
Portanto, $H_1 \union H_2 \subgroup G$.>>
\endquote
\item{(ii)} Demonstre que a proposição não é válida.

%%}}}

%%{{{ x: arbitrary_intersection_of_subgroups_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label arbitrary_intersection_of_subgroups_is_a_subgroup
%%%}}}

Generalize a~\ref[intersection_of_subgroups_is_a_subgroup] para
intersecções arbitrárias:
se $G$ é um grupo, e $\scr H$ uma família não vazia de subgrupos de $G$,
então $\Inter {\scr H} \subgroup G$.

%%}}}

%%{{{ x: congruence_mod_H_teaser 
\exercise.
%%%{{{ meta 
\label congruence_mod_H_teaser
\pdefs
    \pdef RH {\rel {R_H}}
    ;;
%%%}}}

Seja $G$ conjunto e $H\subgroup G$.
Defina no $G$ a relação $\RH$ pela
$$
a \RH b \defiff a\ginv b \in H.
$$
Decida se a relação $\RH$ é uma
relação de ordem parcial, de ordem total, de equivalência, ou nada disso.

\hint
É uma relação de equivalência.
Demonstre as 3 propriedades!

\solution
\def\RH{\rel {R_H}}%
\proofpart {Reflexiva:}
Seja $a\in G$.
Calculamos:
$$
\align
a \RH a
&\iff a\ginv a\in H\\
&\iff e\in H
\endalign
$$
que é verdadeiro pois $H\subgroup G$.
\crproofpart {Transitiva:}
Sejam $a,b,c \in G$ tais que $a \RH b$ e $b \RH c$.
Precisamos mostrar que $a \RH c$, ou seja, mostrar que $a\ginv c \in H$.
Temos
\compute
a\ginv b &\in H  \by {$a \RH b$} \tag 1 \\
b\ginv c &\in H  \by {$b \RH c$} \tag 2 \\
(a\ginv b) (b \ginv c) &\in H \by {pelas (1) e (2) pois $H\subgroup G$} \\
\endcompute
Logo $a\ginv b b \ginv c = a \ginv c \in H$.
\crproofpart {Simétrica:}
Sejam $a,b \in G$ tais que $a \RH b$, ou seja, $a\ginv b \in H$\fact1.
Vamos demonstrar que $b \RH a$, ou seja, queremos $b\ginv a \in H$.
Mas como $H$ é fechado sob inversos, pela~\byfact1~temos que
$\ginvp{a\ginv b}\in H$.
Mas calculando
\compute
\ginvp{a\ginv b}
&= \ginvp{\ginv b} \ginv a      \by {inv.~de~op.} \\
&= b \ginv a                    \by {inv.~de~inv.} \\
\endcompute
ou seja, $b\ginv a \in H$.

%%}}}

\endsection
%%}}}

%%{{{ Generators 
\section Geradores.
%%%{{{ meta 
\label Group_generators
%%%}}}

%%{{{ df: subgroup_generated_by_a 
\definition.
%%%{{{ meta 
\label subgroup_generated_by_a
\defines
    * \generate {~a}  -- o subgrupo gerado por o elemento $a$
    * grupo!subgrupo!gerado por elemento
    ;;
%%%}}}

Sejam $G$ grupo e $a\in G$.
Chamamos o
$$
\align
\generate{a}
&\defeq \setst {a^m} {m\in\ints}\\
&= \set{\dotsc,a^{-2},a^{-1},a^0,a^1,a^2,\dotsc}
\endalign
$$
o \dterm{subgrupo de $G$ gerado por $a$}.

%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generated_by_a 
\exercise.
%%%{{{ meta 
\label justify_subgroup_on_subgroup_generated_by_a
%%%}}}

Justifica a palavra ``subgrupo'' na~\ref[subgroup_generated_by_a].
Ou seja, demonstre que para qualquer grupo $G$ e qualquer $a\in G$,
$\generate a \subgroup G$.

\hint
Use o~\ref[nonempty_subgroup_criterion].

\solution
Graças ao~\ref[nonempty_subgroup_criterion],
precisamos verificar que $\generate a$ é fechado sob a operação e sob inversos.
\eop\noi
\proofpart {Fechado pela operação:}
Sejam $h_1,h_2\in\generate a$.
Logo
$h_1 = a^{k_1}$\fact1
e 
$h_2 = a^{k_2}$\fact2
para alguns $k_1,k_2\in\ints$.
Precisamos mostrar que $h_1h_2\in\generate a$.
Calculamos:
\compute
h_1h_2
&= a^{k_1} a^{k_2}  \by {pelas~\byfact1,\byfact2} \\
&= a^{k_1 + k_2}    \by {pela~\ref[properties_of_powers_in_groups]~(1)} \\
&\in \generate a.   \by {def.~$\generate a$, pois $k_1+k_2\in\ints$} \\
\endcompute
\proofpart {Fechado sob inversos:}
Seja $h \in \generate a$,
logo $h = a^k$ para algum $k\in\ints$.
Pela~\ref[properties_of_powers_in_groups]~(3),
$$
\ginv h = \ginvp {a^k} = a^{-k} \in \generate a.
$$

%%}}}

%%{{{ x: Cyclic group of e 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $\sset G {\ast,e}$ grupo.
Calcule o $\generate e$.

\solution
$\generate e = \set {e}$.

%%}}}

%%{{{ x: Calculate some sets and subgroups of ints 
\exercise.
%%%{{{ meta 
%%%}}}

Nos inteiros com adição, calcule os
$\generate 4$,
$\generate 4 \inter \generate 6$,
$\generate 4 \inter \generate {15}$,
e
$\generate 4 \union \generate 6$.
\eop\noi
Quais deles são subgrupos do $\ints$?

%%}}}

%%{{{ Q: How would you generalize gen a to gen A? 
\question.
%%%{{{ meta 
%%%}}}

Como tu generalizarias o
<<subgrupo gerado por $a\in G$>>
para
<<subgrupo gerado por $A \subset G$>>?
Ou seja, como definirias o $\generate A$ para qualquer $A \subset G$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Falando de \emph{generalização}, a idéia é que queremos definir o $\gen A$ num jeito
\emph{razoável} e tal que $\gen {\set a} = \gen a$.

%%}}}

\spoiler

%%{{{ A wrong generalization of <a> to <A> 
\note.
%%%{{{ meta 
\label wrong_generalization_of_gord_a_to_gord_A
%%%}}}

Queremos generalizar o conceito de geradores para definir $\generate A$,
onde $A\subset G$.
Seguindo ingenuamente a definição de $\generate a$,
uma primeira abordagem seria botar
$$
\generate A = \setst {a^m} {a \in A,\  m \in\ints}
$$
e chamar $\generate A$ o subgrupo de $G$ gerado por $A$.\mistake

%%}}}

%%{{{ x: find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A 
\exercise.
%%%{{{ meta 
\label find_the_problem_in_wrong_generalization_of_gord_a_to_gord_A
%%%}}}

Qual o problema com a definição de $\generate A$ acima?

\hint
Calcule o $\generate {4,6}$ no $\sset \ints +$.

\hint
Ele é um subgrupo?

%%}}}

%%{{{ x: subgroup_generated_by_two_members 
\exercise.
%%%{{{ meta 
\label subgroup_generated_by_two_members
%%%}}}

Tentando generalizar primeiramente para o caso mais simples de <<subgrupo gerado por dois membros $a,b\in G$>>,
alguém definiu o $\gen {a,b}$ para quaisquer $a,b \in G$ assim:
$$
\generate {a,b} \defeq \setst {a^m b^n} {m,n \in \ints}.
$$
Existe um problema.  Qual?

\hint
Se $G$ fosse abeliano, daria certo.

\solution
O problema é que não podemos chamar isso \emph{subgrupo}, pois não é garantidamente fechado sob a operação.
Por exemplo,
sabendo que $a \in \gen{a,b}$ e $a\ast b\in\gen{a,b}$, deveriamos ter
$(ab)a \in \gen{a,b}$, mas o $(ab)a$ \emph{em geral} não pode ser escrito na
forma $a^m b^n$.
Uma outra observação similar que serve também é que o inverso de
$ab \in \gen{a,b}$ é o $\ginv b \ginv a$ que também \emph{em geral} não
pode ser escrito na forma $a^m b^n$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos finalmente definir o $\gen A$.

%%}}}

%%{{{ df: subgroup_generate_A_direct 
\definition direta.
%%%{{{ meta 
\label subgroup_generate_A_direct
\defines
    * \generate {~A}  -- o subgrupo gerado por o conjunto $A$
    * grupo!subgrupo!gerado por subconjunto
    ;;
%%%}}}

Sejam $\sset G \ast$ grupo e $A\subset G$.
Chamamos o
$$
\generate A
\defeq
\setstt {a_0\ast\dotsb\ast a_{k-1}}
        {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
$$
o \dterm{subgrupo de $G$ gerado por $A$}.
Ou seja, os membros de $\generate A$ são os produtos finitos feitos por
membros de $A$ e seus inversos.
Abusando a notação, escrevemos também $\generate {a_1, a_2,\dotsc, a_n}$
para o $\generate {\set{a_1, a_2,\dotsc, a_n}}$.

%%}}}

%%{{{ remark: why_e_is_in_every_generated_subgroup 
\remark.
%%%{{{ meta 
\label why_e_is_in_every_generated_subgroup
%%%}}}

Lembre-se (\ref[operating_on_an_empty_list_of_objects]) que para $k=0$
a expressão acima é a identidade $e$,
e logo $e \in \generate A$ para qualquer $A$.

%%}}}

%%{{{ property: equivalent_formulations_for_generate_A 
\property.
%%%{{{ meta 
\label equivalent_formulations_for_generate_A
%%%}}}

As alternativas definições são equivalentes:
$$
\generate A
=
\leftbrace {
\aligned
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A} \\
& \setst  {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
          {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} \\
& \setstt {a_0\ast\dotsb\ast a_{k-1}}
          {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\endaligned
}
$$

%%}}}

%%{{{ x: check_that_a_word_satisfies_all_three_definitions_for_generate_A 
\exercise.
%%%{{{ meta 
\label check_that_a_word_satisfies_all_three_definitions_for_generate_A
%%%}}}

Sejam $G$ grupo e um subconjunto dele $A=\set{a,b,c,d}$.
Mostre que $a^3b^{-2}cb^3d^{-1} \in \generate A$ para todas
as três definições equivalentes da~\ref[equivalent_formulations_for_generate_A].
Ou seja, para cada um desses conjuntos, decida quais são todas as atribuições
necessárias que satisfazem o ``filtro'' de cada conjunto.

\solution
Pela sua forma, já é óbvio que
$$
\align
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \ints;\ a_i \in A}.
\intertext{Basta tomar $k\asseq 5$ e}
&
\alignedat2
a_0 &\asseq a  & m_0 &\asseq 3  \\
a_1 &\asseq b  & m_1 &\asseq -2 \\
a_2 &\asseq c  & m_2 &\asseq 1  \\
a_3 &\asseq b  & m_3 &\asseq 3  \\
a_4 &\asseq d  & m_4 &\asseq -1
\endalignedat
\intertext{e pronto!  Mas para mostrar que}
a^3b^{-2}cb^3d^{-1}
&\in \setst {a_0^{m_0}\ast\dotsb\ast a_{k-1}^{m_{k-1}}}
            {k\in\nats;\ i\in\finord k;\ m_i \in \set{-1,1};\ a_i \in A} 
\intertext{não podemos fazer a mesma escolha, pois cada um dos $m_i$
pode ser ou $1$ ou $-1$.  Basta só aumentar o $k$, e tomando $k \asseq 10$ e}
&
\alignedat4
a_0 &\asseq a  & m_0 &\asseq 1  & a_5 &\asseq c  & m_5 &\asseq 1 \\
a_1 &\asseq a  & m_1 &\asseq 1  & a_6 &\asseq b  & m_6 &\asseq 1 \\
a_2 &\asseq a  & m_2 &\asseq 1  & a_7 &\asseq b  & m_7 &\asseq 1 \\
a_3 &\asseq b  & m_3 &\asseq -1 & a_8 &\asseq b  & m_8 &\asseq 1 \\
a_4 &\asseq b  & m_4 &\asseq -1 & a_9 &\asseq d  & m_9 &\asseq -1.
\endalignedat
\intertext{Finalmente para demonstrar que}
a^3b^{-2}cb^3d^{-1}
&\in \setstt {a_0\ast\dotsb\ast a_{k-1}}
             {$k\in\nats$;\ $i\in\finord k$;\ $a_i \in A$ ou $\ginv{a_i} \in A$}.
\intertext{o $k$ é o mesmo, $k\asseq 10$, e basta escolher nossos $a_i$'s
em tal forma que cada um deles ou é membro de $A$ ou seu inverso é.  Fácil:}
&
\alignedat2
a_0 &\asseq a        & a_5 &\asseq c \\
a_1 &\asseq a        & a_6 &\asseq b \\
a_2 &\asseq a        & a_7 &\asseq b \\
a_3 &\asseq \ginv b  & a_8 &\asseq b \\
a_4 &\asseq \ginv b  & a_9 &\asseq \ginv d.
\endalignedat
\endalign
$$

%%}}}

%%{{{ df: group_word 
\definition Palavra.
%%%{{{ meta 
\label group_word
%%%}}}

Chamamos dum termo feito por membros dum grupo $G$ operados entre si
de \dterm{palavra} de $G$.  Especificando um subconjunto $A\subset G$,
uma $A$-palavra seria uma palavra de $G$ feita usando apenas membros
de $A$ e seus inversos.

%%}}}

%%{{{ eg: some_examples_of_words 
\example.
%%%{{{ meta 
\label some_examples_of_words
%%%}}}

Seja $G$ grupo e $A=\set{w,x,y,z}$ um subconjunto de $G$.
Umas $A$-palavras são as:
$$
\xalignat5
& wxyz  &
& \ginv x &
& wwwwwww &
& wxx\ginv yyyyw\ginv zw &
& \ginv z\ginv z \ginv z y \ginv y z z x \ginv x z
\intertext{Podemos usar exponentes para abreviar essas palavras:}
& wxyz  &
& \ginv x &
& w^7 &
& wx^2\ginv yy^3w\ginv zw &
& z^{-3} y \ginv y z^2 x \ginv x z.
\intertext{e às vezes até usamos um ``overline'' para indicar os inversos:}
& wxyz  &
& \overline x &
& w^7 &
& w\,x^2\,\overline y\,y^3\,w\,\overline z\,w &
& \overline z^3\,y\,\overline y\,z^2\,x\,\overline x\,z.
\endxalignat
$$
Observe que começando com uma palavra podemos \emph{computar} seu valor,
sendo uma palavra onde não aparecem consecutivos objetos canceláveis,
aplicando um passo cada vez: selecionando um tal par e o apagando.

%%}}}

%%{{{ remark: generate_A is the set of all values of A-words 
\remark.
%%%{{{ meta 
%%%}}}

Com essa definição o $\generate A$ é feito por os valores de todas
as $A$-palavras.

%%}}}

%%{{{ x: Calculate <> and <G> 
\exercise.
%%%{{{ meta 
%%%}}}

Dado grupo $G$,
calcule os $\generate \emptyset$ e $\generate G$.

\hint
Considere o ``produto vazio'' igual ao $e\in G$.

\solution
Temos
$$
\align
\generate \emptyset &= \set{e} \\
\generate G         &= G.
\endalign
$$

%%}}}

%%{{{ x: justify_subgroup_on_subgroup_generate_A_direct 
\exercise.
%%%{{{ meta 
\label justify_subgroup_on_subgroup_generate_A_direct
%%%}}}

Demonstre que $\generate A \subgroup G$ para qualquer grupo $G$ e qualquer $A\subset G$.

%%}}}

%%{{{ Q: How would you describe bottom-up and top-down for generate_A? 
\question.
%%%{{{ meta 
%%%}}}

Temos duas mais caracterizações do~$\generate A$ especialmente
importantes: bottom-up e top-down.  A gente já encontrou algo
similar, definindo os fechos de relações (especialmente o fecho
transitivo) no \ref[Relations],~\reftag[Closures].
Como descreverias os dois processos para definir o $\generate A$?

%%}}}

\spoiler

%%{{{ generated_subgroup_bottom_up_informally 
\note Bottom-up, informalmente.
%%%{{{ meta 
\label generated_subgroup_bottom_up_informally
%%%}}}

Começamos com um conjunto~$T$ onde botamos todos os elementos que desejamos
no subgrupo (os elementos de~$A$ nesse caso),
e enquanto isso não forma um grupo, ficamos nos perguntando \emph{por que não}.
A resposta sempre é que (pelo menos) uma lei de grupo ((G0)--(G3)) está sendo
violada.
Vendo as leis, isso sempre quis dizer que um certo elemento tá faltando:
\tlist:
\li: (G0) violada: para alguns~$s,t \in T$, o~$s\ast t \nin T$.
\li: (G1) violada é impossível (veja~\ref[ass_for_free_in_subgroup]).
\li: (G2) violada: a identidade~$e \nin T$.
\li: (G3) violada: para algum~$t \in T$, seu inverso~$\ginv t \nin T$.
\endtlist
E agora?
\tlist:
\li: (G0) violada? Resolução: adicione o $st$: $T\union \set{st}$.
\li: (G2) violada? Resolução: adicione o $e$: $T\union \set{e}$.
\li: (G3) violada? Resolução: adicione o $\ginv t$: $T\union \set{\ginv t}$.
\endtlist
Como resolver cada um desses três possíveis problemas então?
Adicionando os membros culpados!  E depois?  Se o conjunto já virou
um grupo, paramos.  Se não, continuamos.
Ficamos \emph{adicionando} os membros culpados (os faltantes)
e repetindo a mesma pergunta, até chegar num conjunto que não viola
nenhuma das leis, ou seja, um grupo mesmo.
É o conjunto~$T$ que tem todos os elementos de~$A$ e todos os
necessários de~$G$ para formar um grupo.
\eop
Cuidado: é tentoso pensar como resolução \emph{retirar} os $s,t$, no caso da
(G0), ou o $t$ no caso da (G3).  Por exemplo, alguém poderia pensar que o
problema no caso da violada (G0), foi a presença dos $s,t$ no $T$; mas não é!
O problema é a ausência do $st$.  Lembre nossa intuição: queremos começar com o
$A$ e sem perder nenhum dos seus membros, chegar num subgrupo de $G$, adicionando
apenas os necessários.

%%}}}

%%{{{ thm: generated_subgroup_bottom_up_formally 
\theorem Bottom-up, formalmente.
%%%{{{ meta 
\label generated_subgroup_bottom_up_formally
%%%}}}

Sejam $G$ grupo e $A \subset G$.
Definimos a seqüência de conjuntos:
\mathcol
A_0     &= A \\
A_{n+1} &= A_n
           \union \tubrace {\setst {ab} {a,b \in A_n}} {(G0)}
           \union \tubrace {\set e} {(G2)}
           \union \tubrace {\setst {\ginv a} {a \in A_n}} {(G3)}.
\endmathcol
Logo temos:
\math
A = A_0 \subset A_1 \subset A_2 \subset A_3 \subset \dotsb \\
\generate A = \Union_{n=0}^{\infty} A_n.
\endmath

\sketch.
Demostrar $A_n \subset A_{n+1}$ para todo $n\in\nats$ é imediato
por indução.  Para a afirmação principal,
que $\generate A = \Union_{n=0}^{\infty} A_n$,
demonstramos cada direção separadamente:
para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e ache $w\in\nats$ tal que $\alpha \in A_w$;
para a {\rldirset}, basta demonstrar que cada um dos $A_0, A_1, A_2, \dots$
é subconjunto de $\generate A$.  Podes---aliás, deves---usar indução.

%%}}}

%%{{{ eg: tree_for_a_member_of_generate_A 
\example.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A
%%%}}}

Pensando em como demonstrar formalmente o~\ref[generated_subgroup_bottom_up_formally],
talvez ajuda considerar um exemplo específico para entender melhor como funciona.
Considere então um $A=\set{a,b}\subset G$ e um $a^3b^{-8}\in\generate A$.
Como podemos demonstrar que $a^3b^{-8} \in \Union_n A_n$?
Basta achar um $n\in\nats$ tal que $a^3b^{-8}\in A_n$; mas qual $n$ serve aqui?
Vamos plantar uma árvore abreviada e rascunhosa:
$$
\PROOFmn {
   \A {b \in A}
\I1--------------
    {b \in A_0}
               \A {b \in A}
            \I1--------------
                {b \in A_0}
\I2---------------
    {b^2 \in A_1}
               \A {b \in A}
            \I1--------------
                {b \in A_0}
            \I1--------------
                {b \in A_1}
\I2---------------
    {b^3 \in A_2}
               \A {\vdots}
            \I1--------------
                {b \in A_2}
\I2---------------
    {b^4 \in A_3}
\I1---------------
       {\vdots}
\I1---------------
    {b^7 \in A_6}
                   \A {\vdots}
                \I1--------------
                    {b \in A_6}
\I2-----------------------------
           {b^8 \in A_7}
       \I1----------------
          {b^{-8} \in A_8}
                            \A {a \in A}
                       \I1-----------------
                             {a \in A_0}
                       \I1-----------------
                            {a^2 \in A_1}
                                                 \A {a \in A}
                                             \I1---------------
                                                  {a \in A_0}
                                              \I1--------------
                                                  {a \in A_1}
                       \I2------------------------------------
                                    {a^3 \in A_2}
                               \I1-----------------
                                    {a^3 \in A_8}
\I2-----------------------------------------------
                {a^3 b^{-8} \in A_9}
}
$$
Então já sabemos que o $n\asseq 9$ é suficiente e logo concluimos
que $a^3 b^{-8} \in \Union_n A_n$.

%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_justifications 
\exercise.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A_justifications
%%%}}}

Justifique as linhas de inferência da árvore
do~\ref[tree_for_a_member_of_generate_A].

\solution
\let\rulelabel=\textrmsmallish
A parte esquerda parece assim:
$$
\PROOFmr {
   \A {b \in A}
\I1-------------- {(1)}
    {b \in A_0}
                    \A {b \in A}
                 \I1-------------- {(2)}
                     {b \in A_0}
\I2---------------------------- {(3)}
         {b^2 \in A_1}
                          \A {b \in A}
                       \I1-------------- {(4)}
                           {b \in A_0}
                       \I1-------------- {(5)}
                           {b \in A_1}
   \I2------------------------------- {(6)}
              {b^3 \in A_2}
                                            \A {\vdots}
                                         \I1-------------- {(7)}
                                             {b \in A_2}
\I2------------------------------------------------------ {(8)}
                   {b^4 \in A_3}
              \I1--------------- {*}
                     {\vdots}
              \I1--------------- {*}
                  {b^7 \in A_6}
                                         \A {\vdots}
                                     \I1-------------- {(9)}
                                         {b \in A_6}
              \I2----------------------------------- {(10)}
                            {b^8 \in A_7}
                     \I1--------------------- {(11)}
                           {b^{-8} \in A_8}
}
$$
Onde as justificativas são:
\tlist:
\li (1):  def.~$A_0$;
\li (2):  def.~$A_0$;
\li (3):  def.~$A_1$~(G0);
\li (4):  def.~$A_0$;
\li (5):  $A_0 \subset A_1$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (6):  def.~$A_2$~(G0);
\li (7):  $A \subset A_2$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (8):  def.~$A_3$~(G0);
\li (9):  $A \subset A_6$ (\reftag[generated_subgroup_bottom_up_formally]);
\li (10): def.~$A_7$~(G0);
\li (11): def.~$A_8$~(G3).
\endtlist
Nas (*) usamos a regra inferida:
$$
\PROOFmr {
     \A {x^k \in A_m}
\I1-------------------- {$x\in A$}
   {x^{k+1} \in A_{m+1}}
}
\qquad\leadsto\qquad
\PROOFmr {
\A {x^k \in A_k}
                 \A {x \in A_0}
                \I1------------- {$A_0\subset A_k$}
                    {x \in A_k}
\I2----------------------------- {def.~$A_{k+1}$~(G0)}
        {x^2 \in A_{k+1}}
}
$$
O resto da árvore é justificado numa maneira parecida.

%%}}}

%%{{{ x: tree_for_a_member_of_generate_A_shorter 
\exercise.
%%%{{{ meta 
\label tree_for_a_member_of_generate_A_shorter
%%%}}}

Com uma árvore mais baixa demonstre que $a^3 b^{-8} \in A_5$.

\hint
Tem como mostrar $b^{-8} \in A_4$.

\hint
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {}
    {b^2 \in A_1}
\I1--------------- {}
    {b^4 \in A_2}
\I1--------------- {}
    {b^8 \in A_3}
}
$$
Como justificar cada linha?

\solution
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
\I1--------------- {*}
    {b^2 \in A_1}
\I1--------------- {*}
    {b^4 \in A_2}
\I1--------------- {*}
    {b^8 \in A_3}
\I1----------------- {}
    {b^{-8} \in A_4}
                               \A {a \in A}
                          \I1------------------ {}
                                {a \in A_0}
                          \I1------------------ {*}
                               {a^2 \in A_1}
                                                          \A {a \in A}
                                                      \I1--------------- {}
                                                           {a \in A_0}
                                                       \I1-------------- {}
                                                           {a \in A_1}
                          \I2-------------------------------------------- {}
                                       {a^3 \in A_2}
                                   \I1------------------ {}
                                       {a^3 \in A_4}
\I2------------------------------------------------------ {}
                {a^3 b^{-8} \in A_5}
}
$$
Onde explicamos a regra inferida (*):
$$
\PROOFm {
\A {x \in A_m}
\I1-------------- {*}
   {x^2 \in A_{m+1}}
}
\qquad\leadsto\qquad
\PROOFm {
\A {x \in A_k}
\A {x \in A_k}
\I2----------------- {}
   {x^2 \in A_{k+1}}
}
$$
A parte esquerda com pouco mais detalhe parece assim:
$$
\PROOFm {
   \A {b \in A}
\I1-------------- {}
    {b \in A_0}
                   \A {b \in A}
                \I1-------------- {}
                    {b \in A_0}
\I2-------------------------------- {}
           {b^2 \in A_1}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^2 \in A_1}
        \I2-------------------------- {}
           {b^4 \in A_2}
                           \A {\vdots}
                        \I1-------------- {}
                            {b^4 \in A_2}
        \I2--------------------------- {}
                {b^8 \in A_3}
}
$$

%%}}}

%%{{{ generated_subgroup_top_down_informally 
\note Top-down, informalmente.
%%%{{{ meta 
\label generated_subgroup_top_down_informally
%%%}}}

Começamos considerando o próprio $G$ como um possível candidato para ser
o subgrupo de $G$ gerado por o conjunto $A$.  No final das contas,
$G \subgroup G$, e também $G \supset A$.
Mas no~$G$ existe possível ``lixo'': membros fora do~$A$ cuja presença não
foi justificada como necessária pelas leis de grupo.
Precisamos filtrar esse lixo, para ficar apenas com os membros ``necessários''.
Quais são esses membros?
Bem, se conseguir formar um subgrupo $H \subgroup G$
tal que $H\supset A$ e que \emph{não} tem alguns dos membros,
isso quis dizer que eles não são realmente necessários; ou seja, é lixo.
Então quem fica mesmo?
Ficam apenas aqueles que pertencem a \emph{todos} os subgrupos de $G$
que contêm o $A$.  Estes membros são exatamente os membros do $\generate A$.

%%}}}

%%{{{ top_down_heart_level 
\note Top-down: nível coração.
%%%{{{ meta 
\label top_down_heart_level
%%%}}}

Vamos pensar em nosso alvo (o $\generate A$) como o \emph{menor} de todos
os subgrupos de $G$ que contêm o $A$.  O que significa esse \wq{menor}?
Menor em qual ordem?  Não ligamos sobre quantidade de elementos aqui.
Menor quis dizer subgrupo---lembra que $\subgroup$ é uma
ordem~(\ref[subgroup_is_an_order]), né?---ou $(\subset)$-menor,
que \emph{nesse caso} acaba sendo equivalente.
O que tudo isso quis dizer?
Queremos definir o $\generate A$ como
\emph{aquele} conjunto $\overline A$ que satisfaz:
(i) $A \subset \overline A \subgroup G$; e
(ii) para todo $K$ tal que $A \subset K \subgroup G$,
temos $\overline A \subgroup K$.
Observe que nada muda se trocar o \symq{$\subgroup$} por \symq{$\subset$}
na última condição; pois como $\generate A$ e $K$ são subgrupos de $G$,
as afirmações $\overline A \subset K$ e $\overline A \subgroup K$ são equivalentes.
\eop
Podemos parar nossa definição aqui?  Não, pois esse \wq{aquele} acima
não foi merecido ainda: como sabemos que existe tal conjunto?
Felizmente, graças à (ii), se tal conjunto existe,
ele é único~(\ref[uniqueness_of_minimum_subgroup_containing_A]).
\eop
Começamos com a família~$\scr H$ de \emph{todos} os subgrupos de~$G$
que contêm o~$A$:
$$
\scr H = \setst {H} {A \subset H \subgroup G}.
$$
Afirmamos que o conjunto que procuramos é o $\Inter \scr H$.
Basta verificar que ele satisfaz todas as condições,
algo que tu vai fazer agora nos exercícios abaixo, mas antes disso\dots

%%}}}

%%{{{ x: intersection_of_possibly_empty_family_in_top_down_heart_level 
\exercise.
%%%{{{ meta 
\label intersection_of_possibly_empty_family_in_top_down_heart_level
%%%}}}

Mesmo verificando essas três coisas, ainda falta demonstrar algo!
Temos um erro sutil mas importantíssimo;
\emph{como se fosse} uma possível divisão por zero!
Ache o que é, e demonstre o que precisas demonstrar para corrigi-lo.

\solution
Precisamos verificar que a família $\scr H$ tem pelo menos um membro
antes de intersectar (veja a resolução do~\ref[Inter_emptyset]).
Fato, pois já temos um membro dela: o próprio $G$!
É imediato verificar que $G \in \scr H$, e logo $\scr H \neq \emptyset$.

%%}}}

%%{{{ x: intersection_of_cal_H_is_a_subgroup 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_is_a_subgroup
%%%}}}

$\Inter \scr H \subgroup G$.

\solution
Imediato pelo~\ref[arbitrary_intersection_of_subgroups_is_a_subgroup],
pois $\scr H$ e não vazia e todos os seus membros são subgrupos.

%%}}}

%%{{{ x: intersection_of_cal_H_contains_A 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_contains_A
%%%}}}

$A \subset \Inter \scr H$.

\solution
Pela definição da $\scr H$, para todo $H \in \scr H$ temos $A \subset H$.
Logo $A \subset \Inter \scr H$.
Isso deveria ser óbvio, e resolvido desde~\ref[Inter_of_supsets_supset].

%%}}}

%%{{{ x: intersection_of_cal_H_is_contained_in_every_other_candidate 
\exercise.
%%%{{{ meta 
\label intersection_of_cal_H_is_contained_in_every_other_candidate
%%%}}}

Para cada candidato $K$ com $A \subset K \subgroup G$, temos
$\Inter \scr H \subgroup K$.

\hint
Como já demonstramos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta demonstrar $\Inter \scr H \subset K$.

\solution
Seja $K$ tal que $A \subset K \subgroup G$.
Como já demonstramos que $\Inter \scr H$ é um grupo, e como $K$ também
é grupo, basta demonstrar $\Inter \scr H \subset K$.
Mas, pela sua escolha, $K$ é um dos membros da família $\scr H$,
e logo $\Inter \scr H \subset K$.
Se isso não é óbvio, resolva o~\ref[Inter_is_contained_in_every_member].

%%}}}

%%{{{ x: uniqueness_of_minimum_subgroup_containing_A 
\exercise.
%%%{{{ meta 
\label uniqueness_of_minimum_subgroup_containing_A
%%%}}}

Demonstre que realmente a condição (ii) acima garanta que se tal conjunto
existe, ele é único.

\solution
Isso não é nada demais do que unicidade do mínimo, se existe,
algo fácil para demonstrar num contexto geral para qualquer ordem
(\ref[uniqueness_of_min_max]).
Mas vamos ver essa demonstração nesse contexto especifico aqui.
Suponha que $\overline A, A'$ ambos satisfazem a (i)--(ii).
Vamos demonstrar que $\overline A = A'$.
Como $\overline A$ satisfaz a (ii) e $A'$ satisfaz a (i), temos
$$
\overline A \subgroup A'.
$$
No outro lado, $A'$ satisfaz a (ii) e $\overline A$ satisfaz a (i), logo
$$
A' \subgroup \overline A.
$$
Logo $\overline A = A'$, pois a relação de subgrupo é
antissimétrica~(\ref[subgroup_is_an_order]).

%%}}}

%%{{{ thm: generated_subgroup_top_down_formally 
\theorem Top-down, formalmente.
%%%{{{ meta 
\label generated_subgroup_top_down_formally
%%%}}}

Sejam $G$ grupo e $A\subset G$.
Logo
$$
\generate A = \Inter \setst { H \subgroup G } { A \subset H }.
$$

\sketch.
Seja $\scr H = \setst { H \subgroup G } { A \subset H }$.
Demonstramos cada direção separadamente:
Para a {\lrdirset}, tome um arbitrário membro $\alpha \in \generate A$
e um arbitrário $H \subgroup G$ tal que $H \supset A$,
e mostre que $\alpha\in H$.
Para a {\rldirset}, tome um $\alpha$ que pertence a todos
os subgrupos de $G$ que contêm o $A$ e mostre que
ele pode ser escrito na forma desejada (da definição de~$\generate A$).

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ou seja, temos três definições equivalentes de \dterm{subgrupo gerado por $A$}.

%%}}}

%%{{{ df: cyclic_group 
\definition Grupo cíclico.
%%%{{{ meta 
\label cyclic_group
\defines
    * Grupo!cíclico
    ;;
%%%}}}

Um grupo $G$ é \dterm{cíclico} sse existe $a\in G$ tal que $\generate a = G$.

%%}}}

%%{{{ x: cyclic_and_noncyclic_groups 
\exercise.
%%%{{{ meta 
\label cyclic_and_noncyclic_groups
%%%}}}

Quais dos seguintes são grupos cíclicos?
$$
\xalignat8
& \sset \reals + &
& \sset \rats +  &
& \sset \ints +  &
& \sset {\reals_{\neq0}} \ntimes &
& \sset {\rats_{\neq0}} \ntimes  &
& \sset {\ints_6} {+_6} &
& \sset {\ints_6\setminus\set0} {\ntimes_6} &
& \sym 3
\endxalignat
$$

\solution
O $\sset \reals +$ não é.
O $\sset \rats +$ também não.
O $\sset \ints +$ é: $\generate 1 = \sset \ints +$.
O $\sset {\reals_{\neq0}} \ntimes$ não é.
O $\sset {\rats_{\neq0}} \ntimes$ também não é.
O $\sset {\ints_6} {+_6}$ é: $\generate 1 = \sset {\ints_6} {+_6}$
O $\sset {\ints_6\setminus\set0} {\ntimes_6}$ nem é grupo!
O $\sym 3$ não é.

%%}}}

%%{{{ x: generators_of_additive_Z6
\exercise.
%%%{{{ meta 
\label generators_of_additive_Z6
%%%}}}

Ache todos os membros geradores de $\sset {\ints_6} {+_6}$.

\hint
Ele tem dois.

\solution
$\generate 1 = \generate 5 = \ints_6$.

%%}}}

%%{{{ x: generators_of_S3 
\exercise.
%%%{{{ meta 
\label generators_of_S3
%%%}}}

Ache todos os geradores $A$ de $\sym 3$ com tamanho $2$.

%%}}}

\endsection
%%}}}

%%{{{ A detour: bottom-up and top-down 
\section Um desvio: bottom-up e top-down.
%%%{{{ meta 
\label Bottom_up_and_top_down
%%%}}}

%%{{{ Thingies and subthingies
\note Bichos e subbichos.
%%%{{{ meta 
%%%}}}

As idéias de bottom-up e top-down são tão fundamentais que vale a pena
desviar um pouco do nosso estudo de grupos para discutir e generalizar
o que acabou de acontecer.
Vamos dizer que temos um tipo de coisas que gostamos e estudamos.
Aqui esse tipo de coisas foi o grupo, mas queremos ver essas
idéias num contexto ainda mais abstrato e geral.
Então não vamos especificar esse tipo.
Vamos chamar esses objetos de \dterm{bichos}.
Suponha agora que cada bicho tem ``por trás'' um associado conjunto.
Por exemplo, os grupos e em geral os conjuntos estruturados tem seus carrier sets.
Então faz sentido de unir, intersectar, etc., bichos.
Suponha também que cada bicho tem algo que faz seu conjunto ser especial:
sua estrutura, umas leis, etc.
Assim, já temos como definir o que significa \dterm{subbicho}:
\emph{$B_0$ é subbicho do bicho $B$ sse $B_0 \subset B$ e $B_0$ também é um bicho}.
Agora comece com um bicho $B$, e considere um subconjunto $S \subset B$,
que não é necessariamente um subbicho.
Queremos definir o \dterm{subbicho gerado por $S$}.
Precisamos:
\elist 1:
\li: saber que a relação de ``subbicho'' é uma ordem;
\li: saber que intersecção arbitrária de bichos é bicho.
\endelist
Agora podemos definir o \dterm{subbicho gerado por $S$} para ser o menor subbicho
de $B$ que contem o $S$, ou seja, a intersecção
$$
\align
\generate S &= \Inter \setstt {C} {$C$ é subbicho de $B$ que contem o $S$}.
\intertext{Curtamente: dados $S \subset B$, temos}
\generate S &= \Inter_{\mathclap{S \subset C \leq B}} C,
\endalign
$$
onde $(\leq)$ aqui significa ``subbicho''.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas construções aparecem o tempo todo, para vários bichos:
espaços topológicos, $\sigma$-algebras, espaços vetoriais, relações transitivas,
modelos de lógica, etc.
Aqui vamos usar como exemplo para ilustrar o processo os \emph{conjuntos convexos}
do plano euclideano $\reals^2$:

%%}}}

%%{{{ df: convex_set_in_plane 
\definition Conjuntos convexos.
%%%{{{ meta 
\label convex_set_in_plane
%%%}}}

Seja $C \subset \reals^2$.
Chamamos o $C$ \dterm{convexo} sse
para todo $P, Q \in C$, o segmento $\segment {PQ} \subset C$.

%%}}}

\TODO Add figures.

%%{{{ x: which_sets_are_convex 
\exercise.
%%%{{{ meta 
\label which_sets_are_convex
%%%}}}

Desenhe os subconjuntos seguintes de $\reals^2$:
% TODO: fix reflabs
\elist a:
\li: $\emptyset$;
\li: $\set{\tup{0,0}}$;
\li: $\set{\tup{0,0},\tup{0,1}}$;
\li: $\set{\tup{0,0},\tup{0,1},\tup{1,0},\tup{1,1}}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 = 1}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 \leq 1}$;
\li: $\setst {\tup{x,y}} {x^2+y^2 < 1}$;
\li: $\setst {\tup{x,0}} {0\leq x < 1}$;
\li: $\setst {\tup{x,y}} {\max\set{\abs x, \abs y} < 1}$.
\li: $\setst {\tup{x,y}} {x + y > 1}$.
\endelist
Quais deles são convexos?

%%}}}

%%{{{ x: find_the_convex_hulls 
\exercise.
%%%{{{ meta 
\label find_the_convex_hulls
%%%}}}

Para cada um dos conjuntos do~\ref[which_sets_are_convex]
que não é convexo, desenha seu fecho convexo.

%%}}}

%%{{{ x: convex_sets_have_the_intersection_property 
\exercise.
%%%{{{ meta 
\label convex_sets_have_the_intersection_property
%%%}}}

Demonstre que os conjuntos convexos têm a propriedade de intersecção:
se $\scr C$ é uma família não vazia de conjuntos convexos, então
$\Inter \scr C$ é um conjunto convexo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Logo, \emph{podemos definir} o \dterm{fecho convexo} (ou \dterm{convex hull})
dum subconjunto $S\subset\reals^2$ usando a abordagem top-down.

%%}}}

%%{{{ df: convex_hull_bottom_up 
\definition.
%%%{{{ meta 
\label convex_hull_bottom_up
%%%}}}

Seja $S\subset\reals^2$.
Definimos a seqüência de conjuntos $\seqn S n$ pela recursão:
$$
\align
S_0     &= S \\
S_{n+1} &= S_n \union \setstt {M \in \reals^2} {existem $P,Q \in S_n$ tais que $M$ é um ponto no segmento $\segment {PQ}$}.
\endalign
$$
Agora definimos o \dterm{fecho convexo} (ou \dterm{convex hull}) $\hull S$ de $S$ pela
$$
\hull S \defeq \Union_{n=0}^\infty S_n.
$$

%%}}}

%%{{{ x: convex_hull_bottom_up_deserves_the_name 
\exercise.
%%%{{{ meta 
\label convex_hull_bottom_up_deserves_the_name
%%%}}}

Demonstre que o convex hull $\hull S$ dum $S \subset \reals^2$ merece seu nome:
(i) $\hull S$ é convexo mesmo e contem o $S$; (ii) qualquer convexo $C$ que contem o $S$, está contido no $\hull S$.

%%}}}

%%{{{ Q: how_can_we_define_the_convex_hull_top_down 
\question.
%%%{{{ meta 
\label how_can_we_define_the_convex_hull_top_down
%%%}}}

Como podemos definir o fecho convexo dum conjunto $S\subset\reals^2$ ``top-down''?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Precisamos ter pelo menos um conjunto convexo que contem o $S$,
verificar que intersecção arbitrária de conjuntos convexos é conjunto convexo,
e que a relação ``subconjunto convexo'' é uma ordem.
A última coisa é trivial.  As outras duas, deixo como exercícios
pra ti~(\reftag[at_least_one_convex_contains_S]
e~\reftag[intersection_of_convex_is_convex]).
Com essas coisas podemos definir o $\convexhull S$ como
$$
\convexhull S = \Inter \setst {C} {S \subset C \leq \reals^2}
$$
onde $(\leq)$ é a relação de ``subconjunto convexo''.
Assim $\convexhull S$:
(i) é convexo e contem o $S$;
(ii) esta contido em qualquer conjunto que satisfaz a (i).
A argumentação é exatamente a mesma com o caso de grupos
(\ref[top_down_heart_level] e os exercícios o seguindo:
\reftag[intersection_of_cal_H_is_a_subgroup];
\reftag[intersection_of_cal_H_contains_A];
\reftag[intersection_of_cal_H_is_contained_in_every_other_candidate]).

%%}}}

%%{{{ x: intersection_of_convex_is_convex 
\exercise.
%%%{{{ meta 
\label intersection_of_convex_is_convex
%%%}}}

A intersecção de uma família não vazia de conjuntos convexos é um conjunto convexo.

%%}}}

%%{{{ x: at_least_one_convex_contains_S 
\exercise.
%%%{{{ meta 
\label at_least_one_convex_contains_S
%%%}}}

Seja $S$ um subconjunto do plano.
Demonstre que a família de todos os conjuntos convexos que
contêm o $S$ não é vazia.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Chega para agora.
No~\ref[Posets_Lattices] vamos revisitar esse assunto num contexto abstrato.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ df: group_center 
\definition Centro.
%%%{{{ meta 
\label group_center
\defines
    * \gcenter {~G}  -- o centro do grupo $G$
    * grupo!centro
    ;;
%%%}}}

Dado um grupo $G$, definimos seu \dterm{centro} $\gcenter G$
como o conjunto de todos os membros de $G$ que ``comutam'' com todos os membros de $G$:
$$
\gcenter G \defeq \setstt {z \in G} {para todo $g\in G$, $zg = gz$}.
$$

%%}}}

%%{{{ prob: center_G_is_a_subgroup 
\problem.
%%%{{{ meta 
\label center_G_is_a_subgroup
%%%}}}

Mostre que dado um grupo $G$, seu centro $\gcenter G \subgrp G$.

\solution
Primeiramente observe que $\gcenter G\neq\emptyset$:
$e \in \gcenter G$ pois para todo $g\in G$, $eg=e=ge$ pela definição de $e$.
Como $\emptyset \neq \gcenter G \subset G$, precisamos apenas mostrar que:
\eop\noi
\proofpart {Fechado pela operação:}
Sejam $x,y\in \gcenter G$.
Para demonstrar que $xy\in \gcenter G$,
verificamos que o $(xy)$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
(xy)g
&= x(yg)  \by {(G1)} \\
&= x(gy)  \by {$y\in \gcenter G$} \\
&= (xg)y  \by {(G1)} \\
&= (gx)y  \by {$x\in \gcenter G$} \\
&= g(xy). \by {(G1)} \\
\endcompute
\eop\noi
\proofpart {Fechado sob inversos:}
Seja $x\in \gcenter G$.
Para demonstrar que $\ginv x\in \gcenter G$,
verificamos que o $\ginv x$ comuta com todos os elementos de $G$.
Seja $g\in G$.
Calculamos:
\compute
\ginv x g
&= \ginvp{\ginvp{\ginv x g}}         \by {inv.~de~inv.} \\
&= \ginvp{\ginv g {\ginvp{\ginv x}}} \by {inv.~de~prod.} \\
&= \ginvp{\ginv g x}                 \by {inv.~de~inv.} \\
&= \ginvp{x \ginv g}                 \by {$x \in \gcenter G$} \\
&= \ginvp{\ginv g} \ginv x           \by {inv.~de~prod.} \\
&= g \ginv x.                        \by {inv.~de~inv.} \\
\endcompute

%%}}}

%%{{{ prob: identifier_of_all 
\problem.
%%%{{{ meta 
\label identifier_of_all
%%%}}}

Seja $G$ grupo finito.
Existe inteiro $N>0$ tal que para todo $a \in G$, $a^N = e$.

\hint
Tem como construir mesmo esse $N$.

\hint
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n$ membros de $G$.

\hint
Dado $a \in G$ sabemos que $a^{\gord a} = e$.

\solution
Sejam $G \eqass \set {a_1, \dotsc, a_n}$ os $n>0$ membros de $G$.
O inteiro $N$ que procuramos é o
$$
N \asseq \Prod_{i=1}^n \gord {a_i}.
$$
Para confirmar, seja $w \in \set{1,\dotsc,n}$
(assim temos uma arbitrário membro de $G$, o $a_w$).
Basta mostrar que $a_w^N = e$:
\compute
a_w^N
&= a_w^{\gord{a_1}\dotsb\gord{a_n}}
   \by {def.~$N$} \\
&= a_w^{\gord{a_w}\paren{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}}
   \by {ensino fundamental} \\
&= \paren{a_w^{\gord{a_w}}}^{\gord{a_1}\dotsb\gord{a_{w-1}}\gord{a_{w+1}}\dotsb\gord{a_n}}
   \by {\ref[properties_of_powers_in_groups]-(2)} \\
&= e^{\text{coisa}}
   \by {def.~$\gord {a_w}$} \\
&= e.
   \by {\ref[properties_of_powers_in_groups]-(3)} \\
\endcompute

%%}}}

%%{{{ prob: all_subgroups_of_additive_ints 
\problem.
%%%{{{ meta 
\label all_subgroups_of_additive_ints
%%%}}}

No~\ref[some_subgroups_of_additive_ints] tu demonstraste que para todo $m\in\ints$,
$m\ints \subgroup \sset \ints +$.  Demonstre que esses são \emph{todos} os
subgrupos de $\sset \ints +$.  Ou seja: para todo $H \subgroup \sset\ints+$,
existe $t \in \ints$ tal que $H = t\ints$.

%%}}}

%%{{{ prob: weird_convex 
\problem.
%%%{{{ meta 
\label weird_convex
%%%}}}

Seja $Q$ o conjunto de todos os pontos do cíclo com ângulo racional:
$$
Q = \setst {\tup{\cos\theta, \sin\theta}} {\theta\in[0,2\pi)\inter\rats}.
$$
Considere a seqüência
$$
Q = Q_0 \subset Q_1 \subset Q_2 \subset Q_3 \subset \dotsb
$$
obtenida pela bottom-up construção da~\reftag[Bottom_up_and_top_down].
(i) Qual conjunto é o convex hull $\generate Q$ do $Q$?
(ii) Descreva o conjunto $Q_1$.
(iii) Tem $Q_i = Q_{i+1}$ para algum $i\in\nats$?

%%}}}

%%{{{ prob: weird_convex_hard 
\problem.
%%%{{{ meta 
\label weird_convex_hard
%%%}}}

No~\ref[weird_convex], $Q_1 = Q_2$?

\hint
Não!  O $Q_1$ tem ``buracos'' nele, e o $Q_2$ não tem!
Tem com achar um tal buraco no $Q_1$.

\hint
$(0,0) \in Q_2 \setminus Q_2$.  Por quê?

\hint
Para ``passar pelo $(0,0)$'', uma corda obrigatoriamente
tem que ser uma diámetro.

\hint
Por enquanto só podemos responder ``não'' por causa desse
buraco.  Tem outros buracos?
Paciência até o~\ref[Cantors_paradise], onde revisitamos essa
pergunta nos seus problemas.

%%}}}

%%{{{ prob: weird_convex_modulized 
\problem.
%%%{{{ meta 
\label weird_convex_modulized
%%%}}}

O que muda no~\ref[weird_convex] se definir o $Q$ como
$Q = \Union_n \set{\tup{\cos n, \sin n}}$?

%%}}}

\endproblems
%%}}}

%%{{{ Congruences and cosets 
\section Congruências e coclasses.
%%%{{{ meta 
\label Group_congruences_and_cosets
%%%}}}

%%{{{ The relation R was actually congruence mod subgroup 
\blah.
%%%{{{ meta 
%%%}}}

A relação de equivalência que definimos no~\ref[congruence_mod_H_teaser]
não é tão desconhecida como talvez apareceu ser.
Vamos investigar.

%%}}}

%%{{{ congruence mod H 
\note Congruência módulo subgrupo.
%%%{{{ meta 
%%%}}}

Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
a \cong b \pmod H \defiff a\ginv b \in H.
$$
Usamos também a notação $a \congR H b$.

%%}}}

%%{{{ x: mod_int_as_a_special_case_of_mod_subgroup 
\exercise.
%%%{{{ meta 
\label mod_int_as_a_special_case_of_mod_subgroup
%%%}}}

Justifique a notação da~\ref[equivalence_mod_subgroup] a comparando com a
congruência módulo algum inteiro da~\ref[congruence_modulo_int].
Ou seja, mostre como a definição nos inteiros é apenas um caso especial da definição nos grupos.

\hint
Tome $G \asseq \sset\ints+$ e $H \asseq \sset{m\ints}+$.
E agora?  O que cada uma das
$$
\xalignat2
a \cong b &\pmod m &
a \cong b &\pmod H
\endxalignat
$$
tá dizendo nesse caso?

%%}}}

%%{{{ Investigating the congruence 
\note Investigando a congruência.
%%%{{{ meta 
\label investigation_of_equivalence_mod_subgroup
%%%}}}

Vamos supor que temos um grupo $G$ e um subgrupo $H\subgroup G$.
Tomamos $a,b\in G$ e queremos ver se $a\cong b\pmod H$.
Separamos em casos:
\tlist:
\li \proofcase {Caso 1:}: os dois elementos $a$ e $b$ estão no $H$;
\li \proofcase {Caso 2:}: um dos elementos está dentro do $H$, o outro fora;
\li \proofcase {Caso 3:}: os dois estão fora do $H$.
\endtlist
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)    (a) {$\bullet$};
\node at (-0.5,-0.5) (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (-1,0.5)   (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestbase;
\node at (0.5,1)    (a) {$\bullet$};
\node at (1,-0.5)   (b) {$\bullet$};
\node[above right, outer sep=1pt] at (a) {$a$};
\node[above right, outer sep=1pt] at (b) {$b$};
\endtikzpicture
%%}}}
}
\botcaption{}
Os 3 casos da Investigação~\reftag[investigation_of_equivalence_mod_subgroup].
\endcaption
\endinsert
\noi
Para cada caso, queremos decidir se:
\tlist:
\li (i): podemos concluir que $a \cong b \pmod H$;
\li (ii): podemos concluir que $a \ncong b \pmod H$;
\li (iii): nenhum dos (i)--(ii).
\endtlist
Vamos ver qual dos (i)--(iii) aplica no \proofcasestylize{caso 1}.
Temos
$$
a \cong b \pmod H \iff a\ginv b \in H
$$
Como $b\in H$ e $H$ é um grupo ($H\subgroup G$) concluimos que
$\ginv b \in H$.
Agora, como $a, \ginv b \in H$ ganhamos $a\ginv b\in H$, ou seja,
$a \cong b \pmod H$:
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[color=blue,inner sep=1pt] at (-1.5,-0.5)  (binv)  {$\bullet$};
\draw[->,dashed,color=blue] (b)--(binv);
\node[above,  outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase1base;
\node[inner sep=1pt] (binv)  at (-1.5,-0.5)  {$\bullet$};
\node[color=blue,inner sep=1pt] (abinv)  at (-0.75,-0.75) {$\bullet$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\draw[|-,color=blue]  (a)    edge[out=240,  in=135] (abinv);
\draw[|->,color=blue] (binv) edge[out=60, in=135] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos do \proofcasestylize{caso 1} do~\reftag[investigation_of_equivalence_mod_subgroup].
\endcaption
\endinsert

%%}}}

%%{{{ x: do case 2 
\exercise.
%%%{{{ meta 
\label investigation_of_equivalence_mod_subgroup_case_2
%%%}}}

Decida qual dos (i)--(iii) aplica no \proofcasestylize{caso 2}
do~\reftag[investigation_of_equivalence_mod_subgroup].

\hint
Sem perda de generalidade, podes supor que $a \in H$ e $b \nin H$.
Comece desenhando como fizermos no \proofcasestylize{caso 1}.

\hint
Mostre que $b^{-1}\nin H$.  (Qual seria o problema se $b^{-1} \in H$?)

\hint
Se $b{-1} \in H$ seu inverso também deveria estar no $H$, pois $H$ é um grupo.

\hint
Suponha que $ab^{-1} \in H$ para chegar num absurdo, mostrando assim que necessariamente,
$a \ncong b \pmod H$.  Cuidado:
$$
xy \in H \nimplies x \in H \mland y \in H.
$$

\hint
Mostre que $a^{-1}\in H$.

\solution
Sem perda de generalidade, suponha $a\in H$ e $b\nin H$.
Primeiramente mostramos que $b^{-1} \nin H$:
$$
b^{-1}\in H \implies \paren{b^{-1}}^{-1} \in H \implies b \in H,
$$
logo $b^{-1}\nin H$.
Para chegar num absurdo, vamos supor que $ab^{-1} \in H$.
\topinsert
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt, color=blue] at (0,1.5) (binv) {$\bullet$};
\draw[->,dashed,color=blue] (b) edge[out=180, in=225] (binv);
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
}
\medskip
\centerline{
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node[inner sep=1pt] at (0,1.5) (binv) {$\bullet$};
\node[inner sep=1pt, color=blue] at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\draw[->,dashed,color=blue] (a) to (ainv);
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[above, inner sep=3pt, outer sep=1pt] at (binv) {$\ginv b$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[color=red] at (-0.5,-1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[|-]  (ainv)  edge[out=60, in=250] (binv);
\draw[|->,color=red] (abinv) edge[out=90, in=250] (binv);
\endtikzpicture
%%}}}
\hfil
\tikzpicture[>=stealth]%%{{{
\tikzi groupconginvestcase2base;
\node at (0,1.5) (binv) {$\bullet$};
\node at (-1.25,-1) (ainv) {$\bullet$};
\node[inner sep=1pt,color=blue] at (1,1) (abinv) {$\bullet$};
\node[below, inner sep=1pt, outer sep=1pt] at (ainv) {$\ginv a$};
\node[below, inner sep=1pt, outer sep=1pt] at (abinv) {$a\ginv b$};
\node[above, outer sep=1pt] at (binv) {$\ginv b$};
\draw[-,dashed,color=blue] (a) edge[out=20,  in=160] (abinv);
\draw[->,dashed,color=blue] (b) edge[out=110, in=160] (abinv);
\endtikzpicture
%%}}}
}
\botcaption{}
Os passos da resolução do~\ref[investigation_of_equivalence_mod_subgroup_case_2].
\endcaption
\endinsert
\noi
Vamos deduzir a contradição $b^{-1}\in H$.
Para conseguir isso, observamos que $a^{-1} \in H$ (pois $a\in H$),
e logo
$$
\overbrace{\underbrace{\vphantom{(}a^{-1}}_{\in H}\underbrace{(ab^{-1})}_{\in H}}^{\dsize b^{-1}} \in H.
$$
\noi
Achamos assim nossa contradição:
$$
b^{-1} = eb^{-1} = (a^{-1}a)b^{-1} = a^{-1}(ab^{-1}) \in H.
$$
Concluimos então que $ab^{-1} \nin H$, ou seja $a \ncong b \pmod H$.

%%}}}

%%{{{ x: do case 3 
\exercise.
%%%{{{ meta 
%%%}}}

Decida qual dos (i)--(iii) aplica no \proofcasestylize{caso 3} do~\reftag[investigation_of_equivalence_mod_subgroup].

\hint
Ache dois exemplos com $a,b\nin H$, tais que num
$a \cong b \pmod H$ e no outro $a \ncong b \pmod H$.

\hint
Um exemplo consiste em: um grupo $G$, um subgrupo $H\subgroup G$, e dois elementos $a,b\in G\setminus H$ tais que satisfazem (ou não) a congruência $a\cong b \pmod H$.

\hint
Procure teus exemplos no grupo dos inteiros com adição $\sset \ints +$.

\hint
Tome $G \leteq \sset \ints +$, $H \leteq 2\ints$, $a \leteq 1$, $b \leteq 3$
e observe que $1 \cong 3 \pmod {2\ints}$.

\hint
Não é possível achar o outro exemplo com o mesmo subgrupo $2\ints$,
mas pode sim no $3\ints$.

\solution
No grupo $G\leteq\sset \ints +$ considere seu subgrupo $H\leteq 5\ints$.
Temos:
$$
\xalignat2
\rightbrace {
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 6  
\endaligned
}
&\implies a \cong b \pmod H
&
\rightbrace {
\aligned
G&\leteq \sset \ints +\\
H&\leteq 5\ints\\
a&\leteq 1  \\
b&\leteq 3  
\endaligned
}
&\implies a \ncong b \pmod H,
\endxalignat
$$
porque $1 + (-6) = -5 \in 5\ints$ e $1 + (-3) = -2 \nin 5\ints$ respectivamente.

%%}}}

%%{{{ def: cosets 
\definition Coclasses.
%%%{{{ meta 
\label coset
\indexes
    * coset    see: coclasse
    ;;
\defines
    * H~a  -- o right-coset do $H\subgrp G$ através do $a\in G$
    * ~a H  -- o left-coset do $H\subgrp G$ através do $a\in G$
    * coclasse
    ;;
%%%}}}

Seja $G$ grupo e $H\subgrp G$.  Para $a\in G$ definimos
$$
\xalignat2
aH &\defeq \setst {ah} {h\in H}
&
Ha &\defeq \setst {ha} {h\in H}.
\endxalignat
$$
Chamamos o $aH$ a \dterm{coclasse esquerda} do $H$ através de $a$,
e similarmente o $Ha$ sua \dterm{coclasse direita}.
Também usamos os termos
\dterm{coclasse (lateral) à esquerda/direita},
e também chamamos as coclasses de \dterm{cosets}.

%%}}}

%%{{{ Q: What w \in Ha means? 
\question.
%%%{{{ meta 
%%%}}}

O que significa que algum $w \in Ha$?
Como podemos usá-lo se é dado?
Como podemos matá-lo se é alvo?

%%}}}

\spoiler

%%{{{ A: what_belonging_to_Ha_means 
\note Respostas.
%%%{{{ meta 
\label what_belonging_to_Ha_means
%%%}}}

Pela definição do conjunto $Ha$ com a notação set builder,
$$
w \in Ha \defiff \lexists {h\in H} {w = ha}.
$$
Então ganhando $w \in Ha$ como dado, nos permite ``sejar''
um tal membro de $H$: \emph{seja $h\in H$ tal que $w = ha$}.
E para matar esse alvo precisamos mostrar como escrever
nosso $w$ como produto de algum membro do $H$ e do $a$.
Ou seja, procuramos algo que encaixa no $\holed?$:
$$
w = \mubrace {\holed?} {\in H} a.
$$
Não esqueça: assim que achar um tal objeto que satisfaz
a equação acima, precisa demonstrar que ele pertence ao $H$.

%%}}}

%%{{{ warning: only_declare_variables_group_reminder 
\warning Declare apenas variáveis.
%%%{{{ meta 
\label only_declare_variables_group_reminder
%%%}}}

É comum escrever algo do tipo:
\quote
Seja $ha \in Ha$.
\endquote
Não escreva assim, pois é perigoso roubar sem querer!
Em vez disso, podes escrever:
\quote
Seja $w \in Ha$.  Logo seja $h \in H$ tal que $w = ha$.
\endquote
É provável que esse $w$ tem um papel ``bobo'' aí, e realmente
podemos evitá-lo:
o conjunto $Ha$ é um conjunto \emph{indexado pelo $H$}.
Então tudo que discutimos no~\ref[picking_elements_from_indexed_sets]
aplica, e nesse caso para tomar um arbitrário membro do $Ha$,
basta tomar um arbitrário membro $h\in H$:
\quote
Seja $h \in H$.
\endquote
\dots e já temos um arbitrário membro do $Ha$: o $ha$.

%%}}}

%%{{{ warning: what_does_Ha_eq_Hb_really_mean 
\warning.
%%%{{{ meta 
\label what_does_Ha_eq_Hb_really_mean
%%%}}}

Vamos supor que temos uns $a,b\in G$ e algum $H = \set{h_1,\dotsc,h_n}$.
Logo são definidos os
$$
\matrix
\format
\l &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
H  & =  & \{   & h_1,  & h_2,  & h_3,  & \dotsc, & h_n  & \}; \\
Ha & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \}; \\
Hb & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
\eop
(1) Agora suponha que sabemos que $Ha = Hb$:
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
É um \emph{erro grave} concluir que
$$
\matrix
\format
\c   &~\c~& \c\; & \c\;  & \c\;  & \c\;  & \c\;    & \c\; & \l \\
Ha   & =  & \{   & h_1a, & h_2a, & h_3a, & \dotsc, & h_na & \} \\
\veq &    &      & \veq  & \veq  & \veq  &         & \veq & \\
Hb   & =  & \{   & h_1b, & h_2b, & h_3b, & \dotsc, & h_nb & \}.
\endmatrix
$$
A igualdade desses conjuntos nos permite apenas concluir que
cada $h_ia$ é igual a um dos $h_jb$ e vice versa.  Nada mais!
\eop
(2) E agora suponha que queremos demonstrar que $Ha = Hb$.
Pela definição de igualdade de conjuntos, precisamos demonstrar $Ha \subset Hb$
e $Ha \supset Hb$.  Mas!  Se a gente conseguir demonstrar
que realmente para todo $i$, $h_ia = h_ib$, isso seria
ainda mais forte, e obviamente suficiente para concluir
que $Ha=Hb$, mas \emph{não necessário}.

%%}}}

%%{{{ x: What can we conclude if for some i, h_i a = h_i b?
\exercise.
%%%{{{ meta 
%%%}}}

O que podemos concluir se no (1) acima para \emph{algum} $i$,
$h_ia = h_ib$?

\solution
Que $a = b$ (pela~(GCL))---e logo que \emph{para todo} $i$,
$h_ia = h_ib$.

%%}}}

%%{{{ x: every_coset_is_nonempty 
\exercise.
%%%{{{ meta 
\label every_coset_is_nonempty
%%%}}}

Nenhuma coclasse de $H$ é vazia.

\solution
Qualquer coclasse de $H$ tem a forma $Ha$ ou $aH$ para
algum $a\in G$.  Observe que o proprio $a \in Ha$, pois
$$
a = \mubrace {e} {\in H} a \in Ha,
$$
e similarmente $a\in aH$.

%%}}}

%%{{{ x: Ha_eq_H_iff_a_in_H 
\exercise.
%%%{{{ meta 
\label Ha_eq_H_iff_a_in_H
%%%}}}

Sejam $G$ grupo, $H\subgrp G$, e $a \in G$.
$$
Ha = H \iff a \in H.
$$

\solution
\proofpart {\lrdir.}
Suponha $Ha = H$.
Como $e \in H$, então $ea \in Ha$, mas $ea = a$ e pronto.
Numa linha só:
$$
a = ea \in Ha = H.
$$
\crproofpart {\rldir.}
Suponha $a \in H$.
Para demonstrar $Ha = H$ separamos as duas direcções:
{\lrdirset}.
Seja $x \in Ha$, e logo seja $h \in H$ tal que $x = ha$.
Mas $a \in H$ e logo $ha \in H$ pois $H$ é fechado sob a operação do grupo.
Ou seja, $x\in H$.
{\rldirset}.
Seja $h \in H$.
Para mostrar que $h \in Ha$ procuramos $h' \in H$ tal que $h = h'a$.
Tome $h' \asseq h\ginv a$ e confirma que $h = h \ginv a a$,
e logo $h \in Ha$ pois $h\ginv a \in H$.
Sabemos disso pois $H$ sendo subgrupo de $G$ é fechado sob inversos
(logo $\ginv a \in H$) e pela operação também, e logo $h\ginv a \in H$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Uma conseqüência imediata do \ref[Ha_eq_H_iff_a_in_H] é que
$$
a \nin H \iff Ha \neq H.
$$
Mas assim que souber que $a\nin H$ podemos concluir
algo bem mais forte que $Ha \neq H$:

%%}}}

%%{{{ x: a_notin_H_implies_H_and_Ha_disjoint 
\exercise.
%%%{{{ meta 
\label a_notin_H_implies_H_and_Ha_disjoint
%%%}}}

O quê?  Como?

\hint
Podemos concluir que:
\emph{se $a \nin H\subgroup G$ então $H$ e $Ha$ são disjuntos.}

\solution
Podemos concluir que:
\emph{se $a \nin H\subgroup G$ então $H$ e $Ha$ são disjuntos:}
Suponha que $H$ e $Ha$ tem algum membro em comum $h$.
Vamos chegar numa contradição, demonstrando assim que
$H\inter Ha=\emptyset$.
Como $h \in Ha$, logo seja $h_1\in H$ tal que $h = h_1a$.
Passando o $h_1$ para o outro lado, temos
$$
\mubrace {\ginvp{h_1} h} {\in H} = \mubrace {a} {\nin H}
$$
que é absurdo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E se escolher um $b\in G$ fora do $H$ e fora do $Ha$?

%%}}}

%%{{{ x: every_coset_disjoint_from_all_others 
\exercise.
%%%{{{ meta 
\label every_coset_disjoint_from_all_others
%%%}}}

Mostre que se $a,b \in G$ tais que $b\nin Ha$
então $Hb$ e $Ha$ são disjuntos.
(Que $Hb$ e $H$ são disjuntos já sabemos graças
ao~\ref[a_notin_H_implies_H_and_Ha_disjoint].)

\solution
Suponha que $Ha$ e $Hb$ tem algum membro em comum $w$.
Logo sejam $h_a,h_b\in H$ tais que $w = h_a a$ e $w = h_b b$.
Logo
$$
h_a a = h_b b
$$
e passando o $h_b$ para o outro lado temos:
$$
\mubrace {\mubrace {\ginvp{h_b} h_a} {\in H} a} {\in Ha} = b
$$
que contradiz que $b \nin Ha$.

%%}}}

%%{{{ Q: How many cosets? 
\question.
%%%{{{ meta 
%%%}}}

\emph{Dados um grupo $G$ e $H\subgroup G$, quantas coclasses tem o $H$?
Ou seja, qual é a cardinalidade do conjunto $\setst {Ha} {a\in G}$?}

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver a resposta daqui a pouco (\ref[index_of_subgroup]
e~\ref[lagrange_theorem]).

%%}}}

%%{{{ df: cosetsL_and_cosetsR 
\definition.
%%%{{{ meta 
\label cosetsL_and_cosetsR
\defines
    * \cosetsL {~H}  -- a família das coclasses esquerdas do subgrupo $H$ (grupo implícito)
    * \cosetsR {~H}  -- a família das coclasses direitas do subgrupo $H$ (grupo implícito)
    ;;
%%%}}}

Vamos denotar a família de todas as coclasses esquerdas
e direitas do $H$ assim:
$$
\xalignat2
\cosetsL H &\defeq \setst {aH} {a \in G}; &
\cosetsR H &\defeq \setst {Ha} {a \in G}.
\endxalignat
$$
Observe que ambos os $\cosetsL H,\cosetsR H$ são indexados
pelo mesmo conjunto $G$.
Como o grupo $G$ é implícito pelo contexto não precisamos especificá-lo
na notação; mas caso que não é, escrevemos $\cosetsLin H G$ e
$\cosetsRin H G$ respectivamente.

%%}}}

%%{{{ lemma: cosets_form_a_partition 
\lemma.
%%%{{{ meta 
\label cosets_form_a_partition
\indexes
    * partição
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
A família de todas as coclasses direitas de $H$
é uma partição de $G$, e a mesma coisa é verdade
sobre a família das suas coclasses esquerdas.
Ou seja, cada uma das famílias $\cosetsL H$
e $\cosetsR H$ é uma partição do $G$.

\sketch.
Para a $\cosetsR H$, por exemplo, precisamos demonstrar:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \cosetsR H \supset G$;
          ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\li (P2): as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\li (P3): nenhuma coclasse é vazia ($\emptyset \nin \cosetsR H$).
\endtlist
Para o (P1) tomamos um arbitrário $x\in G$ e achamos
uma coclasse de $H$ que o $x$ esteja dentro.
O (P3) já demonstramos no~\ref[every_coset_is_nonempty].
Essencialmente demonstramos o (P2) também,
no~\ref[every_coset_disjoint_from_all_others].
Mas para variar, demonstramos que para todo $a,b \in G$,
$$
Ha \inter Hb \neq \emptyset \implies Ha=Hb.
$$
Tome um elemento comum $w\in Ha\inter Hb$.  Logo
$$
h_a a = w = h_b b
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Manipulamos a $h_a a = h_b b$ para mostrar que $Ha = Hb$.

\proof.
Vamos demonstrar que $\cosetsR H$ é uma partição do $G$.
A demonstração que $\cosetsL H$ também é, é similar.
Precisamos demonstrar:
% TODO: fix reflabs
\tlist:
\li (P1): $\Union \cosetsR H \supset G$;
          ou seja: para todo $x\in G$, existe coclasse $H'$ com $x \in H'$;
\li (P2): as coclasses no $\cosetsR H$ são disjuntas duas-a-duas;
\li (P3): nenhuma coclasse é vazia ($\emptyset \nin \cosetsR H$).
\endtlist
(P1) Como $H$ é um grupo, sabemos que $e\in H$, então para qualquer $x\in G$,
temos que $x = ex \in Hx$, ou seja todos os elementos de $G$ pertencem
àlguma coclasse.
(P3) Toda coclasse direita de $H$, tem a forma $Ha$ para algum $a\in G$,
e tem pelo menos um elemento: esse mesmo $a$ (a gente demonstrou
isso no~\ref[every_coset_is_nonempty]).
Para o (P2) suponha que $Ha\inter Hb\neq \emptyset$ e tome $w\in Ha\inter Hb$.
Logo
$$
h_aa = w = h_bb
\qqquad
\text{para alguns $h_a, h_b\in H$}.
$$
Para demonstrar que $Ha = Hb$, mostramos que $Ha\subset Hb$ e $Hb\subset Ha$.
Suponha então que $x \in Ha$, logo $x = ha$ para algum $h\in H$.
Precisamos mostrar que $x \in Hb$.
Calculamos:
$$
\align
x= ha
&= h\paren{\ginv {h_a} h_a}a\\
&= h\ginv {h_a} \paren{h_a a}\\
&= h\ginv {h_a} \paren{h_b b}\\
&= \paren{h \ginv {h_a} h_b}b\\
&\in Hb.
\endalign
$$
A outra direção ($Ha \supset Hb$) é similar.

%%}}}

%%{{{ thm: cosets_of_H_eq_quoset_G_congmodR 
\theorem.
%%%{{{ meta 
\label cosets_of_H_eq_quoset_G_congmodR
\indexes
    * partição
    * relação!de equivalência
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
A família $\cosetsR H = \setst {Ha} {a\in G}$ é uma partição do $G$
e sua correspondente relação de equivalência é a congruência $\congR H$
módulo-direito $H$.  Equivalentemente:
$$
\quoset G {\congR H} \;=\; \cosetsR H
$$

\proof.
Vamos denotar por $\eqclassimp a$ a classe de equivalência de
$a\in G$ (através da relação $\congR H$).
Queremos demonstrar que
$\quoset G {\congR H} = \cosetsR H$, ou seja
$$
\setst { \eqclassimp a } {a \in G}
=
\setst { Ha } {a \in G}.
$$
Esses conjuntos são indexados pelo mesmo conjunto (o $G$),
logo basta demonstrar que para todo $a\in G$, $\eqclassimp a = Ha$.
(Veja o~\ref[indexed_sets_equality].)
\crproofpart {\lrdirset:}
Suponha $x \in \eqclassimp a$.
Logo $x \cong a \pmod H$, ou seja, $x\ginv a \in H$.
Pela definição de $Ha$ então temos
$$
Ha\ni
\mubrace {\paren{x\ginv a}} {\in H} a
= x\paren{\ginv a a}
= x.
$$
\proofpart {\rldirset:}
Suponha que $x\in Ha$.
Logo $x=ha$ para algum $h\in H$ e queremos mostrar que $ha\in\eqclassimp a$,
ou seja $ha \cong a \pmod H$.
Confirmamos:
$$
\paren{ha} \ginv a
= h \paren{a\ginv a}
= h
\in H
$$
e pronto.

%%}}}

%%{{{ Q: Why the RIGHT cosets? 
\question.
%%%{{{ meta 
%%%}}}

Por que as coclasses \emph{direitas?}
Tudo até agora na nossa teoria foi justo e simétrico.
Nenhuma lei de grupo e nenhum resultado que demonstramos
favoreceu um lado ou o outro.
Imagine se a gente tivesse conseguido, por exemplo, demonstrar a lei
de cancelamento para um lado e não para o outro.  Seria bizarro,
pois todos os nossos dados trataram os dois lados na mesma maneira.
E, até pior, nossa relação de congruência já demonstramos que é simétrica!
Como pode ser então que ela favoreceu a família das coclasses direitas?
Por que o $\quoset G {\congR H}$ acabou sendo a partição $\cosetsR H$
e não a $\cosetsL H$?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Na questão acima tem uma mentira!
Tem uma coisa que usamos aqui que não tratou os dois lados em maneira igual!
É a relação de congruência módulo $H$!
No seu lado \emph{direito} aparece o inverso dum membro do grupo.
Por isso não seria justo usar a notação que temos usado!
Começando agora, vamos usar a notação justa e própria
$$
a \cong b \pmodR H \iff a\ginv b \in H \iff b\ginv a \in H.
$$

%%}}}

%%{{{ Q: How would you define pmodL ?
\question.
%%%{{{ meta 
%%%}}}

Como tu definarias (diretamente) a relação de equivalência que corresponde
à partição das coclasses esquerdas?

%%}}}

\spoiler

%%{{{ df: equivalence_mod_subgroup 
\definition Equivalência módulo subgrupo.
%%%{{{ meta 
\label equivalence_mod_subgroup
\defines
    * ~a \cong {~b} \pmodL {~H}  -- $a,b$ são equivalentes módulo-esquerdo $H \subgroup G$
    * ~a \cong {~b} \pmodR {~H}  -- $a,b$ são equivalentes módulo-direito $H \subgroup G$
    * ~a \congL {~H} {~b}  -- $a \cong b \pmodL H$
    * ~a \congR {~H} {~b}  -- $a \cong b \pmodR H$
    * equivalência!módulo subgrupo
    * módulo!subgrupo
    ;;
%%%}}}

Seja $G$ grupo e $H\subgroup G$.
Definimos
$$
\xalignat2
a \cong b \pmodL H &\defiff \ginv a b \in H; &
a \cong b \pmodR H &\defiff a \ginv b \in H.
\endxalignat
$$
Usamos também as notações $a \congL H b$ e $a \congR H b$.

%%}}}

%%{{{ remark: same is true for left cosets 
\remark.
%%%{{{ meta 
%%%}}}

Voltando ao~\ref[cosets_of_H_eq_quoset_G_congmodR],
simetricamente temos
$\quoset G {\congL H} = \cosetsL H$,
onde $\cosetsL H = \setst {aH} {a\in G}$.

%%}}}

%%{{{ x: a_ginvb_smells_like_division 
\exercise.
%%%{{{ meta 
\label a_ginvb_smells_like_division
%%%}}}

A operação $\tup{a,b} \mapsto a\ginv b$ tá aparecendo mais e mais.
Como tu chamaria essa operação binária?

\solution
Um nome que faz sentido pensar aqui seria \emph{divisão}, se pensar
multiplicativamente; e \emph{subtraição}, se pensar aditivamente.
Mas pra ser mais específicos ainda deveriamos mudar incluir como
adjectivo o lado: \emph{divisão direita} ou \emph{subtraição direita}.
Como assim divisão/subtraição ``direita''?  Nunca escutamos isso
antes, mas isso é porque nossa operação (multiplicação de números
ou adição de números) foi comutativa, então $a\ginv b$ e $\ginv b a$
eram sempre o mesmo número.  Mas aqui no contexto geral de grupo
podem ser diferentes, então faz sentido incluir os lados mesmo!

%%}}}

%%{{{ Does it still seem weird? 
\note.
%%%{{{ meta 
%%%}}}

Talvez ainda parece estranho:
o que a afirmação <<$a\ginv b \in H$>> tem a ver com a
<<os $a,b$ pertencem à mesma coclasse direita de $H$>>?
Observe que, se $a,b$ pertencem à mesma coclasse direita de $H$,
então para algum $c \in G$ temos $a,b \in Hc$, e logo
$a = h_a c$ e $b = h_b c$ para alguns $h_a, h_b \in H$.
Vamo lá:
$$
a \ginv b \in H
\iff
h_a c \ginvp{h_b c} \in H
\iff
h_a c \ginv c \ginv {h_b} \in H
\iff
h_a \ginv {h_b} \in H
\quad\text{que é verdade.}
$$
Conversamente,
$$
a\ginv b \in H
\implies
\paren{a \ginv b} b \in Hb
\implies
a \paren{\ginv b b} \in Hb
\implies
a \in Hb
$$
e logo $a,b$ pertencem à mesma coclasse de $H$: $a,b \in Hb$.
Espero que ficou mais claro agora.

%%}}}

%%{{{ Actors 
\note Atores.
%%%{{{ meta 
%%%}}}

Fixe um $a \in G$.  Como tu demonstraste
no~\ref[group_actors_are_bijective_proof], isso determina duas
funções $G \to G$, que no problema chamei de $f,g$.
Vamos relembrá-las e dar um nome e notação especial:

%%}}}

%%{{{ df: group_actors
\definition Atores.
%%%{{{ meta 
\label group_actors
%%%}}}

Sejam $G$ grupo e $a\in G$.  Considere as operações de
``operar com $a$ pela esquerda'' e pela direita
$$
\xalignat2
&\lam x {ax} & &\lam x {xa}.
\intertext{que vamos chamar de $a$-\dterm{ator} esquerdo e direito respectivamente.
As notações que vamos usar para essas funções são:}
\actorL a     & \eqtype G \to G & \actorR a     & \eqtype G \to G \\
\actorL a (x) & = ax            & \actorR a (x) & = xa. \\
\endxalignat
$$
Ainda mais, para todo par de membros $a,b\in G$ temos um ator definido pela
$$
\align
\actorS a b     &\eqtype G \to G \\
\actorS a b (x) &= axb.
\endalign
$$

%%}}}

%%{{{ x: actorS_as_composition_of_L_and_R 
\exercise.
%%%{{{ meta 
\label actorS_as_composition_of_L_and_R
%%%}}}

$\actorS a b = \actorL a \fcom \actorR b = \actorR b \fcom \actorL a$.

\solution
Sejam $a,b \in G$.
Calculamos:
\compute
\actorS a b x
&= axb                                    \by {def.~$\actorS a b$} \\
&= a(xb)                                  \by {assoc.} \\
&= a\paren{ \actorR b x }                 \by {def.~$\actorR b$} \\
&= \actorL a {\paren{ \actorR b x }}      \by {def.~$\actorL a$} \\
&= \paren{\actorL a \fcom \actorR b} (x). \by {def.~$\fcom$} \\
\endcompute
Demonstramos a outra igualdade similarmente.

%%}}}

%%{{{ lemma: group_actors_are_bijective 
\lemma.
%%%{{{ meta 
\label group_actors_are_bijective
%%%}}}

Todos as funções-atores são bijecções.

\proof \proofname~já feita no~\ref[group_actors_are_bijective_proof].

%}}}

%%{{{ lemma: cosets_are_equinumerous_finite_case 
\lemma.
%%%{{{ meta 
\label cosets_are_equinumerous_finite_case
%%%}}}

Todas as coclasses dum finito $H\subgrp G$ têm a mesma
quantidade de elementos com o próprio $H$ (e logo entre si também).

\sketch.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos demonstrar que a quantidade dos dois conjuntos acima
é a mesma.  Primeiramente, como poderia ser diferente?
Ambos parecem ter $n$ elementos, mas isso não garanta
cardinalidade $n$ pois pode ter repetições no $Ha$.
No $H$ não pode, pois definimos o $n$ para ser a cardinalidade de $H$.
Basta demonstrar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.

\proof.
Seja $n\in\nats = \card{H}$, e sejam $h_1,\dotsc,h_n$ os membros de $H$:
$$
\align
H  &= \set{h_1, h_2, h_3, \dotsc, h_n}.
\intertext{Para qualquer $a\in G$ temos}
Ha &= \set{h_1a, h_2a, h_3a, \dotsc, h_na}.
\endalign
$$
Queremos demonstrar que o $Ha$ também tem $n$ elementos.
Basta demonstrar então que os
$$
h_1a, h_2a, h_3a, \dotsc, h_na
$$
são distintos dois-a-dois, e logo, são $n$ também.
Mas isso é imediato:
\compute
h_ua = h_va
&\implies h_u = h_v \by {(GCR)} \\
&\implies u = v     \by {pois os $h_i$'s são distintos dois-a-dois} \\
\endcompute
A demonstração sobre as coclasses esquerdas é similar.

%%}}}

%%{{{ remark: cosets are equinumerous even when infinite 
\remark.
%%%{{{ meta 
%%%}}}

O~\ref[cosets_are_equinumerous_finite_case] é
válido até no caso que $H$ é infinito!
Mas não se preocupe agora com isso,
deixe para o~\ref[cosets_are_equinumerous].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos agora generalizar a notação que usamos as coclasses de
``multiplicação de subgrupo por elemento'' para
``multiplicação de subgrupo por subgrupo''.

%%}}}

%%{{{ df: HK_of_groups 
\definition.
%%%{{{ meta 
\label HK_of_groups
%%%}}}

Seja $G$ grupo e $H,K\subgroup G$.  Definimos
$$
HK \defeq \setst {hk} {h\in H,\ k\in K}.
$$

%%}}}

%%{{{ x: group_juxtaposition_is_associative 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre que a operação denotada por justaposição
no~\ref[HK_of_groups] é associativa.

%%}}}

%%{{{ Q: are HK and KH subgroups of G? 
\question.
%%%{{{ meta 
%%%}}}

$HK = KH$?
$HK \subgroup G$?
$KH \subgroup G$?

%%}}}

%%{{{ eg: calculate_HK_KH_S3 
\example.
%%%{{{ meta 
\label calculate_HK_KH_S3
%%%}}}

No grupo $\sym 3$, sejam seus subgrupos
$$
\xalignat2
H &\leteq \set{ \id, \phi }
&
K &\leteq \set{ \id, \psi\phi }.
\endxalignat
$$
Calcule os $HK$ e $KH$ e decida se $HK=KH$ e se $HK$ e $KH$ são subgrupos de $\sym 3$.

\solution.
Pela definição
$$
\xalignat2
HK &= \setst {hk} {h\in H,\ k\in K}
& 
KH &= \setst {kh} {h\in H,\ k\in K}
\\
&= \set{
\id\compose\id,
\id\compose(\psi\compose\phi),
\phi\compose\id,
\phi\compose(\psi\compose\phi)
}
&
&= \set{
\id\compose\id,
\id\compose\phi,
(\psi\compose\phi)\compose\id,
(\psi\compose\phi)\compose\phi)
}
\\
&= \set{ \id, \psi\phi, \phi, \phi\psi\phi }
&
&= \set{ \id, \phi, \psi\phi, \psi\phi^2 }
\\
&= \set{ \id, \psi\phi, \phi, \psi^2}
&
&= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
Observamos que $HK\neq KH$ (pois, por exemplo, $\psi \in KH$ mas $\psi \nin HK$).
E nenhum deles é subgrupo de $\sym 3$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então descobrimos que, em geral, nem $HK=KH$, nem $HK\subgroup G$,
nem $KH\subgroup G$ são garantidos.
Pode acontecer que $HK \subgroup G$ mas $KH \not\subgroup G$?
E o que a igualdade $HK=KH$ tem a ver com a ``subgrupidade'' dos $HK$ e $KH$?
Vamos responder em todas essas perguntas com o teorema seguinte:

%%}}}

%%{{{ thm: HK = KH <=> HK subgrp G 
\theorem.
%%%{{{ meta 
\label HK_equals_KH_iff_HK_subgroup
%%%}}}

Seja $G$ grupo e subgrupos $H,K \subgrp G$.  Então:
$$
HK = KH
\iff
HK \subgrp G
$$

\sketch.
Para a direção \lrdir, precisamos mostrar que $HK$ é fechado
sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e aplicando as propriedades
de grupo e nossa hipótese, mostramos que $(h_1k_1)(h_2k_2) \in HK$.
Similarmente para os inversos:
consideramos um arbitrário elemento $hk\in HK$ e mostramos que seu
inverso $\ginvp{hk} \in HK$.
Aqui, além da hipótese precisamos o~\ref[inverse_of_product_in_group].
Para a direção \rldir, mostramos as ``$\subset$'' e ``$\supset$''
separadamente, usando idéias parecidas.

\proof.
\lrdir:
Precisamos mostrar que $HK$ é fechado sobre a operação e fechado sobre os inversos.
Tomamos aleatórios $h_1k_1,h_2k_2\in HK$ e calculamos:
\compute
(h_1k_1)(h_2k_2)
&= h_1(k_1h_2)k_2 \by {ass.} \\
&= h_1(h_3k_3)k_2\quad\text{para alguns $h_3\in H$ e $k_3 \in K$} \by {$k_1h_2\in KH = HK$} \\
&= (h_1h_3)(k_3k_2)\by {ass.} \\
&\in HK
\endcompute
Para os inversos temos:
$$
\ginvp {h_1k_1} = \ginv{k_1} \ginv{h_1} \in KH = HK.
$$
\eop
\rldir:
Mostramos as ``$\subset$'' e ``$\supset$'' separadamente.
``$\subset$'':
Tome $x \in HK$, logo $x^{-1} \in HK$ e $x^{-1} = hk$ \emph{para alguns}
$h\in H$ e $k\in K$.  Como $H$ e $K$ são sub\emph{grupos} de $G$ seus inversos
também estão em $H$ e $K$ respectivamente.
Mas
$$
x = \ginvp{\ginv x} = \ginvp{hk} \ginv k \ginv h \in KH.
$$
``$\supset$'':
Tome $x \in KH$, logo $x = kh$ \emph{para alguns} $k\in K$, $h\in H$.
Logo $\ginv k \in K$ e $\ginv h \in H$.
Como $HK\subgrp G$, basta apenas demonstrar que $\ginv x \in HK$ pois isso
garantará que $x \in HK$ também.
Realmente, $\ginv x = \ginvp{kh} = \ginv h \ginv k \in HK$.

%%}}}

\endsection
%%}}}

%%{{{ Lagrange theorem 
\section O teorema de Lagrange.
%%%{{{ meta 
\label Lagrange_theorem
\credits
    * Lagrange : teorema
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Talvez não é tão óbvio que temos já descoberto um teorema interessante!
Ele é conhecido como \emph{teorema de Lagrange},
mesmo que não foi Lagrange que o demonstrou na sua generalidade,
mas apenas num caso especifico---mais detalhes nas notas históricas.
Vamos formular e demonstrar o teorema, mas primeiro uma definição simples
e relevante.

%%}}}

%%{{{ df: index_of_subgroup 
\definition Índice.
%%%{{{ meta 
\label index_of_subgroup
\defines
    * \altgroupind {~G} {~H}  -- $\groupind G H$ (notação alternativa)
    * \groupind {~G} {~H}  -- o índice do subgrupo $H$ no grupo $G$
    * grupo!índice de subgrupo
    ;;
%%%}}}

Sejam $G$ grupo e $H\subgroup G$.
O \dterm{índice} de $H$ no $G$ é o número de coclasses direitas de $H$ no $G$.
O denotamos com os símbolos $\groupind G H$ ou $\altgroupind G H$.

%%}}}

%%{{{ remark: it doesn't matter if you choose cosetsL or cosetsR 
\remark.
%%%{{{ meta 
%%%}}}

Escolhemos acima as coclasses direitas, mas isso não é essencial:
escolhendo as esquerdas o número ia sempre ser o mesmo,
como tu demonstrarás agora:

%%}}}

%%{{{ x: number_of_cosets_independend_of_side 
\exercise.
%%%{{{ meta 
\label number_of_cosets_independend_of_side
%%%}}}

Sejam $G$ grupo, $H\subgrp G$.
Demonstre que o número de coclasses à esquerda de $H$ é o mesmo
com o número de coclasses à direita de $H$:
$$
\card{\cosetsL H} = \card{\cosetsR H}.
$$

%%}}}

%%{{{ thm: lagrange_theorem 
\theorem Lagrange.
%%%{{{ meta 
\label lagrange_theorem
\credits
    * Lagrange : teorema
    ;;
\defines
    * teorema!Lagrange
    ;;
%%%}}}

Seja $G$ grupo finito e $H\subgroup G$.
Então $\groupord H \divides \groupord G$.

\proof.
Sabemos que o $G$ pode ser particionado pelos right cosets de $H$,
e que cada um deles tem a mesma cardinalidade $o(H)$ com o próprio $H$.
Logo,
$$
\gord G = \groupind G H \gord H,
$$
e temos o que queremos demonstrar.

%%}}}

%%{{{ remark: lagrange_reformulated 
\remark.
%%%{{{ meta 
\label lagrange_reformulated
%%%}}}

O teorema de Lagrange então afirma que
$$
\groupind G H  =  \card G / \card H.
$$

%%}}}

%%{{{ eg: HK and KH had no chances of being subgroups 
\example eles não tinham nenhuma chance de ser subgrupos.
%%%{{{ meta 
%%%}}}

No~\ref[calculate_HK_KH_S3] achamos que
$$
\xalignat2
HK &= \set{ \id, \psi\phi, \phi, \psi^2} &
KH &= \set{ \id, \phi, \psi\phi, \psi }.
\endxalignat
$$
E afirmamos que nenhum dos dois é subgrupo do $G$.
Por quê?
Em vez de fazer o trabalho tedioso e verificar se cada um
dos $HK,KH$ é um subgrupo do $\sym 3$, observamos que cada
um tem $4$ elementos---verifique que são \emph{realmente} $4$.
Mas, graças ao Lagrange~(\reftag[lagrange_theorem]) $\sym 3$ não
tem subgrupos de ordem $4$, pois $4$ não divide o $6$.  Pronto.

%%}}}

%%{{{ Corollaries as exercises 
\note Corolários.
%%%{{{ meta 
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Graças ao teorema de Lagrange~\reftag[lagrange_theorem]
ganhamos muitos corolários diretamente,
como tu vai verificar agora resolvendo os exercícios seguintes:

%%}}}

%%{{{ x: subgroups_of_group_with_prime_order_proof 
\exercise.
%%%{{{ meta 
\label subgroups_of_group_with_prime_order_proof
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Seja $G$ grupo com $\gord G = p$, onde $p$ primo.
Quais são todos os subgrupos de $G$?

\hint
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G$.  Quais são os divisores de $\gord G$?

\solution
Se $H\subgroup G$, pelo teorema de Lagrange temos que
$\gord H \divides \gord G = p$, logo $\gord H = 1$ ou $p$.
No primeiro caso $H = \set e$, no segundo, $H = G$.
Ou seja:
\emph{um grupo com ordem primo não tem subgrupos não-triviais}.

%%}}}

%%{{{ corollary: subgroups_of_group_with_prime_order 
\corollary.
%%%{{{ meta 
\label subgroups_of_group_with_prime_order
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Um grupo com ordem primo não tem subgrupos não-triviais.

\proof Demonstrado no~\ref[subgroups_of_group_with_prime_order_proof].

%%}}}

%%{{{ corollary: order_of_a_divides_order_of_G 
\corollary.
%%%{{{ meta 
\label order_of_a_divides_order_of_G
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Seja $G$ grupo finito e $a\in G$.  Então $\gord a \divides \gord G$.

\proof Demonstrarás no~\ref[order_of_a_divides_order_of_G_proof].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Já resolveste o~\ref[identifier_of_all]?
O próximo corolário oferece uma resolução mais elegante:

%%}}}

%%{{{ corollary: a_to_the_order_of_G_is_e 
\corollary.
%%%{{{ meta 
\label a_to_the_order_of_G_is_e
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Seja $G$ grupo finito e $a\in G$.
Então $a^{\gord G} = e$.

\proof Demonstrarás no~\ref[a_to_the_order_of_G_is_e_proof].

%%}}}

%%{{{ x: order_of_a_divides_order_of_G_proof 
\exercise.
%%%{{{ meta 
\label order_of_a_divides_order_of_G_proof
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Demonstre o~\ref[order_of_a_divides_order_of_G].

\hint
Se achar um subgrupo $H\subgroup G$ com $\gord H = \gord a$,
acabou (graças ao Lagrange).

\hint
Lembra que $\generate a$ é um subgrupo do $G$\dots?

\hint
\dots e que sua ordem é $\gord {\generate a} = \gord a$?

\solution
Sabemos que $\generate a$ é um subgrupo de $G$, com ordem
$\gord {\generate a} = \gord a$,
e pelo teorema de Lagrange, como $\generate a \subgroup G$
e $G$ é finito temos
$$
\gord a = \gord {\generate a} \divides \gord G.
$$

%%}}}

%%{{{ x: a_to_the_order_of_G_is_e 
\exercise.
%%%{{{ meta 
\label a_to_the_order_of_G_is_e_proof
\credits
    * Lagrange : corolário
    ;;
%%%}}}

Demonstre o~\ref[a_to_the_order_of_G_is_e].

\hint
\ref[order_of_a_divides_order_of_G].

\solution
Graças ao~\ref[order_of_a_divides_order_of_G] temos que
$\gord a \divides \gord G$, ou seja, $\gord G = k\gord a$ para algum
$k\in\ints$.
Agora calculamos:
$$
a^{\gord G}
= a^{k\gord a}
= a^{\gord a k}
= \paren{a^{\gord a}}^k
= e^k
= e.
$$

%%}}}

%%{{{ The idea behind Lagrange 
\note A idéia atrás do teorema de Lagrange.
%%%{{{ meta 
\credits
    * Lagrange
    ;;
%%%}}}

Temos um grupo finito $G$, e um subgrupo $H \subgrp G$.
Vamos conseguir arrumar \emph{todos os membros de $G$}
numa tabela:
$$
\matrix
\format
& \quad\c\quad & \quad\c\quad & \quad\c\quad & \ \ \c\ \  & \quad\c\quad \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet\\
& \phantom\bullet \\
& \vdots   & \vdots   & \vdots   & \ddots  & \vdots \\
& \phantom\bullet \\
& \bullet  & \bullet  & \bullet  & \dots   & \bullet
\endmatrix
$$
Sua primeira linha será feita por todos os membros de $H$.
Sabendo que $G$ é finito, temos que $H$ também é, e
logo essa primeira linha será finita também.
Vamos chamar $n$ a $\gord H$, e logo $h_1,\dots,h_n$
os $n$ membros de $H$.
Então a primeira linha tem tamanho $n$, e é a seguinte:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
\endmatrix
$$
Vamos mostrar como botar o resto dos membros de $G$ nessa tabela.
Na verdade, tem uma chance que não tem mais elementos para
botar: isso acontece se $H = G$.  Nesse caso não temos
mais nada pra fazer, já conseguimos o que queríamos.
Mas, no caso geral, existem membros de $G$ fora do $H$.
Seja $a\in G$ um deles, ou seja, $a \nin H$.
Agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
\endmatrix
$$
Agora \emph{afirmamos} sobre os elementos novos que:
\tlist:
\li: eles são realmente $n$, ou seja, distintos dois-a-dois;
\li: eles são realmente novos, ou seja, nenhum deles é igual àlgum
     dos membros que já estava na tabela.
\endtlist
Se demonstrar essas afirmações, saberemos que temos exatamente $2n$
membros de $G$ já arrumados na nossa tabela.
E depois?
Caso que $G$ não tenha mais elementos, não temos nada mais pra fazer,
pois já conseguimos o que queríamos.
Caso que tenha membros de $G$ fora deles, seja $a'\in G$ um deles,
ou seja, $a'$ não é nenhum dos membros já listados.
E agora bota todos os elementos seguintes na tabela:
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H\phantom{a''} &:
& h_1\phantom{a''}
& h_2\phantom{a''}
& h_3\phantom{a''}
& \dots
& h_n\phantom{a''}\\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'
\endmatrix
$$
Novamente, \emph{afirmamos} sobre os elementos novos que:
\tlist:
\li: eles são realmente $n$;
\li: eles são realmente novos.
\endtlist
\emph{E por aí vai.}
Sabemos que o processo vai terminar depois duma quantidade finita
de passos, pois o $G$ é finito.
Quando terminar então, teriamos conseguido arrumar todos os seus
membros numa tabela de largura $n$ e altura igual à quantidade
de coclasses direitas do $H$ no $G$, ou seja,
altura $m \asseq \groupind G H$.
$$
\matrix
\format
\l   &\l\qqquad & \l\quad & \l\quad & \l\quad & \l\quad & \l    \\
H    &:         & h_1     & h_2     & h_3     & \dots   & h_n   \\
Ha   &:         & h_1 a   & h_2 a   & h_3 a   & \dots   & h_n a \\
Ha'  &:         & h_1 a'  & h_2 a'  & h_3 a'  & \dots   & h_n a'\\
& \phantom\bullet \\
\phantom h\vdots&\phantom:& \phantom h\vdots& \phantom h\vdots & \phantom h\vdots & \ddots  & \phantom h\vdots\\
& \phantom\bullet \\
Ha'' &:         & h_1 a'' & h_2 a'' & h_3 a'' & \dots   & h_n a''
\endmatrix
$$
\eop
A única coisa que basta fazer então, é demonstrar todas as afirmações que
deixamos sem demonstração acima.
Mudando os nomes dos $a, a', \dots, a''$ para $a_2, a_3, \dots, a_m$,
queremos demonstrar para quaisquer $i,j\in\set{2,\dotsc,m}$ as seguintes:\foot
Talvez parece estranha a escolha de índices que começa com ${}_2$,
mas é muito conveniente aqui, pois o índice final ${}_m$ já seria a
própria altura da tabela.
Se ficou triste pela falta do $a_1$, tome $a_1\asseq e$ e vai dar certo:
a primeira coclasse de $H$ (o próprio $H$), seria o $Ha_1$ nesse caso.
Mas nada disso é necessário!
\toof
% TODO: fix reflabs
\tlist:
\li (1): $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente $n$, ou seja,
         distintos dois-a-dois;
\li (2): $h_1a_i, h_2a_i, \dotsc, h_na_i$ são realmente novos, ou seja:
         \tlist:
         \li (2.a): nenhum deles é igual àlgum dos $h_1,h_2,\dotsc,h_n$;
         \li (2.b): nenhum deles é igual àlgum dos $h_1a_j, h_2a_j, \dotsc, h_na_j$
                    para $j < i$.
         \endtlist
\endtlist
Nenhuma delas é difícil pra demonstrar---na verdade, \emph{nos já demonstramos} todas.\foot
A~(1) é o~\ref[cosets_are_equinumerous_finite_case];
a~(2) é o~(ii) do~\reftag[cosets_form_a_partition].
\toof
Mesmo assim, bora demonstrá-las novamente aqui com uns one-liners:
$$
\gather
h_ua_i = h_va_i \implies h_u = h_v \implies u=v;\tag{1}\\
h_ua_i = h_v    \implies a_i = \ginv{h_u}h_v \implies \text{$a_i \in H$, que é absurdo};\tag{2a}\\
h_ua_i = h_va_j \implies a_i = \ginv{h_u}h_va_j \implies \text{$a_i \in Ha_j$, que é absurdo}.\tag{2b}
\endgather
$$
Pronto!

%%}}}

%%{{{ warning: converse_of_lagrange_is_invalid 
\warning.
%%%{{{ meta 
\label converse_of_lagrange_is_invalid
%%%}}}

Não seja tentado para aplicar o \dq{recíproco};
sabendo que $d \divides \gord G$, \emph{não podemos concluir}
que o $G$ possui subgrupos de ordem $d$ (\ref[converse_of_lagrange_is_invalid_proof])

%%}}}

%%{{{ x: dividing_the_additive_group_of_ints 
\exercise dividindo o grupo aditivo dos inteiros.
%%%{{{ meta 
\label dividing_the_additive_group_of_ints
%%%}}}

Qual é o índice do $\sset {4\ints} + \subgrp \sset \ints +$?  Generalize para o $m\ints$.

%%}}}

%%{{{ x: dividing_the_additive_group_of_reals 
\exercise dividindo o grupo aditivo dos reais.
%%%{{{ meta 
\label dividing_the_additive_group_of_reals
%%%}}}

Qual o $\groupind {\sset \ints +} {\sset \reals +}$?

%%}}}

\endsection
%%}}}

%%{{{ Number_theory_revisited 
\section Teoria dos números revisitada.
%%%{{{ meta 
\label Number_theory_revisited
%%%}}}

%%{{{ x: the_multiplicative_group_Zp 
\exercise.
%%%{{{ meta 
\label the_multiplicative_group_Zp
%%%}}}

Seja $p$ primo e defina
$\cal Z_p = \sset {\finord p \setminus \set0} {\ntimes}$
onde $(\ntimes)$ é a multiplicação módulo~$p$.
Mostre que $\cal Z_p$ é um grupo e ache sua ordem.

%%}}}

%%{{{ x: the_multiplicative_group_Zn 
\exercise.
%%%{{{ meta 
\label the_multiplicative_group_Zn
%%%}}}

Seja $n\in\nats$ com $n>1$ e defina
$\cal Z_n = \sset {\setst {a \in \finord n} {\gcd a n = 1}} {\ntimes}$
onde $(\ntimes)$ é a multiplicação módulo~$n$.
Mostre que $\cal Z_n$ é um grupo e ache sua ordem.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
\credits
    * Euler    : teorema de congruência
    * Fermat   : Fermatinho
    * Lagrange : corolário
    ;;
\indexes
    * teorema!Fermatinho
    * corolário!de Lagrange
    ;;
%%%}}}

Já estamos em posição de ganhar o \dq{Fermatinho} (\ref[fermatinho])
e sua generalização, o teorema de congruências
de~Euler~\reftag[euler_congruence_theorem]
como um corolário fácil das nossas novas ferramentas grupoteóricas.

%%}}}

%%{{{ cor: euler_congruence_theorem_as_corollary_of_lagrange 
\corollary Teorema de Euler.
%%%{{{ meta 
\label euler_congruence_theorem_as_corollary_of_lagrange
\credits
    * Lagrange : corolário
    * Euler    : teorema de congruência
    ;;
%%%}}}

Sejam $a,m\in\ints$ com $\gcd a m = 1$.
Então
$$
a^{\tot m} \cong 1 \pmod m.
$$

\sketch.
Conseqüência do teorema de~{\Lagrange}Lagrange~\reftag[lagrange_theorem]
graças ao~\ref[the_multiplicative_group_Zn].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Ainda mais resultados podem ser derivados como
corolários do teorema de Lagrange:
no~\ref[euclids_theorem_as_corollary_of_lagrange]
por exemplo tu ganhas o fato que tem uma
infinidade de primos
(teorema de~\sayEuclid, \reftag[primes_is_infinite]).

%%}}}

\endsection
%%}}}

%%{{{ The_quotient_group 
\section O grupo quociente.
%%%{{{ meta 
\label The_quotient_group
%%%}}}

%%{{{ As soon as you've got a subgroup…
\note Assim que tiver um subgrupo….
%%%{{{ meta 
%%%}}}

Vamos começar com um certo grupo $G$, bagunçado assim:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Identificamos nele um subgrupo $H \subgroup G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$H$};
\endtikzpicture
$$
Assim que fizermos isso, o grupo toda se arruma em
dua maneiras, uma a partir das coclasses esquerdas
e uma a partir das direitas:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitionedmistake;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$

%%}}}

%%{{{ Q: what is wrong with the picture above? 
\question.
%%%{{{ meta 
%%%}}}

Tem algo errado na figura acima.
O que é?

%%}}}

\spoiler

%%{{{ A: we should have used different names 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não sabemos que cada um dos representantes que desenhamos
na partição $\cosetsL H$ vai acabar sendo um representante
da correspodente coclasse direita.  Pode ser, por exemplo
que o $q \in Hp$, e logo $Hp = Hq$.  Para formar a partição
escolhemos cada vez um membro fora das coclasses que já
formamos, mas ninguém garanta que andando pelas coclasses
esquerdas e escolhendo os $p,q,r,s,t,u,v$, vamos conseguir
escolher os mesmos como representantes das coclasses
direitas.
Em geral então, a imagem deve ser alterada para usar
nomes diferentes nos representantes, por exemplo:
$$
\xalignat2
\cosetsL H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpLpartitioned;
\endtikzpicture
\endgathered
&
\cosetsR H &=
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrpRpartitioned;
\endtikzpicture
\endgathered
\endxalignat
$$

%%}}}

%%{{{ eg: cosets_of_K_subgroup_S3 
\example.
%%%{{{ meta 
\label cosets_of_K_subgroup_S3
%%%}}}

Considere o subgrupo $K \subgroup \sym 3$:
$$
K \leteq \set{ \id, \psi\phi }.
$$
Calcule todos os left e right cosets de $K$ no $\sym 3$,
e decida se as duas colecções são iguais.

\solution.
Queremos calcular primeiramente todas as coclasses de $K$.
Como $\gord K = 2$, e o $G$ tem $6$ membros em total,
sabemos que o $K$ tem $3$ coclasses esquerdas, e $3$ coclasses direitas:
$$
\xalignat4
\text{esquerdas:} &  & K &= \set {\id, \psi\phi }  &   \holed? K &= \set{\holed?,\holed?}  &  \holed? K &= \set{ \holed?, \holed? }   \\
\text{direitas:}  &  & K &= \set {\id, \psi\phi }  &   K\holed?  &= \set{\holed?,\holed?}  &  K\holed?  &= \set{ \holed?, \holed? }
\endxalignat
$$
Vamos escolher o primeiro representante para escrever a primeira coclasse
esquerda ``própria'' de $K$.  Temos $4$ opções, pois se escolher qualquer
um dos dois membros do $K$, vamos ``cair'' na mesma coclasse $K$.
Escolhemos o $\psi$.
Calculamos:
$$
\psi K = \set { \psi, \psi\psi\phi } = \set { \psi, \psi^2\phi } = \set { \psi, \phi\psi }.
$$
Observe que seria a mesma coclasse esquerda, se tivemos escolhido o $\phi\psi$.
Vamos calcular a última.  Qual seria o represetante agora?
Precisamos evitar todos os membros de $K$ e de $\psi K$.
Vamos escolher o $\phi$, e bora calular o $\phi K$.  Ou não?
Não precisamos fazer nenhum cálculo, pois so sobraram $2$ membros de $\sym 3$,
então esses $2$ formam a última coclasse esquerda:
$$
\phi K = \set { \phi, \psi^2 }.
$$
Basta calcular as coclasses direitas agora.
Para a primeira, escolhemos de novo o $\psi$, já que observamos que $\psi\nin K$.
Calculamos:
$$
K \psi = \set { \psi, \psi\phi\psi } = \set { \psi, \phi }.
$$
Qual seria o representante ta próxima?
Aqui não pode ser novamente o $\phi$, pois o $\phi$ apareceu no $K\psi$.
Escolhemos um dos dois restantes então, vamos tomar o $\psi^2$,
e junto com o último restante ele forma a última coclasse direita:
$$
K \psi^2 = \set { \psi^2, \phi\psi }.
$$
Finalmente achamos todas:
$$
\xalignat2
\cosetsL K &= \set {
\aligned
     K &= \set {\id, \psi\phi}, \\
\psi K &= \set {\psi, \phi\psi}, \\
\phi K &= \set {\phi, \psi^2}
\endaligned
} & 
\cosetsR K &= \set {
\aligned
K       &= \set {\id, \psi\phi}, \\
K\psi   &= \set {\phi, \psi}, \\
K\psi^2 &= \set {\psi^2, \phi\psi}
\endaligned
}.
\endxalignat
$$
Para responder na pergunta, precisamos comparar as duas
\emph{colecções}, ou seja a pergunta é:
$$
\set{ K, \psi K, \phi K }
\askeq
\set{ K, K\psi, K\psi^2 }
$$
e facilmente observamos que não são iguais, pois, por exemplo,
$\psi K$ não é igual a nenhuma das coclasses direitas,
algo que verificamos comparando o conjunto $\psi K$
com cada um dos conjuntos $K, K\psi, K\psi^2$.

%%}}}

%%{{{ x: cosets_of_H_N_subgroup_S3 
\exercise.
%%%{{{ meta 
\label cosets_of_H_N_subgroup_S3
%%%}}}

Calcule todas as coclasses esquerdas e direitas dos
$$
\xalignat3
H &\leteq \set{ \id, \phi }&
N &\leteq \set{ \id, \psi, \psi^2 }
\endxalignat
$$
Quantas coclasses direitas diferentes cada um deles tem?
Quantas esquerdas?  Explique sua resposta.
A família $\cosetsR H$ de todas as coclasses direitas de $H$ é igual
à família $\cosetsL H$ de todas as esquerdas?
Similarmente para as $K$ e $N$.

%%}}}

%%{{{ notation 
\notation.
%%%{{{ meta 
%%%}}}

Observe que definimos os $aH$, $Ha$, e $HK$, num grupo $G$
para \emph{subgrupos} $H,K\subgroup G$.
Mas não usamos nenhuma propriedade de subgrupo mesmo.
Podemos realmente estender essa notação para arbitrários
\emph{subconjuntos} de $G$, e, por que não,
até usar notação como a seguinte abominagem:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
\defeq
\setst {g_1abg_2b'\ginv{g_3}a'g_1cb''}
{
a, a' \in A,\ 
b, b', b'' \in B,\ 
c \in C
}
$$
dados $g_1,g_2,g_3\in G$ e $A,B,C\subset G$.
Observe primeiramente que \emph{precisamos} usar variáveis diferentes
para cada instância de elemento de $A$, etc.
Observe também que todos esses objetos que escrevemos justaposicionando
elementos e subconjuntos de $G$ são subconjuntos de $G$ se usamos
pelo menos um subconjunto de $G$ na expressão:
$$
\xalignat2
g_1abg_5ab' &\in G &
g_1aBg_5ab' &\subset G.
\endxalignat
$$
Finalmente, \emph{confira} que graças à associatividade da operação do grupo $G$,
não precisamos botar parenteses:
$$
g_1ABg_2B\ginv{g_3}Ag_1CB
= g_1A(Bg_2B)\ginv{g_3}(Ag_1CB)
= (g_1A)(Bg_2)(B\ginv{g_3})(Ag_1)(CB)
= \dotsb
$$
etc.

%%}}}

%%{{{ df: normal_subgroup 
\definition Subgrupo normal.
%%%{{{ meta 
\label normal_subgroup
\indexes
    * normal    see: subgrupo normal
    ;;
\defines
    * ~N \normal ~G  -- $N$ é um subgrupo normal de $G$
    * subgrupo!normal
    ;;
%%%}}}

Seja $G$ grupo e $N\subgroup G$.
O $N$ é um \dterm{subgrupo normal} de $G$
sse a família das suas coclasses esquerdas
e a das suas coclasses direitas são iguais.
Em símbolos,
$$
N \normal G \defiff \cosetsL N = \cosetsR N.
$$

%%}}}

%%{{{ x: subgroup_of_abelian_is_normal 
\exercise.
%%%{{{ meta 
\label subgroup_of_abelian_is_normal
%%%}}}

Se $H \subgroup G$ num $G$ abeliano, então $H \normal G$.

%%}}}

%%{{{ x: cosets_of_subgroup_of_index_2 
\exercise.
%%%{{{ meta 
\label cosets_of_subgroup_of_index_2
%%%}}}

Se $H\subgroup G$ de índice $2$, então $H \normal G$.

\solution
Suponha $H\subgroup G$ com 
Precisamos mostrar que $aH = Ha$ para todo $a\in G$.
Como o índice de $H$ é 2, só tem 2 cosets, logo, fora do próprio $H$, seu
complemento $G\setminus H$ tem que ser um coset.
Agora para qualquer $aH$ com $a \nin H$, temos
$$
aH = G\setminus H = Ha.
$$

%%}}}

%%{{{ The quotient group 
\note.
%%%{{{ meta 
%%%}}}

Acabamos de identificar certos subgrupos dum grupo $G$---que chamamos
\dterm{normais}---com uma propriedade legal:
a colecção de todas as suas coclasses esquerdas é a mesma com
a colecção de todas as suas coclasses direitas.
(Na verdade a situação é bem mais legal que isso---continue lendo.)
Começando então com um $N\normal G$, podemos falar \emph{da} partição
correspodente de $G$, sem especificar se estamos considerando a colecção
das coclasses esquerdas ou das direitas.
Ou seja, nesse caso, as relações de equivalência
$$
\dhole \cong \dhole \pmodL N
\qqqqtext{e}
\dhole \cong \dhole \pmodR N
$$
são a \emph{mesma} relação:

%%}}}

%%{{{ df: congruence_mod_N 
\definition congruência módulo subgrupo.
%%%{{{ meta 
\label congruence_mod_N
\defines
    * ~a \cong ~b \pmod ~N  -- $a,b$ são congruentes módulo o subgrupo normal $N$
    * congruência!módulo subgrupo
    * módulo!subgrupo
    ;;
%%%}}}

Sejam $G$ grupo e $N \normal G$.
Definimos a relação binária
$$
\dhole \cong \dhole \pmod N
$$
que chamamos de \dterm{congruência módulo $N$}.

%%}}}

%%{{{ As soon as we have a normal subgroup… 
\note Assim que tiver um subgrupo normal….
%%%{{{ meta 
\indexes
    * conjunto!quociente
    ;;
%%%}}}

Vamos começar com um certo grupo $G$:
$$
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpinsidemess;
\endtikzpicture
$$
Agora identificamos nele um subgrupo \emph{normal} $N\normal G$.
Assim que fizermos isso, todo o $G$ se arruma
graças à partição de todas as coclasses de $N$:
$$
\gathered
\tikzpicture
\tikzi quogrpbase;
\tikzi quogrpoutsidemess;
\tikzi quogrpsubgroupelems;
\node at (N) {$N$};
\endtikzpicture
\endgathered
\qquad\leadsto\qquad
\gathered
\tikzpicture
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned;
\endtikzpicture
\endgathered
$$
E agora comece se afastar mais e mais, até não dá mais pra ver
os pontinhos \emph{dentro} dessas classes, e até as próprias
classes viram pontinhos:
$$
\tikzpicture
\tikzi quogrpzoomout;
\endtikzpicture
$$
Denotamos esse conjunto por $\quogrp G N$:
$$
\quogrp G N = \setst {Ng} {g \in G}
$$
Observe que esse conjunto é o
\emph{conjunto quociente} de $G$
através da relação de congruência módulo $N$.\foot
Lembra-se que dada qualquer relação de equivalência
num conjunto, definimos seu conjunto quociente?
Não?!  Corra para a~\ref[quoset].
\toof

%%}}}

%%{{{ So what? 
\note E daí?.
%%%{{{ meta 
%%%}}}

Isso é válido mesmo se o $N$ não fosse normal:
podemos definir os (dois) conjuntos quocientes
$\quoset G {\congL N}$ e $\quoset G {\congR N}$.
Mas assim estamos esquecendo \emph{a alma} do $G$:
o $G$ é um \emph{grupo}.
Desde o~\ref[Relations] (\reftag[quoset]) sabemos que podemos
dividir um \emph{conjunto} (por uma relação de equivalência)
e o resultado (quociente) é novamente o mesmo tipo de coisa:
\emph{conjunto}.
Aqui dividimos um \emph{grupo} e o quociente foi o quê?
A melhor coisa que podemos dizer é\dots~\emph{conjunto!}
Péssimo!  O resultado perdeu seu alma!
Por isso os subgrupos normais são \emph{muito} legais:
o quociente retenha a alma do grupo original!

%%}}}

%%{{{ What is stopping us, exactly? 
\note O que exatamente é o problema?.
%%%{{{ meta 
%%%}}}

Suponha então que temos um $H \subgrp G$.
Gostariamos de definir a operação $\ast$ no
$\quoset G {\congL H}$ em tal forma que
$$
aH \ast bH \pseudodefeq (a \ast_G b)H.
$$
O problema é que a operação $\ast$ que estamos
tentando definir não tem acesso nos $a,b$ das suas entradas $aH,bH$
respectivamente, e logo o seu valor $aH \ast bH$ não pode depender
das escolhas desses representantes.
Ou seja, \emph{não temos como demonstrar que $\ast$ é bem-definida},
e logo \emph{não podemos usar a igualdade acima como definição 
de operação}---por isso o $\pseudodefeq$.
Voltando no desenho anterior a situação ficará mais clara;
vou pintar todos os membros da $aH$ de vermelho e todos os
membros da $bH$ de azul:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\endtikzpicture
$$
Querendo usar a ``definição'' da operação $\ast$ acima
escolhemos o $a \in aH$ e o $b \in bH$ e procuramos
o $a \ast_G b$; vamos dizer que achamos aqui no $gH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node[text=magenta] at (ab) {$\bullet$};
\node at (ab) {\pointL {ab}};
\endtikzpicture
$$
agora escolhendo \emph{outros representantes} $a',b'$ das
$aH,bH$
(onde pelo menos uma das $a'\neq a$ e $b'\neq b$ é válida)
procuramos o $a' \ast_G b'$.  O que acontece se ele
não pertence à mesma coclasse $gH$?
Talvez caiu na $cH$:
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned2colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node[text=magenta] at (ab)  {$\bullet$};
\node[text=magenta] at (ab0) {$\bullet$};
\node at (ab)  {\pointL {ab}};
\node at (ab0) {\pointL {a'b'}};
\endtikzpicture
$$
Assim a $\ast$ \emph{não é bem-definida} (e logo
o $\quoset G {\congL H}$ não tem nenhuma chance de
virar grupo com ela.
É exatamente isso que aproveitamos nos subgrupos \emph{normais:}
eles não deixam isso acontecer, pois garantam que
o produto de quaisquer representantes das $aH,bH$ vai sempre
cair dentro da mesma coclasse, e logo apenas a $gH$ será pintada
roxa aqui no nosso desenho
$$
\tikzpicture[scale=2]
\tikzi quogrppartitionednonames;
\tikzi quogrppartitioned3colors;
\tikzi quogrpLpartitioned;
\node at (a2)  {\pointL {a'}};
\node at (b2)  {\pointL {b'}};
\node at (ab2) {\pointL {a'b'}};
\node at (ab)  {\pointL {ab}};
\endtikzpicture
$$
e logo aqui teriamos
$$
aH \ast bH = gH \quad \bigparen{= (ab)H}.
$$

%%}}}

%%{{{ beware: not_well_defined_function_danger_quogrp 
\beware.
%%%{{{ meta 
\label not_well_defined_function_danger_quogrp
\indexes
    * função!bem-definida
    ;;
%%%}}}

Caso que o problema de não ser bem-definida não é óbvio,
primeiramente volte a re-estudar os:
\ref[not_well_defined_function_danger_argument_name_dependence]
e~\ref[not_well_defined_function_danger_choice_dependence].
Agora observe que o $aH$ é na verdade um membro $a$ de $G$
\emph{operado} com um subgrupo $H$ de $G$; e isso resulta
num certo subconjunto de $G$: uma coclasse (esquerda) de $H$.
\eop
Então: as entradas da $\ast$ são coclasses esquerdas de $H$,
por exemplo podem ser as
$$
\xalignat2
aH &\eqass \set{a,a_1,a_2,a_3,a_4,a_5} &
bH &\eqass \set{b,b_1,b_2,b_3,b_4,b_5}
\endxalignat
$$
e agora
$$
\set{a,a_1,a_2,a_3,a_4,a_5}
\ast
\set{b,b_1,b_2,b_3,b_4,b_5}
= ?
$$
Observe que aqui temos
$$
\xalignat2
aH &= a_1H = \dotsb = a_5H &
bH &= b_1H = \dotsb = b_5H.
\endxalignat
$$
Parece então que tentamos definir a $\ast$ pela
$$
A \ast B = (ab)H,\quad
\text{onde $a$ é algum membro de $A$ e $b$ de $B$}
$$
mas para essa ser uma definição de função mesmo
temos uma tarefa para fazer:
\emph{precisamos demonstrar que seu valor $A \ast B$
não depende das escolhas desses ``representantes'' $a$ e $b$}
(\ref[not_well_defined_function_danger_choice_dependence]).
Até conseguir demonstrar isso, não podemos considerar a
$\ast$ uma função \emph{bem-definida}.
Vamos voltar se preocupar com o mesmo tipo de coisa logo
no~\ref[not_well_defined_function_danger_firstiso].

%%}}}

%%{{{ Q: How can we turn the quotient set into a group? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir uma operação interessante $\ast$
nos elementos de $\quogrp G N$, tal que o
$\sset {\quogrp G N} \ast$ vira um grupo?
Qual seria sua identidade?
Para cada um dos seus membros, qual seria o seu inverso?
Para cada dois dos seus membros, qual seria o seu produto?

%%}}}

\spoiler

%%{{{ df: quogrp 
\definition Grupo quociente.
%%%{{{ meta 
\label quogrp
\defines
    * \quogrp {~G} {~N}  -- o grupo quociente de $G$ módulo $N$
    * grupo!quociente
    ;;
%%%}}}

Sejam $G$ grupo e $N \normal G$.
O conjunto
$$
\quoset G {\congmod N}
\quad
\bigparen{ =
\mubrace {\setst { aN } { a \in G }} {\cosetsL N}
=
\mubrace {\setst { Na } { a \in G }} {\cosetsR N}
}
$$
com operação a $\ast$ definida pela
$$
Na \ast Nb \defeq N(ab)
$$
é chamado o \dterm{grupo quociente de $G$ módulo $N$},
e é denotado por $\quogrp G N$.
\mistake

%%}}}

%%{{{ Q: Everything alright with quogrp ? 
\question.
%%%{{{ meta 
%%%}}}

Tá tudo bem com a~\ref[quogrp]?

%%}}}

\spoiler

%%{{{ A: No: you must prove that it is well-defined: 
\blah Resposta.
%%%{{{ meta 
%%%}}}

A operação $\ast$ não é automaticamente ``bem-definida''
(como discutimos no \ref[not_well_defined_function_danger_quogrp]):
precisamos demonstrar que realmente seu valor não
depende da escolha dos representantes $a$ e $b$.
Falei ``precisamos''?  Quis dizer \emph{precisas}.
Agora:

%%}}}

%%{{{ x: nop_is_well_defined 
\exercise.
%%%{{{ meta 
\label nop_is_well_defined
%%%}}}

Demonstre que a $\ast$ definida acima é bem-definida.

\hint
Basta demonstrar que qualquer escolha de representante envolvida
não afetará o resultado.

\hint
Basta demonstrar que para quaisquer $a,a',b,b'\in G$ temos:
$$
\rightbrace {
\mathcoled {
aN &= a'N \\
bN &= b'N
}
}
\implies
(ab)N = (a'b')N
$$

\hint
Temos que $N \normal G$ e logo $a'N = Na'$ e $b'N = Nb'$.

\solution
Sejam $a,a',b,b'$ tais que $aN = a'N$ e $bN = b'N$,
e como $N \normal G$ temos
$aN = a'N = Na'$ e
$bN = b'N = Nb'$.
Basta demonstrar que $(ab)N = (a'b')N$.
Demonstramos apenas a direção \lrdirset (a outra é similar).
\eop
\lrdirset:
Precisamos mostrar que um arbitrario membro do $(ab)N$ pertence ao $(a'b')N$.
Seja $n \in N$.  O $abn$ então já é um arbitrário membro do $(ab)N$.
Basta demonstrar que $abn \in (a'b')N$, ou seja escrevê-lo na forma:
$$
abn = a'b'\mubrace {\askbox} {\in N}.
$$
Calculamos:
\compute
abn
&= an'b'    \by {onde $n'   \in N$ tal que $bn  = n'b'$     (pela $bN=Nb'$)} \\
&= a'n''b'  \by {onde $n''  \in N$ tal que $an' = a'n''$    (pela $aN=a'N$)} \\
&= a'b'n''' \by {onde $n''' \in N$ tal que $n''b' = b'n'''$ (pela $Nb'=b'N$)}
\endcompute

%%}}}

\TODO Sobre bem-definido por argumento.

%%{{{ lemma: operation_for_cosets_of_normal 
\lemma.
%%%{{{ meta 
\label operation_for_cosets_of_normal
%%%}}}

Sejam $G$ grupo, $N \normal G$, e $a,b \in G$.
$$
(Na)\ast(Nb) = (Na)(Nb) \quad \Bigparen{= \setst {uv} {u \in Na, v \in Nb}}
$$

\sketch.
Como $(Na)\ast(Nb) = N(ab)$, mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
Sem detalhes, temos
$$
\xalignat2
&
\aligned
g \in (Na)(Nb)
&\implies g = (n_a a) (n_b b) \\
&\implies g = n_a (a n_b) b \\
&\impliesbecause{$^{(\normal)}$} g = n_a (n_b' a) b \\
&\implies g = \mubrace {\mubrace{(n_a n_b')} {\in N} (a b)} {\in N (ab)}
\endaligned
&&
\aligned
g \in N(ab)
&\implies g = n(ab)\\
&\implies g = \mubrace{\mubrace{(na)} {\in Na} \mubrace{\vphantom(b\vphantom)} {\in Nb}} {\in (Na)(Nb)}
\endaligned
\endxalignat
$$
onde os nomes das variáveis introduzidas devem indicar uns
dos detalhes omitidos.

\proof.
Mostramos cada direção da
$$
g \in (Na)(Nb) \iff g \in N(ab)
$$
separadamente.
\crproofpart {\lrdir}.
Suponha $g \in (Na)(Nb)$.
Logo sejam $a'\in Na$ e $b' \in Nb$ tais que $g = a'b'$.
Pelas definições dos $Na$ e $Nb$, sejam $n_a,n_b \in N$
tais que $a' = n_a a$ e $b' = n_b b$.
Logo temos
$$
g = (n_a a) (n_b b) = n_a (a n_b) b
$$
Mas como $a n_b \in aN$ e $aN = Na$ (pois $N\normal G$),
temos que $a n_b$ = $n_b' a$ para algum $n_b' \in N$.
Logo
$$
g = n_a (n_b' a) b = (n_a n_b') (a b) \in N (ab)
$$
pois $n_a n_b' \in N$.
\crproofpart {\rldir}.
Suponha $g \in N(ab)$.
Logo seja $n\in N$ tal que $g = n(ab)$.
Logo temos
$$
g = n(ab) = (na)b \in (Na)(Nb)
$$
pois $na \in Na$ e $b \in Nb$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Para merecer esse nome, o $\quogrp G N$ deve ser um grupo mesmo.
Vamos demonstrar isso agora.

%%}}}

%%{{{ thm: quogrp_is_a_group 
\theorem.
%%%{{{ meta 
\label quogrp_is_a_group
%%%}}}

Sejam $G$ grupo e $N\normal G$.
O $\quogrp G N$ é um grupo.

\sketch.
Graças ao~\ref[onesided_group_def], basta verificar que
$\quogrp G N$ com sua operação (\ref[quogrp]) satisfaz uma
definição unilateral de grupo: (G0), (G1), (G2L), (G3L).
Observe que o $\quogrp G N$ é indexado pelo $N$,
e logo para solicitar um membro arbitrário do $\quogrp G N$,
basta tomar um arbitrário membro $a \in N$.
\crproofpart {(G0):}
Sejam $a,b \in N$.
Realmente $(Na)(Nb) = N(ab) \in \quogrp G N$.
\crproofpart {(G1):}
Sejam $a,b,c \in N$.
Calculando verificamos que $((Na)(Nb))(Nc) = (Na)((Nb)(Nc))$.
\crproofpart {(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
O candidato óbvio é o próprio $N = Ne$.
Basta confirmar essa afirmação, ou seja, mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
\crproofpart {(G3L):}
Para mostrar que cada um dos membros de $\quogrp G N$ tem um inverso esquerdo,
seje $a \in N$ e mostre como achar um inverso esquerdo de $Na \in \quogrp G N$.
Aqui o candidato que faz sentido considerar é o $N(\ginv a)$.

\proof.
Graças ao~\ref[onesided_group_def], basta verificar que
$\quogrp G N$ com sua operação (\ref[quogrp]) satisfaz uma
definição unilateral de grupo: (G0), (G1), (G2L), (G3L).
\proofpart {(G1):}
Sejam $a,b,c \in N$.
Calculamos:
$$
\bigparen{(Na)(Nb)}(Nc)
= \bigparen{N(ab)}(Nc)
= N\paren{(ab)c}
= N\paren{a(bc)}
= (Na)\bigparen{N(bc)}
= (Na)\bigparen{(Nb)(Nc)}.
$$
\proofpart {(G2L):}
Procuramos um membro de $\quogrp G N$ que satisfaz a lei de identidade esquerda.
Afirmação: o $N \in \quogrp G N$ é uma identidade esquerda do $\quogrp G N$.
Para demonstrar essa afirmação precisamos mostrar que para todo $a \in N$,
temos $N(Na) = Na$.
Realmente, seja $a \in N$.
Calculamos:
$$
N(Na) = (Ne)(Na) = N(ea) = Na.
$$
\proofpart {(G3L):}
Seja $a \in N$.
Afirmação: o $N(\ginv a)$ é um inverso esquerdo de $Na$.
Para demonstrar essa afirmação precisamos verificar que:
$$
(N(\ginv a)) (Na) = N.
$$
Calculamos:
$$
\paren{N(\ginv a)}(Na)
= N(\ginv a a)
= Ne
= N
$$
e pronto.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Seria importante se convencer que essa coisa legal realmente não
é compartilhada por subgrupos não-normais.
Faça agora o:

%%}}}

%%{{{ x: not_normal_subgroup_makes_soulless_quoset 
\exercise.
%%%{{{ meta 
\label not_normal_subgroup_makes_soulless_quoset
%%%}}}

Mostre que para qualquer $H \not\normal G$ as $\congL H$ e
$\congR H$ não são congruências e logo nenhum dos
$\quoset G {\congL H}$ $\quoset G {\congR H}$ pode virar
um grupo com a alma do $G$.

%%}}}

%%{{{ Congruences 
\note Congruências.
%%%{{{ meta 
\label congruences
%%%}}}

Teve mais algo dessatisfatório com as relações $\congL H$
e $\congR H$ baseadas num $H \subgroup G$, mesmo que ambas
são relações de equivalência sim!  Eles não são garantidas
pra ser\dots~\emph{congruências:}

%%}}}

%%{{{ df: congruence_in_group 
\definition congruência (em grupo).
%%%{{{ meta 
\label congruence_in_group
%%%}}}

Uma relação de equivalência $\sim$ num grupo $\ssetfont G = \sset G {\ast, \ginv{}, \gid}$
é uma \dterm{congruência} de $G$ sse $\sim$ é \dterm{compatível com a estrutura} do $\ssetfont G$:
\mathcol
\cforall {a,b,a',b' \in G}  {a \sim b \mland a' \sim b' \implies a \ast a' \sim b \ast b'} \\
\cforall {a,b \in G}        {a \sim b \implies \ginv a \sim \ginv b} \\
                          & \gid \sim \gid. \\
\endmathcol

%%}}}

%%{{{ remark: automaticly compatible with gid 
\remark.
%%%{{{ meta 
%%%}}}

Observe que a última linha não oferece absolutamente nada na definição
de \emph{congruência} pois a $\sim$ sendo relação de equivalência é reflexiva.

%%}}}

%%{{{ corollary: congmod_N_is_a_congruence 
\corollary.
%%%{{{ meta 
%%%}}}

Se $N \normal G$ então $\congmod N$ é uma congruência.

\proof Demonstrado no \ref[nop_is_well_defined].

%%}}}

%%{{{ x: congL_and_congR_not_congruences_counterexample 
\exercise.
%%%{{{ meta 
\label congL_and_congR_not_congruences_counterexample
%%%}}}

Mostre grupo $G$ e $H \subgroup G$ tais que $\congL H$ e $\congR H$
não são congruências.

%%}}}

\endsection
%%}}}

%%{{{ Normal_subgroups 
\section Subgrupos normais.
%%%{{{ meta 
\label Normal_subgroups
%%%}}}

%%{{{ intro 
\secintro
Na~\ref[The_quotient_group] definimos os
\emph{subgrupos normais} como aqueles cujas coclasses
esquerdas e direitas formam a mesma partição.
Aqui encontramos umas definições equivalentes que
superficialmente parecem bastante diferentes.
%%}}}

%%{{{ df: normal_equivalent_definitions 
\definition definições de normal.
%%%{{{ meta 
\label normal_equivalent_definitions
\defines
    * subgrupo!normal
    ;;
%%%}}}

As afirmações seguintes são equivalentes (e logo cada
uma pode servir como definição de $N \normal G$):
$$
N \normal G
\defiff
N \subgrp G
\mland
\text{qualquer uma das:}\ \ 
\leftbrace {
\aligned
\text{(i)}~   & \cosetsL N = \cosetsR N \\
\text{(ii)}~  & \congL N \;=\; \congR N \\
\text{(iii)}~ & \text{$N$ é fechado pelos conjugados} \\
\text{(iv)}~  & \lforall {g\in G} {gN\ginv g \subset N} \\
\text{(v)}~   & \lforall {g\in G} {gN\ginv g = N} \\
\text{(vi)}~  & \lforall {g\in G} {gN = Ng},
\endaligned
}
$$
lembrando que $\cosetsL N$ e $\cosetsR N$ são as colecções de left
e right cosets de $N$ respectivamente (\ref[cosetsL_and_cosetsR]),
e $\congL N$ e $\congR N$ as equivalências módulo-esquerdo e
módulo-direito $N$ respectivamente (\ref[equivalence_mod_subgroup]).
Se demonstrar tudo isso---algo que vamos fazer junto logo---seria
massa pois:
cada vez que vamos ter como dado que $N \normal G$, a gente
vai ganhar \emph{toda} essa afirmação de graça; e dualmente,
cada vez que vamos querer demonstrar que $N \normal G$, a gente
vai ter a liberdade de escolher qualquer uma dessas e pronto!

%%}}}

%%{{{ x: which_normal_altdef_will_never_be_our_goal 
\exercise.
%%%{{{ meta 
\label which_normal_altdef_will_never_be_our_goal
%%%}}}

Qual dessas não faria sentido escolher nunca querendo demonstrar
que $N \normal G$?

\hint
A $\lforall {g\in G} {gN\ginv g = N}$.  Por quê?

\solution
A $\lforall {g\in G} {gN\ginv g = N}$, pois escolhendo
a $\lforall {g\in G} {gN\ginv g \subset N}$, a gente teria
menos trabalho pra fazer.

%%}}}

%%{{{ closed_under_conj_meaning 
\note Fechado pelos quê?.
%%%{{{ meta 
\defines
    * fechado!pelos conjugados
    ;;
%%%}}}

O que significa \emph{fechado pelos conjugados?}
Significa \emph{fechado sob a relação de conjugação};
em símbolos:
\mathcol
\cforallt {n \in N}    {todos os conjugados do $n$ pertencem ao $N$} \\
\intertext{ou seja,}
\pforall {n \in N}   & \lforall {g \in G} { gn\ginv g \in N }. \\
\endmathcol

%%}}}

%%{{{ remark: closed_under_conjugation_swap_quantifiers 
\remark trocando a ordem dos quantificadores.
%%%{{{ meta 
\label closed_under_conjugation_swap_quantifiers
%%%}}}

Observe que podemos trocar a ordem dos quantificadores
pois são do mesmo tipo:
$$
\pforall {n\in N}
\lforall {g\in G}
{ gn\ginv g \in N }
\iff
\pforall {g\in G}
\mubrace {
\lforall{n\in N}
{ gn\ginv g \in N }
}
{ gN\ginv g \subset N }.
$$
Vamos dar uma olhada detalhada agora,
caso que a parte sublinhada acima pareceu estranha.
Lembre-se como tomamos membros arbitrários dum conjunto
indexado (\ref[picking_elements_from_indexed_sets]
e~\ref[only_declare_variables_group_reminder]).
Demonstrando a afirmação
\mathcol
\cforallt {n \in N} {algo sobre o $gn\ginv g$} \\
\intertext{ganhamos que todos os membros do $gN\ginv g$ satisfazem
esse algo, pois o conjunto $gN\ginv g$ é indexado por o $N$.
Aqui o algo é o <<pertencer ao $N$>>.
Ou seja:}
\cforall  {n \in N} {gn\ginv g \in N} \\
\endmathcol
afirma que todos os membros de $gN\ginv g$ pertencem ao $N$,
ou seja, $gN\ginv g \subset N$.

%%}}}

%%{{{ thm: normal_equivalent_definitions_are_equivalent 
\theorem.
%%%{{{ meta 
\label normal_equivalent_definitions_are_equivalent
\indexes
    * subgrupo!normal
    ;;
%%%}}}

Sejam $G$ grupo, e $N\subgroup G$.
Os (i)--(vi) da~\ref[normal_equivalent_definitions] são
equivalentes.

\proof.
\proofpart {(i)\tiff(ii).}
Demonstrado no~\ref[Relations] (veja \ref[eqrel_quoset_partition_summary]).
\crproofpart {(iii)\tiff(iv).}
Demonstrado no~\ref[closed_under_conjugation_swap_quantifiers].
\crproofpart {(iv)\tiff(v).}
A {\rldir} é trivial, pois o que precisamos demonstrar
($N \normal G$) é obviamente uma afirmação mais fraca da nossa hipótese.
Para a {\lrdir}, suponha $N \normal G$ e seja $g\in G$.
Já temos a inclusão $gN\ginv g \subset N$, então só basta demonstrar
a $N \subset gN\ginv g$.  Seja $n \in N$.
Como $n \in N$ e $N$ normal, temos $\ginv g n \ginvp{\ginv g} \in N$.
Logo
$$
\mubrace {g \paren{\ginv g n \ginvp{\ginv g}} \ginv g} {=n} \in gN\ginv g.
$$
\crproofpart {(iii)\timplies(vi)}
Tome $n \in N$; assim $gn\ginv g$ é
um arbitrário membro do $gN\ginv g$.
Basta mostrar que $gn\ginv g \in N$.
Mas $gn \in gN = Ng$ e logo $gn = n'g$ para algum
$n' \in N$.
Calculamos:
$$
gn\ginv g = n'g \ginv g = n' \in N.
$$
\crproofpart {As outras implicações são pra ti:}
\ref[normal_equivalent_definitions_are_equivalent_rest_of_proof].

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um corolário bem útil da (vi) é o seguinte:

%%}}}

%%{{{ cor: normal_commutes_with_every_subset_via_subset_product 
\corollary.
%%%{{{ meta 
\label normal_commutes_with_every_subset_via_subset_product
%%%}}}

Sejam $G$ grupo, $N \normal G$.
Para todo $A \subset G$, $AN = NA$.

\proof.
Numa linha só:
$$
AN = \Union_{a \in A} aN = \Union_{a \in A} Na = NA.
$$

%%}}}

%%{{{ beware: g n g^{-1} \neq n 
\beware.
%%%{{{ meta 
%%%}}}

Se tivemos $N \normal G$ temos sim que $gn\ginv g \in N$ para todo $n\in N$,
mas isso \emph{não garanta} que $gn\ginv g = n$ não!
Sabemos que para todo $n\in N$, temos $gn\ginv g = n'$ \emph{para algum}
$n' \in N$, mas nada nos permite concluir que esse $n'$ é nosso $n$.
Isso quis dizer que em geral não podemos demonstrar que
$$
\align
\famst {gn\ginv g} {n\in N} &= \famst {n} {n\in N}
\intertext{como famílias indexadas por o mesmo conjunto $N$, mas mesmo
assim conseguimos demonstrar que os \emph{conjuntos} são iguais sim:}
\setst {gn\ginv g} {n\in N} &= \setst {n} {n\in N},
\intertext{ou seja,}
gN\ginv g &= N.
\endalign
$$
Parecidamente, sabendo que $gN=Ng$ e tendo um $n\in N$, \emph{não}
podemos concluir que $gn=ng$, mas pelo menos sabemos que
$$
gn = n'g,
\quad\text{para algum $n' \in N$}.
$$

%%}}}

%%{{{ x: gnginvg_neq_n 
\exercise.
%%%{{{ meta 
\label gnginvg_neq_n
%%%}}}

Ache um contraexemplo que mostra que não necessariamente
$gn\ginv g = n$, mesmo com $n\in N \normal G$.

%%}}}

%%{{{ x: normal_equivalent_definitions_are_equivalent_rest_of_proof 
\exercise.
%%%{{{ meta 
\label normal_equivalent_definitions_are_equivalent_rest_of_proof
%%%}}}

Demonstre o que falta para estabelecer que todas
as (i)--(vi) do~\ref[normal_equivalent_definitions_are_equivalent]
são equivalentes.

%%}}}

%%{{{ x: subset_product_of_subgroup_and_normal_is_subgroup 
\exercise.
%%%{{{ meta 
\label subset_product_of_subgroup_and_normal_is_subgroup
%%%}}}

Se $S \subgroup G$ e $N\normal G$, então $SN \subgroup G$.

\hint
\proofalt{Maneira 1:}
imediato pelos:
\ref[HK_equals_KH_iff_HK_subgroup] e~\ref[normal_commutes_with_every_subset_via_subset_product].
\crproofalt{Maneira 2:}
Use o ``one-test''~\ref[subgroup_one_test].
Observe que
$SN$ é indexado pelo conjuto $S\times N$ e logo basta tomar
um arbitrário par $\tup{s,n} \in S \times N$ para ganhar
um arbitrário membro do $SN$: o $sn$.

\hint
Se escolheste investigar a segunda maneira da dica anterior:
\eop
Tome $s_1,s_2 \in S$ e $n_1,n_2 \in N$; assim o $s_1n_1$
e $s_2n_2$ são dois arbitrários membros do $SN$.
Basta demonstrar que $(s_1n_1)\ginvp{s_2n_2} \in SN$.

%%}}}

%%{{{ x: inter_of_subgroup_and_normal_is_normal_in_subgroup 
\exercise.
%%%{{{ meta 
\label inter_of_subgroup_and_normal_is_normal_in_subgroup
%%%}}}

Se $S \subgroup G$ e $N\normal G$, então $S \inter N \normal S$.

\hint
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\reftag[intersection_of_subgroups_is_a_subgroup]
e~\reftag[subgroup_is_an_order]).
Para mostrar que $S \inter N \normal S$,
tente demonstrar que $S\inter N$ é fechado pelos conjugados no $S$.

\solution
Temos $S \inter N \subgroup N \subgroup G$ como intersecção de subgrupos
(veja exercícios~\reftag[intersection_of_subgroups_is_a_subgroup]
e~\reftag[subgroup_is_an_order]).
Basta mostrar que $S \inter N \normal S$,
ou seja, que $S\inter N$ é fechado pelos conjugados no $S$.
Tome $x \in S\inter N$ e $h\in S$.
Temos:
\compute
h x \ginv h &\in S  \by {$S \subgroup G$} \\
h x \ginv h &\in N  \by {$N \normal G$} \\
\endcompute
Logo $hx\ginv h \in S \inter N$.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: converse_of_lagrange_is_invalid_proof 
\problem.
%%%{{{ meta 
\label converse_of_lagrange_is_invalid_proof
%%%}}}

Justifique o~\ref[converse_of_lagrange_is_invalid]:
mostre um grupo $G$ e um divisor $d \divides \gord G$
tal que $G$ não possui nenhum subgrupo de ordem $d$.

%%}}}

%%{{{ prob: euclids_theorem_as_corollary_of_lagrange 
\problem Teorema de Euclides.
%%%{{{ meta 
\label euclids_theorem_as_corollary_of_lagrange
\credits
    * Euclid   : infinidade dos primos
    * Lagrange : corolário
    ;;
%%%}}}

Mostre como demonstrar o teorema de Euclides~\reftag[primes_is_infinite]
como um corolário de Lagrange.

\hint
Para chegar num absurdo, suponha que $P$ é o maior primo.
Considere o número $2^P - 1$.

\hint
Como o $2^P - 1$ não é primo,
seja $q$ um fator primo do $2^P - 1$.
Então
$$
2^P - 1 \cong 0 \pmod q.
$$

\hint
Temos
$$
2^P \cong 1 \pmod q.
$$
O que podemos concluir sobre a ordem de $2$ no grupo\dots
Em qual grupo mesmo?

%%}}}

%%{{{ prob: wilsons_theorem_proof_using_groups 
\problem Teorema de Wilson.
%%%{{{ meta 
\label wilsons_theorem_proof_using_groups
\credits
    * Wilson : teorema
    ;;
%%%}}}

Demonstre o teorema de Wilson
$$
\text{$n$ é primo} \iff \facp{n-1} \cong -1 \pmod n
$$
usando o conhecimento da teoria dos grupos até agora.

%%}}}

%%{{{ prob: cosets_are_equinumerous 
\problem.
%%%{{{ meta 
\label cosets_are_equinumerous
%%%}}}

Demonstre o~\ref[cosets_are_equinumerous_finite_case]
mesmo quando $H$ é infinito.

\hint
Sendo o $H$ infinito, basta demonstrar que o $Ha$ também é?

\hint
Deixe a pergunta da dica anterior para o~\ref[Cantors_paradise].
Por enquanto, demonstre uma bijecção entre $H$ e $Ha$.

\hint
A restricção (\ref[fresto]) no $H$ do $a$-ator direito (\ref[group_actors]).

\hint
Já sabemos que é injetora (\ref[group_actors_are_bijective]).
Basta demonstrar que é sobre o $Ha$.

\solution
Seja $a\in G$.
Basta demonstrar que $Ha$ e $H$ têm a mesma quantidade de elementos
(a demonstração sobre as coclasses esquerdas é similar).
Vamos fazer isso mostrando uma bijecção entre os dois conjuntos.
Primeiramente observe que a função $\actorR a : G \to G$
é injetora (\ref[group_actors_are_bijective])
e logo sua restricção $\actorR a \resto {H}$ também é.
Basta mostrar que ela é sobrejetora no $Ha$.
Seja $d \in Ha$, e logo pela definição de $Ha$ seja $h \in H$
tal que $d = ha$.
Temos então $\actorR a \resto {H} (h) = d$,
e logo $\actorR a \resto {H}$ é sobrejetora no $Ha$.

%%}}}

%%{{{ prob: one_congruence_implies_normal 
\problem.
%%%{{{ meta 
\label one_congruence_implies_normal
%%%}}}

Seja $G$ grupo e $N \subgrp G$ tal que $\congL N$ ou $\congR N$
é uma congruência (\ref[congruence_in_group]).
A afirmação $N \normal G$ é correta?
Responda \wq{sim} e demonstre; ou \wq{não} e refuta;
ou \wq{talvez} e mostre um exemplo e um contraexemplo.

%%}}}

%%{{{ prob: subgroup_product_of_normal_is_normal 
\problem.
%%%{{{ meta 
\label group_subset_product_of_normal_is_normal
%%%}}}

Sejam $G$ grupo e $N,M \normal G$.
Afirmação:
$$
NM \normal G.
$$
Se a afirmação é demonstrável demonstre; se é refutável refute;
caso contrário mostre que não é nem demonstrável nem refutável.

\hint
A afirmação é válida;
demonstre.

\hint
Mostre que $NM$ é fechado pelos conjugados.

%%}}}

\endproblems
%%}}}

%%{{{ Symmetries 
\section Simetrias.
%%%{{{ meta 
\label Symmetries
%%%}}}

%%{{{ eg: [symmetry_eg] flip around a bisector 
\example.
%%%{{{ meta 
\label symmetry_eg
%%%}}}

A transformação $T$ que gira o triangulo por volta do
eixo mostrado por um ângulo $\pi$, é uma simetria
do triangulo.
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=red] (-.5,0.866) -- (B) -- (C);
\draw[color=blue] (-.5,0.866) -- (A) -- (C);
\node[color=blue,xshift=-3mm] at (A) {$A$};
\node[color=red,xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw[color=blue] (-.5,0.866) -- (B) -- (C);
\draw[color=red] (-.5,0.866) -- (A) -- (C);
\node[color=red,xshift=-3mm] at (A) {$B$};
\node[color=blue,xshift=-2mm,yshift=1mm] at (B) {$A$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (1,0) -- +(150:2.5cm);
\draw[dashed] (1,0) -- +(330:5mm);
\endtikzpicture
\endgathered
$$

%%}}}

%%{{{ What is a symmetry? (1) 
\note O que é uma simetria (1).
%%%{{{ meta 
%%%}}}

Ok, então <<simetria>> é uma \emph{transformação} que leva uma forma
geométrica para outra, tal que o resultado fica exatamente em cima
da forma original: se desenhar a forma-depois em cima da forma-antes,
cada ponto da forma-depois vai cair em cima dum ponto da forma-antes.
Isso é bem informal, mas nosso objectivo não é estudar simetrias
geométricas neste momento, apenas dar uma intuição com
``palavras da rua'' então essa descripção deve servir para nos guiar.
Mas isso \emph{não é suficiente} para chamar uma transformação de
simetria.

%%}}}

%%{{{ noneg: [symmetry_noneg] flip just the base 
\nonexample.
%%%{{{ meta 
\label symmetry_noneg
%%%}}}

Considere a transformação $T'$
que deixa todos os pontos dos lados $AB$ e $AC$ em paz,
mas vira todos os pontos do interior do $BC$ para a outra direção:
$$
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=red] (-.5,0.866) -- (B);
\draw[color=blue] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.2) node [pos=.666] {\rotator{150}};
\endtikzpicture
\endgathered
\qquad
\text{vira assim pela $T'$:}
\qqquad
\gathered
\tikzpicture
\node[inner sep=0pt] at (0,1.732)   (A) {};
\node[inner sep=0pt] at (-1,0)      (B) {};
\node[inner sep=0pt] at (1,0)       (C) {};
\node[inner sep=0pt,outer sep=0pt] at (0,0.577) (G) {};
\draw (A) -- (C) -- (B);
\draw[color=blue] (-.5,0.866) -- (B);
\draw[color=red] (-.5,0.866) -- (A);
\node[xshift=-3mm] at (A) {$A$};
\node[xshift=-2mm,yshift=1mm] at (B) {$B$};
\node[xshift=2mm,yshift=2mm] at (C) {$C$};
\draw[dashed] (0,.577) -- +(150:1.0);
\endtikzpicture
\endgathered
$$

%%}}}

%%{{{ Q: What would you add to exclude symmetry_noneg ?
\question.
%%%{{{ meta 
%%%}}}

O que tu adicionaria na ``definição'' de simetria acima
para excluir transformações como essa do~\ref[symmetry_noneg]?

%%}}}

\spoiler

%%{{{ What is a symmetry? (2) 
\note O que é uma simetria (2).
%%%{{{ meta 
\defines
    * isometria
    ;;
%%%}}}

Observe que existe uma diferença importante entre a transformação
do~\ref[symmetry_eg] e aquela do~\ref[symmetry_noneg]:
a primeira \emph{preserva as distâncias}, a segunda não.
Vamos chamar as transformações $T$ e $T'$ respectivamente.
Tome quaisquer dois pontos $x,y$ no triângulo, e meça sua
distância $d(x,y)$.
A transformação $T$ garanta que
$$
d(x,y) = d(Tx, Ty)
$$
para todos os $x,y$, mas a $T'$ não:
existem $x,y$ tais que $d(x,y) \neq d(T'x, T'y)$.
Isso é o que faltou da nossa primeira tentativa de dizer
o que é uma simetria:
ela tem que \emph{preservar as distâncias},
ou seja, ser uma \dterm{isometria}.

%%}}}

%%{{{ x: Show that symmetry_noneg is not a symmetry 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre (informalmente no desenho) que a transformação $T'$
do~\ref[symmetry_noneg] não é uma simetria.

\hint
Ela não é uma isometria.
Demonstre!

\hint
Precisa achar dois pontos $p,q$ no triângulo tal que
a distância $d(p,q) \neq d(T'p, T'q)$.

%%}}}

%%{{{ Q: Which are all the symmetries of an equilateral triangle? 
\question.
%%%{{{ meta 
%%%}}}

Quais são todas as simetrias dum triângulo equilátero?

%%}}}

\spoiler

%%{{{ dih3_symmetries 
\note As simetrias dum triângulo equilátero.
%%%{{{ meta 
\label dih3_symmetries
%%%}}}

Fixa um triângulo equilátero.
Aqui todas as suas simetrias:
$$
\xalignat3
&\tikzpicture
\tikzi dih3base;
\draw[dashed] (0,1.732) -- +(270:2.5cm) node [pos=0.83] {\rotator{90}};
\draw[dashed] (0,1.732) -- +(90:5mm);
\node (label) at (-.5, -.5) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (-1,0) -- +(30:2.5cm) node [pos=0.83] {\rotator{30}};
\draw[dashed] (-1,0) -- +(210:5mm);
\node (label) at (1.1, 1.5) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\draw[color=white,dashed] (0,1.732) -- +(270:2.5cm);
\draw[color=white,dashed] (0,1.732) -- +(90:5mm);
\tikzi dih3base;
\draw[dashed] (1,0) -- +(150:2.5cm) node [pos=0.83] {\rotator{150}};
\draw[dashed] (1,0) -- +(330:5mm);
\node (label) at (-1.0, 1.5) {$\Delta_3$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:210:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{2\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3rotbase;
\draw[->] (0,.877) arc (90:330:0.3);
\node (label) at (-.9, 1.1) {$R_{\frac{4\pi}3}$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih3base;
\node (label) at (-1.1, 1.1) {$I$};
\endtikzpicture
\endxalignat
$$
Tem $6$ simetrias então
$$
\Delta_1, \Delta_2, \Delta_3, R, R', I
$$
onde escrevemos $R$ e $R'$ para as $R_{\frac{2\pi}3}$
e $R_{\frac{4\pi}3}$ respectivamente.

%%}}}

%%{{{ Q: How can we turn dih3 into a group? 
\question.
%%%{{{ meta 
%%%}}}

Como podemos definir uma operação no conjunto de todas as simetrias
dum triângulo equilateral, tal que ele vira um grupo?

%%}}}

\spoiler

%%{{{ df: dih_n 
\definition Os grupos dihedrais.
%%%{{{ meta 
\label dih_n
\indexes
    * dihedral    see: grupo dihedral
    ;;
\defines
    * grupo!dihedral
    ;;
%%%}}}

O \dterm{grupo dihedral} $\dih n$ (também $\dihalt n$)
é o grupo das simetrias dum $n$-gono regular, com operação
a composição $\fcom$ (vendo as simetrias como
transformações---ou seja, funções):
$B \fcom A$ é a simetria que criamos aplicando primeiramente
a $A$ e depois a $B$.\foot
Alternativamente escrevemos isso como
$A \dcom B$ (notação diagramática,~\reftag[diagrammatic_notation]).
Tendo esclarecido qual das~$\fcom$ e~$\dcom$ usamos---e com
a mesma preguiça notacional que temos elaborado
em vários outros casos até agora---escrevemos simplesmente $AB$,
denotando assim a operação do grupo com justaposição.
\toof

%%}}}

%%{{{ x: dih_n is indeed a group 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que o $\dih n$ realmente é um grupo.

%%}}}

%%{{{ x: dih_4 
\exercise.
%%%{{{ meta 
\label dih_4
%%%}}}

Ache todas as simetrias dum quadrado.

\hint
São $8$.

\solution
Aqui todas as simetrias dum quadrado:
$$
\xalignat4
&\tikzpicture
\tikzi dih4base;
\node at (label) {$I$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:90:.4);
\node at (label) {$R$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:180:.4);
\node at (label) {$R'$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4rotbase;
\draw[->] (.4,0) arc (0:270:.4);
\node at (label) {$R''$};
\endtikzpicture
\\
&\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,-1.07) -- (1.07,1.07) node [pos=0.5] {\rotator{45}};
\node at (label) {$\Delta_1$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.07,1.07) -- (1.07,-1.07) node [pos=0.5] {\rotator{-45}};
\node at (label) {$\Delta_2$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (-1.2,0) -- (1.2,0) node [pos=0.5] {\rotator{0}};
\node at (label) {$H$};
\endtikzpicture
&&
\tikzpicture
\tikzi dih4base;
\draw[dashed] (0,-1.2) -- (0,1.2) node [pos=0.5] {\rotator{90}};
\node at (label) {$V$};
\endtikzpicture
\endxalignat
$$

%%}}}

%%{{{ x: gord_dih_n 
\exercise.
%%%{{{ meta 
\label gord_dih_n
%%%}}}

Qual a $\gord{\dih n}$?

%%}}}

%%{{{ Dih n notation warning 
\warning.
%%%{{{ meta 
%%%}}}

O que simbolizamos aqui por $\dih n$ em certos textos aparece
como $\dih {2n}$.  A gente botou a quantidade $n$ de ângulos do
$n$-gono no índice do símbolo, mas tem gente que bota a quantidade
de simetrias do $n$-gono como índice, e como tu acabou de ver
no~\ref[gord_dih_n], essa quantidade é $2n$.
De qualquer forma, nenhuma dessas notações é standard.\foot
Mesmo assim, a nossa notação faz mais sentido, pois:
(i) quando definimos o grupo dihedral $\dih n$ já sabemos a quantidade
de ângulos ($n$) mas por enquanto não sabemos quantos membros esse
grupo tem (até resolver o~\ref[gord_dih_n]);
(ii) já temos uma notação para a ordem dum grupo,
então não perdemos acesso nela optando para o nosso $\dih n$.
\toof
Então tome cuidado quando tu encontra em outros textos
o símbolo $\dih m$.\foot
Se o $m$ é ímpar, não existe ambigüidade.  Óbvio?
\toof

%%}}}

%%{{{ What a discovery!  Or is it? 
\note Que descoberta!  Ou não?.
%%%{{{ meta 
%%%}}}

Então, nosso amigo chegou feliz com sua descoberta
desse grupo interessante.
Mas, mais cedo ou mais tarde, a gente com certeza vai perceber algo:
esse grupo $\dih 3$ \emph{parece ser} o $\sym 3$!
Nosso amigo não achou um grupo realmente novo e original,
mas apenas re-descobriu o grupo $\sym 3$ que conhecemos
desde o início desse capítulo!
Em qual sentido os dois grupos ``são praticamente a mesma coisa''?
Esse é o assunto da~\ref[Group_morphisms],
mas podemos já dar uma primeira resposta informal:
\emph{como grupos, eles comportam no mesmo jeito}.

%%}}}

%%{{{ Are they equal then? 
\note Então são iguais?.
%%%{{{ meta 
%%%}}}

Não!
A palavra certa para esse caso é \dterm{isómorfos} ou
\dterm{isomórficos}, que já encontramos no contexto de
conjuntos~(\ref[isomorphic_sets]).
Lembre-se que isómorfos são aqueles que têm a mesma forma
(\ref[etymology_of_isomorphic]), mas também que o que significa
``forma'' depende do contexto.
Aqui seria \emph{a estrutura de grupos}.
Grupos isómorfos têm exatamente as mesmas \emph{propriedades grupoteóricas}.

%%}}}

%%{{{ Group-theoretic properties 
\note Propriedades grupoteóricas.
%%%{{{ meta 
\label grouptheoretic_properties
\defines
    * propriedade!grupoteórica
    ;;
%%%}}}

Essas são propriedades que o grupista consegue enxergar com
seus olhos grupoteóricos.
Uns exemplos:
\tlist:
\li: \wq{ele tem membro cuja ordem é $2$};
\li: \wq{ele é cíclico};
\li: \wq{ele tem dois membros que são seus próprios inversos};
\li: \wq{ele possui $3$ subgrupos normais};
\li: \wq{ele tem exatamente $4$ membros}.
\endtlist
A última talvez não parece ser muito grupoteórica, mas de fato
o grupista entende essa afirmação---talvez se reformulá-la como
\wq{ele tem ordem $4$} não vai parecer estranho.
Uns nãœxemplos:
\tlist:
\li: \wq{seus membros são conjuntos};
\li: \wq{seus membros são números};
\li: \wq{ele tem membro que é singleton};
\endtlist
Por outro lado, o conjuntista, com seus olhos conjuntoteóricos
consegue enxergar todas as diferenças entre o $\dih 3$ e $\sym 3$:
de fato, ele vai responder que são diferentes---e ainda mais:
disjuntos!
Os membros do $\dih 3$ são transformações dos pontos dum plano;
os membros do $\sym 3$ são permutações, ou seja,
bijecções de $\set{1,2,3}$ para $\set{1,2,3}$.
\eop
E para o grupista?
\emph{O que são} e \emph{quais são} os membros de grupo é irrelevante.
Ele não tá nem aí sobre a natureza dos membros, ou seus nomes,
ou sua aparência!
O que importa pra ele são suas propriedades grupoteóricas e nada mais:
o inverso desse é aquele; o produto desses é aquilo;
a identidade é essa; este aqui é um gerador; estes aqui são conjugados;
tem tantos com ordem $n$;
etc.

%%}}}

%%{{{ eg: why dih 4 is not isomorphic with sym 4
\example.
%%%{{{ meta 
%%%}}}

O $\dih 4$ não é isómorfo com o $\sym 4$.

\solution.
Como $\gord{\dih 4} = 8 \neq 24 = \gord{\sym 4}$,
já sabemos que os dois grupos não são isomórficos.

%%}}}

%%{{{ x: why dih 4 is not isomorphic with Z/8Z 
\exercise.
%%%{{{ meta 
%%%}}}

Explique porque o $\dih 4$ não é isómorfo com o grupo aditivo
$\ints_8$ dos inteiros com adição módulo $8$.

\solution
Basta achar uma propriedade grupoteórica que um dos dois grupos tem
e o outro não.  Uns exemplos:
\tlist:
\li: \wq{{\thole} é abeliano}:
     satisfeita por $\ints_8$ mas não por $\dih 4$;
\li: \wq{{\thole} é cíclico}:
     satisfeita por $\ints_8$ mas não por $\dih 4$;
\li: \wq{{\thole} tem $3$ membros de ordem $2$}:
     satisfeita por $\dih 4$ mas não por $\ints_8$;
\endtlist
etc.

%%}}}

%%{{{ eg: is dih 4 cyclic? 
\example.
%%%{{{ meta 
%%%}}}

O $\dih 4$ é um grupo cíclico?

\solution.
Para ver se $\dih 4$ é um grupo cíclico ou não, conferimos
para cada membro $a$ dele, se $a$ pode gerar o grupo inteiro
ou não.
Calculamos:
$$
\xalignat2
\gen I     &= \set {I}          & \gen {\Delta_1} &= \set {I, \Delta_1} \\
\gen R     &= \set {I,R,R',R''} & \gen {\Delta_2} &= \set {I, \Delta_2} \\
\gen {R'}  &= \set {I,R'}       & \gen H          &= \set {I, H} \\
\gen {R''} &= \gen R            & \gen V          &= \set {I, V}
\endxalignat
$$
Nenhum desses subgrupos gerados é o próprio $\dih 4$,
e logo $\dih 4$ não é um grupo cíclico.

%%}}}

%%{{{ hasse_diagrams_first_encounter 
\note Diagramas Hasse.
%%%{{{ meta 
\label hasse_diagrams_first_encounter
\defines
    * Hasse!diagrama
    ;;
\credits
    * Hasse
    ;;
%%%}}}

Quando temos uma ordem parcial $(\leq)$ definida num conjunto,
podemos desenhar os membros do conjunto num diagrama
chamado \dterm{diagrama Hasse}.
Desenhamos os membros do conjunto e botamos uma linha
\emph{subindo} dum membro $x$ para outro $y$ sse $x\leq y$ e,
ainda mais, não tem nenhum $w$ entre os dois ($x \leq w \leq y$).
(Fique lendo até os exemplos e vai fazer sentido.)
No~\ref[Posets_Lattices] vamos trabalhar demais com esses diagramas;
agora é uma boa oportunidade introduzi-los nesse contexto.
Qual contexto exatamente?  Qual o conjunto e qual a ordem?
Lembre-se que $\subgrp$ é uma ordem parcial entre grupos
(\ref[subgroup_is_an_order]), ou seja, o conjunto de todos
os subgrupos dum dado grupo é ordenado pela $\subgrp$.
Bora desenhar então!

%%}}}

%%{{{ hasse_dih_3 
\example O Hasse das simetrias do triângulo.
%%%{{{ meta 
\label hasse_dih_3
%%%}}}

$$
\tikzpicture
\node (top)     at (0,  0 ) {$\mobrace{\set{I,R,R',\Delta_1,\Delta_2,\Delta_3}}{\dih 3}$};
\node (ir1r2)   at (-3, -2) {$\set{I,R,R'}$};
\node (id1)     at (-1, -2) {$\set{I,\Delta_1}$};
\node (id2)     at (1,  -2) {$\set{I,\Delta_2}$};
\node (id3)     at (3,  -2) {$\set{I,\Delta_3}$};
\node (bot)     at (0,  -4) {$\set{I}$};
\draw (top) -- (ir1r2);
\draw (top) -- (id1);
\draw (top) -- (id2);
\draw (top) -- (id3);
\draw (bot) -- (ir1r2);
\draw (bot) -- (id1);
\draw (bot) -- (id2);
\draw (bot) -- (id3);
\endtikzpicture
$$

%%}}}

%%{{{ hasse_dih_4 
\exercise O Hasse das simetrias do quadrado.
%%%{{{ meta 
\label hasse_dih_4
%%%}}}

Fiz do $\dih 3$; faça do $\dih 4$.

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$?$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$?$};
\endtikzpicture
$$

\hint
$$
\tikzpicture
\tikzi hassedih4;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$?$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$?$};
\node (id2)     at (id2)     {$?$};
\node (id1)     at (id1)     {$?$};
\node (ir2)     at (ir2)     {$?$};
\node (ih)      at (ih)      {$?$};
\node (iv)      at (iv)      {$?$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

\solution
$$
\tikzpicture
\tikzi hassedih4nodes;
\node (top)     at (top)     {$\mobrace{\set{I,R,R',R'',\Delta_1,\Delta_2,H,V}}{\dih 4}$};
\node (id1d2r)  at (id1d2r)  {$\set{I,\Delta_1,\Delta_2,R'}$};
\node (ir1r2r3) at (ir1r2r3) {$\set{I,R,R',R''}$};
\node (ihvr1)   at (ihvr1)   {$\set{I,H,V,R'}$};
\node (id2)     at (id2)     {$\set{I,\Delta_2}$};
\node (id1)     at (id1)     {$\set{I,\Delta_1}$};
\node (ir2)     at (ir2)     {$\set{I,R'}$};
\node (ih)      at (ih)      {$\set{I,H}$};
\node (iv)      at (iv)      {$\set{I,V}$};
\node (bot)     at (bot)     {$\set{I}$};
\tikzi hassedih4edges;
\endtikzpicture
$$

%%}}}

%%{{{ x: dih_4_isomorphic_to_what 
\exercise.
%%%{{{ meta 
\label dih_4_isomorphic_to_what
%%%}}}

Consegues achar um grupo diferente,
que é isomórfico com o $\dih 4$?

\hint
Não pode ser o $\sym 4$ obviamente, por questão de tamanho!

\hint
Mas olhe dentro do $\sym 4$: no seus subgrupos!

\hint
Renomeia teus $A,B,C,D$ para $1,2,3,4$.
Agora veja cada uma das simetrias do $\dih 4$, para onde ela
leva cada número, e escreva sua permutação correspondente do $\sym 4$.
Basta demonstrar que esse conjunto realmente é um subgrupo de $\sym 4$.

%%}}}

%%{{{ x: minimal_generator_for_dih_3 
\exercise.
%%%{{{ meta 
\label minimal_generator_for_dih_3
%%%}}}

Qual é o menor tamanho de gerador $A \subset \dih 3$,
com $\gen{A} = \dih 3$?
Mostre um tal gerador.

%%}}}

%%{{{ x: minimal_generator_for_dih_4 
\exercise.
%%%{{{ meta 
\label minimal_generator_for_dih_4
%%%}}}

E sobre o $\dih 4$?

%%}}}

%%{{{ x: rectangle_symmetries 
\exercise Simetrias de rectângulo.
%%%{{{ meta 
\label rectangle_symmetries
%%%}}}

Ache todas as simetrias do rectângulo.

%%}}}

%%{{{ x: circle_symmetries 
\exercise As simetrias do cíclo.
%%%{{{ meta 
%%%}}}

Ache todas as simetrias do cíclo.

%%}}}

\endsection
%%}}}

%%{{{ Morphisms 
\section Morfismos.
%%%{{{ meta 
\label Group_morphisms
%%%}}}

%%{{{ Idea 
\note Idéia.
%%%{{{ meta 
%%%}}}

Queremos formalizar a idéia de <<o grupo $\dih 3$ \emph{parece com} o $\sym 3$>>.
O que precisa ser satisfeito (ou mostrado) para convencer alguém que,
no final das contas, trabalhar com um grupo $\cal A$ é
\emph{essencialmente a mesma coisa} de trabalhar com um grupo $\cal B$?

%%}}}

%%{{{ pseudodf: group_homomorphism_first_attempt 
\pseudodefinition homomorfismo.
%%%{{{ meta 
\label group_homomorphism_first_attempt
%%%}}}

Sejam $\cal A, \cal B$ grupos.
A função $\phi : A \to B$ é um \dterm{homomorfismo} de $\cal A$ para $\cal B$
sse ela \emph{preserva a estrutura de $\cal A$ no $\cal B$}.

%%}}}

%%{{{ Preserving the structure 
\note Preservando a estrutura.
%%%{{{ meta 
\defines
    * preservar!estrutura
    * respeitar!estrutura
    ;;
%%%}}}

Antes de entender o que significa <<preservar uma estrutura>>, vamos
lembrar: o que é a estrutura dum grupo?
É sua alma: num grupo temos a sua operação (binária), podemos pegar inversos (operação unária),
e temos também em cada grupo um membro especial chamado identidade do grupo (constante).
Ou seja, \dterm{preservar a estrutura} faz sentido significar as três coisas seguintes:
$$
\xalignat2
&\text{preservar a operação:}   & \phi(x \ast_A y)    &= \phi(x) \ast_B \phi(y)   \tag{i}   \\
&\text{preservar os inversos:}  & \phi(\ginvt_A (x))  &= \ginvt_B\paren{\phi(x)}  \tag{ii}  \\
&\text{preservar a identidade:} & \phi(e_A)           &= e_B.                     \tag{iii}
\endxalignat
$$
Também usamos o termo \dterm{respeitar}, muitas vezes como sinônimo de
preservar mas não sempre---então tome cuidado com as definições,
especialmente se a estrutura envolve relações.

%%}}}

%%{{{ Two paths 
\note Dois caminhos.
%%%{{{ meta 
%%%}}}

Considere que temos uma \emph{função} $\phi$ de $\cal A$ para $\cal B$.
Comece no grupo $\cal A$ (o domínio de $\phi$) e tome uns membros
$a_1,\dots,a_n$ do seu carrier set $A$.
Faça quaisquer coisas aí que a estrutura de grupo te permite fazer:
tome inversos, combine eles com a operação do grupo, etc.
Assim tu chega num certo membro $x$ do grupo $\cal A$.
Agora use a $\phi$ nesse resultado $x$, passando assim
para um certo membro $y$ do grupo $\cal B$.
Alternativamente, \emph{começando com os mesmos membros}
$a_1,\dots,a_n$ do~$\cal A$,
use a~$\phi$~logo no início em cada um deles para passar ao grupo $\cal B$,
chegando assim nuns membros $b_1,\dots,b_n$ do~$\cal B$.
Sendo num grupo agora, podes performar exatamente as mesmas operações, na mesma
ordem, nos correspondentes membros que tu fez antes (no grupo $\cal A$),
e assim tu chegarás num certo resultado $b$ no $\cal B$.
Vamos chamar a função $\phi$ um homomorfismo exatamente quando ela garanta que
em qualquer situação como essa, os dois caminhos de $\cal A$ para $\cal B$,
chegam no mesmo membro, ou seja, $b = y$.

%%}}}

%%{{{ Diagramas comutativos 
\note Diagramas comutativos.
%%%{{{ meta 
%%%}}}

Essa idéia é bem melhor desenhada do que escrita, usando diagramas comutativos.
Por exemplo, a lei (ii) é equivalente à comutatividade do diagrama seguinte:
$$
\cdopt{sep=2cm}
A   \ar[r, "\phi"]\ar[d, "\ginvt_A"'] \| B\ar[d, "\ginvt_B"]\ \\
A   \ar[r, "\phi"]                    \| B
\endcd
$$

%%}}}

%%{{{ x: cd_for_respects_operation 
\exercise.
%%%{{{ meta 
\label cd_for_respects_operation
%%%}}}

Desenhe um diagrama cuja comutatividade é a lei (i).

\solution
$$
\cdopt{sep=2cm}
A\times A   \ar[r, "\phi \times \phi"]\ar[d, "\ast_A"'] \| B\times B \ar[d, "\ast_B"]\ \\
A           \ar[r, "\phi"]                              \| B
\endcd
$$

%%}}}

%%{{{ Different structures for groups 
\note Diferentes estruturas para grupos.
%%%{{{ meta 
%%%}}}

Já vimos como definir ``grupo'' como conjunto estruturado usando três
estruturas diferentes:
$$
\xalignat3
\sset A {\ast_A} &
&\sset A {\ast_A, e_A} &
&\sset A {\ast_A, \ginvt_A, e_A}. &
\endxalignat
$$
Então, dependendo na estrutura que escolhemos para nossa definição
de grupo, precisamos definir ``morfismo'' em forma diferente:
No caso de estrutura $\sset A {\ast_A}$ o morfismo deve satisfazer
o~(i); no caso de $\sset A {\ast_A, e_A}$, os~(i)~e~(iii), e no caso
de $\sset A {\ast_A, \ginvt_A, e_A}$ todos os~(i)--(iii).
\emph{Parece então que chegamos no primeiro ponto onde a estrutura
escolhida na definição de grupo será crucial.}
Felizmente, como nós vamos demonstrar logo após, as leis de grupo
são suficientes para garantir que qualquer função $\phi$ que
satisfaz apenas o~(i)~acima, obrigatoriamente satisfaz
os~(ii)~e~(iii) também!
Mesmo assim, vamos botar em nossa definição todos os~(i)--(iii),
pois isso captura melhor a idéia geral de ``homomorfismo''.
E assim que demonstrar nossa afirmação ganhamos um critérion forte
para decidir se alguma função é um homomorfismo.

%%}}}

%%{{{ df: group_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label group_homomorphism
\defines
    * \phi : {~A} \homto {~B}  -- $\phi$ é um homomorfismo do $A$ para o $B$
    * \phi : {~{\cal A}} \to {~{\cal B}}  -- $\phi$ é um homomorfismo do $\cal A$ para o $\cal B$
    * homomorfismo!de grupos
    ;;
%%%}}}

Sejam
\mathcols2
\cal A &= \sset A {\ast_A,\ginvtof A,\gidof A}, &
\cal B &= \sset B {\ast_B,\ginvtof B,\gidof B}
\endmathcols
grupos.
A função $\phi : A \to B$ é um \dterm{homomorfismo} do
$\cal A$ para o $\cal B$ sse ela respeita a operação,
os inversos, e a identidade:
$$
\alignat2
&\text{para todo $x,y\in A$},\quad & \phi(x \ast_A y)   &= (\phi x) \ast_B (\phi y); \\
&\text{para todo $x\in A$},\quad   & \phi(\ginvtof A x) &= \ginvtof B \funparen{\phi x}; \\
&&\phi e_A       &= e_B.
\endalignat
$$
Às vezes escrevemos $\phi : \cal A \to \cal B$ (em vez de $\phi:A\to B$)
para enfatizar que o $\phi$ nos leva do \emph{grupo} $\cal A$ para o
\emph{grupo} $\cal B$; ou também $\phi : A \homto B$.

%%}}}

%%{{{ safe juxtaposition 
\note.
%%%{{{ meta 
%%%}}}

Quando pelo contexto podemos inferir qual é a operação envolvida,
optamos para denotá-la com justaposição como produto mesmo.
Por exemplo, escrevemos
$$
\phi(xy) = \phi(x)\phi(y)
$$
sem ambigüidade nenhuma:
o $xy$ que aparece no lado esquerdo,
só pode denotar o $x \ast_A y$, pois $x,y \in A$.
E, no outro lado, o $(\phi x) (\phi y)$ só pode denotar o $\phi(x) \ast_B \phi(y)$,
pois $\phi(x),\phi(y) \in B$.
A mesma coisa acontece com os inversos:
$\phi(\ginv x)$ só pode denotar ``a imagem do inverso (no $A$) de $x$'',
e $\ginvp{\phi(x)}$ só pode denotar ``o inverso (no $B$) de $\phi(x)$'',
pois, no primeiro caso o $\ginv{}$ é aplicado num membro de $A$,
e no segundo caso num membro de $B$.

%%}}}

%%{{{ criterion: criterion_for_morphism_in_groups
\criterion de homomorfismo.
%%%{{{ meta 
\label criterion_for_morphism_in_groups
%%%}}}

Sejam grupos $\cal A = \sset A {\ast_A,\ginvtof A,\gidof A}$
e $\cal B = \sset B {\ast_B,\ginvtof B,\gidof B}$
e função $\phi : A \to B$ que preserva a operação, ou seja,
tal que
$$
\quad\text{para todo $x,y\in A$},\quad
\phi(x \ast_A y) = (\phi x) \ast_B (\phi y).
$$
Então $\phi$ é um homomorfismo.

\sketch.
Precisamos demonstrar o que falta:
$$
\alignat2
&&\phi e_A       &= e_B              \tag{iii}  \\
&\text{para todo $x\in A$},\quad &
\phi(\ginv x)    &= \ginvp{\phi x}.  \tag{ii}
\endalignat
$$
Para o~(iii), calculamos $\phi(e_A) = \phi(e_A) \phi(e_A)$
para concluir que $e_B = \phi(e_A)$;
para o~(ii), mostramos que o $\phi(\ginv x)$ satisfaz a
propriedade característica de ser inverso de $\phi x$:
$$
\phi(\ginv x) \phi(x) \askeq e_B.
$$

%%}}}

%%{{{ df: group_morphisms 
\definition -morfismos.
%%%{{{ meta 
\label group_morphisms
\defines
    * automorfismo!de grupos
    * endomorfismo!de grupo
    * epimorfismo!de grupo
    * epimorfismo!split (de grupo)
    * homomorfismo!de grupo
    * isomorfismo!de grupo
    * monomorfismo!de grupo
    * monomorfismo!split (de grupo)
    * morfismo!grupo
    ;;
%%%}}}

Sejam grupos $\cal A$ e $\cal B$, e $\phi : \cal A \to \cal B$ um homomorfismo.
Usamos os termos:
$$
\align
\text{$\phi$ monomorfismo}       &\defiff \text{$\phi$ L-cancelável}\\
\text{$\phi$ epimorfismo}        &\defiff \text{$\phi$ R-cancelável}\\
\text{$\phi$ split monomorfismo} &\defiff \text{$\phi$ L-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A}\\
\text{$\phi$ split epimorfismo}  &\defiff \text{$\phi$ R-invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi\phi' = \idof B}\\
\text{$\phi$ isomorfismo}        &\defiff \text{$\phi$ é invertível}\\
                                 &\intiff \lexists {\phi' : \cal B \to \cal A}
                                                   {\phi'\phi = \idof A \mland \phi\phi' = \idof B}\\
\text{$\phi$ endomorfismo}       &\defiff \text{$\dom\phi = \cod\phi$}\\
\text{$\phi$ automorfismo}       &\defiff \text{$\phi$ endomorfismo~\&~isomorfismo}
\endalign
$$
onde ``cancelável'' e ``invertível'' significam com respeito a
operação da composição $\fcom$.

%%}}}

%%{{{ x: mono_splitmono_inj_in_Group 
\exercise.
%%%{{{ meta 
\label mono_splitmono_inj_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ mono}
\askiff \text{$\phi$ split mono}
\askiff \text{$\phi$ injectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos
(veja~\reftag[An_epic_trip])?

%%}}}

%%{{{ x: epi_splitepi_surj_in_Group 
\exercise.
%%%{{{ meta 
\label epi_splitepi_surj_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ epí}
\askiff \text{$\phi$ split epí}
\askiff \text{$\phi$ sobrejectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos?

%%}}}

%%{{{ x: iso_bim_bij_in_Group 
\exercise.
%%%{{{ meta 
\label iso_bim_bij_in_Group
%%%}}}

Investigue:
$$
\text{$\phi$ iso}
\askiff \text{$\phi$ mono} + \text{$\phi$ epí}
\askiff \text{$\phi$ bijectiva}
$$
Como a situação compara com os resultados de funções entre conjuntos?

%%}}}

%%{{{ x: id_is_an_auto 
\exercise.
%%%{{{ meta 
\label id_is_an_auto
%%%}}}

Seja $G$ grupo.  Mostre que a $\id : G \to G$
é um homomorfismo (e logo automorfismo).

\solution
Sejam $x,y\in G$.
Calculamos
$$
\id(xy) = xy = \id(x)\id(y)
$$
e logo $\id$ é um homomorfismo,
e como $\id$ é bijetora e endomapa, $\id$ é um automorfismo.

%%}}}

%%{{{ x: conj_is_an_auto 
\exercise.
%%%{{{ meta 
\label conj_is_an_auto
%%%}}}

Seja $G$ grupo.  Para todo $g\in G$, o $g$-conjugador
(\ref[conjugator]) é um automorfismo.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Finalmente podemos definir o que significa que dois grupos são isómorfos!

%%}}}

%%{{{ df: isomorphic_groups 
\definition Grupos isomórficos.
%%%{{{ meta 
\label isomorphic_groups
\defines
    * grupo!isomórficos
    ;;
%%%}}}

Sejam grupos $G$ e $G'$.
Chamamos o $G$ \dterm{isomórfico} (ou \dterm{isómorfo}) ao $G'$ sse
existe isomorfismo $\phi : G \to G'$.
Nesse caso chamamos o $\phi$ \dterm{isomorfismo de grupos}.
Como introduzimos na~\ref[isomorphic_sets]
escrevemos $G \iso G'$ para dizer que <<os $G,G'$ são isómorfos>>,
e também $\phi : G \isoto G'$ ou até $\phi : G \iso G'$ para
<<$\phi$~é um isomorfismo de $G$ para $G'$>>.

%%}}}

%%{{{ x: isomorphic_is_an_equivalence_relation 
\exercise.
%%%{{{ meta 
\label isomorphic_is_an_equivalence_relation
%%%}}}

Mostre que $\isomorphic$ é uma relação de equivalência.

%%}}}

%%{{{ x: additive_ints_and_rats_are_not_isomorphic 
\exercise.
%%%{{{ meta 
\label additive_ints_and_rats_are_not_isomorphic
%%%}}}

Mostre que os $\sset \ints +$ e $\sset \rats +$ não são
isómorfos.

\hint
Procure uma propriedade grupoteórica que um dos dois tem e o outro não.

\solution
Considere a propriedade seguinte:
$$
\text{Para todo $w$, existe $u$ tal que $u+u = w$.}
$$
Ela é uma propriedade grupoteórica, válida no $\sset \rats +$
e inválida no $\sset \ints +$.
Em outras palavras, suponha para chegar num absurdo que temos
um isomorfismo desses grupos $\phi : \ints \to \rats$.
Olhe para o $w \asseq \phi(1)$ (qualquer número ímpar serveria em vez do $1$).
Sendo racional, o $u \asseq \phi(1)/2$ também é racional e temos:
$$
w = u + u.
$$
Qual inteiro é o $\finv\phi$?
Deve ser um inteiro que satisfaz
$$
\finv\phi(u) + \finv\phi(u)
= \finv\phi(u+u)
= \finv\phi(w)
= 1
$$
mas tal inteiro não existe.
Logo, não pode existir nenhum isomorfismo entre os
$\sset \ints +$ e $\sset \rats +$.
\eop
Usando uma outra propriedade grupoteórica para diferenciar
os dois grupos seria observar que um é cíclico, mas o outro não é.

%%}}}

\endsection
%%}}}

%%{{{ Kernel, Image 
\section Kernel, Image.
%%%{{{ meta 
\label Kernel_Image
%%%}}}

%%{{{ df: kernel 
\definition kernel, image.
%%%{{{ meta 
\label kernel
\defines
    * \ima{~\phi}  -- a image do homomorfismo $\phi$
    * \ker{~\phi}  -- o kernel do homomorfismo $\phi$
    * image de homomorfismo
    * kernel de homomorfismo
    ;;
%%%}}}

Sejam $A,B$ grupos e $\phi:A\to B$ um homomorfismo.
Definimos
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{e_B}} &
\quad\big(&= \setst {a \in A} {\phi(a) = e_B} \ \big)\\
\ima\phi
&\defeq \img \phi A &
\quad\big(&= \setst {b \in B} {\lexists {x\in A} {\phi(x) = b}} \ \big)
\endalignat
$$
Chamamos o $\ker \phi$ o \dterm{kernel} do $\phi$
e o $\ima \phi$ o \dterm{image} do $\phi$.

%%}}}

%%{{{ thm: group_homo_mono_iff_ker_singleton 
\theorem.
%%%{{{ meta 
\label group_homo_mono_iff_ker_singleton
%%%}}}

Sejam $A,B$ grupos e $\phi : A \to B$ homomorfismo.
$$
\text{$\phi$ injetora}
\iff
\ker\phi = \set{e_A}.
$$

\sketch.
\proofpart {\lrdir}:
Como $e_A \in \ker\phi$,
basta demonstrar que todos os membros de $\ker\phi$ são iguais:
suponha $x,y\in\ker\phi$ e mostre que $x = y$.
\crproofpart {\rldir}.
Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.
Operando nessa igualdade e usando o fato que $\phi$ é homomorfismo,
chegamos no $x=y$, ou seja, $\phi$ é injetora.

\proof.
\proofpart {\lrdir}:
Como $e_A \in \ker\phi$,
basta demonstrar que todos os membros de $\ker\phi$ são iguais.
Sejam $x,y\in\ker\phi$ então.
Logo $\phi(x) = e_B = \phi(y)$,
e como $\phi$ é injetora, concluimos o desejado $x=y$.
\crproofpart {\rldir}.
\proofsteps
\steptnb {Sejam $x,y \in A$ tais que $\phi(x) = \phi(y)$.}
\steptby {Logo $\phi(x) \ginv{\phi(y)} = e_B$.}          {$(\ast \ginv{\phi(y)})$}
\steptby {Logo $\phi(x) \phi\funparen{\ginv y} = e_B$.}  {$\phi$ homo (inv.)}
\steptby {Logo $\phi(x \ginv y) = e_B$.}                 {$\phi$ homo (op.)}
\steptby {Logo $x\ginv y \in \ker\phi$.}                 {def.~$\ker\phi$}
\steptby {Logo $x\ginv y \in \set{e_A}$.}                {hipótese}
\steptby {Logo $x\ginv y = e_A$.}                        {$\set{e_A}$ singleton}
\steptby {Logo $x = y$.}                                 {$(\ast y)$}
\endproofsteps

%%}}}

%%{{{ x: kernel_subgroup 
\exercise.
%%%{{{ meta 
\label kernel_subgroup
%%%}}}

Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Demonstre que $\ker\phi\subgrp A$.

\hint
Primeiramente verifique que $\ker\phi\neq\emptyset$.
Agora, graças ao~\ref[nonempty_subgroup_criterion], precisas demonstrar:
(i)~$\ker\phi$ é~$\ast$-fechado;
(ii)~$\ker\phi$ é~$\ginv{}$-fechado.

\hint
Para o (i), tome $x,y\in\ker\phi$ e mostre que $xy\in\ker\phi$,
ou seja, que $\phi(xy) = e_B$.

\hint
Para o (ii), tome $x\in\ker\phi$ e mostre que $\ginv x\in\ker\phi$,
ou seja, que $\phi\funparen{\ginv x} = e_B$.

\solution
Primeiramente observamos que $\ker\phi\neq\emptyset$:
$e_A \in \ker\phi$, pois $\phi$ é um homomorfismo
e logo leva a $e_A$ para a $e_B$.
Então graças ao~\ref[nonempty_subgroup_criterion], basta demonstrar:
\crproofpart {$\ker\phi$ é fechado sob a operação:}
Sejam $x,y\in\ker\phi$.
Precisamos mostrar que $xy\in\ker\phi$, ou seja, que $\phi(xy) = e_B$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)} \\
&= e_B e_B          \by {$x,y\in\ker\phi$} \\
&= e_B.             \by {def.~$e_B$} \\
\endcompute
\proofpart {$\ker\phi$ é fechado sob inversos:}
Seja $x\in\ker\phi$.
Precisamos mostrar que $\ginv x\in\ker\phi$, ou seja, que $\phi\funparen{\ginv x} = e_B$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi(x)}  \by {$\phi$ homo (inv.)} \\
&= \ginv{e_B}       \by {$x\in\ker\phi$} \\
&= e_B.             \by {inverso da identidade~(\ref[inverse_of_identity_in_group])} \\
\endcompute

%%}}}

%%{{{ x: kernel_is_normal 
\exercise.
%%%{{{ meta 
\label kernel_is_normal
%%%}}}

Sejam $A$ e $B$ grupos e $\phi : A \to B$ homomorfismo.
Demonstre que $\ker\phi\normal A$.

\hint
Acabamos de demonstrar que $\ker\phi\subgrp \cal A$ no~\ref[kernel_subgroup].
Basta demonstrar que $\ker\phi$ é fechado pelos conjugados.
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos demonstrar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Ou seja, basta verificar que realmente $\phi(ak\ginv a) = e_B$.

\solution
Seja $k\in\ker\phi$ e tome $a\in A$.
Precisamos demonstrar que o $a$-conjugado de $k$ também está no $\ker\phi$:
$ak\ginv a \in \ker\phi$.
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo} \\
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$k\in\ker\phi$} \\
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$} \\
&= \phi(a) \ginvp{\phi(a)}                  \by {$\phi$ homo} \\
&= e_B                                      \by {def.~$\ginvp{\phi(a)}$} \\
\endcompute
Logo $ak\ginv a\in\ker\phi$ como queremos demonstrar.

%%}}}

%%{{{ x: kernel_is_normal_altproof 
\exercise.
%%%{{{ meta 
\label kernel_is_normal_altproof
%%%}}}

Veja a demonstração completa do~\ref[kernel_is_normal].
No seu cálculo, mostre como continuar num caminho diferente depois da terceira
igualdade para chegar no mesmo resultado desejado: $e_B$.

\hint
Aplicamos a propriedade que homomorfismos preservam os inversos.
Aplique outra propriedade de homomorfismos.

\solution
Calculamos:
\compute
\phi\funparen{ak\ginv a}
&= \phi(a) \phi(k) \phi\funparen{\ginv a}   \by {$\phi$ homo (oper.)} \\
&= \phi(a) e_B \phi\funparen{\ginv a}       \by {$k\in\ker\phi$} \\
&= \phi(a) \phi\funparen{\ginv a}           \by {def.~$e_B$} \\
&= \phi(a \ginv a)                          \by {$\phi$ homo (oper.)} \\
&= \phi(e_A)                                \by {def.~$\ginv a$} \\
&= e_B                                      \by {$\phi$ homo (iden.)} \\
\endcompute

%%}}}

%%{{{ x: image_subgroup 
\exercise.
%%%{{{ meta 
\label image_subgroup
%%%}}}

Sejam $A$ e $B$ grupos e $\phi$ um homomorfismo de $A$ para $B$.
Demonstre que $\ima\phi\subgrp B$.

\hint
Precisas mostrar que $\ima\phi$ é fechado sob a operação e sob inversos.

\hint
\proofpart {$\ima\phi$ fechado sob a operação:}
Tome $x', y' \in \ima\phi$ e ache um $w\in A$ tal que que $\phi(w) = x'y'$.
\crproofpart {$\ima\phi$ fechado sob inversos:}
Tome $x' \in \ima\phi$ e ache um $x\in A$ tal que $\phi(x) = \ginvp{x'}$.

\solution
\proofpart {$\ima\phi$ fechado sob a operação:}
Sejam $x', y' \in \ima\phi$.
Logo, sejam $x,y\in A$ tais que $\phi x = x'$, e $\phi y = y'$.
Calculamos:
\compute
\phi(xy)
&= \phi(x) \phi(y)  \by {$\phi$ homo (oper.)} \\
&= x' y'.           \by {pela escolha dos $x,y$} \\
\endcompute
Ou seja, $x'y' \in \ima\phi$.
\crproofpart {$\ima\phi$ fechado sob inversos:}
Seja $x' \in \ima\phi$.
Logo, seja $x\in A$ tal que $\phi x = x'$.
Calculamos:
\compute
\phi\funparen{\ginv x}
&= \ginvp{\phi x}   \by {$\phi$ homo (inv.)} \\
&= \ginvp{x'}.      \by {pela escolha do $x$} \\
\endcompute
Ou seja, $x'\in\ima\phi$.

%%}}}

%%{{{ thm: first_isomorphism_theorem_groups 
\theorem Primeiro teorema de isomorfismo.
%%%{{{ meta 
\label first_isomorphism_theorem_groups
\indexes
    * isomorfismo    seealso: teorema de isomorfismo
    * grupo!teorema de isomorfismo    see: teorema de isomorfismo
    * teorema de isomorfismo!primeiro (de grupos)
    ;;
%%%}}}

Sejam $G$ e $G'$ grupos
e $\phi : G \to G'$ homomorfismo.
\tlist:
\li (i):   $\ker\phi\normal G$;
\li (ii):  $\ima\phi\subgrp G'$;
\li (iii): $\quogrp G {\ker\phi} \iso \ima\phi$.
\endtlist

\sketch.
Acabamos de demonstrar as (i)~\&~(ii) nos~\reftag[kernel_is_normal]~\&~\reftag[image_subgroup].
Para a (iii) precisamos definir uma função
$$
\Phi : \quogrp G {\ker\phi} \to \ima\phi
$$
tal que $\Phi$ é um isomorfismo.
Seja $K \asseq \ker\phi$.
Queremos definir a $\Phi$ pela
$$
\Phi(Kx) = \phi(x)
$$
para qualquer coclasse $Kx$ do $K$ (essas são as suas entradas).
\eop
O problema é que $\Phi$ não parece \emph{bem-definida}, pois seu valor
pode depender na escolha do representante $x$ da coclasse---veja
o~\ref[not_well_defined_function_danger_firstiso] caso que o problema
com essa definição não é claro.
Precisamos melhorar essa definição e demonstrar que:
(a) realmente defina uma \emph{função} $\Phi$;
(b) $\Phi$ é bijetora;
(c) $\Phi$ é um homomorfismo (e logo isomorfismo).

%%}}}

%%{{{ beware: not_well_defined_function_danger_firstiso 
\beware.
%%%{{{ meta 
\label not_well_defined_function_danger_firstiso
\indexes
    * função!bem-definida
    ;;
%%%}}}

Caso que o perigo descrito no esboço acima não é óbvio,
primeiramente volte re-estudar os
\ref[not_well_defined_function_danger_quogrp],
\ref[not_well_defined_function_danger_argument_name_dependence],
e~%
\ref[not_well_defined_function_danger_choice_dependence].
\eop
Agora vamos pensar como um programador querendo definir essa
função $\Phi$.
Sua função, quando chamada, recebe uma coclasse, ou seja,
um conjunto com certos elementos membros.
Ela não sabe qual foi o nome que o chamador escolheu para essa coclasse
(\ref[not_well_defined_function_danger_argument_name_dependence]).
Até pior, e para corresponder ainda melhor com nosso caso, observe
que o $Kx$ é na verdade uma operação entre um subgrupo $K$ e um membro
$x$ que resulta num subconjunto de $G$.
Mas a $\Phi$ \emph{não tem acesso nesse $x$}
(\ref[not_well_defined_function_danger_choice_dependence]).
\eop
Mesmo se defini-la pela
$$
\Phi(C) = \phi(c),\quad
\text{onde $c$ é algum membro de $C$}
$$
temos uma tarefa para fazer:
\emph{precisamos demonstrar que seu valor $\Phi(C)$ não depende da escolha de $c$}.
Até conseguir demonstrar isso, não podemos considerar a $\Phi$ uma função
\emph{bem-definida}.
Veja bem a demonstração do~\ref[first_isomorphism_theorem_groups].

%%}}}

%%{{{ kernel <==> normal 
\note Dois lados da mesma moeda.
%%%{{{ meta 
%%%}}}

Já demonstramos algo (\ref[kernel_is_normal]) que,
informalmente falando, podemos escrever assim:
$$
\text{kernel} \implies \text{normal}.
$$
E o converso?
Será que também é verdade?
O que exatamente é esse converso?
Como formalizar?  Podemos demonstrar?
\eop
Realmente o converso da implicação-informal também é válido:
$$
\text{normal} \implies \text{kernel}.
$$
Temos então o slogan
$$
\text{normal} \iff \text{kernel}.
$$
Ou seja, em teoria dos grupos os conceitos de ``kernel''
e de ``subgrupo normal'' são apenas dois lados da mesma moeda.
Deixo os \emph{detalhes importantes} pra ti,
no~\ref[normal_is_kernel]---não pule!

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_groups 
\section Pouco de cats---categorias e grupos.
%%%{{{ meta 
\label Categories_and_groups
%%%}}}

%%{{{ intro 
\secintro
Temos uns objetos que nos interessam: os grupos.
Temos umas setas interessantes entre esses objetos: os morfimos.
Será que temos uma categoria (\ref[category_first_def])?
%%}}}

%%{{{ df: GROUP 
\definition.
%%%{{{ meta 
\label GROUP
\defines
    * \GROUP  -- a categoria dos grupos e seus homomorfismos
    ;;
%%%}}}

Denotamos por $\GROUP$ a categoria dos grupos:
\tlist:
\li: $\Obj \GROUP$: todos os grupos;
\li: $\Arr \GROUP$: todos os homomorsfismos de grupos;
\endtlist
onde obviamente os $\src\phi$ e $\tgt\phi$ denotam os $\dom\phi$ e $\cod\phi$ respectivamente.

%%}}}

%%{{{ x: GROUP_is_a_cat 
\exercise.
%%%{{{ meta 
\label GROUP_is_a_cat
%%%}}}

Demonstre que $\GROUP$ realmente é uma categoria.

%%}}}

%%{{{ eg: products_of_Group 
\example.
%%%{{{ meta 
\label products_of_Group
%%%}}}

A categoria $\GROUP$ possui produtos?  (\ref[product_in_category].)

\solution.
Sim.
Dados dois objetos $G,H$ o
$\tupp{\outl, G \cross H, \outr}$ (\reftag[direct_product_of_groups]) é um produto
dos $G,H$.
Primeiramente precisamos demonstrar que $G \cross H$ realmente é um objeto
da $\GROUP$, ou seja, um grupo;
tu demonstraste isso no~\ref[direct_product_of_groups_is_a_group].
Agora falta verificar que dados $\tupp{f_1, F, f_2}$,\foot
Sim, isso é uma frase completa, com seu verbo e tudo mais:
\wq{\dots dados $\tupp{f_1,F,f_2}$,
existe única seta $! : F \to G \cross H$
que faz o diagrama seguinte comutar: \dots}
Mais uma vez que percebemos a veracidade do ditado
$$
\text{1 diagrama comutativo} = \text{1{,}000 palavras}.
$$
\toof
$$
\cdopt{sep=1cm}
                                 \| \|                                  \| G \\
F
\ar[rr, dotted, "\unique"]
\ar[urrr, bend left=24,  "f_1"]
\ar[drrr, bend right=24, "f_2"'] \| \| G \cross H
                                       \ar[ur, bend left=15, "\outl"]
                                       \ar[dr, bend right=15, "\outr"'] \| \\
                                 \| \|                                  \| H
\endcd
$$
Defina a $!$ pela
$$
! = \fpair {f_1} {f_2}.
$$
Isso realmente é o único que faz o diagrama comutar---tu
já verificaste isso no~\ref[product_is_a_product],
certo?---então só basta demonstrar uma coisa pra terminar.

%%}}}

%%{{{ x: what more is needed to prove? 
\exercise.
%%%{{{ meta 
%%%}}}

Qual?
Enuncie e demonstre!

\hint
Basta demonstrar que $! : F \to G \cross H$ é um homomorfismo mesmo.
Demonstre!

%%}}}

%%{{{ x: initial_and_terminal_of_Group 
\exercise.
%%%{{{ meta 
\label initial_and_terminal_of_Group
%%%}}}

A categoria $\GROUP$ possui objetos iniciais?  Terminais?  Quais?
(\ref[initial_terminal_null_objects].)
E, esqueci: a $\SET$ tem?

%%}}}

%%{{{ df: ABEL 
\definition.
%%%{{{ meta 
\label ABEL
\defines
    * \ABEL  -- a categoria dos grupos abelianos e seus homomorfismos
    ;;
%%%}}}

Denotamos por $\ABEL$ a categoria dos grupos abelianos:
\tlist:
\li: $\Obj \ABEL$: todos os grupos abelianos;
\li: $\Arr \ABEL$: todos os homomorsfismos de grupos abelianos;
\endtlist
onde novamente os $\src\phi$ e $\tgt\phi$ são as coisas óbvias.

%%}}}

%%{{{ x: ABEL_is_a_cat 
\exercise.
%%%{{{ meta 
\label ABEL_is_a_cat
%%%}}}

Verifique que $\ABEL$ realmente é uma categoria.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

É fácil verificar que a $\ABEL$ também possui produtos:
essencialmente o mesmo argumento da $\GROUP$ passa aqui também.
Mas a situação é bastante diferente olhando para os \emph{coprodutos}
(\ref[coproduct_in_category]).

%%}}}

%%{{{ products_and_coproducts_in_Group_complicated
\note Coprodutos de grupos.
%%%{{{ meta 
\label products_and_coproducts_in_Group_complicated
%%%}}}

Os coprodutos na~$\GROUP$\dots~meio complicado.
Vamos voltar nesse assunto no~\ref[Category_theory];
mas por enquanto observe que o conjunto $G \disjunion H$
que usamos para o coproduto $G \coprod H$ na $\SET$ não
possui uma estrutura de grupo óbvia para servir como coproduto
dos $G,H$.  Qual seria sua identidade, por exemplo, e, antes
de chegar em conseguir perguntar isso, qual seria sua operação?
Contudo, é fácil demonstrar que $\ABEL$ possui
coprodutos---e tu nem imagina quais são!

%%}}}

%%{{{ x: coproducts_in_Abel 
\exercise.
%%%{{{ meta 
\label coproducts_in_Abel
%%%}}}

Dados objetos (grupos abelianos) $G,H$, ache um coproduto deles.
Tu ficarás surpreso.

\hint
Que tipo de coisa é o coproduto literalmente?

\hint
Na $\ABEL$, o $G\cross H$ serve como objeto tanto de produto,
quanto de coproduto!
Demonstre!

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: conjugates_look_alike 
\problem.
%%%{{{ meta 
\label conjugates_look_alike
%%%}}}

Pode achar alguma propriedade grupoteórica tal que num grupo $G$,
dentro duma das suas classes de conjugação vai ter membros que
satisfazem e membros que não?

%%}}}

%%{{{ prob: hom_abel_with_pointwise_plus 
\problem.
%%%{{{ meta 
\label hom_abel_with_pointwise_plus
%%%}}}

Sejam $G,G'$ grupos abelianos.
Demonstre que
$$
\Hom(G,G') \defeq \setstt {\phi : G \to G'} {$\phi$ homomorfismo}
$$
é um grupo abeliano com operação a $(+)$ definida pointwise (\ref[pointwise_operation]):
$$
(\phi + \psi)(x) = \phi(x) + \psi(x).
$$
com operação a $(+)$ pointwise é um grupo abeliano.
Precisas realmente saber que ambos os $G,G'$ são abelianos?

\solution
Primeiramente precisamos demonstrar que $\Hom(G,G')$ é $(+)$-fechado.
Então sejam $\phi,\psi\in\Hom(G,G')$ e $x,y \in G$.
Calculamos:
\compute
(\phi + \psi)(x + y)
&= \phi(x + y) + \psi(x + y)                \by {pointwise~$(+)$} \\
&= \phi(x) + \phi(y) + \psi(x) + \psi(y)    \by {$\phi,\psi$ homo} \\
&= \phi(x) + \psi(x) + \phi(y) + \psi(y)    \by {$G'$ abeliano} \\
&= (\phi + \psi)(x) + (\phi+\psi)(y).       \by {def.~$\phi+\psi$} \\
\endcompute
Agora basta só confirmar que realmente é abeliano.
Fácil:
$$
(\phi + \psi)(x)
= \phi(x) + \psi(x)
= \psi(x) + \phi(x)
= (\psi + \phi)(x).
$$
Observe que precisamos a comutatividade apenas no $G'$,
ou seja, $\sset {\Hom(G,G')} +$ é abeliano se $G'$ é.

%%}}}

%%{{{ prob: aut_G_is_a_group 
\problem.
%%%{{{ meta 
\label aut_G_is_a_group
\defines
    * \Aut({~G})  -- o grupo de automorfismos no $G$
    ;;
%%%}}}

Mostre que dado um grupo $G$, o conjunto de todos os seus automorfismos
$$
\Aut G
\defeq
\set{
\phi : G\bijto G
\st
\text{$\phi$ é um automorfismo}
}
$$
com operação $\compose$ é um grupo.

%%}}}

%%{{{ prob: bij_G_subgrp_aut_G 
\problem.
%%%{{{ meta 
\label aut_G_subgrp_bij_G
%%%}}}

Sabendo que $\namedop{Bij} G \defeq \sset {(G \bijto G)} {\compose}$ é um grupo,
mostre que
$$
\Aut G \subgroup \namedop{Bij} G.
$$

\hint
Se $F$ é injetora, então: $x=y \impliedby F(x) = F(y)$.

\solution
Como $\Aut G \subset \namedop{Bij} G$ precisamos verificar
apenas que $\Aut G$ é:
\crproofpart {Não vazio:}
$\id : G \to G$ é um automorfismo (\ref[id_is_an_auto])
e logo $\Aut G\neq\emptyset$.
\crproofpart {Fechado pela operação:}
Tome $\phi,\psi\in\Aut G$, e $x,y\in G$.  Calculamos:
\compute
(\phi\compose\psi)(x\cdot y)
&=\phi\paren{\psi(x\cdot y)}                                     \by {def.~$\compose$} \\
&=\phi\paren{\psi(x) \cdot \psi(y)}                              \by {$\psi$ homo} \\
&=\phi\paren{\psi(x)} \cdot \phi\paren{\psi(y)}                  \by {$\phi$ homo} \\
&=\paren{\phi\compose\psi}(x) \cdot \paren{\phi\compose\psi}(y). \by {def.~$\compose$} \\
\endcompute
\proofpart {Fechado sob inversos:}
Tome $\phi\in\Aut G$.
Precisamos verificar que a bijecção $\finv\phi$
é realmente um homomorfismo.
Ou seja, precisamos mostrar que
$$
\phi^{-1}(x\cdot y) = \phi^{-1}(x)\cdot \phi^{-1}(y)
$$
para todos os $x,y\in G$.
Seguindo a dica, basta demonstrar que
$$
\phi\paren{\phi^{-1}(x\cdot y)} = \phi\paren{\phi^{-1}(x)\cdot \phi^{-1}(y)}
$$
O lado esquerdo é igual ao $x\cdot y$.
Calculamos o lado direito:
\compute
\phi\paren{\phi^{-1}(x) \cdot \phi^{-1}(y)}
&=\phi\paren{\phi^{-1}(x)} \cdot \phi\paren{\phi^{-1}(y)}   \by {$\phi$ homo} \\
&=x\cdot y.  \by {def.~$\phi^{-1}$} \\
\endcompute

%%}}}

%%{{{ df: inner_auto 
\definition Inner autos.
%%%{{{ meta 
\label inner_auto
\indexes
    * inner automorfismo    see: automorfismo
    ;;
\defines
    * \Inn({~G})  -- os inner automorfismos de $G$
    * automorfismo!inner
    ;;
%%%}}}

Seja $G$ grupo.
Definimos o conjunto dos seus \dterm{inner automorfismos}
$$
\Inn(G) \defeq \setst {\gconj g} {g \in G}
$$
onde $\gconj g$ é o $g$-conjugador (\ref[conjugator]).

%%}}}

%%{{{ prob: inn_normal_aut 
\problem.
%%%{{{ meta 
\label inn_normal_aut
%%%}}}

$\Inn G \normal \Aut G$.

\hint
Enxergue bem todos os seus alvos:
(i) $\Inn G \subset \Aut G$;
(ii) $\Inn G \subgroup \Aut G$;
(iii) $\Inn G \normal \Aut G$.
O que precisas demonstrar para matar cada um deles?

\solution
Precisamos demonstrar:
$\Inn G \subset \Aut G$;
$\Inn G \subgroup \Aut G$;
$\Inn G \normal \Aut G$.
\crtabproofpart {$\Inn G \subset \Aut G$}.
Seja $f \in \Inn G$.
Logo seja $g \in G$ tal que $f = \actorS g {\ginv g}$.
Precisamos mostrar que $f$ é um automorfismo.
Já demonstramos que é bijetora (\ref[group_actors_are_bijective])
então basta demonstrar que é um homomorfismo.
Pelo~\ref[criterion_for_morphism_in_groups], é suficiente
mostrar que $f$ respeita a operação.
Calculamos:
$$
\align
f(x)f(y)
&= \paren{\actorS g {\ginv g} x}
   \paren{\actorS g {\ginv g} y} \\
&= \paren{gx\ginv g}
   \paren{gy\ginv g} \\
&= gx\ginv g g y \ginv g \\
&= gxey \ginv g \\
&= g(xy) \ginv g \\
&= f(xy).
\endalign
$$
\crtabproofpart {$\Inn G \subgroup \Aut G$}.
Vamos usar o~\ref[nonempty_subgroup_criterion].
Primeiramente mostramos que $\Inn G \neq \emptyset$:
de fato, $\idof G \in \Inn G$, pois $\idof G$ é um inner:
$$
\idof G = \actorS e {\ginv e}.
$$
\crproofpart {$\Inn G$ $\fcom$-fechado}.
Agora sejam $f_1,f_2 \in \Inn G$.
Vou demonstrar que
$f_1\fcom f_2$ é um inner.
Como $f_1,f_2$ são inners, sejam $g_1,g_2$ tais que
$$
\xalignat2
f_1 & = \actorS {g_1} {\ginv {g_1}} &
f_2 & = \actorS {g_2} {\ginv {g_2}}.
\endxalignat
$$
Para um arbitrário $x \in G$ temos:
$$
\align
(f_1 \fcom f_2) x
&= f_1 ( f_2 x ) \\
&= f_1 ( g_2 x \ginv {g_2} ) \\
&= g_1 ( g_2 x \ginv {g_2} ) \ginv {g_1} \\
&= (g_1 g_2) x \paren{\ginv {g_2} \ginv {g_1}} \\
&= (g_1 g_2) x \ginvp{g_1 g_2}.
\endalign
$$
Ou seja, $f_1\fcom f_2\in\Inn G$.
\crproofpart {$\Inn G$ $\ginv{}$-fechado}.
Seja $f \in \Inn G$, e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Observe que $\actorS {\ginv g} g$ é a inversa da $f$,
e que realmente é um inner, pois
$$
\actorS {\ginv g} g = \actorS {\ginv g} {\ginvp {\ginv g}},
$$
ou seja, $\ginv f \in \Inn G$.
\crtabproofpart {$\Inn G$ fechado sob conjugados}.
Seja $f \in \Inn G$ e logo seja $g\in G$
tal que $f = \actorS g {\ginv g}$.
Vou mostrar que todos os conjugados de $f$ são inners.
Seja então $\alpha \in \Aut G$.
Basta demonstrar que $\alpha f \ginv{\alpha} \in \Inn G$.
Ou seja, basta resolver o
$$
\alpha f \ginv{\alpha} = \actorS {\askbox} {\ginv{\askbox}}.
$$
Para um arbitrário $x \in G$ temos:
\compute
\paren{\alpha \fcom f \fcom \ginv{\alpha}} x
&= \alpha \funparen{ f \funparen { \finv{\alpha} x } }                               \by {def.~$\fcom$} \\
&= \alpha \funparen{ g \ast \paren { \finv \alpha x } \ast \ginv g }                 \by {pela escolha de $g$} \\
&= \alpha g \ast \alpha \funparen { \finv \alpha x } \ast \alpha \funparen {\ginv g} \by {$\alpha$ homo: resp.~op.} \\
&= \alpha g \ast \paren{\alpha \fcom \finv \alpha} x \ast \alpha \funparen {\ginv g} \by {def.~$\fcom$} \\
&= \alpha g \ast x \ast \alpha \funparen {\ginv g}                                   \by {def.~$\finv \alpha$} \\
&= \alpha g \ast x \ast \ginvp {\alpha g}                                            \by {$\alpha$ homo: resp.~inv.} \\
\endcompute
e logo $\alpha f \ginv{\alpha} \in \Inn G$.

%%}}}

%%{{{ prob: normal_is_not_an_order 
\problem.
%%%{{{ meta 
\label normal_is_not_an_order
%%%}}}

A relação $\normal$ é uma ordem?

\hint
Não é!
Ela não é transitiva.
Demonstre!

\hint
Basta achar contraexemplo: grupo $G$ e subgrupos $A,B \subgrp G$
tais que $A \normal B \normal G$ mas $A \nnormal G$.

\hint
Procure teu contraexemplo no $G \asseq \sym 4$ e seus subgrupos
(considere o $A \asseq \gen{\permc{1 & 2}\permc{3 & 4}}$.
Alternativamente, procure no $\dih 4$ e seus subgrupos;
talvez olhando para o diagrama Hasse do $\dih 4$ ajuda.

%%}}}

%%{{{ prob: normal_is_kernel 
\problem kernel = normal.
%%%{{{ meta 
\label normal_is_kernel
%%%}}}

Já demonstramos algo que informalmente falando podemos escrever assim:
$$
\text{kernel} \implies \text{normal}
$$
Formalize e demonstre o converso.

\hint
Formalização:
{\proclaimstyle
Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}

\hint
O $G'$ é o $\quogrp G N$.

\solution
Formalização:
{\proclaimstyle Seja $G$ grupo e $N \normal G$.
Logo existem grupo $G'$ e homomorfismo $\phi : G \to G'$
tal que $N$ é o kernel de $\phi$.}
\crproofpart {\proofname.}
Considere o grupo $\quogrp G N$ e
defina a $\phi : G \to \quogrp G N$
pela
$$
\phi(x) = Nx.
$$
Basta demonstrar que:
\tlist:
\li (i):  $\phi$ é um homomorfismo;
\li (ii): $\ker\phi = N$.
\endtlist
(i) Basta verificar que $\phi$ respeita a operação.
Sejam $x,y \in G$.
Calculamos
$$
\phi (xy) = N(xy) = (Nx)(Ny) = \phi(x) \phi(y).
$$
(ii) Temos
\compute
x\in \ker\phi
&\iff \phi(x) = e_{\quogrp G N} \by {def.~$\ker\phi$} \\
&\iff \phi(x) = N    \by {$N$ é a identidade do $\quogrp G N$} \\
&\iff Nx = N         \by {def.~$\phi$} \\
&\iff x \in N.       \by {\ref[Ha_eq_H_iff_a_in_H]} \\
\endcompute
Ou seja, $\ker\phi = N$.
\eop
Com isso concluimos que na teoria dos grupos,
``subgrupo normal'' e ``kernel'' são dois lados da mesma moeda.

%%}}}

%%{{{ prob: cayley_theorem 
\problem Teorema de Cayley.
%%%{{{ meta 
\label cayley_theorem
%%%}}}

\TODO Outline Cayley's theorem.

%%}}}

%%{{{ prob: cauchy_theorem 
\problem Teorema de Cauchy.
%%%{{{ meta 
\label cauchy_theorem_groups
%%%}}}

\TODO Outline Cauchy's theorem.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Para practicar com propriedades de operações vale a pena
resolver os primeiros 15 problemas do~\cite[halmoslapb].

Livros introdutórios de álgebra abstrata tratam em geral
a teoria dos grupos mais profundamente ou extensamente do que
podemos tratá-la aqui.
\cite[pinteralgebra] é um desses livros, bastante acessível,
com exemplos de diversas áreas, mostrando várias aplicações.
Uma \emph{excelente} introdução em vários tópicos de álgebra é
o~\cite[hersteintopics], famoso para sua exposição e didáctica.

O assunto da álgebra abstrata foi composto e tratado numa maneira organizada
no \emph{Moderne Algebra}
de van~der~Waerden{\vanderWaerden}
(dois volúmes: \yearof{1930}, \yearof{1931};
modernas edições traduzidas: \cite[vanderWaerden1], \cite[vanderWaerden2]).
Ele foi baseado principalmente em aulas dadas por Artin{\Artin} e Noether{\Noether}.
e é um dos livros mais influenciadores e importantes em matemática.

Birkhoff{\Birkhoff} e Mac~Lane{\MacLane} trazeram o assunto para os currículos
de graduação com o clássico~\cite[babybm].
Os mesmos autores, no~\cite[papamb], apresentam álgebra mais profundamente e
com um cheiro categórico (veja~\ref[Category_theory]),
algo expectado já que Mac~Lane é um dos fundadores da teoria das categorias
(o outro é o Eilenberg{\Eilenberg}).

Infelizmente, muitos livros (e professores) consideram a teoria das categorias
como algo avançado ou difícil para ser introduzido neste nível
(e geralmente o primeiro contato com categorias chega bem depois
dos primeiros contatos com álgebra abstrata).
Felizmente, o bem-legível \cite[aluffialgebra] é uma excessão brilhante dessa
tradição: começa já introduzindo a linguagem
e as idéias das categorias e trata assim todos os assuntos principais
de álgebra abstrata.
(Essa seria minha maior recomendação para o meu leitor que ficou
animado com o conteudo deste capítulo e do próximo.)

Depois de se acostumar com as idéias algébricas em geral,
dois livros focados especialmente em teoria dos grupos
são os~\cite[rosegroups] e~\cite[rotmangroups].

O convex hull que encontramos \emph{en passant} neste capítulo
gera um problema algorítmico muito interessante:
\emph{dado um conjunto $A$ de pontos dum espaço euclideano
calcule um óptimo $C \subset A$ tal que seus pontos
são as vértices do convex hull do $A$}.
Para mais sobre isso, veja por exemplo o~\cite[clrs: \S33.3].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Algebraic_structures 
\chapter Estruturas algébricas.
%%%{{{ meta 
\label Algebraic_structures
%%%}}}

%%{{{ Semigroups 
\section Semigrupos.
%%%{{{ meta 
\label Semigroups
%%%}}}

%%{{{ semigroups_monoids_groups_abelians 
\note.
%%%{{{ meta 
\label groups_and_abelian_groups_schematically
%%%}}}

Esquematicamente:
$$
% left braces
\gathered
\text{monóide}
\leftbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2
\endgathered
}
\\
\vphantom3\\
\vphantom4\\
\endgathered
\gathered
\text{semigrupo}
\leftbrace {
\gathered
\vphantom0\\
\vphantom1
\endgathered
}
\\
\vphantom2\\
\vphantom3\\
\vphantom4\\
\endgathered
% body
\gathered
\text{(fechado)}\\
\text{(associatividade)}\\
\text{(identidade)}\\
\text{(inversos)}\\
\text{(comutatividade)}
\endgathered
% right braces
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3
\endgathered
}
\text{grupo}\\
\vphantom4\\
\endgathered
\gathered
\rightbrace {
\gathered
\vphantom0\\
\vphantom1\\
\vphantom2\\
\vphantom3\\
\vphantom4
\endgathered
}
\text{grupo abeliano}
\endgathered
$$

%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Monoids 
\section Monóides.
%%%{{{ meta 
\label Monoids
%%%}}}

%%{{{ df: monoid 
\definition Monóide.
%%%{{{ meta 
\label monoid
\defines
    * monóide
    ;;
%%%}}}

Um conjunto estruturado $\cal M = \sset M {\cdot,\epsilon}$
é um \dterm{monóide} sse:
\mathcol
\cforall {a,b\in M}    {a\cdot b \in M}                         \tag{G0} \\
\cforall {a,b,c\in M}  {a\cdot(b\cdot c) = (a\cdot b)\cdot c}   \tag{G1} \\
\cforall {a\in M}      {\epsilon\cdot a = a = a\cdot\epsilon}.  \tag{G2} \\
\endmathcol
Naturalmente, se a $\cdot$ é comutativa chamamos $M$ de \dterm{monóide comutativo}.

%%}}}

%%{{{ eg: any group is a monoid 
\example.
%%%{{{ meta 
%%%}}}

A partir de qualquer exemplo de grupo
$\cal G = \sset G {\ast_G, \ginv{}, \gidof G}$
temos um exemplo de monóide também:
o~$\sset G {\ast_G, \gidof G}$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mais interessantes agora seriam exemplos de monóides
que não são grupos:

%%}}}

%%{{{ eg: nats with addition 
\example.
%%%{{{ meta 
%%%}}}

Os naturais com adição formam um monóide.

%%}}}

%%{{{ eg: positive nats with multiplication 
\example.
%%%{{{ meta 
%%%}}}

O $\sset {\nats_{\neq0}} {\ntimes}$ é um monóide.

%%}}}

%%{{{ eg: strings 
\example Strings.
%%%{{{ meta 
%%%}}}

Considere um alfabeto finito $\Sigma$ e seja $\kstar\Sigma$
o conjunto de todos os strings formados por letras do $\Sigma$.
O $\kstar \Sigma$ com a operação a concatenação de strings,
é um monóide.  Sua identidade é o string vazio.

%%}}}

%%{{{ Q: How would you define the submonoid relation? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias a relação de submonóide?

%%}}}

\spoiler

%%{{{ df: submonoid 
\definition submonóide.
%%%{{{ meta 
\label submonoid
\defines
    * submonóide
    ;;
%%%}}}

Seja $\cal M = \sset M {\cdot_M,\epsilon_M}$ monóide
e $H \subset M$.
O $H$ é um submonóide de $M$ sse $\epsilon_M \in H$
e $H$ é $\cdot_M$-fechado.

%%}}}

%%{{{ remark: same abuses as always 
\remark abusamos como sempre.
%%%{{{ meta 
%%%}}}

Literalmente não é o conjunto $H$ que é submonóide,
mas o conjunto estruturado
$$
\cal H \asseq \text{$\sset H {{{\cdot_M} \restosub {N \times N}}, \epsilon_M}$}.
$$
Eu presumo que tu és acostumado com esses abusos depois que
os discutimos nos itens~\reftag[notational_abuse_structured_sets]
e~\reftag[notational_abuse_groups].

%%}}}

%%{{{ Q: How would you define homomorphism between monoids? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias o homomorfismo entre monóides?

%%}}}

\spoiler

%%{{{ df: monoid_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label monoid_homomorphism
\defines
    * homomorfismo!de monóide
    ;;
%%%}}}

Sejam $\cal M = \sset M {\cdot_M,\epsilon_M}$
e $\cal N = \sset N {\cdot_N,\epsilon_N}$ monóides.
Uma função $\phi : M \to N$ é um \dterm{homomorfismo} sse:
% TODO: fix reflabs
\elist i:
\li: para todo $x,y\in M$,\quad $\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)$.
\li: $\phi(\epsilon_M) = \epsilon_N$;
\endelist

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Considere os monóides $\cal N = \sset \nats {+, 0}$ e
$\cal B = \sset B {\concat,\epsilon}$, onde:
$B$ é o conjunto de todos os strings (finitos) binários,
ou seja, $B=\kstar{\set{\digit 0,\digit 1}}$;
$\epsilon$ é o string vazio ``$\,$'';
$\concat$ a concatenação.
A $\phi : \cal N \to \cal B$ definida recursivamente pelas
$$
\align
\phi(0)     &= \epsilon\\
\phi(n+1)   &= \phi(n) \concat \digit0
\endalign
$$
é um homomorfismo.
A $\namedfun{length} : \cal B \to \cal N$ que retorna o tamanho da sua entrada é um homomorfismo.

%%}}}

%%{{{ noneg 
\nonexample.
%%%{{{ meta 
%%%}}}

Com o contexto do exemplo anterior, a $\psi : \cal N \to \cal B$
definida recursivamente pelas:
$$
\align
\psi(0)     &= \epsilon\\
\psi(n+1)   &=
\knuthcases {
\psi(n) \concat \digit0, & se $\psi(n)$ não termina com $\digit0$\cr
\psi(n) \concat \digit1, & caso contrário
}
\endalign
$$
não é um homomorfismo.

%%}}}

%%{{{ x: why? 
\exercise.
%%%{{{ meta 
%%%}}}

Por quê?

\solution
Temos:
$$
\psi(1+1)
= \digit0\digit1
\neq \digit0\digit0
= \psi(1)\concat\psi(1).
$$

%%}}}

%%{{{ beware: not everything comes for free 
\beware.
%%%{{{ meta 
%%%}}}

No~\ref[Group_theory] assim que definimos o que significa homomorfismo
de grupos~(\reftag[group_homomorphism]) demonstramos
o~\ref[criterion_for_morphism_in_groups] que nos permite concluir
que uma função entre grupos é homomorfismo assim que
souber que ela respeita a operação.
Isso quer dizer que temos esse critério nos monóides também?
Primeiramente olhamos para a demonstração
do~\ref[criterion_for_morphism_in_groups] para ver se
ela ``passa'' nos monóides também:
se ela usou apenas os (G0)--(G2), então passa.
Não é o caso: \emph{essa} demonstração necessitou o (G3)
pois usou os inversos.
Então isso quer dizer que perdemos esse critério nos monóides?
\emph{Não!}
O que perdemos foi a demonstração; mas talvez existe
outra que segura o mesmo teorema, e que não necessita os inversos.
Será?

%%}}}

%%{{{ x: in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity 
\exercise.
%%%{{{ meta 
\label in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity
%%%}}}

Podemos demonstrar um critérion parecido com
o~\ref[criterion_for_morphism_in_groups] para os monóides?
Ou seja, se $\phi$ preserva a operação do monóide,
ela necessariamente preserva a identidade também?

\hint
Não!
Mas como podemos demonstrar que não tem como demonstrar isso?

\hint
Procure um contraexemplo:
monóides $\cal M, \cal N$ e função $\phi : M \to N$ tais que
$\phi$ preserva a operação do monóide mas não a identidade.

%%}}}

%%{{{ criterion: monoid_morphism_criterion 
\criterion.
%%%{{{ meta 
\label monoid_morphism_criterion
%%%}}}

Uma função sobrejetora $\phi : M \surto N$ tal que
$$
\text{para todo $x,y\in M$},\quad
\phi(x \cdot_M y) = \phi(x) \cdot_N \phi(y)
$$
é um homomorfismo.

\proof Demonstrarás agora no~\ref[monoid_morphism_criterion_proof].

%%}}}

%%{{{ x: monoid_morphism_criterion_proof 
\exercise Critérion.
%%%{{{ meta 
\label monoid_morphism_criterion_proof
%%%}}}

Demonstre o~\ref[monoid_morphism_criterion].

\hint
Precisamos demonstrar que $\phi(\epsilon_M) = \epsilon_N$.
Como podemos ler essa igualdade em lingua (mais) natural?

\hint
Queremos: \wq{o $\phi(\epsilon_M)$ é a identidade do $\cal N$}.
O que significa \wq{ser a identidade dum monóide}?
Ou seja, o que precisamos demonstrar sobre esse objeto, $\phi(\epsilon_M)$
para mostrar que realmente ele é a identidade?

\hint
Precisamos demonstrar que:
$$
\lforall {n \in N} {n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n}.
$$
Como começaria essa demonstração?

\hint
\wq{Seja $n \in N$.}
Depois dessa frase, queremos demonstrar que
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) n.
$$

\hint
Já demonstramos no~\ref[in_monoids_preservation_of_oper_does_not_imply_preservation_of_identity] que não tem como ganhar a preservação da identidade como conseqüência da preservação da operação tendo uma função $\phi : M \to N$ qualquer.  Então com certeza precisamos usar nossa hipótese nova aqui, que a $\phi$ é sobrejetora.

\hint
Seja $n \in N$.
Como $\phi$ é sobrejetora, tome $m \in M$ tal que $\phi(m) = n$.

\solution
Vamos demonstrar que $\phi(\epsilon_M) = \epsilon_N$, ou seja, que para todo $n\in N$, 
$$
n \cdot_N \phi(\epsilon_M) = n = \phi(\epsilon_M) \cdot_N n.
$$
Seja $n \in N$.
Logo $n = \phi(m)$ para algum $m \in M$ (pois $\phi$ sobre $N$).
Calculamos:
\compute
n\cdot_N \phi(\epsilon_M)
&= \phi(m) \cdot_N \phi(\epsilon_M) \by {pela escolha do $m$} \\
&= \phi(m \cdot_M \epsilon_M)       \by {$\phi$ homo: resp.~op.} \\
&= \phi(m)                          \by {pela (G2)} \\
&= n                                \by {pela escolha do $m$} \\
\endcompute
Similarmente, $n = \phi(\epsilon_M) \cdot_N n$.
\eop
Alternativamente, podemos começar assim:
seja $m \in M$ tal que $\phi(m) = e_N$; e agora
\compute
\phi(e_M)
&= \phi(e_M) e_N        \by {def.~$e_N$} \\
&= \phi(e_M) \phi(m)    \by {pela escolha de $m$} \\
&= \phi(e_M m)          \by {$\phi$ homo: resp.~op.} \\
&= \phi(m)              \by {def.~$e_M$} \\
&= e_N.                 \by {pela escolha de $m$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Rings 
\section Anéis.
%%%{{{ meta 
\label Rings
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos estudar pouco a estrutura de \emph{anel},
cuja definição foi dada primeiramente por {\Fraenkel}Fraenkel.
Nossa inspiração e guia para os grupos, foram os mapeamentos e as permutações.
Para os anéis, nossa guia são os inteiros.

%%}}}

%%{{{ df: ring 
\definition Anel.
%%%{{{ meta 
\label ring
\defines
    * anel
    * anel!comutativo
    ;;
%%%}}}

Seja $\cal R = \sset R {\plus,\,\ntimes,0,1}$ um conjunto estruturado,
onde $\plus,\ntimes$ são operações binárias
e $0,1$ são constantes.
$\cal R$ é um \dterm{anel} ou \dterm{ring} sse
\mathcol
\cforall {a,b\in R}                 {a\plus b \in R}                               \tag{RA0} \\
\cforall {a,b,c\in R}               {a\plus(b\plus c) = (a\plus b)\plus c}         \tag{RA1} \\
\cforall {a \in R}                  {0\plus a = a = a\plus 0}                      \tag{RA2} \\
\pforall {a\in R} \cexists {y\in R} {y\plus a = 0 = a \plus y}                     \tag{RA3} \\
\cforall {a,b\in R}                 {a\plus b = b \plus a}                         \tag{RA4} \\
\cforall {a,b\in R}                 {a\ntimes b \in R}                             \tag{RM0} \\
\cforall {a,b,c\in R}               {a\ntimes(b\ntimes c) = (a\ntimes b)\ntimes c} \tag{RM1} \\
\cforall {a \in R}                  {1\ntimes a = a = a\ntimes 1}                  \tag{RM2} \\
\cforall {a,b,c \in R}              {a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)} \tag{RDL} \\
\cforall {a,b,c \in R}              {(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)} \tag{RDR} \\
\intertext{Caso que também é satisfeita a}
\cforall {a,b\in R}                 {a\ntimes b = b \ntimes a}.                    \tag{RM4} \\
\endmathcol
chamamos o $\cal R$ \dterm{anel comutativo}.

%%}}}

%%{{{ x: rings_with_different_structures 
\exercise.
%%%{{{ meta 
\label rings_with_different_structures
%%%}}}

Acima escolhemos a maneira ``intermediaria'' de estrutura.
Qual seria uma estrutura ``mais completa'' para definir o conceito de anel, e qual uma estrutura mais pobre?
Descreva as aridades dos símbolos usados (a assinatura da estrutura algébrica).

\solution
A estrutura mais completa:
$$
\sset R {+,\ntimes,-,0,1}
$$
onde seus símbolos têm as aridades $(2,2,1,0,0)$ respectivamente.
A estrutura mais pobre:
$$
\sset R {+,\ntimes}
$$
com assinatura $(2,2)$.

%%}}}

%%{{{ x: ring_definition_using_groups 
\exercise.
%%%{{{ meta 
\label ring_definition_using_groups
%%%}}}

Como podemos definir o que é um anel usando definições de estruturas algébricas que já conhecemos?

\solution
Seja $\cal R = \sset R {\plus, \ntimes, -, 0, 1}$ um conjunto estruturado,
onde $0,1$ são constantes, $\plus,\ntimes$ são operações binárias, e $-$ unária.
O $\cal R$ é um \dterm{anel} sse:
\item{(i)} $\sset R {\plus, -, 0}$ é um grupo abeliano;
\item{(ii)} $\sset R {\ntimes, 1}$ é um monóide;
\item{(iii)} as seguintes leis são satisfeitas:
\mathcol
\cforall {a,b,c \in R} {a\ntimes (b \plus c) = (a\ntimes b) \plus (a \ntimes c)}  \tag{RDL} \\
\cforall {a,b,c \in R} {(b \plus c)\ntimes a = (b\ntimes a) \plus (c \ntimes a)}. \tag{RDR} \\
\endmathcol

%%}}}

%%{{{ beware: ring_or_rng
\beware Ring ou Rng?.
%%%{{{ meta 
\label ring_or_rng
\defines
    * rng
    ;;
%%%}}}

Na definição de \dterm{ring} que usamos aqui necessitamos ter
$(\ntimes)$\,-identidade (unidade).  Infelizmente isso não é padrão:
especialmente em textos antigos (mas também dependendo do objetivo de cada
texto) anéis podem necessitar ou não esse axioma, e logo vendo a palavra
``anel'' num texto, precisamos confirmar qual é a definição usada.
Para a gente aqui, quando queremos referir à estrutura que não necessita
identidades chamamos de \dterm{rng}, a idéia sendo que é como um ``ring''
sem $i$\,(dentidade).\foot
Tentando traduzir ``rng'' para português, tanto ``ael'' quanto ``anl''
funcionam mas não muito bem: na primeira opção perdemos o elemento \emph{n}eutro
da $(\ntimes)$ e na segunda perdemos o $e$ do monóide multiplicativo, mas nenhuma
das opções fica boa, então melhor esquecer esses termos e usar \emph{rng} o  mesmo.
\toof
No outro lado, quem não considera esse axioma como parte de \emph{ser um ring},
refere aos nossos rings como ``ring com unidade'', ``ring com $1$'', ``ring unital'' etc.
Às vezes o termo \dterm{pseudoring} é usado mas este é um termo ainda mais
sobrecarregado, então melhor usar ``rng'' que sempre tem o mesmo significado.
No \cite[poonenrings] encontrarás mais sobre a escolha da nossa \ref[ring]
mas sugiro não consultá-lo antes de pensar sobre o exercício seguinte primeiro:

%}}}

%%{{{ x: justify_unit_in_ring_def 
\exercise.
%%%{{{ meta 
\label justify_unit_in_ring_def 
%%%}}}

Tu escolherias incluir o $1$ na definição de ring?  Por quê?

%%}}}

%%{{{ df: defined_ops_in_rings 
\definition.
%%%{{{ meta 
\label defined_ops_in_rings
%%%}}}

Dado $x\in R$, denotamos com $(-x)$ o objeto garantido pela~(RA3).
Seguindo nossa experiência com adição e multiplicação de números,
adoptamos as mesmas convenções para os anéis: denotamos pela justaposição
a ``multiplicação'' do anel, e consideramos que ela tem precedência contra a ``adição''.
Note também que como não temos alguma operação binária $-$ de subtraição,
a expressão $x-y$ num anel não é definida.
Definimos a operação \emph{binária} $-$ num anel $R$ pela
$$
x - y \sugareq x + (-y).
$$
Pelo contexto sempre dará pra inferir a aridade do símbolo \symq{$-$};
então não tem como criar ambigüidade com a operação \emph{unária} $-$,
mesmo compartilhando o mesmo símbolo.
Continuando, se $n\in\nats$, usamos:
$$
\xalignat2
nx   &\sugareq \tubrace{x + x + \dotsb + x} {$n$ vezes} &
x^n  &\sugareq \tubrace{x x \dotsb x} {$n$ vezes}.
\intertext{Ou seja, lembrando da notação do~\ref[powers_in_group]:}
nx   &\sugareq x^{+n} &
x^n  &\sugareq x^{\ntimes n}.
\endxalignat
$$

%%}}}

%%{{{ eg: first_ring_examples 
\example.
%%%{{{ meta 
\label first_ring_examples
%%%}}}

Todos os seguintes conjuntos são exemplos de anéis:
$$
\xalignat7
&\sset \ints                {+,\ntimes}&
&\sset \rats                {+,\ntimes}&
&\sset \reals               {+,\ntimes}&
&\sset \complex             {+,\ntimes}&
&\sset {\polys\reals x}     {+,\ntimes}&
&\sset {C[a,b]}             {+,\ntimes}&
&\sset {\reals^{n\times n}} {+,\ntimes}
\endxalignat
$$
onde lembramos que
$\polys\reals x$ é o conjunto de todos os polinómios numa variável $x$ com coeficientes
reais,
e $\reals^{n\times n}$ é o conjunto de todas as matrices reais $n\times n$.
Temos também
$$
C[a,b]
\defeq
\setstt {f : [a,b]\to\reals} {$f$ é contínua}
$$
para quaisquer $a,b\in\reals$ com $a\leq b$.
A adição e multiplicação no $C[a,b]$ são as
\emph{operações pointwise}\indexed[pointwise!operação],
definidas pelas:
$$
\xalignat2
f + g       &= \lam x {f(x) + g(x)}         &
f \ntimes g &= \lam x {f(x) \ntimes g(x)}.
\endxalignat
$$
(Veja a~\ref[pointwise_operation].)

%%}}}

%%{{{ eg: End_G_is_a_ring_claim 
\example.
%%%{{{ meta 
%%%}}}

Fez o~\ref[hom_abel_with_pointwise_plus]?\foot
Não?  Vá lá fazer agora e volte assim que resolver.
\toof
Quem fez, sabe que se $G'$ é abeliano, então o
$\sset {\Hom(G,G)} +$ onde $(+)$ é a operação pointwise
baseada no $+_{G'}$.
Em particular, para qualquer grupo abeliano $G$ o conjunto
$$
\End(G) \defeq \Hom(G,G)
$$
vira um grupo abeliano $\sset {\End(G)} +$.
Mas no mesmo conjunto uma outra operação interessante é a composição.
O $\sset {\End(G)} {+,\com}$ é um anel.

%%}}}

%%{{{ x: End_G_is_a_ring_proof 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre!

%%}}}

%%{{{ df: zero_ring 
\definition.
%%%{{{ meta 
\label zero_ring
%%%}}}

Se num anel $R$ temos $0_R = 1_R$ chamamos o $R$ de \dterm{anel zero}.
Caso contrário \dterm{anel não-zero}.

%%}}}

%%{{{ lemma: ring_zero_absorbs 
\lemma Zero absorve.
%%%{{{ meta 
\label ring_zero_absorbs
%%%}}}

Seja $R$ um anel.
Então:
$$
\text{para todo $x\in R$,}\quad
0x = 0 = x0.
$$

\proof.
Seja $x\in R$.
Calculamos:
\compute
0x
&= (0 + 0)x  \by {def.~$0$} \\
&= 0x + 0x   \by {pela~(RDR)} \\
\endcompute
Achamos então que $0x$ é uma resolução da $0x + \askbox = 0x$.
E como o $\sset R +$ é um grupo sabemos então que $0x = 0$
(\ref[cheaper_gid]) que foi o que queremos demonstrar.

%%}}}

%%{{{ corollary: a zero ring is a singleton 
\corollary.
%%%{{{ meta 
%%%}}}

Se $R$ é um anel zero, $R$ é um singleton.

\proof.
Seja $r \in R$.  Calculamos:
$$
r = r1_R = r0_R = 0_R.
$$

%%}}}

%%{{{ x: ring_negation_of_difference 
\exercise.
%%%{{{ meta 
\label ring_negation_of_difference
%%%}}}

Para todo $a,b\in R$,
$$
-(a - b) = b - a.
$$

%%}}}

%%{{{ lemma: ring_negation_of_product 
\lemma Negação de produto.
%%%{{{ meta 
\label ring_negation_of_product
%%%}}}

Seja $R$ um anel.  Logo,
$$
\text{para todo $a,b\in R$,}\quad
(-a)b = -(ab) = a(-b).
$$

\sketch.
Para demonstrar a primeira igualdade, basta enxergá-la como a afirmação seguinte:
\emph{o $(-a)b$ é o $(+)$-inverso do $ab$}.
Verificamos então que $ab + (-a)b = 0$.
A outra igualdade é similar.

\proof.
Verificamos que $(-a)b$ realmente é o inverso de $ab$:
\compute
ab + (-a)b
&= (a + (-a))b  \by {pela (RDR)} \\
&= 0b           \by {def.~$(-a)$} \\
&= 0            \by {\ref[ring_zero_absorbs] com $x\asseq b$} \\
\endcompute
e como a equação $ab + \askbox$ tem resolução única
(pois o $\sset R +$ é um grupo)
e o $-(ab)$ também a resolve,
concluimos que $(-a)b = -(ab)$.
A outra igualdade é similar.

%%}}}

%%{{{ corollary 
\corollary.
%%%{{{ meta 
%%%}}}

Em qualquer anel $\cal R$, para todos $x,y\in\cal R$ temos:
\item{\rm (i)}   $(-x)(-y) = xy$;
\item{\rm (ii)}  $(-1)x = -x$;
\item{\rm (iii)} $(-1)(-1) = 1$;
\item{\rm (iv)}  $-(x+y) = (-x) + (-y)$.

%%}}}

%%{{{ x: pset_with_setops_ring 
\exercise.
%%%{{{ meta 
\label pset_with_setops_ring
%%%}}}

Seja $X$ conjunto.
Defina no $\pset X$ duas operações tais que $\pset X$ vira um anel.
Identifique quais são os seus $0,1$ e demonstre que realmente é um anel.

\hint
Lembre o~\ref[pset_with_setops_group]?

\hint
Graças ao~\ref[pset_with_setops_group], a adição do anel deve ser a $\symdiff$.

\hint
$\sset {\pset X} {\symdiff, \inter}$.

%%}}}

%%{{{ Q: How would you define subring and ring homomorphism? 
\question.
%%%{{{ meta 
%%%}}}

Como tu definirias o conceito de subanel?
Pode definir algum critérion parecido com os critéria~\reftag[nonempty_subgroup_criterion]
ou~\reftag[finite_subgroup_criterion] para decidir se algo é subanel dum dado anel?
E o homomorfismo de anel?  Como definirias isso?  E pode definir algum critérion
parecido com o~\reftag[criterion_for_morphism_in_groups]?

%%}}}

\spoiler

%%{{{ df: subring 
\definition subanel.
%%%{{{ meta 
\label subring
\defines
    * subanel
    ;;
%%%}}}

Seja $\cal R$ um anel.
O $S\subset R$ é um \dterm{subanel} de $\cal R$ sse
$\sset S {+_R, \cdot_R,0_R, 1_R}$ é um anel.

%%}}}

%%{{{ criterion: subring_criterion 
\criterion de subanel.
%%%{{{ meta 
\label subring_criterion
%%%}}}

Sejam $R$ anel e $S \subset R$.
O $S$ é um subanel de $R$ sse:
\item{\rm (i)}  $S$ tem a identidade do $R$: $1_R \in S$;
\item{\rm (ii)} $S$ é fechado sob a adição: para todo $a,b \in S$, $a+b \in S$;
\item{\rm (iii)}$S$ é fechado sob a multiplicação: para todo $a,b \in S$, $ab \in S$;
\item{\rm (iv)} $S$ é fechado sob negativos: para todo $a \in S$, $-a\in S$.

%%}}}

%%{{{ df: ring_homomorphism 
\definition homomorfismo.
%%%{{{ meta 
\label ring_homomorphism
\defines
    * homomorfismo!de anel
    ;;
%%%}}}

Sejam os anéis
$\cal R = \sset R {+_R, \cdot_R, 0_R, 1_R}$ e
$\cal S = \sset S {+_S, \cdot_S, 0_S, 1_S}$.
A~função $\phi : R \to S$ é um homomorfismo sse:
\item{\rm (i)}   $\phi(0_R) = 0_S$;
\item{\rm (ii)}  $\phi(1_R) = 1_S$;
\item{\rm (iii)} para todo $x,y\in R$, $\phi(x+_R y) = \phi(x) +_S \phi(y)$;
\item{\rm (iv)}  para todo $x,y\in R$, $\phi(x\cdot_R y) = \phi(x) \cdot_S \phi(y)$;
\item{\rm (v)}   para todo $x\in R$, $\phi(-x) = -(\phi(x))$.

%%}}}

%%{{{ criterion: ring_homomorphism_criterion 
\criterion de homomorfismo.
%%%{{{ meta 
\label ring_homomorphism_criterion
%%%}}}

Se a função $\phi : \cal R \to \cal S$ satisfaz:
$$
\align
\phi(1_R)           &= 1_S\\
\phi(x +_R y)       &= \phi(x) +_S \phi(y)\quad\text{para todo $x,y\in R$}\\
\phi(x \cdot_R y)   &= \phi(x) \cdot_S \phi(y)\quad\text{para todo $x,y \in R$}
\endalign
$$
então ela é um homomorfismo.
(Ou seja, podemos apagar os itens (i) e (v) na~\ref[ring_homomorphism].)

\proof.
Como $\sset R {+_R}$ e $\sset S {+_S}$ são grupos,
sabemos que se $\phi$ respeita a operação aditiva então
ela necessariamente respeita sua identidade e seus inversos
também~(\ref[criterion_for_morphism_in_groups]).

%%}}}

%%{{{ x: multiplicative_part_of_a_ring_not_a_group 
\exercise.
%%%{{{ meta 
\label multiplicative_part_of_a_ring_not_a_group
%%%}}}

As leis de anel exigem que sua parte aditiva é um grupo abeliano,
e que sua parte multiplicativa é um monóide.
Pode ter anel $\cal R = \sset R {+,\ntimes,0,1}$ cuja parte multiplicativa
realmente forma um grupo?
Ou seja, tal que $\sset R {\ntimes, 1}$ é um grupo?
Se sim, mostre um exemplo de tal anel;
se não, demonstre que não existe tal anel.

\hint
\ref[ring_zero_absorbs].

\hint
Não pode.  Exceto se\dots

\solution
Se é pra ter tal anel $R$, qual seria o inverso de $0$?
Pelo~\ref[ring_zero_absorbs] temos que
$$
0 x = 0
$$
para todo $x\in R$, e logo para $x \asseq \ginv 0$ também:
$$
0 \ginv 0 = 0
$$
Mas $0 \ginv 0 = 1$ pela definição de $\ginv 0$, e logo
$$
0 = 0 \ginv 0 = 1.
$$
Necessariamente então, em tal ring temos $0=1$.
Pode ter mais membros além do $0$?
Não!
Seja $r\in R$.
Temos então
\compute
r
&= 1r \by {def.~$1$} \\
&= 0r \by {pois 0=1} \\
&= 0  \by {pelo~\ref[ring_zero_absorbs]} \\
\endcompute
e logo $R = \set {0_R}$.

%%}}}

%%{{{ df: kernel_image_in_rings 
\definition kernel, image.
%%%{{{ meta 
\label kernel_image_in_rings
%%%}}}

Seja $\phi : R \to S$ homomorfismo de anéis.
$$
\alignat2
\ker\phi
&\defeq \pre \phi {\set{0_S}} &
\quad\big(&= \setst {r \in R} {\phi(r) = 0_S} \ \big)\\
\ima\phi
&\defeq \img \phi R &
\quad\big(&= \setst {s \in S} {\lexists {r\in R} {\phi(r) = s}} \ \big)
\endalignat
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Podemos já demonstrar o equivalente do~\ref[image_subgroup] que encontramos
nos grupos, para os anéis:

%%}}}

%%{{{ lemma: image_subring 
\lemma.
%%%{{{ meta 
\label image_subring
%%%}}}

Seja $\phi : R \to S$ um homomorfismo de anéis.
Sua imagem $\ima\phi$ é um subanel de $S$.

\sketch.
Usamos o~\ref[subring_criterion] e a definição de $\ima\phi$.

\proof.
Tome $a,b\in \ima\phi$.  Logo
$$
\alignat2
a &= \phi(a') &\quad&\text{para algum $a' \in R$}\\
b &= \phi(b') &\quad&\text{para algum $b' \in R$}.
\endalignat
$$
Calculamos:
\compute
1_S
&= \phi(1_R);           \by {$\phi$ homo ($1$)} \\
a + b
&= \phi(a') + \phi(b')  \by {pela escolha dos $a',b'$} \\
&= \phi(a'+b');         \by {$\phi$ homo ($(+)$)} \\
-a
&= -\phi(a')            \by {pela escolha do $a'$} \\
&= \phi(-a');           \by {$\phi$ homo ($-$)} \\
ab
&= \phi(a')\phi(b')     \by {pela escolha dos $a',b'$} \\
&= \phi(a'b').          \by {$\phi$ homo ($\cdot$)} \\
\endcompute
Ou seja:  $1_S, a+b, -a, ab \in \ima\phi$ e podemos usar
o~\ref[subring_criterion].

%%}}}

%%{{{ Q: Is the kernel cooler than just a subring? 
\question.
%%%{{{ meta 
%%%}}}

Será que o kernel é algo mais-legal-que-subanel na mesma
forma que aconteceu nos grupos?

%%}}}

\spoiler

%%{{{ x: 
\exercise.
%%%{{{ meta 
%%%}}}

Seja $\phi : R \homto S$.
O que consegues demonstrar entre o $\ker\phi$ e o $R$?

%%}}}

\endsection
%%}}}

%%{{{ Boolean rings 
\section Anéis booleanos.
%%%{{{ meta 
\label Boolean_rings
%%%}}}

%%{{{ df: boolean_ring 
\definition Anel booleano.
%%%{{{ meta 
\label boolean_ring
\defines
    * anel!booleano
    ;;
%%%}}}

Chamamos o anel $\cal R$ um \dterm{anel booleano} sse
sua multiplicação é \indexed[idempotência]\emph{idempotente}, ou seja:
$$
\text{para todo $a\in \cal R$},\quad
a^2 = a.
$$

%%}}}

%%{{{ eg 
\example.
%%%{{{ meta 
%%%}}}

Dado conjunto $X$, o $\sset {\pset X} {\symdiff, \inter}$
é um anel booleano.

%%}}}

%%{{{ x: boolean_rings_are_idempotent 
\exercise.
%%%{{{ meta 
\label boolean_rings_are_idempotent
%%%}}}

Seja $\cal R$ um anel booleano.
Demonstre que:
$$
\text{para todo $p\in \cal R$},\quad
p = -p.
$$

\hint
$p + p = (p+p)^2 = \dotsc$

\solution
Seja $p \in R$.
Calculamos:
\compute
p + p
&= (p+p)^2               \by {$R$ booleano} \\
&= (p+p)(p+p)            \\
&= (p+p)p + (p+p)q       \\
&= pp + pp + pp + pp     \\
&= p^2 + p^2 + p^2 + p^2 \\
&= p + p + p + p         \by {$R$ booleano} \\
&= p + p + (p + p)
\endcompute
e logo $p + p = 0$, ou seja, $p = -p$.

%%}}}

%%{{{ x: boolean_rings_negative_of_product 
\exercise.
%%%{{{ meta 
\label boolean_rings_negative_of_product
%%%}}}

Seja $\cal R$ um anel booleano.
Demonstre que:
$$
\text{para todo $p,q\in \cal R$},\quad
pq = -qp
$$
e mostre como isso gera mais uma demonstração
do~\ref[boolean_rings_are_idempotent].

\hint
Calcule o $(p+q)^2$.

\solution
Sejam $p,q \in R$.
Calculamos:
\compute
(p+q)^2
&= (p+q)(p+q)           \\
&= (p+q)p + (p+q)q      \\
&= pp + qp + pq + qq    \\
&= p^2 + qp + pq + q^2  \\
&= p + qp + pq + q.     \by {$B$ booleano} \\
\endcompute
Mas como $B$ é booleano temos também $(p+q)^2 = p+q$.
Ou seja
\compute
p + q &= p + qp + pq + q \\
      &= p + q + (qp + pq) \\
\intertext{e logo (\ref[cheaper_gid])}
0     &= qp + pq    \tag{1}
\endcompute
ou seja, $pq = -qp$.
\eop
Para ganhar o~\ref[boolean_rings_are_idempotent] como
corolário, é so tomar $q \asseq 1$.

%%}}}

%%{{{ x: boolean_rings_are_commutative 
\exercise.
%%%{{{ meta 
\label boolean_rings_are_commutative
%%%}}}

Todo anel booleano é comutativo.

\hint
Use os \ref[boolean_rings_are_idempotent]
e~\reftag[boolean_rings_negative_of_product].

\solution
Sejam $p,q$ membros dum anel booleano.
Temos
\compute
pq
&= -qp  \by {\ref[boolean_rings_negative_of_product], com $p \asseq p$ e $q \asseq q$} \\
&= qp.  \by {\ref[boolean_rings_are_idempotent], com $p \asseq qp$} \\
\endcompute

%%}}}

\endsection
%%}}}

%%{{{ Integral domains 
\section Domínios de integridade.
%%%{{{ meta 
\label Integral_domains
%%%}}}

%%{{{ df: zerodivisors 
\definition Divisores de zero.
%%%{{{ meta 
\label zerodivisors
\indexes
    * divisor de zero    see: zerodivisor
    ;;
\defines
    * zerodivisor
    ;;
%%%}}}

Seja $R$ um anel, e $x,y\in R$.
Se $xy = 0_R$ e nem $x=0_R$ nem $y=0_R$, chamamos os $x,y$
\dterm{divisores de zero} (ou \dterm{zerodivisores}) no $R$.

%%}}}

%%{{{ eg: ints_6 
\example.
%%%{{{ meta 
%%%}}}

No anel $\ints_6$, temos $2\ntimes 3 = 0$.
Logo ambos os $2,3$ são divisores de zero nesse anel.
O $4$ também é, pois $3\ntimes 4 = 0$ também.

%%}}}

%%{{{ eg: real_continuous_functions_zerodivisors 
\example.
%%%{{{ meta 
\label real_continuous_functions_zerodivisors
%%%}}}

Considere o anel $C[-1,1]$ com as operações~\indexed[pointwise!operação]pointwise
(veja~\ref[first_ring_examples]).
Tome as funções $f,g$ definidas pelas
$$
\xalignat2
f(x) &= \knuthcases {
-x, & se $x\leq 0$\cr
0,  & se $x > 0$
}&
g(x) &= \knuthcases {
0,  & se $x\leq 0$\cr
x,  & se $x > 0$.
}
\endxalignat
$$
Calculando, achamos
$$
f\ntimes g = \lam x 0_{C[-1,1]}
$$
e logo os $f,g$ são divisores de zero no $C[-1,1]$.

%%}}}

%%{{{ x: design_graphs_of_zerodevisor_real_continuous_functions 
\exercise.
%%%{{{ meta 
\label design_graphs_of_zerodevisor_real_continuous_functions
%%%}}}

Desenhe os gráficos das funções $f,g$
do~\ref[real_continuous_functions_zerodivisors],
e com um cálculo explique porque $f\ntimes g = 0$.

%%}}}

%%{{{ df: integral_domain_cancellation_domain 
\definition Domínio de integridade e de cancelamento.
%%%{{{ meta 
\label integral_domain_cancellation_domain
\defines
    * domínio de cancelamento
    * domínio de integridade
    ;;
%%%}}}

Seja $\cal D$ um anel comutativo.
Chamamos o $\cal D$ \dterm{domínio de integridade}
sse ele não tem zerodivisores, ou seja, sse:
$$
\text{para todo $x,y \in D$,}\quad
\text{se $xy=0$ então $x=0$ ou $y=0$}.
\tag{NZD}
$$
Chamamos o $\cal D$ \dterm{domínio de cancelamento}
sse
$$
\text{para todo $a,x,y \in D$,}\quad
ax = ay \mland a \neq 0 \implies x=y.
\tag{RCL}
$$
que é equivalente à
$$
\text{para todo $a,x,y \in D$,}\quad
xa = ya \mland a \neq 0 \implies x=y.
\tag{RCR}
$$
pois esse anel é comutativo.

%%}}}

%%{{{ criterion: integral_domain_equiv_cancellation_domain 
\criterion.
%%%{{{ meta 
\label integral_domain_equiv_cancellation_domain
%%%}}}

Os termos ``domínio de integridade'' e ``domínio de cancelamento''
são sinônimos, ou seja:
$$
\text{$D$ é um domínio de integridade} \iff \text{$D$ é um domínio de cancelamento}.
$$

\proof.
\proofpart {\lrdir:}
Sejam $a,x,y \in D$ tais que $a \neq 0$ e $ax = ay$.
Logo $ax - ay = 0$.
Logo $a(x-y) = 0$.
Pela hipótese (NZD) então $x-y = 0$, ou seja $x = y$.
\crproofpart {\rldir:}
Sejam $x,y \in D$ tais que $xy = 0$ e $x \neq 0$.
Queremos $y = 0$.
Temos $xy = 0 = x0$ (pois $0 = 0x$ em todo anel).
Ou seja $xy = x0$, e como $x\neq 0$, usando a (RCL) concluimos $y=0$.

%%}}}

\endsection
%%}}}

%%{{{ Fields 
\section Corpos.
%%%{{{ meta 
\label Fields
%%%}}}

%%{{{ df: field 
\definition Corpo.
%%%{{{ meta 
\label field
\defines
    * corpo
    ;;
%%%}}}

Seja $\cal K$ um anel não-zero e comutativo.
Chamamos o $\cal K$ um \dterm{corpo} (ou \dterm{field})
sse todos os seus membros diferentes de $0$ são invertíveis,
ou seja sse:
$$
\text{para todo $a\in K_{\neq0}$,
existe $y \in K$, tal que $ay = 1 = ya$.}
\tag{FM3*}
$$

%%}}}

%%{{{ eg: rats and reals and complex 
\example.
%%%{{{ meta 
%%%}}}

Os racionais, os reais, e os complexos, com suas operações canônicas de adição
e multiplicação são todos corpos.

%%}}}

%%{{{ noneg: ints and nats 
\nonexample.
%%%{{{ meta 
%%%}}}

Os inteiros e os naturais não!

%%}}}

%%{{{ eg: integers_modulo_p_field_example 
\example.
%%%{{{ meta 
\label integers_modulo_p_field_example
%%%}}}

O $\cal Z_p = \sset {\quogrp \ints {p\ints}} {+_p, \ntimes_p}$ onde $p$ primo é um corpo.

%%}}}

%%{{{ noneg: integers_modulo_n_field_nonexample 
\nonexample.
%%%{{{ meta 
\label integers_modulo_n_field_nonexample
%%%}}}

O $\cal Z_n$ onde $n>1$ e não primo, não é um corpo.

%%}}}

%%{{{ criterion: finite_integral_domain_implies_field 
\criterion.
%%%{{{ meta 
%%%}}}

Se $D$ é um domínio de integridade finito então $D$ é um corpo.

\proof.
Suponha que $D$ é um domínio de integridade finito.
Precisamos mostrar que cada $d \neq 0$ no $D$ tem inverso.
Seja $d\in D$, $d\neq 0$.
Procuro $d' \in D$ tal que $dd' = 1$.
Sejam
$$
d_1, d_2, \dotsc, d_n
$$
todos os elementos distintos de $D\setminus\set{0}$.
Considere os
$$
dd_1, dd_2, \dotsc, dd_n.
$$
Observe que:
$$
dd_i = dd_j \impliesbecause{(RCL)} d_i = d_j \implies i = j.
$$
Ou seja,
$$
D\setminus\set{0} = \set{dd_1, dd_2, \dotsc, dd_n}.
$$
Ou seja, como $1\in D\setminus\set{0}$,
$$
1 = dd_u \quad\text{para algum $u\in\set{1,\dotsc,n}$}
$$
que é o que queremos demonstrar.

%%}}}

%%{{{ x: integers_modulo_p_field_iff_p_prime
\exercise.
%%%{{{ meta 
\label integers_modulo_p_field_iff_p_prime
%%%}}}

Demonstre que o~\ref[integers_modulo_p_field_example]
realmente é um exemplo de corpo
e que o~\ref[integers_modulo_n_field_nonexample]
realmente não é.

%%}}}

%%{{{ on the way to defining the characteristic 
\note.
%%%{{{ meta 
\indexes
    * princípio!da boa ordem
    ;;
%%%}}}

Considere um corpo $\cal F$.
Uma coisa que podemos já fazer sem saber nada mais é somar o $1$ com o $1$
e considerar o elemento $1+1 \in F$.
Agora podemos somar mais um $1$, e considerar o $1+1+1 \in F$.
E por aí vai: sabemos que todos eles são membros do $F$ mesmo pois $F$
é $(+)$-fechado.
Agora, existem duas opções: 
(i) todos esses objetos são diferentes do $0$;
(ii) existe $k>0$ tal que a soma de $k$ $1$'s é $0$.
Observe que no caso (ii) pelo principio da boa ordem
existe um menor tal inteiro $m$.
Chegamos no conceito importante seguinte:

%%}}}

%%{{{ df: characteristic_of_field 
\definition Corpo.
%%%{{{ meta 
\label characteristic_of_field
\defines
    * característica!de corpo
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ x: characteristic_of_a_finite_field 
\exercise.
%%%{{{ meta 
\label characteristic_of_a_finite_field
%%%}}}

Um corpo é finito sse tem característica positiva.

%%}}}

%%{{{ x: characteristic_of_finite_field_is_prime 
\exercise.
%%%{{{ meta 
\label characteristic_of_finite_field_is_prime
%%%}}}

A característica de qualquer corpo finito é um número primo.

%%}}}

\endsection
%%}}}

%%{{{ Actions 
\section Ações.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Modules 
\section Modules.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Vector_spaces 
\section Espaços vetoriais.
%%%{{{ meta 
\label Vector_spaces
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os espaços vetoriais é o exemplo mais conhecido de estrutura
algébrica que envolve \emph{dois} conjuntos como carrier sets.

%%}}}

%%{{{ df: vector_space 
\definition.
%%%{{{ meta 
\label vector_space
%%%}}}

Sejam $F = \sset F {+,\ntimes,-,0,1}$ um corpo
e $V = \sset V {\oplus, \ominus, \vecb 0}$ um grupo abeliano.
Chamamos o $\sset {V,F} {\ast}$ com $\ast : F \cross V \to V$
dum \dterm{espaço vetorial sobre o $F$} sse as leis abaixo
são satisfeitas.
Chamamos os membros de $F$ de \dterm{escalares},
e os membros de $V$ de \dterm{vetores}.
Se $F = \reals$, temos um \dterm{espaço vetorial real};
se $F = \complex$, um \dterm{espaço vetorial complexo}.
Usarei $a,b,c,\dotsc$ ou letras gregas como metavariáveis para denotar escalares;
e para denotar vetores userei $\vecb u, \vecb v, \vecb w, \dotsc$ e também
$\veca u, \veca v, \veca w, \dotsc$.
A operação $\ast$ é chamada \dterm{multiplicação escalar}
e é sempre denotada por justaposição.
Mesmo que denotamos a multiplicação do corpo $(\ntimes)$
também por justaposição, isso não gera confusão.
Para diferenciar entre a multiplicação escalar e a multiplicação do corpo
chamarei de \dterm{scalaplicação} a primeira e \dterm{multiplicação} a segunda.
Finalmente, as leis:
% TODO: fix reflabs
\tlist:
\li (VS1): compatibilidade da scalaplicação com a multiplicação;
\li (VS2): identidade da scalaplicação;
\li (VS3): distributividade da scalaplicação com a adição dos vetores;
\li (VS4): distributividade da scalaplicação com a adição dos escalares.
\endtlist
Formulamente:
$$
\align
&a(b\vecb v) = (ab)\vecb v                              \tag{VS1} \\
&1\vecb v = \vecb v                                     \tag{VS2} \\
&a(\vecb u \oplus \vecb v) = a\vecb u \oplus a\vecb v   \tag{VS3} \\
&(a + b)\vecb v = a\vecb v \oplus b\vecb v.             \tag{VS4}
\endalign
$$
Escrevemos $+,-$ em vez dos $\oplus, \ominus$ quando é
claro quais são as operações.

%%}}}

%%{{{ eg: vector_space_eg_reals 
\example.
%%%{{{ meta 
%%%}}}

O $\reals$ é um espaço vetorial sobre o $\reals$.

%%}}}

%%{{{ eg: vector_space_eg_plane 
\example.
%%%{{{ meta 
%%%}}}

O $\reals^2$ com
$$
\align
(x,y) \oplus (x',y') &= (x + x', y + y') \\
\ominus (x,y) &= (-x, -y) \\
\vecb 0 &= (0,0)
\endalign
$$
é um espaço vetorial real.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
\defines
    * algebra!linear
    ;;
%%%}}}

O estudo de espações vetorias e seus morfismos
(\dterm{transformações lineares}) é chamado
\dterm{algebra linear}.

%%}}}

\endsection
%%}}}

%%{{{ Galois_theory 
\section Teoria de Galois.
%%%{{{ meta 
\label Galois_theory
%%%}}}

\TODO Escrever.

%TODO Fixed field, maybe mention fixpoint subring earlier 

\endsection
%%}}}

%%{{{ Lattices 
\section Reticulados.
%%%{{{ meta 
\label Lattices_as_algebras
%%%}}}

%%{{{ Lattice laws 
\note Leis de reticulado.
%%%{{{ meta 
%%%}}}

Num reticulado temos duas operações binárias que chamamos
de \dterm{join} ($\join$) e \dterm{meet} ($\meet$).
Elas satisfazem as leis de reticulado:
$$
\xalignat2
\text{associatividade} &\ \leftbrace {
\aligned
a \join (b \join c) &= (a \join b) \join c \\
a \meet (b \meet c) &= (a \meet b) \meet c
\endaligned
} &
\rightbrace {
\aligned
a \join b &= b \join a \\
a \meet b &= b \meet a
\endaligned
}\ & \text{comutatividade}
\\
\text{idempotência} &\ \leftbrace {
\aligned
a \join a &= a \\
a \meet a &= a
\endaligned
} &
\rightbrace {
\aligned
a \join (a \meet b) &= a \\
a \meet (a \join b) &= a
\endaligned
}\ & \text{absorpção}
\endxalignat
$$
Observe que sem as leis de absorpção não temos uma estrutura interessante.
Essas leis nos dizem como as duas operações interagem e oferecem à teoria
de reticulados sua alma.
Formalmente, temos:

%%}}}

%%{{{ df: lattice_as_algebra 
\definition.
%%%{{{ meta 
\label lattice_as_algebra
\defines
    * reticulado!como álgebra
    * reticulado!limitado, como álgebra
    ;;
%%%}}}

Seja $\cal L = \sset L {\join,\meet}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias que chamamos de \dterm{join}
e \dterm{meet} respectivamente.
$\cal L$ é um \dterm{reticulado} (ou \dterm{láttice}) sse:
\mathcol
\cforall {a,b\in L}   {a\join b \in L}                         \tag{LJ0} \\
\cforall {a,b,c\in L} {a\join(b\join c) = (a\join b)\join c}   \tag{LJ1} \\
\cforall {a,b\in L}   {a\join b = b \join a}                   \tag{LJ2} \\
\cforall {a\in L}     {a\join a = a}                           \tag{LJ3} \\
\cforall {a,b\in L}   {a\meet b \in L}                         \tag{LM0} \\
\cforall {a,b,c\in L} {a\meet(b\meet c) = (a\meet b)\meet c}   \tag{LM1} \\
\cforall {a,b\in L}   {a\meet b = b \meet a}                   \tag{LM2} \\
\cforall {a\in L}     {a\meet a = a}                           \tag{LM3} \\
\cforall {a,b \in L}  {a\join (a \meet b) = a}                 \tag{LAJ} \\
\cforall {a,b \in L}  {a\meet (a \join b) = a}.                \tag{LAM} \\
\intertext{%
Seja $\cal L = \sset L {\join,\meet,0,1}$ um conjunto estruturado onde
$\join,\meet$ são operações binárias e $0,1$ constantes, e tal que
$\cal L$ é um \dterm{reticulado limitado} (ou \dterm{bounded láttice}) sse
$\sset L {\join,\meet}$ é um reticulado e
}
\cforall {a \in L}    {a\join 0 = a}                           \tag{LJB} \\
\cforall {a \in L}    {a\meet 1 = a}.                          \tag{LJB}
\endmathcol

%%}}}

%%{{{ criterion: lattice_without_idem_criterion 
\criterion.
%%%{{{ meta 
\label lattice_without_idem_criterion
%%%}}}

Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join$ e $\meet$ satisfazem as leis de:
associatividade, comutatividade, absorção.
Então $\cal L$ é um reticulado.

\proof.
\ref[abs_and_com_imply_idem].

%%}}}

%%{{{ x: abs_and_com_imply_idem 
\exercise.
%%%{{{ meta 
\label abs_and_com_imply_idem
%%%}}}

Demonstre o~\ref[lattice_without_idem_criterion].

\hint
$a\join(a\meet(a\join a))$.

\solution
Seja $a \in L$.
Calculamos
\compute
a \join ( (a \join a) \meet a )
&= a \join a                         \by {$\meet$-abs.} \\
\intertext{e também}
a \join ( (a \join a) \meet a)
&=  ( (a \join a) \meet a) \join a   \by {$\join$-com.} \\
&=  ( a \meet (a \join a) ) \join a  \by {$\meet$-com.} \\
&=  a                                \by {$\join$-abs.} \\
\endcompute
Logo $a\join a = a$.

%%}}}

%%{{{ x: two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser 
\exercise.
%%%{{{ meta 
\label two_equiv_ways_to_define_an_order_on_an_algebraic_lattice_teaser
%%%}}}

Seja $\cal L = \sset L {\join,\meet}$ um reticulado pela~\ref[lattice_as_algebra].
Demonstre que:
$$
a\join b = b \iff a\meet b = a.
$$

\solution
\proofpart {\lrdir}:
Suponha $b = a \join b$.
Calculamos
\compute
a \meet b
&= a \meet (a \join b)  \by {hipótese} \\
&= (a \join b) \meet a  \by {$\meet$-com.} \\
&= a.                   \by {$\meet$-abs.} \\
\endcompute
\proofpart {\rldir:}
Similar.

%%}}}

%%{{{ df: semilattice 
\definition.
%%%{{{ meta 
\label semilattice
\defines
    * semirreticulado
    * semirreticulado!limitado
    ;;
%%%}}}

Seja $\cal S = \sset S {\dmnd}$ um conjunto estruturado onde
$\dmnd$ é uma operação binária.
$\cal S$ é um \dterm{semirreticulado} (ou \dterm{semiláttice}) sse
sua operação é associativa, comutativa, e idempotente:
\mathcol
\cforall {a,b\in S}   {a\dmnd b \in S}                        \tag{SL0} \\
\cforall {a,b,c\in S} {a\dmnd(b\dmnd c) = (a\dmnd b)\dmnd c}  \tag{SL1} \\
\cforall {a,b\in S}   {a\dmnd b = b \dmnd a}                  \tag{SL2} \\
\cforall {a\in S}     {a\dmnd a = a}.                         \tag{SL3} \\
\intertext{%
Seja $\cal S = \sset S {\dmnd,\ell}$ um conjunto estruturado tal que
$\sset S {\dmnd}$ é um semirreticulado e $\ell$ é uma constante.
$\cal S$ é um \dterm{semirreticulado limitado} (ou \dterm{bounded semiláttice}) sse:
}
\cforall {a\in S}     {a\dmnd \ell = a}.                      \tag{SLB} \\
\endmathcol

%%}}}

%%{{{ remark: shorter (bounded) lattice definitions using (bounded) semilattices
\remark Definições mais curtas.
%%%{{{ meta 
%%%}}}

Com as definições de semirreticulados podemos definir numa maneira mais simples
o que é um reticulado:

%%}}}

%%{{{ x: from_semilattice_to_lattice 
\exercise Definições mais curtas.
%%%{{{ meta 
\label from_semilattice_to_lattice
\defines
    * lattice
    ;;
%%%}}}

Defina os conceitos ``reticulado'' e ``reticulado limitado''
usando os conceitos ``semirreticulado'' e ``semirreticulado limitado''.

\solution
O conjunto estruturado $\cal L = \sset L {\join,\meet}$ é um
\dterm{lattice} sse os conjuntos estruturados
$\sset L {\join}$ e $\sset L {\meet}$ são semilattices,
e as leis de absorção são satisfeitas.
$\cal L = \sset L {\join,\meet}$ é um \dterm{reticulado} sse
$\sset L \join$ e $\sset L \meet$ são semirreticulados.
Similarmente $\sset L {\join,\meet,0,1}$ é um reticulado limitado sse
$\sset L {\join,0}$ e $\sset L {\meet,1}$ são semirreticulados limitados.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nosso objectivo aqui é brincar com várias estruturas algébricas, e não
aprofundar em nenhuma.
Mas se preocupe não: voltamos a estudar reticulados no~\ref[Posets_Lattices].

%%}}}

\endsection
%%}}}

%%{{{ Non purely algebraic structures 
\section Estruturas não puramente algébricas.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%{{{ df: complete_ordered_field 
\definition Corpo ordenado completo.
%%%{{{ meta 
\label complete_ordered_field
\defines
    * corpo!ordenado, completo
    ;;
%%%}}}

Um corpo ordenado $F$ é \dterm{completo} sse
todos os seus subconjuntos bounded above possuem supremum no $F$
\mathcol
\cforall {A \isubset \reals}
         {\text{$l$ cotado por cima} \implies \text{$A$ tem supremum no $F$}}.
\stag[FC]
\endmathcol

%%}}}

%%{{{ eg: reals_is_a_complete_ordered_field 
\example.
%%%{{{ meta 
\label reals_is_a_complete_ordered_field
%%%}}}

Os reais $\sset \reals {+, \,\ntimes\,, -, 0, 1, <}$.

%%}}}

%%{{{ x: can_we_prove_that_reals_is_a_complete_ordered_field 
\exercise.
%%%{{{ meta 
\label can_we_prove_that_reals_is_a_complete_ordered_field
%%%}}}

Tem como demonstrar isso?
Se sim, o que seria uma demonstração disso?
Se não, por que não?

%%}}}

%%{{{ Enough! 
\note Chega!.
%%%{{{ meta 
%%%}}}

Vamos revisar pouco a situação com as estruturas que estudamos até agora.
Como a gente escolha os axiomas (leis) que botamos nas nossas definições?
As mais leis que eu boto, as mais ferramentas que ganho para matar mais
teoremas.  Minha teoria vai acabar sendo capaz de demonstrar mais coisas,
mas o preço que pago para isso são modelos!
\eop
Quantos monóides encontramos?  Demais!  Todos os grupos são monóides,
e a gente já encontrou ainda mais monóides que não são grupos (lembra?).
E grupos?
Menos, mas muitos também!
E grupos abelianos?
Demonstramos mais teoremas, mas temos menos exemplos de grupos abelianos.
E anéis?  E anéis comutativos?  E domínios de integridade?
Cada vez que adicionamos restricções (leis), a teoria correspondente
cresce, e a colecção de models diminui.
E corpos?
Ainda encontramos vários modelos: racionais, reais, complexos, inteiros
módulo primo $p$, \dots
\eop
E corpos ordenados?
Aqui ganhamos muita teoria graças a ordem, mas perdemos os complexos e os
inteiros módulo $p$, mas ainda temos os reais e os racionais e mais
uns modelos, mas já estamos percebendo que fica mais e mais difícil
achar modelos \emph{realmente} diferentes que satisfazem todas as leis!
\eop
E agora?
Adicionamos mais uma lei: o axioma da completude; e assim chegamos nos
\emph{corpos ordenados completos}.  E agora \emph{chega!}
Estamos num ponto onde adicionamos tantos axiomas que nosso conceito
foi tão exigente que perdemos todos os modelos exeto um: os reais!
Realmente não encontramos outro exemplo, mas isso não significa que
não existem outros modelos.  Certo?  Certo, mas acontece que nessa
situação não é o caso: \emph{essencialmente existe apenas um
único corpo ordenado completo: os reais!}

%%}}}

%%{{{ Q: what does "essentially" mean above? 
\question.
%%%{{{ meta 
%%%}}}

O que significa a palavra \wq{essencialmente} acima?

%%}}}

\spoiler

%%{{{ thm: uniqueness_of_complete_ordered_field 
\theorem Unicidade.
%%%{{{ meta 
\label uniqueness_of_complete_ordered_field
%%%}}}

Se $R,R'$ são corpos ordenados completos então $R,R'$ são isómorfos.

\sketch.
Sejam
$\sset R    {+, \;\ntimes\;, -, 0, 1, <}$ e
$\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}$
corpos ordenados completos.
Precisamos definir um isomorfismo
$$
\phi
\eqtype
\sset R    {+, \;\ntimes\;, -, 0, 1, <}
\longtoby{\iso}
\sset {R'} {+', \;\ntimes'\;, -', 0', 1', <'}.
$$
Obviamente botamos
$$
\align
\phi0 &= 0' \\
\phi1 &= 1'
\intertext{Isso já determina a $\phi$ no resto dos
``naturais'' $N\subset R$:}
\phi2 &= \phi(1 + 1) = \phi1 + \phi1 = 1' + 1' = 2' \\
\phi3 &= \phi(2 + 1) = \phi2 + \phi1 = 2' + 1' = 3' \\
&\eqvdots \\
\phi(n+1) &= \phi n + \phi1 = n' + 1' \\
&\eqvdots
\endalign
$$
ou seja, a $\phi$ (restrita no $N$) necessariamente embute
isomorficamente o $N\subset R$ no $\img \phi N = N' \subset R'$:
$$
\phi \restosub N : N \isoto N'.
$$
Agora, como $\phi$ é homomorfismo, temos
$$
\phi(-x) = \mathord{-'}(\phi x)
\quad\text{para todo $x\in R$},
$$
e logo a $\phi$ necessariamente embute os ``inteiros''
$Z\subset R$ nos ``inteiros'' $Z' \subset R'$:
$$
\phi \restosub Z : Z \isoto Z'.
$$
Definimos a $\phi$ nos ``racionais'' $Q\subset R$ assim:
$$
\phi(m/n)
= \phi(m \ntimes \ginv n)
= \phi m \ntimes' \ginvp{\phi n}
= \phi m \ntimes' \phi (\ginv n)
= \phi m \mathbin{/'} \phi n
$$
e logo
$$
\phi \restosub Q : Q \isoto Q'.
$$
Estamos perto!
Basta só definir a $\phi$ nos ``buracos'' (nos ``irracionais'')
de $R$ e pronto!

%}}}

%%{{{ remark: we cannot finish this proof right now 
\remark.
%%%{{{ meta 
%%%}}}

Infelizmente, por enquanto não temos todo o armamento para matar
os detalhes e o que falta no esboço, mas é importante entender
pelo menos tudo que tá lá.  Voltamos nesse assunto
no~\ref[Set_theory]~(\reftag[Constructing_more_numbers]).

%%}}}

%%{{{ warning: does_a_complete_ordered_field_exist_warning 
\warning.
%%%{{{ meta 
\label does_a_complete_ordered_field_exist_warning
%%%}}}

Mesmo se aceitar que quaisquer corpos ordenados completos são
isomorfos (o~\ref[uniqueness_of_complete_ordered_field]), ainda
temos um ponto que roubamos: para existir único, precisamos duas
coisas: \emph{pelo menos} um; \emph{no máximo} um.
O~\reftag[uniqueness_of_complete_ordered_field] realmente ofereceu
a segunda coisa; mas a primeira?
Qual foi tua resolução
do~\ref[can_we_prove_that_reals_is_a_complete_ordered_field]
mesmo?
Voltamos nesse assunto
no~\ref[Set_theory]~(\reftag[Constructing_more_numbers]).

%%}}}

\TODO Reorganizar o seguinte.

%%{{{ Calculus, the real deal 
\note Calculus, real e oficial.
%%%{{{ meta 
\defines
    * calculus
    * análise!real
    ;;
%%%}}}

Como começamos a teoria dos grupos no~\ref[Group_theory]?
Apresentamos os axiomas dos grupos e continumos investigando
suas conseqüências.  A colecção dessas conseqüências (teoremas)
é exatamente o que chamamos de \dterm{teoria}.
E a \emph{teoria dos anéis} é feita por todos os teoremas
que seguem pelos axiomas de anéis; etc.~etc.
E a \emph{teoria dos corpos ordenados completos?}
Ela não é muito famosa por esse nome, mas com certeza
tu já ouviste falar dela por uns dos seus apelidos:
\dterm{calculus}, ou \dterm{análise real}, \ref[The_reals], etc.
Na abordagem axiomática, não nos importa \emph{definir}\/ ou
\emph{construir} os objetos que vamos chamar de \dterm{números reais}.
Começamos aceitando a existência dum certo conjunto que denotamos
por $\reals$ e umas noções primitivas, e estipulamos uns axiomas
sobre eles.
A partir de tais noções primitivas e tais axiomas procedemos
para definir mais conceitos, e demonstrar mais proposições (os teoremas),
elaborando assim a teoria dos corpos ordenados completos.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: N_00 
\problem.
%%%{{{ meta 
\indexes
    * pointwise!operação
    ;;
%%%}}}

Considere o conjunto $\cal N_{00}$ das seqüências infinitas de naturais
``eventualmente zero'', ou seja
$$
\cal N_{00}
\defeq
\setst {f : \nats\to\nats} {\pexists {N\in\nats} \lforall {n \geq N} {f(n) = 0}}.
$$
Consideramos a operação de \emph{adição pointwise} definida pela:
$$
(f + g)(x) = f(x) + g(x).
$$
Demonstre que $\cal N_{00}$ com essa operação forma um monóide
isómorfo com o monóide $\sset {\nats_{>0}} {\ntimes}$
(com operação a multiplicação usual).

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[pinteralgebra],
\cite[hersteintopics],
\cite[babybm],
\cite[papamb].
\cite[sharperings].

Sugiro novamente o~\cite[aluffialgebra] como uma introdução
completa em algebra.

Dois livros excelentes para uma introdução em algebra linear
especificamente são os~\cite[halmosfdvs] e~\cite[halmoslapb]
(para ser estudados em paralelo).
Um primeiro toque dá pra pegar também pelos~\cite[apostol1]
e~\cite[apostol2].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Cantors_paradise 
\chapter O paraíso de Cantor.
%%%{{{ meta 
\label Cantors_paradise
%%%}}}

%%{{{ A bit of historical context 
\history Um pouco de contexto histórico.

\TODO Terminar as duas histórias.

%%{{{ Wild_numbers 
\note Números selvágens.
%%%{{{ meta 
\label Wild_numbers
\credits
    * Leibniz       : algébrico
    * Euler         : transcendentais
    * Lambert       : irracionalidade
    * Liouville     : constantes transcendentais
    * Cantor
    * Hermite       : transcendentalidade do $e$
    * Weierstrass   : teorema Lindemann--
    * vonLindemann  : teorema --Weierstrass
    ;;
\indexes
    * função!algébrica
    ;;
%%%}}}

\yearof{1682}:
Leibniz demonstra que $\sin$ não é uma
\dterm{função algébrica}.
\yearof{1700}:
Euler define os números \dterm{transcendentais};
mas não consegue demonstrar se existem ou não.
\yearof{1768}:
Lambert
demonstra que $\pi$ é \emph{irracional} e os $e^q$ também, para qualquer $q\in\rats_{\neq0}$.
\yearof{1844}:
Liouville demonstra que existem números transcendentais.
Definiu o que hoje chamamos de \dterm{números Liouville},
mostrou que todos eles são transcendentais, e no 1851 construiu
um número Liouville específico, a \dterm{constante Liouville}
$$
\Sum_{n=1}^\infty 10^{-n!}
= 0.11000100000000000000000100\dots
$$
que foi (finalmente) um exemplo simples e concreto de um
número transcendental.
\yearof{1870}--\yearof{1872}:
Cantor;
\yearof{1873}:
Hermite demonstrou que $e$ é transcendental.
Esse foi o primeiro número transcendental que conhecemos cujo
objectivo (cuja definição) não foi feita para ser um tal número.
Liouville \emph{definiu} seus números com objectivo de achar
transcendentais.  O $e$ já era definido e estudado muito,
e sua \emph{raison d'être} não tinha nada a ver com os
números transcendentais.
\yearof{1882}:
von~Lindemann demonstra a transcendentalidade
dos $e^\alpha$ para $\alpha\neq0$ algébrico---e logo
do $\pi$ também (\ref[pi_is_transcendental])---e
Weierstrass generaliza no \yearof{1885} para o
teorema conhecido como Lindemann--Weierstrass na teoria de
números transcendentais.

%%}}}

%%{{{ From Fourier series to the study of sets 
\note De séries Fourier para o estudo de conjuntos.
%%%{{{ meta 
\credits
    * Cantor
    * Fourier : séries
    ;;
\indexes
    * séries!Fourier
    * Fourier   see: séries
    ;;
%%%}}}

\yearof{1870}:
Cantor se interessou nas \dterm{séries Fourier}.
O que são não é importante nesse
momento;\foot
Uma série Fourier tem a forma
$$
f(x)
= a_0
+ \Sum_{n=1}^{\infty} a_n \cos(nx)
+ \Sum_{n=1}^{\infty} b_n \sin(nx).
$$
Os $a_n$'s e $b_n$'s são seus coeficientes.
\toof
basta saber que são determinadas por seus
\emph{coeficientes} que são duas seqüências de números reais
$$
\xalignat2
&a_1,a_2,a_3,\dotsc &
&b_1,b_2,b_3,\dotsc
\endxalignat
$$
Cantor demonstrou um teorema impressionante:

%%}}}

%%{{{ thm: Cantor_theorem_1870 
\theorem Cantor, 1870.
%%%{{{ meta 
\label Cantor_theorem_1870
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
numa função no $[0,2\pi]$.
Então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Mas Cantor se perguntou:
<<E se elas convergem na mesma função em todo o $[0,2\pi]$
\emph{exceto um conjunto de possíveis excessões}
$E \subset [0,2\pi]$?  Será que se o $E$ não é grande
demais eu ainda consigo demonstrar o mesmo resultado,
que os coeficientes são iguais?>>
E realmente conseguiu, já no próximo ano:

%%}}}

%%{{{ thm: Cantor_theorem_1871 
\theorem Cantor, 1871.
%%%{{{ meta 
\label Cantor_theorem_1871
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
na mesma função no $[0,2\pi] \setminus E$.
Se $E$ é finito, então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Observe que o teorema de 1870 é um caso especial do
teorema de 1871, tomando $E \asseq \emptyset$.
No próximo ano, Cantor conseguiu melhorar ainda mais seu
teorema:

%%}}}

%%{{{ thm: Cantor_theorem_1872 
\theorem Cantor, 1872.
%%%{{{ meta 
\label Cantor_theorem_1872
%%%}}}

Sejam $f,f'$ séries Fourier que convergem pointwise
na mesma função no $[0,2\pi] \setminus E$.
Se $E$ é \dterm{derivável até $\emptyset$},
então os coeficientes das $f,f'$ são iguais.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O que significa \dterm{derivável até $\emptyset$} vamos
encontrar no~\ref[Metric_spaces];
por enquanto basta saber que essa condição é satisfeita
por muitos conjuntos \emph{infinitos}, e por todos os
conjuntos finitos, e logo o teorema de 1871 é um caso
especial do teorema de 1872.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Essas aventuras fizeram Cantor se preocupar sobre os
conjuntos como objetos matemáticos próprios, como
``first-class cítizens'' e se preocupar sobre seus
tamanhos também.
E assim nasceu a \dterm{teoria (ingênua) dos conjuntos}.
Neste capítulo estudamos as idéias de Cantor sobre conjuntos e
sobre infinidade(s); descobertas importantíssimas em matemática,
tanto que faz sentido de falar sobre matemática a.C.~e~d.C.~(antes
Cantor e depois Cantor).

%%}}}

\endhistory
%%}}}

%%{{{ What is counting and comparing of quantities? 
\section O que é contar e comparar quantidades?.
%%%{{{ meta 
%%%}}}

%%{{{ How we count 
\note.
%%%{{{ meta 
%%%}}}

Quando queremos \dterm{contar} a quantidade de membros
dum conjunto $A$, começamos apontando a cada um deles
e, usando \emph{números}, atribuimos um para cada membro.
No final das contas---ahem---acabamos com um certo número $n$
e digamos que $A$ tem $n$ membros.  A \dterm{cardinalidade}
de $A$, é o $n$.
Em símbolos,
$$
\card A = n.
$$
Essa análise tem varios pontos hipersimplificados e talvez
controversiais.
\eop
Primeiramente note que, se o conjunto $A$ é infinito, esse
processo nunca vai parar, e a gente não vai conseguir atribuir
um $n\in\nats$ para representar a cardinalidade $\card A$.
Além disso, precisamos \emph{ter} os números.
Isso talvez parece um ponto bobo, mas vale a pena se perguntar
se os humanos sabiam sobre o conceito de \dterm{quantidade},
e equivalentemente de \dterm{cardinalidade de conjunto},
antes de \emph{ter} os números ou não!

%%}}}

%%{{{ Do we really need numbers? 
\note Precisamos mesmo de números?.
%%%{{{ meta 
%%%}}}

Sabemos como contar conjuntos finitos então.
E usamos o $\nats$ para representar as quantidades possíveis.
Agora não queremos contar, mas \emph{comparar} dois conjuntos
\emph{com relação à quantidade de elementos}.
A discussão sobre contagem acima presuponha a existência
dos números que usamos para contar:  1, 2, 3, etc.,
e dependende da época talvez o 0 também faz parte desses números.
Mas, bem antes de ter números para contar, os humanos poderiam
comparar quantidades.
Talvez um humano prehistórico sabia dizer que ele tem a mesma
quantidade de filhos que seu vizinho, sem saber dizer que
cada um tem \emph{cinqo} filhos.
Como ele sabia então comprarar essas cardinalidades?

%%}}}

\endsection
%%}}}

%%{{{ Equinumerosity 
\section Equinumerosidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: finord 
\definition.
%%%{{{ meta 
\label finord
\defines
    * \finord {~n}  -- o conjunto $\set {0,\dotsc,n-1}$
    ;;
%%%}}}

Como usamos bastante o conjunto $\set{0,1,\dotsc,n-1}$,
vale a pena introduzir uma notação para denotá-lo:
$$
\finord n \pseudodefeq \set{0,\dotsc,n-1}.
$$

%%}}}

%%{{{ x: define \finord using set builder 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o $\finord n$ usando a notação set builder.

\hint
Começa com o $\nats$ e filtre seus elementos usando suas relações de ordem.

\solution
Definimos
$$
\finord n \defeq \setst {i \in \nats} { 0 \leq i < n }.
$$

%%}}}

%%{{{ x: define \finord using recursion 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o operador $\finord{\bhole} : \nats \to \pset\nats$ recursivamente.

\hint
Cuidado com as operações e os tipos dos seus argumentos.

\solution
Qualquer uma das definições abaixo serve:
$$
\xalignat 2
\finord 0 &\defeq \emptyset                                     & \finord 0    &\defeq \emptyset\\
\finord n &\defeq \finord {n-1} \union \set{n-1}\qquad(n > 0)   & \finord {Sn} &\defeq \finord n \union \set n.
\endxalignat
$$

%%}}}

%%{{{ df: equinumerous 
\definition Equinúmeros.
%%%{{{ meta 
\label equinumerous
\defines
    * ~A \eqc ~B  -- os $A$ e $B$ são equinúmeros
    * equinúmeros
    ;;
%%%}}}

Chamamos os conjuntos $A$ e $B$ \dterm{equinúmeros} sse
existe bijecção $f : A \bijto B$.
Escrevemos:
$$
A \eqc B \defiff \lexists f {f : A \bijto B}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Continuamos em definir mais relações para comparar os tamanhos de conjuntos:

%%}}}

%%{{{ df: leqc_and_ltc 
\definition.
%%%{{{ meta 
\label leqc_and_ltc
\defines
    * ~A \leqc ~B  -- o $A$ é menor-ou-igual em cardinalidade que o $B$
    * ~A \ltc ~B   -- o $A$ é menor em cardinalidade que o $B$
    ;;
%%%}}}

Sejam $A$ e $B$ conjuntos.
Definimos
$$
\align
A \leqc B &\defiff \lexists {B_0\subset B} {A \eqc B_0}\\
A \ltc B  &\defiff A\leqc B \mland A\neqc B
\endalign
$$
Seguindo nossa práctica comum, usamos também $A\gtc B$ como sinónimo de $B\ltc A$,
$A \not\geqc B$ para significar que não é o caso que $B \leqc A$, etc.

%%}}}

%%{{{ x: A_subset_B_implies_A_leqc_B 
\exercise.
%%%{{{ meta 
%%%}}}

Verifique que
$$
A \subset B \implies A \leqc B.
$$
Mostre que, em geral,
$$
A \psubset B \nimplies A \ltc B.
$$

%%}}}

%%{{{ x: wrong_ltc_def 
\exercise.
%%%{{{ meta 
\label wrong_ltc_def
%%%}}}

Demonstre ou refute a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \ltc B \askiff \lexists {B_0\psubset B} {A \eqc B_0}.
$$

\hint
$\nats\ltc\ints$?

%%}}}

%%{{{ x: fun_leqc_def_injto 
\exercise.
%%%{{{ meta 
\label fun_leqc_def_injto
%%%}}}

Demonstre ou refute a afirmação que podemos usar a seguinte definição como alternativa:
$$
A \leqc B \askiff \lexists f {f : A \injto B}.
$$

\hint
Realmente
$$
A \leqc B \iff \lexists f {f : A \injto B}.
$$
Demonstre!

%%}}}

%%{{{ x: fun_leqc_def_surto 
\exercise.
%%%{{{ meta 
\label fun_leqc_def_surto
%%%}}}

Podemos usar a seguinte definição como alternativa?:
$$
A \leqc B \askiff \lexists f {f : B \surto A}.
$$

%%}}}

%%{{{ x: eqc_is_eqrel 
\exercise.
%%%{{{ meta 
%%%}}}

A $\eqc$ é uma relação de equivalência.  Ou seja:
$$
\align
\text{reflexiva:}\quad&  \text{para todo conjunto $A$,     $A \eqc A$};\\
\text{transitiva:}\quad& \text{para todo conjunto $A,B,C$, $A \eqc B \mland B \eqc C \implies A \eqc C$};\\
\text{simétrica:}\quad&  \text{para todo conjunto $A,B$,   $A \eqc B \implies B \eqc A$}.
\endalign
$$

\solution
Usamos as bijecções seguintes: identidade, composição, inversa.

%%}}}

%%{{{ lemma: leqc_is_equiorder 
\lemma.
%%%{{{ meta 
\label leqc_is_equiorder
%%%}}}

A $\leqc$ é:
$$
\align
\text{reflexiva:}              \quad &A \leqc A;\\
\text{transitiva:}             \quad &A \leqc B \mland B \leqc C \implies A \leqc C;\\
\text{não antissimétrica:}     \quad &A \leqc B \mland B \leqc A \nimplies A = B;\\
\text{``equiantissimétrica'':} \quad &A \leqc B \mland B \leqc A \implies A \eqc B.
\endalign
$$

\sketch.
Para as duas primeiras usamos a identidade e a composição respectivamente.
Para a próxima tomando $A\asseq \nats$ e $B\asseq \ints$ serve.
Para ver que não é antissimétrica basta achar um contraexemplo: tente os $\set 0$ e $\set 1$.
A última é realmente difícil para demonstrar:
é um corolário direto
do teorema Schröder--Bernstein (\ref[schroder_bernstein]).

%%}}}

%%{{{ x: times_respects_eqc 
\exercise.
%%%{{{ meta 
\label times_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies A\times B \eqc A'\times B'$.

\solution
Defina $F: A\times B \to A' \times B'$ pela
$
F(a,b) = (f(a), g(b)).
$
Ou seja, $F = f \cross g$.
\proofpart {Injectividade.}
Tome $\tup{a_1,b_1} \neq \tup{a_2,b_2}$ no $A\times B$.
Logo $a_1\neq a_2$ ou $b_1\neq b_2$ (pela definição de $(=)$ nas tuplas).
Logo
$$
F(a_1,b_2) = \tup{f(a_1), g(b_1)} \neq \tup{f(a_2), g(b_2)} = F(a_2,b_2).
$$
onde a $(\neq)$ segue pelas injectividades das $f,g$:
pois se $a_1\neq a_2$ então $f(a_1)\neq f(a_2)$,
e se $b_1\neq b_2$ então $g(b_1) \neq g(b_2)$.
\proofpart {Sobrejectividade.}
Tome $\tup{a',b'}\in A'\times B'$.
Logo $a'\in A'$ e $b'\in B'$, e como $f$ e $g$ são sobrejetoras,
sejam $a \in A$ e $b\in B$ tais que $f(a) = a'$ e $g(b) = b'$.
Observe que $F(a,b) = \tup{f(a), g(b)} = \tup{a',b'}$.

%%}}}

%%{{{ x: pset_respects_eqc 
\exercise.
%%%{{{ meta 
\label pset_respects_eqc
%%%}}}

$A \eqc A' \implies \pset A \eqc \pset A'$.

\solution
Defina $F : \pset A \to \pset A'$ pela
$
F(X) = \img f X.
$
\proofpart {Injectividade.}
Tome $X,Y \in \pset A$ tais que $X\neq Y$.
Ou seja, existe $z\in X\symdiff Y$.
Tome tal $z$ e considere os $F(X)$ e $F(Y)$.
Como $f$ é injetora, o $f(z) \in F(X) \symdiff F(Y)$.
Ou seja: $F(X) \neq F(Y)$.
\proofpart {Sobrejectividade.}
Tome $X' \in \pset A'$.
Observe que o $\pre f {X'}$ é mapeado no $X'$ através da $F$,
graças ao~\ref[jection_iff_composition_with_inverse].

%%}}}

%%{{{ x: to_respects_eqc 
\exercise.
%%%{{{ meta 
\label to_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies (A\to B) \eqc (A'\to B')$.

\solution
Defina $F : (A\to B) \to (A' \to B')$ pela
$F(t) = g \compose t \compose f^{-1}$.
\proofpart {Injectividade.}
Sejam $s,t \in (A\to B)$ com $s\neq t$.
Logo existe $a_0 \in A$ tal que $s(a_0) \neq t(a_0)$.
Calcule:
\compute
(F(s))(f(a_0))
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s)(a_0)\\
&= g(s(a_0))\\
&\neq g(t(a_0)) \by {$g$ injetora e $s(a_0) \neq t(a_0)$} \\
&= (g \compose t)(a_0)\\
&= (g \compose s \compose \finv f \compose f)(a_0)\\
&= (g \compose s \compose \finv f)(f(a_0))\\
&= (F(t))(f(a_0)).
\endcompute
\proofpart {Sobrejectividade.}
Seja $t' \in (A'\to B')$.
Defina a $t \in (A\to B)$ pela
$$
    t = \finv g \compose t' \compose f
$$
e observe que $F(t) = t'$.

%%}}}

%%{{{ x: disjunion_respects_eqc 
\exercise.
%%%{{{ meta 
\label disjunion_respects_eqc
%%%}}}

$A \eqc A' \mland B \eqc B' \implies A \dunion B \eqc A' \dunion B'$.

%%}}}

%%{{{ x: which_setops_respect_cardinalities 
\exercise.
%%%{{{ meta 
\label which_setops_respect_cardinalities
%%%}}}

Quais das operações $\Union$, $\Inter$, respeitam a equinumerosidade?

\hint
Nenhuma.
Ache contraexemplos.

\solution
Nenhuma!
Como contraexemplo, tome os
$$
A \asseq \set{ \set{0}, \set{1} }
\eqc
B \asseq \set{ \set{0,1}, \set{1,2} }
$$
e calcule
$$
\xalignat2
\Union \set{ \set{0}, \set{1} }     &= \set{0,1} &
\Inter\set{ \set{0}, \set{1} }      &= \emptyset \\
\Union \set{ \set{0,1}, \set{1,2} } &= \set{0,1,2} &
\Inter\set{ \set{0,1}, \set{1,2} }  &= \set{1}.
\endxalignat
$$
Ou seja, $\Union A \neqc \Union B$ e $\Inter A \neqc \Inter B$.

%%}}}

%%{{{ x: currying_eqc 
\exercise.
%%%{{{ meta 
\label currying_eqc
%%%}}}

$((A \times B) \to C) \eqc (A \to (B\to C))$.

\hint
Curry!

\hint
Use lambdas (veja~\ref[A_touch_of_lambda]).

\solution
Defina $F : ((A\times B) \to C) \to (A \to (B\to C))$, pela
$$
F(t) = \lam a {\lam b {t(a,b)}}.
$$
\proofpart {Injectividade.}
Tome $s,t \in ((A\times B) \to C)$ tais que $s\neq t$.
Ou seja, para alguma entrada $\tup{a_0,b_0} \in (A\times B)$,
as saídas são diferentes elementos de $C$:
$$
s(a_0,b_0) \neq t(a_0,b_0).
$$
Observe então que $F(s) \neq F(t)$,
pois para a entrada $a_0$, elas retornam valores diferentes:
a $F(s)$ retorna a função
$\lam b {s(a_0, b)}$,
e a $F(t)$ retorna a função $\lam b {t(a_0, b)}$.
Para confirmar que realmente
$$
\lam b {s(a_0, b)}
\neq
\lam b {t(a_0, b)}
$$
basta observar que seus valores para a entrada $b\asseq b_0$
são diferentes.
\proofpart {Sobrejectividade.}
Toma um $f\in (A\to (B\to C))$.
Defina a $t : (A\times B) \to C$
pela
$$
t(a,b) = (f(a))(b)
$$
e observe que realmente $F(t) = f$.

%%}}}

\endsection
%%}}}

%%{{{ What is cardinality? 
\section O que é cardinalidade?.
%%%{{{ meta 
%%%}}}

%%{{{ The double abstraction of Cantor 
\note A dupla abstracção de Cantor.
%%%{{{ meta 
%%%}}}

{\Cantor}Cantor definiu a cardinalidade numa maneira informal,
mas sua descripção é bastante indicativa e serve como uma guia
para chegar numa definição formal.
A cardinalidade dum conjunto $A$ é o que fica, se
a gente mentalmente esquecer a ordem que pensamos os membros de $A$
e também os seus nomes.  Assim o $A$ parece uma colecção de pontinhos
abstratos e distintos.  Cantor denotou a cardinalidade de $A$
$$
\cantorcard A
$$
usando as duas barras para indicar essa ``dupla abstracção''.

%%}}}

%%{{{ But what is a cardinal number? 
\note Mas o que é um número cardinal?.
%%%{{{ meta 
\credits
    * vonNeumann
    * Hausdorff
    ;;
%%%}}}

Vamos voltar pouco ao passado, e seguindo os passos do livro
clássico de Hausdorff (\cite[hausdorffsettheory])
não vamos preocupar com a \emph{natureza} dos cardinais.
Vamos deixar isso \wq{para os filósofos}, como ele disse,
pois na época que ele escreveu seu texto ninguém tinha conseguido
dar uma definição satisfatória de \dterm{número cardinal}.
Uns anos depois, von~Neumann conseguiu definir
formalmente os números cardinais, algo que vamos encontrar
no~\ref[The_ordinals].  Mas sem saber o que são,
já podemos usá-los deixando claro quais são as propriedades
que exigimos que eles satisfaçam.
Um operador de cardinalidade $\card{\dhole}$ deve satisfazer
pelo menos a:
$$
A \eqc B \iff \card{A} = \card{B}
$$
e possivelmente mais condições ainda.
Vamos voltar para estudar os detalhes no~\ref[Set_theory].

%%}}}

\endsection
%%}}}

%%{{{ Finite and infinite; countable and uncountable 
\section Finitos e infinitos; contáveis e incontáveis; jogos para imortais.
%%%{{{ meta 
%%%}}}

%%{{{ df: finite_set 
\definition.
%%%{{{ meta 
\label finite_set
\defines
    * finito
    * infinito
    ;;
%%%}}}

O conjunto $A$ é \dterm{finito} sse existe $n\in\nats$ tal que $A \eqc \finord n$.
O conjunto $A$ é \dterm{infinito} sse $A$ não é finito.

%%}}}

%%{{{ df: countable_set 
\definition.
%%%{{{ meta 
\label countable_set
\defines
    * conjunto!contável
    * conjunto!incontável
    ;;
%%%}}}

O conjunto $A$ é \dterm{contável} sse $A$ é finito ou $\nats\eqc A$.
Usamos os termos \dterm{enumerável} e \dterm{denumerável} como sinónimos
de contável.
O conjunto $A$ é \dterm{incontável} sse $A$ não é contável.

%%}}}

%%{{{ countable vs enumerable 
\warning.
%%%{{{ meta 
%%%}}}

Em muitos textos as palavras ``contável'' e ``(d)enumerável'' não
são exatamente sinónimas: uma delas pode insistir que o conjunto seja
infinito, e a outra relaxar essa restricção para permitir os finitos
também.  As duas palavras, etimologicamente e semanticamente falando,
parecem ser sinônimos no mundo matemático, e por isso nesse texto
eu vou usar as duas como sinônimos mesmo.  Mas cuidado lendo
textos diferentes, pois podem significar coisas diferentes
no caso que o conjunto em questão é finito.
(Sobre conjuntos infinitos os dois termos sempre concordam.)

%%}}}

%%{{{ df: enumeration 
\definition.
%%%{{{ meta 
\label enumeração
\defines
    * enumeração
    ;;
%%%}}}

Uma \dterm{enumeração} dum conjunto $A$ é qualquer surjecção
$\pi : \nats\surjto A$.
Assim temos:
$$
A = \img \pi {\nats} = \set{\pi(0), \pi(1), \pi(2), \dotsc}
$$

%%}}}

%%{{{ The enumeration game of Smullyan 
\note O jogo de enumeração de Smullyan.
%%%{{{ meta 
\label Smullyan_game
\indexes
    * estratégia!vencedora
    ;;
\credits
    * Smullyan : jogo
    ;;
%%%}}}

Smullyan criou o seguinte jogo que ajuda em entender o conceito
de conjunto enumerável.  Seja $S$ um conjunto que chamaremos de
\dterm{conjunto-segredo}.  Tu, o jogador, e eu, o inimigo, começamos
o jogo e nos dois sabemos qual é o conjunto $S$ desse jogo.
Eu jogo primeiro, escolhendo um membro $w\in S$.
Teu objectivo é adivinhar o $w$.
Todo dia tu tens um palpite, e eu vou responder ``sim'' ou ``não''.
No dia $i$ então, tu escolhe um membro $s_i \in S$ como um
palpite fazer exatamente um palpite na forma equacional:
$$
w = s_i?
$$
onde $s_i$ é teu $i$-ésimo palpite, ou seja, o palpite do dia $i$.
Tu ganhas se um belo dia tu conseguir adivinhar a minha escolha:
o $w$ que selecionei no inicio do jogo.
Um exemplo de jogo então com $S=\nats$ parece assim:
\dialogue
\say Eu escolhi meu membro $w \in \nats$.
\say (Dia 0:) É o 42?
\say Não.
\say (Dia 1:) É o 28?
\say Não.
\say (Dia 2:) É o 8?
\say Não.
\say (Dia 3:) É o 1024?
\say Não.
\say (Dia 4:) É o 1024?
\say Não!
\say (Dia 5:) É o 12?
\say Sim.
\enddialogue
Quantas tentativas tu tens?
Um para cada dia, pra sempre!
Pois é, um detalhe pequeno: vamos supor que nós dois somos imortais.
E o inimigo não tem o direito de mudar seu palpite!
O jogo então é baseado no conjunto-segredo $S$.
O teu objectivo como jogador é adivinhar o $w$ que eu, teu inimigo, escolhi.
\eop
O teu objectivo como matemático é achar uma
\dterm{estratégia vencedora},
ou seja, \emph{uma estratégia que garanta vitória} para o jogador.
Se tal estratégia existe para esse jogo, dizemos que o $S$ é \dterm{enumerável}.
Observe que uma estratégia nesse jogo não é nada mais que uma
\emph{seqüência}
$$
s_0, s_1, s_2, s_3, s_4, \dotsc
$$
de membros de $S$, que o jogador vai seguir, jogando $s_i$ no $i$-ésimo dia.
Ela é vencedora sse
$$
\pforall {w \in S}
\lexists {i \in \nats}
{s_i = w}.
$$
Pensando em seqüências do $S$ como funções $s : \nats\to S$ isso quis
dizer que $s$ é sobrejetora.

%%}}}

%%{{{ Secret set
\note Conjunto-segredo: de easy para nightmare.
%%%{{{ meta 
%%%}}}

Vamos ver se (e como!)~tu jogaria nesse jogo com uns $S$
variando em dificuldade:
$$
S = \set {12, -2, 0}.
$$
Espero que é óbvio como garantir vitória aqui:
$$
0, 12, -2;
$$
ou seja, no primeiro dia jogue o $0$; se não foi o escolhido,
jogue o $12$; se nem isso foi o escolhido, jogue o $-2$ que com
certeza será o certo pois não tem outros membros o~$S$.
$$
S = \nats.
$$
Aqui a situação é pouco mais complicada, mais ainda múito fácil:
$$
0, 1, 2, 3, 4, \dotsc;
$$
ou seja: no dia $i$, escolha o $i$!
Não importa quão grande foi o número segredo $w$ que escolhi,
um belo dia (no $w$-ésimo dia mesmo) tu acertás!
Próximo!
$$
S = \ints.
$$
Aqui eu vou adivinhar qualquer inteiro.  O que farás?
Observe que a última estratégia não funciona mais.
Se eu escolher qualquer número negativo, tu nunca adivinharás,
pois tu \dq{ficarás preso} eternamente adicionando apenas
os inteiros não-negativos.
\emph{O fato que uma estratégia não é vencedora não quer dizer
que não existem vencedoras!}
Aqui realmente existe!

%%}}}

%%{{{ Q: Can we guarantee victory with S = ints ?
\question.
%%%{{{ meta 
%%%}}}

Tem como garantir vitória nesse jogo com $S = \ints$?

%%}}}

\spoiler

%%{{{ x: binary_union_of_countable_is_countable 
\exercise.
%%%{{{ meta 
\label binary_union_of_countable_is_countable
%%%}}}

A união $C\union D$ de dois conjuntos contáveis $C,D$ é contável.

%%}}}

%%{{{ Q: uncountable_or_uncountable_guess 
\question.
%%%{{{ meta 
\label countable_or_uncountable_guess
%%%}}}

Para cada um dos conjuntos seguintes, tu jogaria nesse jogo?
Ou seja, tem estratégia vencedora?
$$
\rm
\align
I   &= \setst {x\in\reals}   {\text{$x$ é irracional}}\\
A   &= \setst {x\in\reals}   {\text{$x$ é algébrico}}\\
T   &= \setst {x\in\reals}   {\text{$x$ é transcendental}}\\
C   &= \setst {z\in\complex} {\modulus z = 1}\\
P_L &= \setstt {p} {$p$ é um programa da linguagem de programação $L$}\\
G   &= \graph(f), \quad \text{onde $f : \reals\to\reals$ definida pela $f(x) = x^2$}\\
D   &= (\nats \to \set{0,2})\\
S   &= (\nats \to \nats)\\
P   &= (\nats \bijto \nats)\\
Z   &= \setst {f:\nats\to\nats} {\pexists {n_0\in\nats} \lforall {n\geq n_0} {f(n)=0}}
\endalign
$$

%%}}}

%%{{{ And the answers? 
\blah E as respostas?.
%%%{{{ meta 
%%%}}}

Pense nisso agora, meio-adivinhando, e até o fim desse capítulo tu vai
saber a resposta para cada um deles!

%%}}}

%%{{{ lemma: A_is_countable_equiv_statements 
\lemma.
%%%{{{ meta 
\label A_is_countable_equiv_statements
%%%}}}

Seja $A$ conjunto.
O.s.s.e.:
\item{\rm (1)} $A$ é contável
\item{\rm (2)} $A \leqc \nats$
\item{\rm (3)} $A=\emptyset$ ou $A$ possui enumeração.

\sketch.
As direcões $(1)\Rightarrow(2)\Rightarrow(3)$ são conseqüências fáceis
das definições.  Para ``fechar o round-robin'' ($(3)\Rightarrow(1)$),
precisamos definir uma \emph{bijecção} $f : \nats\bijto A$
ou $f : \finord n\bijto A$, dados uma \emph{surjecção} $\pi:\nats\surjto A$.
Usamos recursão e o princípio da boa ordem.

\proof.
Vamos demonstrar o lemma na maneira ``round-robin'', demonstrando as implicações
$(1)\Rightarrow(2)\Rightarrow(3)\Rightarrow(1)$.
As duas primeiras são conseqüências imediatas das definições---nada
interessante---mas para a $(3)\Rightarrow(1)$ precisamos mais cuidado.
\crproofpart {$(1)\Rightarrow(2)$.}
Caso $A$ finito, para algum $n\in\nats$ temos $A\eqc \finord n \subset \nats$
e logo $A \leqc \nats$.
Caso que $A$ infinito, temos $A\eqc\nats\subset\nats$ e logo $A \leqc \nats$.
\crproofpart {$(2)\Rightarrow(3)$.}
Suponha que $A\neq\emptyset$.
Vamos construir uma enumeração do $A$, ou seja, uma $\pi : \nats \surjto A$.
Pela hipótese, seja $N_0 \subset \nats$ tal que $A \eqc N_0$.
E logo temos uma bijecção $f : N_0 \bijto A$.
Seja $a_0 \in A$ ($A\neq\emptyset$) e defina a função $\pi : \nats \to A$ pela
$$
\pi(x) =
\knuthcases {
f(x), & se $x \in N_0$ \cr
a_0,  & se não.
}
$$
Basta verificar que $\pi$ é realmente sobrejetora, mas isso é fácil:
para cada $a\in A$, temos
$$
\pi(\finv{f}(a)) = a.
$$
\proofpart {$(3)\Rightarrow(1)$.}
Caso $A$ finito, $A$ é contável.
Suponha que $A$ infinito, e seja $\pi : \nats \surjto A$
uma enumeração de $A$.
Precisamos definir uma bijecção $f : \nats\bijto A$ ou $f : \finord n\bijto A$.
Defina a $f$ pela recursão
$$
\align
f(0)   &= \pi(0) \\
\text{e para $n>0$ defina}\qquad
f(n) &= \pi(m_n)
\phantom{\text{e para $n>0$ defina}\qquad}
\endalign
$$
onde $m_n$ é o menor natural $m$ tal que $\pi(m) \nin \set{f(0),\dotsc,f(n-1)}$.
Observe que tal $m_n$ existe pois a $(\leq)$ no $\nats$ é uma boa ordem (\ref[natleq_woset]).

%%}}}

%%{{{ What do we gain? 
\note O que ganhamos?.
%%%{{{ meta 
%%%}}}

Suponha que um conjunto $A$ é contável.
O que ganhamos realmente com essa informação?
Como podemos usar essa hipótese?
Já sabemos, por exemplo, que o fato ``$C \neq \emptyset$'' nos permite escrever ``Seja $c\in C$.''.
O que o fato ``$A$ é contável'' nos permite fazer?
Bem, podemos escrever: ``seja $a_n$ uma \emph{enumeração} de $A$'', ou, escrever:
``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''.

%%}}}

%%{{{ beware 
\beware.
%%%{{{ meta 
%%%}}}

É um erro comum escrever ``Suponha $A = \set{a_0, a_1, a_2, \dotsc}$.''~mesmo quando
não sabemos que $A$ é contável.  Talvez $A$ é \emph{grande demais} para poder ser
escrito nessa forma.  Como o $\reals$, por exemplo, que sabemos que não pode ser escrito
como $\reals = \set{r_0, r_1, r_2, \dotsc}$, pois é um conjunto incontável!%

%}}}

\endsection
%%}}}

%%{{{ Cantor's first diagonal argument 
\section O primeiro argumento diagonal de Cantor.
%%%{{{ meta 
\label Cantor_first_diagonal_argument
%%%}}}

%%{{{ And the rationals? 
\note E os racionais?.
%%%{{{ meta 
%%%}}}

O fato que $\ints$ é contável não deixou ninguém muito surpreso.
Mas na maneira que contamos os membros do $\ints$, existe essa
idéia de ``próximo número'' meio incorporada no próprio conjunto
pela sua ordem.
\emph{<<Primeiramente tome o $0$.
Depois tome o próximo positívo,
e depois o próximo negativo, e por aí vai.>>}
Mas o $\rats$ com sua ordem padrão é um conjunto \dterm{denso}:
entre quaisquer racionais $x,y$ com $x<y$, existe racional $w$
tal que $x < w < y$.  Vamos dizer que começou no $0$.
Quem vai depois?  Não existe ``próximo'' para nenhuma direção!
Em vez de contar os membros de $\rats$, vamos contar
os membros de $\nats^2$.  E isso já vai resolver o problema
de enumerar o $\rats$ facilmente.

%%}}}

%%{{{ Counting the pairs of nats 
\note Contando os pares de naturais.
%%%{{{ meta 
%%%}}}

Naturalmente pensamos no $\nats^2$ numa forma bidimensional
(até pronunciando o conjunto usamos a palavra ``quadrado'').
Vamos arrumar então os naturais numa tabela bidimensional
e infinita assim:
$$
\tikzpicture
\tikzi pairs5x5nats;
\endtikzpicture
$$
Naturalmente, influenciados por nossos hábitos talvez gostariamos
de contar os membros linha por linha, ou coluna por coluna---só
que\dots
\eop\bigskip\noi
\centerline{Expectativa:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
    \draw[->] (-.5,-\y) -- (4.666,-\y);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
    \draw[->] (\x,.5) -- (\x,-4.5);
}
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
\eop\bigskip\noi
\centerline{Realidade:}\nobreak
$$
\xalignat 2
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node at (-1,-\y) {$S_{\y}$};
}
\draw[->] (-.5,0) -- (4.666,0);
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
&
&\tikzpicture
\tikzi pairs5x5nats;
\foreach \x in {0,...,4} {
    \node at (\x,1) {$S_{\x}$};
}
\draw[->] (0,.5) -- (0,-4.5);
\node at (5, 1) {$\cdots$};
\endtikzpicture
\endxalignat
$$
O que aconteceu?
Stratificando nosso espaço nessa maneira, \emph{ficaremos presos}
no $S_0$ pra sempre!  Se o inimigo no jogo escolher qualquer um dos
membros fora do $S_0$ a gente nunca vai ganhar!

%%}}}

%%{{{ Finite strata 
\note Strata finita.
%%%{{{ meta 
%%%}}}

Stratificando nosso espaço precisamos tomar cuidado para qualquer
stratum ser um conjunto \emph{finito}.  Usando a analogia do jogo
isso garanta vitória, pois ficaremos no primeiro stratum para uma
quantidade finita de dias, e um belo momento depois de ter contado
todos os membros do primeiro stratum vamos começar o segundo,
que (sendo também finito) sabemos que um belo dia já vamos começar
contar o terceiro; etc., etc.

%%}}}

%%{{{ Cantor's first diagonal argument 
\note O primeiro argumento diagonal de Cantor.
%%%{{{ meta 
\label Cantor_stratification_of_pairs
\credits
    * Cantor : diagonalização
    ;;
%%%}}}

Cantor conseguiu stratificar esse
espaço apenas virando sua cabeça num ângulo $\pi/4$:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \y in {0,...,4} {
    \node[rotate=45] at (-.8,-\y-.8) {$S_{\y}$};
    \draw[->] (-.5,-\y-.5) -- (\y+.5,.5);
}
\node at (-.8, -5.666) {$\vdots$};
\endtikzpicture
$$
Observe que na stratificação de Cantor, \emph{cada stratum é finito}.
Com sua método de diagonalização Cantor conseguiu algo maravilhoso:
contou todos dos \emph{racionais}, algo muito chocante, pois a maneira
que visualizamos esse conjunto é \emph{muito} mais populosa daquela
dos inteiros ou dos naturais.  Mas chega Cantor e nos ilumina:
\emph{o $\rats$ parece tão mais populoso porque tu não tá fazendo
essa dupla abstração, deixando a natureza e ordem te confundir!}

%%}}}

%%{{{ Gödel's stratification 
\note A stratificação de Gödel.
%%%{{{ meta 
\label Godel_stratification_of_pairs
%%%}}}

\Godel[diagonalização]Gödel muitos anos depois preferiu uma
stratificação diferente:
$$
\tikzpicture
\tikzi pairs5x5nats;
\foreach \i in {0,...,4} {
    \node at (-1,-\i) {$S_{\i}$};
    \draw[rounded corners=2ex,->] (-.5,-\i) -- (\i,-\i) -- (\i,.5);
}
\node at (-1, -4.666) {$\vdots$};
\endtikzpicture
$$
Observe que aqui também cada stratum é finito, e logo serve para
contar todos os membros do conjunto.

%%}}}

%%{{{ x: define_both_stratifications_of_pairs 
\exercise.
%%%{{{ meta 
\label define_both_stratifications_of_pairs
%%%}}}

Defina formalmante as stratificações de
Cantor~(\reftag[Cantor_stratification_of_pairs]) e de
Gödel~(\reftag[Godel_stratification_of_pairs]).
Observe que cada stratum, sendo finito, pode ser representado por um
conjunto (e não uma tupla) sem problema nenhum.
Defina curtamente então, usando a notação set builder,
os $S_n$'s de ambas as stratificações.

\hint
$S_n = \setst {(x,y)} {\asklhole}$.

%%}}}

%%{{{ no_repetitions_implies_bijection 
\remark.
%%%{{{ meta 
\label no_repetitions_implies_bijection
%%%}}}

Para corresponder numa bijecção mesmo, o jogo do~\reftag[Smullyan_game]
tem que ser modificado, para proibir repetições do mesmo palpite.
Observamos que se o jogador tem uma estratégia para ganhar num jogo que
permite repetições de palpites, ele já pode adaptá-la para ganhar no
jogo com a restricção: ele apenas segue a estratégia do jogo ``livre''
e quando aparecem palpites que ele já adivinhou, ele pula para o próximo,
até chegar num palpite que ele não tentou ainda, para tentá-lo.
Por exemplo, para enumerar os racionais sabendo uma enumeração dos pares
de inteiros, copiamos a estratégia do $\ints^2$, pulando pares que ou não
correspondem em racionais (como o $(0,0)$ por exemplo), ou que são iguais
com palpites anteriores (como o $(2,4)$ que pulamos por causa do $(1,2)$
que já adivinhamos).

%%}}}

%%{{{ thm: countable_union_of_countables_is_countable 
\theorem.
%%%{{{ meta 
%%%}}}

Seja $\cal C$ uma colecção contável de conjuntos contáveis.
Logo $\Union \cal C$ é contável.
Em outras palavras: união contável de contáveis é contável.

\sketch.
Seja $\seqn C n$ uma enumeração dos membros do $\cal C$:
$$
\align
\cal C &= \set{ C_0, C_1, C_2, \dotsc }.
\intertext{Sabemos que todos os $C_n$'s são contáveis; logo seja
$\sequence {c_n^i} i$ uma enumeração do $C_n$:}
C_0 &= \set {c_0^0, c_0^1, c_0^2, c_0^3, \dotsc } \\
C_1 &= \set {c_1^0, c_1^1, c_1^2, c_1^3, \dotsc } \\
C_2 &= \set {c_2^0, c_2^1, c_2^2, c_2^3, \dotsc } \\
    &\eqvdots 
\endalign
$$
e agora é óbvio como usar o primeiro argumento diagonal de Cantor
e obtenir uma enumeração do $\Union \cal C = \Union_{n=0}^{\infty} C_n$.

%%}}}

%%{{{ Are there uncountable sets? 
\note Tem incontáveis?.
%%%{{{ meta 
%%%}}}

Até este momento podemos sentir uns dos sentimentos de {\Cantor}Cantor
investigando essas infinidades.  Até talvez uma frustração, pois,
por enquanto, todos os conjuntos infinitos que testamos acabaram sendo
contáveis.  Será que todos são?  Os reais estão resistindo ainda,
mas antes de pensar no primeiro argumento diagonal, os racionais
também estavam!
Agora tu demonstraras que bem mais conjuntos são realmente contáveis.

%%}}}

%%{{{ x: strings_from_finite_alphabet_countable 
\exercise.
%%%{{{ meta 
\label strings_from_finite_alphabet_countable
%%%}}}

Demonstre ou refute:
o conjunto de todos os strings feitos por qualquer alfabeto finito é contável.

%%}}}

\endsection
%%}}}

%%{{{ Hacking intermission 
\problems Intervalo para hackear.
%%%{{{ meta 
%%%}}}

%%{{{ codeit: EnumPairs 
\codeit EnumPairs.
%%%{{{ meta 
\label program_enumpairs
%%%}}}

Implemente uma estratégia para ganhar no jogo sem repetições com
conjunto-segredos o $\nats^2$.
Ou seja, escreva um programa que imprime (pra sempre) os palpites
do jogador na sua ordem.

%%}}}

%%{{{ codeit: EnumRatsReps 
\codeit EnumRatsReps.
%%%{{{ meta 
\label program_enumrats
%%%}}}

Modifique o EnumPairs para o caso com conjunto-segredos
o conjunto de racionais não-negativos, mas permitindo repetições.
Represente cada palpite como fracção,
imprimindo por exemplo o racional $\frac 1 3$ como o string
``{\tt 1/3}''.

%%}}}

%%{{{ codeit: EnumRats 
\codeit EnumRats.
%%%{{{ meta 
\label program_enumratsnoreps
%%%}}}

Modifique o EnumRats para o caso que o jogo proibe
repetições (mas para o mesmo conjunto $\rats_{\geq0}$).
Use teu código para responder na pergunta:
\emph{dada a escolha do inimigo, em qual dia o jogador vai adivinhá-la?}

%%}}}

%%{{{ x: amnesiac_player 
\exercise Jogador amnésico.
%%%{{{ meta 
\label amnesiac_player
%%%}}}

Ache uma estratégia para ganhar no jogo com conjunto-segredos o
conjunto dos racionais não-negativos, se o jogador tem memória que o
permite lembrar apenas seu último palpite!

%%}}}

%%{{{ x: nextPair 
\exercise.
%%%{{{ meta 
\label nextPair
%%%}}}

Defina uma função 
$\namedop{nextPair} : \nats^2 \to \nats^2$
tal que para cada entrada $(n,m)$ ela retorna o próximo palpite do jogador
que acabou de tentar o $(n,m)$, no jogo com conjunto-segredos o $\nats^2$.
Considera que sua estratégia começa com o palpite $(0,0)$.
Assim, a enumeração representada pela estratégia do jogador seria a:
$$
(0,0), f(0,0), f^2(0,0), f^3(0,0), \dotsc,
$$
ou seja, a seqüência $\set{ f^n (0,0) }_{n}$.

%%}}}

%%{{{ codeit: NextPair 
\codeit NextPair.
%%%{{{ meta 
\label NextPair
%%%}}}

Implemente função do~\ref[nextPair].

%%}}}

\endproblems
%%}}}

%%{{{ Cantor's second diagonal argument 
\section O segundo argumento diagonal de Cantor.
%%%{{{ meta 
\pdefs
    \pdef a {\alert}
    \pdef b {\phantom0}
    \pdef n {}
    \pdef f {\faded}
    \pdef u {\underline}
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos finalmente atacar a cardinalidade dos reais, começando com seu
subconjunto $[0,1]\subset\reals$.
Vamos ver que realmente isso é um conjunto \dterm{incontável}.
Não tem como enumerar seus membros!
Como podemos demonstrar isso?
Lembrando a definição, basta demonstrar que não existe enumeração
$$
[0,1] = \set{a_0, a_1, a_2, \dots}.
$$
Vamos começar com um esboço que tem um erro para entender a idéia
básica---e para ver se tu perceberás o erro, claro.

%%}}}

%%{{{ A slightly wrong sketch 
\note Um esboço pouco errado.
%%%{{{ meta 
%%%}}}

Suponha que alguém chegou feliz pra ti, afirmando que conseguiu enumerar
todos os reais no $[0,1]$, a apresenta sua enumeração pra ti:
$$
a_0, a_1, a_2, a_3, \dots
$$
Tu pega sua lista e escreva a expansão decimal de cada número,
um número por linha; por exemplo:
$$
\matrix
\format
\r  &~~\c~~&     &\c    &\c     &\c     &\c     &\c     &\c     &\c   &\c \\
a_0 &=     &0\b. &\b 3  &\b 6   &\b 4   &\b 8   &\b 8   &\b 5   &\b 0 &\b \dots \\
a_1 &=     &0\b. &\b 2  &\b 1   &\b 8   &\b 9   &\b 8   &\b 0   &\b 5 &\b \dots \\
a_2 &=     &0\b. &\b 0  &\b 8   &\b 9   &\b 8   &\b 5   &\b 8   &\b 8 &\b \dots \\
a_3 &=     &0\b. &\b 9  &\b 2   &\b 6   &\b 6   &\b 8   &\b 6   &\b 6 &\b \dots \\
a_4 &=     &0\b. &\b 2  &\b 3   &\b 4   &\b 6   &\b 0   &\b 5   &\b 7 &\b \dots \\
    &\eqvdots&
\endmatrix
$$
Nosso objectivo é mostrar um certo número $w \in [0,1]$ que não está nessa lista.
Vamos definir esse $w$ construindo sua expansão decimal:
$$
\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots
\endmatrix
$$
E a idéia é a seguinte:
traversa a tabela acima diagonalmente, mudando o dígito,
construindo assim um novo número.
Os primeiros três passos aqui podem ser os seguintes:
$$
\xalignat3
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c \\
  w &\defeq &0\b. &\b\a4 &\b\f? &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\a3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\a2 &\b\f? &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\a1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\u9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
&
&\matrix
\format
\r  &~~\c~~ &     &\c    &\c    &\c    &\c    &\c    &\c    &\c\\
  w &\defeq &0\b. &\b\n4 &\b\n2 &\b\a0 &\b\f? &\b\f? &\b\f? &\b\dots \\
a_0 &=      &0\b. &\b\u3 &\b\f6 &\b\f4 &\b\f8 &\b\f8 &\b\f5 &\b\dots \\
a_1 &=      &0\b. &\b\f2 &\b\u1 &\b\f8 &\b\f9 &\b\f8 &\b\f0 &\b\dots \\
a_2 &=      &0\b. &\b\f0 &\b\f8 &\b\a9 &\b\f8 &\b\f5 &\b\f8 &\b\dots \\
a_3 &=      &0\b. &\b\f9 &\b\f2 &\b\f6 &\b\u6 &\b\f8 &\b\f6 &\b\dots \\
a_4 &=      &0\b. &\b\f2 &\b\f3 &\b\f4 &\b\f6 &\b\u8 &\b\f5 &\b\dots \\
    &\eqvdots
\endmatrix
\endxalignat
$$
onde para mudar cada dígito, eu fui para o ``próximo''.
Foi construido assim o
$$
\matrix
\format
\r  &~~\c~~ &     &\c  &\c  &\c  &\c  &\c  &\c \\
  w &\defeq &0\b. &\b4 &\b2 &\b0 &\b7 &\b9 &\b\dots
\endmatrix
$$
que não está na lista $a_0, a_1, a_2, \dots$.
\mistake

%%}}}

%%{{{ Q: why is w not in the list? 
\question.
%%%{{{ meta 
%%%}}}

Por que $w$ não está na lista?

%%}}}

\spoiler

%%{{{ A 
\blah.
%%%{{{ meta 
%%%}}}

Pois pela sua construção, o $w$ discorda com todos os
membros da lista em pelo menos uma posição:
ele discorda com o $a_0$ na primeira posição, com o $a_1$
na segunda, etc.
É fácil demonstrar que
$$
\text{para todo $n\in\nats$,}\quad
w \neq a_n.
$$
Seja $n\in \nats$.
Agora observe que o $w \neq a_n$ pois pela sua construção,
ele discorda com o $a_n$ no $n$-ésimo dígito.
\mistake

%%}}}

%%{{{ Q: why wrong? 
\question.
%%%{{{ meta 
%%%}}}

Qual o problema com essa argumentação?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

O argumento é baseado numa hipótese falsa para concluir que o
número $w$ construido é diferente de todos os números da lista:
que duas expansões de números reais que discordam no dígito duma
certa posição representão reais distintos, que tá simplesmente errado:
$$
0.4999\dots = \frac 1 2 = 0.5000\dots
$$
as expansões são distintas, não temos reais distintos aqui!

%%}}}

%%{{{ blah: Now what? 
\blah E agora?.
%%%{{{ meta 
%%%}}}

Em vez de desistir e jogar a idéia brilhante fora, podemos
(i) perceber que já temos nas nossas mãos uma demonstração da incontabilidade
dum certo conjunto, só que não é o conjunto $[0,1]$
e (ii) proceder para concertar o probleminha da argumentação para virar
uma demonstração correta da incontabilidade do $[0,1]$ mesmo!
Faça ambos agora.

%%}}}

%%{{{ x: wrong_sketch_is_correct_for_another_set 
\exercise (i).
%%%{{{ meta 
%%%}}}

Sobre qual conjunto podemos já afirmar que é incontável, usando
a argumentação bugada que não deu certo para o $[0,1]$?

\hint
As expansões são distintas sim; os números que representão não.

\solution
Vendo as expansões como strings (infinitos) feitos pelo alfabeto
${0,\dotsc,9}$ já temos que o conjunto de todos eles não é contável.

%%}}}

%%{{{ thm: binary_sequences_uncountable 
\theorem Cantor.
%%%{{{ meta 
\label binary_sequences_uncountable
\credits
    * Cantor
    ;;
\pdefs
    \pdef m   {{\rm m}}
    \pdef w   {{\rm w}}
    \pdef two {{\mathbf 2}}
    ;;
%%%}}}

O conjunto de todas as seqüências feitas por dois símbolos distintos
é incontável.

\proof.
Cantor escolheu os \symq{$\m$} e \symq{$\w$} como símbolos distintos,
vamos seguir seu gosto então.  Denotamos $\two = \set{\m,\w}$.
Seja $\seqnset f n \subset \funspace \nats \to \two$.
Basta construir um membro de $\funspace \nats \to \two$ que não
é nenhum dos membros de $\seqnset f n$.
Definimos a $g : \nats \to \two$ então pela
$$
g(x) =
\knuthcases {
\w,   & se $f(x) = \m$;\cr
\m,   & se $f(x) = \w$.
}
$$
Basta verificar que para todo $n \in \nats$, $g \neq f_n$.
Seja $n \in \nats$ então.
Pela definição da $g$ temos que $g,f_n$ discordam no ponto $n$
e logo $g \neq f_n$.

%%}}}

%%{{{ x: fix_the_problem_of_wrong_sketch 
\exercise (ii).
%%%{{{ meta 
%%%}}}

Conserta o problema.

\hint
Os únicos conflitos de expansões envolvem reais com exatamente duas expansões:
uma que a partir duma posição só tem $0$'s, e uma que a partir duma posição só
tem $9$'s.

\hint
Basta determinar uma maneira de trocar os digitais da diagonal que garanta que
cada dígito mudou mesmo e que o número criado não termina nem em $0$'s nem em
$9$'s.

\solution
Os únicos conflitos de expansões envolvem reais com exatamente duas expansões:
uma que a partir duma posição só tem $0$'s, e uma que a partir duma posição só
tem $9$'s.
Logo basta determinar uma maneira de trocar os digitais da diagonal que garanta
que cada dígito mudou mesmo e que o número criado não termina nem em $0$'s nem
em $9$'s:
Mandamos todos os dígitos diferentes de $5$ para o $4$ e o $4$ para o $5$.

%%}}}

%%{{{ x: Why does this proof (1891) fail for rationals? 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que
o $\setst{q \in \rats}{0\leq q\leq 1}$ também é incontável?

\hint
Como tu vai demonstrar que o número construido pela método
diagonal de Cantor realmente é um elemento de $\rats\inter[0,1]$?

%%}}}

\endsection
%%}}}

%%{{{ Cantor set 
\section O conjunto de Cantor.
%%%{{{ meta 
\label Cantor_set
\credits
    * Cantor : conjunto de Cantor
    ;;
%%%}}}

%%{{{ Cantor set 
\note O conjunto de Cantor.
%%%{{{ meta 
\defines
    * Cantor!conjunto de
    ;;
\indexes
    * conjunto!de Cantor    see: Cantor
    ;;
%%%}}}

$$
\tikzpicture
\tikzi cantorset;
\endtikzpicture
$$

%%}}}

\TODO Terminar.

\endsection
%%}}}

%%{{{ Some important applications 
\section Umas aplicações importantes da teoria de Cantor.
%%%{{{ meta 
%%%}}}

%%{{{ corollary: irrats_uncountable 
\corollary.
%%%{{{ meta 
\label irrats_uncountable
%%%}}}

Os irracionais são incontáveis.

\proof.
Os racionais são contáveis.  Os reais incontáveis.
Logo, os irracionais são incontáveis, pois
$\reals = \rats \union \paren{\reals\setminus\rats}$
e logo se $\reals\setminus\rats$ fosse contável teriamos
a contradição do $\reals$ ser contável também
(\ref[binary_union_of_countable_is_countable]).

%%}}}

%%{{{ And the transcendentals? 
\note E os transcendentais?.
%%%{{{ meta 
%%%}}}

Os transcendentais parecem ainda mais selvagens que os irracionais.
E neste momento temos poquíssimos exemplos: os números de {\Liouville}Liouville
que foram contruidos exatamente com esse propósito;
o $e$ que {\Hermite}Hermite acabou de demonstrar que é
transcendental~(\yearof{1873}) e a transcendentalidade do $\pi$ demorou uns anos.
Como encontramos transcendentais tão raramente em comparação com os algébricos
faz sentido pensar que eles são contáveis.\foot
Na verdade, a única razão que temos nesse momento de acreditar
que o conjunto de transcendentais é infinito são os números Liouville:
ele realmente conseguiu contruir uma infinidade (incontável) de transcendentais.
\toof

%%}}}

%%{{{ lemma: algebraics_are_countable 
\lemma Dedekind.
%%%{{{ meta 
\label algebraics_are_countable
\credits
    * Dedekind
    ;;
%%%}}}

Os algébricos são contáveis.

\sketch.
Basta observar que $\polys\rats x \eqc \kstar\rats$, com a correspondência
$$
a_0 + a_1 x + a_2 x^2 + \dotsb + a_{n-1} x^{n-1} + a_n x^n
\leftrightarrow
\tupp{a_0, a_1, a_2, \dotsc, a_{n-1}, a_n}.
$$
Seja $f_0, f_1, f_2, \dotsc$ uma enumeração do $\polys\rats x$.
Stratificamos então os números algébricos onde o $i$-ésimo stratum é o
conjunto de todas as raízes reais de $f_i$:
$$
S_i = \setst {\alpha\in\reals} {f_i(\alpha) = 0}.
$$
Pelo teorema fundamental da Álgebra agora, sabemos que cada $f_i$
tem no máximo $\deg(f_i)$ raízes, ou seja, todos os strata
são finitos e pronto!

%%}}}

%%{{{ corollary: transcends_uncountable 
\corollary Cantor.
%%%{{{ meta 
\label transcends_uncountable
\credits
    * Cantor
    ;;
%%%}}}

Os transcendentais são incontáveis.

\proof.
Como os algébricos são contáveis (\ref[algebraics_are_countable]),
os transcendentais são incontáveis com o mesmo argumento da demonstração
do~\ref[irrats_uncountable].

%%}}}

%%{{{ Sky and stars 
\note Céu de estrelas.
%%%{{{ meta 
%%%}}}

Sem as descobertas de Cantor, alguém pensaria que isso
é uma coincidência muito grande e bizarra:
como aconteceu que a gente definiu um número bem importante
como o $\pi$ ou o $e$ e aconteceu que ele tem essa propriedade
estranha de ser transcendental?
Mas, graças ao Cantor, sabemos melhor:
\emph{de fato, seria bizarro se fosse o contrário!}
Pois sabemos agora que, na verdade, as excessões são os
algébricos e não os transcendentais.
O estranho seria descobrir que $e$ aconteceu que é racional!
Como piada considere o princípio seguinte:

%%}}}

%%{{{ joke: transcendentality_principle 
\joke Princípio de transcendentalidade.
%%%{{{ meta 
\label transcendentality_principle
%%%}}}

Seja $x\in\reals$ com $x\neq0,1$.
Se $x$ é profundamente interessante em matemática,
então $x$ é transcendental.

%%}}}

%%{{{ Liouville vs Cantor 
\note Liouville vs Cantor.
%%%{{{ meta 
\label Liouville_vs_Cantor
%%%}}}

É comum encontrar argumentos favorecendo o teorema de Liouville
contra o teorema de Cantor, sobre a existência de transcendentais.
Normalmente escutamos algo do tipo <<Liouville construiu e mostrou
transcendentais, Cantor apenas demonstrou que existem sem constriur
ou mostrar nenhum>>.
Essa afirmação é completamente errada!

%%}}}

%%{{{ x: cantor_proof_is_constructive 
\exercise.
%%%{{{ meta 
\label cantor_proof_is_constructive
%%%}}}

Explique o porquê.

%%}}}

%%{{{ codeit: CantorCon 
\codeit CantorCon.
%%%{{{ meta 
\label CantorCon
%%%}}}

Escreva um programa que compute irracionais e transcendentais.
Considere que teu usuário vai querer determinar quantos
números construir, e também até que precisão (quantos dígitos).

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas: Cantor \vs Reais.
%%%{{{ meta 
%%%}}}

%%{{{ blah: Cantor, Cantor, Cantor 
\blah O conjunto dos reais é incontável.
%%%{{{ meta 
%%%}}}

{\Cantor}Cantor não deu apenas uma demonstração para esse teorema seu.
A demonstração que já encontramos aqui, que envolve seu argumento
diagonal, é a mais importante e elegante (exatamente por causa da
diagonalização e suas diversas aplicações).\foot
Cantor terminou seu artigo \cite[cantor1891] onde publicou sua demonstração
com a frase profética
\emph{\dq{Die weitere Erschließung dieses Feldes ist Aufgabe der Zukunft.}}
que significa:
\emph{desenvolver essa área mais é a tarefa do futuro}.
\toof
Mas essa foi nem a primeira, nem a segunda, mas sim a terceira demonstração dele!
As outras duas foram bem diferentes.
{\Cantor}Cantor que o $\reals$ é incontável
foi bem diferente.  Dado quaisquer reais $a,b$ com $a < b$
e qualquer seqüência de reais no $[a,b]$
ele mostrou um certo membro do $[a,b]$ que a seqüência ``esqueceu de contar''.
Redescobrir essa demonstração é o objetivo do \ref[reals_uncountable_first_proof].

%%}}}

%%{{{ prob: reals_uncountable_first_proof 
\problem Cantor \vs Reais: 1874.
%%%{{{ meta 
\label reals_uncountable_first_proof
\credits
    * Cantor
    ;;
%%%}}}

Sejam $a,b\in\reals$ com $a < b$ e $\seqn x n$ seqüência de reais no $[a,b]$.
Demonstre que existe $w \in [a,b]$ tal que $w \nin \seqnset x n$,
seguindo o esboço seguinte.
O plano é construir uma cadeia de intervalos fechados
$$
[a,b] = I_0 \supset I_1 \supset I_2 \supset \dotsb
$$
e escolher o $w$ na sua intersecção.
Para conseguir isso, vamos definir duas subseqüências $\seqn a n$ e $\seqn b n$ da
seqüência $\seqn x n$ tais que
a primeira começa no $a$ e é ascendente e a segunda no $b$ e é descendente
tais que os intervalos $[a_n,b_n]$ vão assumir o papel dos $I_n$.

%%}}}

%%{{{ prob: Why does this proof (1874) fail for rationals? 
\problem.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que o
$\setst{q \in \rats}{a \leq q\leq b}$ também é incontável?

%%}}}

\endproblems
%%}}}

%%{{{ Looking for bijections 
\section Procurando bijecções.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos ver como as transformações de esticar/encolher
(stretch/shrink) e de deslocar (shift) nos intervalos de reais,
sendo bijecções levam suas entradas para saídas equinúmeras.

%%}}}

%%{{{ x: stretch and shrink intervals 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre as seguintes equinumerosidades entre os seguintes intervalos de reais:
\elist a:
\li: $(0,1) \eqc (0,2)$;
\li: $(0,2) \eqc (3,5)$;
\li: $[0,1) \eqc (0,1]$;
\li: $(a,b) \eqc (c,d)$;
\li: $[a,b) \eqc [c,d)$;
\li: $[a,b) \eqc (c,d]$;
\li: $[a,b] \eqc [c,d]$;
\endelist
(onde $a < b$ e $c < d$).

\hint
Tente aproveitar que composição de bijecções é bijecção, quebrando assim cada
tarefa em tarefas menores e mais fáceis para resolver, tais que a composição
das resoluções delas, resultará na resolução da tua tarefa inicial.

%%}}}

%%{{{ x: (α,β) =c (0,1) 
\exercise.
%%%{{{ meta 
%%%}}}

Mostre as seguintes equinumerosidades entre os seguintes intervalos de reais,
$$
(\alpha,\beta) \eqc (0,1)
$$
onde $\alpha,\beta \in \reals\union\set{\minfty,\pinfty}$ com $\alpha < \beta$.

\hint
Esticar um intervalo dum comprimento finito para outro maior
é bem facil visualizar.  Mas como esticamos um intervalo de comprimento
finito para a reta dos reais cujo comprimento é infinito?

\hint
Uma maneira geometrica para resolver o $(a,b) \eqc (\minfty,\pinfty)$ é
pegar o $(a,b)$, curvá-lo para parecer um semicírculo, e posicioná-lo
em cima da reta real como parece na figura seguinte:
\math
\tikzpicture
\tikzi infinitestretch_hint;
\endtikzpicture
\endmath
E agora?

\hint
Agora estabelecemos uma correspondência (bijecção) entre os pontos da reta
e os pontos do nosso semicírculo juntando cada ponto $x \in \reals$
com um segmento reto até o centro do semicírculo e mapeando o $x$
para o ponto que o segmento intersecta o semicírculo:
\math
\tikzpicture
\tikzi infinitestretch;
\endtikzpicture
\endmath

%%}}}

\endsection
%%}}}

%%{{{ The Cantor--Schröder--Bernstein theorem 
\section O teorema Cantor--Schröder--Bernstein.
%%%{{{ meta 
\label The_CSB_theorem
\credits
    * Cantor
    * Schroder
    * Bernstein
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Esse teorema que demonstramos aqui é conhecido como
``Cantor--Schröder--Bernstein''
ou ``Schröder--Bernstein'', mas vamos referir a ele nessas notas
apenas com o nome de Bernstein, pois foi o primeiro que demonstrou
sua veracidade numa forma correta.\foot
E sua demonstração não precisou o
\emph{axioma da escolha}~(\reftag[Axioms_of_choice]),
algo que vamos apreciar mais no~\ref[Set_theory].
\toof
Vamos começar atacando esse problema com uma abordagem amorosa,
de {\Smullyan}Smullyan (veja~\cite[smullyanbeginners]).

%%}}}

%%{{{ x: schroder_bernstein_by_smullyan 
\exercise Abordagem amorosa.
%%%{{{ meta 
\label schroder_bernstein_by_smullyan
%%%}}}

Suponha que num universo seus habitantes são divididos em dois conjuntos \emph{infinitos}:
o conjunto $A$ de homens e $B$ de mulheres.
Suponha também que os seguintes são fatos sobre esse universo:
\elist 1:
\li: Cada homem ama exatamente uma mulher.
\li: Nenhuma mulher é amada por dois homens.
\li: Cada mulher ama exatamente um homem.
\li: Nenhum homem é amado por duas mulheres.
\endelist
(Essas condições já deixam esse universo bem bizarro.)
Mostre que tem como casar todos os habitantes desse universo
em casamentos monogâmicos e heterosexuais,
em tal modo que em cada casal é garantido amor
(mas não necessariamente reciprocal), ou seja:
se $a\in A$ é casado com $b\in B$, \emph{pelo menos uma} das duas condições acontece:
$a$~ama~$b$; $b$~ama~$a$.

\hint
Escolhe uma pessoa $x \in A \union B$.  Independente se ela é homem ou mulher,
podemos a perguntar: \emph{<<quem te ama?>>}.
Duas possibilidades existem: ou ela é amada por algum $x_1 \in A \union B$,
ou ninguém ama $x$.  No primeiro caso perguntamos $x_1$ a mesma pergunta,
definindo assim o $x_2$, se $x_1$ é uma pessoa amada, etc.
Observerve que cada $x \in A \union B$ defina assim um \dterm{caminho amoroso}
$x, x_1, x_2, \dots$.  Esse caminho ou é infinito, ou termina num certo membro $x_n \in A\union B$.
Vamos agora separar todas as pessoas do $A\union B$ em três grupos:
$$
\align
G_A         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $A$}\\
G_B         &= \setstt {x \in A\union B} {o caminho amoroso de $x$ termina num membro de $B$}\\
G_\infty    &= \setstt {x \in A\union B} {o caminho amoroso de $x$ é infinito}
\endalign
$$
Tente casar todos os membros de cada um desse grupo entre si!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Voltando dessa versão antropomórfica do problema, observe que
a condição (1) garanta a existência duma função $f : A \to B$,
que graças à (2) é injetora.
Similarmente, a condição (3) garanta a existência duma função
$g : B \to A$, que graças à (4) é injetora também.
Essas são as hipotéses do~\ref[schroder_bernstein].
Observe também que se resolver o problema amoroso do~\ref[schroder_bernstein_by_smullyan]
tu já forneceu uma função \emph{bijetora} $F : A \to B$, definida pela
$$
F(x) = \text{a pessoa casada com $x$}.
$$
Vamos ver isso agora sem amor.

%%}}}

%%{{{ thm: schroder_bernstein 
\theorem Bernstein.
%%%{{{ meta 
\label schroder_bernstein
\indexes
    * teorema!Schröder--Bernstein
    ;;
%%%}}}

{\Bernstein}%
Sejam conjuntos $A$ e $B$ e funções injetoras
$f : A \injto B$ e $g : B \injto A$.
Então existe bijecção $\phi : A \bijto B$.

%%}}}

\endsection
%%}}}

%%{{{ Looking for injections 
\section Procurando injecções.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora é \emph{bem} mais fácil demonstrar o seguinte
e ganhar o corolário embaixo.
Sem {\Bernstein}Bernstein, precisamos resolver o~\ref[change_of_ends_of_intervals_without_bernstein].

%%}}}

%%{{{ x: (a,b) \eqc (a,b] with Bernstein
\exercise.
%%%{{{ meta 
\label change_of_ends_of_intervals_with_bernstein
%%%}}}

Usando o teorema de Schröder--Bernstein~\reftag[schroder_bernstein]
demonstre que $(a,b) \eqc (a,b] \eqc [a,b]$.

%%}}}

%%{{{ cor: 
\corollary.
%%%{{{ meta 
%%%}}}

Qualquer intervalo não-trivial (vazio ou singleton) de reais,
tem a mesma cardinalidade com o próprio $\reals$.

%%}}}

%%{{{ x: \reals \eqc \pset\nats with Bernstein
\exercise.
%%%{{{ meta 
%%%}}}

Usando o teorema de Schröder--Bernstein~\reftag[schroder_bernstein]
demonstre que $\reals \eqc \pset\nats$.

%%}}}

\endsection
%%}}}

%%{{{ Encodings 
\section Codificações.
%%%{{{ meta 
\label Encodings
%%%}}}

%%{{{ Encodings 
\note Encodings.
%%%{{{ meta 
%%%}}}

Uma maneira de pensamento para construir injecções seria através
de codificações (ou \dterm{encodings}).
Uma \dterm{codificação} de $A$ no $B$ é qualquer injecção
de $A$ para $B$.

%%}}}

%%{{{ eg: rats_leqc_nats_encoding 
\example.
%%%{{{ meta 
\label rats_leqc_nats_encoding
%%%}}}

Para demonstrar que $\rats\leqc\nats$ basta achar uma maneira de
codificar cada racional como um natural.  Aqui um jeito fácil:
dado um racional $q\in \rats$ sejam $m,n$ tais que $q = m/n$
e $m/n$ irredutível; codificamos
$$
\align
m/n  &\mapsto 1\tubrace{00\cdots0}{$m$ vezes}1\tubrace{00\cdots0}{$n$ vezes}1.
\intertext{Assim,}
1/2  &\mapsto 101001 \\
10/6 = 5/3 &\mapsto 10000010001 \\
22/7 &\mapsto 10000000000000000000000100000001
\endalign
$$
etc.
Observe que para qualquer $n\in\nats$, existem dois casos:
ou ele serve como codificação para algum $q\in\rats$
(como o $101001$ acima) ou não (como o $1$, o $2$, o $1011$, etc.).
Caso que sim, podemos facilmente extrair a informação codificada
no $n$, voltando para o racional $q$:
$$
10001001 \leadsto 3/2.
$$
A mesma idéia serve para codificar o $\kstar\nats$:

%%}}}

%%{{{ x: kstar_nats_leqc_nats_encoding 
\exercise.
%%%{{{ meta 
\label kstar_nats_leqc_nats_encoding
%%%}}}

Demonstre usando codificação que $\kstar\nats \leqc \nats$.

%%}}}

%%{{{ x: pset_nats_leqc_zeroone_encoding 
\exercise.
%%%{{{ meta 
\label pset_nats_leqc_zeroone_encoding
%%%}}}

Demonstre usando codificação que $\pset\nats \leqc [0,1)$.

%%}}}

%%{{{ x: zeroone_eqc_nats_to_nats_encoding 
\exercise.
%%%{{{ meta 
\label zeroone_eqc_nats_to_nats_encoding
%%%}}}

Demonstre demonstrando duas codificações que $[0,1) \eqc (\nats\to\nats)$.

%%}}}

\endsection
%%}}}

%%{{{ Cantor's theorem and its consequences 
\section O teorema de Cantor e suas conseqüências.
%%%{{{ meta 
\label Cantors_theorem_and_its_consequences
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Até agora temos encontrado apenas duas quantidades infinitas diferentes:
aquela do $\nats$, e aquela do $\reals$.
Essa situação está prestes a mudar drasticamente..

%%}}}

%%{{{ Cantor's theorem: what it says and first steps 
\note O teorema de Cantor.
%%%{{{ meta 
%%%}}}

Cantor demonstrou que para todo conjunto $A$, seu powerset $\pset A$
tem cardinalidade estritamente maior que do $A$:
$$
A \ltc \pset A.
$$
Primeiramente observe que para conjuntos finitos já sabemos disso,
e é fácil demonstrar:
$$
\card {\pset A} = 2^{\card A} > \card A
$$
pois para todo $n\in\nats$, realmente temos $2^n > n$.
Cantor conseguiu demonstrar que $A \ltc \pset A$ para qualquer $A$.
Lembrando a definição de $\ltc$, precisamos demonstrar duas coisas:
$$
A \leqc \pset A
\qqqquad
A \neqc \pset A.
$$
A primeira é fácil: faça agora!

%%}}}

%%{{{ x: A_leqc_pset_A 
\exercise.
%%%{{{ meta 
\label A_leqc_pset_A
%%%}}}

Para todo conjunto $A$, $A \leqc \pset A$.

\hint
Seja $A$ conjunto e defina a $f : A \to \pset A$ pela
$$
f(x) = \set x.
$$
Demonstre que é injetora.

\solution
Seja $A$ conjunto.
Definimos a $f : a \injto \pset a$ pela
$$
f(x) = \set x.
$$
Facilmente ela é injetora (\ref[the_singletonizer_is_injective]).

%%}}}

%%{{{ proof idea with depressive members 
\note A linda idéia da sua demonstração.
%%%{{{ meta 
%%%}}}

Suponha que temos um conjunto $A$, e uma função $A \toby \pi \pset A$.
Vamos demonstrar que a $\pi$ não pode ser sobrejetora---e logo, nem bijetora.
Para entender a idéia melhor, vamos desenhar um exemplo.
Imagina então que o $A$ parece como no desenho abaixo,
e seu powerset tá no seu lado, onde eu desenhei apenas uns dos
seus membros, pois o desenho ficaria bagunçado demais se eu tivesse
desenhado todos.  Mas todos estão lá mesmo: o $\pset A$, pela sua definição,
é o conjunto de \emph{todos} os subconjuntos de $A$.
$$
\tikzpicture
\draw (0,0) to[out=180,in=90] (-1,-1) to[out=270,in=270] (1,-1) to[out=90,in=0] cycle;
\node at (0,-.2) {$\bullet$};
\node at (-.9,-.9) {$\ast$};
\node at (.9,-.9) {$\star$};
\endtikzpicture
$$
A $\pi$ então mapeia cada membro de $A$ com um membro de $\pset A$.
Por exemplo, pode ser assim:
$$
\mathrm{desenho com $\pi$ aqui}
$$
Vamos dar um toque antropomórfico agora:
vamos considerar os membros de $A$ como pessoas, e a $\pi$
como uma função de \emph{amor}, que mapeia cada $x\in A$
para o conjunto de todas as pessoas que $x$ ama:
$$
\pi (x) = \setstt {y \in A} {$x$ ama $y$}.
$$
Lembre-se que nosso objectivo é achar um membro de $\pset A$
que não pertence na imagem da $\pi$.
Chame \dterm{depressivo} um $x \in A$ sse $x$ não se ama.
Ou seja,
$$
\text{$x$ é depressivo}
\defiff
x \nin \pi(x)
$$
pois $\pi(x)$ são todas as pessoas que $x$ ama.\foot
Outros exemplos de definições razoáveis nessa interpretação
seriam chamar o $x$ \dterm{misántropo} se $\pi(x) = \emptyset$,
\dterm{egoista} se $\pi(x) = \set x$, etc.,
mas aqui só vamos precisar dos depressivos mesmo.
\toof
Assim, cada $x\in A$ ou é depressivo, ou não.
Condiseramos o conjunto $D$ de todos os depressivos membros de $A$:
$$
D
\defeq \setstt {x \in A} {$x$ é depressivo}
= \setst {x \in A} {x \nin \pi(x)}.
$$
Observe que $D \subset A$, ou seja, $D$ é um membro do $\pset A$.
Esse $D$ é o testemunha que estamos procurando:
um membro do codomínio da $\pi$, garantido para não pertencer
na imagem $\img \pi A$.
Por quê?
Para chegar num absurdo, suponha o contrário:
que para algum $d \in A$, temos $\pi(d) = D$.
Faz sentido agora perguntar:
\emph{esse $d$ é depressivo?}
Dois casos existem, e os dois chegam em absurdo:
\compute
\text{$d$ depressivo}
&\implies d \nin \pi(d)           \by {def.~depressivo} \\
&\implies d \nin D                \by {pela escolha de $d$} \\
&\implies \text{$d$ não depressivo} \by {def.~$D$} \\
&\implies \text{absurdo!}
\intertext{e no outro lado,}
\text{$d$ não depressivo}
&\implies d \in \pi(d)              \by {def.~depressivo} \\
&\implies d \in D                   \by {pela escolha de $d$} \\
&\implies \text{$d$ depressivo}     \by {def.~$D$} \\
&\implies \text{absurdo!}
\endcompute
Logo, para nenhum $d \in A$ temos $\pi(d) = D$,
ou seja, $D \nin \img \pi A$ e logo $\pi$ não é sobrejetora.
Em palavras antropomórficas, com essas definições
ninguém pode amar \emph{somente todos} os depressivos.
Note bem que em lugar nenhum usamos os desenhos do $A$
e da $\pi$ nessa demonstração.  Desenhei apenas para ilustrar.
Podemos então demonstrar formalmente o teorema de Cantor,
sem nada depressivo!

%%}}}

%%{{{ thm: cantor_theorem 
\theorem Cantor.
%%%{{{ meta 
\label cantor_theorem
\credits
    * Cantor : teorema de powerset
    ;;
\indexes
    * teorema!Cantor
    ;;
%%%}}}

Seja $A$ conjunto.
Então $A\ltc \pset A$.

\proof.
Seguindo a definição de $\ltc$, precisamos demonstrar duas coisas:
\crproofpart {{\proofname} de $A\leqc \pset A$:}
feita no \ref[A_leqc_pset_A]; um testemunha é a $\lam x {\set{x}}$,
que ``obviamente''~(\ref[the_singletonizer_is_injective]) é injetiva.
\crproofpart {{\proofname} de $A\neqc \pset A$.}
Basta demonstrar que não existe função sobrejetora de $A$ para $\pset A$.
Seja $\pi : A \to \pset A$.
Queremos demonstrar que a $\pi$ não pode ser sobrejetora, ou seja,
mostrar um elemento $C$ do seu codomínio que não pertence na imagem da $\pi$
(ou seja: tal que $C \nin \img \pi A$).
Observe que para qualquer $x\in A$, temos $\pi(x)\in\pset A$,
ou seja $\pi(x) \subset A$.
Considere o conjunto
$$
D = \setst {x\in A} {x \nin \pi(x)}.
$$
Pela definição de $D$, temos $D \subset A$.
Ou seja, $D \in \pset A$, que é o codomínio da $\pi$.
Precisamos demonstrar que para todo $x \in A$, $\pi(x) \neq D$.
Para chegar num absurdo, seja $d\in A$ tal que $\pi(d) = D$.
Agora nos perguntamos: $d\in\pi(d)$?
Como $\pi(d)=D$, a pergunta reduza em: $d\in D$?
Ambas as alternativas (\emph{sim} e \emph{não}) são impossíveis:
$$
d \in D
\iff
d \nin D
$$
pela definição de $D$ e pela escolha de $d$.
Absurdo!
Logo $\pi$ não mapeia nenhum membro de $A$ para o $D\in\pset A$,
ou seja, $\pi$ não é sobrejetora.

%%}}}

%%{{{ x: the_singletonizer_is_injective 
\exercise.
%%%{{{ meta 
\label the_singletonizer_is_injective
%%%}}}

Demonstre em detalhe que a função $\mapsio x {\set{x}}$ na demonstração
de~\ref[cantor_theorem] realmente é injetora.

\hint
O que significa que dois conjuntos são iguais?

%%}}}

%%{{{ cor: infinitely_many_infinities 
\corollary.
%%%{{{ meta 
\label infinitely_many_infinities
%%%}}}

Existe uma infinidade (contável) de cardinalidades infinitas:
$$
\nats
\ltc \pset\nats
\ltc \pset\pset\nats
\ltc \pset\pset\pset\nats
\ltc \pset\pset\pset\pset\nats
\ltc \dotsc
$$

%%}}}

%%{{{ cor: no_maximum_cardinality 
\corollary.
%%%{{{ meta 
%%%}}}

Não existe cardinalidade máxima:
para qualquer conjunto $M$, o conjunto $\pset M$ tem cardinalidade maior.

%%}}}

%%{{{ df: aleph_and_continuum 
\definition.
%%%{{{ meta 
\label aleph_and_continuum
\defines
    * \aleph_0  -- a cardinalidade do $\nats$
    * \continuum  -- a cardinalidade do $\pset\nats$ e do $\reals$
    * aleph 0
    * continuum
    ;;
%%%}}}

Denotamos a cardinalidade de $\nats$ por $\aleph_0$ (\dterm{aleph 0}),
e a cardinalidade de $\pset\nats\eqc\reals$ por $\continuum$.
Chamamos o $\continuum$ o \dterm{continuum}.

%%}}}

%%{{{ holes in the chain of cardinalities of powersets 
\note.
%%%{{{ meta 
%%%}}}

Considere os conjuntos
$$
\emptyset
\ltc \pset\emptyset
\ltc \pset\pset\emptyset
\ltc \pset\pset\pset\emptyset
\ltc \pset\pset\pset\pset\emptyset
\ltc \dotsb
$$
Observe que cada conjunto nessa seqüência (infinita) de conjuntos é finito.
Mas, quais são suas cardinalidades?
Calculamos:
$$
\align
\card{\emptyset}                     &= 0\\
\card{\pset\emptyset}                &= 1\\
\card{\pset\pset\emptyset}           &= 2\\
\card{\pset\pset\pset\emptyset}      &= 4\\
\card{\pset\pset\pset\pset\emptyset} &= 16\\
                                     &\eqvdots\\
\endalign
$$
Observamos que a seqüência dessas cardinalidades ``tem burácos''.
Por exemplo, nenhum desses conjuntos tem cardinalidade $3$,
mesmo que realmente tem conjuntos com essa cardinalidade
(por exemplo o $\finord 3=\set{0,1,2}$).
Ou seja, existe conjunto $C$ com
$$
\pset\pset\emptyset\ltc C\ltc \pset\pset\pset\emptyset.
$$
Similarmente achamos conjuntos ``estritamente entre'' os conjuntos que aparecem
depois nessa seqüência.

%%}}}

%%{{{ some questions arise 
\note.
%%%{{{ meta 
%%%}}}

Umas questões aparecem imediatamente:
% TODO: fix reflabs
\elist 1:
\li: Será que tem conjuntos ``estritamente entre'' alguns dos conjuntos
infinitos da seqüência anterior?
\li: Será que tem algum conjunto com cardinalidade maior que qualquer uma dessas
cardinalidades?
\li: Será que tem algum conjunto incomparável com todos eles?
\li: Até pior: tem conjuntos incomparáveis em cardinalidade?)
\endelist

%%}}}

\endsection
%%}}}

%%{{{ The smallest infinities 
\section As menores infinidades.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então.  Já sabemos que tem uma quantidade infinita de infinidades
diferentes graças ao teorema de Cantor.
Já encontramos as cardinalidades dos primeiros beths
$$
\beth_0 < \beth_1 < \beth_2 < \beth_3 < \dotsb
$$
que são os nomes das cardinalidades dos conjuntos
$$
\nats \ltc \pset\nats \ltc \pset\pset\nats \ltc \pset\pset\pset\nats \ltc \dotsb
$$

%%}}}

%%{{{ The equinumerosities so far 
\note As equinumerosidades até agora.
%%%{{{ meta 
%%%}}}

Temos então demonstrado as:
$$
\nats 
\eqc \ints
\eqc \rats
\eqc \algs
\eqc C\union C'
\eqc \Union_{n=0}^\infty {C_n}
\eqc C^n
\eqc \kstar C
$$
onde $C,C'$, etc.~denotam conjuntos contáveis.
E tambem temos:
$$
\gather
\Delta \eqc \cantorset \eqc \pset\nats \\
(\alpha,\beta) \eqc [\alpha,\beta) \eqc (\alpha,\beta] \eqc [\alpha,\beta] \eqc \reals.
\endgather
$$
onde $\alpha,\beta\in\reals\union\set{\minfty,\pinfty}$ tais que $\alpha<\beta$.
Como $\cantorset \subset [0,1]$ concluimos que
$$
\Delta \eqc \cantorset \eqc \pset\nats \leqc
(a,b) \eqc [a,b) \eqc (a,b] \eqc [a,b] \eqc (0,1) \eqc \reals.
$$

%%}}}

\endsection
%%}}}

%%{{{ Two big hypotheses 
\section Duas grandes hipoteses.
%%%{{{ meta 
\label Two_big_hypotheses
%%%}}}

%%{{{ Cardinal comparability hypothesis 
\note A hipótese da comparabilidade de cardinais.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ CCH 
\hypothesis.
%%%{{{ meta 
\label CCH
%%%}}}

Para todo conjunto $A,B$, $A \leqc B$ ou $B \leqc A$.

%%}}}

%%{{{ The continuum hypothesis 
\note A hipótese do continuum.
%%%{{{ meta 
\credits
    * Godel : CH
    * Cohen : CH
    * Cantor : CH
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ CH 
\hypothesis CH.
%%%{{{ meta 
\label CH
%%%}}}

Não existe subconjunto de reais com cardinalidade estritamente
entre as cardinalidades de $\nats$ e de $\reals$:
$$
\lforall {X \subset \reals} {X \leqc \nats \lor X \eqc \reals}.
$$

%%}}}

%%{{{ GCH 
\hypothesis GCH.
%%%{{{ meta 
\label GHC
%%%}}}

Para todo conjunto infinito $A$, não existe conjunto com cardinalidade
estritamente entre as cardinalidades de $A$ e de $\pset A$.
$$
\lforall {A} {\text{$A$ infinite} \implies \lforall {X \subset \pset A} {X \leqc A \lor X \eqc \pset A}}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Transfinite_numbers 
\section Os números transfinitos.
%%%{{{ meta 
\label Transfinite_numbers
%%%}}}

%%{{{ ordinals_vs_cardinals 
\note Ordinais \vs cardinais.
%%%{{{ meta 
\label ordinals_vs_cardinals
%%%}}}

Na língua natural temos os números \dterm{cardinais}
\quotepar
um, dois, três, quatro, cinco, \dots
\endquote
e os números \dterm{ordinais}
\quotepar
primeiro, segundo, terceiro, quarto, quinto, \dots
\endquote
{\Cantor}Cantor generalizou esses números finitos para os casos finitos,
que chamou de \dterm{números transfinitos} (veja \cite[cantortransfinite]).
Os cardinais representam \emph{quantidades} e os ordinais \emph{ordens}.
Abusando pouco a lingua, podemos dizer que o cardinal dum conjuno $A$
mostra \emph{quantos membros ele tem}, e o ordinal dum conjunto ordenado
$\ssetfont B$ \emph{mostra quão longo ele é}.

%%}}}

%%{{{ Transfinite arithmetic 
\note Aritmética transfinita.
%%%{{{ meta 
\credits
    * Cantor : aritmética transfinita
    ;;
%%%}}}

Bem mais que isso, Cantor conseguiu definir e elaborar uma
\dterm{aritmética transfinita:}
definiu operações de adição, multiplicação, e exponenciação
nesses números e sua aritmética realmente---além de ser
linda---é muito útil e interessante.
Neste capítulo não vamos nos preocupar com isso---paciência até
o~\reffull[Set_theory]
(\reffull[The_cardinals] e~\reffull[The_ordinals]).

%%}}}

\endsection
%%}}}

%%{{{ A taste of measure theory 
\section Um toque de teoria da medida.
%%%{{{ meta 
%%%}}}

%%{{{ from sets to new theories 
\note.
%%%{{{ meta 
%%%}}}

Assim que {\Cantor}Cantor, {\Dedekind}Dedekind, e seus seguidores
desenvolveram essa primeira teoria de conjuntos, os matemáticos
da época ganharam uma ferramenta poderosa e útil que nos liberou
e guiou para desenvolvemento de bem mais teorias interessantes, como:
\emph{teoria de espaços métricos}, \emph{topologia geral},
e \emph{teoria da medida}.
Nesse texto vamos dedicar um capítulo para a primeira (\ref[Metric_spaces])
e um para a segunda (\ref[Topology]),
e apenas uma secção (esta!)~para a terceira.

%%}}}

%%{{{ measure theory 
\note.
%%%{{{ meta 
%%%}}}

Vários matemáticos, principalmente {\Borel}Borel, {\Baire}Baire,
{\Lebesgue}Lebesgue, {\Frechet}Frechét, {\Hausdorff}Hausdorff,
desenvolveram a teoria da medida.
Podemos pensar em medida como uma generalização do comprimento dum intervalo
$(a,b)$ de reais, em tal jeito que podemos atribuir um ``comprimento''
(ou seja, \dterm{medir}) conjuntos bem mais complicados que intervalos,
e equivalentemente para dimensões maiores, generalizando assim as idéias
de área, volume, etc.
Isso nos leva para uma \emph{teoria de integração} bem mais poderosa que
a primeira que encontramos (integral {\Riemann}Riemann), e também serve
como base para fundar a \emph{teoria de probabilidade}, graças ao
{\Kolmogorov}Kolmogorov (\yearof{1933}, \cite[kolmogorovprob]).
Nosso interesse aquí tem a ver com probabilidade mesmo, pois queremos
responder na pergunta seguinte.

%%}}}

%%{{{ Q: pick a random number from [0,1]; what is the probablity that... 
\question.
%%%{{{ meta 
%%%}}}

Escolhemos \emph{aleatoriamente} um número real $r\in[0,1]$.
Qual a probabilidade de $r$ ser\dots
(i) o número $1/2$?
(ii) um número real no $(a,b)$ com $0\leq a<b \leq 1$?
(iii) um número racional?
(iv) um número algébrico?

%%}}}

%%{{{ warning: tends_to_warning 
\warning <<Tende ao>>.
%%%{{{ meta 
\label tends_to_warning
%%%}}}

É um erro comum afirmar certas coisas sobre probabilidades,
números, funções, limites, etc., especialmente usando frases
como a \emph{<<tende ao>>}, então vou deixar certas coisas claras
aqui antes de começar nosso pequeno estudo.
\eop
{(1)}
A probabilidade dum evento especifico acontecer, se é definida,
é um número real no $[0,1]$.
E números não mexem.
Números não tendem a lugar nenhum.
Números ficam quetinhos nos seus lugares.
\eop
{(2)}
O limite duma função também não tende a lugar nenhum.
Se é definido, é apenas um número real;
talvez \emph{estendido} para incluir os $\pminfty$~(\ref[extended_reals]).
Por exemplo, temos
$$
\lim_{x\to\pinfty} 1/x = 0.
$$
Tá vendo essa igualdade aí?
Esse limite \emph{é} o número zero.
O limite \emph{não tende ao} zero.
O limite \emph{é o próprio} zero!
Podemos sim dizer (corretamente) que
\emph{$1/x$ tende ao $0$ quando $x$ tende ao $\pinfty$}.

%%}}}

\endsection
%%}}}

%%{{{ Consequences in computability and definability 
\section Conseqüências em computabilidade e definabilidade.
%%%{{{ meta 
%%%}}}

%%{{{ Aristos vs Blammenos 
\note Áristos vs Blammenos.
%%%{{{ meta 
\label Aristos_vs_Blammenos
%%%}}}

\eop\noi
\centerline{\scshape Cena 1.}
\centerline{\it Segunda-feira, madrugada.}
\centerline{\it Dois amigos, Áristos e Blammenos,}
\centerline{\it estão estudando para a prova de Fundamentos Matemáticos.}
\centerline{\it Eles estão tentando resolver o problema seguinte:}
\standout
\emph{<<O conjunto $P$ de todos os programas de tipo
$\Nat\to\Nat$ é contável?>>}
\endstandout
\dialogue
\who Áristos:
O conjunto $P$ é contável, e aqui minha demonstração:
o conjunto $S$ de todos os strings feitos por um alfabeto finíto
é contável, e todos os programas possíveis correspondem em apenas
um subconjunto próprio de $S$ (pois todo programa é um string,
mas tem strings que não são programas).
Logo, o $P$ é contável.
\who Blammenos:
Então tu tá afirmando que existe enumeração do $P$?
Eu vou chegar num absurdo com essa hipótese.
Suponha $p_0, p_1, p_2, \dotsc$ uma enumeração de $P$.
Eu defino o programa $p_*$ com o algoritmo bem simples:
$$
p_*(n) = p_n(n) + 1.
$$
Agora temos $p_* \nin P$, pois para todo $n\in\nats$, $p_* \neq p_n$.
\who Á:
Por quê?
\who B:
Seja $n\in\nats$.
Eu vou lhe mostrar que $p_* \neq p_n$.
Calculamos
\compute
p_*(n)
&= p_n(n) + 1   \by {pela def.~$p_*$} \\
&\neq p_n(n)
\endcompute
que mostra que $p_* \neq p_n$.
Ou seja, $p_*$ não é nenhum dos $p_0, p_1, \dotsc$
que a gente supôs que esses são todos os membros do $P$.
Cheguei assim num absurdo, logo $P$ é incontáv---
\who Á:
Peraí, tu tá roubando!
Como teu programa usou essa enumeração $p_0, p_1, \dotsc$?
Se tu tivesse um algoritmo (programa) que gera essa
seqüência, tu teria razão.
\who B:
Hmmm\dots\ \ 
Mas é fácil programar esse algoritmo!
Concordas que podemos gerar facilmente todos os strings no $S$?
\who Á:
Sim, esse programa que gera os strings, a gente já encontrou na aula.
\who B:
Bem, então meu algoritmo é o seguinte:
gere todos os strings $s_0, s_1, s_2, \dotsc \in S$,
mas para cada string que não é um programa, pula para o próximo.
Esse programa gera sim a seqüência $p_0, p_1, p_2, \dotsc$
de todos os programas!
\who Á:
Pqp, faz sentido!
Não consigo achar um erro na tua demonstração, mas nem na minha!
\who B:
Eu também não consigo achar um erro na tua demonstração!
\enddialogue

%%}}}

%%{{{ Q: Who is right? 
\question.
%%%{{{ meta 
%%%}}}

Um conjunto não pode ser contável e incontável,
então pelo menos um dos dois alunos tá errado.
Quais são o(s) erro(s)?
Seguindo as suas idéias o que podemos concluir mesmo?

%%}}}

\spoiler

%%{{{ A 
\blah Resposta.
%%%{{{ meta 
%%%}}}

O Blammenos tá errado.
O problema é que seu programa em algum momento tem que decidir se um string aleatório é um programa válido, e ainda mais, se termina ou não para alguma dada entrada.
Também não podemos chamar a
$$
p_*(n) \neq p_n(n)
$$
verdadeira para todo $n \is \Nat$,
pois existe a possibilidade de algum programa não terminar.
Nesse caso os dois lados são $\bot$ (``bottom'').
Podemos então concluir que é impossível criar tal programa!

%%}}}

\TODO Quantos programas?.

\TODO Quantas funções?.

\TODO Gödel numbers e lista de todos os programas.

\endsection
%%}}}

%%{{{ Problems in Cantor's paradise: Russell's paradox 
\section Problemas no paraíso de Cantor: o paradoxo de Russell.
%%%{{{ meta 
%%%}}}

%%{{{ Russell's paradox 
\note O paradoxo de Russell.
%%%{{{ meta 
\label russells_paradox
\defines
    * paradoxo!de Russell
    ;;
%%%}}}

Russell\Russell[paradoxo], no ano \yearof{1902},
observou que o conjunto
$$
\Univ \defeq \setstt x {$x$ é conjunto}
$$
tem uma peculiaridade, uma propriedade estranha:
\emph{ele pertence nele mesmo}, ou seja, $\Univ\in \Univ$.
Os conjuntos que encontramos em matemática normalmente não têm essa
propriedade: $\aR\nats\nin\aB\nats$,
pois o $\aR\nats$ não é um número natural!
Similarmente $\set{0,1,\set{1,2}}\nin\set{0,1,\set{1,2}}$, pois
$\set{0,1,\set{1,2}} \neq 0$,
$\set{0,1,\set{1,2}} \neq 1$, e
$\set{0,1,\set{1,2}} \neq \set{1,2}$.
Também $\aR\emptyset \nin \aB\emptyset$ pois nada pertence ao $\aB\emptyset$.
Tudo bem, nenhum problema com isso, mas faz sentido definir o conjunto de
todos os conjuntos ``tranqüilos'', ou seja, aqueles que não têm essa
propriedade estranha de pertencer neles mesmo.
Russell definiu então o conjunto seguinte:
$$
\align
R &\defeq \setstt x {$x$ é conjunto~\andword~$x$ é tranqüilo} \\
  &=      \setstt x {$x$ é conjunto~\andword~$x\nin x$}.
\endalign
$$
E se perguntou:
\emph{o conjunto $R$ é tranqüilo, ou tem essa propriedade estranha?}
Consideramos os dois casos:
Se $\aR R\in \aB R$ então pela definição de $\aB R$
temos que $\aR R$ é tranquilo, ou seja, $\aR R \nin \aR R$,
então esse caso é impossível.
Se $\aR R\nin \aB R$ então $\aR R$ não pertence nele mesmo
(ou seja, $\aR R$ é tranqüilo) e logo pela definição de $\aB R$
temos $\aR R \in \aB R$;
e assim esse caso também é impossível!
Sem muitas palavras:
\compute
\aR R\in {\aB R}
&\implies \text{$\aR R$ tranqüilo}     \by {def.~$\aB R$} \\
&\implies \aR R \nin \aR R           \by {def.~$\aR R$ tranqüilo} \\
\aR R\nin \aB R
&\implies \text{$\aR R$ não tranqüilo} \by {def.~$\aB R$} \\
&\implies \aR R \in \aR R              \by {def.~$\aR R$ tranqüilo} \\
\endcompute
Ou seja, concluimos que:
$$
R \in R \iff R \nin R
$$
e naturalmente queremos escrever um grande \emph{``absurdo''} neste momento,
mas\dots{}
De onde chegamos nesse absurdo?
Todas as vezes que chegamos num absurdo até agora, foi tentando demonstrar algo:
\emph{supondo uma hipótese $H$}, chegamos num absurdo, então concluimos que
sua negação $\lnot H$ é verdadeira, ou vice-versa, usando o ``reductio ad absurdum'',
querendo demonstrar que a $H$ é verdadeira supomos sua negação $\lnot H$,
achamos um absurdo e concluimos que nossa suposição não pode ser correta,
logo $H$.
Mas aqui não começamos supondo algo aleatoriamente.
Qual vai ser nossa conclusão agora?
Parece que chegamos num absurdo apenas com lógica sem supor nada ``extra''.
Será que lógica ou matemática é quebrada?

%%}}}

%%{{{ General Comprehension Principle 
\principle Comprehensão geral.
%%%{{{ meta 
\label general_comprehension_principle
%%%}}}

Seja $P(\dhole)$ uma condição definitiva.
Existe um conjunto
$$
\setst x {P(x)}
$$
cujos membros são exatamente todos os objetos $x$
que satisfazem a condição: $P(x)$.

%%}}}

%%{{{ cor: The general comprehension principle is invalid 
\corollary Russell.
%%%{{{ meta 
%%%}}}

O princípio da comprehensão geral não é válido.

\proof.
Supondo que é, chegamos no absurdo que achamos no~\reftag[russells_paradox].

%%}}}

%%{{{ the general Russell paradox 
\remark O paradoxo de Russell geral.
%%%{{{ meta 
%%%}}}

O paradoxo de Russell que encontramos fala de conjuntos e de pertencer,
mas facilmente identificamos que seu paradoxo é apenas um caso duma
verdade mais geral.
Considere uma relação $R$.
A fórmula
$$
\lnot
\exists x
\forall y
\paren{ R(x,y) \liff \lnot R(y,y) }
$$
é um tautologia; um teorema da FOL.
Suponha que tal $x$ existe, e o chame de $x_0$.
Como $R(x_0, y) \liff \lnot R(y,y)$ para todos os $y$, então
tomando $y \asseq x_0$ chegamos na contradição
$$
R(x_0,x_0) \liff \lnot R(x_0,x_0).
$$
Observe que tomando como $R$ a relação $\in$ e como universo
o universo matemático comum, chegamos no paradoxo de Russell.

%%}}}

\endsection
%%}}}

%%{{{ Russell's and Zermelo's solutions 
\section As soluções de Russell e de Zermelo.
%%%{{{ meta 
%%%}}}

%%{{{ theory of types 
\note Teoria dos tipos (Russell).
%%%{{{ meta 
\credits
    * Russell : teoria dos tipos
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ axiomatic set theory 
\note Teoria axiomática dos conjuntos (Zermelo).
%%%{{{ meta 
\credits
    * Zermelo : teoria axiomática dos conjuntos
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ credits 
\note Créditos.
%%%{{{ meta 
\credits
    * Zermelo    : teoria dos conjuntos
    * Fraenkel   : teoria dos conjuntos
    * Mirimanoff : teoria dos conjuntos
    * Skolem     : teoria dos conjuntos
    * vonNeumann : teoria dos conjuntos
    ;;
%%%}}}

A teoria axiomática de conjuntos que estudamos neste capítulo é conhecida
como ``Zermelo--Fraenkel set theory''.
Mesmo assim, mais foram envolvidos na sua evolução, sua definição, e seu
amadurecimento, como os Mirimanoff, Skolem,
e von~Neumann, entre outros.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: a_letter_from_cantor_to_dedekind 
\problem Uma carta de Cantor para Dedekind.
%%%{{{ meta 
\label a_letter_from_cantor_to_dedekind
\credits
    * Cantor
    * Dedekind
    ;;
%%%}}}

\emph{Dia 20 de junho, 1877.}
Cantor manda uma carta para Dedekind onde
ele defina a função $f : [0,1]^2 \to [0,1]$ pela
$$
f(a, b)
= 0.a_1b_1a_2b_2a_3b_3\dotsc
\qtext{onde}
\leftbrace {
\aligned
a &\eqass 0.a_1a_2a_3\dotsc\\
b &\eqass 0.b_1b_2b_3\dotsc
\endaligned
}
$$
são as expansões decimais \emph{que não terminam em 0's repetidos},
exceto para o proprio $0$ que só tem essa representação mesmo.\foot
Na verdade esta definição é um caso especial da definição
de Cantor; sua função foi do ``cubo $n$-dimensional'' para
o $[0,1]$.
\toof
Afirmando que ela é bijetora ele ficou surpreso que 
tinha conseguido demonstrar que $[0,1]^2 \eqc [0,1]$.
Ansioso, está esperando a resposta de Dedekind.
\eop
\emph{Dia 22 de junho, \yearof{1877}.}
Cantor recebe a carta-resposta:\foot
sim, foi tão rapido; e sim, foi pelos correios mesmo!
\toof
Dedekind percebeu um erro na demonstração!
\eop
\emph{Dia hoje.}
Tendo lido tudo isso, tu respondes nas perguntas seguintes:
(1) Por que Cantor botou a restricção <<que não terminam em $0$'s repetidos>>?
(2) Qual o erro de Cantor?\foot
Cantor, corrigiu sua demonstração e mandou numa nova carta-resposta,
onde também incluiu sua demonstração que $(0,1] \eqc [0,1]$
(\ref[change_of_ends_of_intervals_without_bernstein]).
Dedekind essa vez não respondeu tão rápidamente, e Cantor
mandou um lembrete com a frase
\emph{je le vois, mais je ne le crois pas}
referindo à sua descoberta.
Ele escreveu essa frase em francês mesmo, mesmo que
a comunicação entre eles foi em alemão.
Traduzindo: \dq{eu o vejo, mas eu não o acredito}.
\toof

\hint
(1) Precisamos disso para que $f$ seja bem-definida (por quê?).
(2) A $f$ não é bijetora!  (Por quê?)

\solution
(1) Precisamos disso para que $f$ seja bem-definida.
Sem essa restricção, para onde $f$ manda o $\tup{1/2,1/3}$?
O $1/3$ realmente \emph{determina} os $b_j$'s, mas o $1/2$
não determina os $a_i$'s pois:
$$
0.4999\dots = 1/2 = 0.5000\dots
$$
e logo a $f$ não seria bem-definida sem essa restricção,
já que seu valor dependeria (e mudaria) dependendo dessa escolha.
\eop\noi
(2) A $f$ não é bijetora!
Basta só criar um exemplo que sua preimagem precisaria dum
número cuja expansão termina em $000\dots$:
$$
f( ? ) = 0.5303030303\dots
$$
Nenhuma entrada $(a,b)$ pode ser mapeada nesse número, pois pela
definição da $f$ o $b$ só pode ser o $0.333\dots = 1/3$
(e nenhum problema com isso), e agora o $a$ só pode ser ser o $0.5000\dots$,
ou seja, $a=1/2=0.5000\dots=0.4999\dots$.
Calculamos
$$
f(\frac 1 2,\frac 1 3) = 0.43939393 \neq 0.530303\dots
$$
e logo $f$ não é sobrejetora!

%%}}}

%%{{{ prob: change_of_ends_of_intervals_without_bernstein 
\problem Sem Bernstein.
%%%{{{ meta 
\label change_of_ends_of_intervals_without_bernstein
%%%}}}

Mostre pela definição a equinumerosidade
$$
(a,b) \eqc [a,b) \eqc [a,b];
$$
onde $a,b \in \reals$ e tais que os intervalos não são
nem vazios nem singletons.

\hint
Aqui duas maneiras diferentes para o $(a,b) \eqc [a,b)$:
(i) demonstre $[0,\pinfty) \eqc (\minfty,\pinfty)$;
(ii) demonstre $(0,1] \eqc (0,1)$.

\hint
Seguindo a idéia (i) da primeira dica:
lembre como demonstramos que $\nats\eqc\ints$;
e seguindo a idéia (ii):
faz sentido mandar o $1$ para o $1/2$; e o $1/2$?

\hint
Seguindo a idéia (i):
$\reals = \Union_n [n,n+1)$.
Seguindo a idéia (ii):
defina uma função $f : (0,1] \eqc (0,1)$ por casos:
$$
f(x) =
\knuthcases {
\askhole & se \asklhole \cr
\askhole & caso contrário
}
$$
tal que
$$
\align
1    &\mapstoby f 1/2 \\
1/2  &\mapstoby f \askhole \\
     &\eqvdots \\
\askhole  &\mapstoby f \askhole
\endalign
$$

%%}}}

%%{{{ prob: reals_eqc_irrats_without_bernstein 
\problem Ainda sem Bernstein.
%%%{{{ meta 
\label reals_eqc_irrats_without_bernstein
\credits
    * Cantor
    ;;
%%%}}}

Cantor demonstrou direitamente (pela sua definição) que
$$
[0,1] \eqc [0,1]\setminus\rats.
$$
Faça o mesmo.

\hint
Já sabemos que o $\rats$ é contável; logo o $\rats\inter[0,1] \subset \rats$
também é.
Seja $\seqn q n$ uma enumeração dos racionais do $[0,1]$.

\hint
Agora defina uma seqüência $\seqn \eta n$
de irracionais no $[0,1]$ distintos dois a dois.
Tente ser específico, mas não importa qual tu vai escolher.

\hint
Cantor usou a seqüência de irracionais $\seqn \eta n$ definida pela
$\eta_n = \sqrt 2 / 2^{n+1}$.
Outra escolha seria a $\frac 1 {n + \sqrt 2}$.
(Verifique que todos os membros de ambas as seqüências são irracionais.)

\hint
Defina a $f : [0,1] \to [0,1]\setminus\rats$ mandando
cada $x \in [0,1]$ nele mesmo, exceto os membros das
$\seqnset q n$ e $\seqnset \eta n$.
Fazer o que com eles?

%%}}}

%%{{{ prob: sime_simo_eqclass_card 
\problem.
%%%{{{ meta 
\label sime_simo_eqclass_card
\pdefs
    \pdef sime {\rel{\stackrel{{}_{\mathrmsmall e}}=}}
    \pdef simo {\rel{\stackrel{{}_{\mathrmsmall o}}=}}
    ;;
%%%}}}

No $(\nats\to\nats)$ sejam as relações $\sime$ e $\simo$ como no~\ref[simz_sime_simo_simi]:
$$
\align
f\sime g&\defiff f(2n)   = g(2n)  \ \text{para todo $n\in\nats$}\\
f\simo g&\defiff f(2k+1) = g(2k+1)\ \text{para todo $k\in\nats$}.
\endalign
$$
Qual é a cardinalidade do $\eqclass f {\sime} \inter \eqclass f {\simo}$?

%%}}}

%%{{{ prob: define three eqrels such that quosets have certain cards 
\problem.
%%%{{{ meta 
%%%}}}

No conjunto dos reais $\reals$, defina três relações de equivalência
$\sim_1$, $\sim_2$, $\sim_3$, diferentes da igualdade $\eqof \reals$,
da vazia, e da trivial $\mathsf{True}$, tais que:
$$
\xalignat3
\quoset \reals {\sim_1} &\ltc \nats &
\quoset \reals {\sim_2} &\eqc \nats &
\quoset \reals {\sim_3} &\gtc \nats.
\endxalignat
$$
Para cada uma, descreva seu conjunto quociente.

\hint
Cada relação de equivalência corresponde numa partição e vice-versa,
então basta definir três partições.

\solution
Cada relação de equivalência corresponde numa partição e vice-versa,
então descrevemos as três partições diretamente:
$$
\align
\scr C_1 &= \set   {(\minfty,0), \set{0}, (0,\pinfty)} \\
\scr C_2 &= \setst {[n,n+1)} {n\in\ints} \\
\scr C_3 &= \setst {\set{a}} {a\in\reals\setminus\rats} \union \set{\rats}.
\endalign
$$
Sem usar partições poderiamos definir as relações diretamente assim:
$$
\align
x \sim_1 y &\defiff \text{$x=y$ ou $xy>0$} \\
x \sim_2 y &\defiff \floor x = \floor y \\
x \sim_3 y &\defiff \text{$x = y$ ou $x,y\in\rats$}.
\endalign
$$

%%}}}

%%{{{ codeit: RatApprox 
\codeit RatApprox.
%%%{{{ meta 
\label RatApprox
%%%}}}

Usando uma implementação de enumeração $\set{q_n}_n$ do $\rats$
(com ou sem repetições), implemente uma função
$a : \reals\times\reals \to \nats$ que, dados $x\in\reals$ e $\epsilon>0$
retorna o primeiro $n\in\nats$ com a propriedade $\abs{q_n - x} < \epsilon$:
$$
a(x,\epsilon) = \min\setst{n\in\nats}{\abs{q_n-x}<\epsilon}.
$$
\eop
Se tua linguagem de programação suporta funções de ordem superior,
considere que seu primeiro argumento deve ser a própria enumeração $q$:
\mathcol
\namedfun{ratApprox} &\eqtype (\nats\to\rats) \to \reals \to \reals \to \nats \\
\namedfun{ratApprox} \fa q \fa x \fa \epsilon &= \min \setst {n\in\nats} {\abs{q_n-x}<\epsilon}
\endmathcol
Alternativamente, pode representar uma enumeração de racionais
como uma lista (infinita) de racionais.  Considere retornar o
primeiro racional suficientemente próximo além de apenas seu
índice.  Improvise e teste sua função, vendo quanto ``demora''
uma enumeração para chegar suficientemente perto de um número
pre-determinado, sendo racional ou não.
Por exemplo, use $x=\sqrt 2$ ou $e$ ou $\pi$,
e
$\epsilon=1, 1/2, 1/4, \dotsc$.
Assim, para qualquer real $x$, tu pode
\emph{construir}---mesmo não muito ``eficientemente''---uma
seqüência de racionais que converge em $x$, apenas aplicando a função
$\lam \epsilon {\namedfun{ratApprox} \fa q \fa x \fa \epsilon}$
em argumentos que formam qualquer seqüência que convirja no zero!

%%}}}

%%{{{ df: terminating_game 
\definition Jogo terminante.
%%%{{{ meta 
\label terminating_game
\defines
    * jogo!terminante
    ;;
%%%}}}

Consideramos jogos entre 2 jogadores.
Chamamos um jogo \dterm{terminante} sse não tem partidas infinitas.
Ou seja, seguindo suas regras cada partida termina depois um finíto número de turnos.

%%}}}

%%{{{ df: hypergame 
\definition Hypergame (Zwicker).
%%%{{{ meta 
\label hypergame
\defines
    * hypergame
    ;;
%%%}}}

{\Zwicker[hypergame]}%
Considere o jogo seguinte $\cal H$, chamado \dterm{hypergame}:
O $\cal H$ começa com o {\scshape Player~I} que escolha um jogo terminante $G$.
O {\scshape Player~II} começa jogar o jogo $G$ contra o {\scshape Player~I}.
Quem ganha nesse jogo $G$ é o vencedor do jogo $\cal H$.

%%}}}

%%{{{ eg: hypergame_plays 
\example.
%%%{{{ meta 
\label hypergame_plays
%%%}}}

Por exemplo, sendo um bom jogador de ``jogo da velha'' e um pessimo jogador
de xadrez, se eu for o {\scshape Player~I} num hypergame, meu primeiro
movimento seria escolher o jogo terminante ``jogo da velha'' para jogar.
Meu oponente, se for o {\scshape Player~I} duma partida de hypergame,
seu primeiro movimento seria escolher o jogo terminante ``xadrez''.
Depois desse movimento eu viro o {\scshape Player~I} no xadrez.
Quem vai ganhar nesse xadrez, vai ser o vencedor dessa partida de hypergame.

%%}}}

%%{{{ hypergame_paradox 
\note O paradoxo de hypergame.
%%%{{{ meta 
\label hypergame_paradox
\pdefs
    \pdef O {\text{\tt O}}
    \pdef P {\text{\tt P}}
    ;;
%%%}}}

Zwicker{\Zwicker[hypergame]} percebeu o seguinte paradoxo, se perguntando
se o próprio Hypergame é um jogo terminante ou não.
Claramente tem que ser, pois a primeira regra do jogo obriga o {\scshape Player~I}
escolher um jogo terminante.  Logo, depois de $n\in\nats$ turnos, esse jogo
termina, e junto com ele termina a partida do hypergame (em $n+1$ turnos).
Então hypergame é terminante.
Logo, numa partida de hypergame, o {\scshape Player~I} pode escolher o próprio
hypergame.  Assim começamos uma sub-partida de hypergame, onde o
{\scshape Player~II} toma o papel de {\scshape Player~I}.
Se ele escolher, por exemplo, ``jogo de velha'', a partida parece assim:
$$
\def\drawTTTboard{%
\draw (-1, 3)     -- (-1,-3);
\draw ( 1, 3)     -- ( 1,-3);
\draw (-3, 1)     -- ( 3, 1);
\draw (-3,-1)     -- ( 3,-1);
}
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Jogo de velha''}\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- (0.7, 0.7);
\draw (-0.7, 0.7) -- (0.7,-0.7);
\endtikzpicture
\endgathered\\
\phantom{\P}\vdots\quad&\vdots\\
\O:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
\endtikzpicture
\endgathered\\
\P:\quad&
\gathered
\tikzpicture[scale=0.15]
\drawTTTboard
% X-moves
\draw (-0.7,-0.7) -- ( 0.7, 0.7);
\draw (-0.7, 0.7) -- ( 0.7,-0.7);
\draw (-2.7,-0.7) -- (-1.3, 0.7);
\draw (-2.7, 0.7) -- (-1.3,-0.7);
\draw ( 1.3,-0.7) -- ( 2.7, 0.7);
\draw ( 1.3, 0.7) -- ( 2.7,-0.7);
% O-moves
\draw (2,2)  circle (0.7);
\draw (0,-2) circle (0.7);
% draw winning line
\draw (-2.7, 0.0) -- ( 2.7, 0.0);
\endtikzpicture
\endgathered\\
\endalign
$$
Onde denotamos os dois jogadores com $\P$ e $\O$ (de ``Player'' e ``Opponent'').
Mas, agora a partida seguinte é possível:
$$
\align
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\P:\quad& \hbox{Escolho ``Hypergame''}\\
\O:\quad& \hbox{Escolho ``Hypergame''}\\
\phantom{\P}\vdots\quad&\vdots
\endalign
$$
e achamos uma partida infinita do hypergame!
Logo o hypergame não é terminante.

%%}}}

%%{{{ prob: from_hypergame_to_cantors_theorem 
\problem.
%%%{{{ meta 
\label from_hypergame_to_cantors_theorem
%%%}}}

Seja conjunto $A$ e suponha que existe injecção $\phi : A \injto \pset A$.
Para todo $x\in A$, denota com $A_x$ o $\phi(x)$, ou seja, $A_x$
é o subconjunto de $A$ associado com o $x$.
Seja $a\in A$.  Chame um \dterm{caminho} de $a$ qualquer seqüência
finita ou infinita $\set{a_i}_i$ de elementos de $A$ que satisfaz:
$$
\align
a_0     &= a\\
a_{n+1} &\in A_{a_n}.
\endalign
$$
Finalmente, chame um $a\in A$ \dterm{terminante} se todos os caminhos
de $a$ são finítos.  Use o paradoxo do Hypergame para demonstrar que
a $\phi$ não pode ser sobrejetora, achando assim uma nova demonstração
do teorema de Cantor~\reftag[cantor_theorem].

\hint
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta demonstrar que $T\nin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, demonstrando assim que $\phi$ não é bijetora.

\hint
Suponha para chegar num absurdo que $T=A_a$ para algum $a\in A$.

\hint
$T = \emptyset$?

\solution
Seja $T \subset A$ o conjunto de todos os terminantes elementos de $A$.
Basta demonstrar que $T\nin \img \phi A$, ou seja, que para todo $x\in A$,
$A_x \neq T$, demonstrando assim que $\phi$ não é bijetora.
Suponha para chegar num absurdo que $T\in \img\phi A$ e logo seja
$a \in A$ tal que $T=A_a$\fact1.
Observe que $T\neq\emptyset$, pois se fosse vazio o $a$ seria terminante
e logo pertenceria ao $T$; absurdo.
Vamos demonstrar que qualquer caminho de $a$ é terminante.
Seja $\alpha$ um caminho de $a$:
$$
\alpha = \paren{\alpha_0, \alpha_1, \alpha_2, \dotsc}
$$
Logo $\alpha_1 \in A_{\alpha_0} = A_a = T$,
ou seja $\alpha_1$ é terminante,
e logo o caminho $\paren{\alpha_1, \alpha_2, \dotsc}$ é finito!
Logo o $\paren{\alpha_0,\alpha_1,\alpha_2,\dotsc}$ também é.
Mostramos então que o arbitrário caminho de $a$ é finito;
ou seja, todos são; ou seja, $a$ é terminante\fact2~e logo
$a \in T$\fact3.
Mas aqui um caminho infinito de $a$:
$$
\align
a_0 &\asseq a \\
a_1 &\asseq a \\
a_2 &\asseq a \\
a_3 &\asseq a \\
    &\eqvdots
\endalign
$$
ou seja, o caminho seguinte:
$$
\paren{a,a,a,\dotsc}
$$
Isso realmente é um caminho de $a$ pois pelos~\byfact1~e~\byfact3,
$a \in A_a$ e logo substituindo iguais por iguais,
$$
\mubrace {a_{n+1}} {a} \in A_{\mubrace {a_n} {a}}.
$$
Concluimos então que $a$ não é terminante, contradizendo o~\byfact2.
Chegamos assim num absurdo, e logo nossa hipótese que
$T \in \img \phi A$ não é válida, ou seja, $T \nin \img \phi A$
e logo $\phi$ não é sobrejetora.

%%}}}

%%{{{ prob: weird_convex_now_easy 
\problem Agora é fácil.
%%%{{{ meta 
\label weird_convex_now_easy
%%%}}}

Para resolver o~\ref[weird_convex_hard] demonstramos um certo
``buraco'' que o $Q_1$ tem: o $(0,0)$.
Tem outro(s)?  Quantos?

\hint
Considere a diámetro horizontal $\setst {(x,0)} {-1 < x < 1}$.

%%}}}

%%{{{ thm: von_Lindemann_theorem 
\theorem von Lindemann.
%%%{{{ meta 
\label von_Lindemann_theorem
\credits
    * vonLindemann
    ;;
%%%}}}

Para todo $\alpha\neq0$ algébrico, $e^\alpha$ é transcendental.

%%}}}

%%{{{ prob: pi_is_transcendental 
\problem.
%%%{{{ meta 
\label pi_is_transcendental
\credits
    * vonLindemann
    ;;
%%%}}}

Dado o teorema de von~Lindemann \reftag[von_Lindemann_theorem]
demonstre que $\pi$ é transcendental.

\hint
Se $\pi$ fosse algébrico, $i\pi$ também seria.

%%}}}

%%{{{ prob: russell_prondo_exam 
\problem.
%%%{{{ meta 
\label russell_prondo_exam
\credits
    * Rondogiannis
    ;;
%%%}}}

Responda com `T' ou `F' quando possível:\foot
A terceira questão fez parte \emph{mutatis mutandis}
duma prova final de Rondogiannis (infelizmente muitos anos
depois de tê-lo como professor).
\toof
\elist a:
\li: o conjunto dos números transcendentais é contável:
\li: existe irracional $\alpha$ tal que $\alpha^\alpha$ é racional:
\li: nas questões do~\ref[russell_prondo_exam] tem mais
     afirmações falsas do que verdadeiras:
\li: o conjunto $(\nats\to\set{0,1})$ é contável:
\li: o segmento $[0,1]$ é equinúmero com o cubo $[0,1]^3$:
\endelist

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

%%{{{ blah 
\blah Sobre a teoria de conjuntos de Cantor.
%%%{{{ meta 
%%%}}}

\cite[kleeneIM], \cite[ynmnst].

Um livro muito divertido que trata bem essas idéias de infinito
que encontramos aqui é o \cite[satancantorinfinity: Part~VI].

%%}}}

%%{{{ blah: About measure theory 
\blah Sobre teoria da medida.
%%%{{{ meta 
%%%}}}

\cite[bartlemeasure],
\cite[halmosmeasure],
\cite[taylorintegration].

%%}}}

%%{{{ blah: About the steps that lead Cantor to his discoveries 
\blah Sobre os passos que levaram Cantor nas suas descobertas.
%%%{{{ meta 
%%%}}}

\cite[srivastavacantor].
Mais sobre a construtividade e os ataques injustos contra a
demonstração de Cantor no~\cite[grayaboutcantor].
{\Cantor}Cantor conheceu {\Dedekind}Dedekind na Suiça no \yearof{1872}
e desde então e até \yearof{1899} trocaram muitas cartas entre si
comunicando suas idéias que acabaram gerando as teorias que
conhecemos aqui neste capítuo e que vão muito além disso!
A colecção dessas cartas foi publicada no \cite[cantordedekind].
O \cite[gouveacantor] é artigo curto e bem escrito que resuma
a historia entre Cantor e Dedekind, oferecendo também uma análise
na situação, nos posicionamentos, e até nos possíveis sentimentos
envolvidos dos dois homens.
O \cite[ferreiroscantordedekind] é uma análise mais extensa,
defendendo bastante a contribuição de Dedekind nos resultados
que geralmente atribuimos apenas ao Cantor.

%%}}}

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Posets_Lattices 
\chapter Posets; reticulados.
%%%{{{ meta 
\label Posets_Lattices
%%%}}}

%%{{{ Concept, notation, properties 
\section Conceito, notação, propriedades.
%%%{{{ meta 
%%%}}}

\TODO Conceito.

%%{{{ df: poset 
\definition poset.
%%%{{{ meta 
\label poset
\defines
    * poset
    ;;
%%%}}}

Chamamos o conjunto estruturado $\cal P = \sset P \leq$
um \dterm{poset} (ou conjunto parcialmente ordenado),
sse $(\leq)$ é uma relação de ordem parcial:
$$
\gather
x \leq x\\
x \leq y \mland y \leq z \implies x \leq z\\
x \leq y \mland y \leq x \implies x = y
\endgather
$$

%%}}}

%%{{{ Notational abuse 
\note Abusos notacionais.
%%%{{{ meta 
%%%}}}

Extendemos o ``tipo'' do predicado $\dhole\leq\dhole$ de elementos de $P$
para elementos e/ou subconjuntos de $P$, definindo:
$$
\align
a \leq Y &\defiff a \leq y, \quad\text{para todo $y\in Y$};\\
X \leq b &\defiff x \leq b, \quad\text{para todo $x\in X$};\\
X \leq Y &\defiff x \leq y, \quad\text{para todo $x\in X$ e $y\in Y$}.
\endalign
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nas definições seguintes nosso contexto é um poset $\sset P \leq$.

%%}}}

%%{{{ df: incomparable 
\definition.
%%%{{{ meta 
\label incomparable
\defines
    * incomparável
    ;;
%%%}}}

Se $x \nleq y$ e $y \nleq x$ chamamos $x$ e $y$ \dterm{incomparáveis}.
Denotamos assim:
$$
x \incomp y \defiff x \nleq y \mland y \nleq x.
$$

%%}}}

%%{{{ df: chain_antichain 
\definition.
%%%{{{ meta 
\label chain_antichain
\defines
    * anticadeia
    * cadeia
    ;;
%%%}}}

Seja $X\subset P$.
Chamamos o $X$ uma \dterm{cadeia} sse todos os seus elementos são comparáveis.
No caso oposto, onde todos são comparáveis apenas com eles mesmo,
chamamos o $X$ \dterm{anticadeia}.  Simbolicamente:
$$
\align
\text{cadeia:}\quad&       x, y \in X  \implies  x \leq y \mlor y\leq x;\\
\text{anticadeia:}\quad&   x, y \in X  \mland x \leq y \implies x = y.
\endalign
$$

%%}}}

%%{{{ df: covby 
\definition.
%%%{{{ meta 
\label covby
\defines
    * ~x \covby ~y  -- o $x$ é coberto por o $y$
    * cobertura
    ;;
%%%}}}

Se $x\leq y$ e não existe nenhum $z$ estritamente entre os $x$ e $y$
falamos que $y$ \dterm{cobre} o $x$.  Simbolicamente:
$$
x\covby y \defiff x < y \mland \lnot\exists z (x < z < y).
$$

%%}}}

%%{{{ Diagramas Hasse 
\note Diagramas Hasse.
%%%{{{ meta 
\defines
    * Hasse!diagrama
    ;;
%%%}}}

Já encontramos diagramas {\Hasse}Hasse no \ref[Group_theory]
(\reftag[hasse_diagrams_first_encounter],
\reftag[hasse_dih_3], \reftag[hasse_dih_4])
onde desenhamos os Hasse duns posets de subgrupos.

%%}}}

%%{{{ beware 
\beware.
%%%{{{ meta 
%%%}}}

Diagramas Hasse podem aparecer bastante diferentes mesmo
sendo do mesmo poset.

%%}}}

%%{{{ eg: cube_and_not_so_cube 
\example.
%%%{{{ meta 
\label cube_and_not_so_cube
\defines
    * reticulado!cubo
    ;;
%%%}}}

Aqui duas formas de desenhar diagramas Hasse para o
$\sset{\pset\set{0,1,2}}{\subset}$:
$$
\xalignat2
&\tikzpicture
\node (max) at (0,4)  {$\set{0,1,2}$};
\node (a)   at (-2,2) {$\set{0,1}$};
\node (b)   at (0,2)  {$\set{0,2}$};
\node (c)   at (2,2)  {$\set{1,2}$};
\node (d)   at (-2,0) {$\set 0$};
\node (e)   at (0,0)  {$\set 1$};
\node (f)   at (2,0)  {$\set 2$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
&
&\tikzpicture
\node (max) at (0,4)       {$\set{0,1,2}$};
\node (a)   at (-2,2.666)  {$\set{1,2}$};
\node (b)   at (0,2.666)   {$\set{0,2}$};
\node (c)   at (2,2.666)   {$\set{0,1}$};
\node (d)   at (-2,-0.666) {$\set 0$};
\node (e)   at (0,-0.666)  {$\set 1$};
\node (f)   at (2,-0.666)  {$\set 2$};
\node (min) at (0,-2)      {$\emptyset$};
\draw (min) -- (d) -- (c) -- (max) -- (a) -- (f) -- (min);
\draw (min) -- (e);
\draw (max) -- (b);
\draw (a) -- (e) -- (c);
\draw (d) -- (b) -- (f);
\endtikzpicture
\endxalignat
$$
Esse poset é chamado \dterm{cubo:} por motivos óbvios se olhar
no seu primeiro diagrama, e não-tão-óbvios olhando para o segundo!

%%}}}

%%{{{ df: min_max 
\definition.
%%%{{{ meta 
\label min_max
\defines
    * \max {~A}  -- o máximo de $A$
    * \min {~A}  -- o mínimo de $A$
    * máximo
    * mínimo
    ;;
%%%}}}

Sejam $A\subset P$.
Chamamos o $m$ de \dterm{mínimo} de $A$ sse
$m \in A$ e $m\leq a$ para todo $a\in A$.
\emph{Dualmente} $m$ é o \dterm{máximo} de $A$ sse
$m \in A$ e $a\leq m$ para todo $a\in A$.
Denotamos o mínimo de $A$, se existe, por $\min A$;
e seu máximo, se existe, por $\max A$.
\mistake

%%}}}

%%{{{ x: uniqueness_of_min_max 
\exercise.
%%%{{{ meta 
\label uniqueness_of_min_max
%%%}}}

Qual o erro na definição acima?
O ache e o corrija.

%%}}}

%%{{{ x: ordered_singleton_set_has_minimum 
\exercise.
%%%{{{ meta 
\label ordered_singleton_set_has_minimum
%%%}}}

Seja $U$ um conjunto unitário ordenado.
Demonstre que ele tem mínimo.
Quais propriedades da $(\leq)$ tu precisas aqui?

\solution
Seja $m \in U$ o único membro do $U$.
Vamos confirmar que satisfaz a definição de mínimo.
Já temos que $m$ é um membro do $U$, então basta verificar que
$$
\lforall {u \in U} { m \leq u }.
$$
Seja $u \in U$ então.
Como $U$ unitário, temos $m = u$.
Portanto $m \leq u$ (pela reflexividade da~$(\leq)$).

%%}}}

%%{{{ x: finite_losets_are_wosets 
\exercise.
%%%{{{ meta 
\label finite_losets_are_wosets 
%%%}}}

Demonstre que qualquer conjunto finito, não vazio, e linearmente ordenado é
bem ordenado.

\hint
Praticamente já resolvido no \ref[finite_numbersets_have_min].
Por quê?  (O que falta observar ou verificar?)

\solution
Já resolvido no \ref[finite_numbersets_have_min], pois na sua resolução
não usamos nenhuma propriedade de números: todo que precisamos foi
que $A$ é totalmente ordenado pela $(\leq)$.
Assim temos que todo conjunto finito, não vazio, e linearmente ordenado
possui mínimo.  Para concluir que é bem ordenado basta observar
que qualquer subconjunto dum conjunto finito, é finito.

%%}}}

%%{{{ df: poset_terminology
\definition.
%%%{{{ meta 
\label poset_terminology
\defines
    * 0_{~P}  -- o zero (o mínimo elemento dum poset)
    * 1_{~P}  -- o um (o máximo elemento dum poset)
    * \bot_{~P}  -- o bottom (o mínimo elemento dum poset)
    * \top_{~P}  -- o top (o máximo elemento dum poset)
    * bottom
    * bounded!por baixo
    * bounded!por cima
    * one!dum poset
    * top
    * zero!dum poset
    ;;
%%%}}}

Se o próprio $P\subset P$ possui elemento
mínimo, o chamamos de \dterm{bottom} de $P$,
e se possui
máximo, o chamamos de \dterm{top} de $P$.
Usamos as notações $\bot_P$ e $\top_P$ respectivamente,
esquecendo o $_P$ quando é implícito pelo contexto.
Sinônimos de bottom e top são os \dterm{zero} e \dterm{um} respectivamente,
usando as notações $0_P$ e $1_P$.
Se um poset possui bottom, ele é chamado \dterm{bounded por baixo},
e se ele possui top, ele é chamado \dterm{bounded por cima}.
Caso que seja bounded por cima e por baixo, o chamamos apenas de
\dterm{bounded}.

%%}}}

%%{{{ df: minimal_maximal 
\definition.
%%%{{{ meta 
\label minimal_maximal
\defines
    * maximal
    * minimal
    ;;
%%%}}}

Chamamos o $x$ um elemento \dterm{minimal} de $P$
sse nenhum elemento está embaixo dele, e, \emph{dualmente}
chamamos o $x$ \dterm{maximal} de $P$ sse nenhum elemento
está acima dele.  Simbolicamente:
$$
\align
\text{$x$ minimal de $P$}&\defiff  \lforall {y \in P} {y \leq x \implies x = y};\\
\text{$x$ maximal de $P$}&\defiff  \lforall {y \in P} {x \leq y \implies x = y}.
\endalign
$$

%%}}}

%%{{{ df: ubs_lbs 
\definition.
%%%{{{ meta 
\label ubs_lbs
\defines
    * \lbs {~A}  -- o conjunto dos lower bounds de $A$
    * \ubs {~A}  -- o conjunto dos upper bounds de $A$
    * lower bound
    * upper bound
    * cota!inferior
    * cota!superior
    ;;
%%%}}}

Sejam $A\subset P$ e $p\in P$.
O $p$ é uma \dterm{cota superior} (ou \dterm{upper bound}) de $A$ sse $p \geq A$.
Dualmente, o $p$ é uma \dterm{cota inferior} (ou \dterm{lower bound}) de $A$ sse $p \leq A$.
Usamos a notação
\mathcol
(A \leq) \defeq \ubs A &\defeq \setst {p \in P} {A \leq p} \\
(\leq A) \defeq \lbs A &\defeq \setst {p \in P} {p \leq A}.
\endmathcol

%%}}}

%%{{{ eg: ubs_lbs_in_reals_example 
\example.
%%%{{{ meta 
\label ubs_lbs_in_reals_example
%%%}}}

No $\reals$, considere seu subconjunto $(1,2]$.
Uns upper bounds dele são os reais $2, 5, \sqrt{12}, 8000$;
uns lower bounds dele são os $-400, -\pi, 0, 1/2, 0.8, 1$.

%%}}}

%%{{{ df: lub_glb 
\definition.
%%%{{{ meta 
\label lub_glb
\defines
    * \Join{~A}  -- o join de $A$
    * \Meet{~A}  -- o meet de $A$
    * \glb{~A}  -- o greatest lower bound de $A$
    * \inf{~A}  -- o infimum de $A$
    * \lub{~A}  -- o least upper bound de $A$
    * \sup{~A}  -- o supremum de $A$
    * greatest lower bound
    * infimum
    * least upper bound
    * supremum
    ;;
%%%}}}

Se os $\ubs A$ e $\lbs A$ tem elemento mínimo e máximo respectivamente,
definimos
$$
\align
\lub A &\defeq \min\ubs A\\
\glb A &\defeq \max\lbs A.
\endalign
$$
Naturalmente chamamos o $\lub A$ o \dterm{least upper bound} de $A$,
e o $\glb A$ o \dterm{greatest lower bound} de $A$.
Usamos \emph{muitos} sinônimos, resumidos aqui:
$$
\xalignat3
\sup A &\ \text{(supremum)}   & \lub A &\ \text{(least upper bound)}    & \Join A &\ \text{(join)}\\
\inf A &\ \text{(infimum)}    & \glb A &\ \text{(greatest lower bound)} & \Meet A &\ \text{(meet)}
\endxalignat
$$

%%}}}

%%{{{ eg: inf_and_sup_of_openclosed_interval 
\example.
%%%{{{ meta 
\label inf_and_sup_of_openclosed_interval
%%%}}}

O $A=(1,2]$ do~\ref[ubs_lbs_in_reals_example] tem
$\inf A = 1$ e $\sup A = 2$.
Observe que $\sup A \in A$ mas $\inf A \nin A$.

%%}}}

%%{{{ x: when_glb_and_lub_is_min_and_max 
\exercise.
%%%{{{ meta 
\label when_glb_and_lub_is_min_and_max
%%%}}}

O que podemos concluir quando $\glb A \in A$ e quando $\lub A \in A$?

%%}}}

%%{{{ df: downset_upset_downs  
\definition.
%%%{{{ meta 
\label downset_upset_downs
\defines
    * \downs{~P}  -- o conjunto de downsets de $P$
    * downset
    * upset
    ;;
%%%}}}

Chamamos o $A\subset P$ um \dterm{downset} no $P$
sse o $A$ é ``fechado para baixo'', e \emph{dualmente},
o chamamos \dterm{upset} sse ele é ``fechado para cima''.
Formalmente,
$$
\align
\text{$A$ downset} &\defiff \pforall {a \in A} \lforall {x \leq a} {x \in A};\\
\text{$A$ upset}   &\defiff \pforall {a \in A} \lforall {x \geq a} {x \in A}.
\endalign
$$
Dado um poset $P$, usamos $\downs P$ para denotar o conjunto de todos os seus
downsets.  Simbolicamente,
$$
\downs P \defeq \setstt {D \subset P} {$D$ é um downset de $P$}.
$$

%%}}}

%%{{{ df: down_up 
\definition.
%%%{{{ meta 
\label down_up
\defines
    * \down {~a}  -- o down de $a$
    * \up {~a}  -- o up de $a$
    ;;
%%%}}}

Definimos para qualquer $a\in P$ os conjuntos
$$
\align
\down a &\defeq \setst {x \in P} {x \leq a}\\
\up a   &\defeq \setst {x \in P} {a \leq x}
\intertext{e generalizamos essas operações de elementos $a\in P$ para subconjuntos $A\subset P$ assim:}
\down A &\defeq \setstt {x \in P} {$x \leq a$ para algum $a \in A$}\\
\up A   &\defeq \setstt {x \in P} {$a \leq x$ para algum $a \in A$}.
\endalign
$$
Observe que $\down x = \down{\set x}$ e $\up x = \up{\set x}$.
Diretamente pelas definições também temos:
$$
\xalignat2
\down A &= \Union_{a\in A} {\down a}&
\up A &= \Union_{a\in A} {\up a}
\endxalignat
$$

%%}}}

%%{{{ x: down_is_downset_up_is_upset 
\exercise.
%%%{{{ meta 
\label down_is_downset_up_is_upset
%%%}}}

Sejam $P$ poset e $A \subset P$.
Demonstre que $\down A$ é um downset e $\up A$ um upset.

%%}}}

%%{{{ x: equivalent_statements_to_x_leq_y 
\exercise.
%%%{{{ meta 
\label equivalent_statements_to_x_leq_y
%%%}}}

Sejam $P$ um poset, $x,y\in P$.
Demonstre que as afirmações
\tlist:
\li (i):   $x \leq y$;
\li (ii):  $\down x \subset \down y$;
\li (iii): para todo downset $D$ de $P$ com $y \in D$, temos $x\in D$;
\endtlist
são equivalentes.

\solution
Vamos demonstrar usando um caminho ``round-robin'':
\crtabproofpart {\rm (i)\timplies(ii).}
Seja $a \in \down x$.  Logo $a \leq x$, e como $x\leq y$ (hipótese),
pela transitividade da $(\leq)$ temos $a \leq y$.  Logo $a\in \down y$.
Ou seja, $\down x \subset \down y$.
\crtabproofpart {\rm (ii)\timplies(iii).}
Seja $D$ downset de $P$ com $y \in D$.
Logo $\down y \subset D$.
Pela hipótese $\down x \subset \down y$ e logo $\down x \subset D$.
Como $x \in \down x$, então $x \in D$.
\crtabproofpart {\rm (iii)\timplies(i).}
Observe que $\down y$ é um downset tal que $y$ pertence nele.
Logo $x \in \down y$ (pela hipótese).
Logo $x \leq y$ (pela def.~de $\down y$).

%%}}}

\endsection
%%}}}

%%{{{ Posets for free: operations and constructions 
\section Posets de graça: operações e construções.
%%%{{{ meta 
%%%}}}

\TODO elaborar.

%{{{ df: discrete_poset 
\definition discreto.
%%%{{{ meta 
\label discrete_poset
\defines
    * poset!discreto
    ;;
%%%}}}

Qualquer conjunto $X$ equipado com a igualdade vira
um poset, que chamamos de \dterm{discreto}.

%%}}}

%%{{{ df: dual_poset 
\definition dual.
%%%{{{ meta 
\defines
    * \dualposet{~P}  -- o poset dual de $P$
    * poset!dual
    ;;
%%%}}}

Dado qualquer poset $\sset P {\leq_P}$ definimos o seu
poset \dterm{dual} que denotamos por $\dualposet P$
apenas virando o $P$ ``de cabeça pra baixo'';
ou seja, usando como ordem do $\dualposet P$ a $\geq_P$:
$$
x \leq_{\dualposet P} y \defiff y \leq_P x.
$$

%%}}}

%%{{{ df: 
\definition números.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: lift_poset 
\definition lift.
%%%{{{ meta 
\label lift_poset
\defines
    * \lift {~P}  -- o lifting do poset $P$
    * poset!lift
    ;;
%%%}}}

Para qualquer poset $P$ definimos seu \dterm{lifting} $\lift P$
botando um novo membro abaixo do $P$.

%%}}}

%%{{{ x: lift_poset_formal_def 
\exercise.
%%%{{{ meta 
\label lift_poset_formal_def
%%%}}}

Formalize a \ref[lift_poset].

%%}}}

%%{{{ df: flat_poset 
\definition flat.
%%%{{{ meta 
\label flat_poset
%%%}}}

Um poset $P$ é chamado \dterm{flat} sse possui mínimo $\bot$ e
$$
x \leq y \iff x = \bot \mlor x = y.
$$

%%}}}

%%{{{ pseudodf: poset_sum_pseudodef 
\pseudodefinition soma.
%%%{{{ meta 
\label poset_sum_pseudodef
\indexes
    * soma!de poset    see: poset
    ;;
\defines
    * ~P \posetplus ~Q  -- a soma do poset $P$ com o poset $Q$
    * poset!soma
    ;;
%%%}}}

Dados posets disjunos $P,Q$ definimos sua \dterm{soma}
$P \posetplus Q$ para ser o poset botando cada
membro de $Q$ para ser maior de cada membro de
$P$; fora disso, consultamos as ordens dos $P$
e $Q$.

%%}}}

%%{{{ x: poset_sum_formal_def 
\exercise.
%%%{{{ meta 
\label poset_sum_formal_def
%%%}}}

Defina formalmente a soma de posets $P \posetplus Q$
numa maneira que é capaz de lidar até com posets
cujos carrier sets não são necessariamente disjuntos.

%%}}}

%%{{{ x: lift_P_as_sum 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o $\lift P$ como somatório.

\solution
$\lift P \defeq \ordnum 1 \ordplus P$.

%%}}}

%%{{{ df: poset_union_pseudodef 
\pseudodefinition união.
%%%{{{ meta 
\label poset_union_pseudodef
%%%}}}

Dados $P$ e $Q$ posets disjuntos definimos sua \dterm{união}
$P \posetunion Q$ para ser o poset botando o $P$ e o $Q$
um no lado do outro.

%%}}}

%%{{{ x: poset_union_formal_def 
\exercise.
%%%{{{ meta 
\label poset_union_formal_def
%%%}}}

Defina formalmente a união de posets $P \posetunion Q$
numa maneira que é capaz de lidar até com posets
cujos carrier sets não são necessariamente disjuntos.

%%}}}

%%{{{ Q: How would you order the points of a product of posets? 
\question.
%%%{{{ meta 
%%%}}}

Dados posets $P,Q$, como tu definaria~(formalmente)~uma ordem nos
membros de $P \times Q$ para ele virar um poset também?

%%}}}

\spoiler

%%{{{ A.: there are two ways: 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Tem duas ordens bem diferentes e importantes que podemos definir
no $P\times Q$: a ``coordinatewise'' e a ``(anti)lexicográfica'':

%%}}}

%%{{{ df: product_order_componentwise 
\definition produto componentwise.
%%%{{{ meta 
\label product_order_componentwise
\indexes
    * ordem!coordinatewise    see: componentwise
    ;;
\defines
    * ordem!componentwise
    ;;
%%%}}}

Sejam $P,Q$ posets.
Definimos a relação $(\leq_{P \cross Q})$ no $P \times Q$ pela:
$$
(p,q) \leq_{P \cross Q} (p',q')
\defiff
p\leq_P p'
\mland
q\leq_Q q'.
$$
Chamamos essa ordem de \dterm{componentwise}
ou \dterm{coordinatewise}.

%%}}}

%%{{{ df: product_order_lexico 
\definition produto (anti)lexicó.
%%%{{{ meta 
\label product_order_lexico
\defines
    * ordem!antilexicográfica
    * ordem!lexicográfica
    ;;
%%%}}}

Sejam $P,Q$ posets.
Definimos a \dterm{ordem lexicográfica} no $P \cross Q$
pela
$$
\align
(p,q) \leq_{P \cross Q} (p',q')
&\defiff
p <_P p'
\mlor
\paren{
p = p'
\mland
q \leq_Q q'
}.
\intertext{%
A ordem é chamada assim pois é a ordem seguida nos diccionários
(e ``lexicó'' significa ``diccionário'').
Similarmente definimos a ordem \dterm{antilexicográfica}
começando as comparações no lado oposto:
}
(p,q) \leq'_{P \cross Q} (p',q')
&\defiff
q <_Q q'
\mlor
\paren{
q = q'
\mland
p \leq_P p'
}.
\endalign
$$

%%}}}

%%{{{ remark: generalizations of product orders to generalized products 
\remark.
%%%{{{ meta 
%%%}}}

A ordem padrão que vamos considerar em produtos de posets
é a coordinatewise.  Observe que ela generaliza tranqüilamente
para famílias indexadas por qualquer conjunto de índices $\cal I$;
porém, para generalizar a (anti)lexicográfica, o $\cal I$
necessita uma ordem também.

%%}}}

%%{{{ x: product_order_componentwise_generalized 
\exercise.
%%%{{{ meta 
\label product_order_componentwise_generalized
%%%}}}

Generalize a ordem componentwise para o produto cartesiano de
família indexada de posets.

%%}}}

%%{{{ x: product_order_lexico_generalized 
\exercise.
%%%{{{ meta 
\label product_order_lexico_generalized
%%%}}}

Generalize a ordem (anti)lexicográfica para o produto cartesiano
de família indexada de posets.

%%}}}

%%{{{ Q: How would you define an order on a function space? 
\question.
%%%{{{ meta 
%%%}}}

Dado poset $P$ e conjunto $A$, como definarias uma ordem
no espaço $(A \to P)$?

%%}}}

\spoiler

%%{{{ df: pointwise_order 
\definition pointwise.
%%%{{{ meta 
\label pointwise_order
\indexes
    * pointwise!order    see: ordem
    ;;
\defines
    * ordem!pointwise
    ;;
%%%}}}

Sejam $P$ poset e $A$ conjunto.
Definimos a ordem \dterm{pointwise} no espaço de funções $\funs A P$
pela
$$
f \leq g
\defiff
\lforall {x \in A} {fx \leq_P gx}.
$$

%%}}}

%%{{{ x: pointwise_order_on_partial_function_space 
\exercise.
%%%{{{ meta 
\label pointwise_order_on_partial_function_space
%%%}}}

A mesma ordem ordena o $(A \parto P)$?

%%}}}

\endsection
%%}}}

%%{{{ Duality_in_posets 
\section Dualidade.
%%%{{{ meta 
\label Duality_in_posets
%%%}}}

\TODO escrever.

\endsection
%%}}}

%%{{{ Mappings 
\section Mapeamentos.
%%%{{{ meta 
%%%}}}

%%{{{ df: monotone_embedding_isomorphism 
\definition.
%%%{{{ meta 
\label monotone_embedding_isomorphism
\defines
    * isomorfismo!de ordem
    * monótona
    * order-embedding
    * order-isomorfismo
    ;;
%%%}}}

Sejam $\sset P {\leq_P}$ e $\sset Q {\leq_Q}$ posets
e $\phi : P \to Q$.
Definimos
$$
\align
\text{$\phi$ monótona}
&\defiff x\leq_P y \implies \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-embedding}
&\defiff \text{$\phi$ injetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)\\
\text{$\phi$ order-isomorfismo}
&\defiff \text{$\phi$ bijetora} \mland x\leq_P y \iff \phi(x) \leq_Q \phi(y)
\endalign
$$

%%}}}

%%{{{ criterion: order_embedding_criterion 
\criterion.
%%%{{{ meta 
\label order_embedding_criterion
%%%}}}

Se $\phi : P \to Q$ tal que
$$
x \leq_P y \iff \phi(x) \leq_Q \phi(y)
$$
então $\phi$ é um order-embedding.
Segue que se $\phi$ é sobrejetora, ela é um order-isomorfismo.

\proof.
Basta demonstrar que $\phi$ é injetora.
Tome $x,y \in P$.
Temos
\compute
\phi(x) = \phi(y)
&\implies \phi(x) \leq_Q \phi(y) \mland \phi(y) \leq_Q \phi(x)  \by {\ref[converse_of_antisymmetry]} \\
&\implies x \leq_P y \mland y \leq_P x                          \by {pela hipótese} \\
&\implies x = y.                                                \by {antissimetria} \\
\endcompute

%%}}}

%%{{{ x: converse_of_antisymmetry 
\exercise Converso de antissimetria.
%%%{{{ meta 
\label converse_of_antisymmetry
%%%}}}

Justifique a primeira implicação na demonstração do~\ref[order_embedding_criterion].

%%}}}

%%{{{ x: downsets_of_poset_iso_downsets_of_dual 
\exercise.
%%%{{{ meta 
\label downsets_of_poset_iso_downsets_of_dual
%%%}}}

Defina um $\phi : \downsets P \iso \downsets { \dual P }$.

\solution
$\phi(X) = P\setminus X$

%%}}}

%%{{{ x: downsets_of_disjunion_iso_product_of_downsets 
\exercise.
%%%{{{ meta 
\label downsets_of_disjunion_iso_product_of_downsets
%%%}}}

Defina um
$\psi : \downsets { P_1 \disjunion P_2 } \iso \downsets {P_1} \times \downsets {P_2}$.

\solution
$\psi(D) = \tup{ D \inter P_1, D \inter P_2 }$.

%%}}}

%%{{{ x: posets_of_divisors 
\exercise.
%%%{{{ meta 
\label posets_of_divisors
%%%}}}

Para $n\in\nats$, definimos o poset
${\cal D}_n \defeq \sset {D_n} {\divides}$
onde $D_n \defeq \setst {d \in \nats} {d \divides n}$.
\item{(i)}
Desenhe o diagrama Hasse de ${\cal D}_{30}$.
\item{(ii)}
Ache conjunto $A$ tal que ${\cal D}_{30} \iso \sset {\pset A} {\subset}$
e defina um isomorfismo $\phi : D_{30} \to \pset A$.
\item{(iii)}
Existe conjunto $B$ tal que ${\cal D}_0 \iso \sset {\pset B} {\subset}$?
Se sim, ache o $B$ e defina um isomorfismo
$\phi : D_0 \to {\pset B}$;
se não, demonstre que é impossível.

\solution
\noi (i)
Primeiramente calculamos: $D_{30} = \set{1, 2, 3, 5, 6, 10, 15, 30}$.
$$
\tikzpicture
\node (max) at (0,4)  {$30$};
\node (a)   at (-2,2) {$6$};
\node (b)   at (0,2)  {$10$};
\node (c)   at (2,2)  {$15$};
\node (d)   at (-2,0) {$2$};
\node (e)   at (0,0)  {$3$};
\node (f)   at (2,0)  {$5$};
\node (min) at (0,-2) {$1$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\eop
\noi (ii)
Tome o $A = \set{2,3,5}$ e defina a função $\phi : \pset A \to D_{30}$
pelas equações:
$$
\align
\phi(30) &= A\\
\phi(15) &= \set{3,5}\\
\phi(10) &= \set{2,5}\\
\phi(6)  &= \set{2,3}\\
\phi(2)  &= \set{2}\\
\phi(3)  &= \set{3}\\
\phi(5)  &= \set{5}\\
\phi(1)  &= \emptyset
\endalign
$$
Seu diagrama Hasse parece assim:
$$
\tikzpicture
\node (max) at (0,4)  {$\set{2,3,5}$};
\node (a)   at (-2,2) {$\set{2,3}$};
\node (b)   at (0,2)  {$\set{2,5}$};
\node (c)   at (2,2)  {$\set{3,5}$};
\node (d)   at (-2,0) {$\set 2$};
\node (e)   at (0,0)  {$\set 3$};
\node (f)   at (2,0)  {$\set 5$};
\node (min) at (0,-2) {$\emptyset$};
\draw (min) -- (d) -- (a) -- (max) -- (b) -- (f)
(e) -- (min) -- (f) -- (c) -- (max)
(d) -- (b);
\draw[preaction={draw=white, -,line width=6pt}] (a) -- (e) -- (c);
\endtikzpicture
$$
\noi
Obs: qualquer conjunto $A$ com $|A|=3$ serve!
Uma avantagem desse é que podemos bem elegantemente definir a bijecção
inversa, mandando cada subconjunto de $\set{2,3,5}$ para seu produtório!
\eop
\noi (iii)
Não existe, pois $D_0 = \nats$ (contável)
e logo não pode ser equinúmero com o powerset de nenhum conjunto $B$.
\eop
\noi (iv)
Verdade, a função $\phi : D_0 \to \setst {D_n} {n\in \nats}$ definida pela
$$
\phi(n) = D_n
$$
é um isomorfismo, pois:
$$
n \divides m \iff D_n \subset D_m.
$$

%%}}}

\endsection
%%}}}

%%{{{ Lattices as posets 
\section Reticulados como posets.
%%%{{{ meta 
%%%}}}

%%{{{ df: lattice_as_poset 
\definition.
%%%{{{ meta 
\label lattice_as_poset
\indexes
    * lattice    see: reticulado
    ;;
\defines
    * lattice!como poset
    ;;
%%%}}}

Um poset $\cal L = \sset L {\leq}$
é um \dterm{lattice} (ou \dterm{reticulado}) sse 
para todo $x,y \in L$, os $\sup\set{x,y}$ e $\inf\set{x,y}$
existem.

%%}}}

\endsection
%%}}}

%%{{{ Lattices as algebraic structures 
\section Reticulados como estruturas algébricas.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

No~\ref[Algebraic_structures] introduzimos reticulados
como uma estrutura algébrica.\foot
Leia a~\ref[Lattices_as_algebras] se não tá ligado.
\toof
Aqui a definição novamente:

%%}}}

%%{{{ df: lattice_as_algebra_human 
\definition.
%%%{{{ meta 
\label lattice_as_algebra_human
\defines
    * lattice!como algebra
    ;;
%%%}}}

Seja $\cal L = \sset L {\join, \meet}$ conjunto estruturado
onde $\join,\meet$ são operadores binários no $L$.
Chamamos o $L$ um \dterm{lattice} (ou \dterm{reticulado}) sse
as operações $\join,\meet$ são associativas, comutativas,
e idempotentes, e satisfazem as leis seguintes \emph{de absorção}:
\mathcol
a \join (b \meet a) &= a \\
a \meet (b \join a) &= a
\endmathcol

%%}}}

\TODO place the following somewhere.

%%{{{ advice: join_and_meet_proof_advice 
\advice.
%%%{{{ meta 
\label join_and_meet_proof_advice
%%%}}}

Vamos supor que tu tá tentando demonstrar
$$
(x \meet y) \join (x \meet z) \leq x \meet (y \join z).
$$
Os $(\meet)$ e $(\join)$ sendo glb e lub, fornecem duas
maneiras de visualizar esse alvo.
Primeiramente esqueça o $(\meet)$ à direita:
considera toda a $x \meet (y \join z)$ como uma coisa só,
e perceba qua a parte esquerda é um $(\join)$, um join, um l.u.b.:
$$
\alertR {(x \meet y)} \join \alertG {(x \meet z)} \leq \alertB {x \meet (y \join z)}.
$$
Ou seja precisamos demonstrar que o $\alertB {azul}$ é $(\geq)$ que um l.u.b.;
basta então mostrar que é \emph{um} u.b.:
$$
\PROOFmn {
\A {\alertB \bullet \geq \alertR \bullet}   \A {\alertB \bullet \geq \alertG \bullet}
\I2----------------------------------------------------------------------------------
          {\alertB \bullet \geq (\alertR \bullet \join \alertG \bullet)}
}
$$
Alternativamente enxergue a parte esquerda como uma coisa só e perceba que a parte direita
é um $(\meet)$, um meet, um g.l.b.:
$$
\alertB {(x \meet y) \join (x \meet z)} \leq \alertR {x} \meet \alertG {(y \join z)}.
$$
Assim precisamos demonstrar que o $\alertB {azul}$ é $(\leq)$ que um g.l.b.;
basta então mostrar que é \emph{um} l.b.:
$$
\PROOFmn {
\A {\alertB \bullet \leq \alertR \bullet}   \A {\alertB \bullet \leq \alertG \bullet}
\I2----------------------------------------------------------------------------------
          {\alertB \bullet \leq (\alertR \bullet \meet \alertG \bullet)}
}
$$

%%}}}

\endsection
%%}}}

%%{{{ Complete lattices 
\section Reticulados completos.
%%%{{{ meta 
%%%}}}

%%{{{ df: complete_lattice 
\definition.
%%%{{{ meta 
\label complete_lattice
%%%}}}

Um reticulado $L$ é um \dterm{reticulado completo} sse
para todo $S\subset L$ ambos os $\Join S$ e $\Meet S$ são definidos.

%%}}}

%%{{{ x: every_complete_lattice_is_bounded 
\exercise.
%%%{{{ meta 
\label every_complete_lattice_is_bounded
%%%}}}

Todo reticulado completo é bounded.

%%}}}

%%{{{ remark: what do we gain in a complete lattice 
\remark.
%%%{{{ meta 
%%%}}}

Já demonstramos que num reticulado $L$ os joins e meets existem para qualquer
subconjunto \emph{não vazio e finito} dele.
Então num reticulado \emph{completo}, sabemos disso para o vazio
e para os subconjuntos infinitos também.

%%}}}

\TODO generalize o~\ref[set_limits] para qualquer reticulado completo.

\endsection
%%}}}

%%{{{ Fixpoints_in_posets 
\section Fixpoints.
%%%{{{ meta 
\label Fixpoints_in_posets
%%%}}}

%%{{{ df: fixpoints 
\definition.
%%%{{{ meta 
\label fixpoints
\defines
    * \fixpoints {~f}  -- o conjunto dos fixpoints de $f$
    * \gfp {~f}  -- o maior fixpoint de $f$
    * \lfp {~f}  -- o menor fixpoint de $f$
    * fixpoint!greatest
    * fixpoint!least
    ;;
%%%}}}

Seja $f : X \to X$.
Usamos a notação
$$
\fixpoints f
\defeq
\setstt { x \in X } {$x$ é um fixpoint de $f$}
$$
e se $X$ é um poset e $\fixpoints F$ tem mínimo e máximo botamos
\mathcall
\lfp f &\defeq \min(\fixpoints f)  \called {o \dterm{menor fixpoint} de $f$} \\
\gfp f &\defeq \max(\fixpoints f). \called {o \dterm{maior fixpoint} de $f$} \\
\endmathcall

%%}}}

%%{{{ df: prefixpoint_postfixpoint 
\definition prefixpoints, postfixpoints.
%%%{{{ meta 
\label prefixpoint_postfixpoint
\defines
    * postfixpoint
    * prefixpoint
    ;;
%%%}}}

Sejam $P$ poset e $F : P \to P$ e seja $p \in P$.
Chamamos o $p$ de \dterm{prefixpoint da $F$}
sse $Fp \leq p$.  Dualmente $p$ é um \dterm{postfixpoint da $F$}
sse $p \leq Fp$.

%%}}}

%%{{{ thm: knaster_tarski_fixpoint 
\theorem Knaster--Tarski.
%%%{{{ meta 
\label knaster_tarski_fixpoint
\indexes
    * teorema!Knaster--Tarski fixpoint
    ;;
%%%}}}

{\Knaster}{\Tarski}%
Seja $L$ reticulado completo e $F : L \to L$ monótona.
Então $F$ tem um fixpoint.

\sketch.
Sejam
$$
\xalignat2
D &\asseq \setst { x \in L } { x \leq Fx } &
U &\asseq \setst { x \in L } { Fx \leq x }.
\endxalignat
$$
os conjuntos de todos os postfixpoints e prefixpoints
da $F$ respecitivamente.
Considere o conjunto $\fixpoints F$.
Observe que $\fixpoints F = D \inter U$.
Vamos demonstrar que o $\Join D$ é um fixpoint de $F$.
(O $\Meet U$ é similar.)
Precisamos $\Join D = F(\Join D)$.
Vamos demonstrar $\Join D \leq F(\Join D)$ primeiro
e depois $F(\Join D) \leq \Join D$.
\proofpart {$\Join D \leq F(\Join D)$:}
Como $\Join D$ é o least upper bound de $D$,
basta demonstrar $F(\Join D)$ é um upper bound de $D$.
\proofpart {$F(\Join D) \leq \Join D$:}
Aqui como $\Join D$ é um upper bound de $D$,
basta mostrar que $F(\Join D)$ é um membro de $D$.
(Nessa parte podemos e vamos usar a $\Join D \leq F(\Join D)$
que acabamos de demonstrar!)

\proof.
Seja
$D \asseq \setst { x \in L } { x \leq Fx }$.
Vamos demonstrar que $\Join D$ é um fixpoint de $F$,
ou seja $F(\Join D) = \Join D$.
Quebramos a demonstração em duas partes:
\proofpart {$\Join D \leq F(\Join D)$:}
Basta mostrar que $F(\Join D)$ é um upper bound de $D$.
Tome $d \in D$.
Logo $d \leq Fd$\fact1~(pela definição de $D$)
e também $d \leq \Join D$\fact2,
pois $\Join D$ é um upper bound de $D$.
Como $F$ é monótona, da \byfact2~ganhamos
$Fd \leq F(\Join D)$\fact3.
Juntando (transitividade) as \byfact1~e~\byfact3:
$$
d \leq Fd \leq F(\Join D)
$$
ou seja, $d \leq F(\Join D)$ e como $d$ foi arbitrário elemento de $D$,
concluimos que $F(\Join D)$ é um upper bound de $D$.
Logo $\Join D \leq F(\Join D)$.
\proofpart {$F(\Join D) \leq \Join D$:}
Basta demonstrar que $F(\Join D) \in D$, pois $\Join D$ é um upper bound de $D$.
Como já demonstramos que $\Join D \leq F(\Join D)$, ganhamos a
$F(\Join D) \leq F(F(\Join D))$ (pela monotonicidade da $F$).
Ou seja, o $F(\Join D)$ satisfaz a definição de $D$, e logo pertence nele:
$F(\Join D) \in D$.
Como $\Join D$ é um upper bound de $D$, temos $F(\Join D) \leq \Join D$.

%%}}}

%%{{{ remark: the full Knaster--Tarski theorem 
\remark.
%%%{{{ meta 
%%%}}}

O teorema Knaster--Tarski fala ainda mais:
o $\fixpoints F\subset L$ é um reticulado completo
(\ref[knaster_tarski_fixpoint_full]).

%%}}}

\TODO explicar e desenhar.

%%{{{ cor: real_f_monotone_on_closed_interval_has_lfp_and_gfp 
\corollary.
%%%{{{ meta 
\label real_f_monotone_on_closed_interval_has_lfp_and_gfp
%%%}}}

Sejam $a,b\in\reals$ com $a\leq b$,
e função $f : [a,b] \to [a,b]$ monótona.
Logo $f$ tem um máximo e um mínimo fixpoint.

%%}}}

%%{{{ remark: we do not need f to be continuous 
\remark.
%%%{{{ meta 
%%%}}}

Observe que no~\ref[real_f_monotone_on_closed_interval_has_lfp_and_gfp]
não precisamos da $f$ ser contínua.

%%}}}

%%{{{ a new proof of Schröder--Bernstein 
\note Nova demonstração de Schröder--Bernstein.
%%%{{{ meta 
%%%}}}

Ganhamos também como corolário o teorema Schröder--Bernstein
(\reftag[schroder_bernstein])!
Os detalhes estão no~\ref[schroder_bernstein_lattice_proof].

%%}}}

%%{{{ df: orbit 
\pseudodefinition órbita.
%%%{{{ meta 
\label orbit
%%%}}}

Seja $a \in A$ e $f : A \to A$.
Chamamos a seqüência 
$$
a, f a, f^2 a, \dotsc
$$
de $f$-\dterm{órbita} de $a$,
omitindo o prefixo \symq{$f$-} quando o mapa
é implícito pelo contexto.

%%}}}

%%{{{ x: orbit_of_bottom 
\exercise.
%%%{{{ meta 
\label orbit_of_bottom
%%%}}}

Sejam $P$ um poset com $\bot$ e $f$ um endomapa no $P$.
Defina formalmente a $f$-órbita do $\bot$.

\solution
Como já definimos as iterações de qualquer endomapa
(\ref[function_iterations]), podemos simplesmente
definir a órbita do $\bot$ como a seqüência
$\seqn {f^n(\bot)} n$.
Alternativamente definimos diretamente por recursão:
\mathcol
x_0     &= \bot \\
x_{n+1} &= f(x_n).
\endmathcol

%%}}}

%%{{{ df: chaincomplete 
\definition.
%%%{{{ meta 
\label chaincomplete
%%%}}}

Um poset $P$ é chamado \dterm{chain-completo} sse
todo chain $C \subset P$ possui lub.

%%}}}

%%{{{ x: chaincomplete_has_bottom 
\exercise.
%%%{{{ meta 
\label chaincomplete_has_bottom
%%%}}}

Todo poset chain-completo possui bottom.

\solution
O $\emptyset$ é uma chain---como poderia não ser?---e
logo o $\Join \emptyset$ existe.
Mas o $\Join \emptyset$ é o bottom pela sua definição
como menor de todos os upper bounds.
(Já observamos que todo membro de $p$ é trivialmente um upper bound do $\emptyset$.)

%%}}}

%%{{{ df: countably_continuous 
\definition.
%%%{{{ meta 
%%%}}}

Um mapa $f : P \to Q$ é chamado \dterm{contavelmente continuo} sse
$f$ respeita os lubs de todas as \emph{cadeias não vazias e contáveis:}
$f( \Join C ) = \Join \img f C$.

%%}}}

%%{{{ thm: Kleene_strongly_least_fixpoint 
\theorem Kleene.
%%%{{{ meta 
\label Kleene_strongly_least_fixpoint
\credits
    * Kleene : strongly least fixpoint
    ;;
\defines
    * fixpoint!strongly least
    ;;
%%%}}}

Sejam $P$ poset chain-completo e $\pi : P \to P$
endomapa monótono e contavelmente continuo.
Logo $\pi$ possui exatamente um
\dterm{strongly least fixpoint} $x^*$:
\math
\pi(x^*) = x^* \tag{i} \\
\lforall {y \in P} {\pi(y) \leq y \implies x^* \leq y} \tag{ii}
\endmath

\sketch.
A idéia é tomar como $x^*$ o lub dos elementos da órbita do $\bottom$
e demonstrar que ele é o único strongly least fixpoint.

\proof.
Pelo \ref[chaincomplete_has_bottom], o $P$ possui $\bot$.
Consideramos a $\pi$-órbita do $\bot$:
$$
\bot, \pi(\bot), \pi(\pi(\bot)), \dotsc
$$
O conjunto dos seus membros é uma cadeia
(\ref[monotone_orbit_of_bottom_is_a_chain])
e logo possui lub pois $P$ é chain-completo.
Tome
$$
x^* \asseq \Join \set{ \bot, \pi(\bot), \pi^2(\bot), \dotsc }
$$
então.
Confirmamos que: (i) $x^*$ é um fixpoint (\ref[lub_of_orbit_is_a_fixpoint]);
e, ainda mais (ii) o strongly least (\ref[lub_of_orbit_is_the_srongly_least_fixpoint]).

%%}}}

%%{{{ x: monotone_orbit_of_bottom_is_a_chain 
\exercise.
%%%{{{ meta 
\label monotone_orbit_of_bottom_is_a_chain
%%%}}}

Para qualquer $\pi$ monótona a $\pi$-órbita de $\bot$ é uma cadeia.

%%}}}

%%{{{ x: lub_of_orbit_is_a_fixpoint 
\exercise.
%%%{{{ meta 
\label lub_of_orbit_is_a_fixpoint
%%%}}}

O $x^*$ da demonstração
do~\ref[Kleene_strongly_least_fixpoint] é um fixpoint.

%%}}}

%%{{{ x: lub_of_orbit_is_the_srongly_least_fixpoint 
\exercise.
%%%{{{ meta 
\label lub_of_orbit_is_the_srongly_least_fixpoint
%%%}}}

O $x^*$ da demonstração
do~\ref[Kleene_strongly_least_fixpoint] é o strongly
least fixpoint.

%%}}}

\endsection
%%}}}

%%{{{ Irreducible elements 
\section Elementos irredutíveis.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Boolean_algebras 
\section Álgebras booleanas.
%%%{{{ meta 
\label Boolean_algebras
\credits
    * Boole : álgebra
    ;;
%%%}}}

\endsection
%%}}}

%%{{{ Heyting_algebras 
\section Álgebras Heyting.
%%%{{{ meta 
\label Heyting_algebras
\credits
    * Heyting : álgebra
    ;;
%%%}}}

\endsection
%%}}}

%%{{{ Categories_and_posets 
\section Pouco de cats---categorias e posets.
%%%{{{ meta 
\label Categories_and_posets
%%%}}}

\endsection
%%}}}

%%{{{ Domain theory 
\section Teoria de domínios.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ x: rats_is_dense 
\problem.
%%%{{{ meta 
\label rats_is_dense
%%%}}}

Demonstre que o $\rats$ com sua ordem padrão é denso.

%%}}}

%%{{{ df: cofinito_em_nats 
\definition.
%%%{{{ meta 
\label cofinito_em_nats
\defines
    * cofinito
    ;;
%%%}}}

Chamamos um $A\subset \nats$ \dterm{cofinito} sse
seu complemento $\nats\setminus A$ é finito.

%%}}}

%%{{{ prob: family_of_cofinite_lattice 
\problem.
%%%{{{ meta 
\label family_of_cofinite_lattice
\defines
    * reticulado!de conjuntos
    ;;
%%%}}}

Mostre que as famílias
$$
\align
\scr L_1 &\asseq \setstt {A \subset \nats} {$A$ é cofinito}\\
\scr L_2 &\asseq \setstt {A \subset \nats} {$A$ é finito ou cofinito}
\endalign
$$
são \dterm{reticulados de conjuntos}, ou seja,
reticulados com relação de ordem $(\subset)$.

\solution
\proofpartstylize{Sobre o $\scr L_1$.}
Sejam $A, B \in \scr L_1$.
Pela definição então $\nats\setminus A$ e $\nats\setminus B$ são finitos.
Vou mostrar que $A\union B$ e $A\inter B$ são cofinitos, e logo pertencem ao
$\scr L_1$ também.
Calculamos 
$$
\align
\nats\setminus(A\union B) &=\paren{\nats\setminus A} \inter \paren{\nats\setminus B}\\
\nats\setminus(A\inter B) &=\paren{\nats\setminus A} \union \paren{\nats\setminus B},
\endalign
$$
logo os dois conjuntos no lado esquerdo são finitos como intersecção e união de
finitos respectivamente.
\eop
\proofpartstylize{Sobre o $\scr L_2$.}
Sejam $A, B \in \scr L_2$.
Separamos em casos:
\eop
\proofcase {Caso ambos finitos:}
Facilmente $A\union B$ e $A \inter B$ são finitos também,
como intersecção e união de conjuntos finitos.
Logo ambos pertencem ao $\scr L_2$.
\eop
\proofcase {Caso ambos cofinitos:}
Fechamos isso na demonstração sobre o $\scr L_1$.
\eop
\proofcase {Caso contrário:}
Temos um dos $A,B$ finito e o outro cofinito.
Sem perda de generalidade, suponha que $A$ finito, $B$ cofinito.
O $A\inter B$ é trivialmente finito como intersecção de finito com qualquer conjunto.
Logo $A\inter B \in \scr L_2$.
O $A\union B$ é cofinito, pois
$$
\nats\setminus(A \union B) = \paren{\nats\setminus A} \inter \paren{\nats\setminus B}
$$
que é finito para o mesmo motivo (intersecção com o $\nats\setminus B$ que é finito).
Logo $A\union B \in \scr L_2$.

%%}}}

%%{{{ prob: family_of_cofinite_not_complete_lattice 
\problem.
%%%{{{ meta 
\label family_of_cofinite_not_complete_lattice
%%%}}}

Mostre que nenhum dos $\scr L_1,\scr L_2$ do~\ref[family_of_cofinite_lattice]
é completo.

\hint
Seja $A_n \asseq \nats\setminus\set{0,2,\dotsc, 2n - 2}$ o $\nats$ sem os
primeiros $n$ números pares.
Mostre que:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.

\solution
Vamos demonstrar primeiramente a afirmação seguinte:
\emph{se $B \subset A_n$ para todo $n\in \nats$, então $B$ não é cofinito}.
\eop
\proofstylize{{\proofname} da afirmação:}
Suponha que para todo $n\in\nats$, $B \subset A_n$.
Logo
$$
\align
    B &\subset \Inter_{i=0}^\infty A_i\\
\intertext{e complementando os dois lado,}
\nats\setminus B
    &\supset \nats\setminus\Inter_{i=0}^\infty A_i\\
    &= \Union_{i=0}^\infty(\nats\setminus A_i)\\
    &= \Union_{i=0}^\infty(\set{0,2,\dotsc, 2n-2})\\
    &= 2\nats.
\endalign
$$
Como $2\nats$ é infinito, o $B$ não é cofinito.
\eop
Agora voltamos a demonstrar que nenhum dos $\scr L_1, \scr L_2$ é completo.
Considere o conjunto
$$
\cal S \asseq \set { A_0, A_1, A_2, \dotsc }
$$
Observe que
$\cal S \subset \scr L_1, \scr L_2$
pois todos os seus elementos são claramente cofinitos.
Mesmo assim, o $\Inter \cal S$ não é cofinito
$\Inter \cal S$ é o conjunto de todos os ímpares)
e logo não pertence em nenhum dos $\scr L_1, L_2$.

%%}}}

%%{{{ prob: knaster_tarski_fixpoint_full 
\problem Teorema Knaster--Tarski completo.
%%%{{{ meta 
\label knaster_tarski_fixpoint_full
%%%}}}

No contexto do~\ref[knaster_tarski_fixpoint], demonstre que
o subconjunto $\fixpoints F \subset L$ é um reticulado completo.

%%}}}

%%{{{ prob: banach_decomposition_theorem 
\problem Teorema de decomposição de Banach.
%%%{{{ meta 
\label banach_decomposition_theorem
%%%}}}

\TODO escrever.

%%}}}

%%{{{ prob: schroder_bernstein_lattice_proof 
\problem Teorema de Schröder--Bernstein.
%%%{{{ meta 
\label schroder_bernstein_lattice_proof
%%%}}}

Sejam $f : A \injto B$ e $g : B \injto A$ funções injetoras.
Usando o teorema fixpoint de Knaster--Tarski~\reftag[knaster_tarski_fixpoint]
demonstre que existe função bijetora $h : A \bijto B$.

\hint
O $\sset{\pset A}{\subset}$ é um reticulado completo.

\hint
Considere a função $F : \pset A \to \pset A$ definida pela
$$
F(X) = A \setminus \paren{ \img g {B \setminus {\img f X}} }.
$$
Mostre que ela é monótona.

\hint
Pelo teorema Knaster--Tarski~\reftag[knaster_tarski_fixpoint]
a $F$ tem um fixpoint $C \subset A$, e
$$
C = F(C)
\iff
C = A \setminus \paren{ \img g {B \setminus {\img f C}} }
\iff
A \setminus C = \img g {B \setminus {\img f C}}.
$$

\hint
Defina a desejada $h : A \bijto B$ por casos:
$$
h(x) = \knuthcases {
\dots, & se $x \in C$ \cr
\dots, & se $x \in A\setminus C$.
}
$$

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[DaveyPriestley],
\cite[gratzerlatticefirst],
\cite[gratzerlatticefoundation].

\cite[ynmnst: Cap.~6].

\cite[corilascar1: Cap.~2],
\cite[bellmachover: Cap.~4],
\cite[halmosboolean].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Category_theory 
\chapter Teoria das categorias.
%%%{{{ meta 
\label Category_theory
%%%}}}

%%{{{ What is a category? 
\section O que é uma categoria?.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.
%%%{{{ meta 
%%%}}}

\TODO Adicionar desenhos.

%%{{{ eg: one 
\example Um.
%%%{{{ meta 
%%%}}}

Aqui a categoria $\ONE$.
Ela possui exatamente um objeto (não importa qual) que denotarei por $\star$,
uma seta (não importa qual).
Necessariamente tal seta deve ter como source e target o único objeto disponível.
Devo também esclarecer qual é a identidade desse objeto, mas eu tenho uma única
opção para ela: só pode ser a única seta do $\star$ para ele mesmo.

%%}}}

%%{{{ eg: two 
\example Dois.
%%%{{{ meta 
%%%}}}

E aqui a categoria $\TWO$.
Ela possui exatamente dois objetos (não importa quais) que denotarei por $\star$ e $\bullet$,
uma seta de $\star$ para $\bullet$ e (necessariamente) mais duas setas (quais?).
Devo também esclarecer qual é a identidade desse objeto, mas eu tenho uma única
opção para ela: só pode ser a única seta do $\star$ para ele mesmo.

%%}}}

\endsection
%%}}}

%%{{{ First definitions 
\section Primeiras definições.
%%%{{{ meta 
\label First_consequences_of_group_laws
%%%}}}

\TODO Escrever.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[babylawvere],
\cite[arbibmanesarrows],
\cite[papalawvere].

\cite[goldblatttopoi].

\cite[awodeycats],
\cite[barrwellscatscs],
\cite[joyofcats],
\cite[borceuxhandbook1].

\cite[riehlcats],
\cite[maclanecats].

Sobre teoria dos grafos, já que foram mencionados neste capítulo:
umas introduções extensas são
os~\cite[bondymurty1976]
e~\cite[chartrandzhang].
Depois continua com~\cite[diestelgraph]
e~\cite[bondymurty2011].
Finalmente, um nível ainda mais avançado, \cite[bollobasmodern].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Set_theory 
\chapter Teoria dos conjuntos.
%%%{{{ meta 
\label Set_theory
%%%}}}

%%{{{ intro: sets like assembly 
\chapintro
Quando ``protoencontramos'' conjuntos no~\ref[Collections],
prometi que eles têm um papel importante para a \emph{fundação de matemática}.
Chegou a hora para ver o porquê!
Podemos traduzir todas as definições e relações matemáticas nessa
linguagem.  Nesse sentido, parece como uma assembly: uma linguagem
low-level onde podemos ``compilar'' toda a matemática, em tal modo
que cada definição, cada afirmação, cada teorema que demonstramos,
no final das contas, todos podem ser traduzidos para definições,
afirmações, teoremas e demonstrações, que envolvem apenas conjuntos
e a relação primitiva de \emph{pertencer}.
E \emph{nada} mais!
%%}}}

%%{{{ prim: set 
\primitive conjunto.
%%%{{{ meta 
\label set_primitive
\defines
    * ~x \in ~A  -- $x$ é um membro do conjunto $A$
    * conjunto
    ;;
%%%}}}

Aceitamos apenas duas \emph{noções primitivas} (\reftag[Axioms_and_primitive_notions]):
$$
\gathered
\text{ser conjunto}\\
\isSet(\dhole)
\endgathered
\qqqquad
\gathered
\text{pertencer}\\
\dhole\in\dhole
\endgathered
$$
Escrevemos \sq{$x \in A$} e pronunciamos
\utter{(o objeto) $x$ é um membro do (conjunto) $A$},
ou simplesmente \utter{$x$ pertence ao $A$}.

%%}}}

%%{{{ The_principle_of_purity 
\section O princípio da puridade.
%%%{{{ meta 
\label The_principle_of_purity
%%%}}}

%%{{{ df: urelement 
\definition urelemento.
%%%{{{ meta 
\label urelement
\indexes
    * átomo    seealso: urelemento
    ;;
\defines
    * urelemento
    ;;
%%%}}}

Chamamos de \dterm{átomos} ou de \dterm{urelementos}, os objetos que não são
conjuntos (mas podem pertencer a conjuntos).  Números, funções, pessoas,
sapos, planetas, etc.

%%}}}

%%{{{ principle: principle_of_purity 
\principle Princípio de Puridade.
%%%{{{ meta 
\headerize
\label principle_of_purity
\defines
    * princípio!da puridade
    ;;
\indexes
    * puridade    see: princípio
    ;;
%%%}}}

Tudo é conjunto.

%%}}}

%%{{{ seems like a bad idea 
\note Seria ruim assumir o princípio da puridade.
%%%{{{ meta 
%%%}}}

Como assim <<só tem conjuntos>>?
É pra jogar fora os objetos de todos os outros tipos que temos estudado
até agora?
E os números, as funções, os grupos?  E as pessoas?  Eu com certaza existo,
e meu leitor também, não é assim?  Se nosso universo é para ter apenas conjunto
só vamos conseguir falar de conjuntos.  E em matemática mesmo que os conjuntos
são importantes per se, temos muitas coisas também importantes que não são conjuntos.
Então não faz sentido nos limitar.
Ou talvez faz:

%%}}}

%%{{{ seems like a good idea 
\note Seria bom assumir o princípio da puridade.
%%%{{{ meta 
%%%}}}

Alguém falando sobre computadores e programação falou:
\quote
\wq{Tudo é $0$'s e $1$'s.  Não tem nada mais que isso.}
\endquote
Primeiramente temos que apreciar a simplicidade dum mundo
onde \emph{só tem bits}.
Porém, meu computador tem este texto que tô escrevendo
aqui pra ti; e umas músicas, fotos, vídeos---e mais coisas que
não são da tua conta.  Os programas que programamos e que usamos
manipulam números, conexões, documentos, ou até outros programas.
O que o rapaz acima quis dizer com sua afirmação então?
Bem, com certeza esse documento \emph{não é} uma seqüência
de $0$'s e $1$'s, mas \emph{pode ser representado fielmente}
por uma.  E é assim que meu computador o representa mesmo.
Pensando na mesma maneira, quando optamos para assumir
o princípio da puridade parece que vamos perder tudo que
não é conjunto como algo primitivo; mas se conseguirmos
\emph{representá-lo fielmente} dentro do mundo dos conjuntos
não vamos perder nada essencialmente.
Vamos voltar nesse assunto daqui a pouco
na~\reftag[Foundations_of_mathematics].

%%}}}

%%{{{ What would Zermelo do? 
\note O que Zermelo faria?.
%%%{{{ meta 
\label what_would_zermelo_do
%%%}}}

Zermelo não assumiu o princípio da puridade, nem sua negação.
Ou seja, talvez o universo tem urelementos, talvez não.
Como nenhum teorema dependeu na existência deles, então tudo continua válido
mesmo se escolher assumí-lo, \emph{algo que vamos fazer aqui},
comentando às vezes o que teria que mudar caso que não tivemos esse princípio.
Assim não vamos precisar do predicado $\isSet(\dhole)$ que teriamos de carregar
em muitas definições e demonstrações.

%%}}}

\endsection
%%}}}

%%{{{ FOL_translations_for_sets 
\section Traduções de e para a FOL de conjuntos.
%%%{{{ meta 
\label FOL_translations_for_sets
%%%}}}

%%{{{ The FOL of set theory 
\note A FOL da teoria de conjuntos.
%%%{{{ meta 
%%%}}}

Nessa linguagem de primeira ordem temos apenas um predicado não-constante:
o $\in$, de aridade 2, cuja interpretação canônica é ``\thole\ pertence ao \thole''.
Nosso universo aqui consiste (apenas) em conjuntos, ou seja
assumimos o princípio da puridade (\reftag[principle_of_purity]).

%%}}}

%%{{{ x: FOL_translations_for_sets_exercise 
\exercise.
%%%{{{ meta 
\label FOL_translations_for_sets_exercise
%%%}}}

Traduza as frases seguintes para a FOL da teoria de conjuntos.
\elist 1:
\li: Existe conjunto sem membros.
\li: O conjunto $x$ não tem membros.
\li: O conjunto $y$ tem membros.
\li: Existe conjunto com membros.
\li: O $x$ é um singleton.
\li: Existe conjunto com exatamente um membro.
\li: Existe conjunto com pelo menos dois membros.
\li: Os $x$ e $y$ têm exatamente um membro em comum.
\li: Todos os conjuntos tem o $x$ como membro.
\li: Existe conjunto que pertence nele mesmo.
\li: O $y$ consiste em todos os subconjuntos de $x$ com exatamente 2 elementos.
\li: Existe conjunto com exatamente dois membros.
\li: Para todos conjuntos $a$ e $b$ sua intersecção é conjunto.
\li: A união de $a$ e $b$ é um conjunto.
\li: O $x$ não pertence em nenhum conjunto.
\li: Existem conjuntos tais que cada um pertence no outro.
\li: Existe conjunto que não é igual com ele mesmo.
\endelist

%%}}}

%%{{{ Merely saying something doesn't make it true 
\note Apenas escrever algo não o torna verdade.
%%%{{{ meta 
%%%}}}

O fato que podemos expressar uma afirmação numa linguagem não quer dizer
que essa afirmação é válida.  Isso não é nada profundo: em português
também podemos escrever a frase ``a lua não é feita de queijo'', mas isso
não quis dizer que realmente não é---todos sabemos que é, certo?
Infelizmente existe um hábito de confundir as duas noções e usar como
``prova de veracidade de algo'' o fato que apenas esse algo foi escrito,
ou dito.\foot
Veja por exemplo argumentações de várias igrejas de várias religiões.
\toof
A afirmação da fórmula que tu achou para a última frase
do~\ref[FOL_translations_for_sets_exercise] por exemplo é falsa em nosso
mundo de conjuntos e ainda mais: é falsa em cada mundo possível, com qualquer
interpretação do símbolo $\in$!

%%}}}

%%{{{ A useful pattern 
\note Um padrão útil.
%%%{{{ meta 
%%%}}}

Muitas vezes queremos dizer que
existe um certo conjunto \emph{determinado por uma propriedade
característica}, ou seja, um conjunto $s$ que consiste em exatamente
todos os objetos que satisfazem um certo critério.
\eop
\emph{Como podemos dizer isso na FOL da teoria de conjuntos?}
Fácil!  Assim:
$$
\phantom{
\forall a
\forall b
\forall c
\dotsb
}
\alert{
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\tubrace{
\text{\vphantom|\xlthole}
}{critério}
}}}.
$$
Na maioria das vezes queremos afirmar a existência dum certo conjunto
dados conjuntos $a,b,c,\dotsc$.
Nesse caso usamos apenas o
$$
\forall a
\forall b
\forall c
\dotsb
\alert{
\exists s
\forall x
\bigparen{
x\in s \liff
{}
{\color{normal}
\text{\xlthole}
}}}.
$$
Esse padrão vai aparecer em muitos dos axiomas abaixo.

%%}}}

%%{{{ Abbreviations and syntactic sugar 
\note Abreviações e açúcar sintáctico.
%%%{{{ meta 
%%%}}}

Assim que conseguirmos descrever um conceito interessante com uma fórmula,
faz sentido introduzir uma notação, um novo predicado.
Por exemplo, nas (2) e (5) de~\ref[FOL_translations_for_sets_exercise],
tu achou fórmulas que afirmam que $x$ é vazio, e que $x$ é um singleton.
Faz sentido definir como abreviações então os predicados seguintes:
$$
\align
\Empty(x)
&\sugareq
\lnot \exists w \paren{ w \in x }\\
\Singleton(x)
&\sugareq
\exists w \bigparen{
w \in x
\land
\forall u \paren{ u \in x \limplies u = w }
}
\intertext{e os símbolos:}
a \subset b
&\sugareq \forall x \paren{ x \in a \limplies x \in b }\\
a \psubset b
&\sugareq a \subset b \land a \neq b.
\intertext{Lembre-se também nossa práctica onde usamos}
x \neq y
&\sugareq \lnot\, x = y,\\
x \nin y
&\sugareq \lnot\, x \in y,
\endalign
$$
etc.

%%}}}

\endsection
%%}}}

%%{{{ Classes vs. Sets (I) 
\section Classes \vs Conjuntos (I).
%%%{{{ meta 
%%%}}}

%%{{{ What is a class? 
\note O que é uma classe?.
%%%{{{ meta 
%%%}}}

Sem dúvida, a notação $\setstt x {\lthole}$
que temos usado até agora é natural e útil.
Ela denota a colecção de todos os objetos $x$ que satisfazem
a condição (ou ``passam o filtro'') que escrevemos no \lthole.
Dada uma condição definitiva $P$ então consideramos a colecção
$$
\setst x {P(x)}
$$
de todos os objetos que a satisfazem.
Provavelmente vocé já percebeu que eu evitei usar a palavra
\emph{conjunto}, pois reservamos essa palavra para
apenas os conjuntos-objetos do nosso universo.

%%}}}

%%{{{ df: class 
\definition Classe.
%%%{{{ meta 
\indexes
    * própria!classe    see: classe própria
    ;;
\defines
    * classe
    * classe!própria
    ;;
%%%}}}

Dada uma condição definitiva $P(\dhole)$ definimos a \dterm{classe}
$$
\classst x {P(x)}
$$
como um sinónimo da própria condição $P$!
Chamamos a classe $P$ \dterm{própria} sse não existe \emph{conjunto}
$S$ que satisfaz a propriedade:
$$
x \in S \iff P(x).
$$

%%}}}

%%{{{ eg: sets and proper classes 
\example.
%%%{{{ meta 
%%%}}}

Dados conjuntos $a$ e $b$,
das classes
$$
\mubrace{\classst x {x = a}} {\set a}
\qqquad
\mubrace{\classst x {x \in a \land x\in b}} {a\inter b}
\qqquad
\mubrace{\classst x {x \neq x}} {\emptyset}
\qqquad
\classst x {x = x}
$$
apenas a última é própria.
As outras são conjuntos mesmo!

%%}}}

%%{{{ warning: notational abuse 
\warning abuso notacional.
%%%{{{ meta 
%%%}}}

É muito comum abusar o símbolo $\in$, escrevendo
$$
x \in C
$$
mesmo quando $C$ é uma classe própria!
Nesse caso consideramos o $x \in C$ apenas como uma
abreviação do $C(x)$.
Em outras palavras, esse $\in$ não é um símbolo de relação da nossa FOL de
teoria de conjuntos, mas sim uma abreviação em nossa \emph{metalinguagem},
no mesmo jeito que $\iff$ também não é, mas o $\liff$ é.
Quando precisamos enfatizar essa diferença vamos usar um símbolo diferente:

%%}}}

%%{{{ notation: inclass 
\notation.
%%%{{{ meta 
\label inclass
\defines
    * ~x\inclass~C  -- o objeto $x$ está na classe $C$
    ;;
%%%}}}

Usamos o símbolo $\inclass$ na metalinguagem como ``pertence''
quando possivelmente o lado direito é uma classe própria.\foot
Seguimos aqui o exemplo dos símbolos de equivalência na metalinguagem
($\Longleftrightarrow$) e na linguagem-objeto de lógica ($\leftrightarrow$).
\toof
Com essa notação:
$$
x\inclass P
\defiff
\knuthcases {
P(x)    & se $P$ é uma classe própria\cr
x\in P  & se $P$ é um conjunto.
}
$$

%%}}}

\endsection
%%}}}

%%{{{ The first axioms of Zermelo 
\section Os primeiros axiomas de Zermelo.
%%%{{{ meta 
%%%}}}

%%{{{ ax: Extensionality 
\axiom Extensionalidade.
%%%{{{ meta 
\label extensionality
\defines
    * axioma!Extensionality
    ;;
%%%}}}

Todo conjunto é determinado por seus membros.
$$
\forall a \forall b
\paren{
\forall x
\paren{
x \in a
\liff
x \in b
}
\limplies
a = b
}
\axtag[extensionality=ZF1]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Qual o efeito disso em nosso mundo?
Ainda nem podemos garantir a existência de nada,
mas pelo menos sabemos dizer se duas coisas são iguais ou não.
Vamos logo garantir a existência dum conjunto familiar:

%%}}}

%%{{{ ax: Emptyset 
\axiom Emptyset.
%%%{{{ meta 
\label emptyset
\defines
    * axioma!Emptyset
    ;;
%%%}}}

Existe conjunto sem membros.
$$
\exists s \forall x
\paren{
x \nin s
}
\axtag[emptyset=ZF2]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

E já nosso mundo mudou completamente:
ganhamos nossa primeira peça, uma coisa para brincar:
\emph{um conjunto sem membros!}
E já estamos em posição de demonstrar nosso primeiro teorema,
seguido pela nossa primeira definição:

%%}}}

%%{{{ thm: uniqueness_of_emptyset 
\theorem Unicidade do conjunto vazio.
%%%{{{ meta 
\label uniqueness_of_emptyset
\indexes
    * unicidade!do $\emptyset$
    ;;
%%%}}}

O conjunto sem membros garantido pelo axioma~\axref[emptyset] é único.

\proof.
Suponha que $e, o$ são conjuntos ambos satisfazendo a propriedade:
$$
\forall x\paren{x \nin e}
\qqqquad
\forall x\paren{x \nin o}.
$$
Então a equivaléncia
$$
x\in e \iff x \in o
$$
é válida para todo $x$, pois ambos lados são falsos.
Logo, pelo axioma~\axref[extensionality], $e=o$.

%%}}}

%%{{{ df: emptyset_def 
\definition Conjunto vazio.
%%%{{{ meta 
\label emptyset_def
\defines
    * \emptyset  -- o conjunto vazio
    * conjunto!vazio
    ;;
%%%}}}

Denotamos por $\emptyset$ o \dterm{conjunto vazio} com a propriedade característica
$$
\forall x\paren{x\nin \emptyset}.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

\dots e agora parece que não podemos fazer muita coisa mais.
Precisamos novos axiomas:

%%}}}

%%{{{ ax: Pairset 
\axiom Pairset.
%%%{{{ meta 
\label pairset
\defines
    * axioma!Pairset
    ;;
%%%}}}

Dado um par de conjuntos, existe conjunto que consiste
em exatamente os conjuntos do par.
$$
\forall a
\forall b
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x = a
\lor
x = b
}
}
\axtag[pairset=ZF3]
$$

%%}}}

%%{{{ df: doubleton 
\definition Doubleton.
%%%{{{ meta 
\defines
    * \set{~a, ~b}  -- o conjunto doubleton de $a$ e $b$
    * doubleton
    ;;
%%%}}}

Dados $a$ e $b$ quaisquer, o conjunto que consiste nos $a$ e $b$
é chamado o \dterm{doubleton} de $a$ e $b$, e denotado por $\set {a, b}$.
Definimos assim o operador $\set{\dhole, \dhole}$.

%%}}}

%%{{{ Effects 
\note Efeitos.
%%%{{{ meta 
%%%}}}

Como isso muda nosso mundo?
Quais novas peças ganhamos em nosso xadrez?
Para ganhar a existência de algo usando o Pairset
precisamos dar a ele dois objetos,
pois começa com dois quantificadores universais ($\forall$)
antes de chegar no seu primeiro existencial ($\exists$):
``$\forall a\forall b \exists \dots$''.
Quais objetos vamos escolher para dá-lo?
Nosso mundo está tão pobre que é fácil responder nessa pergunta:
\emph{vamos usar como $a$ e como $b$ a única peça que temos: o $\emptyset$}.
Ganhamos então que:
$$
\exists s \forall x \bigparen { x \in s \liff \paren{ x = \emptyset \lor x = \emptyset }}
$$
ou seja, $\exists s \forall x \bigparen { x \in s \liff x = \emptyset }$,
ou seja, existe o conjunto
$$
\setst x {x = \emptyset}
$$
que acostumamos a denotá-lo por $\set \emptyset$.
Uma nova peça!\foot
Agora temos duas opções para cada usar nos $\forall$ do Pairset:
$\emptyset$, $\set\emptyset$.
\toof
E teoremas?

%%}}}

%%{{{ thm: singleton_thm 
\theorem Singleton.
%%%{{{ meta 
\label singleton_thm
%%%}}}

Dado conjunto $a$, existe um único conjunto cujo membro único é o $a$.
Formalmente,
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
x = a
}.
$$

\proof.
Bote $a\asseq a$ e $b\asseq a$ no Pairset~\axref[pairset]:
$$
\phantom{\forall a}
\exists s
\forall x
\bigparen{
x \in s
\liff
x = a
}.
$$
O conjunto cuja existência está sendo afirmada tem como membro único o $a$,
e graças ao~\axref[extensionality], ele é o único conjunto com essa propriedade.

%%}}}

%%{{{ df: singleton 
\definition.
%%%{{{ meta 
\label singleton
\defines
    * \set{~a}  -- o conjunto singleton de $a$, com membro único o $a$
    ;;
%%%}}}

Dado qualquer conjunto $a$, o conjunto cujo único membro é o $a$
é chamado o \dterm{singleton} de $a$, e denotado por $\set a$.
Definimos assim o operador $\set{\dhole}$.

%%}}}

%%{{{ x: infinitely_many_singletons_and_doubletons 
\exercise.
%%%{{{ meta 
\label infinitely_many_singletons_and_doubletons
%%%}}}

Mostre como construir uma infinidade de singletons
e uma infinidade de doubletons usando apenas os axiomas
\axref[extensionality], \axref[emptyset], e \axref[pairset].

\hint
\axref[emptyset]~\&~\ref[singleton_thm].

\hint
Comece com o $\emptyset$ e aplique iterativamente o operador $\set{\dhole}$.

\solution
Graças ao Emptyset~\axref[emptyset] temos o $\emptyset$.
Aplicamos iterativamente o operador $\set{\dhole}$ (\ref[singleton_thm])
e assim construimos a seqüência infinita de singletons
$$
\emptyset,
\set{\emptyset},
\set{\set{\emptyset}},
\set{\set{\set{\emptyset}}},
\set{\set{\set{\set{\emptyset}}}},
\dotsc
$$
Para os doubletons, uma abordagem seria aplicar o $\set{\emptyset,\dhole}$
em todos os membros da seqüência acima começando com o segundo.
Construimos assim a seqüência seguinte de doubletons:
$$
\set{\emptyset, \set{\emptyset}},
\set{\emptyset, \set{\set{\emptyset}}},
\set{\emptyset, \set{\set{\set{\emptyset}}}},
\set{\emptyset, \set{\set{\set{\set{\emptyset}}}}},
\dotsc
$$
Outra idéia simples de descrever para criar uma infinidade de doubletons
é a seguinte:
começa com o doubleton dos dois primeiros singletons que construimos acima:
\mathcol
D_0 &\defeq \set { \emptyset, \set{\emptyset} }
\intertext {
e fique aplicando o operador $\set{\dhole}$ em cada um dos membros:
}
D_1 &\defeq \set { \set{\emptyset}, \set{\set{\emptyset}} } \\
D_2 &\defeq \set { \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}} } \\
    &\eqvdots
\endmathcol

%%}}}

%%{{{ x: no_replacement_and_no_infinity_catch 
\exercise.
%%%{{{ meta 
\label no_replacement_and_no_infinity_catch
%%%}}}

Considere a tentativa seguinte de resolver o
\ref[infinitely_many_singletons_and_doubletons].
\eop
<<Para conseguir uma infinidade de doubletons $\cal D$ botamos:
\mathcol
D_0     &\defeq \set {\emptyset, \set{\emptyset}} \\
D_{n+1} &\defeq \setst {\set{s}} {s \in D_n}
\endmathcol
assim construimos o
\mathcol
\cal D
&= \set {D_0, \ D_1, \ D_2, \ \dotsc} \\
&= \set { \set{\emptyset,\set{\emptyset}}
        , \ \set{\set{\emptyset},\set{\set{\emptyset}}}
        , \ \set{\set{\set{\emptyset}},\set{\set{\set{\emptyset}}}}
        , \ \dotsc
        }
\endmathcol
que possui uma infinidade de doubletons como membros.>>
\eop
Ache todos os problemas com essa resolução.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Agora mesmo que nosso mundo mudou drasticamente---sim,
ganhamos uma infinidade de objetos---ele ainda tá bem limitado.

%%}}}

%%{{{ x: only_sets_with_up_to_two_elements 
\exercise.
%%%{{{ meta 
\label only_sets_with_up_to_two_elements
%%%}}}

Será que podemos garantir a existência de conjuntos com qualquer cardinalidade
finita que desejamos?

\hint
No exercício anterior construimos uns conjuntos com cardinalidade até 2.
Tente construir conjunto com cardinalidade 3.

\hint
Não tem como.  Por quê?

\solution
A construção dum conjunto com cardinalidade finita $n$ só pode ter sido garantida
ou pelo Emptyset, se $n=0$ (nesse caso o conjunto construido é o próprio $\emptyset$),
ou pelo Pairset, se $n>0$.  Mas o Pairset só constrói
conjuntos de cardinalidade $1$ ou $2$, dependendo se o aplicamos em conjuntos
iguais ou não (respectivamente).
Para concluir: nossos axiomas não são suficientemente poderosos para garantir
a existência de conjuntos com cardinalidades maiores que $2$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O próximo axioma não vai nos permitir---por enquanto---definir novos conjuntos.
Mas é a versão ``bug-free'' do princípio da comprehensão geral.
Com isso, o paradoxo de Russell se torna teorema!

%%}}}

%%{{{ ax: Separation 
\axiom Separation (schema).
%%%{{{ meta 
\label separation
\defines
    * axioma!Separation (schema)
    ;;
%%%}}}

{\rm Para cada propriedade $\phi(\dhole)$, o seguinte:}
para todo conjunto, a colecção de todos os seus membros que têm a propriedade $\phi$ é um conjunto.
$$
\forall w
\exists s
\forall x
\bigparen{
x\in s
\liff
\paren{
x\in w 
\land
\phi(x)
}
}
\axtag[separation=ZF4]
$$

%%}}}

%%{{{ x: how_many_axioms_so_far  
\exercise.
%%%{{{ meta 
\label how_many_axioms_so_far
%%%}}}

Quantos axiomas temos listado até este momento?

\hint
Não são 4.

\hint
Não é um número finito de axiomas!

\solution
Veja a discussão no~\reftag[axioms_vs_axiomatic_schemata].

%%}}}

%%{{{ axioms_vs_axiomatic_schemata 
\note Axiomas \vs esquemas axiomáticos.
%%%{{{ meta 
\label axioms_vs_axiomatic_schemata
\defines
    * esquema axiomático
    ;;
%%%}}}

Usamos o termo \dterm{esquema axiomático},
pois para cada fórmula $\phi(\dhole)$,
ganhamos um novo axioma pelo~\axref[separation].
Para enfatizar isso podemos até citá-lo como~\axref[separation]$_{\phi}$.
Antes de usá-lo então precisamos primeiramente escolher nossa fórmula $\phi$,
assim passando do \emph{esquema}~\axref[separation]
para o \emph{axioma}~\axref[separation]$_{\phi}$.
Agora como o axioma começa com $\forall w \exists \dots$,
precisamos escolher em qual conjunto $w$ nós vamos aplicá-lo,
para ganhar finalmente um novo conjunto.

%%}}}

%%{{{ df: set_builder_separation 
\definition.
%%%{{{ meta 
%%%}}}

Denotamos por
$$
\setst {x \in W} {\phi(x)}
$$
o conjunto único (pelo~\axref[extensionality]) garantido pelo~\axref[separation] quando o aplicamos com uma fórmula $\phi(x)$ para um conjunto $W$.

%%}}}

%%{{{ x: separation_yields_no_new_sets_yet 
\exercise.
%%%{{{ meta 
\label separation_yields_no_new_sets_yet
%%%}}}

Mostre que os conjuntos garantidos pelos~\axref[extensionality]--\axref[pairset]
são os mesmos com os conjuntos garantidos pelos~\axref[extensionality]--\axref[separation].

\hint
Usando o~\axref[separation], criamos subconjunto de um conjunto dado.

\hint
Quais são todas as cardinalidades possíveis para o conjunto em qual
usamos o~\axref[separation]?

%%}}}

%%{{{ How to use the Separation 
\note Como usar o Separation.
%%%{{{ meta 
%%%}}}

Queremos mostrar que uma certa classe $C$ de objetos realmente é um conjunto.
Para conseguir isso com o~\axref[separation],
precisamos construir (pelos axiomas!) um \emph{conjunto}
$W$ que contem todos os objetos da nossa classe $C$.
Em geral o $W$ vai ter mais elementos, um certo ``lixo'', que precisamos nos livrar.
E é exatamente com o~\axref[separation] que jogamos fora esse lixo,
usando uma apropriada fórmula $\phi$ como ``tesoura'' para cortar o $W$ e ficar só com o $C$,
garantido agora de ser conjunto.
Vamos ver uns exemplos desse uso,
enriquecendo nosso mundo com uns operadores conhecidos.

%%}}}

%%{{{ eg: define inters 
\example.
%%%{{{ meta 
%%%}}}

Defina o operador $\dhole\inter\dhole$.

\solution.
Dados conjuntos $a$ e $b$,
precisamos achar um conjunto $W$ que contenha todos os membros
da intersecção desejada.  Assim vamos conseguir definir o $a \inter b$
usando o~\axref[separation] com filtro a fórmula
$$
\phi(x)\asseq {x \in a \land x \in b}
$$
Observe que todos os elementos da $a \inter b$ são elementos tanto de $a$,
quanto de $b$.
Temos então duas opções.  Vamos escolher a primeira e construir o
$$
\setst {x \in a} {x \in a \land x \in b}
$$
Observamos que com essa escolha nem precisamos a parte ``$x \in a$'' em nosso filtro.
Chegamos assim em duas soluções para nosso problema:
$$
\setst {x \in a} {x \in b}
\qqqquad
\setst {x \in b} {x \in a}
$$

%%}}}

%%{{{ df: inters 
\definition Intersecção binária.
%%%{{{ meta 
\label inters_constructed
%%%}}}

Sejam conjuntos $a,b$.
Usando o~\axref[separation] definimos
$$
a\inter b \defeq \setst {x\in a} {x\in b}.
$$

%%}}}

%%{{{ x: define setminus 
\exercise.
%%%{{{ meta 
%%%}}}

Defina o operador $\dhole\setminus\dhole$.

\hint
Começa considerando dados conjuntos $a$ e $b$.
Procure um \emph{conjunto} que contenha todos os membros
da classe $a\setminus a$ que tu queres construir como conjunto.
Cuidado: nesse caso não temos as duas opções que tivemos
na~\ref[inters_constructed].

\solution
Usando o~\axref[separation] definimos:
$$
a\setminus b\defeq \setst {x \in a} {x \nin b}.
$$

%%}}}

%%{{{ x: cannot_define_union_yet 
\exercise.
%%%{{{ meta 
\label cannot_define_union_yet
%%%}}}

Tente definir os operadores $\dhole\union\dhole$ e $\dhole\symdiff\dhole$.

\hint
Dados conjuntos $a$ e $b$,
precisas achar um \emph{conjunto} $W$
que contenha todos os membros de $a\union b$,
para depois filtarar apenas os certos usando
como filtro a fórmula
$$
\phi(x) \asseq
x \in a \lor x \in b
$$
para a operação $\dhole\union\dhole$;
e similarmente para a $\dhole\symdiff\dhole$ só que
para essa o filtro vai ser a fórmula
$$
\phi(x)\asseq
\paren{x \in a \land x \nin b}
\lor
\paren{x \nin a \land x \in b}.
$$

\hint
Não tem como!

\solution
Não tem como!
Os axiomas que temos por enquanto não são suficientemente poderosos para
definir nenhuma dessas operações!

%%}}}

%%{{{ Blammenos_strikes_back 
\note Blammenos strikes back.
%%%{{{ meta 
\label Blammenos_strikes_back
%%%}}}

Estudamos o paradoxo de Russell, e a resolução do problema por Zermelo:
\emph{o princípio de comprehensão geral não é válido;
usando o separation axiom evitamos cair no paradoxo}.
Mas o aluno Blammenos pensou:
\dialogue
\who Blammenos:
Ok, eu vou trabalhar na teoria de Zermelo então.
Seja $A$ um conjunto.
Defino o
$$
r(A) \defeq \setst {x \in A} {x \nin x}
$$
que realmente é um conjunto, graças ao Separation
(que o usei com a fórmula $\phi(x) \asseq x\nin x$).
Mas agora faço a mesma pergunta que Russell fez: $r(A) \in r(A)$?
Assim consigo cair no mesmo paradoxo:
$$
r(A) \in r(A) \iff r(A) \nin r(A).
$$
Então Zermelo não resolveu o problema não!
\enddialogue

%%}}}

%%{{{ x: Blammenos_strikes_back_spot_the_mistake 
\exercise.
%%%{{{ meta 
\label Blammenos_strikes_back_spot_the_mistake
%%%}}}

Qual o erro do Blammenos essa vez?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Com o axioma da separação no lugar do princípio da comprehensão geral,
o paradoxo de {\Russell}\indexed[paradoxo!de Russell!vira teorema]Russell
vira-se um teorema muito útil que nos permite definir o operador
$\russell\dhole$ que
``escolhe definitivamente um objeto fora da sua entrada''.
Vamos?

%%}}}

%%{{{ thm: russells_paradox_to_theorem 
\theorem.
%%%{{{ meta 
\label russells_paradox_to_theorem
%%%}}}

Dado qualquer conjunto existe algo que não pertence nele.
Ainda mais, pelo menos um dos seus subconjuntos não pertence nele.

\sketch.
Tome um conjunto $A$.
Usamos a mesma idéia do paradoxo de Russell\Russell[de paradoxo para teorema],
só que essa vez não consideramos \emph{todos} os conjuntos que não
pertencem neles mesmo, mas apenas aqueles que pertencem ao $A$:
$$
\russell A \defeq \setst {x \in A} {x \nin x}.
$$
Concluimos que $\russell A \nin A$ pois o caso $\russell A \in A$
chega no mesmo absurdo de Russell.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Destacamos agora o operador que definimos
no~\ref[russells_paradox_to_theorem]:

%%}}}

%%{{{ df: russell_operator 
\definition.
%%%{{{ meta 
\label russell_operator
%%%}}}

Seja $a$ conjunto.  Definimos o operador $\russell\dhole$ pela
$$
\russell a \defeq \setst {x \in a} {x \nin x}.
$$
Chamamos o $\russell\dhole$ de \dterm{operador Russell}{\Russell[operador]}.

%%}}}

%%{{{ property: russell_operator_property 
\property.
%%%{{{ meta 
\label russell_operator_property
%%%}}}

O operador Russell retorna um objeto (um conjunto)
que não pertence à sua entrada:
$$
\lforall a {\russell a \nin a}.
$$

\proof Demonstrado no~\ref[russells_paradox_to_theorem].

%%}}}

%%{{{ Univ is not a set 
\corollary.
%%%{{{ meta 
\label Univ_is_not_a_set
%%%}}}

O universo $\Univ$ não é um conjunto.

\proof.
Se $\Univ$ fosse um conjunto, aplicando o teorema teriamos um conjunto $\russell \Univ$
com $\russell\Univ \nin \Univ$, absurdo pela definição do $\Univ$.

%%}}}

%%{{{ ax: Powerset 
\axiom Powerset.
%%%{{{ meta 
\label powerset
\defines
    * axioma!Powerset
    ;;
%%%}}}

Para cada conjunto a colecção de todos os seus subconjuntos é um conjunto.
$$
\forall a
\exists s
\forall x
\paren{
x\in s
\liff
x \subset a
}
\axtag[powerset=ZF5]
$$

%%}}}

%%{{{ df: pset 
\definition.
%%%{{{ meta 
\indexes
    * conjunto!de partes   see: powerset
    * conjunto!potência    see: powerset
    ;;
\defines
    * \pset {~a}  -- o conjunto de partes (powerset) de $a$
    * powerset
    ;;
%%%}}}

Dado conjunto $a$, escrevemos
$\pset a$
para o conjunto garantido pelo Powerset~\axref[powerset],
que é único graças ao Extensionality~\axref[extensionality].
Definimos assim o operador $\pset\dhole$.

%%}}}

%%{{{ x: powersingleton 
\exercise.
%%%{{{ meta 
\label powersingleton
%%%}}}

Seja $a$ conjunto.  Mostre que a classe
$$
\classst { \set x } { x \in a }
$$
de todos os singletons de elementos de $a$ é conjunto.

\solution
Queremos mostrar que dado conjunto $a$, a classe
$$
\classst { \set x } { x \in a }
$$
é conjunto.
Basta só achar um conjunto $W$ tal que todos os $\set x \in W$.
Botamos apenas o $W\asseq\pset a$ que sabemos que é conjunto
pelo Powerset~\axref[powerset], assim ganhando o conjunto
$$
\setst { z\in \pset a } { \lexists {x \in a} {z = \set x} }.
$$
pelo Separation~\axref[separation].

%%}}}

%%{{{ x: arbitrarily_large_finite_sets 
\exercise.
%%%{{{ meta 
\label arbitrarily_large_finite_sets
%%%}}}

Usando
os~\axref[extensionality]+\axref[emptyset]+\axref[pairset]+\axref[powerset],
podemos construir conjunto com cardinalidade finita, arbitrariamente grande?

\solution
Sim.
Seja $n\in\nats$.
Precisamos construir um conjunto $A$ com $\card A \geq n$.
Se $n=0$, graças ao Emptyset~\axref[emptyset] tomamos $A\asseq\emptyset$.
Se $n>0$, iteramos o operador $\pset\dhole$ até chegar num conjunto
cuja cardinalidade supera o $n$.

%%}}}

%%{{{ x: still_missing_some_finite_cardinalities 
\exercise.
%%%{{{ meta 
\label still_missing_some_finite_cardinalities
%%%}}}

Usando os~\axref[extensionality]+\axref[emptyset]+\axref[pairset]+\axref[powerset], podemos construir conjunto com cardinalidade finita qualquer?

\hint
Não.  Por quê?

\hint
Como vimos no~\ref[only_sets_with_up_to_two_elements],
usando os \axref[extensionality]+\axref[emptyset]+\axref[pairset]
podemos consturir apenas conjuntos com cardinalidades $0$, $1$, e $2$.
Se aplicar o Powerset~\axref[powerset] num conjunto $A$ com cardinalidade
finita $n$, qual será a cardinalidade do $\pset A$?

\solution
Não.
Por exemplo, não temos como construir conjunto com cardinalidade $3$,
pois uma tal construção deveria ``terminar'' com uma aplicação do Powerset
(o Emptyset constrói conjuntos com cardinalidade $0$, e o Pairset com $1$ ou $2$).
Mas aplicando o Powerset para conjunto com cardinalidade finita $n$,
construimos conjunto com cardinalidade $2^n$, e $3$ não é uma potência de $2$.

%%}}}

%%{{{ Games 
\note Jogos.
%%%{{{ meta 
%%%}}}

Como descobrimos no~\ref[still_missing_some_finite_cardinalities]
não existe estratégia\indexed[estratégia!vencedora]\ vencedora num jogo
onde nosso oponente joga primeiro escolhendo um número $n\in\nats$,
e nosso objectivo é construir pelos axiomas um conjunto
com cardinalidade $n$.
Se ele escolher como $n$ um dos
$$
0, 1, 2, 2^2, 2^{2^2}, 2^{2^{2^2}}, \dotsc
$$
temos como ganhar, mas caso contrário, não.
\eop
Por outro lado, num jogo onde nosso objectivo é construir pelos
axiomas um conjunto com cardinalidade \emph{pelo menos} $n$,
como vimos no~\ref[arbitrarily_large_finite_sets],
temos uma estratégia vencedora sim:
comece com uma aplicação do Emptyset~\axref[emptyset]
para ganhar o $\emptyset$ e aplique iterativamente o
Powerset~\axref[powerset] construindo assim conjuntos de
cardinalidades $0$ (do próprio $\emptyset$),
$1$, $2$, $2^2$, $2^{2^2}$, etc.,
até chegar num conjunto com cardinalidade maior-ou-igual
ao~$n$ escolhido por nosso oponente.

%%}}}

%%{{{ x: how many iterations of powerset do we need to win? 
\exercise.
%%%{{{ meta 
%%%}}}

Quantas iterações precisamos para conseguir conjunto com cardinalidade $n\in\nats$?

%%}}}

%%{{{ x: all_finite_cardinalities 
\exercise.
%%%{{{ meta 
\label all_finite_cardinalities
%%%}}}

Usando os~\axref[extensionality]+\axref[emptyset]+\axref[separation]+\axref[powerset], podemos construir conjunto com cardinalidade finita qualquer?

\hint
Dado $n\in\nats$ construa primeiramente um conjunto com cardinalidade
maior-ou-igual, e aplique o Separation~\axref[separation] para
ficar com apenas $n$ elementos.
Formalmente, use indução!

%%}}}

%%{{{ ax: Unionset 
\axiom Unionset.
%%%{{{ meta 
\label unionset
\defines
    * axioma!Unionset
    ;;
%%%}}}

Para cada conjunto, sua união (a colecção de todos os membros dos seus membros) é um conjunto.
$$
\forall a
\exists s
\forall x
\bigparen{
x\in s
\liff
\exists w
\paren{
x \in w
\land
w \in a
}
}
\axtag[unionset=ZF6]
$$

%%}}}

%%{{{ df: unionset 
\definition.
%%%{{{ meta 
\defines
    * \Union {~a}  -- a união de $a$ (operação unária)
    * unionset
    ;;
%%%}}}

Dado conjunto $a$, escrevemos
$\Union a$
para o conjunto garantido pelo Unionset~\axref[unionset],
que é único graças ao Extensionality~\axref[extensionality].
Definimos assim o operador da \dterm{união arbitrária} $\Union\dhole$.

%%}}}

%%{{{ x: union_and_symdiff_constructed 
\exercise.
%%%{{{ meta 
\label union_and_symdiff_constructed
%%%}}}

Defina os operadores binários $\union$ e $\symdiff$.

\hint
(Sobre o operador $\union$.)
Combine os operadores $\Union\dhole$ e $\set{\dhole,\dhole}$!

\hint
(Sobre o operador $\symdiff$.)
Suponha $a,b$ conjuntos.  Temos
$a\symdiff b\subset a\union b$.

\solution
Sejam conjuntos $a,b$.
Definimos:
$$
\align
a \union b   &\defeq \Union\set{a,b}\\
a \symdiff b &\defeq \setst {x \in a\union b} {x \nin a\inter b}
\endalign
$$

%%}}}

%%{{{ x: complement_impossible 
\exercise.
%%%{{{ meta 
\label complement_impossible
%%%}}}

Como podemos definir o operador unitário $\complement{\cdot}$ de \emph{complemento},
tal que $\complement a$ é o conjunto de todos os objetos que não pertencem ao $a$?

\hint
De jeito nenhum!  Por quê?

\solution
Não podemos.
Dado conjunto $a$, se seu complemento $\complement a$ também fosse conjunto,
poderiamos aplicar o $\union$ para construir o $a\union\complement a$.
Mas pela definição dos $\union$ e $\complement a$, temos agora
$$
x\in a\union \complement a
\iff
x\in a \lor x \nin a
$$
ou seja, todos os objetos $x$ satisfazem a condição na direita!
Em outras palavras $a \union \complement a$ seria o próprio universo $\Univ$
que sabemos que não é um conjunto.

%%}}}

%%{{{ x: Inter_constructed 
\exercise.
%%%{{{ meta 
\label Inter_constructed
%%%}}}

Defina o operador unário $\Inter$,
aplicável em qualquer conjunto não vazio.
Precisamos o Unionset~\axref[unionset]?

\solution
Dado conjunto $A\neq\emptyset$, definimos
$$
\Inter A
\defeq
\setst {x \in \Union A} {\lforall {a \in A} {x \in a}}.
$$

%%}}}

%%{{{ thm: finite_set_constructor 
\theorem.
%%%{{{ meta 
\label finite_set_constructor
%%%}}}

Dados $a_1, a_2, \dotsc, a_n$ (onde $n\in\nats$) existe conjunto único
cujos membros são exatamente os $a_1$, $a_2$, \dots, $a_n$.

\proof Demonstrarás no~\ref[finite_set_constructor_proof].

%%}}}

%%{{{ remark: finite_set_constructor_notation 
\remark.
%%%{{{ meta 
%%%}}}

Pelo~\ref[finite_set_constructor] ganhamos para qualquer $n\in\nats$
o operador $n$-ário
$$
\set{\dhole,\dhole,\dotsc,\dhole}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Construction trees 
\section Árvores de construção.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um jeito bem econômico e claro para descrever uma construção
e usando árvores.
Os exemplos seguintes servem para explicar essa idéia.

%%}}}

%%{{{ eg: Tree explanation 
\example.
%%%{{{ meta 
%%%}}}

Queremos demonstrar que $\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$
é um conjunto, ou seja, construí-lo.
Escrevemos:
{Pelo Emptyset~\axref[emptyset], $\emptyset$ é um conjunto.
Pelo Pairset~\axref[pairset] aplicado com $a,b\asseq\emptyset$ temos
que $\set{\emptyset,\emptyset}$ também é conjunto.
Mas, pelo Extensionality~\axref[extensionality],
$\set{\emptyset,\emptyset}=\set{\emptyset}$.
Agora, novamente pelo Pairset~\axref[pairset] essa vez
aplicado com $a\asseq\emptyset$ e $b\asseq\set{\emptyset}$
temos que $\set{\emptyset, \set{\emptyset}}$ é um conjunto.
Aplicando uma última vez o Pairset~\axref[pairset] com
$a\asseq\emptyset$ e $b\asseq \set{\emptyset, \set{\emptyset}}$,
conseguimos construir o conjunto
$\set{ \emptyset, \set{\emptyset, \set{\emptyset}}}$.
}
Podemos representar essa construção em forma de árvore:
$$
\PROOFmr {
\I0------------- {\axref[emptyset]}
    {\emptyset}
                               \I0------------- {\axref[emptyset]}
                                   {\emptyset}
                                                           \I0------------- {\axref[emptyset]}
                                                               {\emptyset}
                                                                             \I0------------- {\axref[emptyset]}
                                                                                 {\emptyset}
                                                           \I2=============================== {\axref[pairset]}
                                                                    {\set{\emptyset}}
                           \I2-------------------------------------------------------- {\axref[pairset]}
                                 {\set{\emptyset, \set{\emptyset}}}
\I2------------------------------------------------------------------ {\axref[pairset]}
         {\set{\emptyset, \set{\emptyset, \set{\emptyset}}}}
}
$$
onde pulamos ou deixamos alguns passos implícitos,
como o uso de Extensionality~\axref[extensionality] nesse caso.
(As vezes indicamos com uma dupla linha tais omissões mas
seu uso pode ter outros significados também.)
Usamos agora essa construção para construir um conjunto de cardinalidade $3$:
$$
\PROOFmrw {
   \I0------------- Emptyset
       {\emptyset}
                                 \I0------------- Emptyset
                                     {\emptyset}
                                                           \I0------------- Emptyset
                                                               {\emptyset}
                                                                             \I0------------- Emptyset
                                                                                 {\emptyset}
                                                           \I2------------------------------- Emptyset
                                                                     \set{\emptyset}
                           \I2-------------------------------------------------------- Pairset
                                 \set{\emptyset, \set{\emptyset}}
\I2------------------------------------------------------------------ Pairset
            \set{\emptyset, \set{\emptyset, \set{\emptyset}}}
\I1-------------------------------------------------------------------------- Powerset
      \set{\emptyset, \set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}},
           \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}
\I1-------------------------------------------------------------------------- {Separation, $\phi(x)\asseq \exists w(w\in x)$}
        \set{\set{\emptyset}, \set{\set{\emptyset, \set{\emptyset}}},
             \set{\emptyset, \set{\emptyset, \set{\emptyset}}}}
}
$$
Observe que para usar o Separation \axref[separation] precisamos especificar qual é a fórmula--filtro.

%%}}}

%%{{{ eg: tree_construction_with_open_leaves 
\example.
%%%{{{ meta 
\label tree_construction_with_open_leaves
%%%}}}

Sejam $a,b$ conjuntos.
Mostre que $\set{b, \set{\emptyset, \set{a}}}$ é conjunto.

\solution.
$$
\PROOFmrw {
      \A
       b
            \I0------------- Empty
                {\emptyset}         \A
                                     a
                               \I1========= Singleton
                                   \set{a}
            \I2---------------------------- Pair
                 \set{\emptyset, \set{a}}
\I2------------------------------------- Pair
     \set{b, \set{\emptyset, \set{a}}}
}
$$
Onde deixamos as ``folhas'' da árvore $a,b$ ``sem fechar'', pois
correspondem realmente em nossas hipotéses: os conjuntos $a,b$ são dados!
Observe também que ``Singleton'' se-refere no~\ref[singleton_thm].

%%}}}

%%{{{ x: tree_construction_practice 
\exercise.
%%%{{{ meta 
\label tree_construction_practice
%%%}}}

Sejam $a,b,c,d$ conjuntos.
Mostre pelos axiomas que os seguintes também são:
\mathcol
A &= \set{a,b,c,d} \\
B &= \set{a,b, \set{c,d}} \\
C &= \setst x {x \subset a\union b\union c\union d \mland \text{$x$ tem exatamente 2 membros}}
\endmathcol
Use a método de árvores para umas construções e outras faça escrevendo em texto mesmo.
É bom practicar os dois jeitos.

\solution
Como $a,b$ são conjuntos, pelo Pairset o $\set{a,b}$ também é.
Similarmente o $\set{c,d}$ é conjunto, e aplicando mais uma vez o Pairset neles
temos que o $\set{\set{a,b},\set{c,d}}$ é conjunto.
Agora aplicando o Union nele o ganhamos o $A$.
\eop
\bigskip
\noi
Aqui uma construção do $B$ pelos axiomas, em forma de árvore:
$$
\PROOFmrw {
    \A a     \A b
\I2---------------  Pair
      \set{a,b}
                       \A c     \A d
                   \I2---------------  Pair
                         \set{c,d}
                  \I1----------------- Singleton
                      \set{\set{c,d}}
\I2------------------------------------ Pair
       \set{\set{a,b}, \set{c,d}}
  \I1------------------------------ Union
             \set{a,b,c,d}
}
$$
\eop
\bigskip
\noi
Para o $C$, usamos o Separation~\axref[separation]
no $\pset \paren{\Union A}$, que é conjunto graças aos Union~\axref[unionset]
\& Powerset~\axref[powerset]:
$$
\PROOFmrw {
        \A
         A
  \I1---------- Union
      \Union A
\I1--------------- Powerset
    \pset\Union A
\I1--------------- {Separation, $\phi$}
          C
}
$$
onde na aplicação do Separation~\axref[separation] usamos a fórmula
$$
\phi(x) \asseq
\mubrace {
\exists u \exists v
\paren{ u \neq v \land \forall w(w \in x \liff w = u \lor w = v ) }
} {\Doubleton(x)}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Foundations_of_mathematics 
\section Fundações de matemática.
%%%{{{ meta 
\label Foundations_of_mathematics
%%%}}}

%%{{{ A low-level language for mathematics 
\note Uma linguagem ``low-level'' para matemática.
%%%{{{ meta 
\indexes
    * açúcar!sintáctico
    ;;
%%%}}}

Fazendo uma analogia entre matemática e programação,
dizemos que a teoria de conjuntos pode servir como uma certa low-level linguagem
em qual podemos ``compilar'' (traduzir, representar, \dots)~todos os high-level
conceitos que nos interessam em matemática!
As ``definições'' (assim entre aspas) que temos usado até agora para os vários
tipos e conceitos que encontramos não foram formais.
Nossa tarefa então aqui é tirar essas aspas.
Dar uma definição formal dum conceito significa defini-lo dentro da
teoria de conjuntos.
No final das contas, tudo vai ser representado dentro da FOL da teoria de conjuntos,
pegando como noções primitívas \emph{apenas} os ``$\isSet(\dhole)$'' de ``ser conjunto''
e o ``$\dhole\in\dhole$'' de ``pertencer''.
Já temos uma primeira biblioteca construida até agora,
um certo \emph{açúcar sintáctico}.
E cada vez que conseguimos compilar algo dentro da teoria de conjuntos,
ganhamos não apenas o próprio algo para seus usos e suas aplicações,
mas também algo mais para usar para nossas próximas compilações.

%%}}}

%%{{{ Our inventory so far 
\note Nosso inventório até agora.
%%%{{{ meta 
%%%}}}

Vamos resumir todos os operadores e predicados que temos já definido
dentro da teoria de conjuntos, usando apenas os axiomas que encontramos
até agora.
Temos:
$$
\gather
\emptyset \;;\\
\set \dhole \;;\quad
\set{\dhole,\dhole} \;;\quad
\set{\dhole,\dotsc,\dhole} \;;\quad
\setst {x \in \dhole} {\phi(x)} \;;\\
\dhole \inter \dhole \;;\quad
\dhole \union \dhole \;;\quad
\dhole \setminus \dhole \;;\quad
\dhole\symdiff \dhole \;;\quad
\Union \dhole \;;\quad
\pset \dhole
\endgather
$$
{e com o proviso de $a$ conjunto com $a\neq\emptyset$ também o}
$$
\dsize\Inter a\,.
$$
Observe-se então que de todos esses operadores, o $\Inter\dhole$ é
o único operador \emph{parcial}.
Mas isso não é nada novo como conceito:
no final das contas, estamos usando operadores parciais o tempo todo
trabalhando com números reais: o $\dhole / \dhole$ por exemplo
não é definido quando seu segundo argumento é o $0$, e a mesma coisa
sobre a operação (unária) de inverso: o $0^{-1}$ também não é definido.

%%}}}

%%{{{ From specification to implementation 
\note De especificação para implementação.
%%%{{{ meta 
%%%}}}

Quando queremos representar algum \emph{tipo} de coisa
dentro do nosso mundo de conjuntos,
precisamos esclarecer qual é a \emph{especificação} desse tipo.
Quais propriedades desejamos dos objetos desse tipo?
O que precisamos para construir um objeto desse tipo?
Quando identificamos dois objetos desse tipo e os consideramos iguais?
Como podemos usar os objetos desse tipo?
Qual é a \dq{interface} deles?
Talvez ajuda pensar que nossa tarefa é semelhante à de um \dq{vendedor
de implementações matemáticas}.
Nossos clientes são os próprios matemáticos que desejam usar certos
tipos de objetos matemáticos, e nos seus pedidos eles estão esclarecendo
quais são as propriedades que eles precisam.
Nosso trabalho então será:
\emph{implementar} essa especificação, ou seja,
\emph{representar fielmente} esses tipos e conceitos como conjuntos.
Para conseguir isto:
(1) \emph{definimos} os conceitos e objetos como conjuntos;
(2) \emph{demonstramos} que nossa implementação realmente atende as especificações.
Muitas vezes vamos até oferecer uma \emph{garantia de unicidade}
para mostrar para nosso cliente-matemático que ele não precisa
procurar outras implementações alternativas da nossa concorrência,
pois \emph{essencialmente} nem tem!

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nosso próximo trabalho será representar as tuplas,
e por isso vamos analisar em muito detalhe essa especificação.
Depois relaxamos um pouco deixando uns detalhes tediosos como
``óbvios''.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_tuples 
\section Construindo as tuplas.
%%%{{{ meta 
\label Constructing_the_tuples
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
\label tup_specification
%%%}}}

Vamos começar com o trabalho de implementar tuplas de tamanho 2,
ou seja \emph{pares ordenados}.
Precisamos então definir \emph{um} operador
$\tup{\dhole,\dhole}$ que atende as especificações.
Primeiramente:
$$
\tup{x, y} = \tup{x', y'} \implies x = x' \mland y=y'.
\mtag[spec_tup1=TUP1]
$$
Mas precisamos mais que isso.
Dados conjuntos $A$ e $B$ queremos que
$$
\text{a \emph{classe}}
\quad
A\times B = \classst z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
\quad
\text{é um \emph{conjunto}}.
\mtag[spec_tup2=TUP2]
$$
Lembrando a idéia de tupla como black\indexed[black box!de tupla]\ box,
a interface que desejamos consiste em duas operações,
as \emph{projecções}
$\outl$ e $\outr$ tais que
$$
\outl \tup{x,y} = x
\qqqquad
\text e
\qqqquad
\outr \tup{x,y} = y.
$$
Queremos definir também um predicado $\Pair(\dhole)$
para afirmar que um certo objeto representa um par ordenado.
Isso é facil:
$$
\Pair(z) \defiff
\exists x
\exists y
\paren{
z = \tup {x,y}
}
$$
Finalmente, precisamos e confirmamos:
$$
\Pair(z) \iff z = \tup{ \outl(z), \outr(z) }.
$$
Anotamos também que assim que definir \emph{funções} dentro
da teoria de conjuntos, vamos mostrar a existência das funções
$$
\xalignat2
\outl &\eqtype A\times B \to A &  \outr&\eqtype A\times B \to B\\
\outl\tup{x,y} &= x            &  \outr\tup{x,y} &= y
\endxalignat
$$
para todos os conjuntos $A$ e $B$.

%%}}}

%%{{{ x: op1_converse_direction_by_logic 
\exercise.
%%%{{{ meta 
\label op1_converse_direction_by_logic
%%%}}}

No \mref[spec_tup1] botamos \sq{$\Longrightarrow$} em vez de \sq{$\Longleftrightarrow$}.
Por quê?  O que acontece com a \sq{$\Longleftarrow$}?

\hint
Como a direção \sq{$\Longleftarrow$} poderia ser inválida?

\solution
A direção \sq{$\Longleftarrow$} é garantida pela nossa lógica:
podemos substituir iguais por iguais em qualquer expressão.

%%}}}

%%{{{ x: first_attempt_pair 
\exercise.
%%%{{{ meta 
\label first_attempt_pair
%%%}}}

Demonstre que a operação
$$
\tup{x,y} \defeq \set{x,y}
$$
satisfaz uma das \mref[spec_tup1]~\&~\mref[spec_tup2]
mas não a outra, então essa
\emph{não} é uma implementação de par ordenado

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Nossa primeira tentativa não deu certo.
Mesmo assim é realmente possível implementar pares ordenados
como conjuntos!  Como?

%%}}}

\spoiler

%%{{{ df: kuratowski_pair 
\definition par de Kuratowski.
%%%{{{ meta 
\label kuratowski_pair
\credits
    * Kuratowski : par
    ;;
\indexes
    * par!de Kuratowski
    ;;
%%%}}}

Sejam $x,y$ objetos.
Definimos
$$
\tup{x,y} \defeq \kurpair x y.
$$

%%}}}

%%{{{ x: kurpair_satisfies_tup0 
\exercise.
%%%{{{ meta 
\label kurpair_satisfies_tup0
%%%}}}

Mostre pelos axiomas que o operador $\tup{\dhole, \dhole}$ de Kuratowski
é bem-definido, ou seja: dados objetos $x,y$, o $\tup{x,y}$ é conjunto.

%%}}}

%%{{{ ppty: kurpair_satisfies_tup1 
\property.
%%%{{{ meta 
\label kurpair_satisfies_tup1
%%%}}}

O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\mref[spec_tup1].

\sketch.
Suponha $\tup{x,y} = \tup{x',y'}$.
Logo
$$
\kurpair x y = \kurpair {x'} {y'}.
$$
Precisamos deduzir que $x=x'$ e $y=y'$ mas ainda não é claro.
O que temos é apenas igualdade desses dois conjuntos, que não
garanta o que queremos imediatamente.
Não podemos concluir nem que
$$
\alignat3
\set {x} &= \set {x'}
&\qquad&\mland\qquad&
\set {x,y} &= \set {x',y'},\\
\intertext{%
pois pela definição de igualdade de conjuntos \axref[extensionality]
sabemos apenas que cada membro do conjunto no lado esquerdo
é algum membro do conjunto no lado direito e vice-versa.
Então, talvez
}
\set {x} &= \set { x',y'}
&\qquad&\mland\qquad &
\set {x,y} &= \set {x'}.
\endalignat
$$
Precisamos então separar em casos:
$x = y$ ou não.
Em cada caso argumentamos usando o \axref[extensionality] e a
cardinalidade dos conjuntos para progressar até chegar nos desejados
$x=x'$ e $y=y'$.

%%}}}

%%{{{ ppty: kurpair_satisfies_tup2 
\property.
%%%{{{ meta 
\label kurpair_satisfies_tup2
%%%}}}

O operador $\tup{\dhole, \dhole}$ de Kuratowski satisfaz a~\mref[spec_tup2].

\proof.
Sejam $A,B$ conjuntos.
Precisamos mosrar que a classe
$$
A\times B = \classst z {
\pexists {x \in A}
\lexists {y \in B}
{z = \tup {x,y}}
}
$$
é um conjunto.
Como já temos escrita a classe nessa forma, basta achar um conjunto $W$
que contem todos os pares que queremos, e aplicar esse mesmo filtro
para ficar apenas com eles mesmo.
Como parece o aleatório $\tup{a,b} \in A\times B$?
$$
a\in A
\mland
b\in B
\implies
\tup{a,b} = \kurpair a b \in \mathord{?}
$$
Vamos ver:
\proofsteps
\steptnb {Suponha $a\in A$ e $b\in B$.}
\steptby {Logo $a,b \in A\union B$.}     {$A,B \subset A \union B$}
\steptnb {Logo $\set {a}, \set{a,b} \subset A \union B$.}
\steptnb {Logo $\set {a}, \set{a,b} \in \pset\paren{A \union B}$.}
\steptnb {Logo $\kurpair a b \subset \pset\paren{A \union B}$.}
\steptnb {Logo $\kurpair a b \in \pset\pset\paren{A \union B}$.}
\steptnb {Logo $\tup {a, b} \in \pset\pset\paren{A \union B}$.}
\endproofsteps
Tome então $W\asseq \pset\pset\paren{A \union B}$
e defina
$$
A \times B \defeq \setst { z \in \pset\pset\paren{A\union B} } {
\pexists {x \in A} \lexists {y \in B} {z = \tup {x,y}}
}
$$
que é conjunto graças ao Separation~\axref[separation].

%%}}}

%%{{{ Being agnostic 
\note Sendo agnósticos.
%%%{{{ meta 
\defines
    * agnóstico
    ;;
\credits
    * Kuratowski
    * Wiener
    ;;
%%%}}}

Acabamos de encontrar \emph{um} operador de par ordenado:
do Kuratowski.
Ele não é o único possível, mas para continuar com nossa teoria,
precisamos apenas mostrar que existe um.
Vamos usar o símbolo $\tup{\dhole,\dhole}$ sem esclarecer se realmente é
a implementação de Kuratowski que usamos, ou alguma outra implementação.
Tomando cuidado, sobre esse operador nos permitimos usar
\emph{apenas as propriedades da sua especificação e nada mais}:
as \mref[spec_tup1]~\&~\mref[spec_tup2] da \reftag[tup_specification].
Falamos então que estamos sendo $\tup{{}\commaop{}}$-\dterm{agnósticos}.
Por exemplo, não podemos afirmar que $\set {x} \in \tup {x,y}$.
Sim, isso é válido com a implementação de Kuratowski, mas é uma
\emph{coincidência} e não uma \emph{conseqüência} da especificação
de par ordenado.
Talvez outra implementação não tem essa propriedade,
como tu vai descobrir agora demonstrando que o $\tup{\dhole,\dhole}$
de Wiener também é uma implementação de par ordenado.

%%}}}

%%{{{ x: wiener_pair 
\exercise par de Wiener.
%%%{{{ meta 
\label wiener_pair
\credits
    * Wiener : par
    ;;
\defines
    * par!de Wiener
    ;;
\indexes
    * par!de Kuratowski
    ;;
%%%}}}

Mostre pelos axiomas que a operação $\tup{\dhole,\dhole}$ definida pela
$$
\tup{x,y} \defeq \bigset{ \set{ \emptyset, \set{x} }, \set{ \set{ y } } }
$$
é uma implementação bem-definida de par ordenado
(ou seja, dados $x,y$ o $\tup{x,y}$ é um conjunto sim)
que satisfaz as~\mref[spec_tup1]~\&~\mref[spec_tup2].\foot
Wiener definiu essa operação uns anos
\emph{antes} da definição de Kuratowski.
\toof

\hint
Trabalhe como fizemos para o par ordenado de Kuratowski
no~\ref[kurpair_satisfies_tup0] e nas
proposições~\reftag[kurpair_satisfies_tup1]--\reftag[kurpair_satisfies_tup2].

\solution
Primeiramente verificamos que, dados objetos $x,y$, o $\tup{x,y}$
realmente é um conjunto:
$$
\PROOFmrw {
\I0------------ Empty
   {\emptyset}              \A     x
                            \I1--------- Singleton
                                \set{x}
\I2------------------------------------- Pair
        \set{\emptyset, \set{x}}                    \A    y
                                                    \I1-------- Singleton
                                                        \set{y}
                                                 \I1--------------- Singleton
                                                     \set{\set{y}}
\I2---------------------------------------------------------------- Pair
          \set{ \set{ \emptyset, \set{x} }, \set{ \set{y} } }
}
$$
\proofpart {\mref[spec_tup2]:}
Sejam $A,B$ conjuntos.
Queremos demonstrar que a classe
$$
A\times B = \classst {\tup{x,y}} {
x\in A
\mland
y\in B
}
$$
é um conjunto.
Como na demonstração da~\ref[kurpair_satisfies_tup2],
Basta achar um conjunto $W$ que contem o arbitrário $\tup{a,b}\in A\times B$,
pois depois aplicamos o Separation~\axref[separation] com a mesma
fórmula da~\ref[kurpair_satisfies_tup2] para ganhar o $A\times B$.
Um conjunto que serve como $W$ é o $\pset\pset\pset(A\union B)$,
como verificamos aqui, escrevendo a derivação em forma de árvore:
$$
\PROOFmn {
\I0--------------------------------
    {\emptyset\in\pset(A\union B)}
                                       \A
                                    {a \in A}
                              \I1------------------
                                 {a \in A\union B}
                    \I1------------------------------------
                         {\set{a} \in \psetp{A\union B}}
\I2-----------------------------------------------------------
      {\set{\emptyset,\set{a}} \in \pset\psetp{A\union B}}
                                                               \A
                                                            {b \in B}
                                                      \I1------------------
                                                         {b \in A\union B}
                                             \I1-----------------------------------
                                                  {\set{b} \in \psetp{A\union B}}
                                           \I1-----------------------------------------
                                                {\set{\set{b}} \in \psetp{A\union B}}
\I2------------------------------------------------------------------------------------
     {\set{\set{\emptyset,\set{a}}, \set{\set{b}}}\in\pset\pset\psetp{A\union B}}
}
$$

%%}}}

%%{{{ x: hausdorff_pair 
\exercise par de Hausdorff.
%%%{{{ meta 
\label hausdorff_pair
\credits
    * Hausdorff : par
    ;;
\defines
    * par!de Hausdorff
    ;;
%%%}}}

Considere $0$ e $1$ dois objetos distintos (algo que nossos axiomas garantam).
Para ser especifico, tome $0\asseq\emptyset$ e $1\asseq\set\emptyset$.
Demonstre que a operação
$$
\tup{x,y} \defeq \bigset{ \set{0, x}, \set{1, y} }
$$
também é uma implementação de par ordenado.

\hint
Calcule os $\tup {0,0}$, $\tup {0,1}$, $\tup {1,0}$, $\tup {1,1}$.

\hint
Separe em casos: $x=y$ ou não.

%%}}}

%%{{{ x: bad_pair 
\exercise Bad pair.
%%%{{{ meta 
\label bad_pair
%%%}}}

Demonstre que não podemos usar a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{y} }
$$
como uma implementação de par ordenado.

\hint
O $\tup{x,y}$ não satisfaz a~\mref[spec_tup1].
Mostre um contraexemplo, ou seja, ache objetos $x,y,x',y'$ tais que:
$$
\tup{x,y} = \tup{x',y'}
$$
e mesmo assim não temos $x=x'$ e $y=y'$.

\solution
Seja $o$ qualquer conjunto (tome $o \asseq \emptyset$ por exemplo).
Considere o $\set{\set{o}, \set{\set{o}}}$.
Ele representa algum par ordenado?
Calculamos:
$$
\align
\tup{ \set{o}, \set{o} } &= \set{\set{o}, \set{\set{o}}} \\
\tup{ \set{\set{o}}, o } &= \set{\set{\set{o}}, \set{o}}
\endalign
$$
Observe que os conjuntos nos lados direitos são iguais:
$$
\set{\set{o}, \set{\set{o}}}
=
\set{\set{\set{o}}, \set{o}}
$$
e logo
$$
\tup{ \set{o}, \set{o} }
=
\tup{ \set{\set{o}}, o }.
$$
Isso já mostra que a~\mref[spec_tup1] não é satisfeita, pois
$\set{o} \neq \set{\set{o}}$.
(E nem $\set{o}=o$ mas só precisamos uma das duas ser falsa
para concluir que a propriedade não é satisfeita.)
\mistake
\eop
A demonstração que acabamos de escrever tem um roubo sutil,
que é muito fácil corrigir, mas difícil identificar!
Para corrigi-lo, basta tomar o conjunto $\emptyset$
onde tomamos um arbitrário conjunto $o$, e a demonstração
vira correta!
O \ref[find_the_crime_of_foundation] pede identificar
o problema.

%%}}}

%%{{{ x: spooky_pair 
\exercise Spooky pair.
%%%{{{ meta 
\label spooky_pair
%%%}}}

Considere a operação
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
como uma implementação de par ordenado.
Demonstre que ela satisfaz a~\mref[spec_tup2].
Sobre a~\mref[spec_tup1], a situação é mais complicada.
Nesse momento não podemos demonstrar que ela é satisfeita,
mas nem construir um contraexemplo!
Mesmo assim, vale a pena pensar:
que conjunto (spooky!) serviria?
Deixo isso para o~\ref[spooky_pair_problem].

\hint
Para demonstrar a~\mref[spec_tup2], dados conjuntos $a,b$,
tome $x\in a$ e $y \in b$ e ache um conjunto $w$ tal que
$\tup{x,y} \in w$.
(Exatamente como a gente fez no~\ref[kurpair_satisfies_tup2].)

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_disjoint_union 
\section Construindo a união disjunta.
%%%{{{ meta 
\label Constructing_the_disjoint_union
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
\label disjunion_specification
\indexes
    * união!disjunta
    ;;
%%%}}}

Queremos definir a operação binária da \emph{união disjunta}.

%%}}}

\TODO Especificação: mention coproduct.

%%{{{ df: disjoint_union 
\definition União disjunta.
%%%{{{ meta 
\label disjoint_union
\defines
    * ~A \disjunion ~B  -- a união disjunta de $A$ com $B$
    * união!disjunta
    ;;
%%%}}}

Fixamos dois objetos distintos como os $\mathrm L\asseq \emptyset$ e $\mathrm R\asseq \set\emptyset$
e definimos:
$$
A \disjunion B
\defeq
\paren{\set{\mathrm L} \times A}
\union
\paren{\set{\mathrm R} \times B}.
$$

%%}}}

%%{{{ x: why_not_use_A_and_B_as_tags 
\exercise.
%%%{{{ meta 
\label why_not_use_A_and_B_as_tags
%%%}}}

Uma escolha de ``tags'' para os membros dos conjuntos $A$ e $B$ seria
os próprios conjuntos $A$ e $B$ em vez dos $\emptyset$ e $\set\emptyset$
que usamos.  Qual é o problema com essa idéia?

%%}}}

%%{{{ x: generalize_disjunion_to_indexed_Disjunion 
\exercise.
%%%{{{ meta 
\label generalize_disjunion_to_indexed_Disjunion
%%%}}}

Generalize a construção de união disjunta binária para
o operador ``grande'' de união disjunta indexada por algum conjunto
de índices $I$.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_relations 
\section Construindo as relações.
%%%{{{ meta 
\label Constructing_the_relations
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

O que precisamos de algum objeto $R$ que merece o nome de
\emph{implementação de relação de $A$ para $B$}?
Bem, primeiramente, dados $a\in A$ e $b\in B$ queremos ter
como ``perguntar'' esse objeto $R$ se o $a$ está relacionado
com o $b$.
Dados quaisquer conjuntos $c$ e $d$ queremos também que
a classe de todas as relações de $c$ para $d$ seja um conjunto.
Nossa definição tem que ser feita em tal jeito que facilita
as demais definições de operações em relações, por exemplo
a composição, os vários fechos que encontramos, etc.
\eop
Praticamente, \emph{nossa especificação é o~\ref[Relations]!}

%%}}}

%%{{{ df: relation_formal_def 
\definition Relação.
%%%{{{ meta 
\label relation_formal_def
%%%}}}

Sejam $A,B$ conjuntos.
Qualquer subconjunto $R \subset A \times B$
é uma relação de $A$ para $B$.
Em outras palavras:
$$
\text{$R$ relação de $A$ para $B$}
\defiff
R \subset A \times B.
$$
Introduzimos as notações
$$
\align
x \rel R y
&\sugiff \tup{x,y} \in R\\
R(x,y)
&\sugiff \tup{x,y} \in R.
\endalign
$$
Formalmente definimos o predicado
$$
\Relation(r,a,b)
\sugiff
r \subset (a \times b).
$$

%%}}}

%%{{{ remark: remember the graph of a relation? 
\remark.
%%%{{{ meta 
%%%}}}

No final das contas, já tivemos definido esse conceito.
Seu nome foi \emph{o gráfico da $R$}.  Lembra?
Se não, veja o~\ref[relation_graph].
Em outras palavras, dentro da teoria de conjuntos,
com nossa~\ref[relation_formal_def],
\emph{identificamos as relações com seus gráficos: $R = \graph R$.}

%%}}}

%%{{{ warning: faithful representation 
\warning.
%%%{{{ meta 
%%%}}}

Enfatizamos mais uma vez que isso não quis dizer que
uma relação \emph{é} o seu gráfico (que é um conjunto)!
Mas que isso é apenas um jeito de \emph{representar fielmente}
o conceito de \emph{relação} dentro da teoria de conjuntos, ou seja:
``\emph{como se fosse} conjunto''.

%%}}}

%%{{{ Q: must we define more terminology from relations? 
\question.
%%%{{{ meta 
%%%}}}

Agora precisamos definir as demais noções e termos que encontramos no~\ref[Relations]?
Por exemplo: precisamos definir os termos ``transitiva'', ``reflexiva'', etc.?

%%}}}

\spoiler

%%{{{ A: No! 
\blah Resposta.
%%%{{{ meta 
%%%}}}

Não!
Voltando no~\ref[Relations] podes verificar que todas as outras definições
dependem apenas na noção de relação mesmo
(que acabamos de definir formalmente na~\ref[relation_formal_def]).

%%}}}

%%{{{ eg: equality in A 
\example.
%%%{{{ meta 
%%%}}}

Seja $A$ um conjunto.
O conjunto
$$
\setst {\tup{x,x}\in A^2} {x \in A}
$$
é uma relação, pois realmente é um subconjunto de $A\times A$.
Qual relação é essa?
Ela merece seu próprio nome e sua própria notação.

%%}}}

%%{{{ df: eqin 
\definition.
%%%{{{ meta 
\label eqin
%%%}}}

Dado conjunto $A$, a relação de \dterm{igualdade no $A$}
é a relação
$$
{\eqin A} \defeq \setst {\tup{x,x}\in A^2} {x \in A}.
$$
Logo temos
$$
x \eqin A y \iff x = y \mland x,y \in A.
$$

%%}}}

%%{{{ prop: a_relto_b_is_a_set 
\proposition.
%%%{{{ meta 
\label a_relto_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
\relspace{a,b}
\defeq
\classstt R {$R$ é uma relação de $a$ para $b$}
$$
é um conjunto.

\proof.
Basta achar um conjunto onde todas as relações de $a$ para $b$
pertencem.
Pela definição de relação, todas pertencem ao $\pset(a\times b)$.
De fato, ainda mais é verdade:
$$
\relspace{a,b}
=
\pset(a\times b)
$$
e logo é um conjunto graças aos operadores (totais) $\pset$ e $\times$.

%%}}}

%%{{{ eg: reflexive_and_irreflexive_formally 
\example.
%%%{{{ meta 
%%%}}}

Seja $R\subset A\times A$.
Então temos
$$
\align
\text{$R$ reflexive}
&\iff {\eqin A} \subset R\\
\text{$R$ irreflexive}
&\iff {\eqin A} \inter R = \emptyset
\endalign
$$
etc.

%%}}}

%%{{{ x: rcompose_formal_def 
\exercise.
%%%{{{ meta 
\label rcompose_formal_def
%%%}}}

Mostre que podemos definir o operador de composição de relações
$\dhole\rcom\dhole$ em tal modo quando é aplicado em conjuntos
$a,b$ que são relações (compatíveis), o conjunto
$a\rcom b$ também é uma relação, e a correta:
a composição de $a$ com $b$.
(Lembre-se a~\ref[rcompose].)

%%}}}

%%{{{ x: closures_formal_def 
\exercise.
%%%{{{ meta 
\label closures_formal_def
%%%}}}

Defina formalmente e diretamente como conjuntos os fechos que encontramos
no~\ref[Relations]:
reflexivo (\reftag[rclosure]),
simétrico (\reftag[sclosure]),
transitivo (\reftag[tclosure]).
Tente dar a definição mais curta, elegante, e flexível possível!

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_functions 
\section Construindo as funções.
%%%{{{ meta 
\label Constructing_the_functions
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

Como nas relações, aqui também nossa especificação deve ser clara:
\emph{traduzir todo o~\ref[Functions] na teoria de conjuntos!}

%%}}}

%%{{{ df: function_formal_def 
\definition Função.
%%%{{{ meta 
\label function_formal_def
%%%}}}

Sejam $A,B$ conjuntos.
Uma relação $f$ de $A$ para $B$ é chamada \dterm{função de $A$ para $B$}
sse
$$
\pforall {a \in A}
\lunique {b \in B}
{\tup{a,b} \in f}.
$$
Equivalentemente
(e para ficar mais perto das Condições~\reftag[functionhood_conditions]
do~\ref[Functions]) podemos separar essa condição em duas:
$$
\gather
\pforall {a \in A}
\lexists {b \in B}
{\tup{a,b} \in f}
\tag{TOT}\\
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
\endgather
$$
Escrevemos
$$
f(a) = b
\defiff
\tup{a,b} \in f
$$
e também usamos
$$
f(a)
\defeq
\text{aquele único $b\in B$ tal que $\tup{a,b}\in f$.}
$$
Lembre-se que escrevemos
$f : A \to B$ ou $A \toby f B$ para dizer que
$f$ é uma função de $A$ para $B$, etc.
(Veja~\ref[function_notation].)
Formalmente definimos o predicado
$$
\Function(f,a,b)
\sugiff
\Relation(f,a,b)
\land
\pforall {x \in a}
\lunique {y \in b}
{\tup{x,y}\in f}.
$$

%%}}}

%%{{{ prop: a_to_b_is_a_set 
\property.
%%%{{{ meta 
\label a_to_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
(a \to b)
\defeq
\classst f {f : A \to B}
$$
é um conjunto.

\proof.
Fácil:
$$
(a \to b)
=
\setst {f \in \relspace{a,b}} {f : A \to B}
$$
que é conjunto graças ao operador $\relspace{\dhole,\dhole}$
(\ref[a_relto_b_is_a_set]) e ao axioma da separação~\axref[separation].

%%}}}

%%{{{ We get inj surj bij for free 
\remark.
%%%{{{ meta 
%%%}}}

Como as definições de ``injetora'', ``sobrejetora'', e ``bijetora''
do~\ref[Functions] dependem apenas da definição de ``função''
(que acabamos de definir), já temos essas definições na teoria de conjuntos!
Simlarmente os operadores $(\dhole\injto\dhole)$, $(\dhole\surjto\dhole)$,
e $(\dhole\bijto\dhole)$ são facilmente definidos graças
à~\ref[a_to_b_is_a_set]
e o axioma da separação~\axref[separation].

%%}}}

%%{{{ eg: eqc_formally_defined 
\example.
%%%{{{ meta 
\label eqc_formally_defined
%%%}}}

Uma definição alternativa e formal do $\eqc$ é a seguinte:
$$
a \eqc b \defiff (a \bijto b) \neq \emptyset.
$$

%%}}}

%%{{{ x: fcompose_fresto_fprod
\exercise.
%%%{{{ meta 
\label fcompose_fresto_fprod
%%%}}}

Defina formalmente as operações e construções de funções que encontramos
no~\ref[Functions]:
composição (\reftag[fcompose]);
restricção (\reftag[fresto]);
produto (\reftag[fprod]).

%%}}}

%%{{{ x: id_char_const_as_sets 
\exercise.
%%%{{{ meta 
%%%}}}

Descreva curtamente as funções identidades, características, e constantes como
conjuntos.
Esses conjuntos representam outras coisas (de outros tipos)?

%%}}}

%%{{{ beware: we do note get partial functions for free! 
\beware.
%%%{{{ meta 
%%%}}}

Tem um conceito do~\ref[Functions] que \emph{não} definimos
em termos de ``função'', e logo precisamos defini-lo formalmente
aqui: a \emph{função parcial}.

%%}}}

%%{{{ df: partial_function 
\definition Função parcial.
%%%{{{ meta 
\label partial_function_formally_defined
%%%}}}

Uma relação $f$ de $A$ para $B$ é uma \dterm{função parcial} sse
$$
\pforall {a \in A}
\lforall {b,b' \in B}
{\tup{a,b},\tup{a,b'} \in f \implies b = b'}.
\tag{DET}
$$

%%}}}

%%{{{ x: a_parto_b_is_a_set 
\exercise.
%%%{{{ meta 
\label a_parto_b_is_a_set
%%%}}}

Dados conjuntos $a,b$, a classe
$$
(a \parto b)
\defeq
\classst f {f : A \parto B}
$$
é um conjunto.

\solution
Fácil, como na demonstração da~\ref[a_to_b_is_a_set]:
$$
(a \parto b)
=
\setst {f \in \relspace{a,b}} {f : A \parto B}
$$
que é conjunto.

%%}}}

%%{{{ x: parto_formally_defined 
\exercise.
%%%{{{ meta 
\label partial_function_formally_defined_as_function
%%%}}}

Ache um outro jeito para definir funções parciais como funções.
(Talvez tu já pensou nisso no~\ref[implement_partial_functions].)
Verifique que dados conjuntos $a,b$ a classe
$(a \parto b)$ também é um conjunto.

\hint
(Resolva primeiro o~\ref[implement_partial_functions].)
Cada função parcial $f : A \parto B$ pode ser representada
como uma função total $f : A \to B'$ onde $B'$ é um outro
conjunto.
Qual $B'$ serve?

\hint
Duas idéias razoáveis:
\crproofalt{Idéia 1:}
Dados conjuntos $A,B$, escolha (como?)\ um objeto fora do $B$
para representar a ``diverjão'', ou valor ``não-definido''.
Lembra-se que $\russell B \nin B$, algo que
temos graças ao \ref[russells_paradox_to_theorem].
Então tome $B' \asseq B \union \russell B$.
\crproofalt{Idéia 2:}
Tome
$$
B'
\asseq
\setstt {Y \subset B} {$\Singleton(Y)$ ou $Y = \emptyset$}.
$$

%%}}}

%%{{{ df: parfun_compatibility 
\definition Compatibilidade.
%%%{{{ meta 
\label parfun_compatibility
\defines
    * função!parcial!compatibilidade
    * função!parcial!conflito
    ;;
%%%}}}

Sejam $A,B$ conjuntos e $\scr F$ uma família de funções parciais de $A$ para $B$:
$\scr F \subset (A\parto B)$.
Chamamos a $\scr F$ \dterm{compatível} sse $\Union {\scr F} \in (A\parto B)$.
Digamos que $\scr F$ tem \dterm{conflito} no $a\in A$ sse
existem $y,y'\in B$ com $y\neq y'$ e $\tup{a,y}, \tup{a,y'}\in \scr F$;
equivalentemente
$$
\card{ \setst {\tup{a,y}} {y\in B} } > 1.
$$

%%}}}

%%{{{ df: approximation 
\definition Aproximação.
%%%{{{ meta 
\label parfun_approx
\defines
    * função!parcial!aproximação
    ;;
%%%}}}

Seja $F : A \to B$.
Chamamos qualquer $f\subset F$ uma aproximação (parcial) da $F$.
Ela é \dterm{própria} se $f\psubset F$.

%%}}}

%%{{{ x: fun_approxes_is_set 
\exercise.
%%%{{{ meta 
\label fun_approxes_is_set
%%%}}}

Seja $F : A \to B$.
Demonstre que a classe
$$
\classst f { \text{$f$ é uma aproximação da $F$} }
$$
é um conjunto.

\solution
Usando o Separation~\axref[separation] escrevemos
$$
\setst {f \in (A\parto B)} {f \subset F}.
$$

%%}}}

%%{{{ x: fun_with_approxes 
\exercise.
%%%{{{ meta 
\label fun_with_approxes
\pdefs
    \pdef Approxes    {{\scr F}}
    \pdef FinApproxes {\Approxes_{\textrm f}}
    ;;
%%%}}}

Seja $F : A \to B$.
(i) Demonstre que:
$$
F = \Union \Approxes
$$
onde $\scr F$ é o conjunto de todas as aproximações da $F$.
(ii) É também verdadeiro que
$$
F = \Union \FinApproxes
$$
onde $\FinApproxes$ é o conjunto de todas as aproximações finitas da $F$?

\solution%
(i)
Tome $\tup{x,y} \in F$.
Para concluir que $\tup{x,y} \in \Union \Approxes$
precisamos achar uma aproximação $f\in\Approxes$ tal que $\tup{x,y} \in f$.
Aqui uma: a aproximação $\set{\tup{x,y}} \subset F$.
Conversamente, tome $\tup{x,y}$ in $\Union\Approxes$.
Pela definição de $\Union$ então temos que $\tup{x,y}\in f$ para alguma aproximação
$f\in\Approxes$.  Pela definição de aproximação agora, $f\subset F$, ou seja:
$\tup{x,y}\in f \subset F$.
\eop
(ii) Sim.  A direção $\Union \FinApproxes \subset F$ é trivial graças ao (i),
e a direção oposta também demonstramos no (i) pois a aproximação $\set{\tup{x,y}}$
que escolhemos nessa direção é realmente finita.

%%}}}

\endsection
%%}}}

%%{{{ Constructing_more_familiar_types 
\section Construindo mais tipos familiares.
%%%{{{ meta 
\label Constructing_more_damiliar_types
%%%}}}

%%{{{ x: constructing_indexed_families 
\exercise famílias indexadas.
%%%{{{ meta 
%%%}}}

Construa as famílias indexadas na teoria dos conjuntos.

%%}}}

%%{{{ x: why_do_we_not_gain_sequences_by_indexed_families_for_free 
\exercise.
%%%{{{ meta 
\label why_do_we_not_gain_sequences_by_indexed_families_for_free
%%%}}}

<<Como podemos implementar cada seqüência como uma família
indexada pelo conjunto de indices $\cal I \asseq \nats$,
e como acabamos de construir as famílias indexadas por
qualquer conjunto de indices $\cal I$, logo já temos
construido as seqüências também dentro da teoria dos
conjuntos.>>
Concordas?

\hint
Esse $\nats$ aí é o que mesmo?

%%}}}

%%{{{ Q: what about groups, monoids, rings, fields, etc.? 
\question.
%%%{{{ meta 
%%%}}}

Ainda falta muita coisa: grupos, monóides, anéis, corpos, etc.
Como podemos construí-los na teoria dos conjuntos?

%%}}}

\spoiler

%%{{{ x: constructing_structured_sets 
\exercise.
%%%{{{ meta 
%%%}}}

Construa o conceito de conjunto estruturado na teoria dos conjuntos.

\hint
Apague o $\cdot$ do $;$ ué.

%%}}}

\endsection
%%}}}

%%{{{ The_cardinals 
\section Os cardinais.
%%%{{{ meta 
\label The_cardinals
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tem mais uma coisa muito legal que conseguimos definir
sem introduzir nenhum axioma ainda: a \emph{aritmética dos
cardinais}.
Infelizmente não podemos ainda definir mesmo os cardinais
mas podemos brincar suficientemente com umas idéias e
entender como funciona sua aritmética ao ponto de aplicá-la
para conseguir uns resultados interessantes.

%%}}}

%%{{{ df: cardinal_assignment 
\definition atribuidor de cardinalidade.
%%%{{{ meta 
\label cardinal_assignment
%%%}}}

Um operador unário $\card\dhole$ é chamado
\dterm{atribuidor (forte) de cardinalidade}
sse ele satisfaz:
\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Classes vs. Sets (II) 
\section Classes \vs Conjuntos (II).
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Pelas nossas definições de relação e de função, observe
que nem $\dhole\subset\dhole$ é uma relação unária,
nem $\pset\dhole$ é uma função unária.

%%}}}

%%{{{ x: Singleton_and_pset_are_too_big 
\exercise.
%%%{{{ meta 
%%%}}}

Por que não?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Então certas coisas que \emph{parecem como} relações na verdade
são ``grandes demais'' para ser relações mesmo (segundo nossa
definição de relação dentro da teoria dos conjuntos), e similarmente
sobre funções.  Vamos chamá-las de predicados ou relações-classes,
e de operadores ou funções-classes:

%%}}}

%%{{{ df: classrelation 
\definition relação-classe.
%%%{{{ meta 
\label classrelation
\defines
    * predicado
    * relação-classe
    ;;
%%%}}}

Qualquer fórmula com $n$ buracos determina um
\dterm{predicado} $n$-ário, que chamamos também de
\dterm{relação-classe} $n$-ária.

%%}}}

%%{{{ df: functionlike 
\definition function-like, função-classe.
%%%{{{ meta 
\label functionlike
%%%}}}

Uma fórmula $\Phi(x,y)$ é \dterm{function-like}, sse:
$$
\forall x
\unique y
\Phi(x,y)
\qqtext{ou seja,}
\forall x
\exists y
\bigparen{
\Phi(x,y)
\land
\forall y'
\paren{\Phi(x,y') \limplies y = y'}}.
$$
Nesse caso, também usamos os termo \dterm{função-classe}, \dterm{operador},
e a notação comum
$$
\Phi(x) = y
\qqqtext{como sinónimo de}
\Phi(x,y).
$$
Seguindo essa linha denotamos por $\Phi(x)$ o único objeto $y$ tal que
$\Phi(x,y)$.
Assim o $\Phi(x)$ denota um \emph{objeto}, mas o $\Phi(x,y)$ uma \emph{afirmação}.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ someset_problem 
\problem Someset is the new Emptyset.
%%%{{{ meta 
\label someset_problem
%%%}}}

Considere o axioma seguinte:
\eop
\noi
{\bf Someset.}
{\proclaimstyle Existe algo.}
$$
\exists s \paren{ s = s }
\axtag[someset=ZF2*]
$$
Mostre que no sistema axiomático
\axref[extensionality]%
+\axref[someset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset],
existe o $\emptyset$.\foot
Dependendo do uso e do contexto, podemos considerar como parte da lógica
que o universo não é vazio, ou seja, existe algo.
Nesse caso nem precisamos o Someset~\axref[someset], pois seria implícito.
\toof

%%}}}

%%{{{ triset_problem 
\problem Triset is the new Pairset.
%%%{{{ meta 
\label triset_problem
%%%}}}

Considere o axioma seguinte:
\eop\noi
{\bf Triset.}
{\proclaimstyle
Dados tres objetos distintos existe conjunto com exatamente
esses membros.
}
$$
\forall a
\forall b
\forall c
\lparen{
\bigparen{
a\neq b \land b \neq c \land c \neq a
}
\limplies
\exists s
\forall x
\bigparen{x\in s \liff x = a \lor x = b \lor x = c}
}
\axtag[triset=ZF3*]
$$
\tlist:
\li (0):
No sistema
\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]
construa conjunto de cardinalidade~$3$.
\li (1):
Demonstre que no mesmo sistema
podemos substituir o axioma Pairset~\axref[pairset] pelo axioma
Triset~\axref[triset] \dq{sem perder nada}.
Em outras palavras, demonstre que no sistema
\axref[extensionality]%
+\axref[emptyset]%
+\axref[triset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]
\emph{para todos os $a,b$ existe o conjunto $\set{a,b}$}.
\li (2):
Podemos demonstrar a mesma coisa no
\axref[extensionality]%
+\axref[emptyset]%
+\axref[triset]%
+\axref[separation]%
+\axref[unionset]%
?
\endtlist

\hint
Para o (1), veja o (2); para o (2), veja o (1)!

%%}}}

%%{{{ conset_problem 
\problem.
%%%{{{ meta 
\label conset_problem
%%%}}}

Considere o axioma seguinte:
$$
\forall h
\forall t
\exists s
\forall x
\bigparen{
x \in s
\liff
x = h
\lor
x \in t
}.
\axtag[conset=CONS]
$$
(1)
No sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[conset]}
demonstre o \axref[pairset].
\eop\noi
(2)
Mostre que não tem como demonstrar o \axref[conset]
no sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]}.
\eop\noi
(3)
No sistema
{\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]%
+\axref[separation]%
+\axref[powerset]%
+\axref[unionset]}
demonstre o \axref[conset].

\solution
(1)
Dados os objetos $a,b$, queremos construir o $\set{a,b}$.
Aplicando o \axref[conset] com $h \asseq b$ e $t \asseq \emptyset$
ganhamos o $\set{b}$, e agora aplicando novamente o mesmo axioma
com $h \asseq a$ e $t \asseq \set{b}$ ganhamos o desejado $\set{a,b}$.
\eop\noi
(2)
Observe que com os axiomas
\axref[extensionality]%
+\axref[emptyset]%
+\axref[conset]\ 
conseguimos construir conjuntos de qualquer cardinalidade finita,
mas com os
\axref[extensionality]%
+\axref[emptyset]%
+\axref[pairset]\ 
conseguimos construir apenas conjuntos com cardinalidades $0$, $1$, ou $2$.
Basta realmente construir um conjunto com cardinalidade maior que $2$ então.
Aplique o \axref[conset] com $h,t \asseq \emptyset$ ganhando assim
o $\set{\emptyset}$.
Agora com $h \asseq \set\emptyset$ e $t \asseq \emptyset$ ganhando
o $\set{\set{\emptyset}}$.
Com $h \asseq \emptyset$ e $t \asseq \set{\set{\emptyset}}$
ganhamos o $\set{\emptyset, \set{\emptyset}}$.
E finalmente, com $h,t \asseq \set{\emptyset, \set{\emptyset}}$
construimos o $\set{\emptyset, \set{\emptyset}, \set{\emptyset, \set{\emptyset}}}$,
que tem cardinalidade $3$.
\eop\noi
(3)
Sejam $h, t$ conjuntos.
Pelo singleton (\ref[singleton_thm]) ganhamos o $\set h$,
e usando a união binária (\ref[union_and_symdiff_constructed])
nos $\set h$ e $t$ ganhamos o desejado conjunto.

%%}}}

%%{{{ one_class_set_the_other_proper_problem 
\problem.
%%%{{{ meta 
\label one_class_set_the_other_proper_problem
%%%}}}

Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref[extensionality]--\axref[unionset] que:
\item{(i)}  a classe $\classst {\set{x,\set y}} {x \in a \land y \in b}$ é conjunto;
\item{(ii)} a classe $\classstt {\set{x,y}} {$x,y$ conjuntos com $x\neq y$}$ é própria.

\hint
(ii) Absurdo.

%%}}}

%%{{{ two_sets_and_one_proper_class_problem 
\problem.
%%%{{{ meta 
\label two_sets_and_one_proper_class_problem
%%%}}}

Sejam $a,b$ conjuntos.
Mostre pelos axiomas \axref[extensionality]--\axref[unionset] que as classes
\mathcol
C &= \classst {\set{x, \set{x,y}}} {x \in a \land y \in b} \\
D &= \classst {\set{x,y}} {
          \paren{ x \in a \lor x \in \Union a }
          \land
          \paren{y \in b \lor y \subset b}
    } \\
\intertext{são conjuntos, mas a classe}
Z &= \classst {\Inter\Inter z} {z \neq \emptyset \land \Inter z \neq \emptyset}
\endmathcol
não é.

%%}}}

%%{{{ finite_set_constructor_proof 
\problem.
%%%{{{ meta 
\label finite_set_constructor_proof
%%%}}}

Demonstre o~\ref[finite_set_constructor].

\hint
Indução!

%%}}}

%%{{{ construct_pfset 
\problem.
%%%{{{ meta 
\label construct_pfset
%%%}}}

Demonstre que para todo conjunto $a$, o $\pfset a$ também é conjunto.
Ganhamos assim mais um construtor (unário) de conjuntos: $\pfset\dhole$.

\hint
O desafio aqui é conseguir escrever a afirmação
``o $x$ é um conjunto finito'' com uma fórmula.

%%}}}

\endproblems
%%}}}

%%{{{ The axiom of infinity 
\section O axioma da infinidade.
%%%{{{ meta 
%%%}}}

%%{{{ No infinite sets but Infinite(-) predicate 
\note.
%%%{{{ meta 
\credits
    * Dedekind
    ;;
%%%}}}

Com todos os nossos axiomas até agora, mesmo tendo conseguido
representar tanta matemática fielmente dentro da teoria de conjuntos,
ainda \emph{não é garantida} a existência de nenhum conjunto infinito.
Mesmo assim, a noção de ``ser infinito'' pode sim ser expressada
em nossa dicionário, num jeito genial graças ao Dedekind,
que deu a primeira definição de infinito que não presupõe
a definição dos números naturais.  Como?

%%}}}

\spoiler

%%{{{ df: Dedekind-infinite 
\definition Dedekind-infinito.
%%%{{{ meta 
\defines
    * \Infinite(~a)  -- o conjunto $a$ é Dedekind-infinito
    * Dedekind-infinito
    ;;
%%%}}}

Seja $A$ conjunto.  Chamamos o $A$ \Dedekind[infinito]\dterm{Dedekind-infinito} sse
ele pode ser ``injetado'' para um subconjunto próprio dele, ou seja,
sse existem $X\psubset A$ e $f : A \bijto X$.
Definimos então o predicado
$$
\Infinite(a) \defiff \exists x
\paren{
x\psubset a \land (a \eqc x)
}.
$$

%%}}}

%%{{{ Set successor 
\note Conjunto-sucessor.
%%%{{{ meta 
\indexes
    * conjunto-sucessor
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ df: setsucc 
\definition Zermelo, von Neumann.
%%%{{{ meta 
\defines
    * \setsucc {~x}  -- o conjunto-sucessor de $x$
    * conjunto-sucessor
    ;;
%%%}}}

Definimos
\vonNeumann[conjunto-sucessor]%
\Zermelo[conjunto-sucessor]%
o \dterm{conjunto-sucessor} dum conjunto $x$ ser o
$$
\align
\setsucc x &\defeq \set x           \tag{Zermelo}\\
\setsucc x &\defeq x \union \set x. \tag{von Neumann}
\endalign
$$
Como não existe ambigüidade, omitimos parenteses escrevendo por exemplo
$\setsucc{\setsucc{\setsucc x}}$ em vez de
$\setsucc{(\setsucc{(\setsucc x)})}$.

%%}}}

%%{{{ ax: Infinity 
\axiom Infinity.
%%%{{{ meta 
\label infinity
\defines
    * axioma!Infinity
    ;;
%%%}}}

Existe um conjunto que tem o $\emptyset$ como membro e é fechado sob a
operação $\lam x {\setsucc x}$.
$$
\exists s
\bigparen{
\emptyset \in s
\land
\forall x
\paren{
x \in s
\limplies
\setsucc x \in s
}
}
\axtag[infinity=ZF7]
$$

%%}}}

%%{{{ x: infinity_axiom_guarantees_natlike_object 
\exercise.
%%%{{{ meta 
%%%}}}

Verdadeiro ou falso?
Com o axioma Infinity~\axref[infinity] é garantida a existéncia \emph{do} conjunto
$$
\set {
\emptyset,
\setsucc\emptyset,
\setsucc{\setsucc{\emptyset}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
(Escrevemos ``do'' em vez de ``dum'' pois o axioma
Extensionality~\axref[extensionality] garanta que se existe, existe único.)

\hint
\emph{Não é} uma conseqüência imediata do~Infinity~\axref[infinity].
Por que não?

%%}}}

%%{{{ df: wrong_definition_of_I 
\definition.
%%%{{{ meta 
\label wrong_definition_of_I
%%%}}}

Seja $I$ o conjunto cuja existência é garantida pelo axioma Infinity~\axref[infinity].
Ou seja, o conjunto que satisfaz a condição:
$$
\emptyset \in I \land \forall x \paren{x \in I \limplies \setsucc x \in I}.
$$
\mistake

%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
%%%{{{ meta 
\label def_of_I_used_definite_articile
%%%}}}

Qual o problema com a \ref[wrong_definition_of_I]?

\hint
O artigo.

\solution
Para definir $I$ como \emph{o} conjunto que satisfaz tal propriedade
precisamos: \emph{existência \& unicidade}.
Existéncia é o que~\axref[infinity] garanta;
mas não temos---e nem podemos demonstrar---unicidade.
Então precisamos definir o $I$ como \emph{um} conjunto
que satisfaz aquela condição.

%%}}}

%%{{{ Effects and side-effects 
\note Efeitos e efeitos colaterais.
%%%{{{ meta 
%%%}}}

O axioma Infinity~\axref[infinity] é o segundo dos nossos axiomas
que garanta diretamente a existência dum certo objeto;
o primeiro foi o Emptyset~\axref[emptyset].\foot
Pois todos os outros começam com quantificadores universais.
\toof
Assim que aceitamos o Emptyset, nós definimos o símbolo $\emptyset$
para ser \emph{o} conjunto vazio.
Para poder fazer isso precisamos \emph{demonstrar} a unicidade
do conjunto vazio~(\ref[uniqueness_of_emptyset]).
Mas a condição que aparece no~\axref[infinity] não é
suficientemente forte para ganhar unicidade pelo~\axref[extensionality]!
Possivelmente (e realmente, como nós vamos ver) nosso mundo tem muitos
conjuntos com essa propriedade!

%%}}}

%%{{{ x: def_of_I_used_definite_articile 
\exercise.
%%%{{{ meta 
\label infinitely_many_infinite_sets
%%%}}}

Mostre que já é garantida uma infinidade de conjuntos infinitos.

\hint
Olhe para os subconjuntos de $I$.

\solution
Tome
$$
\align
I_0 &\asseq I\\
I_1 &\asseq I \setminus \set{ \emptyset }\\
I_2 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset }\\
I_3 &\asseq I \setminus \set{ \emptyset, \setsucc\emptyset, \setsucc\emptyset }\\
    &\eqvdots
\endalign
$$

%%}}}

%%{{{ How does this infinite set look like? 
\note Como parece esse conjunto infinito?.
%%%{{{ meta 
\pdefs
    \pdef noise {\mathord{\;\vdots\;}}
    ;;
%%%}}}

Bem; sabemos que $I$ é infinito e tal, mas quais são os elementos dele?
É tentador pensar que $I$ é o conjunto
$$
I_* \pseudodefeq \set { \emptyset, \setsucc\emptyset, \setsucc{\setsucc\emptyset}, \setsucc{\setsucc{\setsucc{\emptyset}}},\dotsc}.
$$
No final das contas, vendo o~\axref[infinity],
\emph{o que mais poderia estar no $I$?}
Nada.  Certo?
Não.  Bem o oposto!
\emph{Absolutamente tudo} pode pertencer nesse $I$, pois a
única informação que temos sobre ele não tira nenhum objeto como
possível membro dele!
Realmente, os únicos elementos \emph{garantidos} no $I$ são
aqueles que escrevemos acima como membros do $I_*$, mas o $I$
pode ter mais: pode ter ``lixo'', como este:
$$
I_{\spade,\heart} \pseudodefeq \set {
\emptyset,
\spade,
\heart,
\setsucc\emptyset,
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\dotsc
}.
$$
Aqui os $\spade$ e $\heart$ denotam dois objetos do nosso universo,
talvez nem são conjuntos, talvez denotam os próprios símbolos
``$\spade$'' e ``$\heart$'', talvez somos nos, eu e tu, etc.
Para a gente, é o lixo.\foot
Sem ofensa.
\toof
\eop
Na verdade, esse último conjunto não pode ser o nosso $I$, pois ele não
satisfaz a condição do~\axref[infinity] pois
$$
\spade \in I
\qqtext{mas}
\setsucc\spade \nin I.
$$
Podemos então entender melhor nosso $I$.
Ele é um superconjunto do $I_*$---isto é garantido pelo~\axref[infinity] mesmo.
O que mais ele tem?  Não sabemos dizer, mas sabemos que \emph{se tem} outros objetos,
ele obrigatoriamente tem uma infinidade de conjuntos para cada um deles:
$$
\set {
\emptyset,
\spade,
\heart,
\setsucc{\emptyset},
\setsucc{\spade},
\setsucc{\heart},
\setsucc{\setsucc\emptyset},
\setsucc{\setsucc{\spade}},
\setsucc{\setsucc{\heart}},
\setsucc{\setsucc{\setsucc{\emptyset}}},
\setsucc{\setsucc{\setsucc{\spade}}},
\setsucc{\setsucc{\setsucc{\heart}}},
\dotsc
}.
$$
Vamos revisar esse $I$ então.
Sabemos que ele parece assim:
$$
I = \set {
\emptyset,
\noise,
\setsucc{\emptyset},
\noise,
\setsucc{\setsucc{\emptyset}},
\noise,
\setsucc{\setsucc{\setsucc{\emptyset}}},
\noise,
\setsucc{\setsucc{\setsucc{\setsucc{\emptyset}}}},
\noise,
\dotsc
}
$$
onde os $\noise$ representam o lixo,
e nosso próximo trabalho será achar um jeito para nos livrar desse lixo!

%%}}}

\endsection
%%}}}

%%{{{ Constructing_the_natural_numbers 
\section Construindo os números naturais.
%%%{{{ meta 
\label Constructing_the_natural_numbers
%%%}}}

%%{{{ Specification 
\note Especificação.
%%%{{{ meta 
%%%}}}

Primeiramente precisamos esclarecer o que precisamos implementar.
Qual é o ``pedido'' do cliente que queremos atender?
Quais são as leis (suficientes e necessárias) que os números naturais devem
respeitar?

%%}}}

\spoiler

%%{{{ Peano system 
\definition Sistema Peano.
%%%{{{ meta 
\label Peano_system
\defines
    * princípio!da indução, Peano
    * sistema Peano
    * axioma!Dedekind--Peano
    ;;
\credits
    * Peano
    * Dedekind
    ;;
%%%}}}

Um \dterm{sistema Peano} é um conjunto estruturado
$\cal N = \sset \Nats {\Ze,\Su}$ que satisfaz as leis:
$$
\alignat2
&\text{Zero é um número natural:}                     &\qquad&  \Ze \in \Nats                  \tag{P1}\\
&\text{O sucessor é uma operação unária nos naturais:}&&        \Su \eqtype \Nats \to \Nats    \tag{P2}\\
&\text{Naturais diferentes tem sucessores diferentes:}&&        \Su \eqtype \Nats \injto \Nats \tag{P3}\\
&\text{Zero não é o sucessor de nenhum natural:}      &&        \Ze \nin \img \Su \Nats    \tag{P4}\\
&\text{Os naturais satisfazem o princípio da indução:}                                           \tag{P5}
\endalignat
$$
\dterm{Princípio da indução}\/:
\emph{para todo $X\subset \Nats$,}
$$
\bigparen{
\Ze\in X
\land
\forall n
\paren{
n \in X \limplies \Su n \in X
}
} \limplies X = \Nats.
$$
Observe que graças às (P3) e (P4) temos
$$
\gather
\Su n = \Su m \implies n = m \\
\Su n \neq \Ze
\endgather
$$
para todos os $n,m\in \Nats$.
Os axiomas (P1)--(P5) são conhecidos como \dterm{axiomas Dedekind--Peano}.

%%}}}

%%{{{ Defining a Peano system 
\note Definindo um sistema Peano.
%%%{{{ meta 
%%%}}}

Então o que precisamos implementar é um conjunto estruturado
$\cal N = \sset \Nats {\Ze, \Su}$.
Isso é fácil: nosso $\cal N$ vai ser uma tripla $\tup {\Nats, \Ze, \Su}$,
onde seus membros $\Nats$, $\Ze$, e $\Su$ são tais objetos que as leis
(P1)--(P5) são satisfeitas.
Sabemos que o $\Nats$ precisa ser infinito, então temos que o procurar
entre os conjuntos infinitos da nossa teoria.
Uma primeira idéia seria botar $\Nats \defeq I$, mas essa não parece
uma idéia boa---será difícil ``vender'' uma implementação com lixo!
O que realmente queremos botar como $\Nats$ é o $I_*$
(que não conseguimos ainda defini-lo).
Mas vamos supor que o $I_*$ realmente é um conjunto;
ele vai representar os números naturais,
mas quais serão nossos $\Ze$ e $\Su$?
Pela especificação dos naturais, $\Ze$ tem que ser um dos membros do $I_*$,
e bem naturalmente escolhemos o $\emptyset$ como o zero.
E o $\Su$?  Obviamente queremos botar $\Su = \lam x {\setsucc x}$,
mas para realmente definir o $\Su$ como função, lembramos que em nosso
dicionário ``função'' é um certo tipo de conjunto de pares.
Botamos então
$$
\align
\Su &\pseudodefeq \classst {\tup{n,m}} { m = \setsucc n }
\intertext{e agora só basta achar um conjunto que tem todos esses pares
como membros.  Fácil:}
\Su &\defeq \setst {\tup{n,m}\in \Nats\times \Nats} { m = \setsucc n }.
\endalign
$$
Então falta só definir esse $I_*$.

%%}}}

%%{{{ Getting rid of noise 
\note Jogando fora o lixo.
%%%{{{ meta 
%%%}}}

Queremos definir o $I_*$ como conjunto; construí-lo pelos axiomas.
Uma primeira tentativa seria começar com o próprio $I$,
e usar o Separation~\axref[separation] para filtrar
seus elementos, separando os quais queremos do lixo,
assim botando
$$
I_* = \setst {x\in I} {\phi(x)}.
$$
para algum certo filtro $\phi(\dhole)$.
Qual fórmula vamos usar?

%%}}}

\spoiler

%%{{{ A top-down approach 
\note Uma abordagem top-down.
%%%{{{ meta 
%%%}}}

Não podemos descrever um filtro em nossa linguagem de lógica
(FOL de teoria de conjuntos)!  (Lembra-se, uma fórmula não pode
ter tamanho infinito.)
Precisamos então alguma outra idéia para nos livrar dos elementos ``extra'' do $I$.
\emph{Vamos definir o conjunto $I_*$ com a abordagem top-down!}
Sabemos que nosso $I_*$ desejado é um subconjunto de $I$.
Então vamos começar com a colecção de todos os subconjuntos de $I$
que satisfazem a condição do Infinity:
$$
\scr I
\defeq
\setst {i \in \pset I} {\emptyset \in i \land \forall x\paren{x\in i \limplies \setsucc x \in i}
}.
$$
Queremos agora selecionar o ``menor'' elemento dessa família $\scr I$.
Menor no sentido de ``aquele que está contido em todos''.
Sim, nosso $I_*$ é o $(\subset)$-menor elemento do $\scr I$!
Para defini-lo basta tomar a intersecção da família $\scr I$,
que podemos pois
$\scr I \neq \emptyset$~(\ref[why_is_scrI_nonempty]):
$$
I_* \defeq \Inter {\scr I}.
$$

%%}}}

%%{{{ x: why_is_scrI_nonempty 
\exercise.
%%%{{{ meta 
\label why_is_scrI_nonempty
%%%}}}

Por que $\scr I \neq \emptyset$?

\solution
Pois $I\in\scr I$.

%%}}}

%%{{{ thm: existence_of_nats 
\theorem Existência dos naturais.
%%%{{{ meta 
\label existence_of_nats
%%%}}}

Existe pelo menos um sistema Peano $\cal N = \sset \Nats {\Ze, \Su}$.

\sketch.
Definimos
$$
\cal N \defeq \tup{\Nats, \Ze, \Su},
$$
onde:
$$
\align
\Nats &\defeq \Inter \setst {i \in \pset I} {\emptyset \in i \land \forall x \paren{x\in i \limplies \setsucc x \in i}}\\
\Ze &\defeq \emptyset\\
\Su &\defeq \setst {\tup{m,n}\in \Nats\times\Nats} { n = \setsucc m }.
\endalign
$$
Temos já justificado que cada objeto que aparece nessa definição
é conjunto pelos axiomas.  Basta só verificar que as (P1)--(P5)
são satisfeitas.

\proof.
A única coisa que deixamos para completar a demonstração foi
verificar os (P1)--(P5), que é feito nos
exercícios \reftag[zero_is_a_nat]--\reftag[nat_has_induction].

%%}}}

%%{{{ x: P1 zero_is_a_nat 
\exercise P1.
%%%{{{ meta 
\label zero_is_a_nat
%%%}}}

Demonstre que $\Ze\in\Nats$.

%%}}}

%%{{{ x: P2 succ_is_a_function 
\exercise P2.
%%%{{{ meta 
\label succ_is_a_function
%%%}}}

Demonstre que $\Su$ é uma função.

%%}}}

%%{{{ x: P3 succ_is_injective 
\exercise P3.
%%%{{{ meta 
\label succ_is_injective
%%%}}}

Demonstre que $\Su : \Nats \injto \Nats$.

%%}}}

%%{{{ x: P4 zero_is_not_a_succ 
\exercise P4.
%%%{{{ meta 
\label zero_is_not_a_succ
%%%}}}

Demonstre que $\Ze\nin \img \Su \Nats$.

%%}}}

%%{{{ x: P5 nat_has_induction 
\exercise P5.
%%%{{{ meta 
\label nat_has_induction
%%%}}}

Seja $X\subset \Nats$ tal que:
\tlist:
\li (1): $\Ze \in X$;
\li (2): para todo $k\in \Nats$, se $k\in X$ então $\Su k \in X$.
\endtlist
Demonstre que $X=\Nats$.

%%}}}

%%{{{ thm: uniqueness_of_nats 
\theorem Unicidade dos naturais.
%%%{{{ meta 
\label uniqueness_of_nats
\indexes
    * unicidade!dos naturais
    ;;
\credits
    * Dedekind : unicidade dos naturais
    ;;
%%%}}}

Se  $\cal N_1 = \sset {\Nats_1} {\Ze_1, \Su_1}$
e   $\cal N_2 = \sset {\Nats_2} {\Ze_2, \Su_2}$
são sistemas Peano, então são isomorfos: $\cal N_1 \iso \cal N_2$.

\wrongproof.
Precisamos definir um isomorfismo
$\phi : \cal N_1 \iso \cal N_2$.
Definimos a função $\phi : \Nats_1 \to \Nats_2$ usando recursão:
$$
\align
\phi(\Ze_1) &= \Ze_2\\
\phi(\Su_1n) &= \Su_2\phi(n).
\endalign
$$
Pela sua definição, a $\phi$ é um homomorfismo.
Basta só verificar que a $\phi$ é bijetora,
algo que tu vai fazer agora nos exercícios
\reftag[homomorphism_of_nats_is_mono]~\&~\reftag[homomorphism_of_nats_is_epi].
\mistake

%%}}}

%%{{{ x: homomorphism_of_nats_is_mono 
\exercise.
%%%{{{ meta 
\label homomorphism_of_nats_is_mono
%%%}}}

Demonstre que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref[uniqueness_of_nats] é um monomorfismo.

%%}}}

%%{{{ x: homomorphism_of_nats_is_epi 
\exercise.
%%%{{{ meta 
\label homomorphism_of_nats_is_epi
%%%}}}

Demonstre que a $\phi : \Nats_1 \to \Nats_2$ definida
no~\ref[uniqueness_of_nats] é um epimorfismo.

\hint
Pela definição de sobrejetora e de imagem,
basta demonstrar que
$\img \phi {\Nats_1} = \Nats_2$.

\hint
Já sabemos que $\img\phi{\Nats_1} \subset \Nats2$.
Para demonstrar a igualdade mesmo, use o princípio da indução.

\hint
Precisas demonstrar duas coisas então:
(1) $\Ze_2 \in \img\phi{\Nats_1}$;
(2) para todo $n \in \Nats_2$, se $n \in \img\phi{\Nats_1}$ então $\Su_2 n \in \img\phi{\Nats_1}$.

\solution
Como $\img \phi {\Nats_1} \subset \Nats_2$,
demonstramos a igualdade usando o princípio da indução~(P5).
\proofpart {Base.}
$\Ze_2 \in \img\phi{\Nats_1}$:
Imediato pois $\phi(\Ze_1) = \Ze_2$.
\proofpart {Passo indutivo.}
Suponha $k \in \img\phi{\Nats_1}$.
Precisamos mostrar que $\Su_2 k \in \img\phi{\Nats_1}$.
Pela escolha de $k$, tome $k' \in \Nats_1$ tal que
$\phi(k') = k$.
Calculamos:
\compute
\phi(\Su_1 k')
&= \Su_2 (\phi(k')) \by {pela def.~$\phi$} \\
&= \Su_2 k          \by {pela escolha de $k'$} \\
\endcompute
ou seja, $\Su_2 k \in \phi[\Nats_1]$.

%%}}}

%%{{{ x: we_dont_have_recursion_yet 
\exercise.
%%%{{{ meta 
\label we_dont_have_recursion_yet
%%%}}}

Qual o erro na demonstração do~\ref[uniqueness_of_nats]?

\hint
O que é uma função em nosso dicionário,
e quem garanta que escrevendo assim do nada duas equações
sobre um certo objeto $F$, isso realmente defina
uma função?

\solution
Não temos demonstrado que dando equações recursivas como na
demonstração desse teorema podemos realmente definir uma função.
Fazemos isso no~\ref[recursion_theorem], assim
realmente botando o $\qedsymbol$ no~\ref[uniqueness_of_nats].

%%}}}

\endsection
%%}}}

%%{{{ Recursion_theorems 
\section Teoremas de recursão.
%%%{{{ meta 
\label Recursion_theorems
\indexes
    * recursão!teorema    see: teorema de recursão
    ;;
%%%}}}

%%{{{ thm: recursion_theorem 
\theorem Teorema da Recursão.
%%%{{{ meta 
\headerize
\label recursion_theorem
\indexes
    * função!parcial!compatibilidade
    * função!parcial!conflito
    ;;
\defines
    * teorema!de recursão
    ;;
%%%}}}

Sejam $\cal N = \sset \Nats {\Ze, \Su}$ um sistema Peano,
$A$ conjunto,
$a \in A$,
e $h: A \to A$.
Então existe única função $F : \Nats \to A$ que satisfaz as equações:
$$
\align
F(\Ze)    &= a \tag{1}\\
F(\Su n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$

\sketch.
Nosso plano é
\tlist:
\li (i): construir o objeto $F$ como conjunto;
\li (ii): mostrar que $F : \Nats \to A$;
\li (iii): mostrar que $F$ satisfaz as (1)--(2);
\li (iv): unicidade.
\endtlist
\eop
(i)
Vamos construir o $F$ \emph{bottom-up}, juntando umas das suas aproximações finitas:
funções parciais $f : \Nats\parto A$ onde a idéia é que elas ``concordam'' com a $F$
desejada onde elas estão definidas.
Nem vamos considerar todas elas: para nossa conveniência queremos apenas aquelas
cujo domínio é algum $\finord n$.
Por exemplo, as primeiras aproximações seriam as seguintes:
$$
\align
f_0 &= \emptyset\\
f_1 &= \bigset{ \tup{0,a} }\\
f_2 &= \bigset{ \tup{0,a}, \tup{1,h(a)} }\\
f_3 &= \bigset{ \tup{0,a}, \tup{1,h(a)}, \tup{2,h(h(a))} },\\
    &\eqvdots
\endalign
$$
Definimos o conjunto $\scr A$ de todas as aproximações aceitáveis:
$$
\scr A \defeq \setstt {f \in (\Nats\parto A)} {$f$ é aproximação aceitável}
$$
onde falta descrever com uma fórmula nossa idéia de ``ser aproximação aceitável''
(\ref[acceptable_approximation]).
(Das aproximações acima a $f_0$ não é aceitável.)
Agora podemos já definir o $F$:
$$
F \defeq \Union {\scr A}.
$$
\eop
(ii)
Precisamos mostrar a compatibilidade da $\scr A$ e a totalidade da $F$,
ou seja: que não existem \emph{conflitos}
(em outras palavras: que a família de funções parciais
$\scr A$ é \emph{compatível}\indexed[função!parcial!compatibilidade]);
e que $\dom F = \Nats$.
Esses são os exercícios~\ref[compatibility_of_scrF]~\&~\ref[totality_of_F]
respectivamente.
\eop
(iii)
Precisamos verificar a corretude da $F$, que ela atende sua especificação.
Essa parte deve seguir da definição de ``aproximação aceitável''.
Confirmamos isso no~\ref[correctness_of_F].
\eop
(iv)
Para a unicidade da $F$, precisamos mostrar que se $G : \Nats \to A$ tal que
satisfaz as (1)--(2), então $F = G$.  Isso é o~\ref[uniqueness_of_F], e com
ele terminamos nossa demonstração.

\proof.
A demonstração completa segue do seu esboço junto com os exercícios:
\reftag[acceptable_approximation],
\reftag[compatibility_of_scrF],
\reftag[totality_of_F],
\reftag[correctness_of_F], e
\reftag[uniqueness_of_F].

%%}}}

%%{{{ x: recursion_theorem_as_cd 
\exercise.
%%%{{{ meta 
\label recursion_theorem_as_cd
%%%}}}

Desenhe um diagrama comutativo que expressa o \ref[recursion_theorem].

\hint
Uma forma razoável tem a forma seguinte:
$$
\cdopt{sep=2cm}
?   \ar[r, "?"]\ar[dr, "?"'] \| ? \ar[r, "?"]\ar[d, dotted, "\unique"] \| ? \ar[d, dotted, "\unique"] \\
                             \| ?     \ar[r, "?"]                      \| ?
\endcd
$$
Basta nomear os objetos e as setas.

\hint
Aqui os objetos:
$$
\cdopt{sep=2cm}
1   \ar[r, "?"]\ar[dr, "?"'] \| \nats \ar[r, "?"]\ar[d, dotted, "\unique"] \| \nats \ar[d, dotted, "\unique"] \\
                             \| A     \ar[r, "?"]                          \| A
\endcd
$$

\solution
$$
\cdopt{sep=2cm}
1   \ar[r, "O"]\ar[dr, "a"'] \| \nats \ar[r, "S"]\ar[d, dotted, "\unique"] \| \nats \ar[d, dotted, "\unique"] \\
                             \| A     \ar[r, "h"]                          \| A
\endcd
$$

%%}}}

%%{{{ x: acceptable_approximation 
\exercise.
%%%{{{ meta 
\label acceptable_approximation
%%%}}}

No contexto do~\ref[recursion_theorem] defina formalmente a afirmação
\wq{$f$ é uma aproximação aceitável}.

\hint
Podemos ``quebrar'' a afirmação nessas partes:
\elist:A
\li: $f : \Nats \parto A$
\li: $\tup{0,a} \in f$
\li: Para qualquer $n\in\Nats_{\neq0}$, se $f$ é definida no $n$,
     então ela também é definida no predecessor de $n$,
     e o valor dela no $n$ é o correto, ou seja,
     o valor que ganhamos aplicando a $h$ no valor do predecessor de $n$.
\endelist
O único que precisamos formalizar agora é o último.

%%}}}

%%{{{ x: compatibility_of_scrF 
\exercise Compatibilidade.
%%%{{{ meta 
\label compatibility_of_scrF
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $\scr A$ é compatível.

%%}}}

%%{{{ x: totality_of_F 
\exercise Totalidade da $F$.
%%%{{{ meta 
\label totality_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $\dom F = \Nats$.

\hint
Verifique que $\dom F \subset \Nats$.
Agora basta demonstrar que $\dom F = \Nats$, usando o princípio da indução.

%%}}}

%%{{{ x: correctness_of_F 
\exercise Corretude da $F$.
%%%{{{ meta 
\label correctness_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] mostre que $F$ atende sua especificação,
ou seja:
$$
\align
F(\Ze)    &= a \tag{1}\\
F(\Su n)  &= h(F(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$

%%}}}

%%{{{ x: uniqueness_of_F 
\exercise Unicidade da $F$.
%%%{{{ meta 
\label uniqueness_of_F
%%%}}}

No contexto do~\ref[recursion_theorem] demonstre a unicidade da $F$, ou seja:
se $G : \Nats \to A$ tal que
$$
\align
G(\Ze)    &= a \tag{1}\\
G(\Su n)  &= h(G(n)), \quad\text{para todo $n\in\Nats$}.\tag{2}
\endalign
$$
então $F = G$.
Em outras palavras, as equações (1)--(2)
\emph{determinam} a função no $\Nats$.

\hint
Seja $X \subset \Nats$ o conjunto onde $F$ e $G$ ``concordam''.
Mostre que $X = \Nats$ usando o princípio da indução.

%%}}}

\endsection
%%}}}

%%{{{ Consequences of induction and recursion 
\section Conseqüências de indução e recursão.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Na~\reftag[Nats_formally] definimos recursivamente umas operações nos naturais.
Graças ao \ref[recursion_theorem], ganhamos todas essas operações em qualquer
sistema Peano.  Vamos lembrar como, e também demonstrar que não importa
\emph{em qual} sistema Peano calculamos: os resultados serão os
correspondentes!

%%}}}

%%{{{ operations and order 
\note Operações e ordem.
%%%{{{ meta 
%%%}}}

Para qualquer sistema Peano $\cal N = \sset \Nats {\Ze, \Su}$,
definimos as operações de adição e de multiplicação
$$
\xxalignat5
&\text{(a1)}  & n + \Ze   &= n          &&& n \ntimes \Ze   &= \Ze                &&\text{\funref[(\ntimes).1]}\\
&\text{(a2)}  & n + \Su m &= \Su(n+m) &&& n \ntimes \Su m &= (n \ntimes m) + n    &&\text{\funref[(\ntimes).2]}
\endxxalignat
$$
e a relação de ordem no $\Nats$
$$
    n \leq m \defiff (\exists k\in\Nats)[n + k = m].
$$
Sejam dois sistemas Peano
$\cal N_1 = \sset {\Nats_1} {\Ze_1, \Su_1}$ e 
$\cal N_2 = \sset {\Nats_2} {\Ze_2, \Su_2}$, e
suas operações de adição $+_1$ e $+_2$, e suas relações de ordem $\leq_1$ e $\leq_2$.
Seja $\phi:\Nats_1\bijto\Nats_2$ o isomorfismo definido pelas
$$
\align
    \phi(\Ze_1)   &= \Ze_2           \tag{$\phi$1}\\
    \phi(\Su_1 n) &= \Su_2(\phi(n)). \tag{$\phi$2}
\endalign
$$

%%}}}

%%{{{ property: peano_morphism_respects_addition 
\property.
%%%{{{ meta 
\label peano_morphism_respects_addition
%%%}}}

A $\phi$ respeita a adição, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n +_1 m) = \phi(n) +_2 \phi(m)
$$

\proof.
Por indução no $m\in\Nats_1$:
\proofpart {Base ($m \asseq \Ze_1$):}
{\proclaimstyle para todo $n\in\Nats_1$, $\phi(n +_1 \Ze_1) = \phi(n) +_1 \phi(\Ze_1)$.}
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Ze_1)
&= \phi(n)                    \by {pela (a1)$_1$} \\
&= \phi(n) +_2 \Ze_2        \by {pela (a1)$_2$} \\
&= \phi(n) +_2 \phi(\Ze_1)  \by {pela ($\phi$1)} \\
\endcompute
\proofpart {Passo indutivo:}
Seja $k \in \Nats_1$ tal que
$$
\text{para todo $n \in \Nats_1$, $\phi(n +_1 k) = \phi(n) +_1 \phi(k)$.} \tag{H.I.}
$$
Vamos demonstrar que
$$
\text{\proclaimstylize{para todo $n \in \Nats_1$, $\phi(n +_1 \Su_1 k) = \phi(n) +_1 \phi(\Su_1 k)$.}}
$$
Seja $n \in \Nats_1$.
Calculamos:
\compute
\phi(n +_1 \Su_1 k)
&= \phi(\Su_1(n +_1 k))       \by {pela (a1)$_2$} \\
&= \Su_2(\phi(n +_1 k))       \by {pela ($\phi$2)} \\
&= \Su_2(\phi(n) +_2 \phi(k)) \by {pela (H.I.), com $n\asseq n$} \\
&= \phi(n) +_2 \Su_2\phi(k)   \by {pela (a2)$_2$} \\
&= \phi(n) +_2 \phi(\Su_1 k)  \by {pela ($\phi$2)} \\
\endcompute

%%}}}

%%{{{ x: peano_morphism_respects_multiplication 
\exercise.
%%%{{{ meta 
\label peano_morphism_respects_multiplication
%%%}}}

Mostre que $\phi$ respeita a multiplicação, ou seja:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
\phi(n \ntimes_1 m) = \phi(n) \ntimes_2 \phi(m).
$$

\hint
Indução no $m\in\Nats_1$.

%%}}}

%%{{{ x: peano_morphism_respects_order 
\exercise.
%%%{{{ meta 
\label peano_morphism_respects_order
%%%}}}

Mostre que $\phi$ respeita a ordem também, no sentido de:
$$
\text{para todo $n,m\in\Nats_1$},\ \ 
n\leq_1 m \iff \phi(n)\leq_2 \phi(m).
$$

\hint
Demonstre as duas direções da \bidir\ separadamente.

%%}}}

\endsection
%%}}}

%%{{{ Constructing more numbers 
\section Construindo mais números.
%%%{{{ meta 
\label Constructing_more_numbers
\pdefs
    \pdef eqrat {\approx}
    \pdef eqint {\approx}
    ;;
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Tendo construido já os naturais,
vamos construir seus parentes também:
os inteiros, os racionais, os reais, e os complexos.

%%}}}

%%{{{ The integers 
\note Os inteiros.
%%%{{{ meta 
%%%}}}

Provavelmente a primeira idéia para implementar um inteiro $x$ é usar
uma $2$-tupla $x \defeq \tup{s,m}$ onde $s$ é um objeto para indicar o sinal
do $x$ e $m \defeq \abs{x}$.
Essa resolução, mesmo tecnicamente possível, não é legal.
Dependendo de se teriamos $2$ ou $3$ sinais podemos acabar com duas distintas
representações de $0$, números $x \neq 0$ com sinal $0$, ou outros problemas
similares.
Além disso, como vamos definir as operações?  Vão acabar sendo definições
por casos no sinal $s$, na ordem dos argumentos, etc.
Nenhum desses problemas é difícil corrigir; mas tudo isso deve aparecer
coisa com cheiro de \dq{ugly hack}.  E é mesmo.
A idéia é representar os inteiros como diferenças de naturais.
O inteiro $5$ então pode ser visto como a diferença $12 - 7$;
e o inteiro $-5$ como a $7 - 12$.
Como podemos formalizar isso numa maneira elegante?

%%}}}

\spoiler

%%{{{ df: eqint 
\definition Números inteiros.
%%%{{{ meta 
\label eqint
%%%}}}

Seja $Z = \nats \times \nats$.
Defina no $Z$ a relação $\eqint$ pela
$$
\tup{a,b} \eqrat \tup{c,d}
\defiff
a + d = c + b.
$$
Sendo uma relação de equivalência (\ref[eqint_is_an_eqrel]),
definimos
$$
\Ints
\defeq
\quoset Z {\eqint}.
$$

%%}}}

%%{{{ x: eqint_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label eqint_is_an_eqrel
%%%}}}

Mostre que $\eqint$ é uma relação de equivalência.

%%}}}

%%{{{ x: formalints_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalints_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Ints$ virar uma representação
de inteiros útil para o \emph{matemático trabalhador}.
(Parte desses exercícios é decidir o que falta mesmo.)

%%}}}

%%{{{ The rational numbers 
\note Os números racionais.
%%%{{{ meta 
%%%}}}

Essa construção é bem interessante---e simples!---pois usa um conceito nosso que
deve ser familiar já: sim, novamente o conjunto quociente.
Queremos identificar o racional $1/2$ com o par $\tup{1,2}$,
mas não podemos identificar o próprio $\rats$ com o $\ints \times \ints_{\neq0}$,
pois $\tup{1,2} \neq \tup{2,4}$ mesmo que $1/2 = 2/4$.
Duas idéias parecem razoáveis: (1) escolher um representante específico para cada
racional, trabalhando assim num subconjunto próprio do $\ints\times\ints_{\neq0}$;
(2) definir a relação $\eqrat$ de \emph{equivalência} no $\ints\times\ints_{\neq0}$,
e representar os racionais \emph{não como} membros desse conjunto,
mas \emph{sim como} classes de equivalência, ou seja, membros do conjunto quociente
$\quoset {\ints\times\ints_{\neq0}} {\eqrat}$.
Vamos seguir essa segunda idéia, pois é mais símples e elegante.

%%}}}

%%{{{ df: eqrat 
\definition Números racionais.
%%%{{{ meta 
\label eqrat 
%%%}}}

Seja $Q = \ints\times\ints_{\neq0}$.
Defina no $Q$ a relação $\eqrat$ pela
$$
\tup{a,b} \eqrat \tup{c,d}
\defiff
ad = bc.
$$
Sendo uma relação de equivalência (\ref[eqrat_is_an_eqrel]),
definimos
$$
\Rats
\defeq
\quoset Q {\eqrat}.
$$

%%}}}

%%{{{ x: eqrat_is_an_eqrel 
\exercise.
%%%{{{ meta 
\label eqrat_is_an_eqrel
%%%}}}

Mostre que $\eqrat$ é uma relação de equivalência.

%%}}}

%%{{{ x: formalrats_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalrats_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Rats$ virar uma representação
de racionais útil para o \emph{matemático trabalhador}.

%%}}}

%%{{{ The real numbers 
\note Os números reais.
%%%{{{ meta 
\label Constructing_the_reals
\credits
    * Dedekind : construção dos reais
    * Cantor : construção dos reais
    * Cauchy : seqüência Cauchy
    ;;
%%%}}}

Existem várias maneiras de construir os reais com o que temos até agora.
Neste texto encontramos as duas \dq{principais}: de Dedekind, que usa
\emph{Dedekind cuts}, e de Cantor, que usa \emph{seqüências Cauchy}.
Ambas as maneiras são baseadas na idéia que a linha dos racionais
tem buracos (certos pontos estão fazendo falta) e a construção dos reais
precisa adicionar esses buracos.  Para a metodo de Dedekind, visualizamos
os buracos como suprema que estão em falta de certos conjuntos;
para o Cantor, os buracos são limites de seqüências que \emph{querem
converger mas não conseguem} pois seus limites desejados não estão presentes!
Vamos seguir Dedekind agora;
a abordagem de Cantor fica para o~\ref[reals_as_cauchy_seqs].

%%}}}

\TODO Elaborar/terminar.

%%{{{ Dedekind cut 
\note Dedekind cut.
%%%{{{ meta 
\credits
    * Dedekind!Dedekind cut
    ;;
%%%}}}

Seja $\alpha \in \reals$.  O Dedekind cut que corresponde (representa) o $\alpha$ parece assim:
$$
\tikzpicture
\tikzi dedekindcut;
\endtikzpicture
$$
onde
\mathcols 2
A &= \setst {r \in \rats} {r < \alpha} &
B &= \setst {r \in \rats} {r \geq \alpha}.
\endmathcols
A idéia é que podemos definir o real $\alpha$ para ser esse Dedekind cut.
Observe que  definindo o $A$, determinamos o $B$ também, pois
$B = \rats \setminus A$.
Só que já temos um problema: na definição do $A$ usamos o real $\alpha$, ou seja,
nossa definição presupõe que já temos os reais na nossa disposição;
mas os reais são o que estamos tentando construir, então obviamente não
podemos usá-los para construí-los!
Mesmo assim, podemos usar nossa intuição da reta real e da reta dos racionais
no nosso rascunho para nos ajudar resolver esse problema.
Note que caso que $\alpha$ é um racional a parte $B$ possui mínimo (o próprio $\alpha$);
no outro lado, os $B$'s que correspondem em irracionais não possuem mínimo.
Por exemplo, aqui os $1_\reals$ e $\sqrt 2_{\reals}$ como Dedekind cuts:
\math
\tikzpicture
\tikzi dedekindcut_one;
\endtikzpicture
\\
\tikzpicture
\tikzi dedekindcut_sqrttwo;
\endtikzpicture
\endmath
Agora basta achar uma maneira que descreva todos os subconjuntos
do $\rats$ que podem ser usados como $A$'s num Dedekind cut,
para construir o $\reals$ como o conjunto de todos eles:
$$
\Reals \defeq \setstt {A \subset \rats} {$A$ parece como no desenho acima}.
$$

%%}}}

%%{{{ Q: How would you describe these A's? 
\question.
%%%{{{ meta 
%%%}}}

Como descreverias formalmente esses $A$'s?

%%}}}

\spoiler

%%{{{ df: dedekind_cut 
\definition Dedekind cuts.
%%%{{{ meta 
\label dedekind_cut
\defines
    * Dedekind cut
    ;;
\credits
    * Dedekind : Dedekind cut
    ;;
%%%}}}

Chamamos $A$ de {\Dedekind[cut]}\dterm{Dedekind cut} sse:
\elist i:
\li:dedekind_cut_downwards_closed
$A$ é ``fechado pra baixo'': $\pforall {a \in A} \lforall {q \in \rats} {q < a \implies q \in A}$;
\li:dedekind_cut_nomax
$A$ não possui máximo: $\pforall {a \in A} \lexists {a' \in A} {a < a'}$;
\li:dedekind_cut_nonempty
$A \neq \emptyset$;
\li:dedekind_cut_nonfull
$A \neq \rats$.
\endelist
Visualmente parece melhor chamar de \dterm{Dedekind cut} a partição
$\set{A, B}$ ou o par $\tup{A, B}$.  As vezes fazemos isso, algo que
nunca gera confusão graças ao contexto.

%%}}}

%%{{{ x: formalreals_for_the_working_mathematician 
\exercise.
%%%{{{ meta 
\label formalreals_for_the_working_mathematician
%%%}}}

Defina o que falta para o $\Reals$ virar uma representação
de reais útil para o \emph{matemático trabalhador}.

%%}}}

%%{{{ thm: existence_of_reals 
\theorem Existência dos reais.
%%%{{{ meta 
\label existence_of_reals
\pdefs 
    \pdef R {{\cal R}}
    \pdef P {{\rm P}}
    ;;
%%%}}}

Existe um corpo ordenado competo.

\proof.
Seja
$\R \defeq \sset \Reals {+_\R, \ntimes_\R, -_\R, 0_\R, 1_\R, \P_\R}$
um conjunto estruturado,
onde todos os componentes devem estar já definidos
no~\ref[formalreals_for_the_working_mathematician].
Falta só demonstrar que o $\R$ realmente satisfaz os axiomas
de corpo ordenado completo, que deixo para
o~\ref[formalreals_is_a_complete_ordered_field].

%%}}}

%%{{{ x: formalereals 
\exercise.
%%%{{{ meta 
\label formalereals
%%%}}}

O que acontece se apagar os \reftag[dedekind_cut_nonempty] e
\reftag[dedekind_cut_nonfull] da \ref[dedekind_cut]?

%%}}}

%%{{{ More numbers 
\note Mais numeros.
%%%{{{ meta 
%%%}}}

Podemos construir mais mas nosso objetivo aqui não é formalizar
e implementar tudo; apenas apreciar as possibilidades
e o poder da teoria dos conjuntos nesse quesito, e obter
pelo menos o que precisamos aqui:
naturais, inteiros, racionais, reais.
Como exercício, deixo pra ti a construção dos complexos
(que raramente aparecem aqui como \emph{cameo}).
Se quiser implementar ainda mais, sinta-se a vontade aprofundar.

%%}}}

%%{{{ x: construct_complex 
\exercise.
%%%{{{ meta 
\label construct_complex
%%%}}}

Construa os complexos.

%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS INTERMISSION 
\problems Intervalo de problemas.
%%%{{{ meta 
%%%}}}

%%{{{ prob: multiset_formally_defined 
\problem Multisets.
%%%{{{ meta 
\label multiset_formally_defined
\indexes
    * multiset
    ;;
%%%}}}

Alguém te deu a seguinte especificação de multiset
e tu queres implementá-la dentro da teoria de conjuntos.
(Veja também \ref[Multisets] no \ref[Collections].)
\eop
\noi
{\bf ``Definição''.}
Lembre (\ref[Multisets]) que um \dterm{multiset} (ou \dterm{bag})
$M$ é como um conjunto onde um elemento pode pertencer ao $M$ mais que
uma vez (mas não uma infinidade de vezes).
Ou seja, a ordem não importa (como nos conjuntos),
mas a ``multiplicidade'' importa sim.
\eop
Queremos tres operações em multisets, exemplificadas assim:
$$
\align
    \bag{ x, y, y, z, z, z, w } \bagunion
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, y, z, z, z, u, v, v, w }\\
    \bag{ x, y, y, z, z, z, w } \baginter
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, y, z, z }\\
    \bag{ x, y, y, z, z, z, w } \bagplus
    \bag{ x, y, z, z, u, v, v } &=
    \bag{ x, x, y, y, y, z, z, z, z, z, u, v, v, w }
\endalign
$$
Também queremos um predicado de ``pertencer'' $\inbag$
e uma relação de ``submultiset'' $\subbag$ tais que:
$$
\xalignat2
x&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\subbag    \bag{ x, x, y, y, z, z }            \\
z&{}\inbag \bag{ x, y, y, z, z, z, w }           &\bag{ x, y, z, z }&{}\notsubbag \bag{ x, x, y, y, z }               \\
u&{}\ninbag \bag{ x, y, y, z, z, z, w }        &\bag{ x, y, z, z }&{}\subbag    \bag{ x, y, z, z }                  \\
x&{}\ninbag \emptybag \quad\text{para todo $x$}&M                 &{}\subbag    M \quad\text{para todo multiset $M$}\\
 &                                               &\emptybag         &{}\subbag    M \quad\text{para todo multiset $M$}. 
\endxalignat
$$
(MS1) Para os multisets $A$ e $B$ temos $A = B$ sse eles têm os mesmos membro
com as mesmas multiplicidades.
Por exemplo,
$$
\bag{x, y, z, z, y} = \bag{x, y, y, z, z} \neq \bag{x,y,z}.
$$
(MS2) Para cada conjunto $A$, a classe
$$
\classstt M {$M$ é multiset e $\forall x(x \inbag M \limplies x \in A)$}
$$
de todos os multisets formados por membros de $A$ é um conjunto.
\item{(i)}
Defina formalmente (em teoria de conjuntos) o termo ``multiset'' e mostre
(como exemplos) como são representados os multisets seguintes:
$$
\emptybag
\qqqquad
\bag{0, 1, 2, 2, 1}
\qqqquad
\bag{1, 2, 2, 3, 3, 3, 4, 4, 4, 4, \dotsc }.
$$
\item{(ii)}
Defina as operações de multisets ($\bagunion, \baginter, \bagplus$)
e os predicados ($\inbag$, $\subbag$).
\item{(iii)}
Demonstre pelos axiomas ZF que tua definição satisfaz as (MS1)--(MS2).

\hint
Para representar a multiplicidade, use uma função com codomínio o $\nats_{>0}$.

\solution
(i)
Um \dterm{multiset} é uma tupla $\cal M = \tup{ M ; f }$
onde $M$ é um conjunto e $f : M \to \nats_{>0}$.
$$
\align
\emptybag                       &= \tup{ \emptyset ; \emptyset }\\
\bag{0, 1, 2, 2, 1}             &= \tup{ \set{0,1,2} ; f }\\
\bag{1, 2, 2, 3, 3, 3, \dotsc}  &= \tup{ \nats_{>0} ; \idof {\nats_{>0}} }\\
\endalign
$$
onde $f : \set{0,1,2} \to \nats_{>0}$ é a função definida pela
$$
f(n) = \knuthcases {
    1,  &se $n = 0$\cr
    2,  &se $n = 1$\cr
    2,  &se $n = 2$.
}
$$
\eop
(ii)
$$
\align
\tup{A;\alpha} \bagunion \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \baginter \tup{B;\beta}&\defeq\tup{A\inter B \;;\; \lambda x. \max\set{\alpha(x),\beta(x)}}\\
\tup{A;\alpha} \bagplus  \tup{B;\beta}&\defeq\tup{A\union B \;;\; \lambda x. (\alpha(x) + \beta(x))}\\
x \inbag \tup{A;\alpha} &\defiff x \in A\\
\tup{A;\alpha} \subbag \tup{B;\beta} &\defiff A\subset B \mland (\forall x \in A)[ \alpha(x) \leq \beta(x)]
\endalign
$$
\eop
(iii)
A (MS1) é obviamente satisfeita graças à nossa definição de múltiset como tupla
de conjunto e função: ganhamos assim a (MS1) pelas definições de $(=)$ nos três
tipos envolvidos: conjunto; tupla; função.
Vamos verificar a (MS2).
Seja $A$ conjunto.
O arbitrário multiset $\cal M$ com membros de $A$ tem a forma
$\cal M = \tup{X , f}$ para algum $X\subset A$ e $f : X \to\nats_{>0}$.
Então $\cal M \in \pset A \times (A \parto \nats_{>0})$ e construimos o conjunto
de todos os multisets com membros de $A$ usando o ZF4:
$$
\namedop{Multisets}(A) \defeq
    \set{
        \cal M\in \pset A \times (A \parto \nats_{>0})
        \st
        \text{$\cal M$ é um multiset}.
    }
$$
Para mostrar que o $\pset A \times (A \parto \nats\setminus\set{0})$ é um conjunto,
precisamos os operadores $\pset$, $\times$, $\parto$, $\setminus$, e o próprio $\nats$, que já temos construido pelos ZF1--ZF7.

%%}}}

%%{{{ prob: formalreals_is_a_complete_ordered_field 
\problem.
%%%{{{ meta 
\label formalreals_is_a_complete_ordered_field
\pdefs 
    \pdef R {{\cal R}}
    \pdef P {{\rm P}}
    ;;
%%%}}}

Demonstre que o $\R$ do \ref[existence_of_reals] satisfaz
mesmo as leis e corpo ordenado completo.

%%}}}

\endproblems
%%}}}

%%{{{ More_axioms (ZF) 
\section Mais axiomas (ZF).
%%%{{{ meta 
\label More_axioms
%%%}}}

%%{{{ Credits 
\note Créditos.
%%%{{{ meta 
\label fol_filter_by_fraenkel_and_skolem
\credits
    * Zermelo
    * Fraenkel
    * Skolem
    ;;
%%%}}}

Todos os axiomas que temos visto até agora são essencialmente os
axiomas de Zermelo, e falta apenas um dos seus axiomas originais
(o axioma da escolha que encontramos na~\reftag[Axioms_of_choice]).
Sobre o axioma Separation~\axref[separation], Zermelo usou o termo
``propriedade definitiva'', que temos usado também sobre o ``filtro'',
mas foram Fraenkel e~Skolem que consideraram definir isso
como uma fórmula da linguagem da FOL com $(=)$ e $(\in)$.

%%}}}

%%{{{ A letter from Fraenkel to Zermelo 
\note Uma carta de Fraenkel para Zermelo.
%%%{{{ meta 
\credits
    * Fraenkel : carta para Zermelo
    ;;
%%%}}}

Fraenkel percebeu (e comunicou no \yearof{1921} para Zermelo) que
com os seus axiomas não é possível demonstrar a existência duns certos
conjuntos interessantes, como por exemplo o
$$
\bigset{ \Nats, \pset\Nats, \pset\pset\Nats, \pset\pset\pset\Nats, \dotsc }.
$$
Sim, podemos construir cada um dos seus elementos, mas não a
colecção deles como conjunto!

%%}}}

%%{{{ ax: replacement 
\axiom Replacement (schema).
%%%{{{ meta 
\label replacement
\defines
    * axioma!Replacement (schema)
    ;;
%%%}}}

{\rm Para cada função-classe $\Phi(\dhole)$, o seguinte:}
Para todo conjunto $a$, a classe
$
\classimg \Phi a \defeq \classst {\Phi(x)} {x \in a}
$
é um conjunto.
$$
\forall a
\exists b
\forall y
\bigparen{
    y \in b
    \liff
    \lexists {x \in a} {\Phi(x) = y}
}
\axtag[replacement=ZF8]
$$

%%}}}

%%{{{ x: powersingleton_without_powerset 
\exercise.
%%%{{{ meta 
\label powersingleton_without_powerset
%%%}}}

Resolve o~\ref[powersingleton] sem usar o Powerset~\axref[powerset].

\hint
Qual operador $\Phi(\dhole)$ tu podes definir para aplicá-lo no $a$?

\solution
Definimos o operador $\Phi(\dhole)$ assim:
$$
\Phi(x) \defeq \set x.
$$
Facilmente, pelo Replacement~\axref[replacement] aplicado no $a$ com
esse $\Phi$ temos que
$\classimg \Phi a$
é um conjunto: o conjunto que procuramos!

%%}}}

%%{{{ A mortal game 
\note Um jogo mortal.
%%%{{{ meta 
%%%}}}

Teu oponente escolha um conjunto (e ele não participa mais no jogo):
esse é o ``conjunto da mesa''.
Em cada rodada do jogo tu tem que escolher um dos membros do conjunto da mesa,
e ele se vira o novo conjunto da mesa.
O objectivo é simples: \emph{continuar jogando pra sempre}.
(Imagine que se o jogo acabar, tu morre---e que tu queres viver---ou algo desse tipo.)
Então uma partida onde o oponente escolheu o conjunto
$$
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}},
\set{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}}}}
$$
seria a seguinte
(sublinhamos as escolhas do jogador onde possível):
$$
\matrix
\format
\c\quad & \c\quad & \c \\
\text{Rodada} & \text{Conjunto} & \text{Movimento}\\
1 & \bigset{ \emptyset, \ \fsset{\emptyset}, \ \underline{\fsset{\emptyset, \fsset{\emptyset}}}, \ \fsset{ \emptyset, \fsset{\emptyset}, \fsset{\emptyset, \fsset{\emptyset}} } } & \fsset{\emptyset, \fsset{\emptyset}}\\
2 & \bigset{\emptyset, \underline{\fsset{\emptyset}}} & \fsset{\emptyset} \\
3 & \bigset{\underline{\emptyset}} & \emptyset\\
4 & \emptyset & \boohoo
\endmatrix
$$
Talvez esse jogador não foi o mais esperto, mas facilmente confirmamos
que qualquer possível estratégia dele é condenada com morte certa depois
dum finito número de rodadas.
\emph{E se o próprio jogador começa escolhendo qual é o conjunto da mesa inicial?}
Qual conjunto tu escolheria?
Pode \emph{imaginar} algum conjunto que seria uma boa opção que porderia garantir
vitória?

%%}}}

\spoiler

%%{{{ x: how_to_win_the_wf_game 
\exercise.
%%%{{{ meta 
\label how_to_win_the_wf_game
%%%}}}

Considere os conjuntos da mesa seguintes:
\tlist:
\li: o conjunto $x$, onde
$$
x = \bigset{ \emptyset, \ \Nats, \ \set{ \emptyset, \set{\set{\emptyset}}}, \ x };
$$
\li: o conjunto $a$, onde
$$
\xalignat3
a &= \bigset{ \emptyset, \ b } &
b &= \bigset{ \set{\emptyset}, \ c } &
c &= \bigset{ \set{\emptyset}, \ \set{ \set{a}, \set{\set{\set{\emptyset}}}}};
\endxalignat
$$
\li: o conjunto $\Omega$, onde
$$
\Omega = \bigset{ \Omega }.
$$
\endtlist
Como tu jogaria nesses jogos?

%%}}}

%%{{{ Can we win? 
\note Podemos ganhar?.
%%%{{{ meta 
%%%}}}

Talvez.  Nossos axiomas \emph{não garantam a existência} de nenhum conjunto
que nos permitaria ganhar; contudo, \emph{nem garantam a ausência} de
conjuntos como os $x,a,b,c,\Omega$ do~\ref[how_to_win_the_wf_game].
O axioma seguinte resolve essa questão, afirmando que qualquer partida
desse jogo seria realmente mortal.

%%}}}

%%{{{ ax: foundation 
\axiom Foundation.
%%%{{{ meta 
\label foundation
\defines
    * axioma!Foundation
    ;;
\indexes
    * axioma!Regularity    see: Foundation.
    ;;
%%%}}}

Todo conjunto não vazio tem membro disjunto com ele mesmo.
$$
\pforall {a\neq\emptyset}
\lexists {z \in a} {z\inter a = \emptyset}
\axtag[foundation=ZF9]
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Vamos agora pesquisar umas conseqüências desse axioma,
também conhecido como \dterm{Regularity}.

%%}}}

%%{{{ x: x_notin_x 
\exercise.
%%%{{{ meta 
\label x_notin_x
%%%}}}

Demonstre diretamente que para todo conjunto $x$, $x\nin x$.
Quais axiomas tu precisou?

\hint
Seja $x$ conjunto.
Não podemos aplicar o~\reftag[foundation] diretamente no $x$,
pois talvez $x = \emptyset$.
Uma abordagem seria separar casos.
Ao inves disso, aplique o~\reftag[foundation] no conjunto $\set x$.

%%}}}

%%{{{ cor: univ_not_in_univ 
\corollary.
%%%{{{ meta 
\label unit_not_in_univ
%%%}}}

$\Univ\nin\Univ$, ou seja, $\Univ$ não é um conjunto.

%%}}}

%%{{{ x: x_y_cannot_belong_to_each_other 
\exercise.
%%%{{{ meta 
\label x_y_cannot_belong_to_each_other
%%%}}}

Demonstre que é impossível para dois conjuntos $x,y$ ter
$x \in y$ e também $y \in x$.

%%}}}

%%{{{ x: no_infinite_in_descending_chain_of_sets 
\exercise.
%%%{{{ meta 
\label no_infinite_in_descending_chain_of_sets
%%%}}}

Demonstre que não existe seqüência infinita de conjuntos
$$
x_0 \ni x_1 \ni x_2 \ni x_3 \ni \dotsb
$$
e mostre que assim ganhamos os
exercícios~\reftag[x_notin_x]~\&~\reftag[x_y_cannot_belong_to_each_other]
como corolários.

%%}}}

%%{{{ x: spooky_pair_becomes_good_pair 
\exercise Spooky pair agora.
%%%{{{ meta 
\label spooky_pair_becomes_good_pair
%%%}}}

Demonstre que com o axioma Foundation podemos sim usar a operação
do~\ref[spooky_pair]
$$
\tup{x,y} \defeq \bigset{ x, \set{x, y} }
$$
como uma implementação de par ordenado.

%%}}}

%%{{{ ZF_theory 
\note ZF.
%%%{{{ meta 
\label ZF_theory
\credits
    * Zermelo  : ZF
    * Fraenkel : ZF
    ;;
\defines
    * teoria dos conjuntos!ZF
    * \ZF   -- a teoria dos conjuntos Zermelo--Fraenkel (without Choice)
    ;;
\indexes
    * working mathematician
    * ZFC   see: teoria dos conjuntos
    ;;
%%%}}}

A teoria dos axiomas \axref[extensionality]--\axref[foundation]
junto com o \ref[principle_of_purity] é conhecida como $\ZF$:
Zermelo--Fraenkel (without Choice).
O \emph{working mathematician} típico---sendo pouco
mimado---tá querendo mais do que a $\ZF$ oferece como fundação!
Falta um ingrediente só, que é nosso próximo assunto: o axioma da escolha.

%%}}}

\endsection
%%}}}

\TODO Arrumar/espalhar as próximas 4 seções.

%%{{{ Wosets 
\section Wosets.
%%%{{{ meta 
\label Wosets
%%%}}}

%%{{{ intro 
\secintro
O termo \emph{wellorder} (ou \emph{well-order}) de inglês tem sido traduzido
como \emph{boa ordem} em português.  Aqui eu uso o termo \emph{bem-ordem}.
Além de ficar mais perto no termo internacional, a palavra ``bem'' tem
um significado \emph{bem} mais usado em português do que em inglês,
onde não é muito \emph{well} known, exemplificado aqui:\foot
e com certeza \emph{well} beyond nossos interesses aqui
\toof
\eop\smallskip
Uma ordem é uma relação legal.
\eop
Uma \emph{bem}-ordem é uma relação \emph{bem}~legal---vamos descobrir isso nesta secção.
%%}}}

%%{{{ df: woset 
\definition Bem-ordem.
%%%{{{ meta 
\label woset
\indexes
    * conjunto!bem-ordenado    see: woset
    ;;
\defines
    * woset
    ;;
%%%}}}

Seja $\sset A <$ um conjunto totalmente ordenado.
Sua ordem $(<)$ é uma \dterm{bem-ordem}, sse
\emph{cada subconjunto $S\subset A$ possui um elemento mínimo}.
Nesse caso chamamos o $A$ \dterm{bem-ordenado} ou \dterm{woset}
(de \dterm{well-ordered set}).

%%}}}

\TODO Elaborar.

%%{{{ x: spot_the_wosets_1 
\exercise.
%%%{{{ meta 
\label spot_the_wosets_1
%%%}}}

Quais dos $\ints$, $\rats$, $\rats_{>0}$, $\rats_{\geq0}$, $\reals$,
são bem ordenados por sua ordem?

%%}}}

%%{{{ x: spot_the_wosets_2 
\exercise.
%%%{{{ meta 
\label spot_the_wosets_2
%%%}}}

Seja $a\in\reals$.
Quais dos $\rats_{\geq a}$, $\reals_{\geq a}$,
e $\setst {2^{-n}} {n \in\nats, n \leq a}$
satisfázem a propriedade de boa ordem?

%%}}}

\endsection
%%}}}

%%{{{ Transfinite induction 
\section Indução transfinita.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Transfinite recursion 
\section Recursão transfinita.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ The_ordinals 
\section Os ordinais.
%%%{{{ meta 
\label The_ordinals
%%%}}}

%%{{{ x: omegaomega_plus_one_is_well_ordered 
\exercise.
%%%{{{ meta 
\label omegaomega_plus_one_is_well_ordered
%%%}}}

O $\omega^2+1$ é bem ordenado.

\hint
Lembre-se que usamos a ordem (anti)lexicográfica nos produtos.
Tome $A$ tal que $\emptyset\neq A \subset \omega^2 + 1$ e ache se u mínimo.
Separe casos dependendo se $A=\set{\top}$ ou não,
onde $\top$ o máximo elemento do $\omega^2+1$.

\solution
Seja $A\subset \omega^2 + 1$ com $A\neq\emptyset$.
Temos a seguinte ordem no $\omega^2 + 1$:
$$
\mubrace{
 \mubrace{\tup{0,0} < \tup{1,0} < \tup{2,0} < \dotsb}{\dsize\omega} 
 <
 \mubrace{\tup{0,1} < \tup{1,1} < \tup{2,1} < \dotsb}{\dsize\omega} 
 <
 \dotsb
}{\dsize\omega^2}
<
\set\top.
$$
\proofcase {Caso $A = \set {\top}$}:
$\min A = \top$.
\eop
\proofcase {Caso $A \neq \set {\top}$}:
Como $A\neq \emptyset$, concluimos que $A\inter \omega^2 \neq \emptyset$.
Sejam:
$$
\align
y_0 &\asseq \min\setst {y\in\nats} {\lexists {x\in\nats} {\tup{x,y}\in A}}\\
x_0 &\asseq \min\setst {x\in\nats} {\tup{x,y_0}\in A}
\endalign
$$
onde os dois mínima existem graças ao PBO dos naturais.
Facilmente, $\min A = \tup{x_0,y_0}$.

%%}}}

%%{{{ x: solving_for_ordinals 
\exercise.
%%%{{{ meta 
\label solving_for_ordinals
%%%}}}

O que podes concluir sobre os ordinais $\alpha$ e $\beta$ se\dots:
$$
\xxalignat3
\text{(i)}~&\omega + \alpha = \omega & \text{(iii)}~& \omega \cdot \alpha = \omega & \text{(v)}~& \alpha +     \beta = \omega\\
\text{(ii)}~&\alpha + \omega = \omega & \text{(iv)}~& \alpha \cdot \omega = \omega & \text{(vi)}~& \alpha \cdot \beta = \omega
\endxxalignat
$$

\solution
\item{(i)}   $\alpha = 0$
\item{(ii)}  $\alpha$ é finito
\item{(iii)} $\alpha=1$
\item{(iv)}  $\alpha$ finíto \& $\alpha\neq 0$
\item{(v)}   $\text{ou}\,\leftbrace {\aligned&\text{$\alpha$ finíto      \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=0$}\endaligned}$
\item{(vi)}  $\text{ou}\,\leftbrace {\aligned&\text{$1\leq\alpha<\omega$ \& $\beta=\omega$}\\&\text{$\alpha=\omega$ \& $\beta=1$}\endaligned}$

%%}}}

\endsection
%%}}}

%%{{{ Axioms_of_choice (ZFC) 
\section Axiomas de escolha (ZFC).
%%%{{{ meta 
\label Axioms_of_choice
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Finalmente encontramos aqui o último axioma de Zermelo,
o mais infame, seu \emph{axioma de escolha}.
Mas, primeiramente, umas definições.

%%}}}

%%{{{ df: choice_set 
\definition Conjunto-escolha.
%%%{{{ meta 
\label choice_set
\defines
    * conjunto-escolha
    ;;
%%%}}}

Seja $\scr A$ uma família de conjuntos.
Chamamos o $E$ um \dterm{conjunto-escolha} da $\scr A$ sse
(1) $E \subset \union \scr A$, e
(2) para todo $A \in \scr A$, a intersecção $E \inter A$ é um singleton.

%%}}}

%%{{{ eg: choice_sets 
\example.
%%%{{{ meta 
\label choice_sets
%%%}}}

Aqui umas famílias de conjuntos e um exemplo de conjunto-escolha para cada uma:
$$
\xalignat2
\scr A_1 &= \set{ [0,2], [1,4], [3,5] }
&&{\set{ 0, \,5/2, \,5 }}\\
\scr A_2 &= \set{ \set{a,b}, \set{b,c}, \set{d} }
&&{\set{a,c,d}}\\
\scr A_3 &= \set{ \set{a,b}, \set{b,c}, \set{c,a} }
&&\text{não tem conjunto-escolha}\\
\scr A_4 &= \set{ \emptyset, \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\text{não tem conjunto-escolha}\\
\scr A_5 &= \set{            \set{\emptyset}, \set{\set{\emptyset}}, \set{\set{\set{\emptyset}}}, \set{\set{\set{\set{\emptyset}}}}, \dots }
&&\scr A_4\\
\scr A_6 &= \set{ \finord 1, \finord 2, \finord 3, \dotsc }
&&\text{não tem conjunto-escolha}
\endxalignat
$$

%%}}}

%%{{{ df: choice_function 
\definition Função-escolha.
%%%{{{ meta 
\label choice_function
\defines
    * função-escolha!de conjunto
    * função-escolha!de família
    ;;
%%%}}}

Seja $A$ conjunto.
Chamamos a $\epsilon : \pset A \setminus \set{\emptyset} \to A$
uma \dterm{função-escolha do conjunto} $A$ sse $\epsilon(X) \in X$ para todo $X\in\dom\epsilon$.
\eop
Seja $\scr A$ família de conjuntos.
Chamamos a $\epsilon : \scr A \to \Union \scr A$ uma
\dterm{função-escolha da família de conjuntos} $\scr A$ sse
$\epsilon(A) \in A$ para todo $A\in \scr A$.

%%}}}

%%{{{ ax: choice_ac 
\axiom Choice (AC).
%%%{{{ meta 
\label choice_ac
\defines
    * axioma!Choice (AC)
    ;;
%%%}}}

Seja $\scr A$ família de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr A \to \Union \scr A$,
tal que
}\\
\text{
para todo $A\in\scr A$,
$\epsilon(A) \in A$.
}
\endgathered
\axtag[ac=AC]
$$

%%}}}

%%{{{ ax: choice_ac_disjoint 
\axiom Choice (forma disjunta).
%%%{{{ meta 
\label choice_ac_disjoint
%%%}}}

Seja $\scr D$ família disjunta de conjuntos não vazios.
Então
$$
\gathered
\text{
existe
$\epsilon : \scr D \to \Union \scr D$,
tal que
}\\
\text{
para todo $D\in\scr D$,
$\epsilon(D) \in D$.
}
\endgathered
\axtag[acdisj=ACdis]
$$

%%}}}

%%{{{ ax: choice_ac_pset 
\axiom Choice (forma powerset).
%%%{{{ meta 
\label choice_ac_powerset
%%%}}}

Seja $M$ conjunto não vazio.
Então
$$
\gathered
\text{
existe
$\epsilon : \pset M\setminus\set{\emptyset} \to M$,
tal que
}\\
\text{
para todo
$\emptyset\neq A\subset M$,
$\epsilon(A) \in A$.
}
\endgathered
\axtag[acpset=ACpow]
$$

%%}}}

%%{{{ x: first_ac_equivalences 
\exercise.
%%%{{{ meta 
\label first_ac_equivalences
%%%}}}

Todas as ``formas'' do axioma de escolha (AC) que vimos até agora
são logicamente equivalentes.
Demonstre isso seguindo o ``round-robin'' seguinte:
$$
\text{\axref[ac]}
\implies \text{\axref[acdisj]}
\implies \text{\axref[acpset]}
\implies \text{\axref[ac]}.
$$

%%}}}

%%{{{ ZFC 
\note ZFC.
%%%{{{ meta 
\defines
    * teoria dos conjuntos!ZFC
    * \ZFC   -- a teoria dos conjuntos Zermelo--Fraenkel with Choice
    ;;
\indexes
    * esquema axiomático
    * working mathematician
    * ZFC   see: teoria dos conjuntos
    ;;
%%%}}}

Finalmente chegamos na fundação mais popular entre matemáticos,
a teoria dos conjuntos $\ZFC$ (Zermelo--Fraenkel with Choice)
composta por todos os axiomas da ZF junto com o AC:
$$
\ZFC = \ZF + \AC
$$
O \emph{working mathematician} típico provavelmente afirmaria
que trabalha dentro da $\ZFC$, mas em geral não vai saber
citar nem quais são seus próprios axiomas, tanto como um
programador típico não sabe dizer quais são os comandos
primitivos da linguagem primitiva nem da sua própria máquina
que tá usando para escrever e/ou executar seus programas.
Existem outras fundações interessantes, usadas, e investigadas;
voltarei nisso daqui a pouco (\reftag[Other_foundations]).

%%}}}

%%{{{ Pra que tantos axiomas? 
\note Pra que tantos axiomas?.
%%%{{{ meta 
\defines
    * finitamente axiomatizáve
    ;;
\indexes
    * teoria dos conjuntos!ZFC
    * esquema axiomático
    ;;
%%%}}}

Sabemos desde o \ref[how_many_axioms_so_far] que
estamos usando uma quantidade infinita
de axiomas, por causa dos usos de esquemas axiomáticos
(veja~\ref[axioms_vs_axiomatic_schemata]).
Já que a $\ZFC$ é tão importante e usada, faz sentido
nos perguntar se alguém poderia achar
outra maneira de axiomatizar a mesma teoria usando
apenas uma quantidade finita de axiomas, ou seja,
se a teoria $\ZFC$ é \dterm{finitamente axiomatizável}.
Não é o caso: Montague demonstrou na sua tese
\cite[montaguethesis] que isso é impossível:

%%}}}

%%{{{ thm: montague_theorem 
\theorem Montague.
%%%{{{ meta 
\label montague_theorem
\credits
    * Montague : teorema
    ;;
\indexes
    * teoria dos conjuntos!ZFC
    * finitamente axiomatizável
    ;;
%%%}}}

A teoria $\ZFC$ não é finitamente axiomatizável.

%%}}}

\endsection
%%}}}

%%{{{ Desired and controversial consequences 
\section Conseqüências desejáveis e controversiais.
%%%{{{ meta 
%%%}}}

\TODO Terminar.

%%{{{ intro 
\secintro
Vamos ver aqui umas conseqüências do axioma da escolha \axref[ac].
Muitas delas na verdade são logicamente equivalentes a ele!
Certos desses teoremas são realmente desejáveis para os
matemáticos, mas outros parecem tão parádoxos que o assunto
acaba sendo controversial.
%%}}}

%%{{{ thm: banach_tarski 
\theorem Banach--Tarski.
%%%{{{ meta 
\label banach_tarski
\credits
    * Banach : paradoxo --Tarski
    * Tarski : paradoxo Banach--
    ;;
\indexes
    * paradoxo!Banach--Tarski
    ;;
%%%}}}

Podemos decompor a bola sólida unária
$$
B = \setst {\tup{x,y,z} \in \reals^3} {x^2 + y^2 + z^2 \leq 1}
$$
em $5$ subconjuntos
$\sym 1, \sym 2, \sym 3, \sym 4, \sym 5 \subset S$,
rodar e transladar eles, criando duas cópias sólidas de $B$.

%%}}}

%%{{{ thm: wellordering_thm 
\theorem Bem-ordenação (Zermelo).
%%%{{{ meta 
\label wellordering_thm
\indexes
    * teorema!da bem-ordenação
    ;;
%%%}}}

Todo conjunto $A$ pode ser bem ordenado.

%%}}}

%%{{{ thm: cardinal_comparability_thm 
\theorem Comparabilidade de cardinais.
%%%{{{ meta 
\label cardinal_comparability_thm
%%%}}}

Para todos conjuntos $A,B$, temos $A\leqc B$ ou $B \leqc A$.

%%}}}

\endsection
%%}}}

%%{{{ Weaker choices 
\section Escolhas mais fracas.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Other axiomatizations 
\section Outras axiomatizações.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ A different point of view 
\section Um outro ponto de vista.
%%%{{{ meta 
%%%}}}

\TODO Terminar.

%%{{{ Language bug (I): Theory of what?! 
\note Linguagem bugada (I): teoria dos quais?!.
%%%{{{ meta 
\label theory_of_what
\defines
    * teoria dos grupos
    * teoria dos conjuntos
    ;;
%%%}}}

Considere o que chamamos de \dterm{teoria dos grupos},
que encontramos estudar no \ref[Group_theory].
E agora pense no que chamamos de \dterm{teoria dos conjuntos}
e estudamos neste capítulo.
Os dois estudos têm umas diferenças gritantes que vamos identificar
e analisar agora.
Olhe nos axiomas de grupos:
cada um \emph{afirma algo sobre o que acontece dentro dum grupo}.
São do tipo:
\tlist:
\li: para qualquer objeto $g$, tal coisa existe;
\li: existe um objeto que faz aquilo;
\li: para quaisquer objetos $g,h$, tal coisa acontece;
\endtlist
etc.
Podemos vê-los como uma definição de quando uma tal estrutura
merece ser chamada de \dterm{grupo}.
\eop
Observe que existem dois \dq{razoaveis}
interpretações do termo \emph{universo} na teoria dos grupos:
\elist i:
\li: um seria o carrier set $\carrier G$, assim supondo que
     \emph{estamos vivendo dentro dum grupo especifico $G$};
\li: o outro seria a classe de todos os grupos.
\endelist
Os axiomas da teoria dos grupos estão usando a idéia da
primeira interpretação.
Axiomas do segundo tipo seriam proposições como as seguintes:
\tlist:
\li: Para todo grupo $G$, existe um group $G'$ tal que bla blu\dots
\li: Existe grupo com exatamente dois membros.
\li: Para quaisquer grupos $G,H$, existe grupo $A$ tal que blu bla\dots
\endtlist
Em vez disso, os axiomas da teoria dos grupos estão referindo
ao que acontece \dq{dentro} dum grupo.
(Observe que as proposições em cima não são nem \emph{enunciáveis}
dentro dum grupo!)
Podemos vê-los como definição do que significa \dterm{ser um grupo}.
Tome aqui um conjunto talmente estruturado.
Satisfaz as leis de grupo?
Beleza então, vamos chamá-lo de grupo.
Não satisfaz as leis de grupo?
Também beleza, não vamos chamá-lo de grupo e vida que segue.
\eop
Vida que segue sim, pois não estamos usando a teoria dos grupos como
fundação de matemática!  Por outro lado, se encontrar algo que viola
os axiomas da teoria dos conjuntos\dots morte que segue sim!\foot
OK, \emph{talvez} ninguém vai morrer por causa disso
mas com certeza a fundação vai cair todinha, ou seja, não vai ser
mais uma fundação.  E quem quer viver sem fundações matemáticas?
\toof
\eop
Os axiomas da teoria dos conjuntos então não estão falando nada
sobre o que acontece \emph{dentro dum conjunto}---pelo que eles
saibam nem existe o conceito de interior dum conjunto!---e não
pode ser vista como definição do que significa \dterm{ser conjunto}
no sentido que falei sobre as leis dos grupos.
\eop
Infelizmente a linguagem e terminologia usada não é consistente
e contribui na possível confusão criada na tua cabeça lendo
este texto neste momento.
Estamos usando os nomes inconsistentemente escolhidos
\wq{teoria dos grupos} e \wq{teoria dos conjuntos}.
Felizmente a inconsistência é \emph{apenas mais uma} da linguagem
natural que já temos aceitado (e aproveitado) tais \dq{features}
dela, então não é tão problemático para os acostumados.\foot
os falantes nativos duma linguagem não percebem as inconsistências
gramáticas da sua própria linguagem até encontrar um gringo que
reclama delas.
\toof
Para ficar consistentes, alguém precisaria renomear exatamente
uma das duas frases:
ou a \wq{teoria dos grupos} para \wq{teoria dos membros-de-grupo},
ou a \wq{teoria dos conjuntos} para \wq{teoria dos universos}.
Seguindo a maioria dos usos da frase \wq{teoria dos \dots}
a segunda alternativa parece melhor.
\eop
A primeira coisa que fazemos em grupos é procurar
\dterm{modelos dos axiomas}, ou seja, grupos!
Em teoria dos conjuntos não fizemos isso \emph{aqui}.
Meio que deixamos subentendido que tem um modelo só,
\dq{a colecção dos verdadeiros conjuntos} ou sei-lá-o-que
e ficamos procurando ver \wq{o que mais tem por aqui?}\dots
\wq{ah, olha, descobrimos um novo membro do nosso universo}, etc.
Mas, podemos---e devemos!---tratar a teoria dos conjuntos como
\dterm{teoria dos universos} também e procurar ver quantos universos
temos, quais são eles, achar novos, compará-los, etc.
E teoristas dos conjuntos a tratam nessa forma também;
o \ref[set_theory_model_hunting] é um brinquedo para
ajudar visualizar a idéia num nível elementar.
\eop
Mas vamos voltar na treta principal deste momento:
o que chamamos de \emph{grupo} na primeira teoria?
Qualquer \emph{modelo} cujos membros são os objetos referidos pelos axiomas.
Os \emph{objetos} então não são os grupos; mas seus membros
(e não demos um nome especial para eles).
E chamamos essa coisa de \emph{teoria dos \dots} dos quais mesmo?
Dos \emph{grupos}, ou seja, escolhemos o termo do nosso
universo para usar como nome da teoria.
Mas o que chamamos de \emph{conjunto} na segunda teoria?
Agora não é o universo, mas os objetos!
E qual nome escolhemos para esse estudo?
\emph{Teoria dos conjuntos}, ou seja, agora usamos o nome
dos nossos objetos e não do universo para chamar a disciplina.

%%}}}

%%{{{ x: set_theory_model_hunting 
\exercise.
%%%{{{ meta 
\label set_theory_model_hunting
%%%}}}

Escolhe \strikeout{subconjuntos} \emph{subcolecções} dos axiomas ZF1--ZF6
e tente criar modelos diferentes para cada uma delas.
Dê cada modelo em forma dum desenho dum grafo direcionado: o gráfico da
relação $\in$ onde os vértices são os objetos
(os \emph{sets}, os \emph{conjuntos}),
e botamos aresta (seta) de $a$ para $b$ quando \wq{$a$ possui $b$ como membro}.
Tecnicamente isso seria o gráfico da $\ni$, mas ajuda mais desenhar
assim modelos-universos.

%%}}}

%%{{{ Language bug (II): Collection vs Set 
\note Linguagem bugada (II): Colecção \vs conjunto.
%%%{{{ meta 
\label collection_vs_set
\defines
    * conjunto
    * classe
    * colecção
    ;;
\indexes
    * metalinguagem
    * abuso
    ;;
%%%}}}

Mais um desafio criado apenas pela terminologia e linguagem que usamos:
o termo \emph{conjunto} faz parte da nossa metalinguagem, e lá é usado
como um sinónimo dos termos \emph{colecção}, \emph{classe},
\emph{aglomerado}, \emph{grupo}, etc.
Mas aqui precisamos separar os dois conceitos diferentes
e logo faz sentido adoptar palavras distintas para cada uso.
Chamamos então de \dterm{conjunto} (ou de \dterm{set}) um objeto
do universo duma teoria dos conjuntos e reservamos
o termo \dterm{colecção} para referir à idéia intuitiva.
Se for necessário precuramos salientar tal distinção na notação
matemática pois ela aparece na nossa metalinguagem também.
O mais que nossa maturidade aumenta, o menos que procuramos
tais distincções---pois o contexto elimina possíveis confusões
para o versado---e o mais que acabamos abusando notações e termos.
\eop
A distinção é importante pois não existe necessariamente uma
correspondencia entre os dois (aliás, já vimos que na colecção
de todos os objetos dum universo, não corresponde um objeto-membro
na ZF).
\eop
Mas é bem mais que isso.
Por exemplo, entendemos o $\pset A$ como
\wq{o conjunto de todos os subconjuntos de $A$}.
Certo?
Sim e não:
tanto o \emph{conjunto} quanto o \emph{subconjunto} nessa frase
foram usados com o sentido formal da teoria mesmo, como certos
objetos que satisfazem certas coisas (tudo isso dentro dum universo).
\eop
Olha uma conclusão importante disso:
\quote
\wq{Seja $A$ conjunto.}
\endquote
traduzindo para a terminologia mais fria de ZF:
\quote
\wq{Seja $A$ objeto.}
\endquote
e traduzindo para um desenho daqueles que desenhou no
\ref[set_theory_model_hunting] isso vira
\quote
\wq{Seja $A$ um vértice no desenho do universo.}
\endquote
E agora: o que é o $\pset A$?
Pensando com nossa meta-cabeça nas meta-palavras \emph{conjunto}
e \emph{subconjunto} podemos nos confundir que $\pset A$ seria
a colecção de todas as subcolecções de $A$, entendo também aqui
o $A$ como a colecção dos seus membros.
Mas na verdade, nosso universo/desenho \emph{pode faltar de
certas colecções}, que na nossa meta-cabeca existem, mas no
universo não!
Mas observe que tal falta não seria perceptível dentro do universo, pois:
a palavra \emph{conjunto} significa \emph{objeto} e não \emph{colecção};
similarmente \emph{subconjunto} significa o que foi definido significar
e não \emph{subcolecção}; etc.
\eop
Isso parece que pode criar uns problemas, quebrando uns teoremas e tal.
Por exemplo, o que acontece se umas relações de cardinalidade entre
conjuntos ($\eqc$ ou $\ltc$) que deveriam ser num jeito, parecem não ser?
O problema vai embora assim que perceber que a palavra \emph{função}
também sofre o mesmo abuso linguístico:
temos as funções do nosso meta-mundo, e temos o que definimos para
significar \emph{função} dentro dum universo.
No caso, entao, as funções que iam criar o problema que tememos
com nossos meta-olhos simplesmente não existem no nosso universo!
Ou seja, não sao \emph{funções-objetos} mas \emph{metafunções} e
logo as definições que demos referindo às funções na teoria dos
conjuntos não estão referindo a elas!
\eop
Qual o moral da estoria?
É uma boa prática no começo reservar uma palavra diferente
para o \wq{objeto que satisfaz os axiomas ZF} e outra para
a noção intuitiva de \wq{colecção de coisas} (como entendo desde
que me lembro de ser humano).
Aqui então chamamos a primeira de \dterm{conjunto} ou de
\dterm{set} e a segunda de \dterm{colecção} mesmo.
E similarmente sobre todos os outros termos que usamos
tanto no mundo formal dos objetos quanto na metalinguagem.
Usamos os termos \dterm{função} para os objetos e
\dterm{mapeamento} ou \dterm{mapa} para o conceito intuitivo.
Novamente: abusamos tais coisas com mais experiência e
quando o contexto é suficiente para eliminar confusões.

%%}}}

%%{{{ Skolem's paradox 
\note O paradoxo de Skolem.
%%%{{{ meta 
\label more_stuff
\credits
    * Skolem : paradoxo
    ;;
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Other_set_theories 
\section Outras teorias de conjuntos.
%%%{{{ meta 
\label Other_set_theories
%%%}}}

\TODO Terminar.

%%{{{ Which axioms? 
\note Quais axiomas?.
%%%{{{ meta 
\label theory_of_what
\defines
    * equiconsistente
    ;;
%%%}}}

Uma outra diferença entre as disciplinas da teoria dos
grupos e da teoria dos conjuntos encontra-se na ambiguïdade
do segundo termo.
Quando encontrar um \dterm{teorista dos grupos}
trabalhando num outro canto, num outro país, pergunte e veja:
o que ele chama de grupo será o que chamamos de grupo aqui também:
qualquer coisa que satisfaz os (G0)--(G3) é um grupo e pronto.\foot
Pequenas diferenças podem aparecer como já mencionamos em
outras disciplinas, como a teoria dos anéis---tem $1$ ou não?---mas
mesmo assim não chegam ser algo tão assumidamente (e propositadamente)
diverso.
\toof
Porém, não existe \emph{a} teoria dos conjuntos.
Os \dterm{teoristas dos conjuntos}, têm como um objeto do
seu estudo varias teorias diferentes.
Em tal teoria dos conjuntos acontece isso, naquela teriamos
essa outra coisa, basta substituir tal axioma dela por esses
dois, e teremos construido um tal bicho aqui, etc.
Isso não acontece em teoria dos grupos!
\eop
O que estudamos então na disciplina teoria dos conjuntos
poderia ter comecado com:
\wq{chamamos de \dterm{modelo-ZF1--ZF6} qualquer colecção de
objetos com uma relação \sq{$\in$} que satisfaz tais coisas: \dots}
E depois:
\wq{se um modelo-ZF1--ZF6, satisfaz tambem o (ZF7), o chamamos de
\dterm{modelo-ZF1--ZF7}}, etc.
Isso é para lembrar das frases como a \wq{se um grupo (isto é, modelo-G0--G3)
satisfaz o (G4), chamamos de \dterm{grupo abeliano} (isto é, modelo-G0--G4)}.
\eop
E todas essas teorias de conjuntos são equivalentes?
Umas são, mas em geral não---ainda bem, pois não teria graça assim!
Observe que já encontramos várias que não são
(todas baseadas nos ZF) simplesmente adicionando ou não
algum dos próximos axiomas; e, alem disso, podemos
adicionar \emph{negações} de tais axiomas e acabar com
teorias \dterm{equiconsistentes:}
se uma é consistente, entao a outra também é e vice versa.

%%}}}

%%{{{ ZF, ZFC, NBG, NF, MK 
\note ZF, ZFC, NBG, NF, MK.
%%%{{{ meta 
\label more_stuff
\credits
    * Bernays    : NBG
    * vonNeumann : NBG
    * Godel      : NBG
    * Fraenkel   : ZF
    * Skolem     : ZF
    * Zermelo    : ZF
    * Morse      : MK
    * Kelley     : MK
    * Skolem     : MK
    * Wang       : MK
    * Quine      : NF
    * Quine      : ML
    * Aczel      : anti-foundation
    * Aczel      : CZF
    * Russell    : paradoxo
    ;;
\defines
    * teoria dos conjuntos!NBG
    * teoria dos conjuntos!NF
    * teoria dos conjuntos!MK
    * teoria dos conjuntos!CZF
    ;;
\indexes
    * NBG   see: teoria dos conjuntos
    * MK    see: teoria dos conjuntos
    * CZF   see: teoria dos conjuntos
    * NF    see: teoria dos conjuntos
    * New Foundations   see: NF
    * set builder
    ;;
%%%}}}

Tem outras teorias dos conjuntos mais diferentes, as mais famosas
seriam as:
\dterm{NBG} (von Neumann--Bernays--Gödel);
\dterm{NF} (New Foundations, de Quine); e
\dterm{MK} (Morse--Kelley).
NBG e MK têm a noção de \emph{classe} dentro delas
(lembre se que ZF não possui classes formalmentes,
ficaram por fora, e apareceram só no meta-mundo).
NF possui um objeto-universo dentro dela e mesmo assim
não permite Russell explodir o mundo:
em vez de limitar a parte esquerda do set builder,
limita a parte direita (o filtro).

%%}}}

\endsection
%%}}}

%%{{{ Other_foundations 
\section Outras fundações.
%%%{{{ meta 
\label Other_foundations
%%%}}}

\TODO ETCS, MLTT, HoTT.

\TODO connection with unityped \vs statically typed languages.

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ three_classes_are_sets_problem 
\problem.
%%%{{{ meta 
\label three_classes_are_sets_problem
%%%}}}

Seja $a$ conjunto.
\emph{Sem usar} o Separation~\axref[separation],
mostre pelo resto dos axiomas que as classes seguintes são conjuntos:
\mathcols 3
E &= \setlst {\set{x, \Union x,\pset x}} {x\in a} ; &
F &= \setlst x {x\psubset a} ;                      &
G &= \setst  x {x\neq\emptyset \land x = \Inter x}.
\endmathcols

%%}}}

%%{{{ replacement_replaces_separation 
\problem Replacement is the new Separation---or is it?.
%%%{{{ meta 
\label replacement_replaces_separation
%%%}}}

Podemos tirar o Separation scheme~\axref[separation]
dos nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~\axref[replacement] no lugar dele?

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto $A$, vai ``identificar'' todos
aqueles que \emph{não} tem a propriedade $\phi(\dhole)$,
mas mesmo assim sendo injetora quando restrita naqueles
que satisfazem a.

\hint
Além de tudo isso, os ``originais'' $a\in A$ tem que ser
recuperáveis pelas suas imagens atraves da $\Phi$.

\solution
Seja $A$ conjunto e $\phi(x)$ fórmula.
Definimos a class-function
$$
\Phi(x) =
\knuthcases {
    \set {x},   &se $\phi(x)$\cr
    \emptyset,  &se não.
}
$$
Agora aplicamos o Replacement com essa class-function no conjunto $A$,
ganhando assim como conjunto o $\classimg\Phi A$, cujos elementos são exatamente os
\emph{singletons} $\set{a}$ de todos os $a\in A$ que satisfazem a $\phi(a)$,
e o $\emptyset$.
Usando o ZF6 chegamos no $\Union \classimg\Phi A$ que realmente é o desejado
conjunto
$\setst {a \in A} {\phi(a)}$.

%%}}}

%%{{{ replacement_replaces_pairset 
\problem Replacement is the new Pairset---or is it?.
%%%{{{ meta 
\label replacement_replaces_pairset
%%%}}}

Podemos tirar o Pairset~\axref[pairset] dos
nossos axiomas ``sem perder nada'', se temos o
Replacement scheme~\axref[replacement] no lugar dele?

\hint
Podemos sim.
Dados \emph{objetos} $a,b$, mostre que existe o conjunto
$\set{a,b}$ que consiste em exatamente esses objetos.

\hint
Tente achar uma class-function $\Phi$ tal que aplicada
nos elementos dum conjunto suficientemente grande,
vai ter como imagem o desejado $\set{a,b}$.

\solution
Sejam $a,b$ objetos.
Considere a class-function
$$
\Phi (x) \asseq 
\knuthcases {
    a, &se $x=\emptyset$\cr
    b, &se $x\neq\emptyset$.
}
$$
Agora precisamos apenas construir um conjunto $S$ tal que:
$\emptyset \in S$, e $|S| \geq 2$.
Pelo Emptyset, temos o $\emptyset$.
Pelo Powerset aplicado no $\emptyset$ ganhamos o $\set{\emptyset}$, e aplicando mais uma vez o Powerset chegamos no $\set{\emptyset, \set{\emptyset}}$.
Usando o Replacement com a $\Phi(x)$ nesse conjunto, construimos o desejado $\set{a,b}$.
\eop
Em forma de árvore:
$$
\AxiomC{}
\RightLabel{Empty}
\UnaryInfC{$\emptyset$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset}$}
\RightLabel{Power}
\UnaryInfC{$\set{\emptyset, \set{\emptyset}}$}
\RightLabel{Repl; $\Phi$}
\UnaryInfC{$\set{a, b}$}
\DisplayProof
$$

%%}}}

%%{{{ find_the_crime_of_foundation 
\problem.
%%%{{{ meta 
\label find_the_crime_of_foundation
%%%}}}

Na resolução do~\ref[bad_pair], tem um roubo.
Ache e explique.

%%}}}

%%{{{ spooky_pair_problem 
\problem.
%%%{{{ meta 
\label spooky_pair_problem
%%%}}}

No~\ref[spooky_pair] demonstraste que a operação binária definida pela
$$
\tup{x,y} \defeq \bigset{ x, \set{x,y} }
$$
satisfaz a propriedade~\mref[spec_tup2].
Depois, no~\ref[spooky_pair_becomes_good_pair], usando o \axref[foundation]
conseguimos demonstrar que satisfaz a propriedade~\mref[spec_tup1] também.
Mostre que o~\axref[foundation] é necessário para conseguir isso,
mostrando um contraexemplo: conjuntos $a,b,a',b'$ tais que
$$
\tup{a,b} = \tup{a',b'}
$$
mas mesmo assim pelo menos uma das $a = a'$ e $b = b'$ não é válida.

\hint
Obviamente, teu contraexemplo tem que envolver conjuntos mal-funda\-men\-ta\-dos.

\hint
Considere conjuntos $x,y,o$ com a propriedade
$$
x = \set { o, \set{x,y} }
$$
onde $o \neq y$.

\hint
Calcule o
$$
\tup{ \set{x,y}, o }
$$
e ache que ele é igual com um par ordenado diferente.
(Tem que demonstrar que é difernete mesmo!)

\solution
Considere um $x$ mal-fundamentado, que satisfaz a
$$
x = \set { o, \set{x,y} }
$$
para alguns $y,o$ onde $o \neq y$.
Calculamos o
$$
\align
\tup{ \set{x,y}, o }
&= \set{ \set{x,y}, \set{ \set{x,y}, o } } \\
&= \set{ \set{x,y}, x } \\
&= \tup{ x , y }
\endalign
$$
mesmo com $o \neq y$, ou seja, achamos um contraexemplo mesmo.

%%}}}

%%{{{ choice_rel_problem 
\problem.
%%%{{{ meta 
\label choice_rel_problem
%%%}}}

Mostre que o Choice~\axref[ac] é equivalente com o seguinte axioma:
\eop
\noi
{\bf Choice (Rel).}
{\proclaimstyle
Se uma relação $R \in \relspace{A,B}$ tem a propriedade de totalidade,
então existe função $f : A\to B$ com $x \rel R f(x)$ para todo $x\in A$.
}
$$
\bigparen{
R \in \relspace{A,B}
\land
\dom R = A
}
\limplies
\bigparen{
\pexists {f : A \to B}
\lforall {x\in A} {x \mathrel R f(x)}
}
\axtag[acrel=ACrel]
$$

%%}}}

%%{{{ prob: reals_as_cauchy_seqs 
\problem Reais como seqüências Cauchy.
%%%{{{ meta 
\label reals_as_cauchy_seqs
%%%}}}

\TODO Enunciar o problema.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[fromfregetogodel],
\cite[halmosnaive],
\cite[ynmnst],
\cite[kunenfoundations].
\cite[kunen2011],
\cite[cohensetch],
\cite[kunen1980],
\cite[krivineast],
\cite[jechset],
\cite[kanamori].

Sobre teoria dos conjuntos construtiva: \cite[aczelrathjencst].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Metric_spaces 
\chapter Espaços métricos.
%%%{{{ meta 
\label Metric_spaces
%%%}}}

%%{{{ intro 
\chapintro
Logo depois do desenvolvemento da teoria de conjuntos de
{\Cantor}Cantor, no ano \yearof{1906} {\Frechet}Fréchet introduziu
os \dterm{espaços métricos} na sua tese de doutorado~\cite[frechetthesis].
Neste capítulo estudamos as primeiras idéias básicas.
%%}}}

%%{{{ Distances 
\section Distáncias.
%%%{{{ meta 
\label Distances
%%%}}}

%%{{{ pseudodf: metric_space 
\pseudodefinition espaço métrico.
%%%{{{ meta 
\label metric_space_pseudodef
%%%}}}

Um \dterm{espaço métrico} é um conjunto equipado com uma
noção de \dterm{distância} entre quaisquer dois membros dele
em tal forma que:
\tlist:
\li: a distância de cada ponto para ele mesmo é $0$;
\li: a distância entre pontos distintos é positiva;
\li: a distância de $x$ para $y$ é a mesma da de $y$ para $x$;
\li: as distâncias satisfazem a desigualdade triangular.
\endtlist

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Bora formalizar:

%%}}}

%%{{{ df: metric_space 
\definition espaço métrico.
%%%{{{ meta 
\label metric_space
%%%}}}

Seja $X$ conjunto.
Uma função $d : X^2 \to \reals$ é chamada
\dterm{métrica} no $X$ sse:
\mathcall
&d(x,y) \geq 0                \called {não-negatividade} \\
&d(x,x) = 0                   \called {} \\
&d(x,y) = d(y,x)              \called {simetria} \\
&d(x,y) \leq d(x,w) + d(w,y). \called {triangular} \\
&d(x,y) = 0 \implies x = y    \called {} \\
\endmathcall
Chamamos a última \dterm{desigualdade triangular},
e dados pontos $x,y \in X$ chamamos o valor $d(x,y)$
de $d$-\dterm{distância} entre os $x,y$,
omitindo o prefixo \symq{$d$-} quando a métrica é implicita
pelo contexto.
Um conjunto estruturado $\sset X d$ onde $d$ é uma métrica no $X$
é chamado \dterm{espaço métrico}.

%%}}}

%%{{{ df: premetric 
\definition pré-métrica.
%%%{{{ meta 
\label premetric
%%%}}}

Uma função $d : X^2 \to \reals$ que satisfaz as primeiras 4 propriedades
da \ref[metric_space] é chamada \dterm{pré-métrica} (ou \dterm{pseudométrica}).

%%}}}

%%{{{ x: premetric_justify 
\exercise.
%%%{{{ meta 
\label premetric_justify
%%%}}}

Justifique o nome \wq{pré-métrica}.

%%}}}

%%{{{ eg: metric_space_eg_reals 
\example.
%%%{{{ meta 
\label metric_space_eg_reals
%%%}}}

Os reais $\sset \reals d$ onde
$$
d(x,y) = \abs{x - y}.
$$

%%}}}

%%{{{ eg: metric_space_eg_plane 
\example.
%%%{{{ meta 
\label metric_space_eg_plane
%%%}}}

O plano euclideano $\sset {\reals^2} d$ onde
$$
d(\tup{x_1,x_2},\tup{y_1,y_2}) = \sqrt{ (x_1-y_1)^2 + (x_2 - y_2)^2 }.
$$

%%}}}

%%{{{ eg: metric_space_eg_discrete 
\example.
%%%{{{ meta 
\label metric_space_eg_discrete
%%%}}}

Seja $X$ um conjunto e defina a função $d : X^2 \to \reals$ pela
$$
d(x,y) =
\knuthcases {
0, & se $x = 0$ \cr
1, & caso contrário.
}
$$
O $\sset X d$ é um espaço métrico.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Esse espaço é bastante importante e merece seu próprio nome:

%%}}}

%%{{{ df: discrete_metric 
\definition discreto.
%%%{{{ meta 
\label discrete_metric
%%%}}}

Dado conjunto $X$, a \dterm{métrica discreta} nele é a função
$d : X^2 \to \reals$ definida pela
$$
d(x,y) =
\knuthcases {
0, & se $x = y$ \cr
1, & caso contrário.
}
$$
O $\sset X d$ é chamado \dterm{espaço métrico discreto}.

%%}}}

%%{{{ x: explain_euclidean_metric_of_plane 
\exercise.
%%%{{{ meta 
\label explain_euclidean_metric_of_plane
\credits
    * Pythagoras : métrica euclideana
    ;;
%%%}}}

Donde chegou essa $d$ do~\ref[metric_space_eg_plane]?

\hint
De Pythagoras.
Como?
Demonstre!

%%}}}

%%{{{ x: derive standard metric of ℝ³ 
\exercise.
%%%{{{ meta 
%%%}}}

Qual seria a métrica ``standard'' do $\reals^3$?

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Em qualquer espaço métrico, podemos definir a noção de
$\epsilon$-perto:

%%}}}

%%{{{ df: epsilon_close_in_metric 
\definition ε-perto.
%%%{{{ meta 
\label epsilon_close_in_metric
\defines
    * perto!em espaço métrico
    ;;
%%%}}}

Sejam $x,y\in X$ e $\epsilon > 0$.
Dizemos que
$$
\text{$x,y$ são $\epsilon$-perto}
\defiff
d(x,y) < \epsilon.
$$

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Assim temos de graça a definição de limite.
Literalmente copiamos a~\ref[limit_of_sequence_of_reals]:

%%}}}

%%{{{ df: limit_in_metric 
\definition limite.
%%%{{{ meta 
\label limit_in_metric
\defines
    * {~{\seqn a n}} \tends ~\ell  -- a seqüência $\seqn a n$ tende ao $\ell$
    * limite!espaço métrico
    ;;
%%%}}}

Seja $\seqn a n$ uma seqüência num espaço métrico $\sset X d$.
Dizemos que $\seqn a n$ \dterm{tende ao limite} $\ell$
sse a partir dum membro $a_N$, todos os seus membros
ficam $\epsilon$-perto do $\ell$.
Ou seja:
$$
\seqn a n \tends \ell
\defiff
\pforall  {\epsilon > 0}
\pexists  {N \in \nats}
\lforallt {i \geq N}
{$a_i$ é $\epsilon$-perto de $\ell$}.
$$
Escrevemos
$$
\liml_n a_n = \ell
$$
como sinônimo de $\seqn a n \tends \ell$.
\mistake

%%}}}

%%{{{ beware: we need to prove uniqueness again 
\beware.
%%%{{{ meta 
%%%}}}

Lembra do erro da~\ref[limit_of_sequence_of_reals]
que descobreste no~\reftag[limit_of_sequence_of_reals_uniqueness_needed]?
Pois é, junto com a definição, copiamos seu errinho também,
mas não ganhamos de graça sua resolução,
pois a demonstração de unicidade de limites
(\ref[uniqueness_of_limits_of_reals])
usou a definição de \emph{$\epsilon$-perto} dos reais,
e aqui isso mudou.
Então sim, tu tens um trabalho pra fazer agora:

%%}}}

%%{{{ x: uniqueness_of_limits_in_metric 
\exercise Unicidade de limites (espaços métricos).
%%%{{{ meta 
\label uniqueness_of_limits_in_metric
%%%}}}

Demonstre a unicidade dos limites.

\hint
Olhe para a demonstração do~\ref[uniqueness_of_limits_of_reals].

%%}}}

\endsection
%%}}}

%%{{{ Examples and nonexamples 
\section Exemplos e nãœxemplos.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Open_and_closed_sets_in_metric 
\section Conjuntos abertos e fechados.
%%%{{{ meta 
\label Open_and_closed_sets_in_metric
%%%}}}

%%{{{ open_in_metric 
\definition.
%%%{{{ meta 
\label open_in_metric
%%%}}}

Um conjunto $A \subset X$ é \dterm{aberto} (ou \dterm{open})
sse todo $a \in A$ tem bola contida no $A$:
$$
\text{$A$ aberto}
\defiff
\pforall {a \in A}
\lexists {\epsilon > 0}
         {\ball \epsilon a \subset A}.
$$

%%}}}

%%{{{ x: trivial_opens_in_metric 
\exercise.
%%%{{{ meta 
\label trivial_opens_in_metric
%%%}}}

Em todo espaço métrico $\sset X d$,
$X$ e $\emptyset$ são abertos.

%%}}}

%%{{{ x: balls_are_open 
\exercise.
%%%{{{ meta 
%%%}}}

Cada bola $\ball \epsilon x$ é um conjunto aberto.

%%}}}

%%{{{ df: nbhd_in_metric 
\definition.
%%%{{{ meta 
\label nbhd_in_metric
%%%}}}

Sejam $N \subset X$ e $a \in X$.
Dizemos que $A$ é uma \dterm{vizinhança} (ou \dterm{neighborhood},
ou \dterm{nbhd}) de $x$ sse $N$ contenha uma bola de $a$:
$$
\text{$N$ vizinhança de $a$}
\defiff
\lexists
{\epsilon > 0}
{\ball \epsilon a \subset N}
$$

%%}}}

%%{{{ x: nbhd_does_not_imply_open 
\exercise.
%%%{{{ meta 
%%%}}}

Demonstre ou refute a afirmação:
<<cada vizinhança é um conjunto aberto>>.

\hint
A afirmação é falsa.
Ache uma vizinhança $N_x$ dum ponto $x$ tal que $N_x$
não é aberto.
Dá pra achar nos reais.

%%}}}

%%{{{ x: binary_intersections_opens_are_open 
\exercise.
%%%{{{ meta 
\label binary_intersections_of_opens_are_open
%%%}}}

Intersecção binária de abertos é aberto.

%%}}}

%%{{{ x: finite_intersections_of_opens_are_open 
\exercise.
%%%{{{ meta 
\label finite_intersections_of_opens_are_open
%%%}}}

Intersecções finitas de abertos são abertos.

%%}}}

%%{{{ x: arbitrary_unions_of_opens_are_opens 
\exercise.
%%%{{{ meta 
\label arbitrary_unions_of_opens_are_opens
%%%}}}

Uniões arbitrárias de abertos são abertos.

%%}}}

%%{{{ df: punctured_in_metric 
\definition puncturados.
%%%{{{ meta 
\label punctured_in_metric
%%%}}}

Chamamos a $\ball \epsilon a \setminus \set{a}$ de
\dterm{bola puncturada} do $a$.
Similarmente, se e $N$ é uma vizinhança de $a$,
chamamos o $N \setminus \set{a}$ de
\dterm{vizinhança puncturada} de $a$.

%%}}}

%%{{{ df: limit_point 
\definition limit point, conjunto derivado.
%%%{{{ meta 
\label limit_point
\defines
    * limit point
    * conjunto derivado
    * \derived{~A} -- o conjunto derivado de $A$
    ;;
\indexes
    * ponto de acumulação  see: limit point
    ;;
%%%}}}

Sejam $A \subset X$ e $\ell \in X$.
Chamamos o $\ell$ um \dterm{limit point} de $A$ sse
existe seqüência $\seqn a n \subset A\setminus\set{\ell}$
que tende ao $\ell$:
$$
\seqn a n \tends \ell.
$$
Usamos o termo \dterm{ponto de acumulação} como sinônimo.
Chamamos o conjunto de todos os limit points de $A$ de \dterm{conjunto derivado de $A$} e o denotamos por $A'$.

%%}}}

%%{{{ criterion: limit_point_of_A_if_each_punctured_intersects_A 
\criterion.
%%%{{{ meta 
%%%}}}

Sejam $A \subset X$ e $\ell \in X$.
$$
\text{$\ell$ limit point de $A$}
\iff
\text{toda bola puncturada de $\ell$ intersecta o $A$}.
$$

%%}}}

%%{{{ df: closed_in_metric 
\definition.
%%%{{{ meta 
\label closed_in_metric
%%%}}}

Um conjunto $A \subset X$ é \dterm{fechado} sse
$A$ é fechado sob a operação de limites, ou seja,
sse todos os limit points do $A$ estão no $A$,
ou seja:
$$
\text{$A$ fechado}
\defiff
\lforall
{\ell \in X}
{\text{$\ell$ limit point de $A$} \implies \ell \in A}.
$$

%%}}}

%%{{{ criterion: closed_iff_complement_of_open 
\criterion.
%%%{{{ meta 
%%%}}}

Um conjunto $A \subset X$ é fechado sse
seu complemento $X \setminus A$ é aberto.

%%}}}

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: continuous_in_metric 
\definition.
%%%{{{ meta 
\label continuous_in_metric
%%%}}}

Sejam $f : \sset X d \to \sset Y \rho$ e $x_0 \in X$.
Chamamos a $f$ de \dterm{contínua no $x_0$} sse:
$$
\pforall {\epsilon > 0}
\pexists {\delta > 0}
\lforall {x \in X}
{\text{$x_0,x$ são $\delta$-perto} \implies \text{$f x_0, f x$ são $\epsilon$-perto}};
$$
ou, equivalentemente:
$$
\pforall {\epsilon > 0}
\lexists {\delta > 0}
{\img f {\ball \delta {x_0}} \subset \ball \epsilon {f x_0}}.
$$
Chamamos $f$ de \dterm{contínua} sse $f$ é contínua em cada $x \in X$.

%%}}}

\endsection
%%}}}

%%{{{ Completeness 
\section Completude.
%%%{{{ meta 
%%%}}}

%%{{{ df: complete_metric_space 
\definition complete.
%%%{{{ meta 
\label complete_metric_space
%%%}}}

Um espaço metrico em qual todas as seqüências Cauchy convergem
é chamado \dterm{completo}.

%%}}}

\endsection
%%}}}

%%{{{ Compactedness 
\section Compacidade.
%%%{{{ meta 
%%%}}}

%%{{{ df: compact_metric_space 
\definition.
%%%{{{ meta 
%%%}}}

Um espaço métrico é chamado \dterm{compacto} sse é totalmente limitado
e completo.

%%}}}

\endsection
%%}}}

%%{{{ Categories_and_metric_spaces 
\section Pouco de cats---categorias e espaços métricos.
%%%{{{ meta 
\label Categories_and_metric_spaces
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[simmonstopology],
\cite[kolmogorovfomin],
\cite[carothersreal].

``Baby Rudin''~\cite[babyrudin].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Topology 
\chapter Topologia.
%%%{{{ meta 
\label Topology
%%%}}}

%%{{{ What is a topology? 
\section O que é uma topologia.
%%%{{{ meta 
%%%}}}

%%{{{ note: topological_notions 
\note Vocabulário topológico.
%%%{{{ meta 
%%%}}}

Num espaço topológico podemos falar de conjuntos
\dterm{abertos} e de conjuntos \dterm{fechados};
para qualquer conjunto podemos falar so seu \dterm{fecho},
seu \dterm{interior}, e seu \dterm{derivado};
e falar de \dterm{pontos de acumulação}, de \dterm{vizinhanças},
de \dterm{compacidade}, \dterm{conexividade}, \dterm{separabilidade},
e por aí vai.
O conceito mais fundamental que queremos capturar com a introdução
de espaços topológicos é da \dterm{continuidade}.
Sim, o vocabulário topológico é bem grande mesmo;
mas é aplicável em tantas situações diferentes que aprendê-lo,
e se acostumar com as noções envolvidas acaba sendo um
investimento numa ferramenta versátil não apenas de comunicação
mas de pensamento também:
na mesma maneira que temos elaborado pensamento algébrico,
analítico, categorial, vamos elaborar um \emph{pensamento topológico}.

%%}}}

\TODO Relacionar com vocabulário categórico.

\endsection
%%}}}

%%{{{ Equivalent specifications 
\section Especificações equivalentes.
%%%{{{ meta 
%%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Queremos estabelecer logo as noções seguintes:
conjunto \dterm{aberto},
conjunto \dterm{fechado},
\dterm{vizinhança} de ponto,
\dterm{pontos de acumulação} de um conjunto,
\dterm{fecho} de conjunto,
\dterm{interior} de conjunto,
função \dterm{contínua}.
Cada especificação que encontramos aqui considera
uma dessas como noção primitiva, e logo procede
para obter o resto como definidas.
Nesta secção estabelecemos a equivalência entre
essas especificações através de qual ganhamos
nossa primeira experiência com as idéias elementares
de topologia.
E a partir da próxima seção começamos o estudo das
demais noções dos espaços topológicos; tentando trabalhar
numa maneira agnóstica, ou seja, sem escolher uma
especificação especifica.

%%}}}

%%{{{ spec: opens_space 
\specification Espaço de opens.
%%%{{{ meta 
\label opens_space
%%%}}}

Chamamos o $\sset X \opens$ de \dterm{espaço de opens}
onde $\opens$ é uma coleção de subconjuntos de $X$
$$
\opens \is \pset\pset X
$$
e onde as leis seguintes são satisfeitas:
\mathcol
&\text{$\opens$ é fechado sob interseções finitas}; \\
&\text{$\opens$ é fechado sob uniões (arbitrárias)}.
\endmathcol
Chamamos os membros da $\opens$ de \dterm{opens} (abertos).

%%}}}

%%{{{ spec: hoods_space 
\specification Espaço de hoods.
%%%{{{ meta 
\label hoods_space
%%%}}}

Chamamos o $\sset X \hoods$ de \dterm{espaço de vizinhanças}
(neighborhoods, ou hoods, ou nbhds) onde $\hoods$ é uma coleção de
subconjuntos de $X$
$$
\hoods \is \pset\pset X
$$
e onde as leis seguintes são satisfeitas:
\mathcol
&\text{todo ponto mora em alguma nbhd}; \\
&p \in N_1 \inter N_2
 \implies
 \lexists {N} {p \in N \subset N_1 \inter N_2}.
\endmathcol
Chamamos os membros da $\hoods$ de \dterm{nbhds}
ou de \dterm{vizinhaças}.

%%}}}

%%{{{ spec: hoodsys_space 
\specification Espaço de hoodsystems.
%%%{{{ meta 
\label hoods_space
%%%}}}

Chamamos o $\sset X {\famst {\hoods_x} {x \in X}}$
de \dterm{espaço de hood-systems}
onde $\faml \hoods x$ é uma $X$-família de
coleçoẽs de subconjuntos de $X$, ou seja,
para cada $x \in X$,
$$
\hoods_x \is \pset\pset X
$$
e onde para cada $x \in X$ as leis seguintes são satisfeitas:
\mathcol
&x \in \Inter\hoods_x \\
&\text{$\hoods_x$ é um filtro no $\pset X$} \\
&\pforall {N \in \hoods_x}
 \pexists {N \supset M \in \hoods_x}
 \lforall {m \in M}
          {M \in \hoods_m}.
\endmathcol
Chamamos o $\hoods_x$ de \dterm{sistema de $x$-nbhds},
e seus membros de \dterm{$x$-nbhds}.

%%}}}

%%{{{ spec: closure_space 
\specification Espaço de closure.
%%%{{{ meta 
\label closure_space
%%%}}}

Chamamos o $\sset X {\closure\uhole}$
de \dterm{espaço de closure}
onde
$$
\closure\uhole \is \pset X \to \pset X
$$
e onde para cada $A, B \subset X$ as leis seguintes são satisfeitas:
\mathcol
&\closure\emptyset = \emptyset; \\
&A \subset \closure A; \\
&\closure {\closure A} = \closure A; \\
&\closure {A \union B} = \closure A \union \closure B.
\endmathcol
Chamamos o $\closure A$ de \dterm{fecho de $A$}.

%%}}}

%%{{{ df: topology 
\definition topologia.
%%%{{{ meta 
\defines
    * topologia
    * {\opens {~{\cal S}}} -- a topologia do espaço $\cal S$
    ;;
%%%}}}

Dado um espaço $\cal S \inteq \sset S {\dots}$ onde a noção de conjunto aberto é disponível
(primitiva ou definida), chamamos de \dterm{topologia de $\cal S$}
a coleção de todos os conjuntos abertos de $\cal S$:
$$
\opens {\cal S} \defeq \setstt {O \subset S} {$O$ aberto}.
$$
Escrevemos apenas $\opens$ se o espaço é implícito pelo contexto.

%%}}}

%%{{{ x: closeds_space 
\exercise.
%%%{{{ meta 
\label closeds_space
%%%}}}

Dualize a \ref[opens_space] para chegar
na especificação que tem como noção
primitiva os \dterm{fechados}.

%%}}}

%%{{{ x: interior_space 
\exercise.
%%%{{{ meta 
\label interior_space
%%%}}}

Dualize a \ref[closure_space] para chegar
na especificação que tem como noção
primitiva a operação de \dterm{interior}.

%%}}}

\endsection
%%}}}

%%{{{ Bases_and_subbases 
\section Bases e subbases.
%%%{{{ meta 
\label Bases_and_subbases
%%%}}}

\endsection
%%}}}

%%{{{ Topological_spaces 
\section Uns espaços topológicos.
%%%{{{ meta 
\label Topological_spaces
%%%}}}

\endsection
%%}}}

%%{{{ Continuity 
\section Continuidade.
%%%{{{ meta 
\label Continuity
%%%}}}

%%{{{ df: continuous_at_point_in_topology
\definition contínua.
%%%{{{ meta 
\defines
    * função!contínua em ponto
    ;;
\label continuous_at_point_in_topology
%%%}}}

Sejam $p \in X \toby f Y$.
Dizemos que $f$ é \dterm{contínua no $p$} sse
para toda vizinhança $E$ de $f\fa p$,
existe vizinhança $D$ de $p$ tal que $f \img D \subset E$.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Um imaginaria que tendo definido o que significa \emph{contínua
num ponto do domínio} definiríamos \dterm{contínua} para significar
\emph{contínua em cada ponto do seu domínio}.
Conseguimos uma definição melhor que nem precisa olhar para
os pontinhos dos espaços envolvidos:

%%}}}

%%{{{ df: continuous_in_topology
\definition contínua.
%%%{{{ meta 
\defines
    * função!contínua
    ;;
\label continuous_in_topology
%%%}}}

Sejam $X \toby f Y$.
Dizemos que $f$ é \dterm{contínua no $t$} sse
$f$ reflete os abertos, ou seja:
para qualquer $Y$-aberto $U \ni t$, $\pre f U$
é $X$-aberto.

%%}}}

%%{{{ x: continuous_iff_continuous_at_each_point 
\exercise.
%%%{{{ meta 
\label continuous_iff_continuous_at_each_point
%%%}}}

Sejam $X \toby f Y$.
$$
\text{$f$ contínua} \iff \lforallt {x \in X} {$f$ contínua no $x$}.
$$

%%}}}

\endsection
%%}}}

%%{{{ Topology_constructions 
\section Construções.
%%%{{{ meta 
\label Topology_constructions
%%%}}}

\endsection
%%}}}

%%{{{ Compactness 
\section Compacidade.
%%%{{{ meta 
\label Compactness
%%%}}}

\endsection
%%}}}

%%{{{ Connectedness 
\section Conexidade.
%%%{{{ meta 
\label Connectedness
%%%}}}

\endsection
%%}}}

%%{{{ Separation 
\section Separação.
%%%{{{ meta 
\label Separation
%%%}}}

%%{{{ intro 
\secintro
Pelos olhos de um espaço topológico podemos
enxergar conjuntos e pontos mas o quão bem podemos distingüi-los
e separá-los varia.
Considere o espaço indiscreto com $2$ pontos ${0,1}$.
A topologia deste espaço não permite perceber nenhuma diferença
(topológica) entre os dois: aqui só tem dois conjuntos abertos:
o vazio, a qual nenhum dos dois pontos pertence, e o espaço inteiro,
a qual ambos pertencem.  Por outro lado, no espaço de Sierpinski
os dois pointos são distingüíveis, já que temos um aberto a
qual $\top$ pertence e $\bot$ não.
Há muitas maneiras de \emph{separar} coisas dum espaço topológico
e, dependendo do nível e da maneira que estamos querendo separar,
chegamos em conceitos diferentes.
Nesta seção vamos conhecer uns deles.
%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

Os primeiros axiomas estão se referindo à separação
entre dois pontos do espaço.

%%}}}

%%{{{ df: Kolmogorov_space 
\definition Kolmogorov.
%%%{{{ meta 
\defines
    * Espaço!de Kolmogorov
    ;;
%%%}}}

Dizemos que $X$ é um espaço de \dterm{Kolmogorov},
sse para quaisquer dois pontos distintos de $X$
existe vizinhança de um a qual não pertence o outro.

%%}}}

%%{{{ df: Frechet_space 
\definition Frechet.
%%%{{{ meta 
\defines
    * Espaço!de Fréchet
    ;;
%%%}}}

Dizemos que $X$ é um espaço de \dterm{Fréchet},
sse para quaisquer dois pontos distintos de $X$
existem vizinhanças de cada um a qual não pertence o outro.

%%}}}

%%{{{ x: Frechet_iff_closed_points 
\exercise.
%%%{{{ meta 
\label Frechet_iff_closed_points
%%%}}}

Seja $X$ um espaço topológico.
$$
\text{$X$ Fréchet} \iff \text{todo $p \in X$ é fechado}.
$$

%%}}}

%%{{{ df: Hausdorff_space 
\definition Hausdorff.
%%%{{{ meta 
\defines
    * Espaço!de Hausdorff
    ;;
%%%}}}

Dizemos que $X$ é um espaço de \dterm{Hausdorff},
sse para quaisquer pontos $p \neq q$ de $X$
existem vizinhanças disjuntas: $P$ de $p$ e $Q$ de $q$.

%%}}}

%%{{{ x: Hausdorff_compact_separation 
\exercise.
%%%{{{ meta 
\label Hausdorff_compact_separation
%%%}}}

Sejam $H$ um espaço Hausdorff, $K$ um subespaço compacto
de $H$ e $p$ um ponto fora do $K$.
Logo $K$ e $p$ podem ser separados por abertos assim:
existem abertos disjuntos $U, P$ tais que $U \supset K$,
$P \ni p$.

%%}}}

%%{{{ x: Hausdorff_compact_closed 
\exercise.
%%%{{{ meta 
\label Hausdorff_compact_closed
%%%}}}

Seja $H$ um espaço Hausdorff.
Todo subespaço compacto de $H$ é fechado.

%%}}}

%%{{{ blah 
\blah.
%%%{{{ meta 
%%%}}}

O próximo separa conjuntos de pontos fora deles:

%%}}}

%%{{{ df: regular_space 
\definition regular.
%%%{{{ meta 
\defines
    * Espaço!regular
    ;;
%%%}}}

Dizemos que $X$ é um espaço \dterm{regular},
sse para qualquer fechado $F$ e qualquer ponto $p \nin F$,
existem conjuntos abertos e disjuntos $G,P$ com $G \supset F$ e $P \ni p$.

%%}}}

%%{{{ df: normal_space 
\definition normal.
%%%{{{ meta 
\defines
    * Espaço!normal
    ;;
%%%}}}

Dizemos que $X$ é um espaço \dterm{normal},
sse para quaisquer fechados disjuntos $F,F'$,
existem abertos disjuntos $G,G'$ com $G \supset F$ e $G' \supset F'$.

%%}}}

%%{{{ thm: Urysohn_lemma 
\theorem Lema de Urysohn.
%%%{{{ meta 
\headerize
\label Urysohn_lemma
\credits
    * Urysohn : lema
    ;;
\indexes
    * lema!de Urysohn
    ;;
%%%}}}

Sejam $A,B$ disjuntos fechados de um espaço normal $X$.
Seja $[\alpha,\beta]$ um intervalo de reais.
Logo existe função continua
$$
f : X \to [\alpha,\beta]
$$
tal que $\img f A = \set {\alpha}$
e $\img f B = \set {\beta}$.

\sketch.
TODO.

%%}}}

\endsection
%%}}}

%%{{{ Convergences 
\section Convergências.
%%%{{{ meta 
\label Convergences
%%%}}}

\endsection
%%}}}

%%{{{ Countability 
\section Contabilidade.
%%%{{{ meta 
\label Countability
%%%}}}

\endsection
%%}}}

%%{{{ Categories_and_topological_spaces 
\section Pouco de cats---categorias e espaços topológicos.
%%%{{{ meta 
\label Categories_and_topological_spaces
%%%}}}

\endsection
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: reals_uncountable_second_proof 
\problem Cantor \vs Reais: 1884.
%%%{{{ meta 
\label reals_uncountable_second_proof
\credits
    * Cantor
    ;;
\indexes
    * conjunto!perfeito
    * perfeito!conjunto     see: conjunto
    ;;
%%%}}}

Encontramos aqui a segunda demonstração de Cantor sobre a incontabilidade
dos reais, \cite[cantor1884].
Cantor definiu os conceitos de ponto de acumulação, conjunto fechado, conjunto
denso em todo lugar, e conjunto perfeito.
Demonstre que:
\elist i:
\li: qualquer conjunto perfeito e não vazio é incontável;
\li: o intervalo $[0,1]$ da reta real é perfeito;
\endelist
concluindo assim que o $[0,1]$ é incontável.

%%}}}

%%{{{ prob: Why does this proof (1884) fail for rationals? 
\problem.
%%%{{{ meta 
%%%}}}

Por que não podemos usar o mesmo argumento para concluir que o
$\setst{q \in \rats}{a \leq q\leq b}$ também é incontável?

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[janichtopology],
\cite[simmonstopology],
\cite[munkrestopology],
\cite[willardtopology].

\cite[vickerstopology],
\cite[escardosynthetic].

\cite[johnstonestone].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Type_theory 
\chapter Teoria dos tipos.
%%%{{{ meta 
\label Type_theory
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

\cite[nederpeltgeuvers].
\cite[proofsandtypes].
\cite[programmingmltt].
\cite[piercetapl].
\cite[hott].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Lambdas_and_combinators 
\chapter Lambdas e combinadores.
%%%{{{ meta 
\label Lambdas_and_combinators
%%%}}}

%%{{{ The untyped lambda calculus 
\section O λ-calculus não-tipado.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Faithfully representing mathematics 
\section Representando matemática fielmente.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Programming 
\section Programmando.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Recursion and fixpoints 
\section Recursão e fixpoints.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Functional programming revisited 
\section Programação funcional revisitada.
%%%{{{ meta 
%%%}}}

\endsection
%%}}}

%%{{{ Combinatory_logic 
\section Lógica de combinadores.
%%%{{{ meta 
%%%}}}

%%{{{ df: first_combinators 
\definition.
%%%{{{ meta 
\label first_combinators
%%%}}}

$$
\xalignat4
    \cI\,x    &\Cto x     &   \cB\,x\,y\,z &\Cto x\,(y\,z) &   \cS\,x\,y\,z &\Cto x\,z\,(y\,z)&\cR\,x\,y\,z &\Cto y\,z\,x\\\\
    \cK\,x\,y &\Cto x     &   \cBp\,x\,y\,z&\Cto y\,(x\,z) &   \cW\,x\,y    &\Cto x\,y\,y     &\cV\,x\,y\,z &\Cto z\,x\,y\\\\
    \cM\,x    &\Cto x\,x  &   \cC\,x\,y\,z &\Cto x\,z\,y   &                                
\endxalignat
$$

%%}}}

%%{{{ x: some_equiv_to_I 
\exercise.
%%%{{{ meta 
\label some_equiv_to_I
%%%}}}

Mostre que o combinador
$\C S\ \C K\ (\C W\ (\C I\ \C B))$ comporta como o $\C I$.

%%}}}

%%{{{ x: another_equiv_to_I 
\exercise.
%%%{{{ meta 
\label another_equiv_to_I
%%%}}}

Mostre que o combinator
$\C C\ (\C W\ \C K)\ \C K\ \C W$ comporta como o $\C I$.

%%}}}

%%{{{ x: CL_define_Bp 
\exercise.
%%%{{{ meta 
\label CL_define_Bp
%%%}}}

Defina o $\cBp$ dos $\cI$, $\cM$, $\cB$, $\cC$.

%%}}}

%%{{{ x: CL_define_R 
\exercise.
%%%{{{ meta 
\label CL_define_R
%%%}}}

Defina o $\cR$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$.

%%}}}

%%{{{ x: CL_define_V 
\exercise.
%%%{{{ meta 
\label CL_define_V
%%%}}}

Defina o $\cV$ dos $\cI$, $\cK$, $\cM$, $\cB$, $\cBp$, $\cC$, $\cS$, $\cW$, $\cR$.

%%}}}

\endsection
%%}}}

%%{{{ Further reading 
\further.

\endfurther
%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

%%{{{ prob: what_does_this_lambda_term_with_minus_do 
\problem.
%%%{{{ meta 
\label what_does_this_lambda_term_with_minus_do
%%%}}}

Suponha que já temos definido um λ-term $\Lmac{minus}$,
que comporta corretamente, no sentido que:
$$
\align
\Lmac{minus}\ {\Lnum n}\ {\Lnum m}
&\Lfinto \knuthcases {
  \Lnum {n - m},   &se $n \geq m$\cr
  \Lnum {0},       &se $n < m$.
}
\endalign
$$
Explique o comportamento do termo
$$
\Lmac f  \asseq  \Llam n {n\ (\Lmac{minus}\ {\Lnum 1})\ {\Lnum 0}}
$$
quando for aplicado para um numeral de {\Church[numeral]}Church $\Lnum k$:
qual é a função $f : \nats\to\nats$ que o termo $\Lmac f$ computa?

\hint
Cuidado com Curry.

%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Lambda calculus:
\cite[nederpeltgeuvers],
\cite[lecturesch].
\cite[hindleyseldinlambdacl],
\cite[krivinelambda].
\cite[barendregtlambda].

Lógica de combinadores:
\cite[mockingbird],
\cite[bimbocl],
\cite[hindleyseldinlambdacl].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Denotational_semantics 
\chapter Semântica denotacional.
%%%{{{ meta 
\label Denotational_semantics
%%%}}}

%%{{{ PROBLEMS 
\problems.
%%%{{{ meta 
%%%}}}

\endproblems
%%}}}

%%{{{ Further reading 
\further.

Semântica denotacional de linguagens de programação:
\cite[stoysemantics],
\cite[winskelsemantics],
\cite[tennent1976],
\cite[tennentsemantics],
\cite[guntersemantics].

Especificamente sobre domínios para programação funcional:
\cite[streicherdomainsfp].

E para programação lógica:
\cite[lpbook].

\endfurther
%%}}}

\endchapter
%%}}}

%%{{{ chapter: Teasers 
\chapter Teasers.
%%%{{{ meta 
\label Teasers
%%%}}}

%%{{{ Linear_logic 
\section Lógica linear.
%%%{{{ meta 
\label Linear_logic
%%%}}}

\endsection
%%}}}

%%{{{ Proof_theory 
\section Teoria das demonstrações.
%%%{{{ meta 
\label Proof_theory
%%%}}}

%%{{{ Natural_deduction 
\note Dedução natural.
%%%{{{ meta 
\label Natural_deduction
\credits
    * Gentzen : dedução natural
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Sequent_calculus 
\note Cálculo de seqüentes.
%%%{{{ meta 
\label Sequent_calculus
\credits
    * Gentzen : cálculo de seqüentes
    ;;
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Hilbert_style 
\note Sistemas à la Hilbert.
%%%{{{ meta 
\label Hilbert_style
\credits
    * Hilbert : estilo de sistema de demonstração
    ;;
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Mathematical_logic 
\section Lógica matemática.
%%%{{{ meta 
\label Mathematical_logic
%%%}}}

\endsection
%%}}}

%%{{{ Computability_theory 
\section Teoria da computabilidade.
%%%{{{ meta 
\label Computability_theory
%%%}}}

%%{{{ A surprisingly difficult question 
\note Uma questão surpresamente difícil.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Models of computation 
\note Modelos de computação.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Recursion theory 
\note Teoria da recursão.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ Decision problems 
\note Problemas de decisão.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

%%{{{ The halting problem 
\note O problema da parada.
%%%{{{ meta 
%%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Computational_complexity 
\section Complexidade computacional.
%%%{{{ meta 
\label Computational_complexity
%%%}}}

%%{{{ A notação assintótica 
\note A notação assintótica.
%%{{{ meta 
%%}}}

\TODO Escrever.

%%}}}

%%{{{ Análise de algorítmos 
\note Análise de algorítmos.
%%{{{ meta 
%%}}}

\TODO Escrever.

%%}}}

%%{{{ Reduções 
\note Reduções.
%%{{{ meta 
%%}}}

\TODO Escrever.

%%}}}

%%{{{ Classes de complexidade 
\note Classes de complexidade.
%%{{{ meta 
%%}}}

\TODO Escrever.

%%}}}

\endsection
%%}}}

%%{{{ Further reading 
\further.

Teoria das demonstrações:
\cite[vonplatoelements],
\cite[bimboproof],
\cite[negrivonplatospt],
\cite[takeuti],
\cite[prawitz],
\cite[proofsandtypes],
\cite[olthdem],
\cite[kleeneIM].
\cite[lecturesch].
\cite[girardblindspot].

Lógica linear:
\cite[girardllss].
\cite[girardblindspot].

Computabilidade:
\cite[cutlandcomputability],
\cite[kleeneIM],
\cite[rogersrecursive].

\cite[kozenac], \cite[kozentc].

\cite[daviscu], \cite[davisccl], \cite[alicebook].

Teoria das funções recursivas:
\cite[kleeneIM: Part~III],
\cite[shoenfieldrecursion],
\cite[ynmrandc],
\cite[rogersrecursive].

\cite[bellmachover: Cap.~6--8].

Algoritmos e complexidade:
\cite[dpv],
\cite[jonescomputability].
\cite[gareyjohnson].

\endfurther
%%}}}

\endchapter
%%}}}

\endinput

